{
    "Task_id": 31,
    "Github_ID": "166592722",
    "Github_Project_Name": "onedriver",
    "Programming_Language": "Go",
    "suffix": ".go",
    "Interface_class": "IPC",
    "Interface_name": "Advanced HTTP client with custom http.Client and request headers",
    "Instruction": "Task Description: The task involves creating a struct and associated method to handle chunked file uploads to a remote server using HTTP PUT requests with proper content range headers.\n\nStruct Description: The UploadSession struct represents an ongoing file upload session, tracking upload state, metadata, and providing methods for chunked upload operations.\n\nFields:\n\nID: string - Unique identifier for the upload session\nOldID: string - Previous session ID (if applicable)\nParentID: string - ID of parent directory\nNodeID: uint64 - Filesystem node identifier\nName: string - Name of the file being uploaded\nExpirationDateTime: time.Time - When the upload session expires\nSize: uint64 - Total size of the file in bytes\nData: []byte - File content data being uploaded\nQuickXORHash: string - File content hash\nModTime: time.Time - File modification time\nretries: int - Number of upload retry attempts\nUploadURL: string - Server endpoint for chunk uploads\nETag: string - Entity tag from server response\nstate: int - Current upload state\nerror: error - Last encountered error\nsync.Mutex: - Mutex for thread-safe operations\n\nMethods:\n\nuploadChunk: (auth *graph.Auth, offset uint64) -> ([]byte, int, error) - Uploads a file chunk starting at specified offset. Returns response body, HTTP status code, and error if any. Handles authentication refresh and proper Content-Range headers.",
    "Canonical_solution": "import (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/jstaf/onedriver/fs/graph\"\n\t\"github.com/rs/zerolog/log\"\n)\n\ntype UploadSession struct {\n\tID                 string    `json:\"id\"`\n\tOldID              string    `json:\"oldID\"`\n\tParentID           string    `json:\"parentID\"`\n\tNodeID             uint64    `json:\"nodeID\"`\n\tName               string    `json:\"name\"`\n\tExpirationDateTime time.Time `json:\"expirationDateTime\"`\n\tSize               uint64    `json:\"size,omitempty\"`\n\tData               []byte    `json:\"data,omitempty\"`\n\tQuickXORHash       string    `json:\"quickxorhash,omitempty\"`\n\tModTime            time.Time `json:\"modTime,omitempty\"`\n\tretries            int\n\n\tsync.Mutex\n\tUploadURL string `json:\"uploadUrl\"`\n\tETag      string `json:\"eTag,omitempty\"`\n\tstate     int\n\terror\n}\n\nfunc (u *UploadSession) uploadChunk(auth *graph.Auth, offset uint64) ([]byte, int, error) {\n\tu.Lock()\n\turl := u.UploadURL\n\tif url == \"\" {\n\t\tu.Unlock()\n\t\treturn nil, -1, errors.New(\"UploadSession UploadURL cannot be empty\")\n\t}\n\tu.Unlock()\n\n\tend := offset + uploadChunkSize\n\tvar reqChunkSize uint64\n\tif end > u.Size {\n\t\tend = u.Size\n\t\treqChunkSize = end - offset + 1\n\t}\n\tif offset > u.Size {\n\t\treturn nil, -1, errors.New(\"offset cannot be larger than DriveItem size\")\n\t}\n\n\tauth.Refresh()\n\n\tclient := &http.Client{}\n\trequest, _ := http.NewRequest(\n\t\t\"PUT\",\n\t\turl,\n\t\tbytes.NewReader((u.Data)[offset:end]),\n\t)\n\trequest.Header.Add(\"Content-Length\", strconv.Itoa(int(reqChunkSize)))\n\tfrags := fmt.Sprintf(\"bytes %d-%d/%d\", offset, end-1, u.Size)\n\tlog.Info().Str(\"id\", u.ID).Msg(\"Uploading \" + frags)\n\trequest.Header.Add(\"Content-Range\", frags)\n\n\tresp, err := client.Do(request)\n\tif err != nil {\n\t\treturn nil, -1, err\n\t}\n\tdefer resp.Body.Close()\n\tresponse, _ := ioutil.ReadAll(resp.Body)\n\treturn response, resp.StatusCode, nil\n}",
    "FSMID_for_test": 102,
    "Code_level": "Class-level"
}