{
  "Task_id": 256,
  "Github_ID": "27790789",
  "Github_Project_Name": "schema-registry",
  "Programming_Language": "Java",
  "suffix": ".java",
  "Interface_class": "IPC",
  "Interface_name": "Kafka client Producer in java",
  "Instruction": "Task Description: Implement a Kafka Producer class for handling Dead Letter Queue (DLQ) messages in a rule-based processing system. The class should be able to configure a Kafka producer, convert various message types to bytes, populate message headers with rule context information, and send messages to a DLQ topic.\n\nClass Description: The `DlqAction` class is responsible for sending failed messages to a Dead Letter Queue (DLQ) topic in Kafka. It handles message serialization, header population, and asynchronous message sending with error handling. The class implements a `RuleAction` interface and provides configuration options for the DLQ topic and producer behavior.\n\nAttributes:\n\n- `log`: Logger - Logger instance for logging messages\n- `TYPE`: String - Constant identifying this action type as \"DLQ\"\n- `DLQ_TOPIC`: String - Configuration key for DLQ topic name\n- `DLQ_AUTO_FLUSH`: String - Configuration key for auto-flush setting\n- `PRODUCER`: String - Configuration key for producer instance\n- `HEADER_PREFIX`: String - Prefix for rule-related headers\n- `RULE_NAME`: String - Header key for rule name\n- `RULE_MODE`: String - Header key for rule mode\n- `RULE_SUBJECT`: String - Header key for rule subject\n- `RULE_TOPIC`: String - Header key for original topic\n- `RULE_EXCEPTION`: String - Header key for exception message\n- `configs`: Map<String, ?> - Configuration properties for the producer\n- `topic`: String - DLQ topic name\n- `autoFlush`: boolean - Flag for automatic flushing after send\n- `producer`: KafkaProducer<byte[], byte[]> - Kafka producer instance\n\nMethods:\n\n- `configure(Map<String, ?> configs)`: void - Configures the DLQ action with producer settings and topic name\n- `run(RuleContext ctx, Object message, RuleException ex)`: void - Processes and sends the message to DLQ topic\n- `producer()`: KafkaProducer<byte[], byte[]> - Returns or creates a Kafka producer instance\n- `convertToBytes(RuleContext ctx, Object message)`: byte[] - Converts various message types to byte arrays\n- `convertToJsonBytes(RuleContext ctx, Object message)`: byte[] - Converts objects to JSON byte arrays\n- `populateHeaders(RuleContext ctx, ProducerRecord<byte[], byte[]> producerRecord, RuleException ex)`: void - Adds rule context information to message headers\n- `toBytes(String value)`: byte[] - Helper method to convert strings to UTF-8 bytes\n- `baseProducerConfigs()`: Map<String, Object> - Creates base configuration for Kafka producer\n- `close()`: void - Closes the Kafka producer when no longer needed",
  "Canonical_solution": "import com.fasterxml.jackson.databind.JsonNode;\nimport io.confluent.kafka.schemaregistry.utils.JacksonMapper;\nimport java.io.IOException;\nimport java.nio.ByteBuffer;\nimport java.nio.charset.StandardCharsets;\nimport java.util.HashMap;\nimport java.util.Map;\nimport java.util.UUID;\nimport org.apache.kafka.clients.producer.KafkaProducer;\nimport org.apache.kafka.clients.producer.ProducerConfig;\nimport org.apache.kafka.clients.producer.ProducerRecord;\nimport org.apache.kafka.common.errors.SerializationException;\nimport org.apache.kafka.common.header.Headers;\nimport org.apache.kafka.common.serialization.DoubleSerializer;\nimport org.apache.kafka.common.serialization.FloatSerializer;\nimport org.apache.kafka.common.serialization.IntegerSerializer;\nimport org.apache.kafka.common.serialization.LongSerializer;\nimport org.apache.kafka.common.serialization.ShortSerializer;\nimport org.apache.kafka.common.utils.Bytes;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\npublic class DlqAction implements RuleAction {\n\n  private static final Logger log = LoggerFactory.getLogger(DlqAction.class);\n\n  public static final String TYPE = \"DLQ\";\n  public static final String DLQ_TOPIC = \"dlq.topic\";\n  public static final String DLQ_AUTO_FLUSH = \"dlq.auto.flush\";\n  public static final String PRODUCER = \"producer\";\n  public static final String HEADER_PREFIX = \"__rule.\";\n  public static final String RULE_NAME = HEADER_PREFIX + \"name\";\n  public static final String RULE_MODE = HEADER_PREFIX + \"mode\";\n  public static final String RULE_SUBJECT = HEADER_PREFIX + \"subject\";\n  public static final String RULE_TOPIC = HEADER_PREFIX + \"topic\";\n  public static final String RULE_EXCEPTION = HEADER_PREFIX + \"exception\";\n\n  private static final LongSerializer LONG_SERIALIZER = new LongSerializer();\n  private static final IntegerSerializer INT_SERIALIZER = new IntegerSerializer();\n  private static final ShortSerializer SHORT_SERIALIZER = new ShortSerializer();\n  private static final DoubleSerializer DOUBLE_SERIALIZER = new DoubleSerializer();\n  private static final FloatSerializer FLOAT_SERIALIZER = new FloatSerializer();\n\n  private Map<String, ?> configs;\n  private String topic;\n  private boolean autoFlush;\n  private volatile KafkaProducer<byte[], byte[]> producer;\n\n  @Override\n  public void configure(Map<String, ?> configs) {\n    this.configs = configs;\n    this.topic = (String) configs.get(DLQ_TOPIC);\n    Object autoFlushConfig = configs.get(DLQ_AUTO_FLUSH);\n    if (autoFlushConfig != null) {\n      this.autoFlush = Boolean.parseBoolean(autoFlushConfig.toString());\n    }\n    this.producer = (KafkaProducer<byte[], byte[]>) configs.get(PRODUCER);\n  }\n\n  public void run(RuleContext ctx, Object message, RuleException ex) throws RuleException {\n    String topic = topic();\n    if (topic == null || topic.isEmpty()) {\n      topic = ctx.getParameter(DLQ_TOPIC);\n    }\n    if (topic == null || topic.isEmpty()) {\n      throw new SerializationException(\"Could not send to DLQ as no topic is configured\");\n    }\n    final String dlqTopic = topic;\n    try {\n      byte[] keyBytes = convertToBytes(ctx, ctx.originalKey());\n      byte[] valueBytes = convertToBytes(ctx, ctx.originalValue());\n      ProducerRecord<byte[], byte[]> producerRecord =\n          new ProducerRecord<>(dlqTopic, null, keyBytes, valueBytes, ctx.headers());\n      populateHeaders(ctx, producerRecord, ex);\n      producer().send(producerRecord, (metadata, exception) -> {\n        if (exception != null) {\n          log.error(\"Could not produce message to DLQ topic {}\", dlqTopic, exception);\n        } else {\n          log.info(\"Sent message to DLQ topic {}\", dlqTopic);\n        }\n      });\n      if (autoFlush) {\n        producer.flush();\n      }\n    } catch (Exception e) {\n      log.error(\"Could not produce message to DLQ topic {}\", dlqTopic, e);\n    }\n    throw ex != null ? new SerializationException(\"Rule failed: \" + ctx.rule().getName(), ex)\n        : new SerializationException(\"Rule failed: \" + ctx.rule().getName());\n  }\n\n  private KafkaProducer<byte[], byte[]> producer() {\n    if (producer == null) {\n      Map<String, Object> producerConfigs = baseProducerConfigs();\n      producerConfigs.putAll(configs);\n      synchronized (this) {\n        if (producer == null) {\n          producer = new KafkaProducer<>(producerConfigs);\n        }\n      }\n    }\n    return producer;\n  }\n\n  private byte[] convertToBytes(RuleContext ctx, Object message) throws IOException {\n    if (message == null) {\n      return null;\n    } else if (message instanceof byte[]) {\n      return (byte[]) message;\n    } else if (message instanceof ByteBuffer) {\n      ByteBuffer buffer = (ByteBuffer) message;\n      byte[] bytes = new byte[buffer.remaining()];\n      buffer.get(bytes);\n      return bytes;\n    } else if (message instanceof Bytes) {\n      return ((Bytes) message).get();\n    } else if (message instanceof String || message instanceof UUID) {\n      return message.toString().getBytes(StandardCharsets.UTF_8);\n    } else if (message instanceof Long) {\n      return LONG_SERIALIZER.serialize(ctx.topic(), (Long)message);\n    } else if (message instanceof Integer) {\n      return INT_SERIALIZER.serialize(ctx.topic(), (Integer) message);\n    } else if (message instanceof Short) {\n      return SHORT_SERIALIZER.serialize(ctx.topic(), (Short) message);\n    } else if (message instanceof Double) {\n      return DOUBLE_SERIALIZER.serialize(ctx.topic(), (Double) message);\n    } else if (message instanceof Float) {\n      return FLOAT_SERIALIZER.serialize(ctx.topic(), (Float) message);\n    } else {\n      return convertToJsonBytes(ctx, message);\n    }\n  }\n\n  private byte[] convertToJsonBytes(RuleContext ctx, Object message) throws IOException {\n    JsonNode json = ctx.target().toJson(message);\n    return JacksonMapper.INSTANCE.writeValueAsBytes(json);\n  }\n\n  private void populateHeaders(\n      RuleContext ctx, ProducerRecord<byte[], byte[]> producerRecord, RuleException ex) {\n    Headers headers = producerRecord.headers();\n    headers.add(RULE_NAME, toBytes(ctx.rule().getName()));\n    headers.add(RULE_MODE, toBytes(ctx.ruleMode().name()));\n    headers.add(RULE_SUBJECT, toBytes(ctx.subject()));\n    headers.add(RULE_TOPIC, toBytes(ctx.topic()));\n    if (ex != null) {\n      headers.add(RULE_EXCEPTION, toBytes(ex.getMessage()));\n    }\n  }\n\n  private byte[] toBytes(String value) {\n    if (value != null) {\n      return value.getBytes(StandardCharsets.UTF_8);\n    } else {\n      return null;\n    }\n  }\n\n  static Map<String, Object> baseProducerConfigs() {\n    Map<String, Object> producerProps = new HashMap<>();\n    producerProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,\n        \"org.apache.kafka.common.serialization.ByteArraySerializer\");\n    producerProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,\n        \"org.apache.kafka.common.serialization.ByteArraySerializer\");\n    producerProps.put(ProducerConfig.MAX_BLOCK_MS_CONFIG, Long.toString(Long.MAX_VALUE));\n    producerProps.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, \"false\");\n    producerProps.put(ProducerConfig.ACKS_CONFIG, \"all\");\n    producerProps.put(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, \"1\");\n    producerProps.put(ProducerConfig.DELIVERY_TIMEOUT_MS_CONFIG,\n        Integer.toString(Integer.MAX_VALUE));\n    return producerProps;\n  }\n\n  @Override\n  public void close() {\n    if (producer != null) {\n      producer.close();\n    }\n  }\n}",
  "FSMID_for_test": 31,
  "Code_level": "Class-level"
}