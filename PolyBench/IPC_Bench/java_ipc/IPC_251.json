{
  "Task_id": 251,
  "Github_ID": "1089149",
  "Github_Project_Name": "spring-batch",
  "Programming_Language": "Java",
  "suffix": ".java",
  "Interface_class": "IPC",
  "Interface_name": "Kafka client Consumer in java",
  "Instruction": "Task Description: Create a Kafka consumer class that reads messages from specified Kafka topic partitions and integrates with Spring Batch for state management and offset tracking.\n\nClass Description: KafkaItemReader is a Spring Batch ItemReader implementation that consumes messages from Kafka topics. It maintains partition offsets, supports state persistence between batches, and provides configurable polling behavior.\n\nAttributes:\n- TOPIC_PARTITION_OFFSETS: [String] - Key for storing partition offsets in execution context\n- DEFAULT_POLL_TIMEOUT: [long] - Default timeout duration for consumer polling (30 seconds)\n- topicPartitions: [List<TopicPartition>] - List of topic partitions to consume from\n- partitionOffsets: [Map<TopicPartition, Long>] - Current offsets for each partition\n- kafkaConsumer: [KafkaConsumer<K, V>] - Kafka consumer instance\n- consumerProperties: [Properties] - Configuration properties for Kafka consumer\n- consumerRecords: [Iterator<ConsumerRecord<K, V>>] - Iterator for currently polled records\n- pollTimeout: [Duration] - Timeout duration for polling messages\n- saveState: [boolean] - Flag indicating whether to save consumer state\n\nMethods:\n- KafkaItemReader(Properties, String, Integer...) -> [Constructor] - Creates reader with properties, topic name, and partition array\n- KafkaItemReader(Properties, String, List<Integer>) -> [Constructor] - Creates reader with properties, topic name, and partition list\n- open(ExecutionContext) -> [void] - Initializes Kafka consumer, restores offsets if available, and seeks to appropriate positions\n- read() -> [V] - Reads next message from Kafka, returns message value or null if no messages available\n- update(ExecutionContext) -> [void] - Saves current partition offsets to execution context and commits offsets to Kafka\n- close() -> [void] - Closes the Kafka consumer when reader is no longer needed",
  "Canonical_solution": "import org.apache.kafka.clients.consumer.ConsumerConfig;\nimport org.apache.kafka.clients.consumer.ConsumerRecord;\nimport org.apache.kafka.clients.consumer.KafkaConsumer;\nimport org.apache.kafka.common.TopicPartition;\nimport org.springframework.batch.item.ExecutionContext;\nimport org.springframework.batch.item.support.AbstractItemStreamItemReader;\nimport org.springframework.lang.Nullable;\nimport org.springframework.util.Assert;\n\nimport java.time.Duration;\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.HashMap;\nimport java.util.Iterator;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Properties;\n\npublic class KafkaItemReader<K, V> extends AbstractItemStreamItemReader<V> {\n\n    private static final String TOPIC_PARTITION_OFFSETS = \"topic.partition.offsets\";\n    private static final long DEFAULT_POLL_TIMEOUT = 30L;\n\n    private final List<TopicPartition> topicPartitions;\n    private Map<TopicPartition, Long> partitionOffsets;\n    private KafkaConsumer<K, V> kafkaConsumer;\n    private final Properties consumerProperties;\n    private Iterator<ConsumerRecord<K, V>> consumerRecords;\n    private Duration pollTimeout = Duration.ofSeconds(DEFAULT_POLL_TIMEOUT);\n    private boolean saveState = true;\n\n    public KafkaItemReader(Properties consumerProperties, String topicName, Integer... partitions) {\n        this(consumerProperties, topicName, Arrays.asList(partitions));\n    }\n\n    public KafkaItemReader(Properties consumerProperties, String topicName, List<Integer> partitions) {\n        Assert.notNull(consumerProperties, \"Consumer properties must not be null\");\n        Assert.isTrue(consumerProperties.containsKey(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG),\n                ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG + \" property must be provided\");\n        Assert.isTrue(consumerProperties.containsKey(ConsumerConfig.GROUP_ID_CONFIG),\n                ConsumerConfig.GROUP_ID_CONFIG + \" property must be provided\");\n        Assert.isTrue(consumerProperties.containsKey(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG),\n                ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG + \" property must be provided\");\n        Assert.isTrue(consumerProperties.containsKey(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG),\n                ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG + \" property must be provided\");\n        this.consumerProperties = consumerProperties;\n        Assert.hasLength(topicName, \"Topic name must not be null or empty\");\n        Assert.isTrue(!partitions.isEmpty(), \"At least one partition must be provided\");\n        this.topicPartitions = new ArrayList<>();\n        for (Integer partition : partitions) {\n            this.topicPartitions.add(new TopicPartition(topicName, partition));\n        }\n    }\n\n    @Override\n    public void open(ExecutionContext executionContext) {\n        this.kafkaConsumer = new KafkaConsumer<>(this.consumerProperties);\n        if (this.partitionOffsets == null) {\n            this.partitionOffsets = new HashMap<>();\n            for (TopicPartition topicPartition : this.topicPartitions) {\n                this.partitionOffsets.put(topicPartition, 0L);\n            }\n        }\n        if (this.saveState && executionContext.containsKey(TOPIC_PARTITION_OFFSETS)) {\n            Map<TopicPartition, Long> offsets = (Map<TopicPartition, Long>) executionContext\n                    .get(TOPIC_PARTITION_OFFSETS);\n            for (Map.Entry<TopicPartition, Long> entry : offsets.entrySet()) {\n                this.partitionOffsets.put(entry.getKey(), entry.getValue() == 0 ? 0 : entry.getValue() + 1);\n            }\n        }\n        this.kafkaConsumer.assign(this.topicPartitions);\n        this.partitionOffsets.forEach(this.kafkaConsumer::seek);\n    }\n\n    @Nullable\n    @Override\n    public V read() {\n        if (this.consumerRecords == null || !this.consumerRecords.hasNext()) {\n            this.consumerRecords = this.kafkaConsumer.poll(this.pollTimeout).iterator();\n        }\n        if (this.consumerRecords.hasNext()) {\n            ConsumerRecord<K, V> record = this.consumerRecords.next();\n            this.partitionOffsets.put(new TopicPartition(record.topic(), record.partition()), record.offset());\n            return record.value();\n        }\n        else {\n            return null;\n        }\n    }\n\n    @Override\n    public void update(ExecutionContext executionContext) {\n        if (this.saveState) {\n            executionContext.put(TOPIC_PARTITION_OFFSETS, new HashMap<>(this.partitionOffsets));\n        }\n        this.kafkaConsumer.commitSync();\n    }\n\n    @Override\n    public void close() {\n        if (this.kafkaConsumer != null) {\n            this.kafkaConsumer.close();\n        }\n    }\n}",
  "FSMID_for_test": 32,
  "Code_level": "Class-level"
}