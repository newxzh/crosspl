{
  "Task_id": 113,
  "Github_ID": "622202906",
  "Github_Project_Name": "Otter",
  "Programming_Language": "Python",
  "suffix": ".py",
  "Interface_class": "IPC",
  "Interface_name": "HTTP Client-side by using requests in python",
  "Instruction": "Task Description: Implement a Python class that interacts with OpenAI's GPT-4 Vision API to process image and text prompts, handling image encoding and API communication with retry logic.\n\nClass Description: OpenAIGPT4Vision is a client for OpenAI's GPT-4 Vision API that processes both text and image inputs. It handles image conversion to base64 format, API request construction, and response processing with built-in retry mechanisms for failed requests.\n\nAttributes:\napi_key: str - The OpenAI API key for authentication\nheaders: dict - HTTP headers including Content-Type and Authorization\nmax_new_tokens: int - Maximum number of tokens to generate in the response (default: 256)\n\nMethods:\n__init__(api_key: str, max_new_tokens: int = 256) -> None - Initializes the API client with authentication and configuration\nencode_image_to_base64(raw_image_data: PIL.Image.Image) -> str - Static method that converts PIL Image to base64 encoded string\ngenerate(text_prompt: str, raw_image_data: Union[PIL.Image.Image, dict, str]) -> str - Processes text and image input, calls the API, and returns the generated content\n_get_pil_image(raw_image_data: Union[PIL.Image.Image, dict, str]) -> PIL.Image.Image - Static helper method to convert various image formats to PIL Image object",
  "Canonical_solution": "import requests\nimport base64\nfrom PIL import Image\nimport io\nimport time\n\nclass OpenAIGPT4Vision:\n    def __init__(self, api_key: str, max_new_tokens: int = 256):\n        self.api_key = api_key\n        self.headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {api_key}\"}\n        self.max_new_tokens = max_new_tokens\n\n    @staticmethod\n    def encode_image_to_base64(raw_image_data) -> str:\n        if isinstance(raw_image_data, Image.Image):\n            buffered = io.BytesIO()\n            raw_image_data.save(buffered, format=\"JPEG\")\n            return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n        raise ValueError(\"The input image data must be a PIL.Image.Image\")\n\n    def generate(self, text_prompt: str, raw_image_data):\n        raw_image_data = self._get_pil_image(raw_image_data).convert(\"RGB\")\n        base64_image = self.encode_image_to_base64(raw_image_data)\n\n        payload = {\n            \"model\": \"gpt-4-vision-preview\",\n            \"messages\": [\n                {\n                    \"role\": \"user\",\n                    \"content\": [\n                        {\"type\": \"text\", \"text\": text_prompt},\n                        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}},\n                    ],\n                }\n            ],\n            \"max_tokens\": self.max_new_tokens,\n        }\n\n        retry = True\n        retry_times = 0\n        while retry and retry_times < 5:\n            response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=self.headers, json=payload)\n            if response.status_code == 200:\n                response_data = response.json()\n                return response_data[\"choices\"][0][\"message\"][\"content\"]\n            else:\n                print(f\"Failed to connect to OpenAI API: {response.status_code} - {response.text}. Retrying...\")\n                time.sleep(10)\n                retry_times += 1\n        return \"Failed to connect to OpenAI GPT4V API\"\n\n    @staticmethod\n    def _get_pil_image(raw_image_data) -> Image.Image:\n        if isinstance(raw_image_data, Image.Image):\n            return raw_image_data\n        elif isinstance(raw_image_data, dict) and \"bytes\" in raw_image_data:\n            return Image.open(io.BytesIO(raw_image_data[\"bytes\"]))\n        elif isinstance(raw_image_data, str):\n            image_bytes = base64.b64decode(raw_image_data)\n            return Image.open(io.BytesIO(image_bytes))\n        else:\n            raise ValueError(\"Unsupported image data format\")",
  "FSMID_for_test": 57,
  "Code_level": "Class-level"
}