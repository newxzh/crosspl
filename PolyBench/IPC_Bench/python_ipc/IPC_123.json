{
  "Task_id": 123,
  "Github_ID": "625961301",
  "Github_Project_Name": "sd-webui-segment-anything",
  "Programming_Language": "Python",
  "suffix": ".py",
  "Interface_class": "IPC",
  "Interface_name": "HTTP Server - side by using FastAPI in python",
  "Instruction": "Task Description: Create a FastAPI-based HTTP server for handling image segmentation and processing requests using SAM (Segment Anything Model) and related models.\n\nClass Description: SamAPI is a class that encapsulates all the route handlers for a FastAPI application dealing with image segmentation tasks. It provides endpoints for model prediction, mask dilation, and various segmentation techniques.\n\nAttributes:\n- app: FastAPI - The FastAPI application instance that will handle HTTP requests\n\nMethods:\n- __init__(app: FastAPI) -> None - Initializes the SamAPI class with a FastAPI instance and sets up routes\n- _setup_routes() -> None - Private method that defines all API endpoints and their handlers\n\nRoute Handlers (methods defined within _setup_routes):\n- heartbeat() -> Dict - Simple health check endpoint\n- api_sam_model() -> List[str] - Returns available SAM models\n- api_sam_predict(payload: SamPredictRequest) -> Any - Handles SAM model prediction requests\n- api_dino_predict(payload: DINOPredictRequest) -> Any - Handles DINO model prediction requests\n- api_dilate_mask(payload: DilateMaskRequest) -> Any - Handles mask dilation requests\n- api_controlnet_seg(payload: ControlNetSegRequest, autosam_conf: AutoSAMConfig) -> Any - Handles ControlNet segmentation requests\n- api_category_mask(payload: CategoryMaskRequest, autosam_conf: AutoSAMConfig) -> Any - Handles category-specific mask generation requests\n\nSupporting Models (Pydantic BaseModel classes):\n- SamPredictRequest - Request model for SAM predictions\n- DINOPredictRequest - Request model for DINO predictions\n- DilateMaskRequest - Request model for mask dilation\n- AutoSAMConfig - Configuration model for AutoSAM parameters\n- ControlNetSegRequest - Request model for ControlNet segmentation\n- CategoryMaskRequest - Request model for category-specific masking",
  "Canonical_solution": "from fastapi import FastAPI, Body\nfrom pydantic import BaseModel\nfrom typing import Any, Optional, List\nfrom PIL import Image\nimport numpy as np\nimport os\n\nclass SamAPI:\n    def __init__(self, app: FastAPI):\n        self.app = app\n        self._setup_routes()\n\n    class SamPredictRequest(BaseModel):\n        sam_model_name: str = \"sam_vit_h_4b8939.pth\"\n        input_image: str\n        sam_positive_points: List[List[float]] = []\n        sam_negative_points: List[List[float]] = []\n        dino_enabled: bool = False\n        dino_model_name: Optional[str] = \"GroundingDINO_SwinT_OGC (694MB)\"\n        dino_text_prompt: Optional[str] = None\n        dino_box_threshold: Optional[float] = 0.3\n        dino_preview_checkbox: bool = False\n        dino_preview_boxes_selection: Optional[List[int]] = None\n\n    class DINOPredictRequest(BaseModel):\n        input_image: str\n        dino_model_name: str = \"GroundingDINO_SwinT_OGC (694MB)\"\n        text_prompt: str\n        box_threshold: float = 0.3\n\n    class DilateMaskRequest(BaseModel):\n        input_image: str\n        mask: str\n        dilate_amount: int = 10\n\n    class AutoSAMConfig(BaseModel):\n        points_per_side: Optional[int] = 32\n        points_per_batch: int = 64\n        pred_iou_thresh: float = 0.88\n        stability_score_thresh: float = 0.95\n        stability_score_offset: float = 1.0\n        box_nms_thresh: float = 0.7\n        crop_n_layers: int = 0\n        crop_nms_thresh: float = 0.7\n        crop_overlap_ratio: float = 512 / 1500\n        crop_n_points_downscale_factor: int = 1\n        min_mask_region_area: int = 0\n\n    class ControlNetSegRequest(BaseModel):\n        sam_model_name: str = \"sam_vit_h_4b8939.pth\"\n        input_image: str\n        processor: str = \"seg_ofade20k\"\n        processor_res: int = 512\n        pixel_perfect: bool = False\n        resize_mode: Optional[int] = 1\n        target_W: Optional[int] = None\n        target_H: Optional[int] = None\n\n    class CategoryMaskRequest(BaseModel):\n        sam_model_name: str = \"sam_vit_h_4b8939.pth\"\n        processor: str = \"seg_ofade20k\"\n        processor_res: int = 512\n        pixel_perfect: bool = False\n        resize_mode: Optional[int] = 1\n        target_W: Optional[int] = None\n        target_H: Optional[int] = None\n        category: str\n        input_image: str\n\n    def _setup_routes(self):\n        @self.app.get(\"/sam/heartbeat\")\n        async def heartbeat():\n            return {\"msg\": \"Success!\"}\n\n        @self.app.get(\"/sam/sam-model\")\n        async def api_sam_model() -> List[str]:\n            return sam_model_list\n\n        @self.app.post(\"/sam/sam-predict\")\n        async def api_sam_predict(payload: SamPredictRequest = Body(...)) -> Any:\n            payload.input_image = decode_to_pil(payload.input_image).convert('RGBA')\n            sam_output_mask_gallery, sam_message = sam_predict(\n                payload.sam_model_name,\n                payload.input_image,\n                payload.sam_positive_points,\n                payload.sam_negative_points,\n                payload.dino_enabled,\n                payload.dino_model_name,\n                payload.dino_text_prompt,\n                payload.dino_box_threshold,\n                payload.dino_preview_checkbox,\n                payload.dino_preview_boxes_selection)\n            result = {\"msg\": sam_message}\n            if len(sam_output_mask_gallery) == 9:\n                result[\"blended_images\"] = list(map(encode_to_base64, sam_output_mask_gallery[:3]))\n                result[\"masks\"] = list(map(encode_to_base64, sam_output_mask_gallery[3:6]))\n                result[\"masked_images\"] = list(map(encode_to_base64, sam_output_mask_gallery[6:]))\n            return result\n\n        @self.app.post(\"/sam/dino-predict\")\n        async def api_dino_predict(payload: DINOPredictRequest = Body(...)) -> Any:\n            payload.input_image = decode_to_pil(payload.input_image)\n            dino_output_img, _, dino_msg = dino_predict(\n                payload.input_image,\n                payload.dino_model_name,\n                payload.text_prompt,\n                payload.box_threshold)\n            return {\n                \"msg\": dino_msg[\"value\"] if \"value\" in dino_msg else \"Done\",\n                \"image_with_box\": encode_to_base64(dino_output_img) if dino_output_img is not None else None,\n            }\n\n        @self.app.post(\"/sam/dilate-mask\")\n        async def api_dilate_mask(payload: DilateMaskRequest = Body(...)) -> Any:\n            payload.input_image = decode_to_pil(payload.input_image).convert(\"RGBA\")\n            payload.mask = decode_to_pil(payload.mask)\n            dilate_result = list(map(encode_to_base64, update_mask(payload.mask, 0, payload.dilate_amount, payload.input_image)))\n            return {\"blended_image\": dilate_result[0], \"mask\": dilate_result[1], \"masked_image\": dilate_result[2]}\n\n        @self.app.post(\"/sam/controlnet-seg\")\n        async def api_controlnet_seg(payload: ControlNetSegRequest = Body(...),\n                                    autosam_conf: AutoSAMConfig = Body(...)) -> Any:\n            payload.input_image = decode_to_pil(payload.input_image)\n            cnet_seg_img, cnet_seg_msg = cnet_seg(\n                payload.sam_model_name,\n                payload.input_image,\n                payload.processor,\n                payload.processor_res,\n                payload.pixel_perfect,\n                payload.resize_mode,\n                payload.target_W,\n                payload.target_H,\n                autosam_conf.points_per_side,\n                autosam_conf.points_per_batch,\n                autosam_conf.pred_iou_thresh,\n                autosam_conf.stability_score_thresh,\n                autosam_conf.stability_score_offset,\n                autosam_conf.box_nms_thresh,\n                autosam_conf.crop_n_layers,\n                autosam_conf.crop_nms_thresh,\n                autosam_conf.crop_overlap_ratio,\n                autosam_conf.crop_n_points_downscale_factor,\n                autosam_conf.min_mask_region_area)\n            cnet_seg_img = list(map(encode_to_base64, cnet_seg_img))\n            result = {\"msg\": cnet_seg_msg}\n            if len(cnet_seg_img) == 3:\n                result[\"blended_images\"] = cnet_seg_img[0]\n                result[\"random_seg\"] = cnet_seg_img[1]\n                result[\"edit_anything_control\"] = cnet_seg_img[2]\n            elif len(cnet_seg_img) == 4:\n                result[\"sem_presam\"] = cnet_seg_img[0]\n                result[\"sem_postsam\"] = cnet_seg_img[1]\n                result[\"blended_presam\"] = cnet_seg_img[2]\n                result[\"blended_postsam\"] = cnet_seg_img[3]\n            return result\n\n        @self.app.post(\"/sam/category-mask\")\n        async def api_category_mask(payload: CategoryMaskRequest = Body(...),\n                                  autosam_conf: AutoSAMConfig = Body(...)) -> Any:\n            payload.input_image = decode_to_pil(payload.input_image)\n            category_mask_img, category_mask_msg, resized_input_img = categorical_mask(\n                payload.sam_model_name,\n                payload.processor,\n                payload.processor_res,\n                payload.pixel_perfect,\n                payload.resize_mode,\n                payload.target_W,\n                payload.target_H,\n                payload.category,\n                payload.input_image,\n                autosam_conf.points_per_side,\n                autosam_conf.points_per_batch,\n                autosam_conf.pred_iou_thresh,\n                autosam_conf.stability_score_thresh,\n                autosam_conf.stability_score_offset,\n                autosam_conf.box_nms_thresh,\n                autosam_conf.crop_n_layers,\n                autosam_conf.crop_nms_thresh,\n                autosam_conf.crop_overlap_ratio,\n                autosam_conf.crop_n_points_downscale_factor,\n                autosam_conf.min_mask_region_area)\n            category_mask_img = list(map(encode_to_base64, category_mask_img))\n            result = {\"msg\": category_mask_msg}\n            if len(category_mask_img) == 3:\n                result[\"blended_image\"] = category_mask_img[0]\n                result[\"mask\"] = category_mask_img[1]\n                result[\"masked_image\"] = category_mask_img[2]\n            if resized_input_img is not None:\n                result[\"resized_input\"] = encode_to_base64(resized_input_img)\n            return result",
  "FSMID_for_test": 61,
  "Code_level": "Class-level"
}